2020-06-06 22:54:20.412987: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-06-06 22:54:20.983998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:3b:00.0
totalMemory: 31.72GiB freeMemory: 16.66GiB
2020-06-06 22:54:20.984045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-06-06 22:54:22.143947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-06 22:54:22.143995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-06-06 22:54:22.144007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-06-06 22:54:22.144363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12992 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
Arguments:
  f: 
  bert_config_file: ./mnt/bert/uncased_L-12_H-768_A-12/bert_config.json
  vocab_file: ./mnt/bert/uncased_L-12_H-768_A-12/vocab.txt
  init_checkpoint: ./11_turns_output/output/model_58000.ckpt
  output_dir: residual_output/
  coqa_train_file: ./mnt/coqa_extractive_gt/coqa-train-v1.0.json
  coqa_predict_file: ./mnt/coqa_extractive_gt/coqa-dev-v1.0.json
  quac_train_file: ./mnt/quac_original/train_v0.2.json
  quac_predict_file: ./mnt/quac_original/val_v0.2.json
  do_lower_case: True
  max_seq_length: 384
  doc_stride: 128
  max_query_length: 64
  do_train: True
  do_predict: True
  train_batch_size: 12
  predict_batch_size: 12
  learning_rate: 3e-05
  num_train_epochs: 2.0
  warmup_proportion: 0.1
  save_checkpoints_steps: 1000
  evaluation_steps: 1000
  evaluate_after: 50000
  iterations_per_loop: 1000
  n_best_size: 20
  max_answer_length: 50
  max_answer_threshold: 40
  use_tpu: False
  tpu_name: None
  tpu_zone: None
  gcp_project: None
  master: None
  num_tpu_cores: 8
  verbose_logging: False
  history: 6
  use_new_attetion: True
  only_history_answer: False
  use_history_answer_marker: True
  load_small_portion: False
  use_RL: False
  dataset: quac
  max_history_turns: 11
  example_batch_size: 4
  cache_dir: cache_4_turns/
  max_considered_history_turns: 11
  train_steps: 58000
  better_hae: False
  history_selection: previous_j
  more_history: 0
  max_question_len_for_matching: 20
  max_answer_len_for_matching: 40
  glove: ./mnt/glove/glove.840B.300d.pkl
  embedding_dim: 300
  kernel_size: 3
  kernel_count: 16
  pool_size: 3
  rl_learning_rate: 0.0001
  MTL: False
  MTL_lambda: 0.1
  MTL_mu: 0.8
  ideal_selected_num: 1
  aux: False
  aux_lambda: 0.0
  aux_shared: False
  disable_attention: False
  history_attention_hidden: False
  history_attention_input: reduce_mean
  mtl_input: reduce_mean
  history_ngram: 1
  reformulate_question: False
  front_padding: False
  freeze_bert: False
  fine_grained_attention: True
  append_self: False
  null_score_diff_threshold: 0.0
  bert_hidden: 768
====
output_dir residual_output/
attempting to load train features from cache
attempting to load val features from cache
***** Running training *****
  Num orig examples = %d 83568
  Num train_features = %d 440164
  Batch size = %d 12
  Num steps = %d 58000
training step: 0, total_loss: 6.086628437042236
training step: 1, total_loss: 4.62647819519043
training step: 2, total_loss: 5.46511173248291
training step: 3, total_loss: 4.518776893615723
training step: 4, total_loss: 5.452467918395996
training step: 5, total_loss: 5.342850685119629
training step: 6, total_loss: 5.480118751525879
training step: 7, total_loss: 5.85552453994751
training step: 8, total_loss: 5.368964195251465
training step: 9, total_loss: 5.739274024963379
training step: 10, total_loss: 5.139809608459473
training step: 11, total_loss: 5.540227890014648
training step: 12, total_loss: 5.583757400512695
training step: 13, total_loss: 4.000895023345947
training step: 14, total_loss: 6.47945499420166
training step: 15, total_loss: 5.8887505531311035
training step: 16, total_loss: 5.694284915924072
training step: 17, total_loss: 6.409494400024414
training step: 18, total_loss: 6.270998001098633
training step: 19, total_loss: 6.122603893280029
training step: 20, total_loss: 5.581146240234375
training step: 21, total_loss: 4.24490213394165
training step: 22, total_loss: 5.962710380554199
training step: 23, total_loss: 5.902181625366211
training step: 24, total_loss: 5.109953880310059
training step: 25, total_loss: 6.277390480041504
training step: 26, total_loss: 5.9396257400512695
training step: 27, total_loss: 6.116749286651611
training step: 28, total_loss: 4.858970642089844
training step: 29, total_loss: 5.251808166503906
training step: 30, total_loss: 5.805075168609619
training step: 31, total_loss: 4.23814582824707
training step: 32, total_loss: 5.46181583404541
training step: 33, total_loss: 4.738872528076172
training step: 34, total_loss: 5.413912773132324
training step: 35, total_loss: 5.531833171844482
training step: 36, total_loss: 4.877538681030273
training step: 37, total_loss: 4.869088649749756
training step: 38, total_loss: 5.9809722900390625
training step: 39, total_loss: 5.340631484985352
training step: 40, total_loss: 5.652881622314453
training step: 41, total_loss: 5.383547306060791
training step: 42, total_loss: 5.118359088897705
training step: 43, total_loss: 5.658195495605469
training step: 44, total_loss: 5.148041248321533
training step: 45, total_loss: 5.484687805175781
training step: 46, total_loss: 6.181644439697266
training step: 47, total_loss: 5.064142227172852
training step: 48, total_loss: 5.905014991760254
training step: 49, total_loss: 6.268007278442383
training step: 50, total_loss: 5.390088081359863
training step: 51, total_loss: 5.007805347442627
training step: 52, total_loss: 5.510842323303223
training step: 53, total_loss: 5.2706170082092285
training step: 54, total_loss: 5.233401298522949
training step: 55, total_loss: 4.924716949462891
training step: 56, total_loss: 6.031585693359375
training step: 57, total_loss: 5.632552623748779
training step: 58, total_loss: 5.746354103088379
training step: 59, total_loss: 5.046913146972656
training step: 60, total_loss: 6.321081161499023
training step: 61, total_loss: 5.3102617263793945
training step: 62, total_loss: 5.626527786254883
training step: 63, total_loss: 5.765683174133301
training step: 64, total_loss: 5.353055000305176
training step: 65, total_loss: 5.268303871154785
training step: 66, total_loss: 5.495722770690918
training step: 67, total_loss: 5.911187171936035
training step: 68, total_loss: 5.222036361694336
training step: 69, total_loss: 4.2482380867004395
training step: 70, total_loss: 4.9597063064575195
training step: 71, total_loss: 5.1472978591918945
training step: 72, total_loss: 5.530325412750244
training step: 73, total_loss: 5.164055347442627
training step: 74, total_loss: 5.768860340118408
training step: 75, total_loss: 5.212555885314941
training step: 76, total_loss: 4.793805122375488
training step: 77, total_loss: 5.186620712280273
training step: 78, total_loss: 5.4451904296875
training step: 79, total_loss: 6.066882133483887
training step: 80, total_loss: 5.313706398010254
training step: 81, total_loss: 5.933286190032959
training step: 82, total_loss: 6.516667366027832
training step: 83, total_loss: 6.338418483734131
training step: 84, total_loss: 5.684177398681641
training step: 85, total_loss: 5.762992858886719
training step: 86, total_loss: 4.870192050933838
training step: 87, total_loss: 4.779158115386963
training step: 88, total_loss: 5.773348808288574
training step: 89, total_loss: 5.609795570373535
training step: 90, total_loss: 6.143048286437988
training step: 91, total_loss: 6.225306034088135
training step: 92, total_loss: 4.984509468078613
training step: 93, total_loss: 5.225100994110107
training step: 94, total_loss: 5.945247650146484
training step: 95, total_loss: 5.320738792419434
training step: 96, total_loss: 4.932186126708984
training step: 97, total_loss: 5.3514509201049805
training step: 98, total_loss: 5.8170928955078125
training step: 99, total_loss: 5.6760029792785645
training step: 100, total_loss: 5.456805229187012
training step: 101, total_loss: 5.274247646331787
training step: 102, total_loss: 5.594900131225586
training step: 103, total_loss: 4.751900672912598
training step: 104, total_loss: 5.515974521636963
training step: 105, total_loss: 5.590388774871826
training step: 106, total_loss: 4.575803756713867
training step: 107, total_loss: 5.331002712249756
training step: 108, total_loss: 5.101623058319092
training step: 109, total_loss: 4.710034370422363
training step: 110, total_loss: 5.373254776000977
training step: 111, total_loss: 5.640037536621094
training step: 112, total_loss: 5.372029781341553
training step: 113, total_loss: 5.53421688079834
training step: 114, total_loss: 6.017550468444824
training step: 115, total_loss: 4.663325786590576
training step: 116, total_loss: 6.265192985534668
training step: 117, total_loss: 5.087368011474609
training step: 118, total_loss: 5.354686737060547
training step: 119, total_loss: 5.074948310852051
training step: 120, total_loss: 6.055845260620117
training step: 121, total_loss: 4.796753883361816
training step: 122, total_loss: 6.266873836517334
training step: 123, total_loss: 4.369428634643555
training step: 124, total_loss: 3.791158437728882
training step: 125, total_loss: 5.515280723571777
training step: 126, total_loss: 5.965378284454346
training step: 127, total_loss: 5.56591796875
training step: 128, total_loss: 5.500588417053223
training step: 129, total_loss: 5.081164360046387
training step: 130, total_loss: 5.950038433074951
training step: 131, total_loss: 5.6591572761535645
training step: 132, total_loss: 5.359714508056641
training step: 133, total_loss: 5.994431495666504
training step: 134, total_loss: 5.682319641113281
training step: 135, total_loss: 4.660141944885254
training step: 136, total_loss: 5.147810459136963
training step: 137, total_loss: 5.5135040283203125
training step: 138, total_loss: 5.923526763916016
training step: 139, total_loss: 5.598031997680664
training step: 140, total_loss: 5.611911296844482
training step: 141, total_loss: 5.245176315307617
training step: 142, total_loss: 5.238969802856445
training step: 143, total_loss: 5.051266193389893
training step: 144, total_loss: 5.435487270355225
training step: 145, total_loss: 4.288059234619141
training step: 146, total_loss: 5.275852680206299
training step: 147, total_loss: 5.421342849731445
training step: 148, total_loss: 4.267811298370361
training step: 149, total_loss: 6.356934547424316
training step: 150, total_loss: 5.481235980987549
training step: 151, total_loss: 4.754634857177734
training step: 152, total_loss: 5.663649559020996
training step: 153, total_loss: 5.015374183654785
training step: 154, total_loss: 3.9937586784362793
training step: 155, total_loss: 5.479328155517578
training step: 156, total_loss: 4.8085713386535645
training step: 157, total_loss: 6.635622978210449
training step: 158, total_loss: 5.118403434753418
training step: 159, total_loss: 6.005213737487793
training step: 160, total_loss: 4.325331211090088
training step: 161, total_loss: 6.729283809661865
training step: 162, total_loss: 4.87924861907959
training step: 163, total_loss: 5.9245452880859375
training step: 164, total_loss: 5.940855979919434
training step: 165, total_loss: 5.609101295471191
training step: 166, total_loss: 5.7108941078186035
training step: 167, total_loss: 5.081563949584961
training step: 168, total_loss: 5.4221415519714355
training step: 169, total_loss: 4.287503242492676
training step: 170, total_loss: 4.692002296447754
training step: 171, total_loss: 5.066126823425293
training step: 172, total_loss: 5.488835334777832
training step: 173, total_loss: 5.587896347045898
training step: 174, total_loss: 4.91046142578125
training step: 175, total_loss: 4.704839706420898
training step: 176, total_loss: 5.581616401672363
training step: 177, total_loss: 6.374868392944336
training step: 178, total_loss: 5.581103801727295
training step: 179, total_loss: 5.471375942230225
training step: 180, total_loss: 5.831182479858398
training step: 181, total_loss: 5.5305986404418945
training step: 182, total_loss: 5.443304061889648
training step: 183, total_loss: 5.489682674407959
training step: 184, total_loss: 4.8160905838012695
training step: 185, total_loss: 5.071114540100098
training step: 186, total_loss: 5.872576713562012
training step: 187, total_loss: 5.559257507324219
training step: 188, total_loss: 5.8902587890625
training step: 189, total_loss: 5.8072123527526855
training step: 190, total_loss: 5.896640777587891
training step: 191, total_loss: 4.231980323791504
training step: 192, total_loss: 5.182177543640137
training step: 193, total_loss: 4.62923526763916
training step: 194, total_loss: 6.02093505859375
training step: 195, total_loss: 6.193395137786865
training step: 196, total_loss: 5.465964317321777
training step: 197, total_loss: 5.502819538116455
training step: 198, total_loss: 4.619850158691406
training step: 199, total_loss: 5.800975322723389
training step: 200, total_loss: 4.977932929992676
training step: 201, total_loss: 5.003413677215576
training step: 202, total_loss: 4.2982177734375
training step: 203, total_loss: 4.574555397033691
training step: 204, total_loss: 5.715122222900391
training step: 205, total_loss: 4.551400184631348
training step: 206, total_loss: 6.1805620193481445
training step: 207, total_loss: 5.604687690734863
training step: 208, total_loss: 5.045658111572266
training step: 209, total_loss: 5.32265043258667
training step: 210, total_loss: 6.707805633544922
training step: 211, total_loss: 6.4609270095825195
training step: 212, total_loss: 6.096711158752441
training step: 213, total_loss: 5.187619686126709
training step: 214, total_loss: 5.833304405212402
training step: 215, total_loss: 5.6463189125061035
training step: 216, total_loss: 5.350943565368652
training step: 217, total_loss: 4.956575393676758
training step: 218, total_loss: 6.079891204833984
training step: 219, total_loss: 5.474431037902832
training step: 220, total_loss: 6.0403313636779785
training step: 221, total_loss: 5.102017879486084
training step: 222, total_loss: 6.147061347961426
training step: 223, total_loss: 6.347133636474609
training step: 224, total_loss: 5.590557098388672
training step: 225, total_loss: 4.819331645965576
training step: 226, total_loss: 5.216276168823242
training step: 227, total_loss: 5.579400062561035
training step: 228, total_loss: 5.669904708862305
training step: 229, total_loss: 6.079520225524902
training step: 230, total_loss: 5.321256160736084
training step: 231, total_loss: 5.730816841125488
training step: 232, total_loss: 5.341734886169434
training step: 233, total_loss: 5.48660945892334
training step: 234, total_loss: 5.8223090171813965
training step: 235, total_loss: 5.199769973754883
training step: 236, total_loss: 4.762855052947998
training step: 237, total_loss: 4.862666606903076
training step: 238, total_loss: 4.036547660827637
training step: 239, total_loss: 4.792831897735596
training step: 240, total_loss: 4.812459945678711
training step: 241, total_loss: 5.5366106033325195
training step: 242, total_loss: 5.042804718017578
training step: 243, total_loss: 4.679040908813477
training step: 244, total_loss: 5.748048305511475
training step: 245, total_loss: 6.76641845703125
training step: 246, total_loss: 4.923011779785156
training step: 247, total_loss: 5.377965927124023
training step: 248, total_loss: 4.8282470703125
training step: 249, total_loss: 4.355316162109375
training step: 250, total_loss: 6.2145209312438965
training step: 251, total_loss: 4.457990646362305
training step: 252, total_loss: 5.228244781494141
training step: 253, total_loss: 4.946977615356445
training step: 254, total_loss: 4.498950958251953
training step: 255, total_loss: 5.987809181213379
training step: 256, total_loss: 6.456079959869385
training step: 257, total_loss: 4.942168712615967
training step: 258, total_loss: 5.766380310058594
training step: 259, total_loss: 6.331173896789551
training step: 260, total_loss: 4.510932922363281
training step: 261, total_loss: 5.119851589202881
training step: 262, total_loss: 5.791649341583252
training step: 263, total_loss: 5.088946342468262
training step: 264, total_loss: 6.4688639640808105
training step: 265, total_loss: 5.661471366882324
training step: 266, total_loss: 5.509276390075684
training step: 267, total_loss: 6.209590435028076
training step: 268, total_loss: 4.495754718780518
training step: 269, total_loss: 4.517111778259277
training step: 270, total_loss: 5.916740417480469
training step: 271, total_loss: 5.841362953186035
training step: 272, total_loss: 5.420431137084961
training step: 273, total_loss: 5.083583831787109
training step: 274, total_loss: 4.8866424560546875
training step: 275, total_loss: 5.098468780517578
training step: 276, total_loss: 5.845484733581543
training step: 277, total_loss: 5.5691351890563965
training step: 278, total_loss: 5.047432899475098
training step: 279, total_loss: 5.309840202331543
training step: 280, total_loss: 5.744208335876465
training step: 281, total_loss: 5.39548397064209
training step: 282, total_loss: 4.999171257019043
training step: 283, total_loss: 5.954638481140137
training step: 284, total_loss: 5.464066505432129
training step: 285, total_loss: 5.677561283111572
training step: 286, total_loss: 4.876565456390381
training step: 287, total_loss: 6.179598331451416
training step: 288, total_loss: 5.194748878479004
training step: 289, total_loss: 4.959565162658691
training step: 290, total_loss: 3.965075969696045
training step: 291, total_loss: 5.825926780700684
training step: 292, total_loss: 4.711667060852051
training step: 293, total_loss: 4.996623992919922
training step: 294, total_loss: 5.247581481933594
training step: 295, total_loss: 4.9856367111206055
training step: 296, total_loss: 4.347297668457031
training step: 297, total_loss: 5.791535377502441
training step: 298, total_loss: 5.802227020263672
training step: 299, total_loss: 5.243650913238525
training step: 300, total_loss: 6.252623558044434
training step: 301, total_loss: 4.093830585479736
training step: 302, total_loss: 4.419626235961914
training step: 303, total_loss: 4.8372063636779785
training step: 304, total_loss: 5.745175361633301
training step: 305, total_loss: 6.077948570251465
training step: 306, total_loss: 5.61175012588501
training step: 307, total_loss: 4.955735206604004
training step: 308, total_loss: 4.5839643478393555
training step: 309, total_loss: 3.9046144485473633
training step: 310, total_loss: 4.962662220001221
training step: 311, total_loss: 5.988122463226318
training step: 312, total_loss: 5.705386161804199
training step: 313, total_loss: 4.863762855529785
training step: 314, total_loss: 3.9498682022094727
training step: 315, total_loss: 5.978429794311523
training step: 316, total_loss: 6.564509868621826
training step: 317, total_loss: 5.431301116943359
training step: 318, total_loss: 5.958117485046387
training step: 319, total_loss: 5.255984306335449
training step: 320, total_loss: 6.216382026672363
training step: 321, total_loss: 4.440973281860352
training step: 322, total_loss: 5.078782081604004
training step: 323, total_loss: 4.856657981872559
training step: 324, total_loss: 5.169536590576172
training step: 325, total_loss: 5.436089515686035
training step: 326, total_loss: 4.4020233154296875
training step: 327, total_loss: 5.00622034072876
training step: 328, total_loss: 6.151520729064941
training step: 329, total_loss: 6.383889198303223
training step: 330, total_loss: 5.115732192993164
training step: 331, total_loss: 6.07001256942749
training step: 332, total_loss: 5.432051658630371
training step: 333, total_loss: 4.760644435882568
training step: 334, total_loss: 4.530313014984131
training step: 335, total_loss: 5.291433334350586
training step: 336, total_loss: 6.624629497528076
training step: 337, total_loss: 6.7439494132995605
training step: 338, total_loss: 5.9282402992248535
training step: 339, total_loss: 3.985569953918457
training step: 340, total_loss: 4.875201225280762
training step: 341, total_loss: 6.088381767272949
training step: 342, total_loss: 5.571990966796875
training step: 343, total_loss: 5.508707046508789
training step: 344, total_loss: 5.837571144104004
training step: 345, total_loss: 5.80568790435791
training step: 346, total_loss: 4.996590614318848
training step: 347, total_loss: 5.451846599578857
training step: 348, total_loss: 5.54444694519043
training step: 349, total_loss: 4.869348049163818
training step: 350, total_loss: 5.444169998168945
training step: 351, total_loss: 6.286916732788086
training step: 352, total_loss: 4.6445393562316895
training step: 353, total_loss: 5.8078460693359375
training step: 354, total_loss: 5.5792436599731445
training step: 355, total_loss: 5.608205318450928
training step: 356, total_loss: 5.177345275878906
training step: 357, total_loss: 5.925739288330078
training step: 358, total_loss: 5.692614555358887
training step: 359, total_loss: 5.345941543579102
training step: 360, total_loss: 5.591249942779541
training step: 361, total_loss: 5.191448211669922
training step: 362, total_loss: 5.429551124572754
training step: 363, total_loss: 4.6905364990234375
training step: 364, total_loss: 5.503472328186035
training step: 365, total_loss: 5.1466064453125
training step: 366, total_loss: 4.786571979522705
training step: 367, total_loss: 6.281381130218506
training step: 368, total_loss: 5.574263095855713
training step: 369, total_loss: 5.620213031768799
training step: 370, total_loss: 5.249730110168457
training step: 371, total_loss: 4.898029327392578
training step: 372, total_loss: 6.341038227081299
training step: 373, total_loss: 5.226768493652344
training step: 374, total_loss: 6.367156028747559
training step: 375, total_loss: 6.101324081420898
training step: 376, total_loss: 5.824949741363525
training step: 377, total_loss: 4.962906837463379
training step: 378, total_loss: 4.890537261962891
training step: 379, total_loss: 4.431024551391602
training step: 380, total_loss: 5.51108980178833
training step: 381, total_loss: 5.642179489135742
training step: 382, total_loss: 4.613899230957031
training step: 383, total_loss: 5.2289299964904785
training step: 384, total_loss: 4.402708053588867
training step: 385, total_loss: 6.517521858215332
training step: 386, total_loss: 4.597818374633789
training step: 387, total_loss: 6.246611595153809
training step: 388, total_loss: 5.9242401123046875
training step: 389, total_loss: 4.749835014343262
training step: 390, total_loss: 4.674149513244629
training step: 391, total_loss: 3.899956226348877
training step: 392, total_loss: 5.941064834594727
training step: 393, total_loss: 4.66217041015625
training step: 394, total_loss: 5.23553466796875
training step: 395, total_loss: 5.435467720031738
training step: 396, total_loss: 5.214730739593506
training step: 397, total_loss: 5.345172882080078
training step: 398, total_loss: 5.384431838989258
training step: 399, total_loss: 6.4449567794799805
training step: 400, total_loss: 5.510987281799316
training step: 401, total_loss: 6.331599235534668
training step: 402, total_loss: 4.310593128204346
training step: 403, total_loss: 5.513169765472412
training step: 404, total_loss: 5.496232986450195
training step: 405, total_loss: 5.631402015686035
training step: 406, total_loss: 5.799434661865234
training step: 407, total_loss: 4.374932289123535
training step: 408, total_loss: 5.678214073181152
training step: 409, total_loss: 6.660157680511475
training step: 410, total_loss: 5.710536003112793
training step: 411, total_loss: 5.508349418640137
training step: 412, total_loss: 4.948174476623535
training step: 413, total_loss: 4.982332229614258
training step: 414, total_loss: 4.674169540405273
training step: 415, total_loss: 4.458438873291016
training step: 416, total_loss: 5.41599178314209
training step: 417, total_loss: 4.8461713790893555
training step: 418, total_loss: 5.478927135467529
training step: 419, total_loss: 5.9003777503967285
training step: 420, total_loss: 5.948306083679199
training step: 421, total_loss: 5.332376480102539
training step: 422, total_loss: 5.1504926681518555
training step: 423, total_loss: 5.938638210296631
training step: 424, total_loss: 4.258668422698975
training step: 425, total_loss: 6.02705717086792
training step: 426, total_loss: 6.1260294914245605
training step: 427, total_loss: 6.317028999328613
training step: 428, total_loss: 5.456489562988281
training step: 429, total_loss: 5.37550163269043
training step: 430, total_loss: 5.819211006164551
training step: 431, total_loss: 5.713757514953613
training step: 432, total_loss: 5.093789100646973
training step: 433, total_loss: 4.858952522277832
training step: 434, total_loss: 6.035791397094727
training step: 435, total_loss: 5.271686553955078
training step: 436, total_loss: 5.667780876159668
training step: 437, total_loss: 4.743017673492432
training step: 438, total_loss: 5.0587992668151855
training step: 439, total_loss: 5.780156135559082
training step: 440, total_loss: 5.263882637023926
training step: 441, total_loss: 5.825494766235352
training step: 442, total_loss: 5.528139591217041
training step: 443, total_loss: 4.946073055267334
training step: 444, total_loss: 4.755198955535889
training step: 445, total_loss: 5.712985992431641
training step: 446, total_loss: 5.899007797241211
training step: 447, total_loss: 5.464649677276611
training step: 448, total_loss: 5.558701515197754
training step: 449, total_loss: 5.389617919921875
training step: 450, total_loss: 5.369411468505859
training step: 451, total_loss: 5.522961616516113
training step: 452, total_loss: 4.8853349685668945
training step: 453, total_loss: 4.701301574707031
training step: 454, total_loss: 5.401725769042969
training step: 455, total_loss: 5.172570705413818
training step: 456, total_loss: 6.6739091873168945
training step: 457, total_loss: 4.739628791809082
training step: 458, total_loss: 4.5267438888549805
training step: 459, total_loss: 5.457252502441406
training step: 460, total_loss: 5.8066253662109375
training step: 461, total_loss: 5.147911071777344
training step: 462, total_loss: 6.207546234130859
training step: 463, total_loss: 4.794692039489746
training step: 464, total_loss: 5.231409549713135
training step: 465, total_loss: 4.06352424621582
training step: 466, total_loss: 3.8330039978027344
training step: 467, total_loss: 4.53394889831543
training step: 468, total_loss: 5.140018939971924
training step: 469, total_loss: 5.681668281555176
training step: 470, total_loss: 5.387945652008057
training step: 471, total_loss: 5.559903144836426
training step: 472, total_loss: 5.217641353607178
training step: 473, total_loss: 5.946118354797363
training step: 474, total_loss: 4.147098541259766
training step: 475, total_loss: 4.53641414642334
training step: 476, total_loss: 6.13810920715332
training step: 477, total_loss: 4.598142623901367
training step: 478, total_loss: 5.158016204833984
training step: 479, total_loss: 5.810266494750977
training step: 480, total_loss: 4.379761695861816
training step: 481, total_loss: 4.94132137298584
training step: 482, total_loss: 6.23460578918457
training step: 483, total_loss: 4.485352516174316
training step: 484, total_loss: 4.549713134765625
training step: 485, total_loss: 5.655673503875732
training step: 486, total_loss: 6.606550693511963
training step: 487, total_loss: 6.430568695068359
training step: 488, total_loss: 3.824069023132324
training step: 489, total_loss: 6.813983917236328
training step: 490, total_loss: 4.290473937988281
training step: 491, total_loss: 5.769243240356445
training step: 492, total_loss: 6.0221147537231445
training step: 493, total_loss: 5.872137069702148
training step: 494, total_loss: 5.457483291625977
training step: 495, total_loss: 6.045447826385498
training step: 496, total_loss: 5.964533805847168
training step: 497, total_loss: 5.246037483215332
training step: 498, total_loss: 6.12713623046875
training step: 499, total_loss: 4.733463764190674
training step: 500, total_loss: 5.5683112144470215
training step: 501, total_loss: 5.759309768676758
training step: 502, total_loss: 5.285097122192383
training step: 503, total_loss: 5.445051193237305
training step: 504, total_loss: 4.914758205413818
training step: 505, total_loss: 4.650658130645752
training step: 506, total_loss: 5.649672985076904
training step: 507, total_loss: 5.870336532592773
training step: 508, total_loss: 5.057974338531494
training step: 509, total_loss: 5.841266632080078
training step: 510, total_loss: 5.541412830352783
training step: 511, total_loss: 5.583353042602539
training step: 512, total_loss: 5.313405990600586
training step: 513, total_loss: 5.422619819641113
training step: 514, total_loss: 5.533069610595703
training step: 515, total_loss: 5.717436790466309
training step: 516, total_loss: 5.036628723144531
training step: 517, total_loss: 5.374828338623047
training step: 518, total_loss: 5.422645092010498
training step: 519, total_loss: 6.4917707443237305
training step: 520, total_loss: 5.49293851852417
training step: 521, total_loss: 5.4796857833862305
training step: 522, total_loss: 5.065645217895508
training step: 523, total_loss: 5.369183540344238
training step: 524, total_loss: 5.470461845397949
training step: 525, total_loss: 5.950303077697754
training step: 526, total_loss: 4.594454765319824
training step: 527, total_loss: 5.797197341918945
training step: 528, total_loss: 5.711642265319824
training step: 529, total_loss: 5.040855407714844
training step: 530, total_loss: 5.923162460327148
training step: 531, total_loss: 5.995875358581543
training step: 532, total_loss: 5.484386444091797
training step: 533, total_loss: 5.498579025268555
training step: 534, total_loss: 5.5446906089782715
training step: 535, total_loss: 4.641169548034668
training step: 536, total_loss: 6.433517932891846
training step: 537, total_loss: 5.120896339416504
training step: 538, total_loss: 5.714931488037109
training step: 539, total_loss: 5.998200416564941
training step: 540, total_loss: 5.192368507385254
training step: 541, total_loss: 5.94904088973999
training step: 542, total_loss: 5.231620788574219
training step: 543, total_loss: 5.31246280670166
training step: 544, total_loss: 5.903055191040039
training step: 545, total_loss: 5.858301639556885
training step: 546, total_loss: 4.759278297424316
training step: 547, total_loss: 5.152413845062256
training step: 548, total_loss: 5.484917640686035
training step: 549, total_loss: 5.966853141784668
training step: 550, total_loss: 4.63355016708374
training step: 551, total_loss: 4.336352348327637
training step: 552, total_loss: 6.185314178466797
training step: 553, total_loss: 5.817748069763184
training step: 554, total_loss: 5.3794074058532715
training step: 555, total_loss: 4.677525997161865
training step: 556, total_loss: 4.728621482849121
training step: 557, total_loss: 4.979269504547119
training step: 558, total_loss: 5.55224084854126
training step: 559, total_loss: 4.640020370483398
training step: 560, total_loss: 5.492725849151611
training step: 561, total_loss: 4.202059745788574
training step: 562, total_loss: 4.685853004455566
training step: 563, total_loss: 5.46054744720459
training step: 564, total_loss: 5.352758884429932
training step: 565, total_loss: 4.918800354003906
training step: 566, total_loss: 5.8283514976501465
training step: 567, total_loss: 5.103916168212891
training step: 568, total_loss: 5.212530136108398
training step: 569, total_loss: 6.579907417297363
training step: 570, total_loss: 4.974499702453613
training step: 571, total_loss: 4.860133171081543
training step: 572, total_loss: 5.093021392822266
training step: 573, total_loss: 5.3849687576293945
training step: 574, total_loss: 5.636712074279785
training step: 575, total_loss: 5.8273539543151855
training step: 576, total_loss: 4.937021255493164
training step: 577, total_loss: 5.609882354736328
training step: 578, total_loss: 5.234048843383789
training step: 579, total_loss: 6.495551586151123
training step: 580, total_loss: 5.325806617736816
training step: 581, total_loss: 4.553836822509766
training step: 582, total_loss: 5.681562423706055
training step: 583, total_loss: 5.731329441070557
training step: 584, total_loss: 4.921648979187012
training step: 585, total_loss: 4.839047431945801
training step: 586, total_loss: 5.359775543212891
training step: 587, total_loss: 5.374845504760742
training step: 588, total_loss: 5.4667253494262695
training step: 589, total_loss: 5.943782806396484
training step: 590, total_loss: 4.995108127593994
training step: 591, total_loss: 4.811073303222656
training step: 592, total_loss: 5.7644476890563965
training step: 593, total_loss: 4.637707710266113
training step: 594, total_loss: 5.2036590576171875
training step: 595, total_loss: 5.497770309448242
training step: 596, total_loss: 6.208144664764404
training step: 597, total_loss: 5.028460502624512
training step: 598, total_loss: 4.822771072387695
training step: 599, total_loss: 4.684380054473877
training step: 600, total_loss: 5.795337677001953
training step: 601, total_loss: 5.018404006958008
training step: 602, total_loss: 5.6111249923706055
training step: 603, total_loss: 5.416654586791992
training step: 604, total_loss: 6.263546943664551
training step: 605, total_loss: 5.254693031311035
training step: 606, total_loss: 6.236248970031738
training step: 607, total_loss: 4.914323806762695
training step: 608, total_loss: 5.305804252624512
training step: 609, total_loss: 5.615145683288574
training step: 610, total_loss: 4.9310102462768555
training step: 611, total_loss: 5.858628273010254
training step: 612, total_loss: 4.463848114013672
training step: 613, total_loss: 5.873584747314453
training step: 614, total_loss: 5.623540878295898
training step: 615, total_loss: 5.076816558837891
training step: 616, total_loss: 5.335038185119629
training step: 617, total_loss: 5.283575057983398
training step: 618, total_loss: 6.164013862609863
training step: 619, total_loss: 4.517570972442627
training step: 620, total_loss: 5.557703495025635
training step: 621, total_loss: 5.03176212310791
training step: 622, total_loss: 5.153881549835205
training step: 623, total_loss: 5.761703968048096
training step: 624, total_loss: 5.045296669006348
training step: 625, total_loss: 5.0835137367248535
training step: 626, total_loss: 3.731222629547119
training step: 627, total_loss: 4.765212059020996
training step: 628, total_loss: 5.027801513671875
training step: 629, total_loss: 5.251039505004883
training step: 630, total_loss: 3.9095354080200195
training step: 631, total_loss: 6.372307300567627
training step: 632, total_loss: 4.644442558288574
training step: 633, total_loss: 4.355051517486572
training step: 634, total_loss: 5.468015670776367
training step: 635, total_loss: 5.406831741333008
training step: 636, total_loss: 5.458693027496338
training step: 637, total_loss: 5.266757011413574
training step: 638, total_loss: 5.0243120193481445
training step: 639, total_loss: 5.927580833435059
training step: 640, total_loss: 4.481412410736084
training step: 641, total_loss: 5.172264099121094
training step: 642, total_loss: 5.1358747482299805
training step: 643, total_loss: 6.626850128173828
training step: 644, total_loss: 4.954066276550293
training step: 645, total_loss: 5.292923927307129
training step: 646, total_loss: 5.742434501647949
training step: 647, total_loss: 5.3428497314453125
training step: 648, total_loss: 5.303431510925293
training step: 649, total_loss: 5.129860877990723
training step: 650, total_loss: 6.5358171463012695
training step: 651, total_loss: 5.811508655548096
training step: 652, total_loss: 6.034371852874756
training step: 653, total_loss: 5.694566249847412
training step: 654, total_loss: 5.424218654632568
training step: 655, total_loss: 6.353802680969238
training step: 656, total_loss: 4.544491291046143
training step: 657, total_loss: 4.391271591186523
training step: 658, total_loss: 4.665619850158691
training step: 659, total_loss: 5.502371788024902
training step: 660, total_loss: 5.318259239196777
training step: 661, total_loss: 5.966236591339111
training step: 662, total_loss: 6.0110626220703125
training step: 663, total_loss: 6.09672737121582
training step: 664, total_loss: 5.799576759338379
training step: 665, total_loss: 5.472505569458008
training step: 666, total_loss: 5.55308723449707
training step: 667, total_loss: 5.438113212585449
training step: 668, total_loss: 5.576956748962402
training step: 669, total_loss: 5.816703796386719
training step: 670, total_loss: 5.71926212310791
training step: 671, total_loss: 5.3436279296875
training step: 672, total_loss: 5.224458694458008
training step: 673, total_loss: 5.604737281799316
training step: 674, total_loss: 5.431988716125488
training step: 675, total_loss: 4.963574409484863
training step: 676, total_loss: 4.565533638000488
training step: 677, total_loss: 4.644259452819824
training step: 678, total_loss: 5.341215133666992
training step: 679, total_loss: 5.127877235412598
training step: 680, total_loss: 6.247952461242676
training step: 681, total_loss: 5.138421058654785
training step: 682, total_loss: 4.656167030334473
training step: 683, total_loss: 5.4142165184021
training step: 684, total_loss: 5.250290870666504
training step: 685, total_loss: 5.538741111755371
training step: 686, total_loss: 4.860566139221191
training step: 687, total_loss: 4.691606521606445
training step: 688, total_loss: 4.933036804199219
training step: 689, total_loss: 4.129112720489502
training step: 690, total_loss: 5.612547874450684
training step: 691, total_loss: 6.340807914733887
training step: 692, total_loss: 4.833968162536621
training step: 693, total_loss: 5.678565979003906
training step: 694, total_loss: 6.251417636871338
training step: 695, total_loss: 5.570748329162598
training step: 696, total_loss: 4.8376288414001465
training step: 697, total_loss: 4.143488883972168
training step: 698, total_loss: 5.1349077224731445
training step: 699, total_loss: 5.651094913482666
training step: 700, total_loss: 5.888757228851318
training step: 701, total_loss: 5.110811233520508
training step: 702, total_loss: 5.124161720275879
training step: 703, total_loss: 5.292072296142578
training step: 704, total_loss: 5.5202789306640625
training step: 705, total_loss: 5.193777561187744
training step: 706, total_loss: 5.340517520904541
training step: 707, total_loss: 5.440134525299072
training step: 708, total_loss: 5.035428047180176
training step: 709, total_loss: 4.631728172302246
training step: 710, total_loss: 4.468147277832031
training step: 711, total_loss: 5.253039836883545
training step: 712, total_loss: 5.426934719085693
training step: 713, total_loss: 4.896344184875488
training step: 714, total_loss: 5.503268241882324
training step: 715, total_loss: 4.685687065124512
training step: 716, total_loss: 5.550868988037109
training step: 717, total_loss: 5.320938587188721
training step: 718, total_loss: 4.822305679321289
training step: 719, total_loss: 6.3376336097717285
training step: 720, total_loss: 6.053247928619385
training step: 721, total_loss: 5.309344291687012
training step: 722, total_loss: 5.335081577301025
training step: 723, total_loss: 4.660882949829102
training step: 724, total_loss: 4.972700119018555
training step: 725, total_loss: 5.665373802185059
training step: 726, total_loss: 5.285212516784668
training step: 727, total_loss: 6.1025848388671875
training step: 728, total_loss: 4.699797630310059
training step: 729, total_loss: 5.1378045082092285
training step: 730, total_loss: 5.942896842956543
training step: 731, total_loss: 4.382776737213135
training step: 732, total_loss: 4.621169567108154
training step: 733, total_loss: 5.097942352294922
training step: 734, total_loss: 5.010800361633301
training step: 735, total_loss: 4.844563007354736
training step: 736, total_loss: 4.436624050140381
training step: 737, total_loss: 5.366366863250732
training step: 738, total_loss: 5.659608840942383
training step: 739, total_loss: 5.426856994628906
training step: 740, total_loss: 5.231356143951416
training step: 741, total_loss: 5.344552040100098
training step: 742, total_loss: 5.108353614807129
training step: 743, total_loss: 7.312961101531982
training step: 744, total_loss: 5.585565567016602
training step: 745, total_loss: 5.043363571166992
training step: 746, total_loss: 4.912051200866699
training step: 747, total_loss: 5.483094215393066
training step: 748, total_loss: 5.2678937911987305
training step: 749, total_loss: 5.042708396911621
training step: 750, total_loss: 5.336578845977783
training step: 751, total_loss: 5.262613773345947
training step: 752, total_loss: 5.745084762573242
training step: 753, total_loss: 5.559457778930664
training step: 754, total_loss: 5.057070255279541
training step: 755, total_loss: 5.124564170837402
training step: 756, total_loss: 5.289923667907715
training step: 757, total_loss: 6.166138648986816
training step: 758, total_loss: 5.729028701782227
training step: 759, total_loss: 5.255680084228516
training step: 760, total_loss: 5.479674339294434
training step: 761, total_loss: 4.824253082275391
training step: 762, total_loss: 5.954225540161133
training step: 763, total_loss: 5.3836870193481445
training step: 764, total_loss: 5.286362648010254
training step: 765, total_loss: 5.509060859680176
training step: 766, total_loss: 4.968149662017822
training step: 767, total_loss: 5.465694427490234
training step: 768, total_loss: 4.746338367462158
training step: 769, total_loss: 5.715575218200684
training step: 770, total_loss: 5.649761199951172
training step: 771, total_loss: 5.5076189041137695
training step: 772, total_loss: 5.524422645568848
training step: 773, total_loss: 2.4730629920959473
training step: 774, total_loss: 5.003978729248047
training step: 775, total_loss: 5.847790718078613
training step: 776, total_loss: 5.251865386962891
training step: 777, total_loss: 5.209822654724121
training step: 778, total_loss: 4.4720869064331055
training step: 779, total_loss: 5.271744728088379
training step: 780, total_loss: 4.756391525268555
training step: 781, total_loss: 5.32692289352417
training step: 782, total_loss: 5.4415178298950195
training step: 783, total_loss: 5.380899429321289
training step: 784, total_loss: 4.479090690612793
training step: 785, total_loss: 5.009705543518066
training step: 786, total_loss: 4.6248626708984375
training step: 787, total_loss: 6.7680864334106445
training step: 788, total_loss: 5.623879432678223
training step: 789, total_loss: 5.2807087898254395
training step: 790, total_loss: 5.620598316192627
training step: 791, total_loss: 5.162490367889404
training step: 792, total_loss: 4.213024616241455
training step: 793, total_loss: 6.560821056365967
training step: 794, total_loss: 5.82839822769165
training step: 795, total_loss: 5.962796211242676
training step: 796, total_loss: 5.62974739074707
training step: 797, total_loss: 5.299042701721191
training step: 798, total_loss: 6.050443649291992
training step: 799, total_loss: 4.52854585647583
training step: 800, total_loss: 6.595881938934326
training step: 801, total_loss: 5.3452887535095215
training step: 802, total_loss: 5.429452896118164
training step: 803, total_loss: 5.951132774353027
training step: 804, total_loss: 4.642238140106201
training step: 805, total_loss: 6.150648593902588
training step: 806, total_loss: 5.483950614929199
training step: 807, total_loss: 4.839646816253662
training step: 808, total_loss: 5.51387882232666
training step: 809, total_loss: 5.399664878845215
training step: 810, total_loss: 5.968418121337891
training step: 811, total_loss: 4.772243499755859
training step: 812, total_loss: 4.701179504394531
training step: 813, total_loss: 4.478978633880615
training step: 814, total_loss: 5.465169906616211
training step: 815, total_loss: 5.375982284545898
training step: 816, total_loss: 5.645812511444092
training step: 817, total_loss: 5.248628616333008
training step: 818, total_loss: 5.879117012023926
training step: 819, total_loss: 5.633502960205078
training step: 820, total_loss: 6.765329360961914
training step: 821, total_loss: 4.995914459228516
training step: 822, total_loss: 5.326601028442383
training step: 823, total_loss: 5.4825849533081055
training step: 824, total_loss: 5.557085990905762
training step: 825, total_loss: 6.311699390411377
training step: 826, total_loss: 5.743581771850586
training step: 827, total_loss: 4.775589942932129
training step: 828, total_loss: 5.566319465637207
training step: 829, total_loss: 5.540768623352051
training step: 830, total_loss: 5.048611640930176
training step: 831, total_loss: 4.7432966232299805
training step: 832, total_loss: 4.676154136657715
training step: 833, total_loss: 4.927352428436279
training step: 834, total_loss: 5.207942008972168
training step: 835, total_loss: 4.9405670166015625
training step: 836, total_loss: 5.471112251281738
training step: 837, total_loss: 4.432651519775391
training step: 838, total_loss: 5.377487659454346
training step: 839, total_loss: 4.511774063110352
training step: 840, total_loss: 4.9086833000183105
training step: 841, total_loss: 4.445954322814941
training step: 842, total_loss: 5.424537658691406
training step: 843, total_loss: 5.839655876159668
training step: 844, total_loss: 4.4582672119140625
training step: 845, total_loss: 5.253434658050537
training step: 846, total_loss: 4.7644524574279785
training step: 847, total_loss: 3.742643356323242
training step: 848, total_loss: 6.562734603881836
training step: 849, total_loss: 5.327962875366211
training step: 850, total_loss: 4.7914299964904785
training step: 851, total_loss: 5.272965431213379
training step: 852, total_loss: 4.681317329406738
training step: 853, total_loss: 5.347202301025391
training step: 854, total_loss: 4.129108428955078
training step: 855, total_loss: 5.468690872192383
training step: 856, total_loss: 5.435965538024902
training step: 857, total_loss: 6.378225803375244
training step: 858, total_loss: 5.109851837158203
training step: 859, total_loss: 4.788356304168701
training step: 860, total_loss: 5.65129280090332
training step: 861, total_loss: 4.268843173980713
training step: 862, total_loss: 5.044680118560791
training step: 863, total_loss: 5.053919792175293
training step: 864, total_loss: 6.656949996948242
training step: 865, total_loss: 6.487525939941406
training step: 866, total_loss: 6.132477283477783
training step: 867, total_loss: 4.728950500488281
training step: 868, total_loss: 3.32647967338562
training step: 869, total_loss: 4.651450157165527
training step: 870, total_loss: 5.7341814041137695
training step: 871, total_loss: 5.545940399169922
training step: 872, total_loss: 6.272248268127441
training step: 873, total_loss: 4.287293434143066
training step: 874, total_loss: 5.928372859954834
training step: 875, total_loss: 4.927367210388184
training step: 876, total_loss: 5.632499694824219
training step: 877, total_loss: 5.420038223266602
training step: 878, total_loss: 5.1291093826293945
training step: 879, total_loss: 5.445023059844971
training step: 880, total_loss: 5.780709266662598
training step: 881, total_loss: 5.542830467224121
training step: 882, total_loss: 4.775745868682861
training step: 883, total_loss: 5.395571231842041
training step: 884, total_loss: 5.603090286254883
training step: 885, total_loss: 5.324416160583496
training step: 886, total_loss: 5.207096099853516
training step: 887, total_loss: 5.3899946212768555
training step: 888, total_loss: 5.27797794342041
training step: 889, total_loss: 4.4299774169921875
training step: 890, total_loss: 4.152270793914795
training step: 891, total_loss: 4.587790012359619
training step: 892, total_loss: 4.584128379821777
training step: 893, total_loss: 5.299884796142578
training step: 894, total_loss: 5.575032711029053
training step: 895, total_loss: 5.095376968383789
training step: 896, total_loss: 5.91110372543335
training step: 897, total_loss: 6.046175479888916
training step: 898, total_loss: 5.043859958648682
training step: 899, total_loss: 5.441617012023926
training step: 900, total_loss: 4.798859596252441
training step: 901, total_loss: 6.453026294708252
training step: 902, total_loss: 6.463990211486816
training step: 903, total_loss: 6.704418182373047
training step: 904, total_loss: 5.201009750366211
training step: 905, total_loss: 4.959360122680664
training step: 906, total_loss: 4.41745138168335
training step: 907, total_loss: 5.4868364334106445
training step: 908, total_loss: 4.5362067222595215
training step: 909, total_loss: 4.803977966308594
training step: 910, total_loss: 4.540594577789307
training step: 911, total_loss: 5.344126224517822
training step: 912, total_loss: 4.901184558868408
training step: 913, total_loss: 6.426891326904297
training step: 914, total_loss: 5.041911602020264
training step: 915, total_loss: 5.078032970428467
training step: 916, total_loss: 5.013257026672363
training step: 917, total_loss: 4.399788856506348
training step: 918, total_loss: 5.107222080230713
training step: 919, total_loss: 5.568933486938477
training step: 920, total_loss: 5.721576690673828
training step: 921, total_loss: 4.592173099517822
training step: 922, total_loss: 2.326920509338379
training step: 923, total_loss: 3.9663960933685303
training step: 924, total_loss: 2.697112560272217
training step: 925, total_loss: 5.223378658294678
training step: 926, total_loss: 4.498091220855713
training step: 927, total_loss: 6.313555717468262
training step: 928, total_loss: 5.495615005493164
training step: 929, total_loss: 5.9793219566345215
training step: 930, total_loss: 4.887422561645508
training step: 931, total_loss: 5.314770698547363
training step: 932, total_loss: 4.019852161407471
training step: 933, total_loss: 4.929865837097168
training step: 934, total_loss: 4.220014572143555
training step: 935, total_loss: 5.7088212966918945
training step: 936, total_loss: 6.145649433135986
training step: 937, total_loss: 5.605398654937744
training step: 938, total_loss: 6.168828010559082
training step: 939, total_loss: 5.0245561599731445
training step: 940, total_loss: 5.329601287841797
training step: 941, total_loss: 4.818267345428467
training step: 942, total_loss: 4.8118577003479
training step: 943, total_loss: 6.15065860748291
training step: 944, total_loss: 4.6729631423950195
training step: 945, total_loss: 5.980770111083984
training step: 946, total_loss: 5.079632759094238
training step: 947, total_loss: 5.189481735229492
training step: 948, total_loss: 6.457821369171143
training step: 949, total_loss: 4.882448673248291
training step: 950, total_loss: 4.359397888183594
training step: 951, total_loss: 4.765585899353027
training step: 952, total_loss: 4.364340782165527
training step: 953, total_loss: 4.303434371948242
training step: 954, total_loss: 6.5118255615234375
training step: 955, total_loss: 2.496169090270996
training step: 956, total_loss: 6.16098165512085
training step: 957, total_loss: 3.9913980960845947
training step: 958, total_loss: 5.041520595550537
training step: 959, total_loss: 3.383573532104492
training step: 960, total_loss: 5.4760637283325195
training step: 961, total_loss: 5.459148406982422
training step: 962, total_loss: 5.1227521896362305
training step: 963, total_loss: 5.92543888092041
training step: 964, total_loss: 2.2452118396759033
training step: 965, total_loss: 5.610586643218994
training step: 966, total_loss: 5.861934185028076
training step: 967, total_loss: 3.9258995056152344
training step: 968, total_loss: 5.826460361480713
training step: 969, total_loss: 5.4121198654174805
training step: 970, total_loss: 3.3820223808288574
training step: 971, total_loss: 4.823729515075684
training step: 972, total_loss: 5.950771808624268
training step: 973, total_loss: 3.6126670837402344
training step: 974, total_loss: 5.365586757659912
training step: 975, total_loss: 4.99892520904541
training step: 976, total_loss: 4.034982681274414
training step: 977, total_loss: 4.7588605880737305
training step: 978, total_loss: 5.332596778869629
training step: 979, total_loss: 5.286797046661377
training step: 980, total_loss: 5.694482326507568
training step: 981, total_loss: 5.950145721435547
training step: 982, total_loss: 6.119734287261963
training step: 983, total_loss: 5.656682014465332
training step: 984, total_loss: 5.639054775238037
training step: 985, total_loss: 5.324866771697998
training step: 986, total_loss: 4.6734395027160645
training step: 987, total_loss: 4.8031792640686035
training step: 988, total_loss: 5.512177467346191
training step: 989, total_loss: 4.083576202392578
training step: 990, total_loss: 5.114078521728516
training step: 991, total_loss: 5.204253196716309
training step: 992, total_loss: 5.142980575561523
training step: 993, total_loss: 4.356995582580566
training step: 994, total_loss: 5.881256103515625
training step: 995, total_loss: 5.037907600402832
training step: 996, total_loss: 5.1797261238098145
training step: 997, total_loss: 3.0218067169189453
training step: 998, total_loss: 4.600929260253906
training step: 999, total_loss: 5.643072605133057
training step: 1000, total_loss: 4.920085906982422
training step: 1001, total_loss: 4.77305793762207
training step: 1002, total_loss: 5.076023101806641
training step: 1003, total_loss: 5.950383186340332
training step: 1004, total_loss: 6.169333457946777
training step: 1005, total_loss: 4.803350925445557
training step: 1006, total_loss: 5.38096809387207
training step: 1007, total_loss: 5.687140464782715
training step: 1008, total_loss: 4.776345252990723
training step: 1009, total_loss: 3.5783729553222656
training step: 1010, total_loss: 5.089831829071045
training step: 1011, total_loss: 4.312074661254883
training step: 1012, total_loss: 4.328841209411621
training step: 1013, total_loss: 6.203944683074951
training step: 1014, total_loss: 4.359543323516846
training step: 1015, total_loss: 5.102372169494629
training step: 1016, total_loss: 4.963831424713135
training step: 1017, total_loss: 4.4914469718933105
training step: 1018, total_loss: 6.076026439666748
training step: 1019, total_loss: 5.096487522125244
training step: 1020, total_loss: 4.896918296813965
training step: 1021, total_loss: 5.417532444000244
training step: 1022, total_loss: 5.272366046905518
training step: 1023, total_loss: 5.952966690063477
training step: 1024, total_loss: 3.992976188659668
training step: 1025, total_loss: 4.339777946472168
training step: 1026, total_loss: 5.108159065246582
training step: 1027, total_loss: 5.568975448608398
training step: 1028, total_loss: 4.143383026123047
training step: 1029, total_loss: 5.803886413574219
training step: 1030, total_loss: 6.038636684417725
training step: 1031, total_loss: 5.188544273376465
training step: 1032, total_loss: 4.539050102233887
training step: 1033, total_loss: 7.157479286193848
training step: 1034, total_loss: 4.634858131408691
training step: 1035, total_loss: 5.724979400634766
training step: 1036, total_loss: 6.462654113769531
training step: 1037, total_loss: 5.581315040588379
training step: 1038, total_loss: 3.3556671142578125
training step: 1039, total_loss: 4.973701477050781
training step: 1040, total_loss: 6.1948699951171875
training step: 1041, total_loss: 5.937661170959473
training step: 1042, total_loss: 5.022456169128418
training step: 1043, total_loss: 5.361758232116699
training step: 1044, total_loss: 5.373348236083984
training step: 1045, total_loss: 3.932527542114258
training step: 1046, total_loss: 5.594537734985352
training step: 1047, total_loss: 5.381321907043457
training step: 1048, total_loss: 5.329258918762207
training step: 1049, total_loss: 5.871305465698242
training step: 1050, total_loss: 4.640805244445801
training step: 1051, total_loss: 4.8125834465026855
training step: 1052, total_loss: 5.784607887268066
training step: 1053, total_loss: 5.057075023651123
training step: 1054, total_loss: 5.36448860168457
training step: 1055, total_loss: 5.765484809875488
training step: 1056, total_loss: 5.468942642211914
training step: 1057, total_loss: 5.006889343261719
training step: 1058, total_loss: 6.240486145019531
training step: 1059, total_loss: 6.039834022521973
training step: 1060, total_loss: 5.4268388748168945
training step: 1061, total_loss: 5.898751258850098
training step: 1062, total_loss: 4.585092067718506
training step: 1063, total_loss: 5.020207405090332
training step: 1064, total_loss: 3.225428581237793
training step: 1065, total_loss: 5.242848873138428
training step: 1066, total_loss: 4.264756202697754
training step: 1067, total_loss: 5.357966423034668
training step: 1068, total_loss: 5.303127288818359
training step: 1069, total_loss: 5.121864318847656
training step: 1070, total_loss: 5.203832626342773
training step: 1071, total_loss: 5.008861064910889
training step: 1072, total_loss: 5.083972930908203
training step: 1073, total_loss: 5.274291038513184
training step: 1074, total_loss: 4.782867431640625
training step: 1075, total_loss: 5.361109256744385
training step: 1076, total_loss: 5.370099067687988
training step: 1077, total_loss: 4.633784770965576
training step: 1078, total_loss: 5.61976432800293
training step: 1079, total_loss: 4.985017776489258
training step: 1080, total_loss: 3.3266143798828125
training step: 1081, total_loss: 5.923177719116211
training step: 1082, total_loss: 4.889800071716309
training step: 1083, total_loss: 5.398301124572754
training step: 1084, total_loss: 5.717960357666016
training step: 1085, total_loss: 4.746045112609863
training step: 1086, total_loss: 5.136617660522461
training step: 1087, total_loss: 6.1016621589660645
training step: 1088, total_loss: 6.065253734588623
training step: 1089, total_loss: 4.336045742034912
training step: 1090, total_loss: 5.420101165771484
training step: 1091, total_loss: 4.8299407958984375
training step: 1092, total_loss: 3.6519570350646973
training step: 1093, total_loss: 5.2968244552612305
training step: 1094, total_loss: 4.542169094085693
training step: 1095, total_loss: 5.282522201538086
training step: 1096, total_loss: 5.539633750915527
training step: 1097, total_loss: 5.199747085571289
training step: 1098, total_loss: 5.698382377624512
training step: 1099, total_loss: 5.02424955368042
training step: 1100, total_loss: 4.466006755828857
training step: 1101, total_loss: 4.54619836807251
training step: 1102, total_loss: 4.424776077270508
training step: 1103, total_loss: 4.953566074371338
training step: 1104, total_loss: 4.077544212341309
training step: 1105, total_loss: 5.705046653747559
training step: 1106, total_loss: 4.5721755027771
training step: 1107, total_loss: 4.885616302490234
training step: 1108, total_loss: 3.9411096572875977
training step: 1109, total_loss: 5.701964378356934
training step: 1110, total_loss: 5.538923263549805
training step: 1111, total_loss: 6.1226911544799805
training step: 1112, total_loss: 4.736445426940918
training step: 1113, total_loss: 6.516037464141846
training step: 1114, total_loss: 6.25892972946167
training step: 1115, total_loss: 5.0455851554870605
training step: 1116, total_loss: 4.694033622741699
training step: 1117, total_loss: 5.217099666595459
training step: 1118, total_loss: 4.352668762207031
training step: 1119, total_loss: 5.102876663208008
training step: 1120, total_loss: 5.795477390289307
training step: 1121, total_loss: 4.462740898132324
training step: 1122, total_loss: 6.247018337249756
training step: 1123, total_loss: 4.422379493713379
training step: 1124, total_loss: 4.81543493270874
training step: 1125, total_loss: 5.1268815994262695
training step: 1126, total_loss: 6.28665828704834
training step: 1127, total_loss: 5.891170501708984
training step: 1128, total_loss: 5.04296875
training step: 1129, total_loss: 4.276201248168945
training step: 1130, total_loss: 6.380993366241455
training step: 1131, total_loss: 5.662652015686035
training step: 1132, total_loss: 4.887444496154785
training step: 1133, total_loss: 5.1922712326049805
training step: 1134, total_loss: 4.539950370788574
training step: 1135, total_loss: 5.137216567993164
training step: 1136, total_loss: 5.5884222984313965
training step: 1137, total_loss: 5.214173316955566
training step: 1138, total_loss: 2.9268083572387695
training step: 1139, total_loss: 5.189078330993652
training step: 1140, total_loss: 5.3601274490356445
training step: 1141, total_loss: 5.030154228210449
training step: 1142, total_loss: 4.299945831298828
training step: 1143, total_loss: 5.413442134857178
training step: 1144, total_loss: 5.204246520996094
training step: 1145, total_loss: 5.076510429382324
training step: 1146, total_loss: 5.681906700134277
training step: 1147, total_loss: 5.183606147766113
training step: 1148, total_loss: 5.421603679656982
training step: 1149, total_loss: 5.932757377624512
training step: 1150, total_loss: 5.5590667724609375
training step: 1151, total_loss: 5.216568470001221
training step: 1152, total_loss: 5.162763595581055
training step: 1153, total_loss: 4.263670444488525
training step: 1154, total_loss: 5.336938858032227
training step: 1155, total_loss: 4.666496753692627
training step: 1156, total_loss: 4.964382171630859
training step: 1157, total_loss: 6.10402250289917
training step: 1158, total_loss: 5.437148094177246
training step: 1159, total_loss: 5.2476959228515625
training step: 1160, total_loss: 3.3106565475463867
training step: 1161, total_loss: 4.610481262207031
training step: 1162, total_loss: 7.01969051361084
training step: 1163, total_loss: 6.641584396362305
training step: 1164, total_loss: 5.3518853187561035
training step: 1165, total_loss: 5.0690083503723145
training step: 1166, total_loss: 5.288114547729492
training step: 1167, total_loss: 6.458169460296631
training step: 1168, total_loss: 3.8128271102905273
training step: 1169, total_loss: 4.94985818862915
training step: 1170, total_loss: 4.815760612487793
training step: 1171, total_loss: 5.321725845336914
training step: 1172, total_loss: 4.426079273223877
training step: 1173, total_loss: 5.036619186401367
training step: 1174, total_loss: 5.913613319396973
training step: 1175, total_loss: 5.4160966873168945
training step: 1176, total_loss: 5.030280113220215
training step: 1177, total_loss: 3.377607583999634
training step: 1178, total_loss: 5.270982265472412
training step: 1179, total_loss: 5.009607315063477
training step: 1180, total_loss: 6.012914657592773
training step: 1181, total_loss: 3.9953017234802246
training step: 1182, total_loss: 5.444166660308838
training step: 1183, total_loss: 4.749086856842041
training step: 1184, total_loss: 5.313591957092285
training step: 1185, total_loss: 4.340264320373535
training step: 1186, total_loss: 5.042392730712891
training step: 1187, total_loss: 5.860166549682617
training step: 1188, total_loss: 4.621718406677246
training step: 1189, total_loss: 4.2823591232299805
training step: 1190, total_loss: 5.48564338684082
training step: 1191, total_loss: 5.477149963378906
training step: 1192, total_loss: 5.647078037261963
training step: 1193, total_loss: 4.350263595581055
training step: 1194, total_loss: 5.2032246589660645
training step: 1195, total_loss: 5.541681289672852
training step: 1196, total_loss: 5.979206562042236
training step: 1197, total_loss: 5.565595626831055
training step: 1198, total_loss: 4.825406551361084
training step: 1199, total_loss: 4.702661037445068
training step: 1200, total_loss: 4.710057258605957
training step: 1201, total_loss: 4.772266864776611
training step: 1202, total_loss: 5.330458164215088
training step: 1203, total_loss: 5.462833881378174
training step: 1204, total_loss: 5.070898056030273
training step: 1205, total_loss: 5.404515266418457
training step: 1206, total_loss: 5.80127477645874
training step: 1207, total_loss: 4.538762092590332
training step: 1208, total_loss: 3.9690370559692383
training step: 1209, total_loss: 4.499602794647217
training step: 1210, total_loss: 4.53221321105957
training step: 1211, total_loss: 5.721263885498047
training step: 1212, total_loss: 5.123196125030518
training step: 1213, total_loss: 4.724628448486328
training step: 1214, total_loss: 4.196788311004639
training step: 1215, total_loss: 3.793247938156128
training step: 1216, total_loss: 2.473598003387451
training step: 1217, total_loss: 5.601648330688477
training step: 1218, total_loss: 5.176229476928711
training step: 1219, total_loss: 4.687654495239258
training step: 1220, total_loss: 4.241730690002441
training step: 1221, total_loss: 5.08978796005249
training step: 1222, total_loss: 5.490180969238281
training step: 1223, total_loss: 3.7117490768432617
training step: 1224, total_loss: 5.374967575073242
training step: 1225, total_loss: 4.353647232055664
training step: 1226, total_loss: 3.6687710285186768
training step: 1227, total_loss: 5.009986877441406
training step: 1228, total_loss: 6.178553581237793
training step: 1229, total_loss: 5.5130391120910645
training step: 1230, total_loss: 5.681901931762695
training step: 1231, total_loss: 5.441575527191162
training step: 1232, total_loss: 5.332620620727539
training step: 1233, total_loss: 5.714907646179199
training step: 1234, total_loss: 5.191399574279785
training step: 1235, total_loss: 5.531988143920898
training step: 1236, total_loss: 4.850856781005859
training step: 1237, total_loss: 5.5686516761779785
training step: 1238, total_loss: 5.083559513092041
training step: 1239, total_loss: 5.521984100341797
training step: 1240, total_loss: 6.0987043380737305
training step: 1241, total_loss: 5.404986381530762
training step: 1242, total_loss: 5.91847038269043
training step: 1243, total_loss: 4.942931652069092
training step: 1244, total_loss: 5.681305885314941
training step: 1245, total_loss: 5.2773284912109375
training step: 1246, total_loss: 4.798041343688965
training step: 1247, total_loss: 5.036368370056152
training step: 1248, total_loss: 4.7627763748168945
training step: 1249, total_loss: 4.965236663818359
training step: 1250, total_loss: 4.902120590209961
training step: 1251, total_loss: 6.212205410003662
training step: 1252, total_loss: 6.2138872146606445
training step: 1253, total_loss: 5.219728469848633
training step: 1254, total_loss: 5.131283760070801
training step: 1255, total_loss: 5.565238952636719
training step: 1256, total_loss: 5.616205215454102
training step: 1257, total_loss: 6.147915363311768
training step: 1258, total_loss: 4.476662635803223
training step: 1259, total_loss: 5.2670159339904785
training step: 1260, total_loss: 5.7348527908325195
training step: 1261, total_loss: 5.445733547210693
training step: 1262, total_loss: 5.085906028747559
training step: 1263, total_loss: 4.926204204559326
training step: 1264, total_loss: 4.116147041320801
training step: 1265, total_loss: 5.592828750610352
training step: 1266, total_loss: 5.311337471008301
training step: 1267, total_loss: 4.107024669647217
training step: 1268, total_loss: 4.783820152282715
training step: 1269, total_loss: 5.753551006317139
training step: 1270, total_loss: 5.430084705352783
training step: 1271, total_loss: 4.851529121398926
training step: 1272, total_loss: 5.363943576812744
training step: 1273, total_loss: 6.082241058349609
training step: 1274, total_loss: 5.195572853088379
training step: 1275, total_loss: 4.774986743927002
training step: 1276, total_loss: 4.625998020172119
training step: 1277, total_loss: 4.583940505981445
training step: 1278, total_loss: 5.280134201049805
training step: 1279, total_loss: 5.9305243492126465
training step: 1280, total_loss: 4.74965238571167
training step: 1281, total_loss: 5.362894058227539
training step: 1282, total_loss: 4.874569892883301
training step: 1283, total_loss: 5.256925582885742
training step: 1284, total_loss: 4.448729991912842
training step: 1285, total_loss: 5.117862701416016
training step: 1286, total_loss: 4.714159965515137
training step: 1287, total_loss: 4.826724052429199
training step: 1288, total_loss: 3.15617036819458
training step: 1289, total_loss: 6.016408920288086
training step: 1290, total_loss: 5.665066242218018
training step: 1291, total_loss: 5.236663818359375
training step: 1292, total_loss: 3.763387680053711
training step: 1293, total_loss: 4.895836353302002
training step: 1294, total_loss: 5.763638973236084
training step: 1295, total_loss: 5.004580974578857
training step: 1296, total_loss: 5.213351249694824
training step: 1297, total_loss: 5.994775772094727
training step: 1298, total_loss: 5.657544136047363
training step: 1299, total_loss: 5.49888277053833
training step: 1300, total_loss: 4.957543849945068
training step: 1301, total_loss: 4.181939601898193
training step: 1302, total_loss: 6.119020462036133
training step: 1303, total_loss: 3.2126829624176025
training step: 1304, total_loss: 5.098058700561523
training step: 1305, total_loss: 5.353959560394287
training step: 1306, total_loss: 4.647359848022461
training step: 1307, total_loss: 6.524801254272461
training step: 1308, total_loss: 4.453808307647705
training step: 1309, total_loss: 4.955382823944092
training step: 1310, total_loss: 5.118178367614746
training step: 1311, total_loss: 4.667525291442871
training step: 1312, total_loss: 4.817522048950195
training step: 1313, total_loss: 5.341065406799316
training step: 1314, total_loss: 4.490683078765869
training step: 1315, total_loss: 4.7262797355651855
training step: 1316, total_loss: 5.070409774780273
training step: 1317, total_loss: 4.545121669769287
training step: 1318, total_loss: 5.524336338043213
training step: 1319, total_loss: 4.8663330078125
training step: 1320, total_loss: 5.816647052764893
training step: 1321, total_loss: 5.0134358406066895
training step: 1322, total_loss: 5.100246906280518
training step: 1323, total_loss: 4.449510097503662
training step: 1324, total_loss: 5.178670883178711
training step: 1325, total_loss: 5.8662214279174805
training step: 1326, total_loss: 5.361395835876465
training step: 1327, total_loss: 5.00534200668335
training step: 1328, total_loss: 4.836617946624756
training step: 1329, total_loss: 4.916601181030273
training step: 1330, total_loss: 5.95050573348999
training step: 1331, total_loss: 6.48383903503418
training step: 1332, total_loss: 4.394767761230469
training step: 1333, total_loss: 4.441110610961914
training step: 1334, total_loss: 6.484653949737549
training step: 1335, total_loss: 5.189589500427246
training step: 1336, total_loss: 4.402844429016113
training step: 1337, total_loss: 4.649242401123047
training step: 1338, total_loss: 3.2708163261413574
training step: 1339, total_loss: 6.145571708679199
training step: 1340, total_loss: 5.520861625671387
training step: 1341, total_loss: 4.260476112365723
training step: 1342, total_loss: 4.756981372833252
training step: 1343, total_loss: 5.368913650512695
training step: 1344, total_loss: 6.017038822174072
training step: 1345, total_loss: 4.197006702423096
training step: 1346, total_loss: 5.17693567276001
training step: 1347, total_loss: 4.280683517456055
training step: 1348, total_loss: 5.309305667877197
training step: 1349, total_loss: 4.437955856323242
training step: 1350, total_loss: 5.006895065307617
training step: 1351, total_loss: 4.129280090332031
training step: 1352, total_loss: 4.954964637756348
training step: 1353, total_loss: 5.452725887298584
training step: 1354, total_loss: 5.026403427124023
training step: 1355, total_loss: 4.598812103271484
training step: 1356, total_loss: 1.8606387376785278
training step: 1357, total_loss: 5.037644386291504
training step: 1358, total_loss: 5.278354644775391
training step: 1359, total_loss: 6.5742573738098145
training step: 1360, total_loss: 6.341951370239258
training step: 1361, total_loss: 4.987351417541504
training step: 1362, total_loss: 6.036991596221924
training step: 1363, total_loss: 5.828574180603027
training step: 1364, total_loss: 5.804121017456055
training step: 1365, total_loss: 5.399675369262695
training step: 1366, total_loss: 5.475574493408203
training step: 1367, total_loss: 4.951669692993164
training step: 1368, total_loss: 4.330995082855225
training step: 1369, total_loss: 5.256199836730957
training step: 1370, total_loss: 5.087048530578613
training step: 1371, total_loss: 5.258378982543945
training step: 1372, total_loss: 4.729958534240723
training step: 1373, total_loss: 5.133402347564697
training step: 1374, total_loss: 5.426753997802734
training step: 1375, total_loss: 5.079996109008789
training step: 1376, total_loss: 4.500300407409668
training step: 1377, total_loss: 5.184297561645508
training step: 1378, total_loss: 5.240529537200928
training step: 1379, total_loss: 4.334341049194336
training step: 1380, total_loss: 4.699718475341797
training step: 1381, total_loss: 4.637042045593262
training step: 1382, total_loss: 4.0903778076171875
training step: 1383, total_loss: 4.523198127746582
training step: 1384, total_loss: 6.299177169799805
training step: 1385, total_loss: 7.0469536781311035
training step: 1386, total_loss: 4.3408942222595215
training step: 1387, total_loss: 6.262419700622559
training step: 1388, total_loss: 5.564914703369141
training step: 1389, total_loss: 5.6063456535339355
training step: 1390, total_loss: 5.57121467590332
training step: 1391, total_loss: 4.533201217651367
training step: 1392, total_loss: 5.034577369689941
training step: 1393, total_loss: 5.629021644592285
training step: 1394, total_loss: 4.486074447631836
training step: 1395, total_loss: 4.2822160720825195
training step: 1396, total_loss: 5.044172286987305
training step: 1397, total_loss: 5.567388534545898
training step: 1398, total_loss: 4.7763872146606445
training step: 1399, total_loss: 4.834711074829102
training step: 1400, total_loss: 3.92921781539917
training step: 1401, total_loss: 4.949260711669922
training step: 1402, total_loss: 5.006206512451172
training step: 1403, total_loss: 3.5998287200927734
training step: 1404, total_loss: 5.846057891845703
training step: 1405, total_loss: 4.7714972496032715
training step: 1406, total_loss: 5.98728084564209
training step: 1407, total_loss: 4.600712299346924
training step: 1408, total_loss: 6.045613765716553
training step: 1409, total_loss: 5.121017932891846
training step: 1410, total_loss: 4.392183303833008
training step: 1411, total_loss: 4.034390449523926
training step: 1412, total_loss: 6.164807319641113
training step: 1413, total_loss: 2.6996123790740967
training step: 1414, total_loss: 5.734635353088379
training step: 1415, total_loss: 5.10527229309082
training step: 1416, total_loss: 4.089802265167236
training step: 1417, total_loss: 4.916640281677246
training step: 1418, total_loss: 4.982313632965088
training step: 1419, total_loss: 5.009001731872559
training step: 1420, total_loss: 5.086705207824707
training step: 1421, total_loss: 5.161856174468994
training step: 1422, total_loss: 4.90983772277832
training step: 1423, total_loss: 5.355256080627441
training step: 1424, total_loss: 3.5966665744781494
training step: 1425, total_loss: 6.535286903381348
training step: 1426, total_loss: 4.836672782897949
training step: 1427, total_loss: 5.772568225860596
training step: 1428, total_loss: 3.9647302627563477
training step: 1429, total_loss: 4.670307636260986
training step: 1430, total_loss: 4.466574192047119
training step: 1431, total_loss: 4.649753570556641
training step: 1432, total_loss: 5.136063575744629
training step: 1433, total_loss: 4.127457618713379
training step: 1434, total_loss: 5.326828956604004
training step: 1435, total_loss: 4.590913772583008
training step: 1436, total_loss: 5.6784868240356445
training step: 1437, total_loss: 5.099935531616211
training step: 1438, total_loss: 4.6346116065979
training step: 1439, total_loss: 4.971983432769775
training step: 1440, total_loss: 4.692389011383057
training step: 1441, total_loss: 6.019168853759766
training step: 1442, total_loss: 4.50742769241333
training step: 1443, total_loss: 5.388467788696289
training step: 1444, total_loss: 6.199525833129883
training step: 1445, total_loss: 5.7091474533081055
training step: 1446, total_loss: 5.104914665222168
training step: 1447, total_loss: 5.9734039306640625
training step: 1448, total_loss: 5.424871444702148
training step: 1449, total_loss: 6.031149864196777
training step: 1450, total_loss: 4.294610977172852
training step: 1451, total_loss: 4.340304851531982
training step: 1452, total_loss: 5.578066825866699
training step: 1453, total_loss: 4.332513809204102
training step: 1454, total_loss: 5.103058338165283
training step: 1455, total_loss: 5.246250152587891
training step: 1456, total_loss: 4.58556604385376
training step: 1457, total_loss: 4.481642723083496
training step: 1458, total_loss: 4.762972831726074
training step: 1459, total_loss: 5.252618789672852
training step: 1460, total_loss: 5.383781909942627
training step: 1461, total_loss: 4.619448661804199
training step: 1462, total_loss: 6.030366897583008
training step: 1463, total_loss: 5.542754650115967
training step: 1464, total_loss: 4.725787162780762
training step: 1465, total_loss: 3.5950560569763184
training step: 1466, total_loss: 3.763369083404541
training step: 1467, total_loss: 4.867259979248047
training step: 1468, total_loss: 4.318303108215332
training step: 1469, total_loss: 5.127648830413818
training step: 1470, total_loss: 4.595833778381348
training step: 1471, total_loss: 5.530674934387207
training step: 1472, total_loss: 5.089155197143555
training step: 1473, total_loss: 5.225887298583984
training step: 1474, total_loss: 4.760158538818359
training step: 1475, total_loss: 4.482184410095215
training step: 1476, total_loss: 5.4648637771606445
training step: 1477, total_loss: 3.460000514984131
training step: 1478, total_loss: 5.705193996429443
training step: 1479, total_loss: 6.199941635131836
training step: 1480, total_loss: 5.670096397399902
training step: 1481, total_loss: 5.004912376403809
training step: 1482, total_loss: 5.013912200927734
training step: 1483, total_loss: 5.409445762634277
training step: 1484, total_loss: 6.577408790588379
training step: 1485, total_loss: 4.074787139892578
training step: 1486, total_loss: 5.936291694641113
training step: 1487, total_loss: 4.267183303833008
training step: 1488, total_loss: 6.657866477966309
training step: 1489, total_loss: 5.178473472595215
training step: 1490, total_loss: 3.8048453330993652
training step: 1491, total_loss: 5.086602210998535
training step: 1492, total_loss: 5.244489669799805
training step: 1493, total_loss: 3.872650146484375
training step: 1494, total_loss: 5.3357696533203125
training step: 1495, total_loss: 4.815011978149414
training step: 1496, total_loss: 4.71232795715332
training step: 1497, total_loss: 5.696738243103027
training step: 1498, total_loss: 3.5029561519622803
training step: 1499, total_loss: 4.119793891906738
training step: 1500, total_loss: 5.961386203765869
training step: 1501, total_loss: 4.635492324829102
training step: 1502, total_loss: 3.93080997467041
training step: 1503, total_loss: 6.299856185913086
training step: 1504, total_loss: 4.973443984985352
training step: 1505, total_loss: 5.438016891479492
training step: 1506, total_loss: 6.076413631439209
training step: 1507, total_loss: 4.9802141189575195
training step: 1508, total_loss: 4.306774616241455
training step: 1509, total_loss: 4.614366054534912
training step: 1510, total_loss: 5.399618625640869
training step: 1511, total_loss: 3.84759521484375
training step: 1512, total_loss: 5.035727024078369
training step: 1513, total_loss: 4.678670883178711
training step: 1514, total_loss: 4.146458625793457
training step: 1515, total_loss: 5.397891044616699
training step: 1516, total_loss: 5.323252201080322
training step: 1517, total_loss: 4.4143266677856445
training step: 1518, total_loss: 5.250189304351807
training step: 1519, total_loss: 5.200761795043945
training step: 1520, total_loss: 5.900632381439209
training step: 1521, total_loss: 5.116962909698486
training step: 1522, total_loss: 4.472323894500732
training step: 1523, total_loss: 4.268562316894531
training step: 1524, total_loss: 4.041938781738281
training step: 1525, total_loss: 2.848942279815674
training step: 1526, total_loss: 4.145495891571045
training step: 1527, total_loss: 4.554432392120361
training step: 1528, total_loss: 4.8789238929748535
training step: 1529, total_loss: 4.292510032653809
training step: 1530, total_loss: 4.432910442352295
training step: 1531, total_loss: 3.589656352996826
training step: 1532, total_loss: 4.307841777801514
training step: 1533, total_loss: 6.091782093048096
training step: 1534, total_loss: 6.717494964599609
training step: 1535, total_loss: 4.643740653991699
training step: 1536, total_loss: 5.0483598709106445
training step: 1537, total_loss: 4.388544082641602
training step: 1538, total_loss: 4.8899431228637695
training step: 1539, total_loss: 6.062903881072998
training step: 1540, total_loss: 5.714762210845947
training step: 1541, total_loss: 4.108415126800537
training step: 1542, total_loss: 3.2696151733398438
training step: 1543, total_loss: 6.2461676597595215
training step: 1544, total_loss: 4.373597145080566
training step: 1545, total_loss: 6.04896354675293
training step: 1546, total_loss: 5.6541619300842285
training step: 1547, total_loss: 4.905457973480225
training step: 1548, total_loss: 5.587952136993408
training step: 1549, total_loss: 3.9640283584594727
training step: 1550, total_loss: 5.111820697784424
training step: 1551, total_loss: 4.5880279541015625
training step: 1552, total_loss: 4.372720718383789
training step: 1553, total_loss: 4.769464492797852
training step: 1554, total_loss: 2.863211154937744
training step: 1555, total_loss: 6.770439624786377
training step: 1556, total_loss: 3.6770148277282715
training step: 1557, total_loss: 5.172177314758301
training step: 1558, total_loss: 4.482574462890625
training step: 1559, total_loss: 5.103192329406738
training step: 1560, total_loss: 5.034463882446289
training step: 1561, total_loss: 6.058633804321289
training step: 1562, total_loss: 4.558199405670166
training step: 1563, total_loss: 4.304450988769531
training step: 1564, total_loss: 5.654361724853516
training step: 1565, total_loss: 7.204397201538086
training step: 1566, total_loss: 6.309485912322998
training step: 1567, total_loss: 6.091826438903809
training step: 1568, total_loss: 3.884157180786133
training step: 1569, total_loss: 6.045222282409668
training step: 1570, total_loss: 6.288177490234375
training step: 1571, total_loss: 4.757735252380371
training step: 1572, total_loss: 3.3729867935180664
training step: 1573, total_loss: 4.7637152671813965
training step: 1574, total_loss: 4.088605880737305
training step: 1575, total_loss: 4.791817665100098
training step: 1576, total_loss: 5.631485462188721
training step: 1577, total_loss: 4.996777534484863
training step: 1578, total_loss: 6.000181198120117
training step: 1579, total_loss: 4.756198406219482
training step: 1580, total_loss: 4.962449550628662
training step: 1581, total_loss: 5.327353477478027
training step: 1582, total_loss: 4.9013214111328125
training step: 1583, total_loss: 5.461310863494873
training step: 1584, total_loss: 4.910394668579102
training step: 1585, total_loss: 5.5156660079956055
training step: 1586, total_loss: 5.07492208480835
training step: 1587, total_loss: 4.893618583679199
training step: 1588, total_loss: 5.439496994018555
training step: 1589, total_loss: 3.9344468116760254
training step: 1590, total_loss: 3.6621689796447754
training step: 1591, total_loss: 5.7444000244140625
training step: 1592, total_loss: 1.7294751405715942
training step: 1593, total_loss: 5.34458589553833
training step: 1594, total_loss: 6.412548542022705
training step: 1595, total_loss: 2.434393882751465
training step: 1596, total_loss: 5.358493804931641
training step: 1597, total_loss: 4.58802604675293
training step: 1598, total_loss: 4.776914596557617
training step: 1599, total_loss: 5.600205421447754
training step: 1600, total_loss: 4.64367151260376
training step: 1601, total_loss: 5.259336471557617
training step: 1602, total_loss: 4.807462215423584
training step: 1603, total_loss: 4.299472808837891
training step: 1604, total_loss: 5.762557506561279
training step: 1605, total_loss: 6.3717169761657715
training step: 1606, total_loss: 6.064251899719238
training step: 1607, total_loss: 5.115889072418213
training step: 1608, total_loss: 6.097265243530273
training step: 1609, total_loss: 4.27227783203125
training step: 1610, total_loss: 4.058401584625244
training step: 1611, total_loss: 5.303966999053955
training step: 1612, total_loss: 6.504827499389648
training step: 1613, total_loss: 5.737120151519775
training step: 1614, total_loss: 4.971495151519775
training step: 1615, total_loss: 5.258753776550293
training step: 1616, total_loss: 5.269484996795654
training step: 1617, total_loss: 5.338008403778076
training step: 1618, total_loss: 5.7529497146606445
training step: 1619, total_loss: 5.363024711608887
training step: 1620, total_loss: 5.237173080444336
training step: 1621, total_loss: 5.4539995193481445
training step: 1622, total_loss: 5.091379165649414
training step: 1623, total_loss: 5.577482223510742
training step: 1624, total_loss: 4.47442102432251
training step: 1625, total_loss: 6.068120956420898
training step: 1626, total_loss: 4.8521013259887695
training step: 1627, total_loss: 5.01986026763916
training step: 1628, total_loss: 4.278102874755859
training step: 1629, total_loss: 6.169750213623047
training step: 1630, total_loss: 5.218407154083252
training step: 1631, total_loss: 4.995023727416992
training step: 1632, total_loss: 5.068979263305664
training step: 1633, total_loss: 4.08228063583374
training step: 1634, total_loss: 4.813172817230225
training step: 1635, total_loss: 4.737658977508545
training step: 1636, total_loss: 4.847051620483398
training step: 1637, total_loss: 6.188840866088867
training step: 1638, total_loss: 5.069305896759033
training step: 1639, total_loss: 5.168341159820557
training step: 1640, total_loss: 5.846102714538574
training step: 1641, total_loss: 5.108111381530762
training step: 1642, total_loss: 4.464646339416504
training step: 1643, total_loss: 4.721639633178711
training step: 1644, total_loss: 4.690910339355469
training step: 1645, total_loss: 3.6154708862304688
training step: 1646, total_loss: 5.690147399902344
training step: 1647, total_loss: 4.692782402038574
training step: 1648, total_loss: 4.346055030822754
training step: 1649, total_loss: 5.54131555557251
training step: 1650, total_loss: 6.207781791687012
training step: 1651, total_loss: 6.110781669616699
training step: 1652, total_loss: 4.935694694519043
training step: 1653, total_loss: 4.666584014892578
training step: 1654, total_loss: 4.843750953674316
training step: 1655, total_loss: 4.336682319641113
training step: 1656, total_loss: 4.450863838195801
training step: 1657, total_loss: 6.067384719848633
training step: 1658, total_loss: 4.861239910125732
training step: 1659, total_loss: 3.8848626613616943
training step: 1660, total_loss: 4.155796051025391
training step: 1661, total_loss: 4.980594158172607
training step: 1662, total_loss: 5.069917678833008
training step: 1663, total_loss: 3.9726831912994385
training step: 1664, total_loss: 4.707910537719727
training step: 1665, total_loss: 5.860904693603516
training step: 1666, total_loss: 6.012747764587402
training step: 1667, total_loss: 6.4285888671875
training step: 1668, total_loss: 5.704331398010254
training step: 1669, total_loss: 4.400510787963867
training step: 1670, total_loss: 6.016504287719727
training step: 1671, total_loss: 5.455606937408447
training step: 1672, total_loss: 4.291482925415039
training step: 1673, total_loss: 4.537319660186768
training step: 1674, total_loss: 4.5638933181762695
training step: 1675, total_loss: 4.961324691772461
training step: 1676, total_loss: 6.382346153259277
training step: 1677, total_loss: 5.365363597869873
training step: 1678, total_loss: 4.687813758850098
training step: 1679, total_loss: 5.363900184631348
training step: 1680, total_loss: 5.221527099609375
training step: 1681, total_loss: 4.365096092224121
training step: 1682, total_loss: 4.341883182525635
training step: 1683, total_loss: 4.45337438583374
training step: 1684, total_loss: 5.011000633239746
training step: 1685, total_loss: 4.693684101104736
training step: 1686, total_loss: 4.9422526359558105
training step: 1687, total_loss: 4.520962715148926
training step: 1688, total_loss: 5.900401592254639
training step: 1689, total_loss: 5.49409294128418
training step: 1690, total_loss: 4.856423377990723
training step: 1691, total_loss: 4.867201805114746
training step: 1692, total_loss: 4.976051330566406
training step: 1693, total_loss: 6.206783294677734
training step: 1694, total_loss: 3.8831214904785156
training step: 1695, total_loss: 4.623748779296875
training step: 1696, total_loss: 4.6391777992248535
training step: 1697, total_loss: 4.559370040893555
training step: 1698, total_loss: 5.159091949462891
training step: 1699, total_loss: 5.807313919067383
training step: 1700, total_loss: 4.926546573638916
training step: 1701, total_loss: 5.441066741943359
training step: 1702, total_loss: 5.032451152801514
training step: 1703, total_loss: 4.975255966186523
training step: 1704, total_loss: 5.419706344604492
training step: 1705, total_loss: 3.4525647163391113
training step: 1706, total_loss: 5.265057563781738
training step: 1707, total_loss: 5.303107261657715
training step: 1708, total_loss: 4.689867973327637
training step: 1709, total_loss: 4.995434761047363
training step: 1710, total_loss: 5.239514350891113
training step: 1711, total_loss: 5.4056806564331055
training step: 1712, total_loss: 4.676937580108643
training step: 1713, total_loss: 3.45470929145813
training step: 1714, total_loss: 5.599057674407959
training step: 1715, total_loss: 4.976618766784668
training step: 1716, total_loss: 6.0506086349487305
training step: 1717, total_loss: 4.686906814575195
training step: 1718, total_loss: 5.222500801086426
training step: 1719, total_loss: 4.796908855438232
training step: 1720, total_loss: 6.647305011749268
training step: 1721, total_loss: 5.394400596618652
training step: 1722, total_loss: 5.945237159729004
training step: 1723, total_loss: 5.300268173217773
training step: 1724, total_loss: 4.764168739318848
training step: 1725, total_loss: 4.46575403213501
training step: 1726, total_loss: 5.55751371383667
training step: 1727, total_loss: 4.063665390014648
training step: 1728, total_loss: 6.05421257019043
training step: 1729, total_loss: 4.7798848152160645
training step: 1730, total_loss: 4.250011444091797
training step: 1731, total_loss: 4.839936256408691
training step: 1732, total_loss: 4.855996131896973
training step: 1733, total_loss: 4.663407325744629
training step: 1734, total_loss: 5.732132434844971
training step: 1735, total_loss: 4.962258338928223
training step: 1736, total_loss: 6.195497512817383
training step: 1737, total_loss: 1.760186791419983
training step: 1738, total_loss: 5.227856636047363
training step: 1739, total_loss: 5.2795562744140625
training step: 1740, total_loss: 5.765613079071045
training step: 1741, total_loss: 5.843620300292969
training step: 1742, total_loss: 4.724079608917236
training step: 1743, total_loss: 6.091782093048096
training step: 1744, total_loss: 5.598557472229004
training step: 1745, total_loss: 5.496456146240234
training step: 1746, total_loss: 5.443209171295166
training step: 1747, total_loss: 5.573534965515137
training step: 1748, total_loss: 5.08234977722168
training step: 1749, total_loss: 5.804947376251221
training step: 1750, total_loss: 4.671303749084473
training step: 1751, total_loss: 4.712996482849121
training step: 1752, total_loss: 5.006439208984375
training step: 1753, total_loss: 4.549571514129639
training step: 1754, total_loss: 5.798951625823975
training step: 1755, total_loss: 4.814953804016113
training step: 1756, total_loss: 5.559411525726318
training step: 1757, total_loss: 5.094520568847656
training step: 1758, total_loss: 5.065126895904541
training step: 1759, total_loss: 4.683030128479004
training step: 1760, total_loss: 5.698644161224365
training step: 1761, total_loss: 5.252762794494629
training step: 1762, total_loss: 4.855123996734619
training step: 1763, total_loss: 5.249016284942627
training step: 1764, total_loss: 6.223409652709961
training step: 1765, total_loss: 5.068656921386719
training step: 1766, total_loss: 4.818343162536621
training step: 1767, total_loss: 4.828566074371338
training step: 1768, total_loss: 5.113802909851074
training step: 1769, total_loss: 4.339288711547852
training step: 1770, total_loss: 5.2956109046936035
training step: 1771, total_loss: 4.810946941375732
training step: 1772, total_loss: 5.065062999725342
training step: 1773, total_loss: 2.7767605781555176
training step: 1774, total_loss: 4.995573043823242
training step: 1775, total_loss: 4.4122819900512695
training step: 1776, total_loss: 4.779571056365967
training step: 1777, total_loss: 5.49314546585083
training step: 1778, total_loss: 5.41087532043457
training step: 1779, total_loss: 4.427745819091797
training step: 1780, total_loss: 5.147632122039795
training step: 1781, total_loss: 4.546459674835205
training step: 1782, total_loss: 4.603147983551025
training step: 1783, total_loss: 5.299140930175781
training step: 1784, total_loss: 4.625133514404297
training step: 1785, total_loss: 4.7298078536987305
training step: 1786, total_loss: 5.106123447418213
training step: 1787, total_loss: 4.987484931945801
training step: 1788, total_loss: 4.865768909454346
training step: 1789, total_loss: 4.901070594787598
training step: 1790, total_loss: 5.572606563568115
training step: 1791, total_loss: 4.598140716552734
training step: 1792, total_loss: 5.670768737792969
training step: 1793, total_loss: 4.8927717208862305
training step: 1794, total_loss: 4.766074180603027
training step: 1795, total_loss: 4.305464267730713
training step: 1796, total_loss: 5.584015846252441
training step: 1797, total_loss: 5.457315921783447
training step: 1798, total_loss: 4.650025844573975
training step: 1799, total_loss: 4.768303871154785
training step: 1800, total_loss: 4.501128196716309
training step: 1801, total_loss: 4.775700569152832
training step: 1802, total_loss: 5.757340431213379
training step: 1803, total_loss: 4.906968116760254
training step: 1804, total_loss: 4.131546497344971
training step: 1805, total_loss: 4.206144332885742
training step: 1806, total_loss: 3.9855167865753174
training step: 1807, total_loss: 5.376688003540039
training step: 1808, total_loss: 5.202314376831055
training step: 1809, total_loss: 4.5526885986328125
training step: 1810, total_loss: 4.496850490570068
training step: 1811, total_loss: 5.413796424865723
training step: 1812, total_loss: 6.071643829345703
training step: 1813, total_loss: 4.573359489440918
training step: 1814, total_loss: 5.52955436706543
training step: 1815, total_loss: 4.948794841766357
training step: 1816, total_loss: 4.813072204589844
training step: 1817, total_loss: 5.356829643249512
training step: 1818, total_loss: 4.685022830963135
training step: 1819, total_loss: 3.705752372741699
training step: 1820, total_loss: 5.459007263183594
training step: 1821, total_loss: 5.966639518737793
training step: 1822, total_loss: 6.067692756652832
training step: 1823, total_loss: 5.484532833099365
training step: 1824, total_loss: 6.057469367980957
training step: 1825, total_loss: 5.234574794769287
training step: 1826, total_loss: 4.515987873077393
training step: 1827, total_loss: 5.108135223388672
training step: 1828, total_loss: 5.203108787536621
training step: 1829, total_loss: 5.219497203826904
training step: 1830, total_loss: 4.714343070983887
training step: 1831, total_loss: 4.791898250579834
training step: 1832, total_loss: 4.086281776428223
training step: 1833, total_loss: 4.0427045822143555
training step: 1834, total_loss: 6.128267288208008
training step: 1835, total_loss: 4.908053398132324
training step: 1836, total_loss: 4.5049943923950195
training step: 1837, total_loss: 6.375768184661865
training step: 1838, total_loss: 5.03240966796875
training step: 1839, total_loss: 5.541433811187744
training step: 1840, total_loss: 4.544858455657959
training step: 1841, total_loss: 4.288144111633301
training step: 1842, total_loss: 5.108887195587158
training step: 1843, total_loss: 6.491734504699707
training step: 1844, total_loss: 5.267067909240723
training step: 1845, total_loss: 4.402210712432861
training step: 1846, total_loss: 4.266598701477051
training step: 1847, total_loss: 3.736722469329834
training step: 1848, total_loss: 4.648005485534668
training step: 1849, total_loss: 4.709603309631348
training step: 1850, total_loss: 6.444206237792969
training step: 1851, total_loss: 4.791690826416016
training step: 1852, total_loss: 5.416696071624756
training step: 1853, total_loss: 5.656921863555908
training step: 1854, total_loss: 4.885021209716797
training step: 1855, total_loss: 3.74224853515625
training step: 1856, total_loss: 4.6408796310424805
training step: 1857, total_loss: 5.523331642150879
training step: 1858, total_loss: 5.4901442527771
training step: 1859, total_loss: 3.6231203079223633
training step: 1860, total_loss: 6.161773204803467
training step: 1861, total_loss: 5.037275314331055
training step: 1862, total_loss: 5.195720195770264
training step: 1863, total_loss: 5.731442451477051
training step: 1864, total_loss: 4.71795129776001
training step: 1865, total_loss: 4.9805684089660645
training step: 1866, total_loss: 4.191493034362793
training step: 1867, total_loss: 4.7279534339904785
training step: 1868, total_loss: 4.921152591705322
training step: 1869, total_loss: 4.802096366882324
training step: 1870, total_loss: 4.715468883514404
training step: 1871, total_loss: 4.399925231933594
training step: 1872, total_loss: 5.89146614074707
training step: 1873, total_loss: 3.399726629257202
training step: 1874, total_loss: 4.722073554992676
training step: 1875, total_loss: 5.704143524169922
training step: 1876, total_loss: 3.7482547760009766
training step: 1877, total_loss: 4.42833948135376
training step: 1878, total_loss: 4.179419994354248
training step: 1879, total_loss: 5.451152801513672
training step: 1880, total_loss: 4.815680027008057
training step: 1881, total_loss: 4.448386192321777
training step: 1882, total_loss: 5.311720371246338
training step: 1883, total_loss: 5.355461597442627
training step: 1884, total_loss: 5.30422306060791
training step: 1885, total_loss: 5.252596855163574
training step: 1886, total_loss: 4.323063850402832
training step: 1887, total_loss: 4.73321533203125
training step: 1888, total_loss: 3.728666305541992
training step: 1889, total_loss: 5.326620578765869
training step: 1890, total_loss: 5.599377632141113
training step: 1891, total_loss: 4.1553955078125
training step: 1892, total_loss: 4.139508247375488
training step: 1893, total_loss: 3.108280897140503
training step: 1894, total_loss: 6.093987464904785
training step: 1895, total_loss: 4.914610862731934
training step: 1896, total_loss: 5.918408393859863
training step: 1897, total_loss: 2.574272871017456
training step: 1898, total_loss: 4.31949520111084
training step: 1899, total_loss: 6.313537120819092
training step: 1900, total_loss: 6.915505409240723
training step: 1901, total_loss: 4.378249645233154
training step: 1902, total_loss: 5.993141174316406
training step: 1903, total_loss: 4.180911540985107
training step: 1904, total_loss: 4.7614946365356445
training step: 1905, total_loss: 3.8291592597961426
training step: 1906, total_loss: 4.740828037261963
training step: 1907, total_loss: 5.46514892578125
training step: 1908, total_loss: 5.273139953613281
training step: 1909, total_loss: 3.3827242851257324
training step: 1910, total_loss: 5.646820545196533
training step: 1911, total_loss: 5.606507301330566
training step: 1912, total_loss: 6.349414348602295
training step: 1913, total_loss: 5.220026969909668
training step: 1914, total_loss: 5.064963340759277
training step: 1915, total_loss: 6.193907737731934
training step: 1916, total_loss: 5.309898376464844
training step: 1917, total_loss: 5.481766700744629
training step: 1918, total_loss: 4.515653133392334
training step: 1919, total_loss: 5.366761207580566
training step: 1920, total_loss: 6.346255302429199
training step: 1921, total_loss: 4.03677225112915
training step: 1922, total_loss: 5.340640068054199
training step: 1923, total_loss: 4.0085320472717285
training step: 1924, total_loss: 5.253294467926025
training step: 1925, total_loss: 5.323878288269043
training step: 1926, total_loss: 4.162711143493652
training step: 1927, total_loss: 2.583584785461426
training step: 1928, total_loss: 4.408050537109375
training step: 1929, total_loss: 3.7738728523254395
training step: 1930, total_loss: 4.435393810272217
training step: 1931, total_loss: 4.8527021408081055
training step: 1932, total_loss: 2.9000742435455322
training step: 1933, total_loss: 4.5506486892700195
training step: 1934, total_loss: 5.037083625793457
training step: 1935, total_loss: 4.203442096710205
training step: 1936, total_loss: 5.05016565322876
training step: 1937, total_loss: 5.0321574211120605
training step: 1938, total_loss: 6.306750774383545
training step: 1939, total_loss: 3.6225361824035645
training step: 1940, total_loss: 5.320969581604004
training step: 1941, total_loss: 6.182793617248535
training step: 1942, total_loss: 5.823906898498535
training step: 1943, total_loss: 2.123523712158203
training step: 1944, total_loss: 4.343360900878906
training step: 1945, total_loss: 5.739931583404541
training step: 1946, total_loss: 5.002656936645508
training step: 1947, total_loss: 4.776684284210205
training step: 1948, total_loss: 4.226071834564209
training step: 1949, total_loss: 3.8867712020874023
training step: 1950, total_loss: 4.411568641662598
training step: 1951, total_loss: 5.483453273773193
training step: 1952, total_loss: 4.785774230957031
training step: 1953, total_loss: 4.623680114746094
training step: 1954, total_loss: 5.509169578552246
training step: 1955, total_loss: 5.26639986038208
training step: 1956, total_loss: 3.8480751514434814
training step: 1957, total_loss: 4.616735458374023
training step: 1958, total_loss: 6.196296691894531
training step: 1959, total_loss: 6.1116437911987305
training step: 1960, total_loss: 4.451283931732178
training step: 1961, total_loss: 5.454850196838379
training step: 1962, total_loss: 5.386829376220703
training step: 1963, total_loss: 4.824944496154785
training step: 1964, total_loss: 5.3909912109375
training step: 1965, total_loss: 4.575684070587158
training step: 1966, total_loss: 6.324613571166992
training step: 1967, total_loss: 3.342012405395508
training step: 1968, total_loss: 5.857207298278809
training step: 1969, total_loss: 3.8447985649108887
training step: 1970, total_loss: 4.4243879318237305
training step: 1971, total_loss: 5.703156471252441
training step: 1972, total_loss: 4.214875221252441
training step: 1973, total_loss: 5.090259552001953
training step: 1974, total_loss: 5.1053056716918945
training step: 1975, total_loss: 5.519047737121582
training step: 1976, total_loss: 4.525419235229492
training step: 1977, total_loss: 5.913815021514893
training step: 1978, total_loss: 5.3502912521362305
training step: 1979, total_loss: 4.568512439727783
training step: 1980, total_loss: 4.790938377380371
training step: 1981, total_loss: 4.906075477600098
training step: 1982, total_loss: 4.620180606842041
training step: 1983, total_loss: 4.109889030456543
training step: 1984, total_loss: 3.9373831748962402
training step: 1985, total_loss: 4.731316566467285
training step: 1986, total_loss: 6.195684432983398
training step: 1987, total_loss: 5.103457450866699
training step: 1988, total_loss: 4.790058135986328
training step: 1989, total_loss: 4.086965560913086
training step: 1990, total_loss: 4.647392749786377
training step: 1991, total_loss: 5.45317268371582
training step: 1992, total_loss: 6.520181655883789
training step: 1993, total_loss: 4.327052593231201
training step: 1994, total_loss: 5.224300384521484
training step: 1995, total_loss: 5.713342189788818
training step: 1996, total_loss: 5.849381446838379
training step: 1997, total_loss: 4.1884307861328125
training step: 1998, total_loss: 5.9518890380859375
training step: 1999, total_loss: 5.2394208908081055
training step: 2000, total_loss: 4.820690155029297
training step: 2001, total_loss: 2.767314910888672
training step: 2002, total_loss: 4.42487907409668
training step: 2003, total_loss: 5.3462138175964355
training step: 2004, total_loss: 5.824476718902588
training step: 2005, total_loss: 5.666693687438965
training step: 2006, total_loss: 3.5280699729919434
training step: 2007, total_loss: 5.53972053527832
training step: 2008, total_loss: 6.67458438873291
training step: 2009, total_loss: 5.137595176696777
training step: 2010, total_loss: 4.424770832061768
training step: 2011, total_loss: 5.450101852416992
training step: 2012, total_loss: 4.237497806549072
training step: 2013, total_loss: 4.629734516143799
training step: 2014, total_loss: 4.9239349365234375
training step: 2015, total_loss: 5.123827934265137
training step: 2016, total_loss: 4.812938213348389
training step: 2017, total_loss: 4.198196887969971
training step: 2018, total_loss: 4.549708366394043
training step: 2019, total_loss: 5.198403835296631
training step: 2020, total_loss: 2.5374574661254883
training step: 2021, total_loss: 5.708786487579346
training step: 2022, total_loss: 4.69930362701416
training step: 2023, total_loss: 2.722543716430664
training step: 2024, total_loss: 5.634344100952148
training step: 2025, total_loss: 5.780962944030762
training step: 2026, total_loss: 3.0644521713256836
training step: 2027, total_loss: 5.538633346557617
training step: 2028, total_loss: 4.741894721984863
training step: 2029, total_loss: 3.088815689086914
training step: 2030, total_loss: 5.6695122718811035
training step: 2031, total_loss: 4.8549699783325195
training step: 2032, total_loss: 6.661989688873291
training step: 2033, total_loss: 5.166831016540527
training step: 2034, total_loss: 5.153966903686523
training step: 2035, total_loss: 5.31252384185791
training step: 2036, total_loss: 5.6584014892578125
training step: 2037, total_loss: 4.50991153717041
training step: 2038, total_loss: 2.644918441772461
training step: 2039, total_loss: 4.665143013000488
training step: 2040, total_loss: 6.408570289611816
training step: 2041, total_loss: 5.693762302398682
training step: 2042, total_loss: 5.336475849151611
training step: 2043, total_loss: 5.184274196624756
training step: 2044, total_loss: 5.072354316711426
training step: 2045, total_loss: 5.138187408447266
training step: 2046, total_loss: 3.3989224433898926
training step: 2047, total_loss: 5.634164333343506
training step: 2048, total_loss: 5.674661159515381
training step: 2049, total_loss: 3.5735652446746826
training step: 2050, total_loss: 5.634605407714844
training step: 2051, total_loss: 5.127071380615234
training step: 2052, total_loss: 5.373610496520996
training step: 2053, total_loss: 5.186621189117432
training step: 2054, total_loss: 5.045737266540527
training step: 2055, total_loss: 4.420921802520752
training step: 2056, total_loss: 4.879070281982422
training step: 2057, total_loss: 5.3152947425842285
training step: 2058, total_loss: 5.299738883972168
training step: 2059, total_loss: 5.20461368560791
training step: 2060, total_loss: 4.499668121337891
training step: 2061, total_loss: 6.4981207847595215
training step: 2062, total_loss: 6.377273082733154
training step: 2063, total_loss: 4.464120388031006
training step: 2064, total_loss: 5.249279022216797
training step: 2065, total_loss: 5.589786529541016
training step: 2066, total_loss: 4.3967437744140625
training step: 2067, total_loss: 4.494573593139648
training step: 2068, total_loss: 4.7973127365112305
training step: 2069, total_loss: 5.799506187438965
training step: 2070, total_loss: 6.102795600891113
training step: 2071, total_loss: 5.87614107131958
training step: 2072, total_loss: 5.513312816619873
training step: 2073, total_loss: 5.357473850250244
training step: 2074, total_loss: 4.8897705078125
training step: 2075, total_loss: 5.578679084777832
training step: 2076, total_loss: 5.102254867553711
training step: 2077, total_loss: 5.550043106079102
training step: 2078, total_loss: 5.079563140869141
training step: 2079, total_loss: 5.214466094970703
training step: 2080, total_loss: 5.876887321472168
training step: 2081, total_loss: 4.396888732910156
training step: 2082, total_loss: 5.0790205001831055
training step: 2083, total_loss: 5.251023292541504
training step: 2084, total_loss: 6.255096435546875
training step: 2085, total_loss: 5.676079750061035
training step: 2086, total_loss: 5.591432094573975
training step: 2087, total_loss: 4.563803195953369
training step: 2088, total_loss: 4.187509059906006
training step: 2089, total_loss: 4.924236297607422
training step: 2090, total_loss: 4.508599281311035
training step: 2091, total_loss: 5.058088302612305
training step: 2092, total_loss: 5.117143630981445
training step: 2093, total_loss: 4.517555236816406
training step: 2094, total_loss: 5.065905570983887
training step: 2095, total_loss: 4.685018062591553
training step: 2096, total_loss: 6.273325443267822
training step: 2097, total_loss: 5.428493022918701
training step: 2098, total_loss: 4.1388468742370605
training step: 2099, total_loss: 5.756059646606445
training step: 2100, total_loss: 3.932619571685791
training step: 2101, total_loss: 4.792727470397949
training step: 2102, total_loss: 4.592647075653076
training step: 2103, total_loss: 5.132282257080078
training step: 2104, total_loss: 5.097680568695068
training step: 2105, total_loss: 4.174892425537109
training step: 2106, total_loss: 3.1581640243530273
training step: 2107, total_loss: 4.521681785583496
training step: 2108, total_loss: 5.046756267547607
training step: 2109, total_loss: 5.351700782775879
training step: 2110, total_loss: 6.215620994567871
training step: 2111, total_loss: 4.838321685791016
training step: 2112, total_loss: 5.033775329589844
training step: 2113, total_loss: 5.698271751403809
training step: 2114, total_loss: 4.488350868225098
training step: 2115, total_loss: 5.893028736114502
training step: 2116, total_loss: 3.0805859565734863
training step: 2117, total_loss: 5.433140754699707
training step: 2118, total_loss: 4.558844566345215
training step: 2119, total_loss: 5.4803900718688965
training step: 2120, total_loss: 5.810193061828613
training step: 2121, total_loss: 3.8575170040130615
training step: 2122, total_loss: 5.400097846984863
training step: 2123, total_loss: 5.572387218475342
training step: 2124, total_loss: 5.216466426849365
training step: 2125, total_loss: 4.84130859375
training step: 2126, total_loss: 4.181224346160889
training step: 2127, total_loss: 7.1718668937683105
training step: 2128, total_loss: 4.973143577575684
training step: 2129, total_loss: 4.548462867736816
training step: 2130, total_loss: 5.224806785583496
training step: 2131, total_loss: 5.37412166595459
training step: 2132, total_loss: 3.4115004539489746
training step: 2133, total_loss: 5.229332447052002
training step: 2134, total_loss: 5.265257835388184
training step: 2135, total_loss: 4.416821479797363
training step: 2136, total_loss: 4.619966506958008
training step: 2137, total_loss: 5.648828029632568
training step: 2138, total_loss: 4.665805816650391
training step: 2139, total_loss: 3.9587490558624268
training step: 2140, total_loss: 4.649018287658691
training step: 2141, total_loss: 4.31285285949707
training step: 2142, total_loss: 4.822342872619629
training step: 2143, total_loss: 4.379375457763672
training step: 2144, total_loss: 6.278933525085449
training step: 2145, total_loss: 5.155129432678223
training step: 2146, total_loss: 5.193882942199707
training step: 2147, total_loss: 4.785449981689453
training step: 2148, total_loss: 4.518578052520752
training step: 2149, total_loss: 3.6972391605377197
training step: 2150, total_loss: 5.533627510070801
training step: 2151, total_loss: 4.313950061798096
training step: 2152, total_loss: 5.041922569274902
training step: 2153, total_loss: 5.87818717956543
training step: 2154, total_loss: 5.270905494689941
training step: 2155, total_loss: 4.338186264038086
training step: 2156, total_loss: 5.704123020172119
training step: 2157, total_loss: 5.170591831207275
training step: 2158, total_loss: 6.110339164733887
training step: 2159, total_loss: 5.619171619415283
training step: 2160, total_loss: 6.516799449920654
training step: 2161, total_loss: 6.098621368408203
training step: 2162, total_loss: 4.980771541595459
training step: 2163, total_loss: 6.014782905578613
training step: 2164, total_loss: 5.705732345581055
training step: 2165, total_loss: 5.827877044677734
training step: 2166, total_loss: 5.998656272888184
training step: 2167, total_loss: 6.401633262634277
training step: 2168, total_loss: 6.001005172729492
training step: 2169, total_loss: 5.5807061195373535
training step: 2170, total_loss: 5.9816060066223145
training step: 2171, total_loss: 5.53549861907959
training step: 2172, total_loss: 4.65785026550293
training step: 2173, total_loss: 5.794694900512695
training step: 2174, total_loss: 5.897457122802734
training step: 2175, total_loss: 5.804186820983887
training step: 2176, total_loss: 5.913942337036133
training step: 2177, total_loss: 5.9240875244140625
training step: 2178, total_loss: 5.421504497528076
training step: 2179, total_loss: 5.923958778381348
training step: 2180, total_loss: 5.7501325607299805
training step: 2181, total_loss: 5.239341735839844
training step: 2182, total_loss: 5.914821147918701
training step: 2183, total_loss: 4.898813724517822
training step: 2184, total_loss: 5.436065196990967
training step: 2185, total_loss: 5.360666751861572
training step: 2186, total_loss: 5.625361919403076
training step: 2187, total_loss: 5.918919086456299
training step: 2188, total_loss: 4.267737865447998
training step: 2189, total_loss: 5.321263790130615
training step: 2190, total_loss: 5.892421722412109
training step: 2191, total_loss: 4.692148685455322
training step: 2192, total_loss: 4.51319694519043
training step: 2193, total_loss: 5.56727409362793
training step: 2194, total_loss: 4.3384246826171875
training step: 2195, total_loss: 5.956247329711914
training step: 2196, total_loss: 5.594350337982178
training step: 2197, total_loss: 4.3527936935424805
training step: 2198, total_loss: 5.4914093017578125
training step: 2199, total_loss: 5.464028835296631
training step: 2200, total_loss: 5.268136024475098
training step: 2201, total_loss: 5.802114486694336
training step: 2202, total_loss: 5.024031639099121
training step: 2203, total_loss: 5.612691879272461
training step: 2204, total_loss: 4.832548141479492
training step: 2205, total_loss: 4.901798725128174
training step: 2206, total_loss: 5.1595377922058105
training step: 2207, total_loss: 5.265895843505859
training step: 2208, total_loss: 5.15065860748291
training step: 2209, total_loss: 6.468633651733398
training step: 2210, total_loss: 5.2726335525512695
training step: 2211, total_loss: 7.225924491882324
training step: 2212, total_loss: 5.0277252197265625
training step: 2213, total_loss: 5.445603847503662
training step: 2214, total_loss: 2.7080793380737305
training step: 2215, total_loss: 4.694025993347168
training step: 2216, total_loss: 2.8975038528442383
training step: 2217, total_loss: 6.536854267120361
training step: 2218, total_loss: 4.744442462921143
training step: 2219, total_loss: 4.895439147949219
training step: 2220, total_loss: 4.9152021408081055
training step: 2221, total_loss: 4.168950080871582
training step: 2222, total_loss: 5.388097763061523
training step: 2223, total_loss: 4.700843811035156
training step: 2224, total_loss: 5.183408737182617
training step: 2225, total_loss: 3.85444974899292
training step: 2226, total_loss: 6.76279354095459
training step: 2227, total_loss: 5.123573303222656
training step: 2228, total_loss: 4.927224159240723
training step: 2229, total_loss: 4.732763767242432
training step: 2230, total_loss: 4.668295860290527
training step: 2231, total_loss: 4.873426914215088
training step: 2232, total_loss: 6.777311325073242
training step: 2233, total_loss: 6.105396747589111
training step: 2234, total_loss: 4.767901420593262
training step: 2235, total_loss: 5.092924118041992
training step: 2236, total_loss: 5.039211273193359
training step: 2237, total_loss: 5.402580261230469
training step: 2238, total_loss: 4.51642370223999
training step: 2239, total_loss: 5.23956823348999
training step: 2240, total_loss: 3.8319010734558105
training step: 2241, total_loss: 4.786639213562012
training step: 2242, total_loss: 4.923165798187256
training step: 2243, total_loss: 4.593071460723877
training step: 2244, total_loss: 5.865242958068848
training step: 2245, total_loss: 5.115025520324707
training step: 2246, total_loss: 4.315247058868408
training step: 2247, total_loss: 5.398758888244629
training step: 2248, total_loss: 5.094155788421631
training step: 2249, total_loss: 6.346688270568848
training step: 2250, total_loss: 4.007673263549805
training step: 2251, total_loss: 2.594649076461792
training step: 2252, total_loss: 4.603598594665527
training step: 2253, total_loss: 6.803532600402832
training step: 2254, total_loss: 4.979893207550049
training step: 2255, total_loss: 6.036206245422363
training step: 2256, total_loss: 4.278044700622559
training step: 2257, total_loss: 4.8468403816223145
training step: 2258, total_loss: 4.782077789306641
training step: 2259, total_loss: 5.72188663482666
training step: 2260, total_loss: 4.426022529602051
training step: 2261, total_loss: 5.229152679443359
training step: 2262, total_loss: 5.035429000854492
training step: 2263, total_loss: 4.770506381988525
training step: 2264, total_loss: 4.46344518661499
training step: 2265, total_loss: 5.498212814331055
training step: 2266, total_loss: 5.552768230438232
training step: 2267, total_loss: 5.452348232269287
training step: 2268, total_loss: 4.977211952209473
training step: 2269, total_loss: 4.350193977355957
training step: 2270, total_loss: 4.96209716796875
training step: 2271, total_loss: 6.2498555183410645
training step: 2272, total_loss: 6.27181339263916
training step: 2273, total_loss: 3.340865135192871
training step: 2274, total_loss: 5.415485382080078
training step: 2275, total_loss: 4.712721824645996
training step: 2276, total_loss: 5.036931991577148
training step: 2277, total_loss: 2.151251792907715
training step: 2278, total_loss: 5.265974044799805
training step: 2279, total_loss: 4.6104326248168945
training step: 2280, total_loss: 5.474885940551758
training step: 2281, total_loss: 5.344232082366943
training step: 2282, total_loss: 5.554468154907227
training step: 2283, total_loss: 4.580306053161621
training step: 2284, total_loss: 5.02829122543335
training step: 2285, total_loss: 5.653479099273682
training step: 2286, total_loss: 4.720224380493164
training step: 2287, total_loss: 3.3868908882141113
training step: 2288, total_loss: 5.4659271240234375
training step: 2289, total_loss: 6.370944976806641
training step: 2290, total_loss: 3.6458802223205566
training step: 2291, total_loss: 3.8141956329345703
training step: 2292, total_loss: 5.786337375640869
training step: 2293, total_loss: 5.328558921813965
training step: 2294, total_loss: 6.037718296051025
training step: 2295, total_loss: 4.564906597137451
training step: 2296, total_loss: 4.742112159729004
training step: 2297, total_loss: 5.267948627471924
training step: 2298, total_loss: 3.8901283740997314
training step: 2299, total_loss: 5.876149654388428
training step: 2300, total_loss: 6.090086936950684
training step: 2301, total_loss: 4.4346208572387695
training step: 2302, total_loss: 5.013911724090576
training step: 2303, total_loss: 5.133096694946289
training step: 2304, total_loss: 4.83110237121582
training step: 2305, total_loss: 6.455493927001953
training step: 2306, total_loss: 5.227143287658691
training step: 2307, total_loss: 4.740074157714844
training step: 2308, total_loss: 5.226491928100586
training step: 2309, total_loss: 4.64677619934082
training step: 2310, total_loss: 5.247000694274902
training step: 2311, total_loss: 5.128105163574219
training step: 2312, total_loss: 5.437458038330078
training step: 2313, total_loss: 5.417481899261475
training step: 2314, total_loss: 5.081136703491211
training step: 2315, total_loss: 5.520839691162109
training step: 2316, total_loss: 6.15125846862793
training step: 2317, total_loss: 5.346644401550293
training step: 2318, total_loss: 4.73728084564209
training step: 2319, total_loss: 4.515806674957275
training step: 2320, total_loss: 3.912580966949463
training step: 2321, total_loss: 4.974618911743164
training step: 2322, total_loss: 6.3993144035339355
training step: 2323, total_loss: 4.849410057067871
training step: 2324, total_loss: 4.60871696472168
training step: 2325, total_loss: 4.837780952453613
training step: 2326, total_loss: 4.225647449493408
training step: 2327, total_loss: 5.469624996185303
training step: 2328, total_loss: 4.660833358764648
training step: 2329, total_loss: 4.4386396408081055
training step: 2330, total_loss: 5.225861072540283
training step: 2331, total_loss: 5.387966632843018
training step: 2332, total_loss: 6.149087905883789
training step: 2333, total_loss: 5.361766338348389
training step: 2334, total_loss: 5.718663692474365
training step: 2335, total_loss: 5.497783660888672
training step: 2336, total_loss: 5.172342777252197
training step: 2337, total_loss: 5.911770820617676
training step: 2338, total_loss: 5.707218170166016
training step: 2339, total_loss: 5.112648963928223
training step: 2340, total_loss: 5.721817970275879
training step: 2341, total_loss: 4.425285816192627
training step: 2342, total_loss: 2.450746536254883
training step: 2343, total_loss: 5.885867595672607
training step: 2344, total_loss: 5.914743423461914
training step: 2345, total_loss: 5.040587425231934
training step: 2346, total_loss: 4.876453399658203
training step: 2347, total_loss: 4.178389072418213
training step: 2348, total_loss: 5.9156813621521
training step: 2349, total_loss: 5.7664642333984375
training step: 2350, total_loss: 5.506156921386719
training step: 2351, total_loss: 1.6931002140045166
training step: 2352, total_loss: 5.739282131195068
training step: 2353, total_loss: 4.63997220993042
training step: 2354, total_loss: 6.289503574371338
training step: 2355, total_loss: 5.304595947265625
training step: 2356, total_loss: 5.002885341644287
training step: 2357, total_loss: 4.679281234741211
training step: 2358, total_loss: 3.9642434120178223
training step: 2359, total_loss: 4.991717338562012
training step: 2360, total_loss: 4.125237464904785
training step: 2361, total_loss: 4.7989044189453125
training step: 2362, total_loss: 5.922285079956055
training step: 2363, total_loss: 4.728715896606445
training step: 2364, total_loss: 5.26984977722168
training step: 2365, total_loss: 5.821828842163086
training step: 2366, total_loss: 5.4099225997924805
training step: 2367, total_loss: 5.202888488769531
training step: 2368, total_loss: 6.369078636169434
training step: 2369, total_loss: 4.463774681091309
training step: 2370, total_loss: 5.229546070098877
training step: 2371, total_loss: 5.378440856933594
training step: 2372, total_loss: 4.109893798828125
training step: 2373, total_loss: 4.800985813140869
training step: 2374, total_loss: 4.403313636779785
training step: 2375, total_loss: 5.018914222717285
training step: 2376, total_loss: 4.676189422607422
training step: 2377, total_loss: 5.275885581970215
training step: 2378, total_loss: 4.873869895935059
training step: 2379, total_loss: 4.469104766845703
training step: 2380, total_loss: 6.049503803253174
training step: 2381, total_loss: 5.466924667358398
training step: 2382, total_loss: 2.9975380897521973
training step: 2383, total_loss: 5.0027618408203125
training step: 2384, total_loss: 4.908379554748535
training step: 2385, total_loss: 5.323965072631836
training step: 2386, total_loss: 5.74968147277832
training step: 2387, total_loss: 5.886662483215332
training step: 2388, total_loss: 5.080284118652344
training step: 2389, total_loss: 6.06484317779541
training step: 2390, total_loss: 3.9743900299072266
training step: 2391, total_loss: 5.689205169677734
training step: 2392, total_loss: 4.314870357513428
training step: 2393, total_loss: 4.796618461608887
training step: 2394, total_loss: 5.621469497680664
training step: 2395, total_loss: 5.03671407699585
training step: 2396, total_loss: 4.938507080078125
training step: 2397, total_loss: 4.909543991088867
training step: 2398, total_loss: 4.627653121948242
training step: 2399, total_loss: 6.706001281738281
training step: 2400, total_loss: 4.705491542816162
training step: 2401, total_loss: 5.445537567138672
training step: 2402, total_loss: 2.9683635234832764
training step: 2403, total_loss: 3.1850168704986572
training step: 2404, total_loss: 3.1618356704711914
training step: 2405, total_loss: 5.70073127746582
training step: 2406, total_loss: 6.331760406494141
training step: 2407, total_loss: 5.607651710510254
training step: 2408, total_loss: 5.122746467590332
training step: 2409, total_loss: 4.840903282165527
training step: 2410, total_loss: 4.749424934387207
training step: 2411, total_loss: 5.9992170333862305
training step: 2412, total_loss: 4.074589252471924
training step: 2413, total_loss: 5.649218559265137
training step: 2414, total_loss: 5.314728736877441
training step: 2415, total_loss: 5.588090419769287
training step: 2416, total_loss: 4.904369831085205
training step: 2417, total_loss: 5.119354724884033
training step: 2418, total_loss: 4.490290641784668
training step: 2419, total_loss: 3.9867570400238037
training step: 2420, total_loss: 4.0518083572387695
training step: 2421, total_loss: 5.3280534744262695
training step: 2422, total_loss: 4.885215759277344
training step: 2423, total_loss: 4.710019588470459
training step: 2424, total_loss: 5.718294143676758
training step: 2425, total_loss: 2.9590752124786377
training step: 2426, total_loss: 5.112037658691406
training step: 2427, total_loss: 1.2060227394104004
training step: 2428, total_loss: 4.538401126861572
training step: 2429, total_loss: 5.484357833862305
training step: 2430, total_loss: 5.460025787353516
training step: 2431, total_loss: 3.993255615234375
training step: 2432, total_loss: 5.029221534729004
training step: 2433, total_loss: 5.876776695251465
training step: 2434, total_loss: 3.139765501022339
training step: 2435, total_loss: 6.235151767730713
training step: 2436, total_loss: 5.089712142944336
training step: 2437, total_loss: 5.616415023803711
training step: 2438, total_loss: 7.524735450744629
training step: 2439, total_loss: 5.235032081604004
training step: 2440, total_loss: 4.921669006347656
training step: 2441, total_loss: 4.866825580596924
training step: 2442, total_loss: 5.728458404541016
training step: 2443, total_loss: 5.590501308441162
training step: 2444, total_loss: 4.750588893890381
training step: 2445, total_loss: 5.186387062072754
training step: 2446, total_loss: 5.137948036193848
training step: 2447, total_loss: 4.620469093322754
training step: 2448, total_loss: 5.513782024383545
training step: 2449, total_loss: 6.168117046356201
training step: 2450, total_loss: 5.958965301513672
training step: 2451, total_loss: 5.616931915283203
training step: 2452, total_loss: 4.224216938018799
training step: 2453, total_loss: 5.295124053955078
training step: 2454, total_loss: 5.082091808319092
training step: 2455, total_loss: 4.090402603149414
training step: 2456, total_loss: 4.754581451416016
training step: 2457, total_loss: 5.620145797729492
training step: 2458, total_loss: 5.044417381286621
training step: 2459, total_loss: 3.7936267852783203
training step: 2460, total_loss: 5.228588104248047
training step: 2461, total_loss: 4.777031898498535
training step: 2462, total_loss: 4.660317420959473
training step: 2463, total_loss: 5.079022407531738
training step: 2464, total_loss: 5.392394542694092
training step: 2465, total_loss: 4.564424514770508
training step: 2466, total_loss: 6.511314868927002
training step: 2467, total_loss: 5.562285423278809
training step: 2468, total_loss: 4.1381635665893555
training step: 2469, total_loss: 5.661105155944824
training step: 2470, total_loss: 5.610024452209473
training step: 2471, total_loss: 5.015888214111328
training step: 2472, total_loss: 5.337388038635254
training step: 2473, total_loss: 4.206582069396973
training step: 2474, total_loss: 5.205295562744141
training step: 2475, total_loss: 6.013119697570801
training step: 2476, total_loss: 3.9788384437561035
training step: 2477, total_loss: 4.540546417236328
training step: 2478, total_loss: 4.510143756866455
training step: 2479, total_loss: 5.471755027770996
training step: 2480, total_loss: 4.295556545257568
training step: 2481, total_loss: 5.16133451461792
training step: 2482, total_loss: 5.157483100891113
training step: 2483, total_loss: 4.02628755569458
training step: 2484, total_loss: 5.899498462677002
training step: 2485, total_loss: 5.075528144836426
training step: 2486, total_loss: 5.385155200958252
training step: 2487, total_loss: 5.744842052459717
training step: 2488, total_loss: 4.2236433029174805
training step: 2489, total_loss: 5.285401821136475
training step: 2490, total_loss: 4.816601753234863
training step: 2491, total_loss: 4.542060375213623
training step: 2492, total_loss: 3.718366861343384
training step: 2493, total_loss: 5.078948020935059
training step: 2494, total_loss: 5.0619096755981445
training step: 2495, total_loss: 5.361943244934082
training step: 2496, total_loss: 5.254605293273926
training step: 2497, total_loss: 5.0210371017456055
training step: 2498, total_loss: 5.730345726013184
training step: 2499, total_loss: 5.037701606750488
training step: 2500, total_loss: 4.188482761383057
training step: 2501, total_loss: 5.139524459838867
training step: 2502, total_loss: 5.141912460327148
training step: 2503, total_loss: 4.691056728363037
training step: 2504, total_loss: 4.896431922912598
training step: 2505, total_loss: 6.124224662780762
training step: 2506, total_loss: 5.186870574951172
training step: 2507, total_loss: 4.4605393409729
training step: 2508, total_loss: 6.672908782958984
training step: 2509, total_loss: 4.995855331420898
training step: 2510, total_loss: 5.4153289794921875
training step: 2511, total_loss: 4.903536796569824
training step: 2512, total_loss: 4.8633904457092285
training step: 2513, total_loss: 5.273138046264648
training step: 2514, total_loss: 3.766345500946045
training step: 2515, total_loss: 4.427024841308594
training step: 2516, total_loss: 5.26602840423584
training step: 2517, total_loss: 5.846999168395996
training step: 2518, total_loss: 5.199820518493652
training step: 2519, total_loss: 4.853553771972656
training step: 2520, total_loss: 3.411060333251953
training step: 2521, total_loss: 4.905930519104004
training step: 2522, total_loss: 3.253579616546631
training step: 2523, total_loss: 5.226375102996826
training step: 2524, total_loss: 5.025365829467773
training step: 2525, total_loss: 5.445895195007324
training step: 2526, total_loss: 4.365636825561523
training step: 2527, total_loss: 4.131094932556152
training step: 2528, total_loss: 5.2099761962890625
training step: 2529, total_loss: 4.835996150970459
training step: 2530, total_loss: 4.365286350250244
training step: 2531, total_loss: 5.375123023986816
training step: 2532, total_loss: 7.204642295837402
training step: 2533, total_loss: 5.241728782653809
training step: 2534, total_loss: 4.179264068603516
training step: 2535, total_loss: 6.068142890930176
training step: 2536, total_loss: 3.2252633571624756
training step: 2537, total_loss: 4.658017158508301
training step: 2538, total_loss: 3.758647918701172
training step: 2539, total_loss: 5.9614787101745605
training step: 2540, total_loss: 5.554586410522461
training step: 2541, total_loss: 3.612398147583008
training step: 2542, total_loss: 4.583795070648193
training step: 2543, total_loss: 4.950550079345703
training step: 2544, total_loss: 4.724400520324707
training step: 2545, total_loss: 5.647453784942627
training step: 2546, total_loss: 5.337467193603516
training step: 2547, total_loss: 4.527176856994629
training step: 2548, total_loss: 4.559256076812744
training step: 2549, total_loss: 5.406993865966797
training step: 2550, total_loss: 5.601917266845703
training step: 2551, total_loss: 5.4223527908325195
training step: 2552, total_loss: 5.960352897644043
training step: 2553, total_loss: 4.732824325561523
training step: 2554, total_loss: 4.903175354003906
training step: 2555, total_loss: 5.107978820800781
training step: 2556, total_loss: 5.060905456542969
training step: 2557, total_loss: 4.833198547363281
training step: 2558, total_loss: 2.0539331436157227
training step: 2559, total_loss: 5.4974446296691895
training step: 2560, total_loss: 4.375893592834473
training step: 2561, total_loss: 4.960638999938965
training step: 2562, total_loss: 4.128252029418945
training step: 2563, total_loss: 2.656954526901245
training step: 2564, total_loss: 5.3040971755981445
training step: 2565, total_loss: 4.0317277908325195
training step: 2566, total_loss: 5.771799564361572
training step: 2567, total_loss: 5.281286239624023
training step: 2568, total_loss: 5.019320487976074
training step: 2569, total_loss: 5.124519348144531
training step: 2570, total_loss: 5.437211036682129
training step: 2571, total_loss: 5.182501792907715
training step: 2572, total_loss: 5.0044846534729
training step: 2573, total_loss: 4.727646827697754
training step: 2574, total_loss: 6.375555515289307
training step: 2575, total_loss: 6.178205490112305
training step: 2576, total_loss: 3.8890233039855957
training step: 2577, total_loss: 5.277220249176025
training step: 2578, total_loss: 4.560664176940918
training step: 2579, total_loss: 5.768519401550293
training step: 2580, total_loss: 5.259047508239746
training step: 2581, total_loss: 4.319363594055176
training step: 2582, total_loss: 6.698641300201416
training step: 2583, total_loss: 5.798672199249268
training step: 2584, total_loss: 4.957141876220703
training step: 2585, total_loss: 4.681032180786133
training step: 2586, total_loss: 6.050437927246094
training step: 2587, total_loss: 4.301079750061035
training step: 2588, total_loss: 5.690932273864746
training step: 2589, total_loss: 4.933215141296387
training step: 2590, total_loss: 5.132359504699707
training step: 2591, total_loss: 6.513706207275391
training step: 2592, total_loss: 5.397900581359863
training step: 2593, total_loss: 5.467000961303711
training step: 2594, total_loss: 4.8499932289123535
training step: 2595, total_loss: 4.470265865325928
training step: 2596, total_loss: 4.339448928833008
training step: 2597, total_loss: 4.473003387451172
training step: 2598, total_loss: 5.504733085632324
training step: 2599, total_loss: 4.219175338745117
training step: 2600, total_loss: 5.610537052154541
training step: 2601, total_loss: 4.851480484008789
training step: 2602, total_loss: 5.2647294998168945
training step: 2603, total_loss: 4.292231559753418
training step: 2604, total_loss: 6.017180442810059
training step: 2605, total_loss: 5.814610481262207
training step: 2606, total_loss: 5.180232048034668
training step: 2607, total_loss: 3.989044666290283
training step: 2608, total_loss: 6.485942840576172
training step: 2609, total_loss: 5.148958206176758
training step: 2610, total_loss: 5.589641571044922
training step: 2611, total_loss: 5.246021270751953
training step: 2612, total_loss: 3.7042171955108643
training step: 2613, total_loss: 5.247405052185059
training step: 2614, total_loss: 5.037312984466553
training step: 2615, total_loss: 5.525300979614258
training step: 2616, total_loss: 5.2417426109313965
training step: 2617, total_loss: 4.143043518066406
training step: 2618, total_loss: 4.4440202713012695
training step: 2619, total_loss: 5.404155731201172
training step: 2620, total_loss: 4.574780464172363
training step: 2621, total_loss: 6.200371742248535
training step: 2622, total_loss: 6.0677080154418945
training step: 2623, total_loss: 5.026223182678223
training step: 2624, total_loss: 5.2439775466918945
training step: 2625, total_loss: 4.416730880737305
training step: 2626, total_loss: 5.15000581741333
training step: 2627, total_loss: 4.739737510681152
training step: 2628, total_loss: 4.844810962677002
training step: 2629, total_loss: 5.108287811279297
training step: 2630, total_loss: 4.2515950202941895
training step: 2631, total_loss: 4.294600009918213
training step: 2632, total_loss: 5.079427719116211
training step: 2633, total_loss: 5.124614715576172
training step: 2634, total_loss: 6.811911106109619
training step: 2635, total_loss: 6.25308895111084
training step: 2636, total_loss: 4.478031635284424
training step: 2637, total_loss: 6.7092742919921875
training step: 2638, total_loss: 4.621376991271973
training step: 2639, total_loss: 5.909688949584961
training step: 2640, total_loss: 4.603389739990234
training step: 2641, total_loss: 5.972002983093262
training step: 2642, total_loss: 5.031445503234863
training step: 2643, total_loss: 5.2286882400512695
training step: 2644, total_loss: 5.263454437255859
training step: 2645, total_loss: 5.793720722198486
training step: 2646, total_loss: 5.868222236633301
training step: 2647, total_loss: 5.379827976226807
training step: 2648, total_loss: 5.828489780426025
training step: 2649, total_loss: 4.666758060455322
training step: 2650, total_loss: 4.503775596618652
training step: 2651, total_loss: 5.433152198791504
training step: 2652, total_loss: 4.975577354431152
training step: 2653, total_loss: 4.924439430236816
training step: 2654, total_loss: 5.249885559082031
training step: 2655, total_loss: 5.8295111656188965
training step: 2656, total_loss: 5.037425994873047
training step: 2657, total_loss: 4.377871990203857
training step: 2658, total_loss: 4.17837381362915
training step: 2659, total_loss: 4.08533239364624
training step: 2660, total_loss: 4.588054656982422
training step: 2661, total_loss: 5.300196647644043
training step: 2662, total_loss: 4.644889831542969
training step: 2663, total_loss: 4.286680221557617
training step: 2664, total_loss: 4.938698768615723
training step: 2665, total_loss: 3.8554129600524902
training step: 2666, total_loss: 4.744757652282715
training step: 2667, total_loss: 5.30465030670166
training step: 2668, total_loss: 6.305371284484863
training step: 2669, total_loss: 2.802422046661377
training step: 2670, total_loss: 5.394537925720215
training step: 2671, total_loss: 5.255005836486816
training step: 2672, total_loss: 4.4590253829956055
training step: 2673, total_loss: 4.639466762542725
training step: 2674, total_loss: 3.944882392883301
training step: 2675, total_loss: 5.603546619415283
training step: 2676, total_loss: 4.9583740234375
training step: 2677, total_loss: 5.884435653686523
training step: 2678, total_loss: 4.153865814208984
training step: 2679, total_loss: 4.791685581207275
training step: 2680, total_loss: 5.579155445098877
training step: 2681, total_loss: 4.443998336791992
training step: 2682, total_loss: 3.270040512084961
training step: 2683, total_loss: 5.80715274810791
training step: 2684, total_loss: 5.29616641998291
training step: 2685, total_loss: 4.914709568023682
training step: 2686, total_loss: 4.749698162078857
training step: 2687, total_loss: 5.084711074829102
training step: 2688, total_loss: 5.597662448883057
training step: 2689, total_loss: 5.030215740203857
training step: 2690, total_loss: 4.908206939697266
training step: 2691, total_loss: 4.930704116821289
training step: 2692, total_loss: 3.551985740661621
training step: 2693, total_loss: 3.691472291946411
training step: 2694, total_loss: 6.42037296295166
training step: 2695, total_loss: 5.266566276550293
training step: 2696, total_loss: 5.395226001739502
training step: 2697, total_loss: 5.896653175354004
training step: 2698, total_loss: 5.130306243896484
training step: 2699, total_loss: 4.991151809692383
training step: 2700, total_loss: 1.7510733604431152
training step: 2701, total_loss: 5.430273532867432
training step: 2702, total_loss: 4.786559104919434
training step: 2703, total_loss: 4.7151947021484375
training step: 2704, total_loss: 5.292128562927246
training step: 2705, total_loss: 5.411937713623047
training step: 2706, total_loss: 5.8166913986206055
training step: 2707, total_loss: 5.207088947296143
training step: 2708, total_loss: 5.294371604919434
training step: 2709, total_loss: 4.622594356536865
training step: 2710, total_loss: 5.571399211883545
training step: 2711, total_loss: 6.411624908447266
training step: 2712, total_loss: 5.004456043243408
training step: 2713, total_loss: 3.6982760429382324
training step: 2714, total_loss: 5.052955627441406
training step: 2715, total_loss: 4.690830230712891
training step: 2716, total_loss: 5.760797500610352
training step: 2717, total_loss: 5.378475189208984
training step: 2718, total_loss: 4.418559551239014
training step: 2719, total_loss: 5.777746200561523
training step: 2720, total_loss: 5.216264247894287
training step: 2721, total_loss: 3.9059059619903564
training step: 2722, total_loss: 3.532864570617676
training step: 2723, total_loss: 4.409435272216797
training step: 2724, total_loss: 4.252572059631348
training step: 2725, total_loss: 5.681799411773682
training step: 2726, total_loss: 4.020481586456299
training step: 2727, total_loss: 6.704643249511719
training step: 2728, total_loss: 4.078863620758057
training step: 2729, total_loss: 4.666204929351807
training step: 2730, total_loss: 5.486912727355957
training step: 2731, total_loss: 5.201907157897949
training step: 2732, total_loss: 6.513538360595703
training step: 2733, total_loss: 5.391753196716309
training step: 2734, total_loss: 0.9047896862030029
training step: 2735, total_loss: 6.3891448974609375
training step: 2736, total_loss: 4.904580116271973
training step: 2737, total_loss: 5.495110511779785
training step: 2738, total_loss: 5.690873622894287
training step: 2739, total_loss: 2.234436511993408
training step: 2740, total_loss: 5.511218547821045
training step: 2741, total_loss: 5.342849254608154
training step: 2742, total_loss: 4.290993690490723
training step: 2743, total_loss: 5.447019100189209
training step: 2744, total_loss: 4.507657527923584
training step: 2745, total_loss: 5.352343559265137
training step: 2746, total_loss: 4.028955936431885
training step: 2747, total_loss: 4.638233661651611
training step: 2748, total_loss: 5.638930320739746
training step: 2749, total_loss: 5.075898170471191
training step: 2750, total_loss: 4.241445541381836
training step: 2751, total_loss: 4.46676778793335
training step: 2752, total_loss: 3.879115104675293
training step: 2753, total_loss: 6.524175643920898
training step: 2754, total_loss: 4.525649547576904
training step: 2755, total_loss: 6.907533168792725
training step: 2756, total_loss: 4.541910171508789
training step: 2757, total_loss: 5.358836650848389
training step: 2758, total_loss: 4.191095352172852
training step: 2759, total_loss: 5.49608039855957
training step: 2760, total_loss: 5.777113914489746
training step: 2761, total_loss: 4.604096412658691
training step: 2762, total_loss: 5.224848747253418
training step: 2763, total_loss: 5.055597305297852
training step: 2764, total_loss: 6.121896743774414
training step: 2765, total_loss: 6.180171012878418
training step: 2766, total_loss: 4.928890228271484
training step: 2767, total_loss: 4.628844738006592
training step: 2768, total_loss: 4.7823944091796875
training step: 2769, total_loss: 6.729839324951172
training step: 2770, total_loss: 4.978902816772461
training step: 2771, total_loss: 5.838325500488281
training step: 2772, total_loss: 4.893123149871826
training step: 2773, total_loss: 5.956204414367676
training step: 2774, total_loss: 5.23569393157959
training step: 2775, total_loss: 5.123809814453125
training step: 2776, total_loss: 6.076178550720215
training step: 2777, total_loss: 5.527267932891846
training step: 2778, total_loss: 4.1001505851745605
training step: 2779, total_loss: 5.430825233459473
training step: 2780, total_loss: 5.848850250244141
training step: 2781, total_loss: 5.149785995483398
training step: 2782, total_loss: 4.825278282165527
training step: 2783, total_loss: 2.8045475482940674
training step: 2784, total_loss: 5.640583038330078
training step: 2785, total_loss: 5.902322769165039
training step: 2786, total_loss: 4.049985408782959
training step: 2787, total_loss: 5.182594299316406
training step: 2788, total_loss: 4.97402286529541
training step: 2789, total_loss: 5.4352827072143555
training step: 2790, total_loss: 4.044361114501953
training step: 2791, total_loss: 5.836063861846924
training step: 2792, total_loss: 5.667200088500977
training step: 2793, total_loss: 1.7594568729400635
training step: 2794, total_loss: 4.51331090927124
training step: 2795, total_loss: 3.171900749206543
training step: 2796, total_loss: 4.667667388916016
training step: 2797, total_loss: 5.727114677429199
training step: 2798, total_loss: 6.10169792175293
training step: 2799, total_loss: 5.012021064758301
training step: 2800, total_loss: 1.2900162935256958
training step: 2801, total_loss: 4.425826549530029
training step: 2802, total_loss: 5.849083423614502
training step: 2803, total_loss: 4.365232944488525
training step: 2804, total_loss: 4.630303859710693
training step: 2805, total_loss: 3.852457046508789
training step: 2806, total_loss: 5.649819374084473
training step: 2807, total_loss: 5.437037467956543
training step: 2808, total_loss: 6.533563613891602
training step: 2809, total_loss: 5.288200378417969
training step: 2810, total_loss: 5.618628978729248
training step: 2811, total_loss: 0.28353285789489746
training step: 2812, total_loss: 4.708049297332764
training step: 2813, total_loss: 6.10009765625
training step: 2814, total_loss: 5.529736518859863
training step: 2815, total_loss: 4.492551803588867
training step: 2816, total_loss: 0.3821929395198822
training step: 2817, total_loss: 6.135789394378662
training step: 2818, total_loss: 5.771778583526611
training step: 2819, total_loss: 5.46920108795166
training step: 2820, total_loss: 5.9865827560424805
training step: 2821, total_loss: 5.379140377044678
training step: 2822, total_loss: 5.158583641052246
training step: 2823, total_loss: 4.25701904296875
training step: 2824, total_loss: 5.878421783447266
training step: 2825, total_loss: 4.154019832611084
training step: 2826, total_loss: 4.945350646972656
training step: 2827, total_loss: 4.815228462219238
training step: 2828, total_loss: 4.551503658294678
training step: 2829, total_loss: 4.380888938903809
training step: 2830, total_loss: 4.369531631469727
training step: 2831, total_loss: 5.299145698547363
training step: 2832, total_loss: 4.195398807525635
training step: 2833, total_loss: 6.468231201171875
training step: 2834, total_loss: 5.334170818328857
training step: 2835, total_loss: 5.840475082397461
training step: 2836, total_loss: 4.912350654602051
training step: 2837, total_loss: 3.6482698917388916
training step: 2838, total_loss: 4.615134239196777
training step: 2839, total_loss: 5.803008079528809
training step: 2840, total_loss: 5.264734745025635
training step: 2841, total_loss: 4.6883320808410645
training step: 2842, total_loss: 4.11615514755249
training step: 2843, total_loss: 4.896341323852539
training step: 2844, total_loss: 4.40289306640625
training step: 2845, total_loss: 0.5266656875610352
training step: 2846, total_loss: 4.919594764709473
training step: 2847, total_loss: 4.410932540893555
training step: 2848, total_loss: 3.9592063426971436
training step: 2849, total_loss: 5.169282913208008
training step: 2850, total_loss: 4.7218122482299805
training step: 2851, total_loss: 4.97148323059082
training step: 2852, total_loss: 5.545713424682617
training step: 2853, total_loss: 5.468625068664551
training step: 2854, total_loss: 4.2736358642578125
training step: 2855, total_loss: 4.210075855255127
training step: 2856, total_loss: 3.34287691116333
training step: 2857, total_loss: 3.9826788902282715
training step: 2858, total_loss: 5.08711051940918
training step: 2859, total_loss: 5.8746161460876465
training step: 2860, total_loss: 6.463889122009277
training step: 2861, total_loss: 1.481952428817749
training step: 2862, total_loss: 4.532938003540039
training step: 2863, total_loss: 6.028475761413574
training step: 2864, total_loss: 4.518556594848633
training step: 2865, total_loss: 4.673315525054932
training step: 2866, total_loss: 4.29613733291626
training step: 2867, total_loss: 4.490882396697998
training step: 2868, total_loss: 4.853021144866943
training step: 2869, total_loss: 3.2323501110076904
training step: 2870, total_loss: 4.921143531799316
training step: 2871, total_loss: 5.907991409301758
training step: 2872, total_loss: 5.050665855407715
training step: 2873, total_loss: 4.824237823486328
training step: 2874, total_loss: 5.35123348236084
training step: 2875, total_loss: 5.105080604553223
training step: 2876, total_loss: 5.800323486328125
training step: 2877, total_loss: 4.0926361083984375
training step: 2878, total_loss: 3.8080687522888184
training step: 2879, total_loss: 5.255451202392578
training step: 2880, total_loss: 3.2435684204101562
training step: 2881, total_loss: 5.674673080444336
training step: 2882, total_loss: 3.1420559883117676
training step: 2883, total_loss: 4.413561820983887
training step: 2884, total_loss: 6.243041515350342
training step: 2885, total_loss: 5.600625991821289
training step: 2886, total_loss: 3.862588405609131
training step: 2887, total_loss: 5.147703170776367
training step: 2888, total_loss: 2.8998684883117676
training step: 2889, total_loss: 5.5034074783325195
training step: 2890, total_loss: 6.001136779785156
training step: 2891, total_loss: 6.297677040100098
training step: 2892, total_loss: 5.911167144775391
training step: 2893, total_loss: 5.386765956878662
training step: 2894, total_loss: 6.08366584777832
training step: 2895, total_loss: 6.20140266418457
training step: 2896, total_loss: 5.357813835144043
training step: 2897, total_loss: 4.522073268890381
training step: 2898, total_loss: 5.522027015686035
training step: 2899, total_loss: 5.5750837326049805
training step: 2900, total_loss: 5.417153358459473
training step: 2901, total_loss: 4.3381147384643555
training step: 2902, total_loss: 5.560651779174805
training step: 2903, total_loss: 5.562222480773926
training step: 2904, total_loss: 5.590676307678223
training step: 2905, total_loss: 5.090033054351807
training step: 2906, total_loss: 4.7755231857299805
training step: 2907, total_loss: 5.406866073608398
training step: 2908, total_loss: 5.998798370361328
training step: 2909, total_loss: 5.338281154632568
training step: 2910, total_loss: 5.591645240783691
training step: 2911, total_loss: 5.29979133605957
training step: 2912, total_loss: 5.287945747375488
training step: 2913, total_loss: 5.461091995239258
training step: 2914, total_loss: 5.216446399688721
training step: 2915, total_loss: 5.440789222717285
training step: 2916, total_loss: 6.2615156173706055
training step: 2917, total_loss: 4.946320533752441
training step: 2918, total_loss: 5.27473258972168
training step: 2919, total_loss: 5.389122009277344
training step: 2920, total_loss: 5.409263610839844
training step: 2921, total_loss: 5.757861137390137
training step: 2922, total_loss: 4.789553642272949
training step: 2923, total_loss: 5.389698028564453
training step: 2924, total_loss: 4.116281032562256
training step: 2925, total_loss: 4.89141321182251
training step: 2926, total_loss: 4.559000015258789
training step: 2927, total_loss: 5.943463325500488
training step: 2928, total_loss: 4.1317219734191895
training step: 2929, total_loss: 4.767782211303711
training step: 2930, total_loss: 5.210594177246094
training step: 2931, total_loss: 5.642572402954102
training step: 2932, total_loss: 5.893946647644043
training step: 2933, total_loss: 4.75123405456543
training step: 2934, total_loss: 5.666450023651123
training step: 2935, total_loss: 4.716899871826172
training step: 2936, total_loss: 6.184908866882324
training step: 2937, total_loss: 3.6062870025634766
training step: 2938, total_loss: 5.238628387451172
training step: 2939, total_loss: 5.161787033081055
training step: 2940, total_loss: 5.7959723472595215
training step: 2941, total_loss: 3.993626594543457
training step: 2942, total_loss: 5.904349327087402
training step: 2943, total_loss: 5.302966594696045
training step: 2944, total_loss: 6.430988311767578
training step: 2945, total_loss: 5.3648881912231445
training step: 2946, total_loss: 5.613714218139648
training step: 2947, total_loss: 5.390349388122559
training step: 2948, total_loss: 4.563805103302002
training step: 2949, total_loss: 5.293764114379883
training step: 2950, total_loss: 5.026137828826904
training step: 2951, total_loss: 5.704659461975098
training step: 2952, total_loss: 5.729719161987305
training step: 2953, total_loss: 3.28749942779541
training step: 2954, total_loss: 5.964228630065918
training step: 2955, total_loss: 5.381520748138428
training step: 2956, total_loss: 4.032248497009277
training step: 2957, total_loss: 2.865516185760498
training step: 2958, total_loss: 4.933588027954102
training step: 2959, total_loss: 5.089648246765137
training step: 2960, total_loss: 6.077783584594727
training step: 2961, total_loss: 5.128691673278809
training step: 2962, total_loss: 3.643200397491455
training step: 2963, total_loss: 5.189316749572754
training step: 2964, total_loss: 4.701606750488281
training step: 2965, total_loss: 4.787135601043701
training step: 2966, total_loss: 3.8541057109832764
training step: 2967, total_loss: 4.717740535736084
training step: 2968, total_loss: 5.569039821624756
training step: 2969, total_loss: 1.4554212093353271
training step: 2970, total_loss: 5.560043811798096
training step: 2971, total_loss: 4.7351226806640625
training step: 2972, total_loss: 5.195596694946289
training step: 2973, total_loss: 5.3317389488220215
training step: 2974, total_loss: 4.896929740905762
training step: 2975, total_loss: 5.220038414001465
training step: 2976, total_loss: 5.091684818267822
training step: 2977, total_loss: 5.748766899108887
training step: 2978, total_loss: 3.628875732421875
training step: 2979, total_loss: 5.066063404083252
training step: 2980, total_loss: 3.7737393379211426
training step: 2981, total_loss: 4.320749282836914
training step: 2982, total_loss: 4.633718490600586
training step: 2983, total_loss: 4.748560905456543
training step: 2984, total_loss: 4.646553039550781
training step: 2985, total_loss: 4.655675411224365
training step: 2986, total_loss: 4.754666328430176
training step: 2987, total_loss: 5.422747611999512
training step: 2988, total_loss: 4.414302825927734
training step: 2989, total_loss: 4.0020060539245605
training step: 2990, total_loss: 5.017805099487305
training step: 2991, total_loss: 5.921987056732178
training step: 2992, total_loss: 5.52951717376709
training step: 2993, total_loss: 6.879448413848877
training step: 2994, total_loss: 4.399138450622559
training step: 2995, total_loss: 4.726716995239258
training step: 2996, total_loss: 4.798070430755615
training step: 2997, total_loss: 4.7841081619262695
training step: 2998, total_loss: 5.752316474914551
training step: 2999, total_loss: 3.291428565979004
training step: 3000, total_loss: 4.032848358154297
training step: 3001, total_loss: 5.3958892822265625
training step: 3002, total_loss: 4.769775390625
training step: 3003, total_loss: 4.8794097900390625
training step: 3004, total_loss: 4.329672336578369
training step: 3005, total_loss: 3.7304840087890625
training step: 3006, total_loss: 0.5818345546722412
training step: 3007, total_loss: 5.504533767700195
training step: 3008, total_loss: 4.070905685424805
training step: 3009, total_loss: 5.727472305297852
training step: 3010, total_loss: 5.738035202026367
training step: 3011, total_loss: 2.5497779846191406
training step: 3012, total_loss: 3.2658333778381348
training step: 3013, total_loss: 5.953824996948242
training step: 3014, total_loss: 5.0185956954956055
training step: 3015, total_loss: 4.66505241394043
training step: 3016, total_loss: 4.902700424194336
training step: 3017, total_loss: 5.064324378967285
training step: 3018, total_loss: 5.427745819091797
training step: 3019, total_loss: 4.944087505340576
training step: 3020, total_loss: 6.236292839050293
training step: 3021, total_loss: 6.130733489990234
training step: 3022, total_loss: 6.545429229736328
training step: 3023, total_loss: 5.425070762634277
training step: 3024, total_loss: 4.188020706176758
training step: 3025, total_loss: 4.426845550537109
training step: 3026, total_loss: 4.661018371582031
training step: 3027, total_loss: 4.932744026184082
training step: 3028, total_loss: 6.136706352233887
training step: 3029, total_loss: 5.081513404846191
training step: 3030, total_loss: 4.611870288848877
training step: 3031, total_loss: 5.5290093421936035
training step: 3032, total_loss: 5.175451755523682
training step: 3033, total_loss: 5.6745924949646
training step: 3034, total_loss: 5.94708251953125
training step: 3035, total_loss: 5.043361663818359
training step: 3036, total_loss: 4.967026233673096
training step: 3037, total_loss: 3.894789218902588
training step: 3038, total_loss: 4.8614888191223145
training step: 3039, total_loss: 5.463376998901367
training step: 3040, total_loss: 4.0495758056640625
training step: 3041, total_loss: 4.955228805541992
training step: 3042, total_loss: 5.1873016357421875
training step: 3043, total_loss: 4.706123352050781
training step: 3044, total_loss: 6.261622428894043
training step: 3045, total_loss: 4.862802505493164
training step: 3046, total_loss: 4.111766815185547
training step: 3047, total_loss: 5.7845916748046875
training step: 3048, total_loss: 5.235351085662842
training step: 3049, total_loss: 5.312411785125732
training step: 3050, total_loss: 5.641886234283447
training step: 3051, total_loss: 3.6809935569763184
training step: 3052, total_loss: 5.3451457023620605
training step: 3053, total_loss: 5.124834060668945
training step: 3054, total_loss: 4.893457412719727
training step: 3055, total_loss: 5.043933868408203
training step: 3056, total_loss: 4.950798034667969
training step: 3057, total_loss: 5.227605819702148
training step: 3058, total_loss: 5.3498663902282715
training step: 3059, total_loss: 4.4321112632751465
training step: 3060, total_loss: 4.724627494812012
training step: 3061, total_loss: 5.151862144470215
training step: 3062, total_loss: 6.51251220703125
training step: 3063, total_loss: 5.959977149963379
training step: 3064, total_loss: 5.477396011352539
training step: 3065, total_loss: 6.145423889160156
training step: 3066, total_loss: 5.3192315101623535
training step: 3067, total_loss: 4.269657611846924
training step: 3068, total_loss: 4.52754545211792
training step: 3069, total_loss: 4.020740509033203
training step: 3070, total_loss: 3.5014915466308594
training step: 3071, total_loss: 4.640681743621826
training step: 3072, total_loss: 5.3237433433532715
training step: 3073, total_loss: 5.59037971496582
training step: 3074, total_loss: 4.040290832519531
training step: 3075, total_loss: 5.3052496910095215
training step: 3076, total_loss: 4.5070648193359375
training step: 3077, total_loss: 5.194814682006836
training step: 3078, total_loss: 5.863115310668945
training step: 3079, total_loss: 4.499233245849609
training step: 3080, total_loss: 5.10683536529541
training step: 3081, total_loss: 4.2542853355407715
training step: 3082, total_loss: 4.498102188110352
training step: 3083, total_loss: 5.2704243659973145
training step: 3084, total_loss: 5.1535491943359375
training step: 3085, total_loss: 3.990001678466797
training step: 3086, total_loss: 3.476625442504883
training step: 3087, total_loss: 5.346190929412842
training step: 3088, total_loss: 5.011170864105225
training step: 3089, total_loss: 5.005845069885254
training step: 3090, total_loss: 4.437522888183594
training step: 3091, total_loss: 5.1382246017456055
training step: 3092, total_loss: 4.256951332092285
training step: 3093, total_loss: 4.260987758636475
training step: 3094, total_loss: 3.8640570640563965
training step: 3095, total_loss: 6.331021308898926
training step: 3096, total_loss: 4.63731575012207
training step: 3097, total_loss: 4.532029151916504
training step: 3098, total_loss: 4.885878562927246
training step: 3099, total_loss: 4.409597396850586
training step: 3100, total_loss: 4.559084892272949
training step: 3101, total_loss: 4.055334091186523
training step: 3102, total_loss: 5.480359077453613
training step: 3103, total_loss: 4.811301231384277
training step: 3104, total_loss: 5.500352382659912
training step: 3105, total_loss: 5.418304920196533
training step: 3106, total_loss: 4.801063537597656
training step: 3107, total_loss: 5.234492301940918
training step: 3108, total_loss: 4.107329368591309
training step: 3109, total_loss: 5.005728721618652
training step: 3110, total_loss: 6.772600173950195
training step: 3111, total_loss: 5.644583702087402
training step: 3112, total_loss: 5.082878112792969
training step: 3113, total_loss: 4.372830867767334
training step: 3114, total_loss: 3.3613693714141846
training step: 3115, total_loss: 6.412529945373535
training step: 3116, total_loss: 4.646073818206787
training step: 3117, total_loss: 5.72434663772583
training step: 3118, total_loss: 6.096070289611816
training step: 3119, total_loss: 4.118525981903076
training step: 3120, total_loss: 4.929976463317871
training step: 3121, total_loss: 5.079503059387207
training step: 3122, total_loss: 4.939873218536377
training step: 3123, total_loss: 4.662269592285156
training step: 3124, total_loss: 4.238310813903809
training step: 3125, total_loss: 4.7502593994140625
training step: 3126, total_loss: 3.8852756023406982
training step: 3127, total_loss: 4.560410499572754
training step: 3128, total_loss: 5.369287967681885
training step: 3129, total_loss: 4.88623046875
training step: 3130, total_loss: 1.5425260066986084
training step: 3131, total_loss: 4.649650573730469
training step: 3132, total_loss: 4.9291276931762695
training step: 3133, total_loss: 4.614254951477051
training step: 3134, total_loss: 5.455715179443359
training step: 3135, total_loss: 4.165578842163086
training step: 3136, total_loss: 3.0591952800750732
training step: 3137, total_loss: 4.7396039962768555
training step: 3138, total_loss: 5.9224958419799805
training step: 3139, total_loss: 5.756402492523193
training step: 3140, total_loss: 5.534460067749023
training step: 3141, total_loss: 5.986109256744385
training step: 3142, total_loss: 5.373177528381348
training step: 3143, total_loss: 7.010692596435547
training step: 3144, total_loss: 4.943517208099365
training step: 3145, total_loss: 5.260241508483887
training step: 3146, total_loss: 2.5914604663848877
training step: 3147, total_loss: 4.469310283660889
training step: 3148, total_loss: 5.028514862060547
training step: 3149, total_loss: 5.9598259925842285
training step: 3150, total_loss: 4.470463752746582
training step: 3151, total_loss: 3.954042434692383
training step: 3152, total_loss: 6.173184394836426
training step: 3153, total_loss: 5.481728553771973
training step: 3154, total_loss: 5.545782089233398
training step: 3155, total_loss: 4.972142696380615
training step: 3156, total_loss: 5.128642559051514
training step: 3157, total_loss: 4.23977518081665
training step: 3158, total_loss: 6.580080032348633
training step: 3159, total_loss: 5.188974857330322
training step: 3160, total_loss: 5.75432014465332
training step: 3161, total_loss: 4.0294647216796875
training step: 3162, total_loss: 6.25344181060791
training step: 3163, total_loss: 5.815423965454102
training step: 3164, total_loss: 1.7266488075256348
training step: 3165, total_loss: 5.478597640991211
training step: 3166, total_loss: 4.839162826538086
training step: 3167, total_loss: 5.003960609436035
training step: 3168, total_loss: 5.207109451293945
training step: 3169, total_loss: 4.268263339996338
training step: 3170, total_loss: 5.522985458374023
training step: 3171, total_loss: 2.459380626678467
training step: 3172, total_loss: 5.130298137664795
training step: 3173, total_loss: 5.794448375701904
training step: 3174, total_loss: 5.56756067276001
training step: 3175, total_loss: 5.123031139373779
training step: 3176, total_loss: 6.055980682373047
training step: 3177, total_loss: 3.867238998413086
training step: 3178, total_loss: 5.5063157081604
training step: 3179, total_loss: 5.6056952476501465
training step: 3180, total_loss: 4.23634672164917
training step: 3181, total_loss: 5.132599830627441
training step: 3182, total_loss: 6.763240337371826
training step: 3183, total_loss: 5.175383567810059
training step: 3184, total_loss: 5.596214771270752
training step: 3185, total_loss: 3.50876784324646
training step: 3186, total_loss: 5.451149940490723
training step: 3187, total_loss: 5.138092994689941
training step: 3188, total_loss: 5.2058210372924805
training step: 3189, total_loss: 5.557835578918457
training step: 3190, total_loss: 5.155367374420166
training step: 3191, total_loss: 4.010491371154785
training step: 3192, total_loss: 4.996964454650879
training step: 3193, total_loss: 5.128691673278809
training step: 3194, total_loss: 5.053579330444336
training step: 3195, total_loss: 5.4976301193237305
training step: 3196, total_loss: 5.316900253295898
training step: 3197, total_loss: 3.1214847564697266
training step: 3198, total_loss: 4.1685872077941895
training step: 3199, total_loss: 4.9076337814331055
training step: 3200, total_loss: 6.958248615264893
training step: 3201, total_loss: 5.498746871948242
training step: 3202, total_loss: 4.087226867675781
training step: 3203, total_loss: 4.956778526306152
training step: 3204, total_loss: 5.332765102386475
training step: 3205, total_loss: 5.626654624938965
training step: 3206, total_loss: 5.5227251052856445
training step: 3207, total_loss: 4.676398277282715
training step: 3208, total_loss: 4.853494644165039
training step: 3209, total_loss: 6.212985515594482
training step: 3210, total_loss: 5.046106815338135
training step: 3211, total_loss: 4.088807582855225
training step: 3212, total_loss: 2.5957717895507812
training step: 3213, total_loss: 4.815881729125977
training step: 3214, total_loss: 2.787126064300537
training step: 3215, total_loss: 5.224145889282227
training step: 3216, total_loss: 5.157479286193848
training step: 3217, total_loss: 5.303576469421387
training step: 3218, total_loss: 5.171285629272461
training step: 3219, total_loss: 4.3428802490234375
training step: 3220, total_loss: 4.725995063781738
training step: 3221, total_loss: 6.202695369720459
training step: 3222, total_loss: 4.667362689971924
training step: 3223, total_loss: 2.548208236694336
training step: 3224, total_loss: 4.447199821472168
training step: 3225, total_loss: 4.876413345336914
training step: 3226, total_loss: 4.584712982177734
training step: 3227, total_loss: 4.058616638183594
training step: 3228, total_loss: 1.96576726436615
training step: 3229, total_loss: 6.2180585861206055
training step: 3230, total_loss: 5.0740203857421875
training step: 3231, total_loss: 4.082590103149414
training step: 3232, total_loss: 5.500603675842285
training step: 3233, total_loss: 6.042742729187012
training step: 3234, total_loss: 4.9971818923950195
training step: 3235, total_loss: 4.859273910522461
training step: 3236, total_loss: 5.954738616943359
training step: 3237, total_loss: 5.205577850341797
training step: 3238, total_loss: 5.358908653259277
training step: 3239, total_loss: 5.38370418548584
training step: 3240, total_loss: 5.09913444519043
training step: 3241, total_loss: 4.902172088623047
training step: 3242, total_loss: 2.3575010299682617
training step: 3243, total_loss: 5.252652168273926
training step: 3244, total_loss: 3.982295036315918
training step: 3245, total_loss: 5.0655717849731445
training step: 3246, total_loss: 5.270418167114258
training step: 3247, total_loss: 5.926327228546143
training step: 3248, total_loss: 4.672772407531738
training step: 3249, total_loss: 4.754244804382324
training step: 3250, total_loss: 3.966102123260498
training step: 3251, total_loss: 5.493902206420898
training step: 3252, total_loss: 5.764387130737305
training step: 3253, total_loss: 0.6129226684570312
training step: 3254, total_loss: 6.844322204589844
training step: 3255, total_loss: 2.556107521057129
training step: 3256, total_loss: 5.238166809082031
training step: 3257, total_loss: 4.154820919036865
training step: 3258, total_loss: 4.373149871826172
training step: 3259, total_loss: 3.691183567047119
training step: 3260, total_loss: 5.05481481552124
training step: 3261, total_loss: 5.4872283935546875
training step: 3262, total_loss: 5.989436149597168
training step: 3263, total_loss: 5.351832866668701
training step: 3264, total_loss: 5.278361797332764
training step: 3265, total_loss: 5.340362548828125
training step: 3266, total_loss: 5.611413955688477
training step: 3267, total_loss: 5.088291645050049
training step: 3268, total_loss: 4.773720741271973
training step: 3269, total_loss: 2.6052517890930176
training step: 3270, total_loss: 5.271542072296143
training step: 3271, total_loss: 5.066964149475098
training step: 3272, total_loss: 5.966752052307129
training step: 3273, total_loss: 3.9446630477905273
training step: 3274, total_loss: 3.3881800174713135
training step: 3275, total_loss: 3.597668170928955
training step: 3276, total_loss: 5.175810813903809
training step: 3277, total_loss: 5.001151084899902
training step: 3278, total_loss: 6.386980056762695
training step: 3279, total_loss: 5.441805839538574
training step: 3280, total_loss: 2.975484848022461
training step: 3281, total_loss: 4.925045013427734
training step: 3282, total_loss: 5.020315647125244
training step: 3283, total_loss: 4.748873710632324
training step: 3284, total_loss: 5.280679702758789
training step: 3285, total_loss: 5.976295471191406
training step: 3286, total_loss: 5.23239803314209
training step: 3287, total_loss: 5.983696937561035
training step: 3288, total_loss: 1.8641215562820435
training step: 3289, total_loss: 5.4569807052612305
training step: 3290, total_loss: 4.938436508178711
training step: 3291, total_loss: 3.975430488586426
training step: 3292, total_loss: 5.630837917327881
training step: 3293, total_loss: 5.08599328994751
training step: 3294, total_loss: 4.684750556945801
training step: 3295, total_loss: 4.23099422454834
training step: 3296, total_loss: 5.088412284851074
training step: 3297, total_loss: 4.8361005783081055
training step: 3298, total_loss: 5.925583839416504
training step: 3299, total_loss: 2.1196932792663574
training step: 3300, total_loss: 4.968478202819824
training step: 3301, total_loss: 4.983216762542725
training step: 3302, total_loss: 1.2277339696884155
training step: 3303, total_loss: 6.036460876464844
training step: 3304, total_loss: 4.926220893859863
training step: 3305, total_loss: 3.0889501571655273
training step: 3306, total_loss: 5.028688430786133
training step: 3307, total_loss: 5.0752410888671875
training step: 3308, total_loss: 5.083052158355713
training step: 3309, total_loss: 4.428291320800781
training step: 3310, total_loss: 5.601130485534668
training step: 3311, total_loss: 4.009922504425049
training step: 3312, total_loss: 4.450206756591797
training step: 3313, total_loss: 3.9377899169921875
training step: 3314, total_loss: 4.972625732421875
training step: 3315, total_loss: 4.605959892272949
training step: 3316, total_loss: 5.471484184265137
training step: 3317, total_loss: 4.501808166503906
training step: 3318, total_loss: 2.6274566650390625
training step: 3319, total_loss: 5.284667015075684
training step: 3320, total_loss: 4.158447265625
training step: 3321, total_loss: 4.821896553039551
training step: 3322, total_loss: 5.175350189208984
training step: 3323, total_loss: 5.977953910827637
training step: 3324, total_loss: 4.900366306304932
training step: 3325, total_loss: 4.72183895111084
training step: 3326, total_loss: 5.107283592224121
training step: 3327, total_loss: 4.514110088348389
training step: 3328, total_loss: 4.7063374519348145
training step: 3329, total_loss: 7.311032295227051
training step: 3330, total_loss: 3.8058009147644043
training step: 3331, total_loss: 4.170095920562744
training step: 3332, total_loss: 4.758670806884766
training step: 3333, total_loss: 6.013674736022949
training step: 3334, total_loss: 5.062249183654785
training step: 3335, total_loss: 4.178804397583008
training step: 3336, total_loss: 4.956180095672607
training step: 3337, total_loss: 4.740009784698486
training step: 3338, total_loss: 4.606001377105713
training step: 3339, total_loss: 4.148146629333496
training step: 3340, total_loss: 5.294126510620117
training step: 3341, total_loss: 6.422079086303711
training step: 3342, total_loss: 5.530481338500977
training step: 3343, total_loss: 4.1930999755859375
training step: 3344, total_loss: 6.893862247467041
training step: 3345, total_loss: 4.090174674987793
training step: 3346, total_loss: 5.217654228210449
training step: 3347, total_loss: 3.740156650543213
training step: 3348, total_loss: 5.704294204711914
training step: 3349, total_loss: 5.560492038726807
training step: 3350, total_loss: 4.391645908355713
training step: 3351, total_loss: 6.30039644241333
training step: 3352, total_loss: 4.156778812408447
training step: 3353, total_loss: 2.3945298194885254
training step: 3354, total_loss: 5.112949371337891
training step: 3355, total_loss: 5.859043598175049
training step: 3356, total_loss: 1.5726630687713623
training step: 3357, total_loss: 5.873488903045654
training step: 3358, total_loss: 4.761092185974121
training step: 3359, total_loss: 5.499174118041992
training step: 3360, total_loss: 3.284353733062744
training step: 3361, total_loss: 4.473981857299805
training step: 3362, total_loss: 6.248648166656494
training step: 3363, total_loss: 4.438472747802734
training step: 3364, total_loss: 5.0781168937683105
training step: 3365, total_loss: 4.636085510253906
training step: 3366, total_loss: 5.577478885650635
training step: 3367, total_loss: 6.399716854095459
training step: 3368, total_loss: 4.676758766174316
training step: 3369, total_loss: 5.852532386779785
training step: 3370, total_loss: 4.735559463500977
training step: 3371, total_loss: 5.578611373901367
training step: 3372, total_loss: 5.4671125411987305
training step: 3373, total_loss: 5.099431991577148
training step: 3374, total_loss: 4.669559478759766
training step: 3375, total_loss: 4.196233749389648
training step: 3376, total_loss: 5.236146926879883
training step: 3377, total_loss: 5.309298515319824
training step: 3378, total_loss: 4.4593353271484375
training step: 3379, total_loss: 4.261411190032959
training step: 3380, total_loss: 4.124484062194824
training step: 3381, total_loss: 6.604468822479248
training step: 3382, total_loss: 4.411428928375244
training step: 3383, total_loss: 7.028684139251709
training step: 3384, total_loss: 3.066399574279785
training step: 3385, total_loss: 5.996516227722168
training step: 3386, total_loss: 5.830534934997559
training step: 3387, total_loss: 4.595083236694336
training step: 3388, total_loss: 6.106745719909668
training step: 3389, total_loss: 4.40411376953125
training step: 3390, total_loss: 5.221355438232422
training step: 3391, total_loss: 6.087442874908447
training step: 3392, total_loss: 4.442603588104248
training step: 3393, total_loss: 3.8876090049743652
training step: 3394, total_loss: 5.1995015144348145
training step: 3395, total_loss: 3.41388201713562
training step: 3396, total_loss: 3.7024683952331543
training step: 3397, total_loss: 4.9073591232299805
training step: 3398, total_loss: 4.84812068939209
training step: 3399, total_loss: 4.853382587432861
training step: 3400, total_loss: 4.619134902954102
training step: 3401, total_loss: 5.187999725341797
training step: 3402, total_loss: 4.763012886047363
training step: 3403, total_loss: 3.145124912261963
training step: 3404, total_loss: 5.041202068328857
training step: 3405, total_loss: 3.5590476989746094
training step: 3406, total_loss: 5.072600364685059
training step: 3407, total_loss: 5.6668572425842285
training step: 3408, total_loss: 5.283941268920898
training step: 3409, total_loss: 4.5597429275512695
training step: 3410, total_loss: 4.191251754760742
training step: 3411, total_loss: 4.514164924621582
training step: 3412, total_loss: 4.626404762268066
training step: 3413, total_loss: 4.30271577835083
training step: 3414, total_loss: 4.541990280151367
training step: 3415, total_loss: 3.097843647003174
training step: 3416, total_loss: 5.387730121612549
training step: 3417, total_loss: 5.056456565856934
training step: 3418, total_loss: 4.570741653442383
training step: 3419, total_loss: 4.710174083709717
training step: 3420, total_loss: 5.378890037536621
training step: 3421, total_loss: 4.312382221221924
training step: 3422, total_loss: 5.103677749633789
training step: 3423, total_loss: 4.796053886413574
training step: 3424, total_loss: 5.645010471343994
training step: 3425, total_loss: 4.407048225402832
training step: 3426, total_loss: 5.177112102508545
training step: 3427, total_loss: 4.009005546569824
training step: 3428, total_loss: 4.541692733764648
training step: 3429, total_loss: 4.8854756355285645
training step: 3430, total_loss: 5.068080425262451
training step: 3431, total_loss: 5.395674705505371
training step: 3432, total_loss: 5.521585464477539
training step: 3433, total_loss: 5.481728553771973
training step: 3434, total_loss: 4.399876594543457
training step: 3435, total_loss: 5.1623992919921875
training step: 3436, total_loss: 4.293066024780273
training step: 3437, total_loss: 4.529804706573486
training step: 3438, total_loss: 4.16863489151001
training step: 3439, total_loss: 5.0478081703186035
training step: 3440, total_loss: 4.831544399261475
training step: 3441, total_loss: 5.03434944152832
training step: 3442, total_loss: 4.382170677185059
training step: 3443, total_loss: 5.0279035568237305
training step: 3444, total_loss: 4.488012313842773
training step: 3445, total_loss: 5.610979080200195
training step: 3446, total_loss: 4.60136604309082
training step: 3447, total_loss: 5.495162010192871
training step: 3448, total_loss: 4.085387229919434
training step: 3449, total_loss: 5.237009048461914
training step: 3450, total_loss: 4.111246585845947
training step: 3451, total_loss: 3.967620372772217
training step: 3452, total_loss: 4.594119071960449
training step: 3453, total_loss: 5.335941314697266
training step: 3454, total_loss: 4.018222332000732
training step: 3455, total_loss: 4.818889141082764
training step: 3456, total_loss: 3.3954455852508545
training step: 3457, total_loss: 4.356142997741699
training step: 3458, total_loss: 5.121156692504883
training step: 3459, total_loss: 5.135231971740723
training step: 3460, total_loss: 4.617694854736328
training step: 3461, total_loss: 4.689802169799805
training step: 3462, total_loss: 4.7879228591918945
training step: 3463, total_loss: 6.564310073852539
training step: 3464, total_loss: 3.784221649169922
training step: 3465, total_loss: 5.428443908691406
training step: 3466, total_loss: 5.007074356079102
training step: 3467, total_loss: 4.334199905395508
training step: 3468, total_loss: 4.657022476196289
training step: 3469, total_loss: 3.486339569091797
training step: 3470, total_loss: 3.5880227088928223
training step: 3471, total_loss: 5.48020601272583
training step: 3472, total_loss: 4.216048240661621
training step: 3473, total_loss: 4.999663352966309
training step: 3474, total_loss: 5.195062637329102
training step: 3475, total_loss: 4.909258842468262
training step: 3476, total_loss: 3.8806586265563965
training step: 3477, total_loss: 5.966629981994629
training step: 3478, total_loss: 4.377700328826904
training step: 3479, total_loss: 4.793246269226074
training step: 3480, total_loss: 3.96781849861145
training step: 3481, total_loss: 5.3483805656433105
training step: 3482, total_loss: 5.155445575714111
training step: 3483, total_loss: 5.801242351531982
training step: 3484, total_loss: 5.5281782150268555
training step: 3485, total_loss: 5.294877052307129
training step: 3486, total_loss: 5.667202472686768
training step: 3487, total_loss: 6.312599182128906
training step: 3488, total_loss: 4.970590591430664
training step: 3489, total_loss: 3.344562292098999
training step: 3490, total_loss: 4.486825942993164
training step: 3491, total_loss: 4.596410751342773
training step: 3492, total_loss: 5.1687445640563965
training step: 3493, total_loss: 5.56943416595459
training step: 3494, total_loss: 5.376876354217529
training step: 3495, total_loss: 3.206817150115967
training step: 3496, total_loss: 4.778471946716309
training step: 3497, total_loss: 5.106906890869141
training step: 3498, total_loss: 5.977967739105225
training step: 3499, total_loss: 4.854378700256348
training step: 3500, total_loss: 4.978404521942139
training step: 3501, total_loss: 4.92148494720459
training step: 3502, total_loss: 1.9369094371795654
training step: 3503, total_loss: 4.8863205909729
training step: 3504, total_loss: 4.692829132080078
training step: 3505, total_loss: 4.865884780883789
training step: 3506, total_loss: 5.457162380218506
training step: 3507, total_loss: 5.767967700958252
training step: 3508, total_loss: 5.331212997436523
training step: 3509, total_loss: 4.759477615356445
training step: 3510, total_loss: 4.222124099731445
training step: 3511, total_loss: 4.605081081390381
training step: 3512, total_loss: 5.363352298736572
training step: 3513, total_loss: 4.908684730529785
training step: 3514, total_loss: 1.5264737606048584
training step: 3515, total_loss: 4.21787166595459
training step: 3516, total_loss: 5.934164047241211
training step: 3517, total_loss: 4.161328315734863
training step: 3518, total_loss: 6.7578301429748535
training step: 3519, total_loss: 5.8485026359558105
training step: 3520, total_loss: 4.765785217285156
training step: 3521, total_loss: 6.083216667175293
training step: 3522, total_loss: 4.32840633392334
training step: 3523, total_loss: 5.254241943359375
training step: 3524, total_loss: 5.018210411071777
training step: 3525, total_loss: 5.711555480957031
training step: 3526, total_loss: 5.233734607696533
training step: 3527, total_loss: 5.386562347412109
training step: 3528, total_loss: 5.150672912597656
training step: 3529, total_loss: 4.017662048339844
training step: 3530, total_loss: 4.883611679077148
training step: 3531, total_loss: 4.4027485847473145
training step: 3532, total_loss: 5.709136962890625
training step: 3533, total_loss: 4.185652732849121
training step: 3534, total_loss: 6.457340240478516
training step: 3535, total_loss: 6.0225982666015625
training step: 3536, total_loss: 4.743779182434082
training step: 3537, total_loss: 4.693987846374512
training step: 3538, total_loss: 5.238556861877441
training step: 3539, total_loss: 5.19941520690918
training step: 3540, total_loss: 4.566963195800781
training step: 3541, total_loss: 4.781581878662109
training step: 3542, total_loss: 4.964657783508301
training step: 3543, total_loss: 5.552873611450195
training step: 3544, total_loss: 5.105010986328125
training step: 3545, total_loss: 3.0219192504882812
training step: 3546, total_loss: 4.676087856292725
training step: 3547, total_loss: 5.446718215942383
training step: 3548, total_loss: 5.27052116394043
training step: 3549, total_loss: 3.6775877475738525
training step: 3550, total_loss: 4.063107490539551
training step: 3551, total_loss: 2.8500285148620605
training step: 3552, total_loss: 5.741218566894531
training step: 3553, total_loss: 4.070699691772461
training step: 3554, total_loss: 4.672934055328369
training step: 3555, total_loss: 3.519392967224121
training step: 3556, total_loss: 5.276191234588623
training step: 3557, total_loss: 4.18282413482666
training step: 3558, total_loss: 0.5734775066375732
training step: 3559, total_loss: 0.615206778049469
training step: 3560, total_loss: 5.418354034423828
training step: 3561, total_loss: 2.3281917572021484
training step: 3562, total_loss: 4.207663536071777
training step: 3563, total_loss: 5.1179070472717285
training step: 3564, total_loss: 3.4369027614593506
training step: 3565, total_loss: 5.2915544509887695
training step: 3566, total_loss: 5.879241466522217
training step: 3567, total_loss: 0.2349872589111328
training step: 3568, total_loss: 4.719203948974609
training step: 3569, total_loss: 5.732295036315918
training step: 3570, total_loss: 0.1610684096813202
training step: 3571, total_loss: 5.763542175292969
training step: 3572, total_loss: 5.25956916809082
training step: 3573, total_loss: 5.14694881439209
training step: 3574, total_loss: 6.181778907775879
training step: 3575, total_loss: 6.004215717315674
training step: 3576, total_loss: 4.818741798400879
training step: 3577, total_loss: 6.315042018890381
training step: 3578, total_loss: 5.067688941955566
training step: 3579, total_loss: 5.4585371017456055
training step: 3580, total_loss: 5.3660736083984375
training step: 3581, total_loss: 0.06562398374080658
training step: 3582, total_loss: 3.3792295455932617
training step: 3583, total_loss: 3.5681443214416504
training step: 3584, total_loss: 4.820757865905762
training step: 3585, total_loss: 4.5205206871032715
training step: 3586, total_loss: 5.05387020111084
training step: 3587, total_loss: 4.375259876251221
training step: 3588, total_loss: 4.556821346282959
training step: 3589, total_loss: 4.948183536529541
training step: 3590, total_loss: 4.474321365356445
training step: 3591, total_loss: 5.511966705322266
training step: 3592, total_loss: 7.019441604614258
training step: 3593, total_loss: 4.288943290710449
training step: 3594, total_loss: 5.278701305389404
training step: 3595, total_loss: 6.674709320068359
training step: 3596, total_loss: 6.084671974182129
training step: 3597, total_loss: 5.529636383056641
training step: 3598, total_loss: 5.585196018218994
training step: 3599, total_loss: 5.366748809814453
training step: 3600, total_loss: 4.266308784484863
training step: 3601, total_loss: 4.437946319580078
training step: 3602, total_loss: 5.2552337646484375
training step: 3603, total_loss: 5.220487117767334
training step: 3604, total_loss: 5.358675003051758
training step: 3605, total_loss: 5.486440181732178
training step: 3606, total_loss: 5.307954788208008
training step: 3607, total_loss: 4.222124099731445
training step: 3608, total_loss: 5.139102935791016
training step: 3609, total_loss: 5.459454536437988
training step: 3610, total_loss: 5.730977535247803
training step: 3611, total_loss: 4.840810775756836
training step: 3612, total_loss: 4.821163654327393
training step: 3613, total_loss: 5.914811134338379
training step: 3614, total_loss: 5.14282751083374
training step: 3615, total_loss: 6.176301002502441
training step: 3616, total_loss: 5.374322414398193
training step: 3617, total_loss: 5.597614288330078
training step: 3618, total_loss: 5.832157135009766
training step: 3619, total_loss: 5.291568279266357
training step: 3620, total_loss: 6.15941047668457
training step: 3621, total_loss: 4.954751968383789
training step: 3622, total_loss: 4.9522504806518555
training step: 3623, total_loss: 5.3606343269348145
training step: 3624, total_loss: 5.812078475952148
training step: 3625, total_loss: 5.316083908081055
training step: 3626, total_loss: 4.748398780822754
training step: 3627, total_loss: 5.199395179748535
training step: 3628, total_loss: 4.379977226257324
training step: 3629, total_loss: 4.91217041015625
training step: 3630, total_loss: 4.904223442077637
training step: 3631, total_loss: 5.011542797088623
training step: 3632, total_loss: 6.676446437835693
training step: 3633, total_loss: 5.474990367889404
training step: 3634, total_loss: 4.610880374908447
training step: 3635, total_loss: 5.293442726135254
training step: 3636, total_loss: 5.3715291023254395
training step: 3637, total_loss: 4.642745018005371
training step: 3638, total_loss: 4.800176620483398
training step: 3639, total_loss: 4.577179908752441
training step: 3640, total_loss: 4.934745788574219
training step: 3641, total_loss: 4.396696090698242
training step: 3642, total_loss: 4.467004776000977
training step: 3643, total_loss: 4.578914165496826
training step: 3644, total_loss: 4.186357021331787
training step: 3645, total_loss: 3.4707818031311035
training step: 3646, total_loss: 6.225198745727539
training step: 3647, total_loss: 5.656866073608398
training step: 3648, total_loss: 5.346902370452881
training step: 3649, total_loss: 5.778378486633301
training step: 3650, total_loss: 3.829454183578491
training step: 3651, total_loss: 5.008617877960205
training step: 3652, total_loss: 4.919456481933594
training step: 3653, total_loss: 4.142132759094238
training step: 3654, total_loss: 5.165587902069092
training step: 3655, total_loss: 5.316583156585693
training step: 3656, total_loss: 6.773954391479492
training step: 3657, total_loss: 4.140751838684082
training step: 3658, total_loss: 3.625413417816162
training step: 3659, total_loss: 4.839388847351074
training step: 3660, total_loss: 4.222378253936768
training step: 3661, total_loss: 4.403810024261475
training step: 3662, total_loss: 1.8778917789459229
training step: 3663, total_loss: 6.798768997192383
training step: 3664, total_loss: 5.120697021484375
training step: 3665, total_loss: 6.7571258544921875
training step: 3666, total_loss: 7.32256555557251
training step: 3667, total_loss: 1.4156020879745483
training step: 3668, total_loss: 4.179882049560547
training step: 3669, total_loss: 6.563304901123047
training step: 3670, total_loss: 6.653679847717285
training step: 3671, total_loss: 5.524445533752441
training step: 3672, total_loss: 3.873380422592163
training step: 3673, total_loss: 4.33709192276001
training step: 3674, total_loss: 4.528375148773193
training step: 3675, total_loss: 4.412971019744873
training step: 3676, total_loss: 2.510291814804077
training step: 3677, total_loss: 4.680569171905518
training step: 3678, total_loss: 5.263590335845947
training step: 3679, total_loss: 4.6859307289123535
training step: 3680, total_loss: 5.112675666809082
training step: 3681, total_loss: 5.798214912414551
training step: 3682, total_loss: 0.7593252658843994
training step: 3683, total_loss: 4.793784141540527
training step: 3684, total_loss: 5.567291259765625
training step: 3685, total_loss: 5.939411163330078
training step: 3686, total_loss: 6.14801025390625
training step: 3687, total_loss: 5.239828109741211
training step: 3688, total_loss: 4.828969955444336
training step: 3689, total_loss: 4.944470405578613
training step: 3690, total_loss: 6.508916854858398
training step: 3691, total_loss: 5.2815399169921875
training step: 3692, total_loss: 5.20575475692749
training step: 3693, total_loss: 2.3763890266418457
training step: 3694, total_loss: 4.762026786804199
training step: 3695, total_loss: 2.5436220169067383
training step: 3696, total_loss: 7.0042266845703125
training step: 3697, total_loss: 4.469404220581055
training step: 3698, total_loss: 4.544136047363281
training step: 3699, total_loss: 6.35349178314209
training step: 3700, total_loss: 4.708823204040527
training step: 3701, total_loss: 4.666622161865234
training step: 3702, total_loss: 5.307758331298828
training step: 3703, total_loss: 4.426373481750488
training step: 3704, total_loss: 4.710043907165527
training step: 3705, total_loss: 5.002740859985352
training step: 3706, total_loss: 5.463510990142822
training step: 3707, total_loss: 4.851573944091797
training step: 3708, total_loss: 4.334446907043457
training step: 3709, total_loss: 4.739323616027832
training step: 3710, total_loss: 4.285522937774658
training step: 3711, total_loss: 6.0086588859558105
training step: 3712, total_loss: 4.497296333312988
training step: 3713, total_loss: 5.381809234619141
training step: 3714, total_loss: 5.241782188415527
training step: 3715, total_loss: 4.2812418937683105
training step: 3716, total_loss: 4.848383903503418
training step: 3717, total_loss: 4.427417278289795
training step: 3718, total_loss: 4.546956539154053
training step: 3719, total_loss: 5.449707508087158
training step: 3720, total_loss: 4.133083820343018
training step: 3721, total_loss: 4.127684116363525
training step: 3722, total_loss: 5.944215774536133
training step: 3723, total_loss: 4.428256988525391
training step: 3724, total_loss: 4.654276371002197
training step: 3725, total_loss: 4.48846960067749
training step: 3726, total_loss: 3.8422563076019287
training step: 3727, total_loss: 4.242433547973633
training step: 3728, total_loss: 4.172135829925537
training step: 3729, total_loss: 4.188230514526367
training step: 3730, total_loss: 4.611839771270752
training step: 3731, total_loss: 5.045224189758301
training step: 3732, total_loss: 5.826512336730957
training step: 3733, total_loss: 6.024691581726074
training step: 3734, total_loss: 4.148504257202148
training step: 3735, total_loss: 4.188197135925293
training step: 3736, total_loss: 4.120981216430664
training step: 3737, total_loss: 4.387979030609131
training step: 3738, total_loss: 5.128818511962891
training step: 3739, total_loss: 4.549096584320068
training step: 3740, total_loss: 3.1127169132232666
training step: 3741, total_loss: 5.276342868804932
training step: 3742, total_loss: 4.460520267486572
training step: 3743, total_loss: 3.8035473823547363
training step: 3744, total_loss: 6.223186492919922
training step: 3745, total_loss: 4.824193954467773
training step: 3746, total_loss: 5.466501235961914
training step: 3747, total_loss: 5.269211292266846
training step: 3748, total_loss: 4.447418212890625
training step: 3749, total_loss: 3.766627788543701
training step: 3750, total_loss: 2.7625136375427246
training step: 3751, total_loss: 2.5059444904327393
training step: 3752, total_loss: 4.5121049880981445
training step: 3753, total_loss: 5.5444512367248535
training step: 3754, total_loss: 6.372305393218994
training step: 3755, total_loss: 5.125767230987549
training step: 3756, total_loss: 5.050361633300781
training step: 3757, total_loss: 4.936718463897705
training step: 3758, total_loss: 5.213804244995117
training step: 3759, total_loss: 4.609177589416504
training step: 3760, total_loss: 4.635645866394043
training step: 3761, total_loss: 6.835787773132324
training step: 3762, total_loss: 5.052093982696533
training step: 3763, total_loss: 4.161477565765381
training step: 3764, total_loss: 4.341490268707275
training step: 3765, total_loss: 4.161507606506348
training step: 3766, total_loss: 4.761546611785889
training step: 3767, total_loss: 4.775161266326904
training step: 3768, total_loss: 4.86903715133667
training step: 3769, total_loss: 5.592078685760498
training step: 3770, total_loss: 4.3094706535339355
training step: 3771, total_loss: 5.601914405822754
training step: 3772, total_loss: 4.054195404052734
training step: 3773, total_loss: 5.463216304779053
training step: 3774, total_loss: 5.53204870223999
training step: 3775, total_loss: 3.299588680267334
training step: 3776, total_loss: 3.81825852394104
training step: 3777, total_loss: 4.18925666809082
training step: 3778, total_loss: 5.404274940490723
training step: 3779, total_loss: 5.52685546875
training step: 3780, total_loss: 6.194801330566406
training step: 3781, total_loss: 4.503495216369629
training step: 3782, total_loss: 5.883126258850098
training step: 3783, total_loss: 5.252560138702393
training step: 3784, total_loss: 4.869865417480469
training step: 3785, total_loss: 5.956624984741211
training step: 3786, total_loss: 3.4984018802642822
training step: 3787, total_loss: 5.170917510986328
training step: 3788, total_loss: 6.032320022583008
training step: 3789, total_loss: 4.321552276611328
training step: 3790, total_loss: 4.598149299621582
training step: 3791, total_loss: 4.788836479187012
training step: 3792, total_loss: 5.429426670074463
training step: 3793, total_loss: 5.7149200439453125
training step: 3794, total_loss: 4.258373260498047
training step: 3795, total_loss: 4.511971473693848
training step: 3796, total_loss: 4.744802474975586
training step: 3797, total_loss: 5.188377380371094
training step: 3798, total_loss: 5.279047012329102
training step: 3799, total_loss: 5.251557350158691
training step: 3800, total_loss: 4.571281433105469
training step: 3801, total_loss: 3.9644103050231934
training step: 3802, total_loss: 5.003387928009033
training step: 3803, total_loss: 4.443598747253418
training step: 3804, total_loss: 6.070370674133301
training step: 3805, total_loss: 5.947827339172363
training step: 3806, total_loss: 4.542211055755615
training step: 3807, total_loss: 5.472956657409668
training step: 3808, total_loss: 5.000149726867676
training step: 3809, total_loss: 4.708863258361816
training step: 3810, total_loss: 5.47014856338501
training step: 3811, total_loss: 4.344606876373291
training step: 3812, total_loss: 6.206162452697754
training step: 3813, total_loss: 5.862749099731445
training step: 3814, total_loss: 4.941619873046875
training step: 3815, total_loss: 3.519554376602173
training step: 3816, total_loss: 4.938255310058594
training step: 3817, total_loss: 4.00827169418335
training step: 3818, total_loss: 5.366250991821289
training step: 3819, total_loss: 3.9716429710388184
training step: 3820, total_loss: 3.117161750793457
training step: 3821, total_loss: 6.288372993469238
training step: 3822, total_loss: 5.778722763061523
training step: 3823, total_loss: 4.484592437744141
training step: 3824, total_loss: 4.9883832931518555
training step: 3825, total_loss: 3.8638429641723633
training step: 3826, total_loss: 5.451932907104492
training step: 3827, total_loss: 3.399958610534668
training step: 3828, total_loss: 4.006595611572266
training step: 3829, total_loss: 5.318735122680664
training step: 3830, total_loss: 1.1624794006347656
training step: 3831, total_loss: 4.710735321044922
training step: 3832, total_loss: 4.938358783721924
training step: 3833, total_loss: 5.199033737182617
training step: 3834, total_loss: 4.984933853149414
training step: 3835, total_loss: 6.4302825927734375
training step: 3836, total_loss: 5.3122968673706055
training step: 3837, total_loss: 5.520989418029785
training step: 3838, total_loss: 4.134334564208984
training step: 3839, total_loss: 2.8118367195129395
training step: 3840, total_loss: 4.921000957489014
training step: 3841, total_loss: 3.9300718307495117
training step: 3842, total_loss: 5.839485168457031
training step: 3843, total_loss: 5.254488468170166
training step: 3844, total_loss: 5.765710830688477
training step: 3845, total_loss: 5.065996170043945
training step: 3846, total_loss: 4.972528457641602
training step: 3847, total_loss: 1.6137375831604004
training step: 3848, total_loss: 4.930793762207031
training step: 3849, total_loss: 5.393196105957031
training step: 3850, total_loss: 5.1288299560546875
training step: 3851, total_loss: 5.279006481170654
training step: 3852, total_loss: 4.9516401290893555
training step: 3853, total_loss: 4.910734176635742
training step: 3854, total_loss: 4.385648727416992
training step: 3855, total_loss: 3.859983444213867
training step: 3856, total_loss: 5.488725662231445
training step: 3857, total_loss: 4.864688396453857
training step: 3858, total_loss: 4.761448383331299
training step: 3859, total_loss: 4.686628818511963
training step: 3860, total_loss: 3.197478771209717
training step: 3861, total_loss: 4.229732990264893
training step: 3862, total_loss: 4.602069854736328
training step: 3863, total_loss: 4.748722076416016
training step: 3864, total_loss: 5.752882957458496
training step: 3865, total_loss: 5.8742899894714355
training step: 3866, total_loss: 3.698878526687622
training step: 3867, total_loss: 6.964086532592773
training step: 3868, total_loss: 4.061875343322754
training step: 3869, total_loss: 4.191597938537598
training step: 3870, total_loss: 3.3404226303100586
training step: 3871, total_loss: 4.699823379516602
training step: 3872, total_loss: 5.6704559326171875
training step: 3873, total_loss: 4.791645526885986
training step: 3874, total_loss: 5.802321434020996
training step: 3875, total_loss: 3.4679276943206787
training step: 3876, total_loss: 5.189977645874023
training step: 3877, total_loss: 5.185554504394531
training step: 3878, total_loss: 4.51220178604126
training step: 3879, total_loss: 5.220920085906982
training step: 3880, total_loss: 4.847082138061523
training step: 3881, total_loss: 4.732584476470947
training step: 3882, total_loss: 5.444910049438477
training step: 3883, total_loss: 4.910695552825928
training step: 3884, total_loss: 5.833102226257324
training step: 3885, total_loss: 4.796709060668945
training step: 3886, total_loss: 4.589480400085449
training step: 3887, total_loss: 5.636719703674316
training step: 3888, total_loss: 5.080168724060059
training step: 3889, total_loss: 5.23022985458374
training step: 3890, total_loss: 4.165943145751953
training step: 3891, total_loss: 4.095409393310547
training step: 3892, total_loss: 5.247281074523926
training step: 3893, total_loss: 2.433957815170288
training step: 3894, total_loss: 5.037524700164795
training step: 3895, total_loss: 4.697300910949707
training step: 3896, total_loss: 4.244495868682861
training step: 3897, total_loss: 4.344958305358887
training step: 3898, total_loss: 3.9820468425750732
training step: 3899, total_loss: 5.230773448944092
training step: 3900, total_loss: 5.343189239501953
training step: 3901, total_loss: 3.1789989471435547
training step: 3902, total_loss: 4.476113319396973
training step: 3903, total_loss: 4.563581466674805
training step: 3904, total_loss: 3.985193967819214
training step: 3905, total_loss: 4.481738090515137
training step: 3906, total_loss: 7.305910587310791
training step: 3907, total_loss: 4.628136157989502
training step: 3908, total_loss: 4.103973388671875
training step: 3909, total_loss: 5.4274396896362305
training step: 3910, total_loss: 6.707360744476318
training step: 3911, total_loss: 4.296446800231934
training step: 3912, total_loss: 5.603151321411133
training step: 3913, total_loss: 3.345522880554199
training step: 3914, total_loss: 4.738731384277344
training step: 3915, total_loss: 5.043617248535156
training step: 3916, total_loss: 5.450830459594727
training step: 3917, total_loss: 4.392267227172852
training step: 3918, total_loss: 4.180706024169922
training step: 3919, total_loss: 4.885491371154785
training step: 3920, total_loss: 5.690224647521973
training step: 3921, total_loss: 4.448247909545898
training step: 3922, total_loss: 4.8008246421813965
training step: 3923, total_loss: 5.263152599334717
training step: 3924, total_loss: 5.412134647369385
training step: 3925, total_loss: 4.3727803230285645
training step: 3926, total_loss: 4.30171012878418
training step: 3927, total_loss: 5.047869682312012
training step: 3928, total_loss: 4.497742652893066
training step: 3929, total_loss: 5.4511566162109375
training step: 3930, total_loss: 4.294401168823242
training step: 3931, total_loss: 4.763562202453613
training step: 3932, total_loss: 4.5461812019348145
training step: 3933, total_loss: 5.067418098449707
training step: 3934, total_loss: 4.7957000732421875
training step: 3935, total_loss: 4.720206260681152
training step: 3936, total_loss: 4.916328430175781
training step: 3937, total_loss: 4.036094665527344
training step: 3938, total_loss: 5.659883499145508
training step: 3939, total_loss: 5.347800254821777
training step: 3940, total_loss: 4.387653350830078
training step: 3941, total_loss: 3.947061061859131
training step: 3942, total_loss: 5.380904197692871
training step: 3943, total_loss: 5.658024787902832
training step: 3944, total_loss: 4.703321933746338
training step: 3945, total_loss: 5.211700916290283
training step: 3946, total_loss: 4.845729827880859
training step: 3947, total_loss: 5.011159896850586
training step: 3948, total_loss: 6.626808166503906
training step: 3949, total_loss: 4.079532623291016
training step: 3950, total_loss: 5.880785942077637
training step: 3951, total_loss: 4.938529968261719
training step: 3952, total_loss: 4.356513977050781
training step: 3953, total_loss: 4.6480607986450195
training step: 3954, total_loss: 4.101395606994629
training step: 3955, total_loss: 5.000739097595215
training step: 3956, total_loss: 5.1606340408325195
training step: 3957, total_loss: 4.673895359039307
training step: 3958, total_loss: 5.247365951538086
training step: 3959, total_loss: 5.135873794555664
training step: 3960, total_loss: 4.85219669342041
training step: 3961, total_loss: 5.200979232788086
training step: 3962, total_loss: 4.5023698806762695
training step: 3963, total_loss: 4.875499248504639
training step: 3964, total_loss: 4.556203842163086
training step: 3965, total_loss: 5.0258708000183105
training step: 3966, total_loss: 4.2557573318481445
training step: 3967, total_loss: 4.416668891906738
training step: 3968, total_loss: 4.920473575592041
training step: 3969, total_loss: 5.5502777099609375
training step: 3970, total_loss: 5.805424690246582
training step: 3971, total_loss: 5.395659923553467
training step: 3972, total_loss: 4.379508018493652
training step: 3973, total_loss: 4.414949893951416
training step: 3974, total_loss: 6.097793102264404
training step: 3975, total_loss: 4.277884006500244
training step: 3976, total_loss: 4.5271711349487305
training step: 3977, total_loss: 5.137267112731934
training step: 3978, total_loss: 3.995478630065918
training step: 3979, total_loss: 3.6469614505767822
training step: 3980, total_loss: 3.360760450363159
training step: 3981, total_loss: 4.689543724060059
training step: 3982, total_loss: 5.3655877113342285
training step: 3983, total_loss: 5.142193794250488
training step: 3984, total_loss: 5.278129577636719
training step: 3985, total_loss: 4.312089443206787
training step: 3986, total_loss: 5.177617073059082
training step: 3987, total_loss: 5.229640960693359
training step: 3988, total_loss: 5.405119895935059
training step: 3989, total_loss: 3.949864625930786
training step: 3990, total_loss: 5.519748687744141
training step: 3991, total_loss: 4.708603382110596
training step: 3992, total_loss: 4.9519219398498535
training step: 3993, total_loss: 3.870795726776123
training step: 3994, total_loss: 4.78956413269043
training step: 3995, total_loss: 4.517813682556152
training step: 3996, total_loss: 4.717350959777832
training step: 3997, total_loss: 4.652874946594238
training step: 3998, total_loss: 4.622097969055176
training step: 3999, total_loss: 4.9878315925598145
training step: 4000, total_loss: 3.4951395988464355
training step: 4001, total_loss: 6.099820137023926
training step: 4002, total_loss: 5.950987815856934
training step: 4003, total_loss: 4.259481430053711
training step: 4004, total_loss: 5.82429313659668
training step: 4005, total_loss: 4.5529351234436035
training step: 4006, total_loss: 4.034438133239746
training step: 4007, total_loss: 5.428464412689209
training step: 4008, total_loss: 4.394156455993652
training step: 4009, total_loss: 5.71434211730957
training step: 4010, total_loss: 4.598165512084961
training step: 4011, total_loss: 2.7656285762786865
training step: 4012, total_loss: 4.162258148193359
training step: 4013, total_loss: 4.481388092041016
training step: 4014, total_loss: 4.630437850952148
training step: 4015, total_loss: 5.279462814331055
training step: 4016, total_loss: 4.7042694091796875
training step: 4017, total_loss: 4.2163543701171875
training step: 4018, total_loss: 4.6021833419799805
training step: 4019, total_loss: 5.3229780197143555
training step: 4020, total_loss: 6.0390706062316895
training step: 4021, total_loss: 3.7321465015411377
training step: 4022, total_loss: 5.25583028793335
training step: 4023, total_loss: 6.11328649520874
training step: 4024, total_loss: 5.224852561950684
training step: 4025, total_loss: 4.267218589782715
training step: 4026, total_loss: 6.153835773468018
training step: 4027, total_loss: 4.068001747131348
training step: 4028, total_loss: 4.587662696838379
training step: 4029, total_loss: 5.00289249420166
training step: 4030, total_loss: 5.148980140686035
training step: 4031, total_loss: 7.020055770874023
training step: 4032, total_loss: 3.7897229194641113
training step: 4033, total_loss: 4.064794540405273
training step: 4034, total_loss: 4.876400947570801
training step: 4035, total_loss: 4.667477607727051
training step: 4036, total_loss: 5.695103645324707
training step: 4037, total_loss: 5.070291519165039
training step: 4038, total_loss: 4.292292594909668
training step: 4039, total_loss: 4.9387664794921875
training step: 4040, total_loss: 5.87890100479126
training step: 4041, total_loss: 5.9192962646484375
training step: 4042, total_loss: 4.582079887390137
training step: 4043, total_loss: 4.569882392883301
training step: 4044, total_loss: 5.364897727966309
training step: 4045, total_loss: 4.509566783905029
training step: 4046, total_loss: 4.831740379333496
training step: 4047, total_loss: 4.131943702697754
training step: 4048, total_loss: 4.337879657745361
training step: 4049, total_loss: 3.294095039367676
training step: 4050, total_loss: 5.131433486938477
training step: 4051, total_loss: 5.331512451171875
training step: 4052, total_loss: 6.474685192108154
training step: 4053, total_loss: 6.3812971115112305
training step: 4054, total_loss: 4.073685646057129
training step: 4055, total_loss: 4.961596965789795
training step: 4056, total_loss: 5.822988510131836
training step: 4057, total_loss: 4.860664367675781
training step: 4058, total_loss: 5.506653785705566
training step: 4059, total_loss: 5.166393280029297
training step: 4060, total_loss: 5.911705017089844
training step: 4061, total_loss: 4.50051736831665
training step: 4062, total_loss: 4.756955623626709
training step: 4063, total_loss: 4.8691511154174805
training step: 4064, total_loss: 5.005461692810059
training step: 4065, total_loss: 4.527818202972412
training step: 4066, total_loss: 4.435410022735596
training step: 4067, total_loss: 5.0110063552856445
training step: 4068, total_loss: 5.143174171447754
training step: 4069, total_loss: 6.116864204406738
training step: 4070, total_loss: 4.8769450187683105
training step: 4071, total_loss: 4.548590660095215
training step: 4072, total_loss: 4.44240140914917
training step: 4073, total_loss: 4.136201858520508
training step: 4074, total_loss: 4.557896137237549
training step: 4075, total_loss: 3.910036087036133
training step: 4076, total_loss: 4.8760809898376465
training step: 4077, total_loss: 5.131251335144043
training step: 4078, total_loss: 3.167266845703125
training step: 4079, total_loss: 5.295151233673096
training step: 4080, total_loss: 4.7607035636901855
training step: 4081, total_loss: 4.900875568389893
training step: 4082, total_loss: 5.120723724365234
training step: 4083, total_loss: 3.694819927215576
training step: 4084, total_loss: 5.568554401397705
training step: 4085, total_loss: 5.427022933959961
training step: 4086, total_loss: 1.407204508781433
training step: 4087, total_loss: 5.995058059692383
training step: 4088, total_loss: 5.465372085571289
training step: 4089, total_loss: 4.71970796585083
training step: 4090, total_loss: 4.636430740356445
training step: 4091, total_loss: 5.468784332275391
training step: 4092, total_loss: 3.886829137802124
training step: 4093, total_loss: 5.789337158203125
training step: 4094, total_loss: 5.674654006958008
training step: 4095, total_loss: 4.582954406738281
training step: 4096, total_loss: 4.295657157897949
training step: 4097, total_loss: 4.907707691192627
training step: 4098, total_loss: 5.140154838562012
training step: 4099, total_loss: 5.29517936706543
training step: 4100, total_loss: 5.0301737785339355
training step: 4101, total_loss: 3.186382293701172
training step: 4102, total_loss: 4.227162837982178
training step: 4103, total_loss: 4.766644477844238
training step: 4104, total_loss: 5.186100006103516
training step: 4105, total_loss: 5.7742414474487305
training step: 4106, total_loss: 5.47019100189209
training step: 4107, total_loss: 4.8790082931518555
training step: 4108, total_loss: 4.970639228820801
training step: 4109, total_loss: 3.238220691680908
training step: 4110, total_loss: 5.695067405700684
training step: 4111, total_loss: 4.917159080505371
training step: 4112, total_loss: 5.947900772094727
training step: 4113, total_loss: 4.31791877746582
training step: 4114, total_loss: 4.314881324768066
training step: 4115, total_loss: 4.603978157043457
training step: 4116, total_loss: 4.932121276855469
training step: 4117, total_loss: 4.220617294311523
training step: 4118, total_loss: 5.48496150970459
training step: 4119, total_loss: 4.600179195404053
training step: 4120, total_loss: 4.87222146987915
training step: 4121, total_loss: 5.014159202575684
training step: 4122, total_loss: 4.644186019897461
training step: 4123, total_loss: 3.9118967056274414
training step: 4124, total_loss: 4.678804397583008
training step: 4125, total_loss: 6.708154201507568
training step: 4126, total_loss: 4.2742600440979
training step: 4127, total_loss: 4.481121063232422
training step: 4128, total_loss: 4.709764003753662
training step: 4129, total_loss: 5.7850341796875
training step: 4130, total_loss: 5.773161888122559
training step: 4131, total_loss: 4.990795135498047
training step: 4132, total_loss: 4.510139465332031
training step: 4133, total_loss: 5.928150177001953
training step: 4134, total_loss: 4.382044315338135
training step: 4135, total_loss: 4.397633075714111
training step: 4136, total_loss: 5.064049243927002
training step: 4137, total_loss: 4.5185089111328125
training step: 4138, total_loss: 4.0665082931518555
training step: 4139, total_loss: 4.111447334289551
training step: 4140, total_loss: 4.958313941955566
training step: 4141, total_loss: 4.188610076904297
training step: 4142, total_loss: 3.91912841796875
training step: 4143, total_loss: 7.51878023147583
training step: 4144, total_loss: 4.014057159423828
training step: 4145, total_loss: 5.749216556549072
training step: 4146, total_loss: 5.11964225769043
training step: 4147, total_loss: 3.940293312072754
training step: 4148, total_loss: 4.190382957458496
training step: 4149, total_loss: 3.789616107940674
training step: 4150, total_loss: 5.2824554443359375
training step: 4151, total_loss: 4.799556255340576
training step: 4152, total_loss: 3.5275745391845703
training step: 4153, total_loss: 5.780740737915039
training step: 4154, total_loss: 5.020399570465088
training step: 4155, total_loss: 3.997359275817871
training step: 4156, total_loss: 3.325742244720459
training step: 4157, total_loss: 4.245464324951172
training step: 4158, total_loss: 3.9397072792053223
training step: 4159, total_loss: 4.531852722167969
training step: 4160, total_loss: 6.116562843322754
training step: 4161, total_loss: 4.3474836349487305
training step: 4162, total_loss: 4.171120643615723
training step: 4163, total_loss: 4.649384498596191
training step: 4164, total_loss: 4.779175281524658
training step: 4165, total_loss: 4.322193145751953
training step: 4166, total_loss: 2.7436351776123047
training step: 4167, total_loss: 5.542238235473633
training step: 4168, total_loss: 3.9561777114868164
training step: 4169, total_loss: 5.152470111846924
training step: 4170, total_loss: 5.622929573059082
training step: 4171, total_loss: 4.368856430053711
training step: 4172, total_loss: 5.4252238273620605
training step: 4173, total_loss: 5.215570449829102
training step: 4174, total_loss: 4.874133110046387
training step: 4175, total_loss: 3.4670495986938477
training step: 4176, total_loss: 4.059200286865234
training step: 4177, total_loss: 4.7209367752075195
training step: 4178, total_loss: 4.565708637237549
training step: 4179, total_loss: 6.359356880187988
training step: 4180, total_loss: 3.703688859939575
training step: 4181, total_loss: 4.606522560119629
training step: 4182, total_loss: 4.680015563964844
training step: 4183, total_loss: 4.288319110870361
training step: 4184, total_loss: 3.5073494911193848
training step: 4185, total_loss: 5.122493743896484
training step: 4186, total_loss: 5.769021034240723
training step: 4187, total_loss: 6.292798042297363
training step: 4188, total_loss: 5.907147407531738
training step: 4189, total_loss: 4.925670146942139
training step: 4190, total_loss: 5.009592533111572
training step: 4191, total_loss: 2.0377888679504395
training step: 4192, total_loss: 5.617122173309326
training step: 4193, total_loss: 4.990772247314453
training step: 4194, total_loss: 4.410423278808594
training step: 4195, total_loss: 4.727988243103027
training step: 4196, total_loss: 4.173763275146484
training step: 4197, total_loss: 4.78430700302124
training step: 4198, total_loss: 4.1652326583862305
training step: 4199, total_loss: 4.892492294311523
training step: 4200, total_loss: 3.6360301971435547
training step: 4201, total_loss: 4.936490058898926
training step: 4202, total_loss: 2.888646364212036
training step: 4203, total_loss: 4.460880279541016
training step: 4204, total_loss: 5.876779556274414
training step: 4205, total_loss: 4.872145652770996
training step: 4206, total_loss: 3.127211093902588
training step: 4207, total_loss: 4.475478172302246
training step: 4208, total_loss: 5.22783899307251
training step: 4209, total_loss: 6.428138732910156
training step: 4210, total_loss: 6.239273548126221
training step: 4211, total_loss: 4.558516025543213
training step: 4212, total_loss: 7.44927978515625
training step: 4213, total_loss: 4.3218512535095215
training step: 4214, total_loss: 4.680436611175537
training step: 4215, total_loss: 3.821539878845215
training step: 4216, total_loss: 5.943683624267578
training step: 4217, total_loss: 3.168109893798828
training step: 4218, total_loss: 4.316573143005371
training step: 4219, total_loss: 5.428510665893555
training step: 4220, total_loss: 6.058515548706055
training step: 4221, total_loss: 4.294770240783691
training step: 4222, total_loss: 5.703823566436768
training step: 4223, total_loss: 5.723886013031006
training step: 4224, total_loss: 4.688510417938232
training step: 4225, total_loss: 5.12977409362793
training step: 4226, total_loss: 4.254817008972168
training step: 4227, total_loss: 4.498935699462891
training step: 4228, total_loss: 3.6098146438598633
training step: 4229, total_loss: 4.977530002593994
training step: 4230, total_loss: 4.197658538818359
training step: 4231, total_loss: 4.922370910644531
training step: 4232, total_loss: 4.80452299118042
training step: 4233, total_loss: 4.918992042541504
training step: 4234, total_loss: 4.542932510375977
training step: 4235, total_loss: 4.981314182281494
training step: 4236, total_loss: 5.527860641479492
training step: 4237, total_loss: 4.086930274963379
training step: 4238, total_loss: 5.132850646972656
training step: 4239, total_loss: 3.95169997215271
training step: 4240, total_loss: 4.905612945556641
training step: 4241, total_loss: 4.8781938552856445
training step: 4242, total_loss: 4.942351341247559
training step: 4243, total_loss: 3.6219444274902344
training step: 4244, total_loss: 4.094770431518555
training step: 4245, total_loss: 4.093604564666748
training step: 4246, total_loss: 4.447502613067627
training step: 4247, total_loss: 4.862246990203857
training step: 4248, total_loss: 5.122272968292236
training step: 4249, total_loss: 4.2925825119018555
training step: 4250, total_loss: 3.951692581176758
training step: 4251, total_loss: 2.390538215637207
training step: 4252, total_loss: 3.9748687744140625
training step: 4253, total_loss: 4.410158157348633
training step: 4254, total_loss: 4.562154293060303
training step: 4255, total_loss: 3.2833330631256104
training step: 4256, total_loss: 4.764102935791016
training step: 4257, total_loss: 4.958898544311523
training step: 4258, total_loss: 4.567503929138184
training step: 4259, total_loss: 4.239458084106445
training step: 4260, total_loss: 4.9887824058532715
training step: 4261, total_loss: 5.3512773513793945
training step: 4262, total_loss: 5.676210880279541
training step: 4263, total_loss: 5.1689605712890625
training step: 4264, total_loss: 3.6778564453125
training step: 4265, total_loss: 1.8562248945236206
training step: 4266, total_loss: 5.466239929199219
training step: 4267, total_loss: 4.701074123382568
training step: 4268, total_loss: 4.938901901245117
training step: 4269, total_loss: 5.633293151855469
training step: 4270, total_loss: 2.6695141792297363
training step: 4271, total_loss: 5.514627456665039
training step: 4272, total_loss: 2.7920708656311035
training step: 4273, total_loss: 5.363317489624023
training step: 4274, total_loss: 4.698785781860352
training step: 4275, total_loss: 7.030805587768555
training step: 4276, total_loss: 3.025509834289551
training step: 4277, total_loss: 6.1811676025390625
training step: 4278, total_loss: 4.447105407714844
training step: 4279, total_loss: 3.351041793823242
training step: 4280, total_loss: 3.498995304107666
training step: 4281, total_loss: 4.954030990600586
training step: 4282, total_loss: 5.303446292877197
training step: 4283, total_loss: 5.395701885223389
training step: 4284, total_loss: 7.078470230102539
training step: 4285, total_loss: 4.837872505187988
training step: 4286, total_loss: 4.4198222160339355
training step: 4287, total_loss: 5.601532936096191
training step: 4288, total_loss: 4.903343200683594
training step: 4289, total_loss: 4.331625461578369
training step: 4290, total_loss: 4.776416778564453
training step: 4291, total_loss: 5.418365478515625
training step: 4292, total_loss: 6.077215194702148
training step: 4293, total_loss: 4.013815879821777
training step: 4294, total_loss: 5.061496734619141
training step: 4295, total_loss: 5.685088157653809
training step: 4296, total_loss: 5.511445999145508
training step: 4297, total_loss: 4.757676124572754
training step: 4298, total_loss: 4.511674404144287
training step: 4299, total_loss: 4.415539741516113
training step: 4300, total_loss: 4.8358683586120605
training step: 4301, total_loss: 5.0862932205200195
training step: 4302, total_loss: 4.430008411407471
training step: 4303, total_loss: 4.268620491027832
training step: 4304, total_loss: 6.102288246154785
training step: 4305, total_loss: 5.435483932495117
training step: 4306, total_loss: 5.332177639007568
training step: 4307, total_loss: 5.235522270202637
training step: 4308, total_loss: 6.544419288635254
training step: 4309, total_loss: 4.040671348571777
training step: 4310, total_loss: 5.975150108337402
training step: 4311, total_loss: 5.730024814605713
training step: 4312, total_loss: 4.936130046844482
training step: 4313, total_loss: 5.04084587097168
training step: 4314, total_loss: 5.642266273498535
training step: 4315, total_loss: 4.6718549728393555
training step: 4316, total_loss: 4.820466995239258
training step: 4317, total_loss: 5.154605388641357
training step: 4318, total_loss: 4.655769348144531
training step: 4319, total_loss: 5.337847709655762
training step: 4320, total_loss: 5.830453872680664
training step: 4321, total_loss: 5.143959045410156
training step: 4322, total_loss: 5.847126483917236
training step: 4323, total_loss: 4.961849212646484
training step: 4324, total_loss: 4.288593292236328
training step: 4325, total_loss: 2.382734537124634
training step: 4326, total_loss: 4.178763389587402
training step: 4327, total_loss: 4.181809425354004
training step: 4328, total_loss: 5.169508457183838
training step: 4329, total_loss: 4.328798294067383
training step: 4330, total_loss: 5.373832702636719
training step: 4331, total_loss: 4.198422431945801
training step: 4332, total_loss: 4.2498579025268555
training step: 4333, total_loss: 4.147180557250977
training step: 4334, total_loss: 6.654426574707031
training step: 4335, total_loss: 3.6575329303741455
training step: 4336, total_loss: 4.431511878967285
training step: 4337, total_loss: 3.5834603309631348
training step: 4338, total_loss: 5.932161808013916
training step: 4339, total_loss: 4.929325103759766
training step: 4340, total_loss: 3.742218494415283
training step: 4341, total_loss: 5.0085344314575195
training step: 4342, total_loss: 4.358946323394775
training step: 4343, total_loss: 5.094854354858398
training step: 4344, total_loss: 4.462614059448242
training step: 4345, total_loss: 6.1373772621154785
training step: 4346, total_loss: 4.704406261444092
training step: 4347, total_loss: 4.523580551147461
training step: 4348, total_loss: 5.435366630554199
training step: 4349, total_loss: 3.673576593399048
training step: 4350, total_loss: 4.464727878570557
training step: 4351, total_loss: 7.1284637451171875
training step: 4352, total_loss: 4.318315505981445
training step: 4353, total_loss: 4.313816547393799
training step: 4354, total_loss: 5.512518882751465
training step: 4355, total_loss: 4.385275840759277
training step: 4356, total_loss: 4.575338363647461
training step: 4357, total_loss: 3.738560914993286
training step: 4358, total_loss: 4.053299427032471
training step: 4359, total_loss: 3.532858371734619
training step: 4360, total_loss: 4.277420520782471
training step: 4361, total_loss: 5.700361251831055
training step: 4362, total_loss: 5.107735633850098
training step: 4363, total_loss: 3.977476119995117
training step: 4364, total_loss: 4.053652286529541
training step: 4365, total_loss: 4.227081775665283
training step: 4366, total_loss: 5.720623970031738
training step: 4367, total_loss: 5.001165390014648
training step: 4368, total_loss: 3.8602824211120605
training step: 4369, total_loss: 5.056309700012207
training step: 4370, total_loss: 5.175718784332275
training step: 4371, total_loss: 4.78788948059082
training step: 4372, total_loss: 4.318758487701416
training step: 4373, total_loss: 4.861411094665527
training step: 4374, total_loss: 5.202439308166504
training step: 4375, total_loss: 4.8844475746154785
training step: 4376, total_loss: 4.990106582641602
training step: 4377, total_loss: 4.9369707107543945
training step: 4378, total_loss: 4.410610198974609
training step: 4379, total_loss: 5.781918048858643
training step: 4380, total_loss: 3.8238189220428467
training step: 4381, total_loss: 4.413995742797852
training step: 4382, total_loss: 4.896088600158691
training step: 4383, total_loss: 4.252216815948486
training step: 4384, total_loss: 4.280693531036377
training step: 4385, total_loss: 3.90108323097229
training step: 4386, total_loss: 6.183138370513916
training step: 4387, total_loss: 4.877593040466309
training step: 4388, total_loss: 4.416203498840332
training step: 4389, total_loss: 4.709546089172363
training step: 4390, total_loss: 6.103021621704102
training step: 4391, total_loss: 4.350412368774414
training step: 4392, total_loss: 4.193149089813232
training step: 4393, total_loss: 4.6478776931762695
training step: 4394, total_loss: 4.063493251800537
training step: 4395, total_loss: 8.431032180786133
training step: 4396, total_loss: 5.375340461730957
training step: 4397, total_loss: 4.145236492156982
training step: 4398, total_loss: 5.028697967529297
training step: 4399, total_loss: 6.013364791870117
training step: 4400, total_loss: 5.645763397216797
training step: 4401, total_loss: 5.8712968826293945
training step: 4402, total_loss: 4.927525997161865
training step: 4403, total_loss: 4.750837326049805
training step: 4404, total_loss: 5.448742866516113
training step: 4405, total_loss: 5.073148727416992
training step: 4406, total_loss: 5.519783020019531
training step: 4407, total_loss: 4.4939422607421875
training step: 4408, total_loss: 4.121363639831543
training step: 4409, total_loss: 4.61405611038208
training step: 4410, total_loss: 4.618263244628906
training step: 4411, total_loss: 4.266433238983154
training step: 4412, total_loss: 5.598821640014648
training step: 4413, total_loss: 5.312005996704102
training step: 4414, total_loss: 3.7823879718780518
training step: 4415, total_loss: 4.738777160644531
training step: 4416, total_loss: 4.59827184677124
training step: 4417, total_loss: 3.85178804397583
training step: 4418, total_loss: 5.470145225524902
training step: 4419, total_loss: 5.734594821929932
training step: 4420, total_loss: 4.802545070648193
training step: 4421, total_loss: 3.9120776653289795
training step: 4422, total_loss: 4.076654434204102
training step: 4423, total_loss: 5.09603214263916
training step: 4424, total_loss: 5.325582504272461
training step: 4425, total_loss: 6.4022064208984375
training step: 4426, total_loss: 3.758927345275879
training step: 4427, total_loss: 5.162698745727539
training step: 4428, total_loss: 4.203080177307129
training step: 4429, total_loss: 5.644784927368164
training step: 4430, total_loss: 4.038429260253906
training step: 4431, total_loss: 4.9452619552612305
training step: 4432, total_loss: 4.720920085906982
training step: 4433, total_loss: 5.839580535888672
training step: 4434, total_loss: 6.9963483810424805
training step: 4435, total_loss: 5.0999579429626465
training step: 4436, total_loss: 3.375382423400879
training step: 4437, total_loss: 4.849431991577148
training step: 4438, total_loss: 5.750673770904541
training step: 4439, total_loss: 4.576074600219727
training step: 4440, total_loss: 5.276066780090332
training step: 4441, total_loss: 5.773564338684082
training step: 4442, total_loss: 5.332114219665527
training step: 4443, total_loss: 4.913763999938965
training step: 4444, total_loss: 4.879742622375488
training step: 4445, total_loss: 5.628602027893066
training step: 4446, total_loss: 3.091474771499634
training step: 4447, total_loss: 5.376073837280273
training step: 4448, total_loss: 4.670767784118652
training step: 4449, total_loss: 4.863227844238281
training step: 4450, total_loss: 4.940958023071289
training step: 4451, total_loss: 5.597223281860352
training step: 4452, total_loss: 6.363244533538818
training step: 4453, total_loss: 5.195094585418701
training step: 4454, total_loss: 4.7689619064331055
training step: 4455, total_loss: 4.579012870788574
training step: 4456, total_loss: 5.370077610015869
training step: 4457, total_loss: 5.2335429191589355
training step: 4458, total_loss: 3.8054704666137695
training step: 4459, total_loss: 5.575484275817871
training step: 4460, total_loss: 5.149953365325928
training step: 4461, total_loss: 4.216850280761719
training step: 4462, total_loss: 5.372247695922852
training step: 4463, total_loss: 4.789658546447754
training step: 4464, total_loss: 4.619720935821533
training step: 4465, total_loss: 5.30000114440918
training step: 4466, total_loss: 6.758121013641357
training step: 4467, total_loss: 4.969449043273926
training step: 4468, total_loss: 5.664333343505859
training step: 4469, total_loss: 5.37442684173584
training step: 4470, total_loss: 4.875723361968994
training step: 4471, total_loss: 4.454530239105225
training step: 4472, total_loss: 4.641777992248535
training step: 4473, total_loss: 4.168832302093506
training step: 4474, total_loss: 5.381563186645508
training step: 4475, total_loss: 4.980831146240234
training step: 4476, total_loss: 5.611290454864502
training step: 4477, total_loss: 4.084163665771484
training step: 4478, total_loss: 2.9727373123168945
training step: 4479, total_loss: 5.08707857131958
training step: 4480, total_loss: 4.751591205596924
training step: 4481, total_loss: 6.562461853027344
training step: 4482, total_loss: 4.625445365905762
training step: 4483, total_loss: 4.05855655670166
training step: 4484, total_loss: 5.536441802978516
training step: 4485, total_loss: 6.54282283782959
training step: 4486, total_loss: 6.128855228424072
training step: 4487, total_loss: 4.6198859214782715
training step: 4488, total_loss: 4.554763317108154
training step: 4489, total_loss: 5.134580135345459
training step: 4490, total_loss: 3.062832832336426
training step: 4491, total_loss: 4.841599464416504
training step: 4492, total_loss: 6.449522972106934
training step: 4493, total_loss: 5.654221057891846
training step: 4494, total_loss: 4.958171367645264
training step: 4495, total_loss: 5.650344371795654
training step: 4496, total_loss: 5.348577976226807
training step: 4497, total_loss: 4.783514022827148
training step: 4498, total_loss: 5.209983825683594
training step: 4499, total_loss: 6.094484329223633
training step: 4500, total_loss: 4.580906867980957
training step: 4501, total_loss: 4.302803993225098
training step: 4502, total_loss: 3.0712356567382812
training step: 4503, total_loss: 6.385015487670898
training step: 4504, total_loss: 5.7148261070251465
training step: 4505, total_loss: 5.13290548324585
training step: 4506, total_loss: 4.617055892944336
training step: 4507, total_loss: 4.798371315002441
training step: 4508, total_loss: 5.173266410827637
training step: 4509, total_loss: 4.350443363189697
training step: 4510, total_loss: 5.041541576385498
training step: 4511, total_loss: 4.5929155349731445
training step: 4512, total_loss: 6.4231181144714355
training step: 4513, total_loss: 4.963084697723389
training step: 4514, total_loss: 5.249667644500732
training step: 4515, total_loss: 1.6144111156463623
training step: 4516, total_loss: 4.941374778747559
training step: 4517, total_loss: 5.401788711547852
training step: 4518, total_loss: 5.451834678649902
training step: 4519, total_loss: 4.772975921630859
training step: 4520, total_loss: 4.8998613357543945
training step: 4521, total_loss: 1.2763757705688477
training step: 4522, total_loss: 6.528063774108887
training step: 4523, total_loss: 4.338560104370117
training step: 4524, total_loss: 1.6441121101379395
training step: 4525, total_loss: 4.840679168701172
training step: 4526, total_loss: 4.891985893249512
training step: 4527, total_loss: 4.554874420166016
training step: 4528, total_loss: 4.414102554321289
training step: 4529, total_loss: 5.162441730499268
training step: 4530, total_loss: 4.902618885040283
training step: 4531, total_loss: 4.744091033935547
training step: 4532, total_loss: 5.603575706481934
training step: 4533, total_loss: 4.819530487060547
training step: 4534, total_loss: 4.658340930938721
training step: 4535, total_loss: 6.018950462341309
training step: 4536, total_loss: 5.655941963195801
training step: 4537, total_loss: 3.134685516357422
training step: 4538, total_loss: 4.537138938903809
training step: 4539, total_loss: 4.0735063552856445
training step: 4540, total_loss: 6.59854793548584
training step: 4541, total_loss: 4.756124496459961
training step: 4542, total_loss: 4.414395332336426
training step: 4543, total_loss: 4.80764102935791
training step: 4544, total_loss: 3.891550064086914
training step: 4545, total_loss: 5.782159328460693
training step: 4546, total_loss: 4.002059459686279
training step: 4547, total_loss: 3.989926338195801
training step: 4548, total_loss: 4.8640899658203125
training step: 4549, total_loss: 4.906619071960449
training step: 4550, total_loss: 5.111235618591309
training step: 4551, total_loss: 3.646883487701416
training step: 4552, total_loss: 4.657426357269287
training step: 4553, total_loss: 3.5185904502868652
training step: 4554, total_loss: 5.7479472160339355
training step: 4555, total_loss: 4.338173866271973
training step: 4556, total_loss: 5.270423889160156
training step: 4557, total_loss: 5.5243120193481445
training step: 4558, total_loss: 4.841488361358643
training step: 4559, total_loss: 5.963491439819336
training step: 4560, total_loss: 4.303364276885986
training step: 4561, total_loss: 5.617047309875488
training step: 4562, total_loss: 4.975562572479248
training step: 4563, total_loss: 4.6816205978393555
training step: 4564, total_loss: 4.470870494842529
training step: 4565, total_loss: 6.1923322677612305
training step: 4566, total_loss: 4.921204566955566
training step: 4567, total_loss: 2.3726515769958496
training step: 4568, total_loss: 3.963977336883545
training step: 4569, total_loss: 4.805521011352539
training step: 4570, total_loss: 5.768797874450684
training step: 4571, total_loss: 4.562565803527832
training step: 4572, total_loss: 4.604696273803711
training step: 4573, total_loss: 6.495231628417969
training step: 4574, total_loss: 4.607555389404297
training step: 4575, total_loss: 4.693840503692627
training step: 4576, total_loss: 4.357478141784668
training step: 4577, total_loss: 4.16141939163208
training step: 4578, total_loss: 4.3977813720703125
training step: 4579, total_loss: 3.9439308643341064
training step: 4580, total_loss: 4.122694492340088
training step: 4581, total_loss: 5.71669864654541
training step: 4582, total_loss: 5.042661190032959
training step: 4583, total_loss: 4.608942031860352
training step: 4584, total_loss: 5.273883819580078
training step: 4585, total_loss: 4.443822860717773
training step: 4586, total_loss: 4.821274757385254
training step: 4587, total_loss: 4.210814476013184
training step: 4588, total_loss: 3.4901490211486816
training step: 4589, total_loss: 4.81488037109375
training step: 4590, total_loss: 3.5000481605529785
training step: 4591, total_loss: 3.2836666107177734
training step: 4592, total_loss: 4.576944828033447
training step: 4593, total_loss: 3.3842458724975586
training step: 4594, total_loss: 5.195703506469727
training step: 4595, total_loss: 3.6186342239379883
training step: 4596, total_loss: 5.296412467956543
training step: 4597, total_loss: 4.398734092712402
training step: 4598, total_loss: 4.066101551055908
training step: 4599, total_loss: 4.339868545532227
training step: 4600, total_loss: 6.351168155670166
training step: 4601, total_loss: 5.439737319946289
training step: 4602, total_loss: 4.895421504974365
training step: 4603, total_loss: 4.785346031188965
training step: 4604, total_loss: 5.408304214477539
training step: 4605, total_loss: 4.763564109802246
training step: 4606, total_loss: 4.793211460113525
training step: 4607, total_loss: 5.332084655761719
training step: 4608, total_loss: 3.557807683944702
training step: 4609, total_loss: 4.360489845275879
training step: 4610, total_loss: 4.722781181335449
training step: 4611, total_loss: 3.8784940242767334
training step: 4612, total_loss: 4.655627250671387
training step: 4613, total_loss: 4.2476043701171875
training step: 4614, total_loss: 4.827776908874512
training step: 4615, total_loss: 5.515430927276611
training step: 4616, total_loss: 4.654784202575684
training step: 4617, total_loss: 3.8520545959472656
training step: 4618, total_loss: 5.104384422302246
training step: 4619, total_loss: 4.428985118865967
training step: 4620, total_loss: 4.4770355224609375
training step: 4621, total_loss: 4.405859470367432
training step: 4622, total_loss: 6.038373947143555
training step: 4623, total_loss: 4.504059791564941
training step: 4624, total_loss: 5.704067230224609
training step: 4625, total_loss: 4.621703147888184
training step: 4626, total_loss: 5.5041961669921875
training step: 4627, total_loss: 4.393757343292236
training step: 4628, total_loss: 4.435645580291748
training step: 4629, total_loss: 4.44712495803833
training step: 4630, total_loss: 1.6547341346740723
training step: 4631, total_loss: 4.158192157745361
training step: 4632, total_loss: 4.710240364074707
training step: 4633, total_loss: 4.056861400604248
training step: 4634, total_loss: 5.097538948059082
training step: 4635, total_loss: 5.2518510818481445
training step: 4636, total_loss: 4.173827648162842
training step: 4637, total_loss: 4.208071708679199
training step: 4638, total_loss: 4.643368244171143
training step: 4639, total_loss: 4.482302665710449
training step: 4640, total_loss: 5.428484916687012
training step: 4641, total_loss: 5.771068096160889
training step: 4642, total_loss: 6.90984582901001
training step: 4643, total_loss: 4.067632675170898
training step: 4644, total_loss: 4.694574356079102
training step: 4645, total_loss: 5.591492652893066
training step: 4646, total_loss: 3.902679681777954
training step: 4647, total_loss: 4.772952556610107
training step: 4648, total_loss: 4.040072441101074
training step: 4649, total_loss: 5.429692268371582
training step: 4650, total_loss: 6.852789878845215
training step: 4651, total_loss: 3.6151695251464844
training step: 4652, total_loss: 5.254992485046387
training step: 4653, total_loss: 5.038455486297607
training step: 4654, total_loss: 4.806694030761719
training step: 4655, total_loss: 5.192958354949951
training step: 4656, total_loss: 4.7480950355529785
training step: 4657, total_loss: 5.623882293701172
training step: 4658, total_loss: 4.42912483215332
training step: 4659, total_loss: 5.866358280181885
training step: 4660, total_loss: 6.16165828704834
training step: 4661, total_loss: 3.606077194213867
training step: 4662, total_loss: 6.059621810913086
training step: 4663, total_loss: 4.30327033996582
training step: 4664, total_loss: 4.414974689483643
training step: 4665, total_loss: 4.908844947814941
training step: 4666, total_loss: 5.924942970275879
training step: 4667, total_loss: 2.3501439094543457
training step: 4668, total_loss: 4.755550384521484
training step: 4669, total_loss: 6.351676940917969
training step: 4670, total_loss: 5.328702926635742
training step: 4671, total_loss: 4.390939712524414
training step: 4672, total_loss: 6.10784387588501
training step: 4673, total_loss: 4.3276543617248535
training step: 4674, total_loss: 3.5295205116271973
training step: 4675, total_loss: 4.436789512634277
training step: 4676, total_loss: 5.641510009765625
training step: 4677, total_loss: 5.120852470397949
training step: 4678, total_loss: 4.8810224533081055
training step: 4679, total_loss: 5.201087951660156
training step: 4680, total_loss: 5.066927909851074
training step: 4681, total_loss: 4.426090717315674
training step: 4682, total_loss: 3.874892473220825
training step: 4683, total_loss: 4.518584728240967
training step: 4684, total_loss: 5.74969482421875
training step: 4685, total_loss: 4.735393047332764
training step: 4686, total_loss: 4.724269866943359
training step: 4687, total_loss: 5.02166748046875
training step: 4688, total_loss: 4.397730827331543
training step: 4689, total_loss: 5.357309341430664
training step: 4690, total_loss: 6.146386623382568
training step: 4691, total_loss: 4.383995056152344
training step: 4692, total_loss: 4.6575212478637695
training step: 4693, total_loss: 5.3009257316589355
training step: 4694, total_loss: 4.829447269439697
training step: 4695, total_loss: 4.696537494659424
training step: 4696, total_loss: 4.947813510894775
training step: 4697, total_loss: 4.203617572784424
training step: 4698, total_loss: 5.359171390533447
training step: 4699, total_loss: 5.221895217895508
training step: 4700, total_loss: 3.761669158935547
training step: 4701, total_loss: 4.682165145874023
training step: 4702, total_loss: 5.931174278259277
training step: 4703, total_loss: 3.6131482124328613
training step: 4704, total_loss: 4.258010387420654
training step: 4705, total_loss: 3.6087822914123535
training step: 4706, total_loss: 6.612508773803711
training step: 4707, total_loss: 6.08384895324707
training step: 4708, total_loss: 6.0505218505859375
training step: 4709, total_loss: 5.3282151222229
training step: 4710, total_loss: 4.647774696350098
training step: 4711, total_loss: 3.3528642654418945
training step: 4712, total_loss: 5.433472156524658
training step: 4713, total_loss: 4.198117733001709
training step: 4714, total_loss: 4.616817474365234
training step: 4715, total_loss: 5.106776237487793
training step: 4716, total_loss: 5.015077590942383
training step: 4717, total_loss: 4.28737735748291
training step: 4718, total_loss: 6.1215314865112305
training step: 4719, total_loss: 4.664565086364746
training step: 4720, total_loss: 4.392107009887695
training step: 4721, total_loss: 4.912456512451172
training step: 4722, total_loss: 6.261081695556641
training step: 4723, total_loss: 4.336601734161377
training step: 4724, total_loss: 4.709769248962402
training step: 4725, total_loss: 5.353967666625977
training step: 4726, total_loss: 4.4839582443237305
training step: 4727, total_loss: 5.760695457458496
training step: 4728, total_loss: 4.379388809204102
training step: 4729, total_loss: 4.039466381072998
training step: 4730, total_loss: 5.927651405334473
training step: 4731, total_loss: 4.603809356689453
training step: 4732, total_loss: 3.9673287868499756
training step: 4733, total_loss: 3.7687175273895264
training step: 4734, total_loss: 4.307270050048828
training step: 4735, total_loss: 4.814424514770508
training step: 4736, total_loss: 4.210339069366455
training step: 4737, total_loss: 4.381384372711182
training step: 4738, total_loss: 5.341876983642578
training step: 4739, total_loss: 4.91875696182251
training step: 4740, total_loss: 5.33961296081543
training step: 4741, total_loss: 4.442844867706299
training step: 4742, total_loss: 5.225743770599365
training step: 4743, total_loss: 4.384744167327881
training step: 4744, total_loss: 3.9601857662200928
training step: 4745, total_loss: 2.789027690887451
training step: 4746, total_loss: 4.594153881072998
training step: 4747, total_loss: 4.1111836433410645
training step: 4748, total_loss: 3.459353446960449
training step: 4749, total_loss: 5.534723281860352
training step: 4750, total_loss: 4.195226669311523
training step: 4751, total_loss: 4.647071838378906
training step: 4752, total_loss: 4.609273910522461
training step: 4753, total_loss: 5.617663860321045
training step: 4754, total_loss: 4.624545097351074
training step: 4755, total_loss: 5.503036022186279
training step: 4756, total_loss: 5.159363746643066
training step: 4757, total_loss: 5.25549840927124
training step: 4758, total_loss: 5.6183977127075195
training step: 4759, total_loss: 4.410404682159424
training step: 4760, total_loss: 4.048004150390625
training step: 4761, total_loss: 4.859818458557129
training step: 4762, total_loss: 6.647047519683838
training step: 4763, total_loss: 4.810134410858154
training step: 4764, total_loss: 3.888559341430664
training step: 4765, total_loss: 3.7439897060394287
training step: 4766, total_loss: 5.032188415527344
training step: 4767, total_loss: 3.9433934688568115
training step: 4768, total_loss: 4.365664005279541
training step: 4769, total_loss: 6.210569381713867
training step: 4770, total_loss: 4.6903486251831055
training step: 4771, total_loss: 1.5358986854553223
training step: 4772, total_loss: 5.608013153076172
training step: 4773, total_loss: 5.7194366455078125
training step: 4774, total_loss: 4.804814338684082
training step: 4775, total_loss: 4.231898784637451
training step: 4776, total_loss: 4.467136859893799
training step: 4777, total_loss: 4.5752973556518555
training step: 4778, total_loss: 4.361551284790039
training step: 4779, total_loss: 5.449273109436035
training step: 4780, total_loss: 4.006112575531006
training step: 4781, total_loss: 5.599433898925781
training step: 4782, total_loss: 5.363116264343262
training step: 4783, total_loss: 5.266146659851074
training step: 4784, total_loss: 4.847074508666992
training step: 4785, total_loss: 4.283041477203369
training step: 4786, total_loss: 5.2453107833862305
training step: 4787, total_loss: 6.370081901550293
training step: 4788, total_loss: 6.266827583312988
training step: 4789, total_loss: 5.165122985839844
training step: 4790, total_loss: 2.54552960395813
training step: 4791, total_loss: 4.6260085105896
training step: 4792, total_loss: 5.001269340515137
training step: 4793, total_loss: 4.059120178222656
training step: 4794, total_loss: 6.306202411651611
training step: 4795, total_loss: 3.9419026374816895
training step: 4796, total_loss: 4.5016632080078125
training step: 4797, total_loss: 5.260664939880371
training step: 4798, total_loss: 6.594513893127441
training step: 4799, total_loss: 2.1792025566101074
training step: 4800, total_loss: 4.61552619934082
training step: 4801, total_loss: 4.411289215087891
training step: 4802, total_loss: 2.7092859745025635
training step: 4803, total_loss: 5.173410415649414
training step: 4804, total_loss: 5.805753707885742
training step: 4805, total_loss: 4.383325099945068
training step: 4806, total_loss: 5.498745441436768
training step: 4807, total_loss: 3.8699140548706055
training step: 4808, total_loss: 4.635209083557129
training step: 4809, total_loss: 4.814126014709473
training step: 4810, total_loss: 5.585221290588379
training step: 4811, total_loss: 5.140528678894043
training step: 4812, total_loss: 4.843201637268066
training step: 4813, total_loss: 4.259769439697266
training step: 4814, total_loss: 4.992555618286133
training step: 4815, total_loss: 3.0931198596954346
training step: 4816, total_loss: 5.650864601135254
training step: 4817, total_loss: 3.8159971237182617
training step: 4818, total_loss: 5.067227363586426
training step: 4819, total_loss: 4.683889865875244
training step: 4820, total_loss: 5.387772083282471
training step: 4821, total_loss: 5.495065689086914
training step: 4822, total_loss: 6.575570106506348
training step: 4823, total_loss: 4.61174201965332
training step: 4824, total_loss: 4.994688987731934
training step: 4825, total_loss: 3.7081797122955322
training step: 4826, total_loss: 4.644809722900391
training step: 4827, total_loss: 4.526186943054199
training step: 4828, total_loss: 3.387967824935913
training step: 4829, total_loss: 4.657992362976074
training step: 4830, total_loss: 5.877897262573242
training step: 4831, total_loss: 5.798099994659424
training step: 4832, total_loss: 5.262973308563232
training step: 4833, total_loss: 6.114577770233154
training step: 4834, total_loss: 4.670533180236816
training step: 4835, total_loss: 5.8505473136901855
training step: 4836, total_loss: 4.093120574951172
training step: 4837, total_loss: 4.870302200317383
training step: 4838, total_loss: 4.282187461853027
training step: 4839, total_loss: 4.904056549072266
training step: 4840, total_loss: 5.2843780517578125
training step: 4841, total_loss: 5.44017219543457
training step: 4842, total_loss: 4.145639896392822
training step: 4843, total_loss: 5.338397979736328
training step: 4844, total_loss: 4.785069465637207
training step: 4845, total_loss: 3.229185104370117
training step: 4846, total_loss: 4.536940097808838
training step: 4847, total_loss: 4.767427444458008
training step: 4848, total_loss: 4.968234539031982
training step: 4849, total_loss: 5.442605972290039
training step: 4850, total_loss: 3.993283748626709
training step: 4851, total_loss: 4.524697303771973
training step: 4852, total_loss: 3.8316314220428467
training step: 4853, total_loss: 4.494559288024902
training step: 4854, total_loss: 4.688053131103516
training step: 4855, total_loss: 5.8348588943481445
training step: 4856, total_loss: 6.444372177124023
training step: 4857, total_loss: 7.016252517700195
training step: 4858, total_loss: 3.8957881927490234
training step: 4859, total_loss: 4.001969337463379
training step: 4860, total_loss: 4.625967979431152
training step: 4861, total_loss: 4.63762092590332
training step: 4862, total_loss: 4.701147079467773
training step: 4863, total_loss: 5.625640869140625
training step: 4864, total_loss: 3.6390719413757324
training step: 4865, total_loss: 4.836442947387695
training step: 4866, total_loss: 5.621842384338379
training step: 4867, total_loss: 5.4732770919799805
training step: 4868, total_loss: 4.196343421936035
training step: 4869, total_loss: 5.711307525634766
training step: 4870, total_loss: 6.060917854309082
training step: 4871, total_loss: 4.099038124084473
training step: 4872, total_loss: 4.087944507598877
training step: 4873, total_loss: 4.946969032287598
training step: 4874, total_loss: 4.4124908447265625
training step: 4875, total_loss: 1.748445749282837
training step: 4876, total_loss: 4.6979241371154785
training step: 4877, total_loss: 4.720304489135742
training step: 4878, total_loss: 5.307742595672607
training step: 4879, total_loss: 5.438420295715332
training step: 4880, total_loss: 4.62407112121582
training step: 4881, total_loss: 3.8562586307525635
training step: 4882, total_loss: 2.6647653579711914
training step: 4883, total_loss: 5.049808979034424
training step: 4884, total_loss: 4.320258617401123
training step: 4885, total_loss: 4.439167499542236
training step: 4886, total_loss: 4.643900394439697
training step: 4887, total_loss: 4.263637065887451
training step: 4888, total_loss: 4.34321403503418
training step: 4889, total_loss: 4.359570026397705
training step: 4890, total_loss: 3.9098405838012695
training step: 4891, total_loss: 3.992496967315674
training step: 4892, total_loss: 5.470060348510742
training step: 4893, total_loss: 5.675877571105957
training step: 4894, total_loss: 3.883617401123047
training step: 4895, total_loss: 4.696881294250488
training step: 4896, total_loss: 5.9120049476623535
training step: 4897, total_loss: 4.394103527069092
training step: 4898, total_loss: 4.392455101013184
training step: 4899, total_loss: 5.120914936065674
training step: 4900, total_loss: 5.592060565948486
training step: 4901, total_loss: 4.223687171936035
training step: 4902, total_loss: 4.011885643005371
training step: 4903, total_loss: 5.729012966156006
training step: 4904, total_loss: 5.42960262298584
training step: 4905, total_loss: 5.267767906188965
training step: 4906, total_loss: 6.286482334136963
training step: 4907, total_loss: 4.763657569885254
training step: 4908, total_loss: 1.9049350023269653
training step: 4909, total_loss: 4.746559143066406
training step: 4910, total_loss: 3.287871837615967
training step: 4911, total_loss: 6.265582084655762
training step: 4912, total_loss: 4.293479919433594
training step: 4913, total_loss: 3.6392176151275635
training step: 4914, total_loss: 5.943175315856934
training step: 4915, total_loss: 4.752620697021484
training step: 4916, total_loss: 4.887743949890137
training step: 4917, total_loss: 5.403522968292236
training step: 4918, total_loss: 4.188945770263672
training step: 4919, total_loss: 2.970977306365967
training step: 4920, total_loss: 1.8113303184509277
training step: 4921, total_loss: 6.168424606323242
training step: 4922, total_loss: 5.054774761199951
training step: 4923, total_loss: 4.538730621337891
training step: 4924, total_loss: 4.070993423461914
training step: 4925, total_loss: 6.003636360168457
training step: 4926, total_loss: 4.979236602783203
training step: 4927, total_loss: 3.3297767639160156
training step: 4928, total_loss: 4.774909019470215
training step: 4929, total_loss: 3.0603814125061035
training step: 4930, total_loss: 5.365955352783203
training step: 4931, total_loss: 4.400032043457031
training step: 4932, total_loss: 5.5363359451293945
training step: 4933, total_loss: 5.617701530456543
training step: 4934, total_loss: 6.012722969055176
training step: 4935, total_loss: 3.347649097442627
training step: 4936, total_loss: 3.7083663940429688
training step: 4937, total_loss: 5.171691417694092
training step: 4938, total_loss: 4.288723468780518
training step: 4939, total_loss: 1.054527759552002
training step: 4940, total_loss: 5.457423210144043
training step: 4941, total_loss: 4.949034690856934
training step: 4942, total_loss: 4.690793991088867
training step: 4943, total_loss: 4.744519233703613
training step: 4944, total_loss: 4.420627593994141
training step: 4945, total_loss: 5.0235490798950195
training step: 4946, total_loss: 4.374920845031738
training step: 4947, total_loss: 0.8447839021682739
training step: 4948, total_loss: 5.088943958282471
training step: 4949, total_loss: 6.106698989868164
training step: 4950, total_loss: 3.2266860008239746
training step: 4951, total_loss: 3.852294683456421
training step: 4952, total_loss: 0.7435903549194336
training step: 4953, total_loss: 4.27979850769043
training step: 4954, total_loss: 4.22845458984375
training step: 4955, total_loss: 4.736900329589844
training step: 4956, total_loss: 5.150913715362549
training step: 4957, total_loss: 1.1526727676391602
training step: 4958, total_loss: 5.660314559936523
training step: 4959, total_loss: 4.3676862716674805
training step: 4960, total_loss: 4.172187328338623
training step: 4961, total_loss: 5.745326042175293
training step: 4962, total_loss: 5.200438499450684
training step: 4963, total_loss: 4.831487655639648
training step: 4964, total_loss: 4.315901756286621
training step: 4965, total_loss: 5.098426342010498
training step: 4966, total_loss: 5.193591594696045
training step: 4967, total_loss: 3.741994857788086
training step: 4968, total_loss: 5.5708723068237305
training step: 4969, total_loss: 4.265800952911377
training step: 4970, total_loss: 4.855528831481934
training step: 4971, total_loss: 4.557703018188477
training step: 4972, total_loss: 4.681209564208984
training step: 4973, total_loss: 5.559393405914307
training step: 4974, total_loss: 5.689511299133301
training step: 4975, total_loss: 5.177761554718018
training step: 4976, total_loss: 4.442442893981934
training step: 4977, total_loss: 5.956552505493164
training step: 4978, total_loss: 5.524892807006836
training step: 4979, total_loss: 5.5528154373168945
training step: 4980, total_loss: 4.26698112487793
training step: 4981, total_loss: 5.465992450714111
training step: 4982, total_loss: 3.197922706604004
training step: 4983, total_loss: 4.4702348709106445
training step: 4984, total_loss: 5.042710781097412
training step: 4985, total_loss: 4.964985370635986
training step: 4986, total_loss: 4.184633255004883
training step: 4987, total_loss: 1.8076443672180176
training step: 4988, total_loss: 3.242316961288452
training step: 4989, total_loss: 4.4489593505859375
training step: 4990, total_loss: 3.5348381996154785
training step: 4991, total_loss: 5.490658760070801
training step: 4992, total_loss: 3.8043441772460938
training step: 4993, total_loss: 5.318829536437988
training step: 4994, total_loss: 4.461036682128906
training step: 4995, total_loss: 4.503868579864502
training step: 4996, total_loss: 4.229143142700195
training step: 4997, total_loss: 4.645682334899902
training step: 4998, total_loss: 5.1062541007995605
training step: 4999, total_loss: 5.65691614151001
training step: 5000, total_loss: 4.778184413909912
training step: 5001, total_loss: 5.073197364807129
training step: 5002, total_loss: 6.913099765777588
training step: 5003, total_loss: 5.112218379974365
training step: 5004, total_loss: 5.512129783630371
training step: 5005, total_loss: 5.516020774841309
training step: 5006, total_loss: 4.772416114807129
training step: 5007, total_loss: 4.831842422485352
training step: 5008, total_loss: 5.8556718826293945
training step: 5009, total_loss: 4.586477279663086
training step: 5010, total_loss: 4.902933120727539
training step: 5011, total_loss: 3.92441987991333
training step: 5012, total_loss: 7.560116767883301
training step: 5013, total_loss: 4.694596290588379
training step: 5014, total_loss: 4.483968734741211
training step: 5015, total_loss: 1.549109935760498
training step: 5016, total_loss: 7.301159858703613
training step: 5017, total_loss: 4.683308124542236
training step: 5018, total_loss: 4.715349197387695
training step: 5019, total_loss: 5.9901018142700195
training step: 5020, total_loss: 4.501742839813232
training step: 5021, total_loss: 4.399026870727539
training step: 5022, total_loss: 4.051360130310059
training step: 5023, total_loss: 4.766396522521973
training step: 5024, total_loss: 4.956867694854736
training step: 5025, total_loss: 4.596918106079102
training step: 5026, total_loss: 4.442241668701172
training step: 5027, total_loss: 3.7783212661743164
training step: 5028, total_loss: 5.276163101196289
training step: 5029, total_loss: 2.576606273651123
training step: 5030, total_loss: 5.056905746459961
training step: 5031, total_loss: 4.60462760925293
training step: 5032, total_loss: 6.569522857666016
training step: 5033, total_loss: 2.885601282119751
training step: 5034, total_loss: 2.997380018234253
training step: 5035, total_loss: 3.5424118041992188
training step: 5036, total_loss: 4.239112854003906
training step: 5037, total_loss: 5.350717544555664
training step: 5038, total_loss: 5.059641361236572
training step: 5039, total_loss: 4.569890022277832
training step: 5040, total_loss: 6.1878461837768555
training step: 5041, total_loss: 3.017683982849121
training step: 5042, total_loss: 5.446127891540527
training step: 5043, total_loss: 4.256769180297852
training step: 5044, total_loss: 5.671845436096191
training step: 5045, total_loss: 4.012702941894531
training step: 5046, total_loss: 4.002502918243408
training step: 5047, total_loss: 5.213401794433594
training step: 5048, total_loss: 5.7515411376953125
training step: 5049, total_loss: 4.6845293045043945
training step: 5050, total_loss: 4.8828630447387695
training step: 5051, total_loss: 5.095318794250488
training step: 5052, total_loss: 6.176761627197266
training step: 5053, total_loss: 3.8400750160217285
training step: 5054, total_loss: 6.124024391174316
training step: 5055, total_loss: 3.4704761505126953
training step: 5056, total_loss: 2.0286178588867188
training step: 5057, total_loss: 3.963932514190674
training step: 5058, total_loss: 4.730044841766357
training step: 5059, total_loss: 4.138095378875732
training step: 5060, total_loss: 5.332769393920898
training step: 5061, total_loss: 5.390973091125488
training step: 5062, total_loss: 3.885021209716797
training step: 5063, total_loss: 4.344561576843262
training step: 5064, total_loss: 4.155017375946045
training step: 5065, total_loss: 5.067081451416016
training step: 5066, total_loss: 5.2188310623168945
training step: 5067, total_loss: 4.147224426269531
training step: 5068, total_loss: 4.446540355682373
training step: 5069, total_loss: 5.2271037101745605
training step: 5070, total_loss: 5.332720756530762
training step: 5071, total_loss: 5.426657676696777
training step: 5072, total_loss: 5.198638916015625
training step: 5073, total_loss: 5.525452613830566
training step: 5074, total_loss: 5.549215316772461
training step: 5075, total_loss: 3.5099263191223145
training step: 5076, total_loss: 4.375957489013672
training step: 5077, total_loss: 5.264535903930664
training step: 5078, total_loss: 5.906896591186523
training step: 5079, total_loss: 3.8951714038848877
training step: 5080, total_loss: 5.048680305480957
training step: 5081, total_loss: 5.509971618652344
training step: 5082, total_loss: 5.977781295776367
training step: 5083, total_loss: 4.771389007568359
training step: 5084, total_loss: 6.834696292877197
training step: 5085, total_loss: 5.685351371765137
training step: 5086, total_loss: 6.202146530151367
training step: 5087, total_loss: 6.326128959655762
training step: 5088, total_loss: 5.10520076751709
training step: 5089, total_loss: 5.420219898223877
training step: 5090, total_loss: 3.4365549087524414
training step: 5091, total_loss: 4.694491386413574
training step: 5092, total_loss: 5.16180419921875
training step: 5093, total_loss: 5.18023681640625
training step: 5094, total_loss: 5.100867748260498
training step: 5095, total_loss: 3.9214916229248047
training step: 5096, total_loss: 4.684604644775391
training step: 5097, total_loss: 5.269182205200195
training step: 5098, total_loss: 5.447457313537598
training step: 5099, total_loss: 5.088560104370117
training step: 5100, total_loss: 5.552509784698486
training step: 5101, total_loss: 4.220322608947754
training step: 5102, total_loss: 4.783393859863281
training step: 5103, total_loss: 5.309894561767578
training step: 5104, total_loss: 4.209486961364746
training step: 5105, total_loss: 4.977622985839844
training step: 5106, total_loss: 4.36073637008667
training step: 5107, total_loss: 5.8195085525512695
training step: 5108, total_loss: 5.510104179382324
training step: 5109, total_loss: 5.295721054077148
training step: 5110, total_loss: 5.759434700012207
training step: 5111, total_loss: 4.663683891296387
training step: 5112, total_loss: 4.056585788726807
training step: 5113, total_loss: 5.158363342285156
training step: 5114, total_loss: 4.429782867431641
training step: 5115, total_loss: 5.488570690155029
training step: 5116, total_loss: 4.4308881759643555
training step: 5117, total_loss: 5.49739933013916
training step: 5118, total_loss: 3.9226999282836914
training step: 5119, total_loss: 5.487422466278076
training step: 5120, total_loss: 3.649488925933838
training step: 5121, total_loss: 4.732053756713867
training step: 5122, total_loss: 3.6678853034973145
training step: 5123, total_loss: 6.44876766204834
training step: 5124, total_loss: 5.286410331726074
training step: 5125, total_loss: 4.527137756347656
training step: 5126, total_loss: 5.597864151000977
training step: 5127, total_loss: 2.769989490509033
training step: 5128, total_loss: 4.334347724914551
training step: 5129, total_loss: 3.9595651626586914
training step: 5130, total_loss: 4.886687278747559
training step: 5131, total_loss: 4.726330757141113
training step: 5132, total_loss: 4.951283931732178
training step: 5133, total_loss: 3.3732786178588867
training step: 5134, total_loss: 4.789703369140625
training step: 5135, total_loss: 4.369851112365723
training step: 5136, total_loss: 4.982546806335449
training step: 5137, total_loss: 4.0038371086120605
training step: 5138, total_loss: 3.7978854179382324
training step: 5139, total_loss: 5.029989242553711
training step: 5140, total_loss: 2.815056562423706
training step: 5141, total_loss: 5.4208984375
training step: 5142, total_loss: 4.700994968414307
training step: 5143, total_loss: 6.882957458496094
training step: 5144, total_loss: 6.075372695922852
training step: 5145, total_loss: 1.9026362895965576
training step: 5146, total_loss: 4.917205810546875
training step: 5147, total_loss: 5.173194885253906
training step: 5148, total_loss: 4.403445720672607
training step: 5149, total_loss: 5.531785488128662
training step: 5150, total_loss: 3.433014392852783
training step: 5151, total_loss: 4.216927528381348
training step: 5152, total_loss: 5.460829734802246
training step: 5153, total_loss: 4.891027450561523
training step: 5154, total_loss: 5.1646409034729
training step: 5155, total_loss: 4.475546836853027
training step: 5156, total_loss: 5.328680515289307
training step: 5157, total_loss: 5.940006256103516
training step: 5158, total_loss: 4.518715858459473
training step: 5159, total_loss: 4.82521915435791
training step: 5160, total_loss: 5.37230110168457
training step: 5161, total_loss: 5.316927909851074
training step: 5162, total_loss: 5.433238983154297
training step: 5163, total_loss: 5.4102702140808105
training step: 5164, total_loss: 3.3935039043426514
training step: 5165, total_loss: 5.051543712615967
training step: 5166, total_loss: 7.185726642608643
training step: 5167, total_loss: 4.656036376953125
training step: 5168, total_loss: 4.735831260681152
training step: 5169, total_loss: 5.686595916748047
training step: 5170, total_loss: 5.015181064605713
training step: 5171, total_loss: 4.660806179046631
training step: 5172, total_loss: 1.6584066152572632
training step: 5173, total_loss: 6.0745954513549805
training step: 5174, total_loss: 4.875550270080566
training step: 5175, total_loss: 6.050938606262207
training step: 5176, total_loss: 4.36916971206665
training step: 5177, total_loss: 5.399914264678955
training step: 5178, total_loss: 6.307742118835449
training step: 5179, total_loss: 4.815104007720947
training step: 5180, total_loss: 4.225966453552246
training step: 5181, total_loss: 4.494741439819336
training step: 5182, total_loss: 5.2377848625183105
training step: 5183, total_loss: 4.683422088623047
training step: 5184, total_loss: 4.677145004272461
training step: 5185, total_loss: 4.775412082672119
training step: 5186, total_loss: 6.126989364624023
training step: 5187, total_loss: 4.773983001708984
training step: 5188, total_loss: 4.752167224884033
training step: 5189, total_loss: 5.668808937072754
training step: 5190, total_loss: 4.842241287231445
training step: 5191, total_loss: 4.548397541046143
training step: 5192, total_loss: 5.136765003204346
training step: 5193, total_loss: 4.899432182312012
training step: 5194, total_loss: 4.375575065612793
training step: 5195, total_loss: 2.657702922821045
training step: 5196, total_loss: 3.6711089611053467
training step: 5197, total_loss: 6.314477443695068
training step: 5198, total_loss: 6.252391815185547
training step: 5199, total_loss: 5.02821683883667
training step: 5200, total_loss: 4.863897800445557
training step: 5201, total_loss: 4.608924388885498
training step: 5202, total_loss: 3.240785598754883
training step: 5203, total_loss: 5.564213275909424
training step: 5204, total_loss: 4.348040580749512
training step: 5205, total_loss: 4.2927398681640625
training step: 5206, total_loss: 4.551052570343018
training step: 5207, total_loss: 4.685128211975098
training step: 5208, total_loss: 4.676833152770996
training step: 5209, total_loss: 5.110401153564453
training step: 5210, total_loss: 5.769906044006348
training step: 5211, total_loss: 5.3203630447387695
training step: 5212, total_loss: 4.444131374359131
training step: 5213, total_loss: 5.466549873352051
training step: 5214, total_loss: 4.348329544067383
training step: 5215, total_loss: 4.826893329620361
training step: 5216, total_loss: 4.273588180541992
training step: 5217, total_loss: 2.961945056915283
training step: 5218, total_loss: 1.535372257232666
training step: 5219, total_loss: 2.8603389263153076
training step: 5220, total_loss: 6.48991584777832
training step: 5221, total_loss: 3.163468837738037
training step: 5222, total_loss: 4.4630303382873535
training step: 5223, total_loss: 5.282741546630859
training step: 5224, total_loss: 4.416914939880371
training step: 5225, total_loss: 4.2884111404418945
training step: 5226, total_loss: 4.587802410125732
training step: 5227, total_loss: 5.268946647644043
training step: 5228, total_loss: 5.150883674621582
training step: 5229, total_loss: 5.105256080627441
training step: 5230, total_loss: 6.180389404296875
training step: 5231, total_loss: 5.217016696929932
training step: 5232, total_loss: 5.741032600402832
training step: 5233, total_loss: 4.769312858581543
training step: 5234, total_loss: 4.534551620483398
training step: 5235, total_loss: 6.9506731033325195
training step: 5236, total_loss: 4.659983158111572
training step: 5237, total_loss: 4.550177097320557
training step: 5238, total_loss: 6.762752056121826
training step: 5239, total_loss: 3.7409846782684326
training step: 5240, total_loss: 5.709338188171387
training step: 5241, total_loss: 4.327895164489746
training step: 5242, total_loss: 4.897188663482666
training step: 5243, total_loss: 5.72352409362793
training step: 5244, total_loss: 4.434210777282715
training step: 5245, total_loss: 5.599356651306152
training step: 5246, total_loss: 5.264019966125488
training step: 5247, total_loss: 5.308627605438232
training step: 5248, total_loss: 5.6420793533325195
training step: 5249, total_loss: 5.435379981994629
training step: 5250, total_loss: 5.757030487060547
training step: 5251, total_loss: 5.398141860961914
training step: 5252, total_loss: 3.670886278152466
training step: 5253, total_loss: 5.136885643005371
training step: 5254, total_loss: 4.309626579284668
training step: 5255, total_loss: 4.266820907592773
training step: 5256, total_loss: 4.60491943359375
training step: 5257, total_loss: 4.821869373321533
training step: 5258, total_loss: 3.5900728702545166
training step: 5259, total_loss: 4.255126476287842
training step: 5260, total_loss: 3.3574697971343994
training step: 5261, total_loss: 5.117876052856445
training step: 5262, total_loss: 5.491163730621338
training step: 5263, total_loss: 2.6945838928222656
training step: 5264, total_loss: 4.381670951843262
training step: 5265, total_loss: 4.581214427947998
training step: 5266, total_loss: 5.625482559204102
training step: 5267, total_loss: 5.217342376708984
training step: 5268, total_loss: 5.935479164123535
training step: 5269, total_loss: 4.730212688446045
training step: 5270, total_loss: 6.995757579803467
training step: 5271, total_loss: 4.950266361236572
training step: 5272, total_loss: 5.50404167175293
training step: 5273, total_loss: 3.2348310947418213
training step: 5274, total_loss: 4.655670166015625
training step: 5275, total_loss: 1.4496095180511475
training step: 5276, total_loss: 4.183795928955078
training step: 5277, total_loss: 4.657259941101074
training step: 5278, total_loss: 5.581399917602539
training step: 5279, total_loss: 5.998587608337402
training step: 5280, total_loss: 4.245432376861572
training step: 5281, total_loss: 3.5697946548461914
training step: 5282, total_loss: 3.088813304901123
training step: 5283, total_loss: 2.459009885787964
training step: 5284, total_loss: 3.6946933269500732
training step: 5285, total_loss: 4.8305888175964355
training step: 5286, total_loss: 3.5668301582336426
training step: 5287, total_loss: 5.8491926193237305
training step: 5288, total_loss: 5.095455169677734
training step: 5289, total_loss: 3.0283496379852295
training step: 5290, total_loss: 4.222019195556641
training step: 5291, total_loss: 5.593032360076904
training step: 5292, total_loss: 3.6570489406585693
training step: 5293, total_loss: 4.857842445373535
training step: 5294, total_loss: 5.059955596923828
training step: 5295, total_loss: 3.362746238708496
training step: 5296, total_loss: 5.83671760559082
training step: 5297, total_loss: 4.707747459411621
training step: 5298, total_loss: 5.122223854064941
training step: 5299, total_loss: 4.723222255706787
training step: 5300, total_loss: 5.089108467102051
training step: 5301, total_loss: 6.109477519989014
training step: 5302, total_loss: 4.21685791015625
training step: 5303, total_loss: 5.269989967346191
training step: 5304, total_loss: 5.252315521240234
training step: 5305, total_loss: 5.247611999511719
training step: 5306, total_loss: 3.9233462810516357
training step: 5307, total_loss: 5.054823875427246
training step: 5308, total_loss: 4.899144172668457
training step: 5309, total_loss: 4.791337013244629
training step: 5310, total_loss: 5.982935905456543
training step: 5311, total_loss: 4.523530960083008
training step: 5312, total_loss: 5.700448989868164
training step: 5313, total_loss: 4.074897289276123
training step: 5314, total_loss: 5.524418830871582
training step: 5315, total_loss: 1.7258250713348389
training step: 5316, total_loss: 5.335641860961914
training step: 5317, total_loss: 5.561540603637695
training step: 5318, total_loss: 4.686253547668457
training step: 5319, total_loss: 4.310235023498535
training step: 5320, total_loss: 2.9915683269500732
training step: 5321, total_loss: 5.38946533203125
training step: 5322, total_loss: 4.271623611450195
training step: 5323, total_loss: 5.747949600219727
training step: 5324, total_loss: 4.9372429847717285
training step: 5325, total_loss: 4.981730937957764
training step: 5326, total_loss: 4.408544540405273
training step: 5327, total_loss: 5.486963272094727
training step: 5328, total_loss: 5.683090686798096
training step: 5329, total_loss: 4.826160430908203
training step: 5330, total_loss: 4.255673408508301
training step: 5331, total_loss: 3.04288911819458
training step: 5332, total_loss: 4.3308305740356445
training step: 5333, total_loss: 4.682435989379883
training step: 5334, total_loss: 3.8260574340820312
training step: 5335, total_loss: 4.731992721557617
training step: 5336, total_loss: 5.5227861404418945
training step: 5337, total_loss: 5.136921405792236
training step: 5338, total_loss: 4.744518756866455
training step: 5339, total_loss: 5.908645153045654
training step: 5340, total_loss: 5.759122848510742
training step: 5341, total_loss: 2.7375102043151855
training step: 5342, total_loss: 5.3394670486450195
training step: 5343, total_loss: 3.1236143112182617
training step: 5344, total_loss: 6.022286415100098
training step: 5345, total_loss: 5.028717041015625
training step: 5346, total_loss: 5.574578285217285
training step: 5347, total_loss: 4.785677909851074
training step: 5348, total_loss: 4.8519606590271
training step: 5349, total_loss: 3.7889394760131836
training step: 5350, total_loss: 5.333810806274414
training step: 5351, total_loss: 3.2093353271484375
training step: 5352, total_loss: 4.702031135559082
training step: 5353, total_loss: 5.45230770111084
training step: 5354, total_loss: 4.766280174255371
training step: 5355, total_loss: 4.3801774978637695
training step: 5356, total_loss: 4.3167829513549805
training step: 5357, total_loss: 5.683714866638184
training step: 5358, total_loss: 4.5415191650390625
training step: 5359, total_loss: 5.534845352172852
training step: 5360, total_loss: 4.2780561447143555
training step: 5361, total_loss: 5.070562362670898
training step: 5362, total_loss: 3.559077024459839
training step: 5363, total_loss: 5.890494346618652
training step: 5364, total_loss: 5.8687028884887695
training step: 5365, total_loss: 4.303495407104492
training step: 5366, total_loss: 6.043386936187744
training step: 5367, total_loss: 5.365761756896973
training step: 5368, total_loss: 4.347590446472168
training step: 5369, total_loss: 4.288264274597168
training step: 5370, total_loss: 4.976101398468018
training step: 5371, total_loss: 4.483828544616699
training step: 5372, total_loss: 4.932575225830078
training step: 5373, total_loss: 4.176339626312256
training step: 5374, total_loss: 5.178409099578857
training step: 5375, total_loss: 1.4459871053695679
training step: 5376, total_loss: 3.8860843181610107
training step: 5377, total_loss: 4.03986930847168
training step: 5378, total_loss: 4.588456630706787
training step: 5379, total_loss: 4.0589423179626465
training step: 5380, total_loss: 4.4500250816345215
training step: 5381, total_loss: 3.7090532779693604
training step: 5382, total_loss: 3.7234082221984863
training step: 5383, total_loss: 4.3992600440979
training step: 5384, total_loss: 6.19223690032959
training step: 5385, total_loss: 4.849603176116943
training step: 5386, total_loss: 5.11956787109375
training step: 5387, total_loss: 5.141086578369141
training step: 5388, total_loss: 4.810580253601074
training step: 5389, total_loss: 2.708446979522705
training step: 5390, total_loss: 4.675519943237305
training step: 5391, total_loss: 4.896827697753906
training step: 5392, total_loss: 5.5243988037109375
training step: 5393, total_loss: 5.225346565246582
training step: 5394, total_loss: 6.361663818359375
training step: 5395, total_loss: 5.514439582824707
training step: 5396, total_loss: 3.951857566833496
training step: 5397, total_loss: 5.125029563903809
training step: 5398, total_loss: 4.289419174194336
training step: 5399, total_loss: 5.102811336517334
training step: 5400, total_loss: 5.443333148956299
training step: 5401, total_loss: 4.952533721923828
training step: 5402, total_loss: 5.617789268493652
training step: 5403, total_loss: 5.343877792358398
training step: 5404, total_loss: 5.550589561462402
training step: 5405, total_loss: 6.130297660827637
training step: 5406, total_loss: 6.343900680541992
training step: 5407, total_loss: 5.013646125793457
training step: 5408, total_loss: 5.5457258224487305
training step: 5409, total_loss: 4.017508029937744
training step: 5410, total_loss: 4.3612542152404785
training step: 5411, total_loss: 5.005460739135742
training step: 5412, total_loss: 5.643190383911133
training step: 5413, total_loss: 4.52180814743042
training step: 5414, total_loss: 4.627001762390137
training step: 5415, total_loss: 5.449672222137451
training step: 5416, total_loss: 4.252192974090576
training step: 5417, total_loss: 4.691638946533203
training step: 5418, total_loss: 4.361342906951904
training step: 5419, total_loss: 5.058467864990234
training step: 5420, total_loss: 4.495872497558594
training step: 5421, total_loss: 3.259225845336914
training step: 5422, total_loss: 5.434571266174316
training step: 5423, total_loss: 4.951600074768066
training step: 5424, total_loss: 4.851458549499512
training step: 5425, total_loss: 5.226343154907227
training step: 5426, total_loss: 5.086429595947266
training step: 5427, total_loss: 4.158702373504639
training step: 5428, total_loss: 6.191180229187012
training step: 5429, total_loss: 4.207314491271973
training step: 5430, total_loss: 5.205593109130859
training step: 5431, total_loss: 5.756902694702148
training step: 5432, total_loss: 2.9747095108032227
training step: 5433, total_loss: 5.027161598205566
training step: 5434, total_loss: 3.2413768768310547
training step: 5435, total_loss: 6.019053936004639
training step: 5436, total_loss: 6.400157928466797
training step: 5437, total_loss: 4.888031482696533
training step: 5438, total_loss: 5.5443620681762695
training step: 5439, total_loss: 4.988767623901367
training step: 5440, total_loss: 5.365279197692871
training step: 5441, total_loss: 4.526706218719482
training step: 5442, total_loss: 5.422123908996582
training step: 5443, total_loss: 5.124658584594727
training step: 5444, total_loss: 4.5310163497924805
training step: 5445, total_loss: 5.0239152908325195
training step: 5446, total_loss: 3.4875104427337646
training step: 5447, total_loss: 5.12432336807251
training step: 5448, total_loss: 5.080655097961426
training step: 5449, total_loss: 4.7644548416137695
training step: 5450, total_loss: 5.191976547241211
training step: 5451, total_loss: 4.8432841300964355
training step: 5452, total_loss: 6.052392959594727
training step: 5453, total_loss: 4.658148288726807
training step: 5454, total_loss: 5.4140095710754395
training step: 5455, total_loss: 6.628643035888672
training step: 5456, total_loss: 5.48994255065918
training step: 5457, total_loss: 4.21299409866333
training step: 5458, total_loss: 5.0996928215026855
training step: 5459, total_loss: 6.509878158569336
training step: 5460, total_loss: 6.403241157531738
training step: 5461, total_loss: 4.966147422790527
training step: 5462, total_loss: 5.228200912475586
training step: 5463, total_loss: 6.62587308883667
training step: 5464, total_loss: 4.219417095184326
training step: 5465, total_loss: 5.737627983093262
training step: 5466, total_loss: 4.625194549560547
training step: 5467, total_loss: 5.218099594116211
training step: 5468, total_loss: 4.565891742706299
training step: 5469, total_loss: 4.7671709060668945
training step: 5470, total_loss: 4.579764366149902
training step: 5471, total_loss: 4.249227046966553
training step: 5472, total_loss: 5.099045753479004
training step: 5473, total_loss: 2.9576706886291504
training step: 5474, total_loss: 5.07444953918457
training step: 5475, total_loss: 4.105404853820801
training step: 5476, total_loss: 4.5031843185424805
training step: 5477, total_loss: 5.967107772827148
training step: 5478, total_loss: 6.320151329040527
training step: 5479, total_loss: 5.050816535949707
training step: 5480, total_loss: 5.116347789764404
training step: 5481, total_loss: 3.3342442512512207
training step: 5482, total_loss: 5.03270149230957
training step: 5483, total_loss: 3.1827893257141113
training step: 5484, total_loss: 3.5396347045898438
training step: 5485, total_loss: 5.174651145935059
training step: 5486, total_loss: 2.5699636936187744
training step: 5487, total_loss: 3.6984968185424805
training step: 5488, total_loss: 5.406826019287109
training step: 5489, total_loss: 4.498322486877441
training step: 5490, total_loss: 5.163404941558838
training step: 5491, total_loss: 4.867166996002197
training step: 5492, total_loss: 3.7777202129364014
training step: 5493, total_loss: 6.3203020095825195
training step: 5494, total_loss: 5.214999198913574
training step: 5495, total_loss: 4.667214393615723
training step: 5496, total_loss: 5.136351585388184
training step: 5497, total_loss: 5.346240997314453
training step: 5498, total_loss: 3.6324098110198975
training step: 5499, total_loss: 4.4824676513671875
training step: 5500, total_loss: 5.438786506652832
training step: 5501, total_loss: 4.717267990112305
training step: 5502, total_loss: 5.846347808837891
training step: 5503, total_loss: 6.617755889892578
training step: 5504, total_loss: 4.633860111236572
training step: 5505, total_loss: 4.499009132385254
training step: 5506, total_loss: 4.051430702209473
training step: 5507, total_loss: 5.549569129943848
training step: 5508, total_loss: 4.475620269775391
training step: 5509, total_loss: 5.05611515045166
training step: 5510, total_loss: 3.789830207824707
training step: 5511, total_loss: 4.905040740966797
training step: 5512, total_loss: 5.374463081359863
training step: 5513, total_loss: 4.829277038574219
training step: 5514, total_loss: 4.7612104415893555
training step: 5515, total_loss: 5.331073760986328
training step: 5516, total_loss: 4.534698486328125
training step: 5517, total_loss: 5.290252685546875
training step: 5518, total_loss: 5.809082508087158
training step: 5519, total_loss: 6.087009429931641
training step: 5520, total_loss: 5.095975875854492
training step: 5521, total_loss: 4.506545066833496
training step: 5522, total_loss: 4.911468505859375
training step: 5523, total_loss: 4.363623142242432
training step: 5524, total_loss: 4.300628662109375
training step: 5525, total_loss: 5.117721080780029
training step: 5526, total_loss: 4.597400665283203
training step: 5527, total_loss: 3.4531607627868652
training step: 5528, total_loss: 6.211920738220215
training step: 5529, total_loss: 5.098752021789551
training step: 5530, total_loss: 5.141201019287109
training step: 5531, total_loss: 4.786789894104004
training step: 5532, total_loss: 4.883357524871826
training step: 5533, total_loss: 4.207039833068848
training step: 5534, total_loss: 5.118877410888672
training step: 5535, total_loss: 4.361238956451416
training step: 5536, total_loss: 5.4675116539001465
training step: 5537, total_loss: 5.980068206787109
training step: 5538, total_loss: 4.2064714431762695
training step: 5539, total_loss: 5.057428359985352
training step: 5540, total_loss: 3.2812418937683105
training step: 5541, total_loss: 4.96055269241333
training step: 5542, total_loss: 5.440751075744629
training step: 5543, total_loss: 6.359755039215088
training step: 5544, total_loss: 4.1633620262146
training step: 5545, total_loss: 4.877354621887207
training step: 5546, total_loss: 5.509313583374023
training step: 5547, total_loss: 1.3902727365493774
training step: 5548, total_loss: 3.891857147216797
training step: 5549, total_loss: 4.485506057739258
training step: 5550, total_loss: 4.992801666259766
training step: 5551, total_loss: 5.707649230957031
training step: 5552, total_loss: 5.078347206115723
training step: 5553, total_loss: 6.161893844604492
training step: 5554, total_loss: 5.821844100952148
training step: 5555, total_loss: 2.6978771686553955
training step: 5556, total_loss: 4.055981636047363
training step: 5557, total_loss: 5.462549686431885
training step: 5558, total_loss: 5.804509162902832
training step: 5559, total_loss: 6.27476692199707
training step: 5560, total_loss: 5.846324920654297
training step: 5561, total_loss: 4.865274906158447
training step: 5562, total_loss: 4.987703323364258
training step: 5563, total_loss: 5.245479106903076
training step: 5564, total_loss: 5.060248374938965
training step: 5565, total_loss: 4.861854553222656
training step: 5566, total_loss: 5.361273288726807
training step: 5567, total_loss: 4.508128643035889
training step: 5568, total_loss: 5.68035364151001
training step: 5569, total_loss: 5.696201324462891
training step: 5570, total_loss: 3.986668586730957
training step: 5571, total_loss: 4.807650566101074
training step: 5572, total_loss: 4.9269609451293945
training step: 5573, total_loss: 6.285280227661133
training step: 5574, total_loss: 5.956568717956543
training step: 5575, total_loss: 5.596166610717773
training step: 5576, total_loss: 3.5161731243133545
training step: 5577, total_loss: 5.033390998840332
training step: 5578, total_loss: 5.31581974029541
training step: 5579, total_loss: 5.152573585510254
training step: 5580, total_loss: 3.5418853759765625
training step: 5581, total_loss: 5.152583122253418
training step: 5582, total_loss: 4.992387771606445
training step: 5583, total_loss: 5.879026412963867
training step: 5584, total_loss: 4.750472068786621
training step: 5585, total_loss: 5.76537561416626
training step: 5586, total_loss: 5.467491626739502
training step: 5587, total_loss: 5.256433486938477
training step: 5588, total_loss: 4.8391218185424805
training step: 5589, total_loss: 5.540631294250488
training step: 5590, total_loss: 4.136709213256836
training step: 5591, total_loss: 4.608623027801514
training step: 5592, total_loss: 1.9005529880523682
training step: 5593, total_loss: 5.227666854858398
training step: 5594, total_loss: 5.277137756347656
training step: 5595, total_loss: 3.8088502883911133
training step: 5596, total_loss: 5.789781093597412
training step: 5597, total_loss: 5.195826530456543
training step: 5598, total_loss: 5.122688293457031
training step: 5599, total_loss: 6.153520107269287
training step: 5600, total_loss: 3.5690996646881104
training step: 5601, total_loss: 4.9550628662109375
training step: 5602, total_loss: 3.603896141052246
training step: 5603, total_loss: 5.7830376625061035
training step: 5604, total_loss: 4.467166423797607
training step: 5605, total_loss: 5.5767412185668945
training step: 5606, total_loss: 3.356388568878174
training step: 5607, total_loss: 5.480712890625
training step: 5608, total_loss: 4.663755893707275
training step: 5609, total_loss: 4.585807800292969
training step: 5610, total_loss: 5.591397285461426
training step: 5611, total_loss: 4.73215389251709
training step: 5612, total_loss: 5.244887828826904
training step: 5613, total_loss: 5.864618301391602
training step: 5614, total_loss: 5.74587345123291
training step: 5615, total_loss: 4.987427711486816
training step: 5616, total_loss: 5.266379356384277
training step: 5617, total_loss: 5.066771507263184
training step: 5618, total_loss: 5.134570121765137
training step: 5619, total_loss: 3.852151393890381
training step: 5620, total_loss: 5.4106621742248535
training step: 5621, total_loss: 5.96840763092041
training step: 5622, total_loss: 1.634844422340393
training step: 5623, total_loss: 4.805977821350098
training step: 5624, total_loss: 5.228118896484375
training step: 5625, total_loss: 5.116810321807861
training step: 5626, total_loss: 5.710577011108398
training step: 5627, total_loss: 5.24979305267334
training step: 5628, total_loss: 5.397515296936035
training step: 5629, total_loss: 4.76815938949585
training step: 5630, total_loss: 5.289752960205078
training step: 5631, total_loss: 3.6900832653045654
training step: 5632, total_loss: 5.773545265197754
training step: 5633, total_loss: 4.994375228881836
training step: 5634, total_loss: 4.87137508392334
training step: 5635, total_loss: 4.808084487915039
training step: 5636, total_loss: 4.713171005249023
training step: 5637, total_loss: 5.205865859985352
training step: 5638, total_loss: 5.296520233154297
training step: 5639, total_loss: 2.8151092529296875
training step: 5640, total_loss: 4.994789123535156
training step: 5641, total_loss: 6.850850582122803
training step: 5642, total_loss: 4.873824119567871
training step: 5643, total_loss: 7.3264665603637695
training step: 5644, total_loss: 5.49870491027832
training step: 5645, total_loss: 4.45640230178833
training step: 5646, total_loss: 4.9860992431640625
training step: 5647, total_loss: 5.621371746063232
training step: 5648, total_loss: 5.32889986038208
training step: 5649, total_loss: 4.4026689529418945
training step: 5650, total_loss: 4.786291599273682
training step: 5651, total_loss: 5.095851898193359
training step: 5652, total_loss: 5.471278190612793
training step: 5653, total_loss: 5.626071929931641
training step: 5654, total_loss: 4.247473239898682
training step: 5655, total_loss: 2.620797634124756
training step: 5656, total_loss: 6.438887596130371
training step: 5657, total_loss: 6.178511619567871
training step: 5658, total_loss: 5.113668441772461
training step: 5659, total_loss: 4.999050617218018
training step: 5660, total_loss: 1.5515689849853516
training step: 5661, total_loss: 4.953914642333984
training step: 5662, total_loss: 4.740659713745117
training step: 5663, total_loss: 4.386641979217529
training step: 5664, total_loss: 4.45954704284668
training step: 5665, total_loss: 4.366912364959717
training step: 5666, total_loss: 6.0463457107543945
training step: 5667, total_loss: 5.750364303588867
training step: 5668, total_loss: 5.379213333129883
training step: 5669, total_loss: 5.129355430603027
training step: 5670, total_loss: 5.218057155609131
training step: 5671, total_loss: 3.981444835662842
training step: 5672, total_loss: 4.466799736022949
training step: 5673, total_loss: 5.276615619659424
training step: 5674, total_loss: 4.326629638671875
training step: 5675, total_loss: 6.756862640380859
training step: 5676, total_loss: 3.291053056716919
training step: 5677, total_loss: 4.795197486877441
training step: 5678, total_loss: 5.718040943145752
training step: 5679, total_loss: 3.3804845809936523
training step: 5680, total_loss: 4.382070064544678
training step: 5681, total_loss: 4.719797134399414
training step: 5682, total_loss: 5.715210914611816
training step: 5683, total_loss: 1.2845537662506104
training step: 5684, total_loss: 3.351757526397705
training step: 5685, total_loss: 4.066373825073242
training step: 5686, total_loss: 5.07396125793457
training step: 5687, total_loss: 4.904643535614014
training step: 5688, total_loss: 4.850442409515381
training step: 5689, total_loss: 5.947035789489746
training step: 5690, total_loss: 4.625293731689453
training step: 5691, total_loss: 4.698823928833008
training step: 5692, total_loss: 3.8612592220306396
training step: 5693, total_loss: 4.803736686706543
training step: 5694, total_loss: 5.749884605407715
training step: 5695, total_loss: 5.412092208862305
training step: 5696, total_loss: 6.563803195953369
training step: 5697, total_loss: 3.307194232940674
training step: 5698, total_loss: 4.782017707824707
training step: 5699, total_loss: 3.9339916706085205
training step: 5700, total_loss: 4.842079162597656
training step: 5701, total_loss: 5.13749361038208
training step: 5702, total_loss: 4.6726579666137695
training step: 5703, total_loss: 4.422006607055664
training step: 5704, total_loss: 5.626026630401611
training step: 5705, total_loss: 4.351370811462402
training step: 5706, total_loss: 7.598672866821289
training step: 5707, total_loss: 4.602834701538086
training step: 5708, total_loss: 4.623015880584717
training step: 5709, total_loss: 2.5120925903320312
training step: 5710, total_loss: 5.336550712585449
training step: 5711, total_loss: 3.7190499305725098
training step: 5712, total_loss: 4.957965850830078
training step: 5713, total_loss: 5.7546868324279785
training step: 5714, total_loss: 4.95393180847168
training step: 5715, total_loss: 5.145212173461914
training step: 5716, total_loss: 5.342546463012695
training step: 5717, total_loss: 5.5087175369262695
training step: 5718, total_loss: 4.289316177368164
training step: 5719, total_loss: 5.936716079711914
training step: 5720, total_loss: 4.084382057189941
training step: 5721, total_loss: 5.337822914123535
training step: 5722, total_loss: 4.117630958557129
training step: 5723, total_loss: 4.884878158569336
training step: 5724, total_loss: 4.305296897888184
training step: 5725, total_loss: 5.503641605377197
training step: 5726, total_loss: 4.116060256958008
training step: 5727, total_loss: 6.5326032638549805
training step: 5728, total_loss: 5.6649580001831055
training step: 5729, total_loss: 4.819997310638428
training step: 5730, total_loss: 4.557024002075195
training step: 5731, total_loss: 5.056276798248291
training step: 5732, total_loss: 5.1046833992004395
training step: 5733, total_loss: 4.822256088256836
training step: 5734, total_loss: 3.123232126235962
training step: 5735, total_loss: 4.68373966217041
training step: 5736, total_loss: 5.187292098999023
training step: 5737, total_loss: 4.622100353240967
training step: 5738, total_loss: 5.355410099029541
training step: 5739, total_loss: 5.230837821960449
training step: 5740, total_loss: 3.983910322189331
training step: 5741, total_loss: 4.808534622192383
training step: 5742, total_loss: 5.380950450897217
training step: 5743, total_loss: 5.687679290771484
training step: 5744, total_loss: 4.838811874389648
training step: 5745, total_loss: 4.106135845184326
training step: 5746, total_loss: 4.782116889953613
training step: 5747, total_loss: 6.148890495300293
training step: 5748, total_loss: 5.567540168762207
training step: 5749, total_loss: 6.395964622497559
training step: 5750, total_loss: 4.542473793029785
training step: 5751, total_loss: 4.76572847366333
training step: 5752, total_loss: 4.550017356872559
training step: 5753, total_loss: 5.043460845947266
training step: 5754, total_loss: 3.9525444507598877
training step: 5755, total_loss: 5.666862964630127
training step: 5756, total_loss: 3.9517998695373535
training step: 5757, total_loss: 4.5021772384643555
training step: 5758, total_loss: 4.953842639923096
training step: 5759, total_loss: 2.6473026275634766
training step: 5760, total_loss: 5.809901714324951
training step: 5761, total_loss: 5.51318883895874
training step: 5762, total_loss: 4.443058013916016
training step: 5763, total_loss: 5.280158519744873
training step: 5764, total_loss: 5.345414161682129
training step: 5765, total_loss: 5.112707138061523
training step: 5766, total_loss: 4.60193395614624
training step: 5767, total_loss: 4.629795551300049
training step: 5768, total_loss: 6.33258056640625
training step: 5769, total_loss: 3.9418563842773438
training step: 5770, total_loss: 5.330554962158203
training step: 5771, total_loss: 4.414888858795166
training step: 5772, total_loss: 6.963155746459961
training step: 5773, total_loss: 5.679192543029785
training step: 5774, total_loss: 4.0107831954956055
training step: 5775, total_loss: 4.248373985290527
training step: 5776, total_loss: 4.5405778884887695
training step: 5777, total_loss: 5.498624801635742
training step: 5778, total_loss: 4.358082294464111
training step: 5779, total_loss: 4.767262935638428
training step: 5780, total_loss: 4.645637512207031
training step: 5781, total_loss: 5.770990371704102
training step: 5782, total_loss: 4.872650146484375
training step: 5783, total_loss: 5.089138507843018
training step: 5784, total_loss: 3.7962701320648193
training step: 5785, total_loss: 5.306955337524414
training step: 5786, total_loss: 5.186661720275879
training step: 5787, total_loss: 5.373205661773682
training step: 5788, total_loss: 4.84444522857666
training step: 5789, total_loss: 1.7724385261535645
training step: 5790, total_loss: 4.591819763183594
training step: 5791, total_loss: 5.199502944946289
training step: 5792, total_loss: 3.5237488746643066
training step: 5793, total_loss: 4.978608131408691
training step: 5794, total_loss: 4.226322650909424
training step: 5795, total_loss: 5.43159294128418
training step: 5796, total_loss: 4.61043643951416
training step: 5797, total_loss: 5.334199905395508
training step: 5798, total_loss: 5.306241989135742
training step: 5799, total_loss: 4.028257369995117
training step: 5800, total_loss: 4.842897891998291
training step: 5801, total_loss: 5.630950450897217
training step: 5802, total_loss: 5.088682174682617
training step: 5803, total_loss: 4.434432029724121
training step: 5804, total_loss: 5.527769088745117
training step: 5805, total_loss: 4.544485569000244
training step: 5806, total_loss: 4.15125036239624
training step: 5807, total_loss: 4.612273216247559
training step: 5808, total_loss: 1.156951904296875
training step: 5809, total_loss: 5.827641487121582
training step: 5810, total_loss: 4.681109428405762
training step: 5811, total_loss: 5.496532917022705
training step: 5812, total_loss: 6.311141490936279
training step: 5813, total_loss: 6.989255905151367
training step: 5814, total_loss: 4.881214141845703
training step: 5815, total_loss: 5.044651031494141
training step: 5816, total_loss: 3.813436985015869
training step: 5817, total_loss: 5.564571380615234
training step: 5818, total_loss: 4.483471870422363
training step: 5819, total_loss: 3.98514723777771
training step: 5820, total_loss: 5.551071643829346
training step: 5821, total_loss: 6.175873756408691
training step: 5822, total_loss: 6.161150932312012
training step: 5823, total_loss: 5.1008620262146
training step: 5824, total_loss: 3.8201146125793457
training step: 5825, total_loss: 5.656136512756348
training step: 5826, total_loss: 5.751150131225586
training step: 5827, total_loss: 4.642949104309082
training step: 5828, total_loss: 2.8436803817749023
training step: 5829, total_loss: 4.1677446365356445
training step: 5830, total_loss: 5.560659408569336
training step: 5831, total_loss: 5.341233253479004
training step: 5832, total_loss: 5.590588569641113
training step: 5833, total_loss: 4.720067977905273
training step: 5834, total_loss: 4.641365051269531
training step: 5835, total_loss: 4.7423224449157715
training step: 5836, total_loss: 5.181771278381348
training step: 5837, total_loss: 3.1383304595947266
training step: 5838, total_loss: 4.723225116729736
training step: 5839, total_loss: 5.488982200622559
training step: 5840, total_loss: 4.14530611038208
training step: 5841, total_loss: 5.249337196350098
training step: 5842, total_loss: 5.339695930480957
training step: 5843, total_loss: 5.0063862800598145
training step: 5844, total_loss: 4.47243595123291
training step: 5845, total_loss: 5.0191473960876465
training step: 5846, total_loss: 4.623759746551514
training step: 5847, total_loss: 5.846508026123047
training step: 5848, total_loss: 4.727719306945801
training step: 5849, total_loss: 4.460699081420898
training step: 5850, total_loss: 5.458587646484375
training step: 5851, total_loss: 6.031668663024902
training step: 5852, total_loss: 3.695119619369507
training step: 5853, total_loss: 4.645166397094727
training step: 5854, total_loss: 4.629426002502441
training step: 5855, total_loss: 6.132082939147949
training step: 5856, total_loss: 3.748199939727783
training step: 5857, total_loss: 4.646888256072998
training step: 5858, total_loss: 4.654946327209473
training step: 5859, total_loss: 4.819831371307373
training step: 5860, total_loss: 6.916376113891602
training step: 5861, total_loss: 4.5778584480285645
training step: 5862, total_loss: 5.429783821105957
training step: 5863, total_loss: 4.522127151489258
training step: 5864, total_loss: 4.355456829071045
training step: 5865, total_loss: 3.8355274200439453
training step: 5866, total_loss: 3.5620455741882324
training step: 5867, total_loss: 4.937460422515869
training step: 5868, total_loss: 3.871710777282715
training step: 5869, total_loss: 4.0647406578063965
training step: 5870, total_loss: 4.445693016052246
training step: 5871, total_loss: 5.889342784881592
training step: 5872, total_loss: 7.941548824310303
training step: 5873, total_loss: 3.7127881050109863
training step: 5874, total_loss: 6.117624282836914
training step: 5875, total_loss: 4.060405254364014
training step: 5876, total_loss: 4.028076171875
training step: 5877, total_loss: 5.063093662261963
training step: 5878, total_loss: 3.760364294052124
training step: 5879, total_loss: 4.951750755310059
training step: 5880, total_loss: 4.418656349182129
training step: 5881, total_loss: 4.626853942871094
training step: 5882, total_loss: 5.496376037597656
training step: 5883, total_loss: 6.015577793121338
training step: 5884, total_loss: 4.246490955352783
training step: 5885, total_loss: 4.920660018920898
training step: 5886, total_loss: 4.3570356369018555
training step: 5887, total_loss: 3.947627305984497
training step: 5888, total_loss: 6.750038146972656
training step: 5889, total_loss: 3.729295253753662
training step: 5890, total_loss: 3.803455114364624
training step: 5891, total_loss: 4.627299785614014
training step: 5892, total_loss: 4.589293479919434
training step: 5893, total_loss: 4.766086101531982
training step: 5894, total_loss: 4.2019429206848145
training step: 5895, total_loss: 4.496603012084961
training step: 5896, total_loss: 4.9527082443237305
training step: 5897, total_loss: 5.624898910522461
training step: 5898, total_loss: 4.889377593994141
training step: 5899, total_loss: 4.131921768188477
training step: 5900, total_loss: 4.647636413574219
training step: 5901, total_loss: 5.089444160461426
training step: 5902, total_loss: 5.989062309265137
training step: 5903, total_loss: 4.055967807769775
training step: 5904, total_loss: 4.175592422485352
training step: 5905, total_loss: 4.79763126373291
training step: 5906, total_loss: 5.581141948699951
training step: 5907, total_loss: 4.761463165283203
training step: 5908, total_loss: 4.712664604187012
training step: 5909, total_loss: 4.99307918548584
training step: 5910, total_loss: 5.317065238952637
training step: 5911, total_loss: 4.90330696105957
training step: 5912, total_loss: 5.3175048828125
training step: 5913, total_loss: 6.040064334869385
training step: 5914, total_loss: 5.678435325622559
training step: 5915, total_loss: 5.496563911437988
training step: 5916, total_loss: 4.435731410980225
training step: 5917, total_loss: 4.39592170715332
training step: 5918, total_loss: 5.341521739959717
training step: 5919, total_loss: 3.545988082885742
training step: 5920, total_loss: 3.9422383308410645
training step: 5921, total_loss: 4.809906005859375
training step: 5922, total_loss: 4.938284397125244
training step: 5923, total_loss: 4.236867427825928
training step: 5924, total_loss: 5.268142223358154
training step: 5925, total_loss: 5.151693344116211
training step: 5926, total_loss: 4.0935564041137695
training step: 5927, total_loss: 4.374570846557617
training step: 5928, total_loss: 4.585083961486816
training step: 5929, total_loss: 4.168382167816162
training step: 5930, total_loss: 4.512960433959961
training step: 5931, total_loss: 6.11659574508667
training step: 5932, total_loss: 3.4146625995635986
training step: 5933, total_loss: 3.4224300384521484
training step: 5934, total_loss: 4.854536533355713
training step: 5935, total_loss: 5.289810657501221
training step: 5936, total_loss: 4.3765459060668945
training step: 5937, total_loss: 4.830172538757324
training step: 5938, total_loss: 4.104704856872559
training step: 5939, total_loss: 4.474061012268066
training step: 5940, total_loss: 4.633817195892334
training step: 5941, total_loss: 5.235489368438721
training step: 5942, total_loss: 4.743510723114014
training step: 5943, total_loss: 3.5238311290740967
training step: 5944, total_loss: 3.4938135147094727
training step: 5945, total_loss: 3.442789077758789
training step: 5946, total_loss: 4.743371963500977
training step: 5947, total_loss: 5.704181671142578
training step: 5948, total_loss: 5.980564594268799
training step: 5949, total_loss: 4.412222862243652
training step: 5950, total_loss: 5.754519462585449
training step: 5951, total_loss: 5.924311637878418
training step: 5952, total_loss: 4.38496208190918
training step: 5953, total_loss: 4.044734954833984
training step: 5954, total_loss: 5.603718280792236
training step: 5955, total_loss: 3.7908411026000977
training step: 5956, total_loss: 5.478659629821777
training step: 5957, total_loss: 4.727004528045654
training step: 5958, total_loss: 5.388058662414551
training step: 5959, total_loss: 5.089097023010254
training step: 5960, total_loss: 5.165282249450684
training step: 5961, total_loss: 6.163928031921387
training step: 5962, total_loss: 3.8600850105285645
training step: 5963, total_loss: 4.488741397857666
training step: 5964, total_loss: 5.869723320007324
training step: 5965, total_loss: 5.429213523864746
training step: 5966, total_loss: 5.294685363769531
training step: 5967, total_loss: 4.479479789733887
training step: 5968, total_loss: 3.046398401260376
training step: 5969, total_loss: 4.445001602172852
training step: 5970, total_loss: 4.565862655639648
training step: 5971, total_loss: 4.259742736816406
training step: 5972, total_loss: 2.7349965572357178
training step: 5973, total_loss: 4.435813903808594
training step: 5974, total_loss: 2.8839492797851562
training step: 5975, total_loss: 3.1327311992645264
training step: 5976, total_loss: 4.359109401702881
training step: 5977, total_loss: 3.44819974899292
training step: 5978, total_loss: 6.725244045257568
training step: 5979, total_loss: 3.9223392009735107
training step: 5980, total_loss: 5.423636436462402
training step: 5981, total_loss: 4.183730602264404
training step: 5982, total_loss: 3.6869957447052
training step: 5983, total_loss: 4.308856010437012
training step: 5984, total_loss: 5.90688419342041
training step: 5985, total_loss: 4.782774448394775
training step: 5986, total_loss: 3.428560972213745
training step: 5987, total_loss: 5.109645843505859
training step: 5988, total_loss: 5.636100769042969
training step: 5989, total_loss: 4.1833109855651855
training step: 5990, total_loss: 5.370871067047119
training step: 5991, total_loss: 4.313453197479248
training step: 5992, total_loss: 5.331921577453613
training step: 5993, total_loss: 4.029360771179199
training step: 5994, total_loss: 4.204154968261719
training step: 5995, total_loss: 2.6734118461608887
training step: 5996, total_loss: 6.198880195617676
training step: 5997, total_loss: 4.11319637298584
training step: 5998, total_loss: 5.48457670211792
training step: 5999, total_loss: 4.352583885192871
training step: 6000, total_loss: 4.746400833129883
training step: 6001, total_loss: 3.337825059890747
training step: 6002, total_loss: 5.692005157470703
training step: 6003, total_loss: 5.99954891204834
training step: 6004, total_loss: 4.962108612060547
training step: 6005, total_loss: 4.041575908660889
training step: 6006, total_loss: 3.4517014026641846
training step: 6007, total_loss: 4.786590576171875
training step: 6008, total_loss: 5.164955139160156
training step: 6009, total_loss: 4.495864391326904
training step: 6010, total_loss: 4.933615684509277
training step: 6011, total_loss: 5.067508697509766
training step: 6012, total_loss: 5.054310321807861
training step: 6013, total_loss: 4.635152816772461
training step: 6014, total_loss: 6.446866035461426
training step: 6015, total_loss: 2.7021312713623047
training step: 6016, total_loss: 5.192605972290039
training step: 6017, total_loss: 4.350225925445557
training step: 6018, total_loss: 5.518810749053955
training step: 6019, total_loss: 4.408039093017578
training step: 6020, total_loss: 4.6222944259643555
training step: 6021, total_loss: 2.7841436862945557
training step: 6022, total_loss: 3.278975009918213
training step: 6023, total_loss: 4.679222106933594
training step: 6024, total_loss: 4.919476509094238
training step: 6025, total_loss: 5.416722297668457
training step: 6026, total_loss: 3.0546092987060547
training step: 6027, total_loss: 5.514279365539551
training step: 6028, total_loss: 1.8469202518463135
training step: 6029, total_loss: 5.305822372436523
training step: 6030, total_loss: 1.2935538291931152
training step: 6031, total_loss: 6.560715675354004
training step: 6032, total_loss: 4.879688262939453
training step: 6033, total_loss: 4.814546585083008
training step: 6034, total_loss: 5.508482933044434
training step: 6035, total_loss: 3.7617318630218506
training step: 6036, total_loss: 4.892509937286377
training step: 6037, total_loss: 4.073173522949219
training step: 6038, total_loss: 4.638689994812012
training step: 6039, total_loss: 5.563462734222412
training step: 6040, total_loss: 5.162163257598877
training step: 6041, total_loss: 6.024929046630859
training step: 6042, total_loss: 3.654568672180176
training step: 6043, total_loss: 3.9220292568206787
training step: 6044, total_loss: 4.576116561889648
training step: 6045, total_loss: 4.193232536315918
training step: 6046, total_loss: 4.811595916748047
training step: 6047, total_loss: 5.312108993530273
training step: 6048, total_loss: 4.692318916320801
training step: 6049, total_loss: 4.139575958251953
training step: 6050, total_loss: 4.909749984741211
training step: 6051, total_loss: 5.252723217010498
training step: 6052, total_loss: 3.6542367935180664
training step: 6053, total_loss: 5.1499924659729
training step: 6054, total_loss: 5.1237945556640625
training step: 6055, total_loss: 7.534917831420898
training step: 6056, total_loss: 3.46404767036438
training step: 6057, total_loss: 4.822905540466309
training step: 6058, total_loss: 4.303232192993164
training step: 6059, total_loss: 4.941598892211914
training step: 6060, total_loss: 2.889648675918579
training step: 6061, total_loss: 5.849181175231934
training step: 6062, total_loss: 5.264511585235596
training step: 6063, total_loss: 4.342806339263916
training step: 6064, total_loss: 6.07046365737915
training step: 6065, total_loss: 5.082250595092773
training step: 6066, total_loss: 6.095559120178223
training step: 6067, total_loss: 5.009726047515869
training step: 6068, total_loss: 5.614049911499023
training step: 6069, total_loss: 5.204556465148926
training step: 6070, total_loss: 3.1613566875457764
training step: 6071, total_loss: 5.399112224578857
training step: 6072, total_loss: 4.263424873352051
training step: 6073, total_loss: 6.785077095031738
training step: 6074, total_loss: 3.737586498260498
training step: 6075, total_loss: 5.45976448059082
training step: 6076, total_loss: 3.906177043914795
training step: 6077, total_loss: 4.915707588195801
training step: 6078, total_loss: 3.369624137878418
training step: 6079, total_loss: 4.110204696655273
training step: 6080, total_loss: 4.557439804077148
training step: 6081, total_loss: 4.998897075653076
training step: 6082, total_loss: 6.038113594055176
training step: 6083, total_loss: 3.1699323654174805
training step: 6084, total_loss: 5.138393402099609
training step: 6085, total_loss: 4.28794002532959
training step: 6086, total_loss: 4.628764629364014
training step: 6087, total_loss: 5.680037498474121
training step: 6088, total_loss: 3.751455783843994
training step: 6089, total_loss: 6.356904029846191
training step: 6090, total_loss: 4.42470645904541
training step: 6091, total_loss: 2.8822927474975586
training step: 6092, total_loss: 4.153197288513184
training step: 6093, total_loss: 5.442047595977783
training step: 6094, total_loss: 4.330975532531738
training step: 6095, total_loss: 3.3452279567718506
training step: 6096, total_loss: 4.441729545593262
training step: 6097, total_loss: 3.726853847503662
training step: 6098, total_loss: 2.2281203269958496
training step: 6099, total_loss: 3.6027679443359375
training step: 6100, total_loss: 4.3746747970581055
training step: 6101, total_loss: 4.2961602210998535
training step: 6102, total_loss: 4.327843189239502
training step: 6103, total_loss: 6.388458251953125
training step: 6104, total_loss: 4.102151393890381
training step: 6105, total_loss: 4.967695236206055
training step: 6106, total_loss: 0.4153004288673401
training step: 6107, total_loss: 4.540676116943359
training step: 6108, total_loss: 4.531516075134277
training step: 6109, total_loss: 6.468337059020996
training step: 6110, total_loss: 4.98484468460083
training step: 6111, total_loss: 6.095974445343018
training step: 6112, total_loss: 4.921561241149902
training step: 6113, total_loss: 1.855851650238037
training step: 6114, total_loss: 4.306431770324707
training step: 6115, total_loss: 5.9840521812438965
training step: 6116, total_loss: 6.794891834259033
training step: 6117, total_loss: 4.986053466796875
training step: 6118, total_loss: 5.253439903259277
training step: 6119, total_loss: 2.584757089614868
training step: 6120, total_loss: 0.5349658131599426
training step: 6121, total_loss: 4.655275344848633
training step: 6122, total_loss: 4.849084854125977
training step: 6123, total_loss: 5.910311698913574
training step: 6124, total_loss: 4.8394598960876465
training step: 6125, total_loss: 5.912215232849121
training step: 6126, total_loss: 5.619974136352539
training step: 6127, total_loss: 0.7551900148391724
training step: 6128, total_loss: 5.785659313201904
training step: 6129, total_loss: 6.5600199699401855
training step: 6130, total_loss: 5.070293426513672
training step: 6131, total_loss: 4.357961177825928
training step: 6132, total_loss: 4.236078262329102
training step: 6133, total_loss: 5.793754577636719
training step: 6134, total_loss: 4.636353492736816
training step: 6135, total_loss: 6.208388328552246
training step: 6136, total_loss: 4.7482805252075195
training step: 6137, total_loss: 5.742676734924316
training step: 6138, total_loss: 4.613531589508057
training step: 6139, total_loss: 5.020565032958984
training step: 6140, total_loss: 4.282321929931641
training step: 6141, total_loss: 5.929093360900879
training step: 6142, total_loss: 4.544198989868164
training step: 6143, total_loss: 5.182302951812744
training step: 6144, total_loss: 6.671712875366211
training step: 6145, total_loss: 4.723742485046387
training step: 6146, total_loss: 6.0235595703125
training step: 6147, total_loss: 5.561387062072754
training step: 6148, total_loss: 5.130613327026367
training step: 6149, total_loss: 4.790220260620117
training step: 6150, total_loss: 5.000411033630371
training step: 6151, total_loss: 4.6571455001831055
training step: 6152, total_loss: 4.803950309753418
training step: 6153, total_loss: 5.301836013793945
training step: 6154, total_loss: 4.478544235229492
training step: 6155, total_loss: 5.122350692749023
training step: 6156, total_loss: 4.155089855194092
training step: 6157, total_loss: 4.729795455932617
training step: 6158, total_loss: 4.186471939086914
training step: 6159, total_loss: 4.86053466796875
training step: 6160, total_loss: 4.873054504394531
training step: 6161, total_loss: 5.366692066192627
training step: 6162, total_loss: 4.963812351226807
training step: 6163, total_loss: 4.847671031951904
training step: 6164, total_loss: 4.419421672821045
training step: 6165, total_loss: 3.886960744857788
training step: 6166, total_loss: 4.772454261779785
training step: 6167, total_loss: 5.880468368530273
training step: 6168, total_loss: 4.967884540557861
training step: 6169, total_loss: 5.7767109870910645
training step: 6170, total_loss: 3.8961803913116455
training step: 6171, total_loss: 3.937546730041504
training step: 6172, total_loss: 4.117713928222656
training step: 6173, total_loss: 4.454743385314941
training step: 6174, total_loss: 5.892192363739014
training step: 6175, total_loss: 5.08657169342041
training step: 6176, total_loss: 5.48999547958374
training step: 6177, total_loss: 5.1482253074646
training step: 6178, total_loss: 4.518888473510742
training step: 6179, total_loss: 4.665349006652832
training step: 6180, total_loss: 4.982940673828125
training step: 6181, total_loss: 5.216194152832031
training step: 6182, total_loss: 3.4678382873535156
training step: 6183, total_loss: 3.8090274333953857
training step: 6184, total_loss: 3.974384307861328
training step: 6185, total_loss: 3.492800235748291
training step: 6186, total_loss: 4.310296535491943
training step: 6187, total_loss: 2.0365309715270996
training step: 6188, total_loss: 4.335964679718018
training step: 6189, total_loss: 4.671144962310791
training step: 6190, total_loss: 3.1789302825927734
training step: 6191, total_loss: 5.673295974731445
training step: 6192, total_loss: 4.387796878814697
training step: 6193, total_loss: 5.745798587799072
training step: 6194, total_loss: 4.101475238800049
training step: 6195, total_loss: 4.569095611572266
training step: 6196, total_loss: 4.872112274169922
training step: 6197, total_loss: 2.245906352996826
training step: 6198, total_loss: 2.364956855773926
training step: 6199, total_loss: 4.61320686340332
training step: 6200, total_loss: 4.746417999267578
training step: 6201, total_loss: 4.8075175285339355
training step: 6202, total_loss: 5.027588367462158
training step: 6203, total_loss: 4.408408164978027
training step: 6204, total_loss: 6.291160583496094
training step: 6205, total_loss: 6.290031433105469
training step: 6206, total_loss: 4.808450698852539
training step: 6207, total_loss: 5.004806995391846
training step: 6208, total_loss: 4.135548114776611
training step: 6209, total_loss: 5.881609916687012
training step: 6210, total_loss: 6.3001604080200195
training step: 6211, total_loss: 5.201011657714844
training step: 6212, total_loss: 5.316694736480713
training step: 6213, total_loss: 5.343593597412109
training step: 6214, total_loss: 5.17441463470459
training step: 6215, total_loss: 5.048934459686279
training step: 6216, total_loss: 4.393563270568848
training step: 6217, total_loss: 5.232024192810059
training step: 6218, total_loss: 5.178287029266357
training step: 6219, total_loss: 5.048979759216309
training step: 6220, total_loss: 1.8199729919433594
training step: 6221, total_loss: 5.281615257263184
training step: 6222, total_loss: 4.8861002922058105
training step: 6223, total_loss: 3.375908374786377
training step: 6224, total_loss: 2.5294055938720703
training step: 6225, total_loss: 3.550076723098755
training step: 6226, total_loss: 5.064198017120361
training step: 6227, total_loss: 4.63378381729126
training step: 6228, total_loss: 5.418929576873779
training step: 6229, total_loss: 5.102057456970215
training step: 6230, total_loss: 5.074544906616211
training step: 6231, total_loss: 4.741935729980469
training step: 6232, total_loss: 4.672935485839844
training step: 6233, total_loss: 4.528571128845215
training step: 6234, total_loss: 5.40098762512207
training step: 6235, total_loss: 4.620379447937012
training step: 6236, total_loss: 5.529441833496094
training step: 6237, total_loss: 4.37846565246582
training step: 6238, total_loss: 4.354438781738281
training step: 6239, total_loss: 3.3289473056793213
training step: 6240, total_loss: 0.8785108327865601
training step: 6241, total_loss: 4.971957206726074
training step: 6242, total_loss: 4.367321491241455
training step: 6243, total_loss: 4.287778854370117
training step: 6244, total_loss: 4.702786445617676
training step: 6245, total_loss: 4.43114709854126
training step: 6246, total_loss: 3.804147481918335
training step: 6247, total_loss: 5.613579273223877
training step: 6248, total_loss: 4.524846076965332
training step: 6249, total_loss: 4.696451187133789
training step: 6250, total_loss: 4.623682022094727
training step: 6251, total_loss: 5.872770309448242
training step: 6252, total_loss: 4.7576189041137695
training step: 6253, total_loss: 5.029256820678711
training step: 6254, total_loss: 5.31632137298584
training step: 6255, total_loss: 5.406723976135254
training step: 6256, total_loss: 4.536627769470215
training step: 6257, total_loss: 4.096658229827881
training step: 6258, total_loss: 5.6122589111328125
training step: 6259, total_loss: 3.8284645080566406
training step: 6260, total_loss: 5.8187642097473145
training step: 6261, total_loss: 5.223849296569824
training step: 6262, total_loss: 4.154995918273926
training step: 6263, total_loss: 5.348381996154785
training step: 6264, total_loss: 5.264707565307617
training step: 6265, total_loss: 4.991572380065918
training step: 6266, total_loss: 5.614506721496582
training step: 6267, total_loss: 3.6117305755615234
training step: 6268, total_loss: 4.428470134735107
training step: 6269, total_loss: 4.2084503173828125
training step: 6270, total_loss: 5.14110803604126
training step: 6271, total_loss: 4.80368709564209
training step: 6272, total_loss: 3.9162964820861816
training step: 6273, total_loss: 4.351564407348633
training step: 6274, total_loss: 4.795502185821533
training step: 6275, total_loss: 4.286866188049316
training step: 6276, total_loss: 4.440802574157715
training step: 6277, total_loss: 4.8890380859375
training step: 6278, total_loss: 5.107771873474121
training step: 6279, total_loss: 4.269223213195801
training step: 6280, total_loss: 3.4907474517822266
training step: 6281, total_loss: 4.743995666503906
training step: 6282, total_loss: 6.1238627433776855
training step: 6283, total_loss: 2.8021247386932373
training step: 6284, total_loss: 5.654712200164795
training step: 6285, total_loss: 6.50152587890625
training step: 6286, total_loss: 4.852842330932617
training step: 6287, total_loss: 5.580519676208496
training step: 6288, total_loss: 5.22952938079834
training step: 6289, total_loss: 4.637054920196533
training step: 6290, total_loss: 5.031650066375732
training step: 6291, total_loss: 5.752901077270508
training step: 6292, total_loss: 5.433802604675293
training step: 6293, total_loss: 4.749991416931152
training step: 6294, total_loss: 3.9492921829223633
training step: 6295, total_loss: 5.423710823059082
training step: 6296, total_loss: 4.184077262878418
training step: 6297, total_loss: 4.516334533691406
training step: 6298, total_loss: 6.158130645751953
training step: 6299, total_loss: 4.246333122253418
training step: 6300, total_loss: 4.534926414489746
training step: 6301, total_loss: 5.254610061645508
training step: 6302, total_loss: 4.833006858825684
training step: 6303, total_loss: 5.5996317863464355
training step: 6304, total_loss: 4.823856830596924
training step: 6305, total_loss: 5.406435966491699
training step: 6306, total_loss: 5.61851692199707
training step: 6307, total_loss: 3.9468774795532227
training step: 6308, total_loss: 4.789618968963623
training step: 6309, total_loss: 4.55019474029541
training step: 6310, total_loss: 4.96415901184082
training step: 6311, total_loss: 4.922544956207275
training step: 6312, total_loss: 6.060551643371582
training step: 6313, total_loss: 4.0745930671691895
training step: 6314, total_loss: 5.669927597045898
training step: 6315, total_loss: 5.582745552062988
training step: 6316, total_loss: 4.402497291564941
training step: 6317, total_loss: 5.122422218322754
training step: 6318, total_loss: 5.280498504638672
training step: 6319, total_loss: 3.665628433227539
training step: 6320, total_loss: 4.816329002380371
training step: 6321, total_loss: 4.756311893463135
training step: 6322, total_loss: 4.92085075378418
training step: 6323, total_loss: 4.330815315246582
training step: 6324, total_loss: 3.4347031116485596
training step: 6325, total_loss: 5.542203426361084
training step: 6326, total_loss: 3.98370623588562
training step: 6327, total_loss: 4.688856601715088
training step: 6328, total_loss: 4.762178897857666
training step: 6329, total_loss: 4.971992492675781
training step: 6330, total_loss: 4.767209053039551
training step: 6331, total_loss: 4.201632022857666
training step: 6332, total_loss: 4.6719069480896
training step: 6333, total_loss: 4.939621925354004
training step: 6334, total_loss: 5.770051956176758
training step: 6335, total_loss: 3.7071266174316406
training step: 6336, total_loss: 3.772820234298706
training step: 6337, total_loss: 4.0499186515808105
training step: 6338, total_loss: 5.136747360229492
training step: 6339, total_loss: 4.535833358764648
training step: 6340, total_loss: 4.5071187019348145
training step: 6341, total_loss: 4.984021186828613
training step: 6342, total_loss: 4.456559181213379
training step: 6343, total_loss: 4.367912292480469
training step: 6344, total_loss: 3.9728503227233887
training step: 6345, total_loss: 5.092764854431152
training step: 6346, total_loss: 4.369891166687012
training step: 6347, total_loss: 5.450113296508789
training step: 6348, total_loss: 4.0175557136535645
training step: 6349, total_loss: 5.3222856521606445
training step: 6350, total_loss: 4.370481967926025
training step: 6351, total_loss: 4.766287326812744
training step: 6352, total_loss: 6.43704891204834
training step: 6353, total_loss: 6.499935150146484
training step: 6354, total_loss: 4.386516571044922
training step: 6355, total_loss: 5.502143859863281
training step: 6356, total_loss: 5.323627471923828
training step: 6357, total_loss: 4.580801963806152
training step: 6358, total_loss: 5.041299819946289
training step: 6359, total_loss: 4.55927038192749
training step: 6360, total_loss: 3.380772829055786
training step: 6361, total_loss: 5.096587181091309
training step: 6362, total_loss: 5.077634334564209
training step: 6363, total_loss: 4.342392921447754
training step: 6364, total_loss: 5.059840202331543
training step: 6365, total_loss: 4.175436973571777
training step: 6366, total_loss: 3.6167521476745605
training step: 6367, total_loss: 5.397871494293213
training step: 6368, total_loss: 4.458322525024414
training step: 6369, total_loss: 4.6256914138793945
training step: 6370, total_loss: 4.729766368865967
training step: 6371, total_loss: 2.66855788230896
training step: 6372, total_loss: 5.30069637298584
training step: 6373, total_loss: 4.248291015625
training step: 6374, total_loss: 4.081870079040527
training step: 6375, total_loss: 2.674736261367798
training step: 6376, total_loss: 5.504055023193359
training step: 6377, total_loss: 4.011884689331055
training step: 6378, total_loss: 4.882235527038574
training step: 6379, total_loss: 5.375520706176758
training step: 6380, total_loss: 4.718561172485352
training step: 6381, total_loss: 5.022593021392822
training step: 6382, total_loss: 5.32463264465332
training step: 6383, total_loss: 4.334569454193115
training step: 6384, total_loss: 4.585927486419678
training step: 6385, total_loss: 5.152245044708252
training step: 6386, total_loss: 6.060602188110352
training step: 6387, total_loss: 5.188689231872559
training step: 6388, total_loss: 4.903810024261475
training step: 6389, total_loss: 3.125016212463379
training step: 6390, total_loss: 4.512054920196533
training step: 6391, total_loss: 6.072726726531982
training step: 6392, total_loss: 6.139285564422607
training step: 6393, total_loss: 4.191469192504883
training step: 6394, total_loss: 5.028633117675781
training step: 6395, total_loss: 4.546962738037109
training step: 6396, total_loss: 4.2017107009887695
training step: 6397, total_loss: 4.479580402374268
training step: 6398, total_loss: 4.418632984161377
training step: 6399, total_loss: 5.377859592437744
training step: 6400, total_loss: 5.679696083068848
training step: 6401, total_loss: 5.3393964767456055
training step: 6402, total_loss: 6.4850873947143555
training step: 6403, total_loss: 4.757535934448242
training step: 6404, total_loss: 3.6555747985839844
training step: 6405, total_loss: 5.062335014343262
training step: 6406, total_loss: 4.172443866729736
training step: 6407, total_loss: 3.3360397815704346
training step: 6408, total_loss: 5.034457206726074
training step: 6409, total_loss: 3.762345552444458
training step: 6410, total_loss: 6.536748886108398
training step: 6411, total_loss: 7.081416130065918
training step: 6412, total_loss: 5.236591815948486
training step: 6413, total_loss: 4.974569797515869
training step: 6414, total_loss: 4.037031650543213
training step: 6415, total_loss: 4.542830944061279
training step: 6416, total_loss: 5.022695541381836
training step: 6417, total_loss: 6.7501702308654785
training step: 6418, total_loss: 2.400160312652588
training step: 6419, total_loss: 4.906129837036133
training step: 6420, total_loss: 4.523116111755371
training step: 6421, total_loss: 2.8088974952697754
training step: 6422, total_loss: 3.958481550216675
training step: 6423, total_loss: 4.412753582000732
training step: 6424, total_loss: 4.857682704925537
training step: 6425, total_loss: 2.013139486312866
training step: 6426, total_loss: 3.8133959770202637
training step: 6427, total_loss: 4.877335548400879
training step: 6428, total_loss: 4.315811634063721
training step: 6429, total_loss: 4.958173751831055
training step: 6430, total_loss: 4.9068379402160645
training step: 6431, total_loss: 3.5019707679748535
training step: 6432, total_loss: 4.582428932189941
training step: 6433, total_loss: 5.965244293212891
training step: 6434, total_loss: 5.051082611083984
training step: 6435, total_loss: 4.255472183227539
training step: 6436, total_loss: 5.000400543212891
training step: 6437, total_loss: 3.589510679244995
training step: 6438, total_loss: 4.527622222900391
training step: 6439, total_loss: 4.464412689208984
training step: 6440, total_loss: 4.382841110229492
training step: 6441, total_loss: 4.972922325134277
training step: 6442, total_loss: 4.143566131591797
training step: 6443, total_loss: 4.77200174331665
training step: 6444, total_loss: 4.69964599609375
training step: 6445, total_loss: 4.318306922912598
training step: 6446, total_loss: 4.7969465255737305
training step: 6447, total_loss: 6.239068031311035
training step: 6448, total_loss: 5.277340888977051
training step: 6449, total_loss: 2.015859603881836
training step: 6450, total_loss: 4.222339153289795
training step: 6451, total_loss: 4.517940044403076
training step: 6452, total_loss: 5.8347673416137695
training step: 6453, total_loss: 5.626637935638428
training step: 6454, total_loss: 4.720457077026367
training step: 6455, total_loss: 4.3354597091674805
training step: 6456, total_loss: 3.6683754920959473
training step: 6457, total_loss: 6.942875862121582
training step: 6458, total_loss: 3.7879323959350586
training step: 6459, total_loss: 4.302084922790527
training step: 6460, total_loss: 4.425022125244141
training step: 6461, total_loss: 4.931150436401367
training step: 6462, total_loss: 4.709766387939453
training step: 6463, total_loss: 4.424822807312012
training step: 6464, total_loss: 4.524101734161377
training step: 6465, total_loss: 6.265988349914551
training step: 6466, total_loss: 5.652439594268799
training step: 6467, total_loss: 4.920836448669434
training step: 6468, total_loss: 5.247416973114014
training step: 6469, total_loss: 7.498705863952637
training step: 6470, total_loss: 5.6979875564575195
training step: 6471, total_loss: 4.611032009124756
training step: 6472, total_loss: 5.242608547210693
training step: 6473, total_loss: 4.196444511413574
training step: 6474, total_loss: 5.214608192443848
training step: 6475, total_loss: 5.224390983581543
training step: 6476, total_loss: 4.995715618133545
training step: 6477, total_loss: 4.47857141494751
training step: 6478, total_loss: 3.87760591506958
training step: 6479, total_loss: 4.921446323394775
training step: 6480, total_loss: 4.704501628875732
training step: 6481, total_loss: 2.1884913444519043
training step: 6482, total_loss: 5.162050247192383
training step: 6483, total_loss: 5.283718109130859
training step: 6484, total_loss: 4.629286766052246
training step: 6485, total_loss: 4.1717529296875
training step: 6486, total_loss: 3.8092660903930664
training step: 6487, total_loss: 6.1143975257873535
training step: 6488, total_loss: 4.522359848022461
training step: 6489, total_loss: 3.431469440460205
training step: 6490, total_loss: 2.411616325378418
training step: 6491, total_loss: 5.595335960388184
training step: 6492, total_loss: 3.9869441986083984
training step: 6493, total_loss: 5.0283660888671875
training step: 6494, total_loss: 4.072425842285156
training step: 6495, total_loss: 5.284528732299805
training step: 6496, total_loss: 2.635688066482544
training step: 6497, total_loss: 3.304800033569336
training step: 6498, total_loss: 6.96561336517334
training step: 6499, total_loss: 5.674493312835693
training step: 6500, total_loss: 4.6638898849487305
training step: 6501, total_loss: 5.0604658126831055
training step: 6502, total_loss: 5.703136444091797
training step: 6503, total_loss: 4.419795513153076
training step: 6504, total_loss: 4.335302352905273
training step: 6505, total_loss: 4.502624034881592
training step: 6506, total_loss: 4.743268013000488
training step: 6507, total_loss: 3.047996759414673
training step: 6508, total_loss: 5.220164775848389
training step: 6509, total_loss: 3.9988033771514893
training step: 6510, total_loss: 4.993674278259277
training step: 6511, total_loss: 5.3985161781311035
training step: 6512, total_loss: 4.054847717285156
training step: 6513, total_loss: 3.5832061767578125
training step: 6514, total_loss: 1.1217811107635498
training step: 6515, total_loss: 4.938927173614502
training step: 6516, total_loss: 6.27950382232666
training step: 6517, total_loss: 4.958813667297363
training step: 6518, total_loss: 3.681008815765381
training step: 6519, total_loss: 5.3012919425964355
training step: 6520, total_loss: 3.3249945640563965
training step: 6521, total_loss: 4.882202625274658
training step: 6522, total_loss: 4.2993669509887695
training step: 6523, total_loss: 5.044355392456055
training step: 6524, total_loss: 4.685447692871094
training step: 6525, total_loss: 4.253685474395752
training step: 6526, total_loss: 1.4585610628128052
training step: 6527, total_loss: 4.624659538269043
training step: 6528, total_loss: 3.1184778213500977
training step: 6529, total_loss: 4.563896656036377
training step: 6530, total_loss: 4.395993232727051
training step: 6531, total_loss: 4.79515266418457
training step: 6532, total_loss: 5.553577423095703
training step: 6533, total_loss: 4.374014854431152
training step: 6534, total_loss: 4.38482141494751
training step: 6535, total_loss: 5.257076263427734
training step: 6536, total_loss: 5.236730098724365
training step: 6537, total_loss: 4.588857173919678
training step: 6538, total_loss: 3.801420211791992
training step: 6539, total_loss: 1.330432653427124
training step: 6540, total_loss: 5.275574684143066
training step: 6541, total_loss: 4.893122673034668
training step: 6542, total_loss: 4.9200520515441895
training step: 6543, total_loss: 5.053745269775391
training step: 6544, total_loss: 5.581648826599121
training step: 6545, total_loss: 5.259389877319336
training step: 6546, total_loss: 7.194228172302246
training step: 6547, total_loss: 4.110568523406982
training step: 6548, total_loss: 5.063981056213379
training step: 6549, total_loss: 5.707120895385742
training step: 6550, total_loss: 3.0719871520996094
training step: 6551, total_loss: 2.914545774459839
training step: 6552, total_loss: 5.855554103851318
training step: 6553, total_loss: 5.842592716217041
training step: 6554, total_loss: 4.483950614929199
training step: 6555, total_loss: 5.426973342895508
training step: 6556, total_loss: 1.7997218370437622
training step: 6557, total_loss: 4.38377571105957
training step: 6558, total_loss: 4.3118720054626465
training step: 6559, total_loss: 4.533820629119873
training step: 6560, total_loss: 5.717533588409424
training step: 6561, total_loss: 5.389510154724121
training step: 6562, total_loss: 5.329642295837402
training step: 6563, total_loss: 4.498162269592285
training step: 6564, total_loss: 4.892937660217285
training step: 6565, total_loss: 4.974820137023926
training step: 6566, total_loss: 5.115489959716797
training step: 6567, total_loss: 5.647442817687988
training step: 6568, total_loss: 4.748294830322266
training step: 6569, total_loss: 5.550766944885254
training step: 6570, total_loss: 5.521332740783691
training step: 6571, total_loss: 4.379344463348389
training step: 6572, total_loss: 5.1722412109375
training step: 6573, total_loss: 4.966353416442871
training step: 6574, total_loss: 4.0351057052612305
training step: 6575, total_loss: 3.677126884460449
training step: 6576, total_loss: 3.553760051727295
training step: 6577, total_loss: 3.952035427093506
training step: 6578, total_loss: 3.8210866451263428
training step: 6579, total_loss: 5.767987251281738
training step: 6580, total_loss: 6.339090347290039
training step: 6581, total_loss: 3.4393413066864014
training step: 6582, total_loss: 4.894635200500488
training step: 6583, total_loss: 5.048618316650391
training step: 6584, total_loss: 4.415308952331543
training step: 6585, total_loss: 5.014667510986328
training step: 6586, total_loss: 4.543091773986816
training step: 6587, total_loss: 4.443211078643799
training step: 6588, total_loss: 6.9779052734375
training step: 6589, total_loss: 4.742293834686279
training step: 6590, total_loss: 3.908738613128662
training step: 6591, total_loss: 5.07929801940918
training step: 6592, total_loss: 3.066161632537842
training step: 6593, total_loss: 4.3318634033203125
training step: 6594, total_loss: 5.475056171417236
training step: 6595, total_loss: 6.495968341827393
training step: 6596, total_loss: 4.629612445831299
training step: 6597, total_loss: 4.4802446365356445
training step: 6598, total_loss: 3.873222827911377
training step: 6599, total_loss: 5.851537704467773
training step: 6600, total_loss: 3.8233275413513184
training step: 6601, total_loss: 4.372418403625488
training step: 6602, total_loss: 4.3944807052612305
training step: 6603, total_loss: 5.068125247955322
training step: 6604, total_loss: 5.69405460357666
training step: 6605, total_loss: 4.213059425354004
training step: 6606, total_loss: 4.618124961853027
training step: 6607, total_loss: 4.3243489265441895
training step: 6608, total_loss: 4.984708786010742
training step: 6609, total_loss: 4.383685111999512
training step: 6610, total_loss: 6.129457473754883
training step: 6611, total_loss: 4.661578178405762
training step: 6612, total_loss: 6.272953033447266
training step: 6613, total_loss: 6.3672027587890625
training step: 6614, total_loss: 4.3415679931640625
training step: 6615, total_loss: 4.709863185882568
training step: 6616, total_loss: 4.179763317108154
training step: 6617, total_loss: 3.583061695098877
training step: 6618, total_loss: 5.918339252471924
training step: 6619, total_loss: 5.541701793670654
training step: 6620, total_loss: 3.9673893451690674
training step: 6621, total_loss: 4.905307769775391
training step: 6622, total_loss: 5.931429862976074
training step: 6623, total_loss: 4.56373405456543
training step: 6624, total_loss: 5.231497764587402
training step: 6625, total_loss: 5.033805847167969
training step: 6626, total_loss: 4.371274471282959
training step: 6627, total_loss: 6.195733070373535
training step: 6628, total_loss: 4.3829264640808105
training step: 6629, total_loss: 4.40353536605835
training step: 6630, total_loss: 4.722854137420654
training step: 6631, total_loss: 5.824039459228516
training step: 6632, total_loss: 4.885011672973633
training step: 6633, total_loss: 4.181133270263672
training step: 6634, total_loss: 4.98917818069458
training step: 6635, total_loss: 5.154474258422852
training step: 6636, total_loss: 4.441431999206543
training step: 6637, total_loss: 5.33695125579834
training step: 6638, total_loss: 5.146785259246826
training step: 6639, total_loss: 4.874939918518066
training step: 6640, total_loss: 4.470100402832031
training step: 6641, total_loss: 4.620279788970947
training step: 6642, total_loss: 4.48036527633667
training step: 6643, total_loss: 4.424683570861816
training step: 6644, total_loss: 4.619364261627197
training step: 6645, total_loss: 4.821501731872559
training step: 6646, total_loss: 4.768166542053223
training step: 6647, total_loss: 4.6763505935668945
training step: 6648, total_loss: 7.3766679763793945
training step: 6649, total_loss: 6.212085723876953
training step: 6650, total_loss: 4.261508464813232
training step: 6651, total_loss: 4.642557144165039
training step: 6652, total_loss: 4.739178657531738
training step: 6653, total_loss: 3.7473769187927246
training step: 6654, total_loss: 4.400476932525635
training step: 6655, total_loss: 4.622821807861328
training step: 6656, total_loss: 4.165074825286865
training step: 6657, total_loss: 6.447758674621582
training step: 6658, total_loss: 4.503015995025635
training step: 6659, total_loss: 4.650364875793457
training step: 6660, total_loss: 3.193011999130249
training step: 6661, total_loss: 4.845521926879883
training step: 6662, total_loss: 5.76219367980957
training step: 6663, total_loss: 4.5903496742248535
training step: 6664, total_loss: 3.9410400390625
training step: 6665, total_loss: 4.999548435211182
training step: 6666, total_loss: 3.5218453407287598
training step: 6667, total_loss: 4.920935153961182
training step: 6668, total_loss: 5.1324005126953125
training step: 6669, total_loss: 4.225837707519531
training step: 6670, total_loss: 4.524257659912109
training step: 6671, total_loss: 4.016299724578857
training step: 6672, total_loss: 5.119800090789795
training step: 6673, total_loss: 5.237741947174072
training step: 6674, total_loss: 5.890852928161621
training step: 6675, total_loss: 3.0564422607421875
training step: 6676, total_loss: 6.111865520477295
training step: 6677, total_loss: 4.587808132171631
training step: 6678, total_loss: 4.213995456695557
training step: 6679, total_loss: 4.550970077514648
training step: 6680, total_loss: 4.263339996337891
training step: 6681, total_loss: 6.2445573806762695
training step: 6682, total_loss: 4.391993522644043
training step: 6683, total_loss: 4.498054504394531
training step: 6684, total_loss: 4.51089334487915
training step: 6685, total_loss: 5.317826271057129
training step: 6686, total_loss: 5.220949649810791
training step: 6687, total_loss: 3.9120399951934814
training step: 6688, total_loss: 3.6441245079040527
training step: 6689, total_loss: 5.377392768859863
training step: 6690, total_loss: 5.587508201599121
training step: 6691, total_loss: 3.841672420501709
training step: 6692, total_loss: 5.253500938415527
training step: 6693, total_loss: 6.272103309631348
training step: 6694, total_loss: 5.268782615661621
training step: 6695, total_loss: 4.86898946762085
training step: 6696, total_loss: 5.204876899719238
training step: 6697, total_loss: 5.679490089416504
training step: 6698, total_loss: 2.638866662979126
training step: 6699, total_loss: 4.52805757522583
training step: 6700, total_loss: 5.084111213684082
training step: 6701, total_loss: 4.476009845733643
training step: 6702, total_loss: 4.650703430175781
training step: 6703, total_loss: 4.388775825500488
training step: 6704, total_loss: 3.6972949504852295
training step: 6705, total_loss: 4.465946197509766
training step: 6706, total_loss: 4.2044525146484375
training step: 6707, total_loss: 4.689859390258789
training step: 6708, total_loss: 4.681337833404541
training step: 6709, total_loss: 4.798828125
training step: 6710, total_loss: 5.161550998687744
training step: 6711, total_loss: 3.9472317695617676
training step: 6712, total_loss: 5.897806167602539
training step: 6713, total_loss: 5.156867980957031
training step: 6714, total_loss: 2.8180465698242188
training step: 6715, total_loss: 4.383840084075928
training step: 6716, total_loss: 2.373678207397461
training step: 6717, total_loss: 5.987208843231201
training step: 6718, total_loss: 4.558199882507324
training step: 6719, total_loss: 4.752594947814941
training step: 6720, total_loss: 5.4793291091918945
training step: 6721, total_loss: 4.979466438293457
training step: 6722, total_loss: 5.007835865020752
training step: 6723, total_loss: 5.447473526000977
training step: 6724, total_loss: 4.667809963226318
training step: 6725, total_loss: 4.8502044677734375
training step: 6726, total_loss: 4.556007385253906
training step: 6727, total_loss: 2.9551291465759277
training step: 6728, total_loss: 5.6987385749816895
training step: 6729, total_loss: 3.918785572052002
training step: 6730, total_loss: 4.198853969573975
training step: 6731, total_loss: 3.166327476501465
training step: 6732, total_loss: 4.51273250579834
training step: 6733, total_loss: 6.139885425567627
training step: 6734, total_loss: 4.3346710205078125
training step: 6735, total_loss: 4.559523582458496
training step: 6736, total_loss: 5.816823959350586
training step: 6737, total_loss: 4.885315418243408
training step: 6738, total_loss: 3.085000514984131
training step: 6739, total_loss: 2.8013899326324463
training step: 6740, total_loss: 4.384476661682129
training step: 6741, total_loss: 3.164797306060791
training step: 6742, total_loss: 6.96720027923584
training step: 6743, total_loss: 5.145197868347168
training step: 6744, total_loss: 5.453175067901611
training step: 6745, total_loss: 3.9647648334503174
training step: 6746, total_loss: 5.716107368469238
training step: 6747, total_loss: 2.4961466789245605
training step: 6748, total_loss: 3.4879255294799805
training step: 6749, total_loss: 4.2583184242248535
training step: 6750, total_loss: 4.939749240875244
training step: 6751, total_loss: 4.490571022033691
training step: 6752, total_loss: 4.229216575622559
training step: 6753, total_loss: 3.8949036598205566
training step: 6754, total_loss: 4.165315628051758
training step: 6755, total_loss: 5.141705513000488
training step: 6756, total_loss: 2.75171160697937
training step: 6757, total_loss: 5.341033935546875
training step: 6758, total_loss: 3.018500328063965
training step: 6759, total_loss: 4.561837196350098
training step: 6760, total_loss: 6.357161521911621
training step: 6761, total_loss: 4.912477493286133
training step: 6762, total_loss: 6.216987609863281
training step: 6763, total_loss: 4.956171035766602
training step: 6764, total_loss: 5.369289875030518
training step: 6765, total_loss: 5.09365177154541
training step: 6766, total_loss: 4.145080089569092
training step: 6767, total_loss: 3.9896671772003174
training step: 6768, total_loss: 1.7406303882598877
training step: 6769, total_loss: 5.7813720703125
training step: 6770, total_loss: 3.17116117477417
training step: 6771, total_loss: 5.304539203643799
training step: 6772, total_loss: 3.7239034175872803
training step: 6773, total_loss: 4.2045135498046875
training step: 6774, total_loss: 4.948407173156738
training step: 6775, total_loss: 3.4194936752319336
training step: 6776, total_loss: 4.7023539543151855
training step: 6777, total_loss: 5.381707191467285
training step: 6778, total_loss: 4.608691215515137
training step: 6779, total_loss: 5.738999366760254
training step: 6780, total_loss: 6.298211097717285
training step: 6781, total_loss: 4.918159008026123
training step: 6782, total_loss: 4.459376335144043
training step: 6783, total_loss: 3.726402997970581
training step: 6784, total_loss: 5.506387233734131
training step: 6785, total_loss: 5.977714538574219
training step: 6786, total_loss: 4.352322101593018
training step: 6787, total_loss: 4.188106536865234
training step: 6788, total_loss: 5.0317230224609375
training step: 6789, total_loss: 4.83306360244751
training step: 6790, total_loss: 5.335641860961914
training step: 6791, total_loss: 3.007631778717041
training step: 6792, total_loss: 3.610835552215576
training step: 6793, total_loss: 0.9567727446556091
training step: 6794, total_loss: 4.147153854370117
training step: 6795, total_loss: 5.860289573669434
training step: 6796, total_loss: 4.150136470794678
training step: 6797, total_loss: 3.5716986656188965
training step: 6798, total_loss: 5.528393745422363
training step: 6799, total_loss: 4.475188255310059
training step: 6800, total_loss: 2.106285333633423
training step: 6801, total_loss: 5.757061004638672
training step: 6802, total_loss: 4.811959743499756
training step: 6803, total_loss: 4.883816719055176
training step: 6804, total_loss: 4.088621139526367
training step: 6805, total_loss: 3.685602903366089
training step: 6806, total_loss: 3.050626754760742
training step: 6807, total_loss: 5.1834797859191895
training step: 6808, total_loss: 4.357767105102539
training step: 6809, total_loss: 5.218476295471191
training step: 6810, total_loss: 5.226832389831543
training step: 6811, total_loss: 4.6044158935546875
training step: 6812, total_loss: 3.2444610595703125
training step: 6813, total_loss: 5.064365386962891
training step: 6814, total_loss: 4.545613765716553
training step: 6815, total_loss: 7.632038593292236
training step: 6816, total_loss: 4.382586479187012
training step: 6817, total_loss: 5.282170295715332
training step: 6818, total_loss: 5.536623001098633
training step: 6819, total_loss: 5.572694778442383
training step: 6820, total_loss: 5.504590034484863
training step: 6821, total_loss: 4.802032470703125
training step: 6822, total_loss: 5.096937656402588
training step: 6823, total_loss: 4.08791446685791
training step: 6824, total_loss: 4.544614315032959
training step: 6825, total_loss: 4.291424751281738
training step: 6826, total_loss: 6.143474578857422
training step: 6827, total_loss: 4.466283798217773
training step: 6828, total_loss: 3.7726919651031494
training step: 6829, total_loss: 6.244905471801758
training step: 6830, total_loss: 4.309869766235352
training step: 6831, total_loss: 5.31320858001709
training step: 6832, total_loss: 4.601222991943359
training step: 6833, total_loss: 5.538848876953125
training step: 6834, total_loss: 4.273865222930908
training step: 6835, total_loss: 4.671342372894287
training step: 6836, total_loss: 5.8540940284729
training step: 6837, total_loss: 5.20142936706543
training step: 6838, total_loss: 4.117358207702637
training step: 6839, total_loss: 5.160860061645508
training step: 6840, total_loss: 5.625431060791016
training step: 6841, total_loss: 4.462324142456055
training step: 6842, total_loss: 3.815742254257202
training step: 6843, total_loss: 3.9665071964263916
training step: 6844, total_loss: 4.197713851928711
training step: 6845, total_loss: 4.030966281890869
training step: 6846, total_loss: 5.558653831481934
training step: 6847, total_loss: 5.577237129211426
training step: 6848, total_loss: 5.200104713439941
training step: 6849, total_loss: 3.852367401123047
training step: 6850, total_loss: 3.517366886138916
training step: 6851, total_loss: 5.455703258514404
training step: 6852, total_loss: 3.9244942665100098
training step: 6853, total_loss: 4.726006507873535
training step: 6854, total_loss: 6.905426979064941
training step: 6855, total_loss: 4.628478050231934
training step: 6856, total_loss: 5.410138130187988
training step: 6857, total_loss: 4.46250057220459
training step: 6858, total_loss: 4.619183540344238
training step: 6859, total_loss: 4.544661998748779
training step: 6860, total_loss: 3.756126880645752
training step: 6861, total_loss: 5.044965744018555
training step: 6862, total_loss: 5.423269271850586
training step: 6863, total_loss: 5.958454608917236
training step: 6864, total_loss: 3.6046128273010254
training step: 6865, total_loss: 5.327465057373047
training step: 6866, total_loss: 4.930102825164795
training step: 6867, total_loss: 4.782425880432129
training step: 6868, total_loss: 3.5678892135620117
training step: 6869, total_loss: 5.368983268737793
training step: 6870, total_loss: 4.134228706359863
training step: 6871, total_loss: 4.020151138305664
training step: 6872, total_loss: 5.7211761474609375
training step: 6873, total_loss: 5.966991424560547
training step: 6874, total_loss: 5.169963836669922
training step: 6875, total_loss: 5.319856643676758
training step: 6876, total_loss: 4.53285026550293
training step: 6877, total_loss: 4.076522350311279
training step: 6878, total_loss: 6.178579807281494
training step: 6879, total_loss: 5.518377780914307
training step: 6880, total_loss: 4.320685863494873
training step: 6881, total_loss: 4.775567054748535
training step: 6882, total_loss: 5.539089202880859
training step: 6883, total_loss: 4.0819549560546875
training step: 6884, total_loss: 5.144585609436035
training step: 6885, total_loss: 6.412243366241455
training step: 6886, total_loss: 3.620851993560791
training step: 6887, total_loss: 3.9778003692626953
training step: 6888, total_loss: 3.6410422325134277
training step: 6889, total_loss: 5.322425842285156
training step: 6890, total_loss: 4.5847320556640625
training step: 6891, total_loss: 6.397851943969727
training step: 6892, total_loss: 3.857856273651123
training step: 6893, total_loss: 3.9484314918518066
training step: 6894, total_loss: 2.704549789428711
training step: 6895, total_loss: 5.545335292816162
training step: 6896, total_loss: 3.3139100074768066
training step: 6897, total_loss: 3.3701910972595215
training step: 6898, total_loss: 5.091553688049316
training step: 6899, total_loss: 4.596440315246582
training step: 6900, total_loss: 4.886325359344482
training step: 6901, total_loss: 4.916071891784668
training step: 6902, total_loss: 3.7266640663146973
training step: 6903, total_loss: 1.2369533777236938
training step: 6904, total_loss: 2.7000246047973633
training step: 6905, total_loss: 5.176122188568115
training step: 6906, total_loss: 5.284295082092285
training step: 6907, total_loss: 4.637662887573242
training step: 6908, total_loss: 5.439177513122559
training step: 6909, total_loss: 5.017594337463379
training step: 6910, total_loss: 3.8097615242004395
training step: 6911, total_loss: 5.300128936767578
training step: 6912, total_loss: 4.089500427246094
training step: 6913, total_loss: 8.158512115478516
training step: 6914, total_loss: 5.310301780700684
training step: 6915, total_loss: 5.9547038078308105
training step: 6916, total_loss: 5.076288223266602
training step: 6917, total_loss: 5.560345649719238
training step: 6918, total_loss: 5.395885467529297
training step: 6919, total_loss: 5.186958312988281
training step: 6920, total_loss: 4.8428192138671875
training step: 6921, total_loss: 4.142604351043701
training step: 6922, total_loss: 4.421025276184082
training step: 6923, total_loss: 4.7922821044921875
training step: 6924, total_loss: 5.295412063598633
training step: 6925, total_loss: 4.361316204071045
training step: 6926, total_loss: 4.547889709472656
training step: 6927, total_loss: 4.424294948577881
training step: 6928, total_loss: 4.733741283416748
training step: 6929, total_loss: 5.612093925476074
training step: 6930, total_loss: 5.917333602905273
training step: 6931, total_loss: 5.036218643188477
training step: 6932, total_loss: 2.1947999000549316
training step: 6933, total_loss: 5.022861957550049
training step: 6934, total_loss: 3.742795467376709
training step: 6935, total_loss: 5.168815612792969
training step: 6936, total_loss: 4.439810276031494
training step: 6937, total_loss: 5.5892415046691895
training step: 6938, total_loss: 4.010278224945068
training step: 6939, total_loss: 5.548469543457031
training step: 6940, total_loss: 4.758784770965576
training step: 6941, total_loss: 4.581654071807861
training step: 6942, total_loss: 7.381834983825684
training step: 6943, total_loss: 5.240257740020752
training step: 6944, total_loss: 5.59649133682251
training step: 6945, total_loss: 4.986944675445557
training step: 6946, total_loss: 7.863242149353027
training step: 6947, total_loss: 4.108072280883789
training step: 6948, total_loss: 4.678278923034668
training step: 6949, total_loss: 4.351044654846191
training step: 6950, total_loss: 4.510313034057617
training step: 6951, total_loss: 4.8734846115112305
training step: 6952, total_loss: 4.609571933746338
training step: 6953, total_loss: 5.749390602111816
training step: 6954, total_loss: 4.05570125579834
training step: 6955, total_loss: 5.2639546394348145
training step: 6956, total_loss: 4.456145763397217
training step: 6957, total_loss: 3.555710792541504
training step: 6958, total_loss: 4.5074872970581055
training step: 6959, total_loss: 4.576780319213867
training step: 6960, total_loss: 4.545415878295898
training step: 6961, total_loss: 4.767409324645996
training step: 6962, total_loss: 3.331160545349121
training step: 6963, total_loss: 6.7389960289001465
training step: 6964, total_loss: 4.598099708557129
training step: 6965, total_loss: 5.421713352203369
training step: 6966, total_loss: 6.798691749572754
training step: 6967, total_loss: 4.253223419189453
training step: 6968, total_loss: 5.287649154663086
training step: 6969, total_loss: 4.986590385437012
training step: 6970, total_loss: 4.572691440582275
training step: 6971, total_loss: 5.778434753417969
training step: 6972, total_loss: 6.787106513977051
training step: 6973, total_loss: 6.416948318481445
training step: 6974, total_loss: 5.417812347412109
training step: 6975, total_loss: 4.860509872436523
training step: 6976, total_loss: 4.808250427246094
training step: 6977, total_loss: 5.131174087524414
training step: 6978, total_loss: 5.071292400360107
training step: 6979, total_loss: 4.992825508117676
training step: 6980, total_loss: 5.796775817871094
training step: 6981, total_loss: 4.744239330291748
training step: 6982, total_loss: 4.698176383972168
training step: 6983, total_loss: 4.80267858505249
training step: 6984, total_loss: 4.557074546813965
training step: 6985, total_loss: 5.33131217956543
training step: 6986, total_loss: 5.102056980133057
training step: 6987, total_loss: 5.081092834472656
training step: 6988, total_loss: 2.969564914703369
training step: 6989, total_loss: 5.436672210693359
training step: 6990, total_loss: 3.8238532543182373
training step: 6991, total_loss: 4.6160383224487305
training step: 6992, total_loss: 3.8750619888305664
training step: 6993, total_loss: 3.7296414375305176
training step: 6994, total_loss: 5.110879421234131
training step: 6995, total_loss: 4.9959821701049805
training step: 6996, total_loss: 4.3305535316467285
training step: 6997, total_loss: 1.5388269424438477
training step: 6998, total_loss: 6.2160539627075195
training step: 6999, total_loss: 5.172140121459961
training step: 7000, total_loss: 5.080787181854248
training step: 7001, total_loss: 4.632933616638184
training step: 7002, total_loss: 4.464972496032715
training step: 7003, total_loss: 4.309432029724121
training step: 7004, total_loss: 4.809591293334961
training step: 7005, total_loss: 5.171683311462402
training step: 7006, total_loss: 4.304285049438477
training step: 7007, total_loss: 5.725403785705566
training step: 7008, total_loss: 5.397800922393799
training step: 7009, total_loss: 4.391458511352539
training step: 7010, total_loss: 5.75250768661499
training step: 7011, total_loss: 5.504778861999512
training step: 7012, total_loss: 4.174262523651123
training step: 7013, total_loss: 4.734340667724609
training step: 7014, total_loss: 6.159294128417969
training step: 7015, total_loss: 4.297510623931885
training step: 7016, total_loss: 5.702383995056152
training step: 7017, total_loss: 4.304340839385986
training step: 7018, total_loss: 2.127023696899414
training step: 7019, total_loss: 4.026137351989746
training step: 7020, total_loss: 4.412871360778809
training step: 7021, total_loss: 4.8871941566467285
training step: 7022, total_loss: 4.858287811279297
training step: 7023, total_loss: 5.850184440612793
training step: 7024, total_loss: 6.03900146484375
training step: 7025, total_loss: 4.439329147338867
training step: 7026, total_loss: 3.757330894470215
training step: 7027, total_loss: 3.353212594985962
training step: 7028, total_loss: 4.284090995788574
training step: 7029, total_loss: 4.419644355773926
training step: 7030, total_loss: 5.496847152709961
training step: 7031, total_loss: 4.976605415344238
training step: 7032, total_loss: 4.635413646697998
training step: 7033, total_loss: 6.061723709106445
training step: 7034, total_loss: 4.115214824676514
training step: 7035, total_loss: 6.474625587463379
training step: 7036, total_loss: 6.355462074279785
training step: 7037, total_loss: 2.0108554363250732
training step: 7038, total_loss: 3.850527048110962
training step: 7039, total_loss: 6.080774307250977
training step: 7040, total_loss: 4.1317362785339355
training step: 7041, total_loss: 4.469781875610352
training step: 7042, total_loss: 4.23785400390625
training step: 7043, total_loss: 3.7826974391937256
training step: 7044, total_loss: 5.682592391967773
training step: 7045, total_loss: 3.341630458831787
training step: 7046, total_loss: 5.6135454177856445
training step: 7047, total_loss: 5.163728713989258
training step: 7048, total_loss: 1.8786348104476929
training step: 7049, total_loss: 4.301488876342773
training step: 7050, total_loss: 5.244566917419434
training step: 7051, total_loss: 4.681277751922607
training step: 7052, total_loss: 5.393198490142822
training step: 7053, total_loss: 5.253958225250244
training step: 7054, total_loss: 6.548623561859131
training step: 7055, total_loss: 4.011751174926758
training step: 7056, total_loss: 3.7374377250671387
training step: 7057, total_loss: 5.168078422546387
training step: 7058, total_loss: 4.669038772583008
training step: 7059, total_loss: 5.918814659118652
training step: 7060, total_loss: 5.411866664886475
training step: 7061, total_loss: 4.814341068267822
training step: 7062, total_loss: 3.2123050689697266
training step: 7063, total_loss: 5.5742974281311035
training step: 7064, total_loss: 6.2985639572143555
training step: 7065, total_loss: 4.875789642333984
training step: 7066, total_loss: 4.511378288269043
training step: 7067, total_loss: 5.57614803314209
training step: 7068, total_loss: 2.8318710327148438
training step: 7069, total_loss: 4.250431060791016
training step: 7070, total_loss: 5.1639862060546875
training step: 7071, total_loss: 6.378387928009033
training step: 7072, total_loss: 4.980788230895996
training step: 7073, total_loss: 5.218047618865967
training step: 7074, total_loss: 5.322360992431641
training step: 7075, total_loss: 3.276185989379883
training step: 7076, total_loss: 3.437350273132324
training step: 7077, total_loss: 5.486475944519043
training step: 7078, total_loss: 4.942212104797363
training step: 7079, total_loss: 3.84222149848938
training step: 7080, total_loss: 4.8412981033325195
training step: 7081, total_loss: 4.892507553100586
training step: 7082, total_loss: 4.401606559753418
training step: 7083, total_loss: 3.9847726821899414
training step: 7084, total_loss: 4.3378801345825195
training step: 7085, total_loss: 4.00103235244751
training step: 7086, total_loss: 5.772322177886963
training step: 7087, total_loss: 4.802350044250488
training step: 7088, total_loss: 5.904648780822754
training step: 7089, total_loss: 5.846253395080566
training step: 7090, total_loss: 4.5122175216674805
training step: 7091, total_loss: 5.180851936340332
training step: 7092, total_loss: 6.055601596832275
training step: 7093, total_loss: 4.821217060089111
training step: 7094, total_loss: 4.094216346740723
training step: 7095, total_loss: 5.601923942565918
training step: 7096, total_loss: 4.628028869628906
training step: 7097, total_loss: 5.107913017272949
training step: 7098, total_loss: 7.1361260414123535
training step: 7099, total_loss: 5.382183074951172
training step: 7100, total_loss: 2.8011560440063477
training step: 7101, total_loss: 4.771406173706055
training step: 7102, total_loss: 4.696073055267334
training step: 7103, total_loss: 4.205379962921143
training step: 7104, total_loss: 5.845980644226074
training step: 7105, total_loss: 4.692447185516357
training step: 7106, total_loss: 4.023633003234863
training step: 7107, total_loss: 3.8731331825256348
training step: 7108, total_loss: 6.116549491882324
training step: 7109, total_loss: 5.706631660461426
training step: 7110, total_loss: 5.199378967285156
training step: 7111, total_loss: 5.259289741516113
training step: 7112, total_loss: 3.416280746459961
training step: 7113, total_loss: 5.354490280151367
training step: 7114, total_loss: 4.820030212402344
training step: 7115, total_loss: 5.0262579917907715
training step: 7116, total_loss: 5.454110145568848
training step: 7117, total_loss: 3.928682327270508
training step: 7118, total_loss: 5.885644435882568
training step: 7119, total_loss: 5.268485069274902
training step: 7120, total_loss: 4.485468864440918
training step: 7121, total_loss: 4.388221263885498
training step: 7122, total_loss: 4.771625518798828
training step: 7123, total_loss: 4.8566741943359375
training step: 7124, total_loss: 4.273989677429199
training step: 7125, total_loss: 4.865741729736328
training step: 7126, total_loss: 5.682917594909668
training step: 7127, total_loss: 1.511535882949829
training step: 7128, total_loss: 4.163400650024414
training step: 7129, total_loss: 3.294712543487549
training step: 7130, total_loss: 3.8949954509735107
training step: 7131, total_loss: 4.460914611816406
training step: 7132, total_loss: 4.133646011352539
training step: 7133, total_loss: 5.494649887084961
training step: 7134, total_loss: 4.802244186401367
training step: 7135, total_loss: 4.445230960845947
training step: 7136, total_loss: 6.0264177322387695
training step: 7137, total_loss: 6.5707478523254395
training step: 7138, total_loss: 5.537689208984375
training step: 7139, total_loss: 5.28179407119751
training step: 7140, total_loss: 4.912198066711426
training step: 7141, total_loss: 4.514841079711914
training step: 7142, total_loss: 4.809299945831299
training step: 7143, total_loss: 5.076241970062256
training step: 7144, total_loss: 5.345829963684082
training step: 7145, total_loss: 4.527021884918213
training step: 7146, total_loss: 5.223143100738525
training step: 7147, total_loss: 4.127163887023926
training step: 7148, total_loss: 4.9675517082214355
training step: 7149, total_loss: 5.422539234161377
training step: 7150, total_loss: 4.271942138671875
training step: 7151, total_loss: 4.822231292724609
training step: 7152, total_loss: 3.9572455883026123
training step: 7153, total_loss: 4.614511489868164
training step: 7154, total_loss: 3.8510782718658447
training step: 7155, total_loss: 4.452934265136719
training step: 7156, total_loss: 5.19484806060791
training step: 7157, total_loss: 4.949044227600098
training step: 7158, total_loss: 3.843405246734619
training step: 7159, total_loss: 4.533488750457764
training step: 7160, total_loss: 4.418721675872803
training step: 7161, total_loss: 6.139071464538574
training step: 7162, total_loss: 3.719970941543579
training step: 7163, total_loss: 4.205261707305908
training step: 7164, total_loss: 4.84787654876709
training step: 7165, total_loss: 3.89511775970459
training step: 7166, total_loss: 6.6576385498046875
training step: 7167, total_loss: 3.8787081241607666
training step: 7168, total_loss: 6.1374921798706055
training step: 7169, total_loss: 4.278815746307373
training step: 7170, total_loss: 4.647411823272705
training step: 7171, total_loss: 4.968023300170898
training step: 7172, total_loss: 4.3685302734375
training step: 7173, total_loss: 5.228099822998047
training step: 7174, total_loss: 4.002164840698242
training step: 7175, total_loss: 4.41492223739624
training step: 7176, total_loss: 5.767930030822754
training step: 7177, total_loss: 5.81837797164917
training step: 7178, total_loss: 6.201264381408691
training step: 7179, total_loss: 5.512270450592041
training step: 7180, total_loss: 4.955114364624023
training step: 7181, total_loss: 5.071338653564453
training step: 7182, total_loss: 4.9966912269592285
training step: 7183, total_loss: 5.195429801940918
training step: 7184, total_loss: 5.4580254554748535
training step: 7185, total_loss: 4.628758430480957
training step: 7186, total_loss: 5.92997932434082
training step: 7187, total_loss: 2.8021857738494873
training step: 7188, total_loss: 5.427282810211182
training step: 7189, total_loss: 5.338580131530762
training step: 7190, total_loss: 4.608079433441162
training step: 7191, total_loss: 4.798109531402588
training step: 7192, total_loss: 4.495170593261719
training step: 7193, total_loss: 4.674576759338379
training step: 7194, total_loss: 3.981443166732788
training step: 7195, total_loss: 5.663212299346924
training step: 7196, total_loss: 4.924016952514648
training step: 7197, total_loss: 5.606867790222168
training step: 7198, total_loss: 4.482476711273193
training step: 7199, total_loss: 5.584042549133301
training step: 7200, total_loss: 4.2671403884887695
training step: 7201, total_loss: 3.926290988922119
training step: 7202, total_loss: 4.489295482635498
training step: 7203, total_loss: 4.6254682540893555
training step: 7204, total_loss: 4.345973014831543
training step: 7205, total_loss: 5.125181674957275
training step: 7206, total_loss: 4.842331886291504
training step: 7207, total_loss: 5.554911136627197
training step: 7208, total_loss: 5.095380783081055
training step: 7209, total_loss: 4.31375789642334
training step: 7210, total_loss: 5.951386451721191
training step: 7211, total_loss: 5.806391716003418
training step: 7212, total_loss: 4.769875526428223
training step: 7213, total_loss: 4.511260509490967
training step: 7214, total_loss: 4.645310401916504
training step: 7215, total_loss: 5.192888259887695
training step: 7216, total_loss: 3.04787540435791
training step: 7217, total_loss: 4.783943176269531
training step: 7218, total_loss: 5.679485321044922
training step: 7219, total_loss: 5.28647518157959
training step: 7220, total_loss: 3.867859363555908
training step: 7221, total_loss: 4.596541404724121
training step: 7222, total_loss: 4.710725784301758
training step: 7223, total_loss: 5.41552734375
training step: 7224, total_loss: 4.557136058807373
training step: 7225, total_loss: 5.703052520751953
training step: 7226, total_loss: 4.093388557434082
training step: 7227, total_loss: 4.77482271194458
training step: 7228, total_loss: 5.576453685760498
training step: 7229, total_loss: 3.874467611312866
training step: 7230, total_loss: 3.801682949066162
training step: 7231, total_loss: 4.592901229858398
training step: 7232, total_loss: 4.29718542098999
training step: 7233, total_loss: 4.564528465270996
training step: 7234, total_loss: 4.073354244232178
training step: 7235, total_loss: 4.866995811462402
training step: 7236, total_loss: 4.742410659790039
training step: 7237, total_loss: 4.503082275390625
training step: 7238, total_loss: 6.526318550109863
training step: 7239, total_loss: 3.8338418006896973
training step: 7240, total_loss: 4.816538333892822
training step: 7241, total_loss: 3.8949360847473145
training step: 7242, total_loss: 3.4534151554107666
training step: 7243, total_loss: 4.329197883605957
training step: 7244, total_loss: 4.397031784057617
training step: 7245, total_loss: 4.840691566467285
training step: 7246, total_loss: 5.3314666748046875
training step: 7247, total_loss: 6.04188346862793
training step: 7248, total_loss: 5.76908016204834
training step: 7249, total_loss: 5.288768768310547
training step: 7250, total_loss: 4.694471836090088
training step: 7251, total_loss: 4.943066120147705
training step: 7252, total_loss: 5.23936653137207
training step: 7253, total_loss: 3.047255516052246
training step: 7254, total_loss: 4.4419074058532715
training step: 7255, total_loss: 4.940812587738037
training step: 7256, total_loss: 4.109220027923584
training step: 7257, total_loss: 5.189358234405518
training step: 7258, total_loss: 1.5882368087768555
training step: 7259, total_loss: 3.4681859016418457
training step: 7260, total_loss: 6.059748649597168
training step: 7261, total_loss: 4.619126319885254
training step: 7262, total_loss: 4.91274356842041
training step: 7263, total_loss: 4.792801380157471
training step: 7264, total_loss: 4.618902206420898
training step: 7265, total_loss: 3.9410247802734375
training step: 7266, total_loss: 5.3317766189575195
training step: 7267, total_loss: 5.443165302276611
training step: 7268, total_loss: 3.693239212036133
training step: 7269, total_loss: 4.2692036628723145
training step: 7270, total_loss: 5.339624404907227
training step: 7271, total_loss: 4.573030948638916
training step: 7272, total_loss: 4.428859710693359
training step: 7273, total_loss: 5.316493034362793
training step: 7274, total_loss: 3.8491249084472656
training step: 7275, total_loss: 4.983584880828857
training step: 7276, total_loss: 5.492465496063232
training step: 7277, total_loss: 6.378901481628418
training step: 7278, total_loss: 5.668665885925293
training step: 7279, total_loss: 3.635573387145996
training step: 7280, total_loss: 5.333544731140137
training step: 7281, total_loss: 4.640676975250244
training step: 7282, total_loss: 5.032114028930664
training step: 7283, total_loss: 5.198707580566406
training step: 7284, total_loss: 3.92294979095459
training step: 7285, total_loss: 5.859293460845947
training step: 7286, total_loss: 5.64621114730835
training step: 7287, total_loss: 4.021038055419922
training step: 7288, total_loss: 5.271030426025391
training step: 7289, total_loss: 3.8220033645629883
training step: 7290, total_loss: 4.743814468383789
training step: 7291, total_loss: 4.692112922668457
training step: 7292, total_loss: 6.078311920166016
training step: 7293, total_loss: 4.940487861633301
training step: 7294, total_loss: 5.277698993682861
training step: 7295, total_loss: 4.283839225769043
training step: 7296, total_loss: 3.568413257598877
training step: 7297, total_loss: 5.393489837646484
training step: 7298, total_loss: 4.824455261230469
training step: 7299, total_loss: 4.783824443817139
training step: 7300, total_loss: 3.869297504425049
training step: 7301, total_loss: 4.874114513397217
training step: 7302, total_loss: 5.36528205871582
training step: 7303, total_loss: 5.103845596313477
training step: 7304, total_loss: 4.83837890625
training step: 7305, total_loss: 4.704432487487793
training step: 7306, total_loss: 4.767582416534424
training step: 7307, total_loss: 4.101510047912598
training step: 7308, total_loss: 3.886643886566162
training step: 7309, total_loss: 5.132754325866699
training step: 7310, total_loss: 4.0923919677734375
training step: 7311, total_loss: 6.60630989074707
training step: 7312, total_loss: 4.625744342803955
training step: 7313, total_loss: 4.888662338256836
training step: 7314, total_loss: 4.791367530822754
training step: 7315, total_loss: 4.563875675201416
training step: 7316, total_loss: 5.1966423988342285
training step: 7317, total_loss: 5.168346405029297
training step: 7318, total_loss: 4.292609691619873
training step: 7319, total_loss: 4.716262340545654
training step: 7320, total_loss: 5.145320415496826
training step: 7321, total_loss: 4.4020280838012695
training step: 7322, total_loss: 4.8183441162109375
training step: 7323, total_loss: 5.147095680236816
training step: 7324, total_loss: 6.4877753257751465
training step: 7325, total_loss: 4.099926948547363
training step: 7326, total_loss: 5.292021751403809
training step: 7327, total_loss: 4.578406810760498
training step: 7328, total_loss: 4.625711917877197
training step: 7329, total_loss: 5.644639015197754
training step: 7330, total_loss: 6.039872169494629
training step: 7331, total_loss: 5.337987899780273
training step: 7332, total_loss: 5.749285697937012
training step: 7333, total_loss: 5.517823219299316
training step: 7334, total_loss: 4.1575117111206055
training step: 7335, total_loss: 5.605193614959717
training step: 7336, total_loss: 4.335977554321289
training step: 7337, total_loss: 5.213134765625
training step: 7338, total_loss: 4.519442558288574
training step: 7339, total_loss: 5.5357441902160645
training step: 7340, total_loss: 3.374526023864746
training step: 7341, total_loss: 6.7115983963012695
training step: 7342, total_loss: 4.794733047485352
training step: 7343, total_loss: 5.507058143615723
training step: 7344, total_loss: 4.457698822021484
training step: 7345, total_loss: 4.7230329513549805
training step: 7346, total_loss: 5.723701477050781
training step: 7347, total_loss: 4.945873260498047
training step: 7348, total_loss: 4.784814834594727
training step: 7349, total_loss: 5.215210914611816
training step: 7350, total_loss: 3.765676259994507
training step: 7351, total_loss: 4.537555694580078
training step: 7352, total_loss: 5.648836135864258
training step: 7353, total_loss: 4.439709663391113
training step: 7354, total_loss: 5.3562421798706055
training step: 7355, total_loss: 5.134636878967285
training step: 7356, total_loss: 4.10860013961792
training step: 7357, total_loss: 4.84490966796875
training step: 7358, total_loss: 6.258938789367676
training step: 7359, total_loss: 3.812570571899414
training step: 7360, total_loss: 4.2339582443237305
training step: 7361, total_loss: 5.243189811706543
training step: 7362, total_loss: 5.077585697174072
training step: 7363, total_loss: 2.69498348236084
training step: 7364, total_loss: 5.475648403167725
training step: 7365, total_loss: 5.903722763061523
training step: 7366, total_loss: 3.791123151779175
training step: 7367, total_loss: 3.326953411102295
training step: 7368, total_loss: 4.531379699707031
training step: 7369, total_loss: 4.670954704284668
training step: 7370, total_loss: 4.273843765258789
training step: 7371, total_loss: 5.7942728996276855
training step: 7372, total_loss: 3.508267402648926
training step: 7373, total_loss: 4.432565689086914
training step: 7374, total_loss: 5.039597511291504
training step: 7375, total_loss: 4.530368804931641
training step: 7376, total_loss: 5.7533111572265625
training step: 7377, total_loss: 3.9578428268432617
training step: 7378, total_loss: 3.6916160583496094
training step: 7379, total_loss: 3.835523843765259
training step: 7380, total_loss: 5.82773494720459
training step: 7381, total_loss: 5.28375244140625
training step: 7382, total_loss: 4.943344593048096
training step: 7383, total_loss: 4.975838661193848
training step: 7384, total_loss: 4.626666069030762
training step: 7385, total_loss: 5.353664398193359
training step: 7386, total_loss: 3.632915735244751
training step: 7387, total_loss: 5.641048431396484
training step: 7388, total_loss: 4.951139450073242
training step: 7389, total_loss: 3.484565496444702
training step: 7390, total_loss: 4.938553810119629
training step: 7391, total_loss: 3.022305965423584
training step: 7392, total_loss: 4.326603889465332
training step: 7393, total_loss: 4.999606132507324
training step: 7394, total_loss: 4.451855182647705
training step: 7395, total_loss: 4.441017150878906
training step: 7396, total_loss: 4.463335990905762
training step: 7397, total_loss: 4.880222797393799
training step: 7398, total_loss: 4.4645843505859375
training step: 7399, total_loss: 4.188599586486816
training step: 7400, total_loss: 3.9814095497131348
training step: 7401, total_loss: 4.337812423706055
training step: 7402, total_loss: 4.576976776123047
training step: 7403, total_loss: 3.7154266834259033
training step: 7404, total_loss: 4.8221917152404785
training step: 7405, total_loss: 4.211501598358154
training step: 7406, total_loss: 4.656515121459961
training step: 7407, total_loss: 3.779127597808838
training step: 7408, total_loss: 4.711228370666504
training step: 7409, total_loss: 4.543587684631348
training step: 7410, total_loss: 4.637834548950195
training step: 7411, total_loss: 6.053589344024658
training step: 7412, total_loss: 4.641556739807129
training step: 7413, total_loss: 4.385583400726318
training step: 7414, total_loss: 4.506967067718506
training step: 7415, total_loss: 4.598264694213867
training step: 7416, total_loss: 4.362341403961182
training step: 7417, total_loss: 5.030237197875977
training step: 7418, total_loss: 5.118699073791504
training step: 7419, total_loss: 5.510356426239014
training step: 7420, total_loss: 4.609094619750977
training step: 7421, total_loss: 4.700323104858398
training step: 7422, total_loss: 4.756915092468262
training step: 7423, total_loss: 4.984628677368164
training step: 7424, total_loss: 4.1272053718566895
training step: 7425, total_loss: 4.555665016174316
training step: 7426, total_loss: 2.73153018951416
training step: 7427, total_loss: 5.918844223022461
training step: 7428, total_loss: 3.915433406829834
training step: 7429, total_loss: 5.69624137878418
training step: 7430, total_loss: 5.046837329864502
training step: 7431, total_loss: 4.585747718811035
training step: 7432, total_loss: 5.61107063293457
training step: 7433, total_loss: 3.2334916591644287
training step: 7434, total_loss: 4.01177453994751
training step: 7435, total_loss: 5.152956008911133
training step: 7436, total_loss: 4.525904655456543
training step: 7437, total_loss: 3.8922667503356934
training step: 7438, total_loss: 5.285362720489502
training step: 7439, total_loss: 5.38059663772583
training step: 7440, total_loss: 5.749844074249268
training step: 7441, total_loss: 5.688607215881348
training step: 7442, total_loss: 5.329820156097412
training step: 7443, total_loss: 5.003543853759766
training step: 7444, total_loss: 5.05059289932251
training step: 7445, total_loss: 4.927062034606934
training step: 7446, total_loss: 5.05684232711792
training step: 7447, total_loss: 2.0170137882232666
training step: 7448, total_loss: 4.546041965484619
training step: 7449, total_loss: 4.8864216804504395
training step: 7450, total_loss: 5.12376594543457
training step: 7451, total_loss: 4.020695686340332
training step: 7452, total_loss: 4.428836345672607
training step: 7453, total_loss: 5.223417282104492
training step: 7454, total_loss: 4.718287467956543
training step: 7455, total_loss: 4.492249965667725
training step: 7456, total_loss: 3.3540921211242676
training step: 7457, total_loss: 3.2898850440979004
training step: 7458, total_loss: 4.806859970092773
training step: 7459, total_loss: 5.0963335037231445
training step: 7460, total_loss: 4.531384468078613
training step: 7461, total_loss: 4.744688510894775
training step: 7462, total_loss: 3.556212902069092
training step: 7463, total_loss: 5.234366416931152
training step: 7464, total_loss: 3.1155879497528076
training step: 7465, total_loss: 6.018599033355713
training step: 7466, total_loss: 4.438234806060791
training step: 7467, total_loss: 5.4202680587768555
training step: 7468, total_loss: 4.382815837860107
training step: 7469, total_loss: 5.19230842590332
training step: 7470, total_loss: 3.7003684043884277
training step: 7471, total_loss: 4.681792259216309
training step: 7472, total_loss: 4.253389358520508
training step: 7473, total_loss: 5.056847095489502
training step: 7474, total_loss: 5.629535675048828
training step: 7475, total_loss: 3.6955087184906006
training step: 7476, total_loss: 5.091425895690918
training step: 7477, total_loss: 5.204662322998047
training step: 7478, total_loss: 4.958791732788086
training step: 7479, total_loss: 4.764975070953369
training step: 7480, total_loss: 6.149670124053955
training step: 7481, total_loss: 5.709146022796631
training step: 7482, total_loss: 4.86660623550415
training step: 7483, total_loss: 3.3811614513397217
training step: 7484, total_loss: 4.766025543212891
training step: 7485, total_loss: 5.589265823364258
training step: 7486, total_loss: 4.782848358154297
training step: 7487, total_loss: 4.732692241668701
training step: 7488, total_loss: 4.187796592712402
training step: 7489, total_loss: 5.017693519592285
training step: 7490, total_loss: 3.175424337387085
training step: 7491, total_loss: 5.635514259338379
training step: 7492, total_loss: 4.408807754516602
training step: 7493, total_loss: 3.8612852096557617
training step: 7494, total_loss: 5.496809005737305
training step: 7495, total_loss: 4.685545921325684
training step: 7496, total_loss: 4.702550888061523
training step: 7497, total_loss: 4.624963760375977
training step: 7498, total_loss: 4.342459678649902
training step: 7499, total_loss: 5.831199645996094
training step: 7500, total_loss: 4.016790866851807
training step: 7501, total_loss: 4.718932151794434
training step: 7502, total_loss: 2.1084671020507812
training step: 7503, total_loss: 3.6251845359802246
training step: 7504, total_loss: 6.493607521057129
training step: 7505, total_loss: 5.638645172119141
training step: 7506, total_loss: 4.6964497566223145
training step: 7507, total_loss: 5.35934591293335
training step: 7508, total_loss: 5.037351608276367
training step: 7509, total_loss: 4.377504825592041
training step: 7510, total_loss: 4.703542709350586
training step: 7511, total_loss: 1.7258388996124268
training step: 7512, total_loss: 5.532629489898682
training step: 7513, total_loss: 4.946343898773193
training step: 7514, total_loss: 4.246634006500244
training step: 7515, total_loss: 4.534703254699707
training step: 7516, total_loss: 4.105075359344482
training step: 7517, total_loss: 4.740261077880859
training step: 7518, total_loss: 4.655578136444092
training step: 7519, total_loss: 4.607564449310303
training step: 7520, total_loss: 4.325042247772217
training step: 7521, total_loss: 3.7616844177246094
training step: 7522, total_loss: 5.087937355041504
training step: 7523, total_loss: 5.284440994262695
training step: 7524, total_loss: 5.217447280883789
training step: 7525, total_loss: 4.039308071136475
training step: 7526, total_loss: 4.621405601501465
training step: 7527, total_loss: 5.670216083526611
training step: 7528, total_loss: 6.8573808670043945
training step: 7529, total_loss: 5.777772903442383
training step: 7530, total_loss: 4.787153244018555
training step: 7531, total_loss: 7.194214820861816
training step: 7532, total_loss: 4.998878479003906
training step: 7533, total_loss: 4.1020188331604
training step: 7534, total_loss: 5.6808648109436035
training step: 7535, total_loss: 4.262478828430176
training step: 7536, total_loss: 5.432875633239746
training step: 7537, total_loss: 4.733649730682373
training step: 7538, total_loss: 4.105771064758301
training step: 7539, total_loss: 4.637813568115234
training step: 7540, total_loss: 4.416609287261963
training step: 7541, total_loss: 5.471685409545898
training step: 7542, total_loss: 5.809082984924316
training step: 7543, total_loss: 5.096205711364746
training step: 7544, total_loss: 6.096626281738281
training step: 7545, total_loss: 4.270227432250977
training step: 7546, total_loss: 4.191171646118164
training step: 7547, total_loss: 4.089396953582764
training step: 7548, total_loss: 5.735613822937012
training step: 7549, total_loss: 3.6751179695129395
training step: 7550, total_loss: 5.336357116699219
training step: 7551, total_loss: 4.099307060241699
training step: 7552, total_loss: 3.965502977371216
training step: 7553, total_loss: 6.347861289978027
training step: 7554, total_loss: 5.439403533935547
training step: 7555, total_loss: 3.631580114364624
training step: 7556, total_loss: 5.506275177001953
training step: 7557, total_loss: 4.027144432067871
training step: 7558, total_loss: 3.8261892795562744
training step: 7559, total_loss: 5.094811916351318
training step: 7560, total_loss: 6.22175407409668
training step: 7561, total_loss: 5.597041130065918
training step: 7562, total_loss: 4.632859230041504
training step: 7563, total_loss: 4.311741828918457
training step: 7564, total_loss: 4.630207538604736
training step: 7565, total_loss: 4.877482891082764
training step: 7566, total_loss: 3.9453141689300537
training step: 7567, total_loss: 4.518978118896484
training step: 7568, total_loss: 5.091278076171875
training step: 7569, total_loss: 5.261919021606445
training step: 7570, total_loss: 4.790329933166504
training step: 7571, total_loss: 4.715291976928711
training step: 7572, total_loss: 3.557828903198242
training step: 7573, total_loss: 5.689431190490723
training step: 7574, total_loss: 6.265533447265625
training step: 7575, total_loss: 5.213533401489258
training step: 7576, total_loss: 4.12025260925293
training step: 7577, total_loss: 5.003748893737793
training step: 7578, total_loss: 4.837194442749023
training step: 7579, total_loss: 5.303600311279297
training step: 7580, total_loss: 6.335975170135498
training step: 7581, total_loss: 4.636775016784668
training step: 7582, total_loss: 4.822117805480957
training step: 7583, total_loss: 3.7710089683532715
training step: 7584, total_loss: 5.554356098175049
training step: 7585, total_loss: 5.695326805114746
training step: 7586, total_loss: 4.941266059875488
training step: 7587, total_loss: 4.94558048248291
training step: 7588, total_loss: 4.357204437255859
training step: 7589, total_loss: 3.8213913440704346
training step: 7590, total_loss: 5.667872428894043
training step: 7591, total_loss: 4.920183181762695
training step: 7592, total_loss: 4.501141548156738
training step: 7593, total_loss: 4.01927375793457
training step: 7594, total_loss: 4.6150922775268555
training step: 7595, total_loss: 4.066051006317139
training step: 7596, total_loss: 4.486845970153809
training step: 7597, total_loss: 4.495769500732422
training step: 7598, total_loss: 3.967207908630371
training step: 7599, total_loss: 4.779110908508301
training step: 7600, total_loss: 5.5953688621521
training step: 7601, total_loss: 5.081232070922852
training step: 7602, total_loss: 4.800989151000977
training step: 7603, total_loss: 4.0720133781433105
training step: 7604, total_loss: 5.358205795288086
training step: 7605, total_loss: 2.4223885536193848
training step: 7606, total_loss: 4.83164644241333
training step: 7607, total_loss: 5.384284973144531
training step: 7608, total_loss: 5.899327278137207
training step: 7609, total_loss: 4.466061592102051
training step: 7610, total_loss: 4.91956901550293
training step: 7611, total_loss: 4.963074684143066
training step: 7612, total_loss: 4.561530590057373
training step: 7613, total_loss: 5.151923179626465
training step: 7614, total_loss: 5.259851932525635
training step: 7615, total_loss: 5.418904781341553
training step: 7616, total_loss: 4.647068977355957
training step: 7617, total_loss: 4.295459747314453
training step: 7618, total_loss: 5.675009727478027
training step: 7619, total_loss: 4.510492324829102
training step: 7620, total_loss: 4.175963401794434
training step: 7621, total_loss: 4.790876388549805
training step: 7622, total_loss: 6.2578887939453125
training step: 7623, total_loss: 3.364710807800293
training step: 7624, total_loss: 4.635417938232422
training step: 7625, total_loss: 4.555119514465332
training step: 7626, total_loss: 6.476076126098633
training step: 7627, total_loss: 5.607213497161865
training step: 7628, total_loss: 4.467082977294922
training step: 7629, total_loss: 3.627070665359497
training step: 7630, total_loss: 4.7373762130737305
training step: 7631, total_loss: 4.239586353302002
training step: 7632, total_loss: 5.225647449493408
training step: 7633, total_loss: 5.230771064758301
training step: 7634, total_loss: 5.465203285217285
training step: 7635, total_loss: 5.264105796813965
training step: 7636, total_loss: 4.637015342712402
training step: 7637, total_loss: 3.856961250305176
training step: 7638, total_loss: 4.620579719543457
training step: 7639, total_loss: 4.033363342285156
training step: 7640, total_loss: 3.528689384460449
training step: 7641, total_loss: 4.310546398162842
training step: 7642, total_loss: 4.349400520324707
training step: 7643, total_loss: 5.999538898468018
training step: 7644, total_loss: 5.55027961730957
training step: 7645, total_loss: 5.983583450317383
training step: 7646, total_loss: 4.872028350830078
training step: 7647, total_loss: 3.9095818996429443
training step: 7648, total_loss: 3.616269111633301
training step: 7649, total_loss: 3.9914636611938477
training step: 7650, total_loss: 4.4289116859436035
training step: 7651, total_loss: 3.7374649047851562
training step: 7652, total_loss: 4.858024597167969
training step: 7653, total_loss: 3.6828484535217285
training step: 7654, total_loss: 4.871478080749512
training step: 7655, total_loss: 3.088716506958008
training step: 7656, total_loss: 4.719051361083984
training step: 7657, total_loss: 5.848647594451904
training step: 7658, total_loss: 4.425146102905273
training step: 7659, total_loss: 4.7752180099487305
training step: 7660, total_loss: 5.333066940307617
training step: 7661, total_loss: 4.1092529296875
training step: 7662, total_loss: 5.553004741668701
training step: 7663, total_loss: 4.342565536499023
training step: 7664, total_loss: 4.446429252624512
training step: 7665, total_loss: 5.246620178222656
training step: 7666, total_loss: 5.4637250900268555
training step: 7667, total_loss: 4.619935512542725
training step: 7668, total_loss: 5.919342041015625
training step: 7669, total_loss: 4.732620716094971
training step: 7670, total_loss: 4.527334213256836
training step: 7671, total_loss: 4.583099365234375
training step: 7672, total_loss: 6.555990219116211
training step: 7673, total_loss: 3.088803291320801
training step: 7674, total_loss: 4.1419501304626465
training step: 7675, total_loss: 3.5970358848571777
training step: 7676, total_loss: 5.981990337371826
training step: 7677, total_loss: 5.2921624183654785
training step: 7678, total_loss: 5.482463836669922
training step: 7679, total_loss: 5.499290466308594
training step: 7680, total_loss: 5.708315372467041
training step: 7681, total_loss: 6.756280899047852
training step: 7682, total_loss: 4.060975551605225
training step: 7683, total_loss: 5.999024391174316
training step: 7684, total_loss: 5.182827949523926
training step: 7685, total_loss: 4.272950172424316
training step: 7686, total_loss: 5.542542457580566
training step: 7687, total_loss: 4.767396450042725
training step: 7688, total_loss: 4.989141464233398
training step: 7689, total_loss: 5.426156520843506
training step: 7690, total_loss: 4.458550453186035
training step: 7691, total_loss: 4.920203685760498
training step: 7692, total_loss: 4.12674617767334
training step: 7693, total_loss: 5.128917694091797
training step: 7694, total_loss: 5.281599998474121
training step: 7695, total_loss: 4.680922031402588
training step: 7696, total_loss: 5.394438743591309
training step: 7697, total_loss: 5.382380485534668
training step: 7698, total_loss: 4.9295878410339355
training step: 7699, total_loss: 4.591274738311768
training step: 7700, total_loss: 3.3892033100128174
training step: 7701, total_loss: 5.669475078582764
training step: 7702, total_loss: 4.690087795257568
training step: 7703, total_loss: 5.529738426208496
training step: 7704, total_loss: 4.8754377365112305
training step: 7705, total_loss: 4.32915735244751
training step: 7706, total_loss: 4.606151580810547
training step: 7707, total_loss: 5.485076904296875
training step: 7708, total_loss: 4.938029766082764
training step: 7709, total_loss: 4.332517147064209
training step: 7710, total_loss: 5.862423896789551
training step: 7711, total_loss: 4.263548851013184
training step: 7712, total_loss: 4.784653663635254
training step: 7713, total_loss: 4.288934707641602
training step: 7714, total_loss: 3.4143099784851074
training step: 7715, total_loss: 5.291282653808594
training step: 7716, total_loss: 4.2956953048706055
training step: 7717, total_loss: 4.574883460998535
training step: 7718, total_loss: 4.700321197509766
training step: 7719, total_loss: 2.6680948734283447
training step: 7720, total_loss: 4.433180809020996
training step: 7721, total_loss: 3.975533962249756
training step: 7722, total_loss: 5.6898298263549805
training step: 7723, total_loss: 5.400002956390381
training step: 7724, total_loss: 3.8529772758483887
training step: 7725, total_loss: 3.8891210556030273
training step: 7726, total_loss: 3.0627288818359375
training step: 7727, total_loss: 3.9641709327697754
training step: 7728, total_loss: 2.3325159549713135
training step: 7729, total_loss: 3.9326467514038086
training step: 7730, total_loss: 4.437926292419434
training step: 7731, total_loss: 3.2430505752563477
training step: 7732, total_loss: 4.504748821258545
training step: 7733, total_loss: 3.575643539428711
training step: 7734, total_loss: 4.933745384216309
training step: 7735, total_loss: 5.394700527191162
training step: 7736, total_loss: 5.435196399688721
training step: 7737, total_loss: 3.6172842979431152
training step: 7738, total_loss: 5.092985153198242
training step: 7739, total_loss: 5.041050910949707
training step: 7740, total_loss: 4.60374116897583
training step: 7741, total_loss: 4.604127883911133
training step: 7742, total_loss: 6.184760093688965
training step: 7743, total_loss: 7.39387321472168
training step: 7744, total_loss: 4.6646294593811035
training step: 7745, total_loss: 5.251547336578369
training step: 7746, total_loss: 5.265012264251709
training step: 7747, total_loss: 4.699497222900391
training step: 7748, total_loss: 4.784544944763184
training step: 7749, total_loss: 4.573146343231201
training step: 7750, total_loss: 4.14354133605957
training step: 7751, total_loss: 5.328371047973633
training step: 7752, total_loss: 4.332202911376953
training step: 7753, total_loss: 1.6234647035598755
training step: 7754, total_loss: 4.562480926513672
training step: 7755, total_loss: 4.913637638092041
training step: 7756, total_loss: 5.498542785644531
training step: 7757, total_loss: 4.5427565574646
training step: 7758, total_loss: 3.0680432319641113
training step: 7759, total_loss: 4.403209686279297
training step: 7760, total_loss: 6.4727463722229
training step: 7761, total_loss: 5.357919692993164
training step: 7762, total_loss: 4.666460990905762
training step: 7763, total_loss: 4.333415985107422
training step: 7764, total_loss: 4.837181091308594
training step: 7765, total_loss: 5.231236457824707
training step: 7766, total_loss: 5.845579147338867
training step: 7767, total_loss: 4.915593147277832
training step: 7768, total_loss: 5.10014533996582
training step: 7769, total_loss: 4.4679975509643555
training step: 7770, total_loss: 4.986370086669922
training step: 7771, total_loss: 3.1750566959381104
training step: 7772, total_loss: 4.276813507080078
training step: 7773, total_loss: 4.662510871887207
training step: 7774, total_loss: 5.366620063781738
training step: 7775, total_loss: 2.143125057220459
training step: 7776, total_loss: 3.919046401977539
training step: 7777, total_loss: 3.8095297813415527
training step: 7778, total_loss: 3.560892105102539
training step: 7779, total_loss: 7.17526912689209
training step: 7780, total_loss: 5.124298572540283
training step: 7781, total_loss: 4.193451881408691
training step: 7782, total_loss: 5.187042713165283
training step: 7783, total_loss: 5.869049549102783
training step: 7784, total_loss: 5.331236839294434
training step: 7785, total_loss: 5.346841812133789
training step: 7786, total_loss: 5.888881683349609
training step: 7787, total_loss: 5.220648288726807
training step: 7788, total_loss: 4.843317985534668
training step: 7789, total_loss: 4.672269821166992
training step: 7790, total_loss: 5.649463176727295
training step: 7791, total_loss: 4.709746837615967
training step: 7792, total_loss: 4.825887680053711
training step: 7793, total_loss: 3.7283921241760254
training step: 7794, total_loss: 3.825394630432129
training step: 7795, total_loss: 4.494016647338867
training step: 7796, total_loss: 5.087843894958496
training step: 7797, total_loss: 3.988755941390991
training step: 7798, total_loss: 4.891505241394043
training step: 7799, total_loss: 4.07660436630249
training step: 7800, total_loss: 4.972212314605713
training step: 7801, total_loss: 5.1072845458984375
training step: 7802, total_loss: 4.4629411697387695
training step: 7803, total_loss: 4.016705513000488
training step: 7804, total_loss: 4.603196144104004
training step: 7805, total_loss: 5.821120262145996
training step: 7806, total_loss: 4.386048316955566
training step: 7807, total_loss: 4.373420715332031
training step: 7808, total_loss: 4.642255783081055
training step: 7809, total_loss: 4.822521209716797
training step: 7810, total_loss: 6.447942733764648
training step: 7811, total_loss: 5.078855514526367
training step: 7812, total_loss: 4.065082550048828
training step: 7813, total_loss: 4.835504055023193
training step: 7814, total_loss: 4.122476577758789
training step: 7815, total_loss: 4.722126007080078
training step: 7816, total_loss: 4.123309135437012
training step: 7817, total_loss: 5.0713582038879395
training step: 7818, total_loss: 5.814815998077393
training step: 7819, total_loss: 5.945730686187744
training step: 7820, total_loss: 4.915383338928223
training step: 7821, total_loss: 3.88718318939209
training step: 7822, total_loss: 5.1222968101501465
training step: 7823, total_loss: 5.062273025512695
training step: 7824, total_loss: 4.5535888671875
training step: 7825, total_loss: 5.213963508605957
training step: 7826, total_loss: 4.439361572265625
training step: 7827, total_loss: 4.972687721252441
training step: 7828, total_loss: 4.762847423553467
training step: 7829, total_loss: 5.965872287750244
training step: 7830, total_loss: 6.791869163513184
training step: 7831, total_loss: 4.451850891113281
training step: 7832, total_loss: 3.516995906829834
training step: 7833, total_loss: 4.1175537109375
training step: 7834, total_loss: 4.987103462219238
training step: 7835, total_loss: 5.262411117553711
training step: 7836, total_loss: 1.7179713249206543
training step: 7837, total_loss: 3.271564483642578
training step: 7838, total_loss: 3.80613374710083
training step: 7839, total_loss: 1.8718006610870361
training step: 7840, total_loss: 4.393570899963379
training step: 7841, total_loss: 3.5793468952178955
training step: 7842, total_loss: 5.444155693054199
training step: 7843, total_loss: 3.2757089138031006
training step: 7844, total_loss: 4.643449783325195
training step: 7845, total_loss: 5.044050216674805
training step: 7846, total_loss: 4.200214385986328
training step: 7847, total_loss: 4.468062400817871
training step: 7848, total_loss: 3.4448306560516357
training step: 7849, total_loss: 4.667642593383789
training step: 7850, total_loss: 1.2482523918151855
training step: 7851, total_loss: 5.0049848556518555
training step: 7852, total_loss: 5.881389617919922
training step: 7853, total_loss: 6.090272903442383
training step: 7854, total_loss: 6.629631519317627
training step: 7855, total_loss: 4.353540897369385
training step: 7856, total_loss: 4.664592742919922
training step: 7857, total_loss: 4.533687591552734
training step: 7858, total_loss: 5.030105113983154
training step: 7859, total_loss: 1.3682935237884521
training step: 7860, total_loss: 4.143988132476807
training step: 7861, total_loss: 4.873734474182129
training step: 7862, total_loss: 4.792999267578125
training step: 7863, total_loss: 5.217959403991699
training step: 7864, total_loss: 5.900546073913574
training step: 7865, total_loss: 4.5555620193481445
training step: 7866, total_loss: 4.6693115234375
training step: 7867, total_loss: 5.270054817199707
training step: 7868, total_loss: 5.838531494140625
training step: 7869, total_loss: 5.355869293212891
training step: 7870, total_loss: 4.246856212615967
training step: 7871, total_loss: 5.347894668579102
training step: 7872, total_loss: 5.046099662780762
training step: 7873, total_loss: 3.4432873725891113
training step: 7874, total_loss: 4.422008514404297
training step: 7875, total_loss: 4.3864216804504395
training step: 7876, total_loss: 5.255348205566406
training step: 7877, total_loss: 5.7751312255859375
training step: 7878, total_loss: 3.4332520961761475
training step: 7879, total_loss: 4.464468002319336
training step: 7880, total_loss: 5.092522144317627
training step: 7881, total_loss: 5.687038421630859
training step: 7882, total_loss: 5.048648834228516
training step: 7883, total_loss: 3.386225700378418
training step: 7884, total_loss: 5.03278923034668
training step: 7885, total_loss: 2.5043907165527344
training step: 7886, total_loss: 5.022106170654297
training step: 7887, total_loss: 3.170286178588867
training step: 7888, total_loss: 4.565043926239014
training step: 7889, total_loss: 3.5297303199768066
training step: 7890, total_loss: 5.491393089294434
training step: 7891, total_loss: 4.226237773895264
training step: 7892, total_loss: 4.189477443695068
training step: 7893, total_loss: 4.213159084320068
training step: 7894, total_loss: 3.1771748065948486
training step: 7895, total_loss: 4.739650726318359
training step: 7896, total_loss: 4.529659271240234
training step: 7897, total_loss: 4.225154876708984
training step: 7898, total_loss: 5.2316741943359375
training step: 7899, total_loss: 5.734516143798828
training step: 7900, total_loss: 6.928126811981201
training step: 7901, total_loss: 4.321998596191406
training step: 7902, total_loss: 4.378570556640625
training step: 7903, total_loss: 5.314335823059082
training step: 7904, total_loss: 5.058342933654785
training step: 7905, total_loss: 5.207792282104492
training step: 7906, total_loss: 4.887896537780762
training step: 7907, total_loss: 4.8310866355896
training step: 7908, total_loss: 1.3840208053588867
training step: 7909, total_loss: 4.256175994873047
training step: 7910, total_loss: 4.762360572814941
training step: 7911, total_loss: 5.137778282165527
training step: 7912, total_loss: 5.455187797546387
training step: 7913, total_loss: 6.655402183532715
training step: 7914, total_loss: 4.243188858032227
training step: 7915, total_loss: 5.388385772705078
training step: 7916, total_loss: 4.40563440322876
training step: 7917, total_loss: 2.8727376461029053
training step: 7918, total_loss: 4.489775657653809
training step: 7919, total_loss: 4.367473602294922
training step: 7920, total_loss: 4.63671875
training step: 7921, total_loss: 5.218480110168457
training step: 7922, total_loss: 5.188955307006836
training step: 7923, total_loss: 4.948278427124023
training step: 7924, total_loss: 3.99301815032959
training step: 7925, total_loss: 4.392989158630371
training step: 7926, total_loss: 4.093873977661133
training step: 7927, total_loss: 4.822983741760254
training step: 7928, total_loss: 4.2072038650512695
training step: 7929, total_loss: 4.930816650390625
training step: 7930, total_loss: 5.224588394165039
training step: 7931, total_loss: 4.3733954429626465
training step: 7932, total_loss: 5.053131580352783
training step: 7933, total_loss: 3.9920449256896973
training step: 7934, total_loss: 1.669264316558838
training step: 7935, total_loss: 5.226102352142334
training step: 7936, total_loss: 4.825573921203613
training step: 7937, total_loss: 3.61873459815979
training step: 7938, total_loss: 5.214620590209961
training step: 7939, total_loss: 3.588376522064209
training step: 7940, total_loss: 4.146052360534668
training step: 7941, total_loss: 4.807947158813477
training step: 7942, total_loss: 3.8521339893341064
training step: 7943, total_loss: 4.4912848472595215
training step: 7944, total_loss: 5.790257453918457
training step: 7945, total_loss: 4.2382893562316895
training step: 7946, total_loss: 3.467160224914551
training step: 7947, total_loss: 3.566525459289551
training step: 7948, total_loss: 4.80167293548584
training step: 7949, total_loss: 4.816099166870117
training step: 7950, total_loss: 5.732484817504883
training step: 7951, total_loss: 5.773606300354004
training step: 7952, total_loss: 4.913174629211426
training step: 7953, total_loss: 5.666882514953613
training step: 7954, total_loss: 5.291778564453125
training step: 7955, total_loss: 6.071059703826904
training step: 7956, total_loss: 2.683344841003418
training step: 7957, total_loss: 4.833200454711914
training step: 7958, total_loss: 4.715776443481445
training step: 7959, total_loss: 4.52259635925293
training step: 7960, total_loss: 4.35772180557251
training step: 7961, total_loss: 5.989677429199219
training step: 7962, total_loss: 6.838644981384277
training step: 7963, total_loss: 5.132671356201172
training step: 7964, total_loss: 3.606832981109619
training step: 7965, total_loss: 5.198404312133789
training step: 7966, total_loss: 4.640627861022949
training step: 7967, total_loss: 5.242578506469727
training step: 7968, total_loss: 5.189148426055908
training step: 7969, total_loss: 4.961204528808594
training step: 7970, total_loss: 5.2185564041137695
training step: 7971, total_loss: 3.889960765838623
training step: 7972, total_loss: 4.799762725830078
training step: 7973, total_loss: 5.21650505065918
training step: 7974, total_loss: 4.9451904296875
training step: 7975, total_loss: 6.0884246826171875
training step: 7976, total_loss: 5.218166351318359
training step: 7977, total_loss: 4.644865989685059
training step: 7978, total_loss: 3.841428756713867
training step: 7979, total_loss: 4.178940773010254
training step: 7980, total_loss: 4.91038703918457
training step: 7981, total_loss: 3.743523120880127
training step: 7982, total_loss: 4.694924354553223
training step: 7983, total_loss: 4.234231948852539
training step: 7984, total_loss: 5.381463050842285
training step: 7985, total_loss: 4.899296760559082
training step: 7986, total_loss: 4.4766340255737305
training step: 7987, total_loss: 4.297147750854492
training step: 7988, total_loss: 6.356815814971924
training step: 7989, total_loss: 2.8337576389312744
training step: 7990, total_loss: 5.040132999420166
training step: 7991, total_loss: 4.554895877838135
training step: 7992, total_loss: 4.644790172576904
training step: 7993, total_loss: 5.731266021728516
training step: 7994, total_loss: 4.563142776489258
training step: 7995, total_loss: 4.6459197998046875
training step: 7996, total_loss: 4.812674522399902
training step: 7997, total_loss: 4.985004901885986
training step: 7998, total_loss: 4.609847545623779
training step: 7999, total_loss: 3.685086727142334
training step: 8000, total_loss: 4.474998474121094
training step: 8001, total_loss: 4.399942874908447
training step: 8002, total_loss: 5.696848392486572
training step: 8003, total_loss: 5.428078651428223
training step: 8004, total_loss: 3.5942835807800293
training step: 8005, total_loss: 4.509765625
training step: 8006, total_loss: 6.089712142944336
training step: 8007, total_loss: 4.0496063232421875
training step: 8008, total_loss: 4.820982456207275
training step: 8009, total_loss: 4.801860332489014
training step: 8010, total_loss: 4.7444024085998535
training step: 8011, total_loss: 5.4896039962768555
training step: 8012, total_loss: 4.950955867767334
training step: 8013, total_loss: 4.93270206451416
training step: 8014, total_loss: 4.610272407531738
training step: 8015, total_loss: 4.5329203605651855
training step: 8016, total_loss: 3.2811222076416016
training step: 8017, total_loss: 3.126538038253784
training step: 8018, total_loss: 4.293754577636719
training step: 8019, total_loss: 5.333464622497559
training step: 8020, total_loss: 4.970165252685547
training step: 8021, total_loss: 6.20340633392334
training step: 8022, total_loss: 5.763466835021973
training step: 8023, total_loss: 5.409477710723877
training step: 8024, total_loss: 6.143721580505371
training step: 8025, total_loss: 4.835906982421875
training step: 8026, total_loss: 5.497727394104004
training step: 8027, total_loss: 5.3047194480896
training step: 8028, total_loss: 5.776684284210205
training step: 8029, total_loss: 4.608662128448486
training step: 8030, total_loss: 4.295901298522949
training step: 8031, total_loss: 5.072070121765137
training step: 8032, total_loss: 3.9094796180725098
training step: 8033, total_loss: 4.615117073059082
training step: 8034, total_loss: 4.887791156768799
training step: 8035, total_loss: 4.789180755615234
training step: 8036, total_loss: 4.1453094482421875
training step: 8037, total_loss: 3.8677384853363037
training step: 8038, total_loss: 4.822673797607422
training step: 8039, total_loss: 5.339044570922852
training step: 8040, total_loss: 1.6988261938095093
training step: 8041, total_loss: 4.116034030914307
training step: 8042, total_loss: 3.5840232372283936
training step: 8043, total_loss: 5.774034023284912
training step: 8044, total_loss: 5.065426826477051
training step: 8045, total_loss: 6.458559989929199
training step: 8046, total_loss: 4.348122596740723
training step: 8047, total_loss: 5.206396102905273
training step: 8048, total_loss: 6.3871259689331055
training step: 8049, total_loss: 4.717574119567871
training step: 8050, total_loss: 5.502532958984375
training step: 8051, total_loss: 3.7062559127807617
training step: 8052, total_loss: 4.389438629150391
training step: 8053, total_loss: 3.8926525115966797
training step: 8054, total_loss: 3.2396464347839355
training step: 8055, total_loss: 5.052331924438477
training step: 8056, total_loss: 3.5949509143829346
training step: 8057, total_loss: 4.207425117492676
training step: 8058, total_loss: 5.534757614135742
training step: 8059, total_loss: 4.574120998382568
training step: 8060, total_loss: 5.7656660079956055
training step: 8061, total_loss: 4.742049217224121
training step: 8062, total_loss: 4.8293256759643555
training step: 8063, total_loss: 4.765866279602051
training step: 8064, total_loss: 4.397557258605957
training step: 8065, total_loss: 2.9559545516967773
training step: 8066, total_loss: 4.956920146942139
training step: 8067, total_loss: 5.563681602478027
training step: 8068, total_loss: 4.835410118103027
training step: 8069, total_loss: 4.642041206359863
training step: 8070, total_loss: 4.671220779418945
training step: 8071, total_loss: 3.0901997089385986
training step: 8072, total_loss: 4.887667179107666
training step: 8073, total_loss: 4.485414981842041
training step: 8074, total_loss: 5.100687026977539
training step: 8075, total_loss: 4.499134063720703
training step: 8076, total_loss: 5.230870246887207
training step: 8077, total_loss: 5.268360137939453
training step: 8078, total_loss: 5.786352157592773
training step: 8079, total_loss: 4.62760591506958
training step: 8080, total_loss: 6.54332971572876
training step: 8081, total_loss: 4.454043388366699
training step: 8082, total_loss: 3.7165541648864746
training step: 8083, total_loss: 5.40023946762085
training step: 8084, total_loss: 4.955382347106934
training step: 8085, total_loss: 4.344768524169922
training step: 8086, total_loss: 6.612874984741211
training step: 8087, total_loss: 4.060291290283203
training step: 8088, total_loss: 4.9037699699401855
training step: 8089, total_loss: 4.291090965270996
training step: 8090, total_loss: 5.6741533279418945
training step: 8091, total_loss: 4.442673683166504
training step: 8092, total_loss: 7.321136951446533
training step: 8093, total_loss: 3.334148406982422
training step: 8094, total_loss: 4.263671875
training step: 8095, total_loss: 5.250086784362793
training step: 8096, total_loss: 4.871220588684082
training step: 8097, total_loss: 5.235940933227539
training step: 8098, total_loss: 5.004437446594238
training step: 8099, total_loss: 5.183863162994385
training step: 8100, total_loss: 4.24800968170166
training step: 8101, total_loss: 4.530858516693115
training step: 8102, total_loss: 5.577547073364258
training step: 8103, total_loss: 4.836503505706787
training step: 8104, total_loss: 5.5009918212890625
training step: 8105, total_loss: 4.453118801116943
training step: 8106, total_loss: 4.247341632843018
training step: 8107, total_loss: 5.924473762512207
training step: 8108, total_loss: 4.16594934463501
training step: 8109, total_loss: 5.346813201904297
training step: 8110, total_loss: 5.027329444885254
training step: 8111, total_loss: 4.4325761795043945
training step: 8112, total_loss: 5.001192569732666
training step: 8113, total_loss: 4.945600509643555
training step: 8114, total_loss: 4.391452312469482
training step: 8115, total_loss: 6.0211992263793945
training step: 8116, total_loss: 5.427053451538086
training step: 8117, total_loss: 4.247781753540039
training step: 8118, total_loss: 4.411416053771973
training step: 8119, total_loss: 4.421229362487793
training step: 8120, total_loss: 4.865399360656738
training step: 8121, total_loss: 1.6832139492034912
training step: 8122, total_loss: 4.58028507232666
training step: 8123, total_loss: 6.345905303955078
training step: 8124, total_loss: 4.990704536437988
training step: 8125, total_loss: 4.567460536956787
training step: 8126, total_loss: 6.4969353675842285
training step: 8127, total_loss: 4.749911785125732
training step: 8128, total_loss: 4.292234420776367
training step: 8129, total_loss: 5.166908264160156
training step: 8130, total_loss: 4.31887149810791
training step: 8131, total_loss: 3.945815324783325
training step: 8132, total_loss: 4.733423709869385
training step: 8133, total_loss: 4.354424476623535
training step: 8134, total_loss: 4.713524341583252
training step: 8135, total_loss: 4.499567031860352
training step: 8136, total_loss: 2.6633126735687256
training step: 8137, total_loss: 4.397302627563477
training step: 8138, total_loss: 5.19882869720459
training step: 8139, total_loss: 2.8482112884521484
training step: 8140, total_loss: 4.39936637878418
training step: 8141, total_loss: 1.5605354309082031
training step: 8142, total_loss: 4.771698474884033
training step: 8143, total_loss: 4.378706455230713
training step: 8144, total_loss: 5.696371555328369
training step: 8145, total_loss: 6.207480430603027
training step: 8146, total_loss: 4.120295524597168
training step: 8147, total_loss: 4.966163635253906
training step: 8148, total_loss: 4.4880290031433105
training step: 8149, total_loss: 5.134455680847168
training step: 8150, total_loss: 5.5263590812683105
training step: 8151, total_loss: 4.685784339904785
training step: 8152, total_loss: 3.774322032928467
training step: 8153, total_loss: 4.550991058349609
training step: 8154, total_loss: 2.0221426486968994
training step: 8155, total_loss: 4.436722278594971
training step: 8156, total_loss: 5.011209487915039
training step: 8157, total_loss: 5.467630386352539
training step: 8158, total_loss: 3.2213568687438965
training step: 8159, total_loss: 4.905655384063721
training step: 8160, total_loss: 4.212221145629883
training step: 8161, total_loss: 4.204501152038574
training step: 8162, total_loss: 3.755511999130249
training step: 8163, total_loss: 4.933934688568115
training step: 8164, total_loss: 3.115946054458618
training step: 8165, total_loss: 3.8766841888427734
training step: 8166, total_loss: 3.8198094367980957
training step: 8167, total_loss: 3.962085723876953
training step: 8168, total_loss: 3.598829746246338
training step: 8169, total_loss: 2.8551783561706543
training step: 8170, total_loss: 4.923680305480957
training step: 8171, total_loss: 4.443279266357422
training step: 8172, total_loss: 4.278836250305176
training step: 8173, total_loss: 4.940653324127197
training step: 8174, total_loss: 4.8298420906066895
training step: 8175, total_loss: 6.516302108764648
training step: 8176, total_loss: 2.960779905319214
training step: 8177, total_loss: 4.672029972076416
training step: 8178, total_loss: 4.048539161682129
training step: 8179, total_loss: 5.791481018066406
training step: 8180, total_loss: 5.153939247131348
training step: 8181, total_loss: 4.192072868347168
training step: 8182, total_loss: 4.515103816986084
training step: 8183, total_loss: 4.252462387084961
training step: 8184, total_loss: 5.553096294403076
training step: 8185, total_loss: 1.40895676612854
training step: 8186, total_loss: 5.839828968048096
training step: 8187, total_loss: 4.393223285675049
training step: 8188, total_loss: 5.067873954772949
training step: 8189, total_loss: 5.193761825561523
training step: 8190, total_loss: 3.665921449661255
training step: 8191, total_loss: 5.046282768249512
training step: 8192, total_loss: 4.841936111450195
training step: 8193, total_loss: 3.4999337196350098
training step: 8194, total_loss: 4.168540954589844
training step: 8195, total_loss: 4.669700622558594
training step: 8196, total_loss: 4.535521030426025
training step: 8197, total_loss: 5.818487167358398
training step: 8198, total_loss: 5.9895758628845215
training step: 8199, total_loss: 5.210387229919434
training step: 8200, total_loss: 3.6974079608917236
training step: 8201, total_loss: 4.513738632202148
training step: 8202, total_loss: 4.249005317687988
training step: 8203, total_loss: 4.99059534072876
training step: 8204, total_loss: 5.017668724060059
training step: 8205, total_loss: 4.03993034362793
training step: 8206, total_loss: 3.319797992706299
training step: 8207, total_loss: 5.04872989654541
training step: 8208, total_loss: 6.51950216293335
training step: 8209, total_loss: 4.324762344360352
training step: 8210, total_loss: 5.206908226013184
training step: 8211, total_loss: 4.318613529205322
training step: 8212, total_loss: 4.615579605102539
training step: 8213, total_loss: 2.6619462966918945
training step: 8214, total_loss: 3.3814496994018555
training step: 8215, total_loss: 5.231650352478027
training step: 8216, total_loss: 4.658973693847656
training step: 8217, total_loss: 3.0152587890625
training step: 8218, total_loss: 5.592628479003906
training step: 8219, total_loss: 4.775665283203125
training step: 8220, total_loss: 5.300227165222168
training step: 8221, total_loss: 4.63465690612793
training step: 8222, total_loss: 5.196484088897705
training step: 8223, total_loss: 4.287577152252197
training step: 8224, total_loss: 4.594125747680664
training step: 8225, total_loss: 4.566622734069824
training step: 8226, total_loss: 4.600074768066406
training step: 8227, total_loss: 5.5548529624938965
training step: 8228, total_loss: 0.9462664127349854
training step: 8229, total_loss: 3.2459349632263184
training step: 8230, total_loss: 4.111931800842285
training step: 8231, total_loss: 5.499530792236328
training step: 8232, total_loss: 6.108570098876953
training step: 8233, total_loss: 0.7788759469985962
training step: 8234, total_loss: 3.1950178146362305
training step: 8235, total_loss: 6.950767517089844
training step: 8236, total_loss: 4.257050037384033
training step: 8237, total_loss: 4.788653373718262
training step: 8238, total_loss: 4.96368932723999
training step: 8239, total_loss: 5.463054656982422
training step: 8240, total_loss: 5.705103874206543
training step: 8241, total_loss: 5.38282585144043
training step: 8242, total_loss: 2.3415796756744385
training step: 8243, total_loss: 5.549248695373535
training step: 8244, total_loss: 2.9930193424224854
training step: 8245, total_loss: 4.6722259521484375
training step: 8246, total_loss: 5.466075420379639
training step: 8247, total_loss: 3.7408204078674316
training step: 8248, total_loss: 5.091822624206543
training step: 8249, total_loss: 3.830808162689209
training step: 8250, total_loss: 5.4827985763549805
training step: 8251, total_loss: 4.39625883102417
training step: 8252, total_loss: 5.018033504486084
training step: 8253, total_loss: 5.014331340789795
training step: 8254, total_loss: 3.2409892082214355
training step: 8255, total_loss: 4.026529788970947
training step: 8256, total_loss: 4.762940406799316
training step: 8257, total_loss: 3.928433656692505
training step: 8258, total_loss: 4.7722063064575195
training step: 8259, total_loss: 4.688941478729248
training step: 8260, total_loss: 4.837770462036133
training step: 8261, total_loss: 5.348803520202637
training step: 8262, total_loss: 5.177648544311523
training step: 8263, total_loss: 5.000092029571533
training step: 8264, total_loss: 4.319716930389404
training step: 8265, total_loss: 4.845701217651367
training step: 8266, total_loss: 6.233035087585449
training step: 8267, total_loss: 1.0572535991668701
training step: 8268, total_loss: 1.4314355850219727
training step: 8269, total_loss: 4.4793219566345215
training step: 8270, total_loss: 4.236802101135254
training step: 8271, total_loss: 4.2084503173828125
training step: 8272, total_loss: 5.2462944984436035
training step: 8273, total_loss: 2.146209955215454
training step: 8274, total_loss: 4.69177770614624
training step: 8275, total_loss: 4.933974266052246
training step: 8276, total_loss: 3.8257944583892822
training step: 8277, total_loss: 4.224259376525879
training step: 8278, total_loss: 5.210945129394531
training step: 8279, total_loss: 4.807901382446289
training step: 8280, total_loss: 6.313215732574463
training step: 8281, total_loss: 4.830086708068848
training step: 8282, total_loss: 5.221353530883789
training step: 8283, total_loss: 4.11099910736084
training step: 8284, total_loss: 3.856049060821533
training step: 8285, total_loss: 5.574281215667725
training step: 8286, total_loss: 4.706921577453613
training step: 8287, total_loss: 3.6443684101104736
training step: 8288, total_loss: 4.896322250366211
training step: 8289, total_loss: 4.65322732925415
training step: 8290, total_loss: 5.853397369384766
training step: 8291, total_loss: 5.30812931060791
training step: 8292, total_loss: 5.5755438804626465
training step: 8293, total_loss: 6.901026725769043
training step: 8294, total_loss: 3.463221549987793
training step: 8295, total_loss: 1.5756666660308838
training step: 8296, total_loss: 6.318107604980469
training step: 8297, total_loss: 4.392981052398682
training step: 8298, total_loss: 4.4189558029174805
training step: 8299, total_loss: 5.2928571701049805
training step: 8300, total_loss: 5.177704811096191
training step: 8301, total_loss: 4.987694263458252
training step: 8302, total_loss: 4.565325736999512
training step: 8303, total_loss: 4.035784721374512
training step: 8304, total_loss: 4.469358444213867
training step: 8305, total_loss: 4.4948225021362305
training step: 8306, total_loss: 4.790496826171875
training step: 8307, total_loss: 4.32426643371582
training step: 8308, total_loss: 4.905235290527344
training step: 8309, total_loss: 4.943356990814209
training step: 8310, total_loss: 1.8267172574996948
training step: 8311, total_loss: 4.545560836791992
training step: 8312, total_loss: 4.824292182922363
training step: 8313, total_loss: 5.5636186599731445
training step: 8314, total_loss: 5.417745113372803
training step: 8315, total_loss: 4.599834442138672
training step: 8316, total_loss: 5.547188758850098
training step: 8317, total_loss: 4.6363701820373535
training step: 8318, total_loss: 4.156846046447754
training step: 8319, total_loss: 4.453472137451172
training step: 8320, total_loss: 4.2473273277282715
training step: 8321, total_loss: 4.806374549865723
training step: 8322, total_loss: 5.506399154663086
training step: 8323, total_loss: 3.9466938972473145
training step: 8324, total_loss: 4.490814208984375
training step: 8325, total_loss: 4.429426193237305
training step: 8326, total_loss: 6.5559234619140625
training step: 8327, total_loss: 4.809523582458496
training step: 8328, total_loss: 4.665109634399414
training step: 8329, total_loss: 4.590856552124023
training step: 8330, total_loss: 4.014671325683594
training step: 8331, total_loss: 4.334640026092529
training step: 8332, total_loss: 6.126813888549805
training step: 8333, total_loss: 4.191338539123535
training step: 8334, total_loss: 5.147770404815674
training step: 8335, total_loss: 4.083239555358887
training step: 8336, total_loss: 3.0197105407714844
training step: 8337, total_loss: 2.186551570892334
training step: 8338, total_loss: 5.026440143585205
training step: 8339, total_loss: 4.913372039794922
training step: 8340, total_loss: 4.484518527984619
training step: 8341, total_loss: 3.492844581604004
training step: 8342, total_loss: 4.387640953063965
training step: 8343, total_loss: 5.477573394775391
training step: 8344, total_loss: 4.433321952819824
training step: 8345, total_loss: 5.266636848449707
training step: 8346, total_loss: 5.915376663208008
training step: 8347, total_loss: 4.134949207305908
training step: 8348, total_loss: 3.5177831649780273
training step: 8349, total_loss: 3.932676315307617
training step: 8350, total_loss: 5.024209976196289
training step: 8351, total_loss: 4.379367828369141
training step: 8352, total_loss: 5.8178815841674805
training step: 8353, total_loss: 3.632500648498535
training step: 8354, total_loss: 4.3810625076293945
training step: 8355, total_loss: 4.304940223693848
training step: 8356, total_loss: 2.6751270294189453
training step: 8357, total_loss: 5.3194379806518555
training step: 8358, total_loss: 4.661460876464844
training step: 8359, total_loss: 4.076108455657959
training step: 8360, total_loss: 5.366350173950195
training step: 8361, total_loss: 4.636972427368164
training step: 8362, total_loss: 4.04207706451416
training step: 8363, total_loss: 4.048131942749023
training step: 8364, total_loss: 5.294261932373047
training step: 8365, total_loss: 5.975772857666016
training step: 8366, total_loss: 4.004945755004883
training step: 8367, total_loss: 5.042510509490967
training step: 8368, total_loss: 5.18824577331543
training step: 8369, total_loss: 6.244187355041504
training step: 8370, total_loss: 3.5403623580932617
training step: 8371, total_loss: 4.154053688049316
training step: 8372, total_loss: 4.570448875427246
training step: 8373, total_loss: 4.913959503173828
training step: 8374, total_loss: 4.019736289978027
training step: 8375, total_loss: 4.273992538452148
training step: 8376, total_loss: 4.2297210693359375
training step: 8377, total_loss: 4.096960544586182
training step: 8378, total_loss: 4.7493896484375
training step: 8379, total_loss: 3.1177918910980225
training step: 8380, total_loss: 5.831457614898682
training step: 8381, total_loss: 4.2925944328308105
training step: 8382, total_loss: 2.4560093879699707
training step: 8383, total_loss: 2.6663708686828613
training step: 8384, total_loss: 3.646930694580078
training step: 8385, total_loss: 5.471156120300293
training step: 8386, total_loss: 5.81553840637207
training step: 8387, total_loss: 5.429547309875488
training step: 8388, total_loss: 3.725677967071533
training step: 8389, total_loss: 4.349728584289551
training step: 8390, total_loss: 5.515289306640625
training step: 8391, total_loss: 3.721196413040161
training step: 8392, total_loss: 6.821284294128418
training step: 8393, total_loss: 4.090578079223633
training step: 8394, total_loss: 3.581294059753418
training step: 8395, total_loss: 4.046463489532471
training step: 8396, total_loss: 4.4151458740234375
training step: 8397, total_loss: 4.06129264831543
training step: 8398, total_loss: 5.842594146728516
training step: 8399, total_loss: 6.193392753601074
training step: 8400, total_loss: 4.048917293548584
training step: 8401, total_loss: 3.909290313720703
training step: 8402, total_loss: 2.735430955886841
training step: 8403, total_loss: 3.037609577178955
training step: 8404, total_loss: 5.566231727600098
training step: 8405, total_loss: 5.590741157531738
training step: 8406, total_loss: 4.595493316650391
training step: 8407, total_loss: 2.389528274536133
training step: 8408, total_loss: 4.21391487121582
training step: 8409, total_loss: 5.188374042510986
training step: 8410, total_loss: 4.443681716918945
training step: 8411, total_loss: 5.0088982582092285
training step: 8412, total_loss: 5.791347503662109
training step: 8413, total_loss: 3.719661235809326
training step: 8414, total_loss: 4.683598518371582
training step: 8415, total_loss: 6.692812919616699
training step: 8416, total_loss: 5.808981895446777
training step: 8417, total_loss: 4.338778495788574
training step: 8418, total_loss: 5.832033157348633
training step: 8419, total_loss: 4.521596908569336
training step: 8420, total_loss: 4.887396812438965
training step: 8421, total_loss: 4.333432674407959
training step: 8422, total_loss: 4.089180946350098
training step: 8423, total_loss: 5.693816184997559
training step: 8424, total_loss: 5.336935043334961
training step: 8425, total_loss: 5.345426082611084
training step: 8426, total_loss: 3.0260918140411377
training step: 8427, total_loss: 4.04766321182251
training step: 8428, total_loss: 4.095959663391113
training step: 8429, total_loss: 5.5294318199157715
training step: 8430, total_loss: 5.656157493591309
training step: 8431, total_loss: 4.926131248474121
training step: 8432, total_loss: 4.013637542724609
training step: 8433, total_loss: 6.01076602935791
training step: 8434, total_loss: 5.335831642150879
training step: 8435, total_loss: 6.851714134216309
training step: 8436, total_loss: 4.590945720672607
training step: 8437, total_loss: 6.422995567321777
training step: 8438, total_loss: 4.818361759185791
training step: 8439, total_loss: 5.643052577972412
training step: 8440, total_loss: 4.456495761871338
training step: 8441, total_loss: 3.2558226585388184
training step: 8442, total_loss: 4.045431137084961
training step: 8443, total_loss: 4.31419038772583
training step: 8444, total_loss: 3.95987868309021
training step: 8445, total_loss: 4.460486888885498
training step: 8446, total_loss: 3.3867321014404297
training step: 8447, total_loss: 4.884308815002441
training step: 8448, total_loss: 4.43535041809082
training step: 8449, total_loss: 5.061402797698975
training step: 8450, total_loss: 4.8774518966674805
training step: 8451, total_loss: 4.496003150939941
training step: 8452, total_loss: 3.626288890838623
training step: 8453, total_loss: 3.706756114959717
training step: 8454, total_loss: 6.129159450531006
training step: 8455, total_loss: 4.398352146148682
training step: 8456, total_loss: 5.164060592651367
training step: 8457, total_loss: 4.347825050354004
training step: 8458, total_loss: 5.7626543045043945
training step: 8459, total_loss: 5.5010576248168945
training step: 8460, total_loss: 3.4696295261383057
training step: 8461, total_loss: 4.306501388549805
training step: 8462, total_loss: 3.434953212738037
training step: 8463, total_loss: 2.8627378940582275
training step: 8464, total_loss: 5.045310020446777
training step: 8465, total_loss: 4.151299476623535
training step: 8466, total_loss: 3.2314200401306152
training step: 8467, total_loss: 4.560398578643799
training step: 8468, total_loss: 4.074695110321045
training step: 8469, total_loss: 5.808114051818848
training step: 8470, total_loss: 7.765853404998779
training step: 8471, total_loss: 5.157327651977539
training step: 8472, total_loss: 5.306027412414551
training step: 8473, total_loss: 4.735369682312012
training step: 8474, total_loss: 4.955627918243408
training step: 8475, total_loss: 3.7866997718811035
training step: 8476, total_loss: 4.901987075805664
training step: 8477, total_loss: 3.404648780822754
training step: 8478, total_loss: 2.85082745552063
training step: 8479, total_loss: 6.927797317504883
training step: 8480, total_loss: 5.768855094909668
training step: 8481, total_loss: 4.406883716583252
training step: 8482, total_loss: 3.3428444862365723
training step: 8483, total_loss: 5.446374893188477
training step: 8484, total_loss: 5.05027437210083
training step: 8485, total_loss: 5.468245506286621
training step: 8486, total_loss: 5.36410665512085
training step: 8487, total_loss: 5.243845462799072
training step: 8488, total_loss: 3.7571706771850586
training step: 8489, total_loss: 4.609172821044922
training step: 8490, total_loss: 5.074180603027344
training step: 8491, total_loss: 6.011728286743164
training step: 8492, total_loss: 4.251073837280273
training step: 8493, total_loss: 6.915911674499512
training step: 8494, total_loss: 4.459532260894775
training step: 8495, total_loss: 4.4218950271606445
training step: 8496, total_loss: 4.825735092163086
training step: 8497, total_loss: 4.641304016113281
training step: 8498, total_loss: 4.172577857971191
training step: 8499, total_loss: 4.64802360534668
training step: 8500, total_loss: 4.35751485824585
training step: 8501, total_loss: 4.859760284423828
training step: 8502, total_loss: 5.17490291595459
training step: 8503, total_loss: 4.886645317077637
training step: 8504, total_loss: 4.7782135009765625
training step: 8505, total_loss: 4.6833953857421875
training step: 8506, total_loss: 6.215648651123047
training step: 8507, total_loss: 3.9208056926727295
training step: 8508, total_loss: 4.040647506713867
training step: 8509, total_loss: 4.304933071136475
training step: 8510, total_loss: 4.708720684051514
training step: 8511, total_loss: 4.450998306274414
training step: 8512, total_loss: 4.221989631652832
training step: 8513, total_loss: 4.964242935180664
training step: 8514, total_loss: 5.0193281173706055
training step: 8515, total_loss: 4.991793632507324
training step: 8516, total_loss: 3.449896812438965
training step: 8517, total_loss: 5.2118072509765625
training step: 8518, total_loss: 4.1042585372924805
training step: 8519, total_loss: 6.67274808883667
training step: 8520, total_loss: 6.100650310516357
training step: 8521, total_loss: 4.16801643371582
training step: 8522, total_loss: 3.9483914375305176
training step: 8523, total_loss: 3.7035062313079834
training step: 8524, total_loss: 5.813352584838867
training step: 8525, total_loss: 4.816662311553955
training step: 8526, total_loss: 5.142887115478516
training step: 8527, total_loss: 4.831679344177246
training step: 8528, total_loss: 4.793625831604004
training step: 8529, total_loss: 4.747797966003418
training step: 8530, total_loss: 5.633670330047607
training step: 8531, total_loss: 5.42216682434082
training step: 8532, total_loss: 3.8308045864105225
training step: 8533, total_loss: 4.936807155609131
training step: 8534, total_loss: 4.033965110778809
training step: 8535, total_loss: 5.566970348358154
training step: 8536, total_loss: 4.113170623779297
training step: 8537, total_loss: 4.350911617279053
training step: 8538, total_loss: 6.594178199768066
training step: 8539, total_loss: 4.046565532684326
training step: 8540, total_loss: 6.282896518707275
training step: 8541, total_loss: 3.1304664611816406
training step: 8542, total_loss: 5.288020610809326
training step: 8543, total_loss: 5.496278762817383
training step: 8544, total_loss: 4.433531761169434
training step: 8545, total_loss: 1.9455045461654663
training step: 8546, total_loss: 5.208322525024414
training step: 8547, total_loss: 5.410712718963623
training step: 8548, total_loss: 5.0987467765808105
training step: 8549, total_loss: 5.736224174499512
training step: 8550, total_loss: 4.606240272521973
training step: 8551, total_loss: 5.504228591918945
training step: 8552, total_loss: 4.745105266571045
training step: 8553, total_loss: 4.024639129638672
training step: 8554, total_loss: 4.467199325561523
training step: 8555, total_loss: 6.145068645477295
training step: 8556, total_loss: 4.131441116333008
training step: 8557, total_loss: 4.4354095458984375
training step: 8558, total_loss: 4.915699005126953
training step: 8559, total_loss: 4.8863935470581055
training step: 8560, total_loss: 5.106791973114014
training step: 8561, total_loss: 4.366115093231201
training step: 8562, total_loss: 4.9516987800598145
training step: 8563, total_loss: 4.662898063659668
training step: 8564, total_loss: 5.913888931274414
training step: 8565, total_loss: 4.611318111419678
training step: 8566, total_loss: 4.81441593170166
training step: 8567, total_loss: 4.531387805938721
training step: 8568, total_loss: 5.468752861022949
training step: 8569, total_loss: 3.9522993564605713
training step: 8570, total_loss: 4.732547760009766
training step: 8571, total_loss: 4.187139511108398
training step: 8572, total_loss: 4.440733909606934
training step: 8573, total_loss: 3.996856212615967
training step: 8574, total_loss: 4.118432998657227
training step: 8575, total_loss: 3.2395572662353516
training step: 8576, total_loss: 7.662840366363525
training step: 8577, total_loss: 4.783752918243408
training step: 8578, total_loss: 4.489974498748779
training step: 8579, total_loss: 5.551456451416016
training step: 8580, total_loss: 4.69973087310791
training step: 8581, total_loss: 5.214360237121582
training step: 8582, total_loss: 5.816977024078369
training step: 8583, total_loss: 3.6955642700195312
training step: 8584, total_loss: 4.873875617980957
training step: 8585, total_loss: 4.568016052246094
training step: 8586, total_loss: 5.1475911140441895
training step: 8587, total_loss: 4.6976776123046875
training step: 8588, total_loss: 5.173123359680176
training step: 8589, total_loss: 5.660506248474121
training step: 8590, total_loss: 3.357672691345215
training step: 8591, total_loss: 5.3582963943481445
training step: 8592, total_loss: 4.545487880706787
training step: 8593, total_loss: 5.1385955810546875
training step: 8594, total_loss: 5.481658935546875
training step: 8595, total_loss: 4.101718425750732
training step: 8596, total_loss: 5.008298873901367
training step: 8597, total_loss: 4.785050392150879
training step: 8598, total_loss: 4.133571147918701
training step: 8599, total_loss: 5.373495101928711
training step: 8600, total_loss: 5.062394142150879
training step: 8601, total_loss: 3.829606533050537
training step: 8602, total_loss: 5.110236167907715
training step: 8603, total_loss: 5.757053375244141
training step: 8604, total_loss: 4.119199752807617
training step: 8605, total_loss: 5.274258136749268
training step: 8606, total_loss: 4.757957458496094
training step: 8607, total_loss: 4.723301887512207
training step: 8608, total_loss: 4.332440376281738
training step: 8609, total_loss: 5.296716213226318
training step: 8610, total_loss: 4.504608154296875
training step: 8611, total_loss: 5.478708744049072
training step: 8612, total_loss: 4.345467567443848
training step: 8613, total_loss: 4.508557319641113
training step: 8614, total_loss: 5.085277557373047
training step: 8615, total_loss: 4.380626678466797
training step: 8616, total_loss: 4.558687210083008
training step: 8617, total_loss: 4.9993181228637695
training step: 8618, total_loss: 4.44467830657959
training step: 8619, total_loss: 4.741361618041992
training step: 8620, total_loss: 3.634131908416748
training step: 8621, total_loss: 4.244568824768066
training step: 8622, total_loss: 5.664829254150391
training step: 8623, total_loss: 4.9738054275512695
training step: 8624, total_loss: 5.999261856079102
training step: 8625, total_loss: 4.446659088134766
training step: 8626, total_loss: 4.6777238845825195
training step: 8627, total_loss: 3.862196445465088
training step: 8628, total_loss: 4.6887993812561035
training step: 8629, total_loss: 4.347036361694336
training step: 8630, total_loss: 4.957117557525635
training step: 8631, total_loss: 4.763551712036133
training step: 8632, total_loss: 5.586406707763672
training step: 8633, total_loss: 4.713523864746094
training step: 8634, total_loss: 4.86271858215332
training step: 8635, total_loss: 4.724048614501953
training step: 8636, total_loss: 3.666046142578125
training step: 8637, total_loss: 5.462536811828613
training step: 8638, total_loss: 2.721266031265259
training step: 8639, total_loss: 4.8892951011657715
training step: 8640, total_loss: 5.905330181121826
training step: 8641, total_loss: 1.659080982208252
training step: 8642, total_loss: 6.198622703552246
training step: 8643, total_loss: 4.672381401062012
training step: 8644, total_loss: 5.275356292724609
training step: 8645, total_loss: 4.817661285400391
training step: 8646, total_loss: 5.289493560791016
training step: 8647, total_loss: 4.188497543334961
training step: 8648, total_loss: 4.92392110824585
training step: 8649, total_loss: 5.836263656616211
training step: 8650, total_loss: 5.081745147705078
training step: 8651, total_loss: 4.573566913604736
training step: 8652, total_loss: 6.2741241455078125
training step: 8653, total_loss: 3.538851499557495
training step: 8654, total_loss: 5.4922075271606445
training step: 8655, total_loss: 4.24644660949707
training step: 8656, total_loss: 4.22591495513916
training step: 8657, total_loss: 4.438100814819336
training step: 8658, total_loss: 3.525700330734253
training step: 8659, total_loss: 6.122707366943359
training step: 8660, total_loss: 5.476607322692871
training step: 8661, total_loss: 5.44134521484375
training step: 8662, total_loss: 5.2531418800354
training step: 8663, total_loss: 5.69869327545166
training step: 8664, total_loss: 5.505743026733398
training step: 8665, total_loss: 2.8597311973571777
training step: 8666, total_loss: 5.33150053024292
training step: 8667, total_loss: 5.311797142028809
training step: 8668, total_loss: 4.1910810470581055
training step: 8669, total_loss: 5.562784194946289
training step: 8670, total_loss: 3.816307783126831
training step: 8671, total_loss: 4.519696235656738
training step: 8672, total_loss: 4.187982082366943
training step: 8673, total_loss: 3.904479503631592
training step: 8674, total_loss: 3.712252616882324
training step: 8675, total_loss: 5.642523288726807
training step: 8676, total_loss: 5.711211204528809
training step: 8677, total_loss: 5.563420295715332
training step: 8678, total_loss: 4.406131744384766
training step: 8679, total_loss: 4.793546676635742
training step: 8680, total_loss: 4.859080791473389
training step: 8681, total_loss: 3.7050840854644775
training step: 8682, total_loss: 4.457682132720947
training step: 8683, total_loss: 5.548091888427734
training step: 8684, total_loss: 5.213173866271973
training step: 8685, total_loss: 4.4327239990234375
training step: 8686, total_loss: 3.7907748222351074
training step: 8687, total_loss: 6.483560085296631
training step: 8688, total_loss: 4.689535617828369
training step: 8689, total_loss: 3.0415282249450684
training step: 8690, total_loss: 4.327816963195801
training step: 8691, total_loss: 4.597954273223877
training step: 8692, total_loss: 4.8432793617248535
training step: 8693, total_loss: 3.6462934017181396
training step: 8694, total_loss: 4.6928839683532715
training step: 8695, total_loss: 4.359890460968018
training step: 8696, total_loss: 3.457772731781006
training step: 8697, total_loss: 4.1146440505981445
training step: 8698, total_loss: 5.407711029052734
training step: 8699, total_loss: 5.757990837097168
training step: 8700, total_loss: 4.002152442932129
training step: 8701, total_loss: 5.229615211486816
training step: 8702, total_loss: 4.645174026489258
training step: 8703, total_loss: 4.7892560958862305
training step: 8704, total_loss: 6.54934549331665
training step: 8705, total_loss: 5.6503801345825195
training step: 8706, total_loss: 4.3331618309021
training step: 8707, total_loss: 5.42225980758667
training step: 8708, total_loss: 4.381102085113525
training step: 8709, total_loss: 3.142817497253418
training step: 8710, total_loss: 5.043252944946289
training step: 8711, total_loss: 5.384889125823975
training step: 8712, total_loss: 5.326282501220703
training step: 8713, total_loss: 4.423428535461426
training step: 8714, total_loss: 4.796567916870117
training step: 8715, total_loss: 4.403696537017822
training step: 8716, total_loss: 4.577239990234375
training step: 8717, total_loss: 5.183628559112549
training step: 8718, total_loss: 5.699930191040039
training step: 8719, total_loss: 3.3239784240722656
training step: 8720, total_loss: 4.639331817626953
training step: 8721, total_loss: 4.841704368591309
training step: 8722, total_loss: 5.106650352478027
training step: 8723, total_loss: 3.429849624633789
training step: 8724, total_loss: 5.7576751708984375
training step: 8725, total_loss: 4.1083574295043945
training step: 8726, total_loss: 5.050850868225098
training step: 8727, total_loss: 4.607651710510254
training step: 8728, total_loss: 3.255026340484619
training step: 8729, total_loss: 3.776988983154297
training step: 8730, total_loss: 5.823788166046143
training step: 8731, total_loss: 3.7594714164733887
training step: 8732, total_loss: 5.681288719177246
training step: 8733, total_loss: 3.5843353271484375
training step: 8734, total_loss: 4.109277248382568
training step: 8735, total_loss: 4.655125617980957
training step: 8736, total_loss: 4.6195902824401855
training step: 8737, total_loss: 5.095160484313965
training step: 8738, total_loss: 3.6043221950531006
training step: 8739, total_loss: 4.682200908660889
training step: 8740, total_loss: 5.893131256103516
training step: 8741, total_loss: 4.646602630615234
training step: 8742, total_loss: 3.976731300354004
training step: 8743, total_loss: 4.860019207000732
training step: 8744, total_loss: 3.959218978881836
training step: 8745, total_loss: 5.5576300621032715
training step: 8746, total_loss: 5.750677585601807
training step: 8747, total_loss: 5.2376508712768555
training step: 8748, total_loss: 3.526562452316284
training step: 8749, total_loss: 3.9959726333618164
training step: 8750, total_loss: 4.963293075561523
training step: 8751, total_loss: 4.741487979888916
training step: 8752, total_loss: 4.430578231811523
training step: 8753, total_loss: 4.6904754638671875
training step: 8754, total_loss: 3.7419652938842773
training step: 8755, total_loss: 4.275359630584717
training step: 8756, total_loss: 4.565483093261719
training step: 8757, total_loss: 2.9289093017578125
training step: 8758, total_loss: 4.4961748123168945
training step: 8759, total_loss: 5.475864410400391
training step: 8760, total_loss: 3.4813055992126465
training step: 8761, total_loss: 4.223640441894531
training step: 8762, total_loss: 3.737604856491089
training step: 8763, total_loss: 4.872439384460449
training step: 8764, total_loss: 4.565740585327148
training step: 8765, total_loss: 5.118607044219971
training step: 8766, total_loss: 5.551642417907715
training step: 8767, total_loss: 3.2915916442871094
training step: 8768, total_loss: 4.64066219329834
training step: 8769, total_loss: 5.919584274291992
training step: 8770, total_loss: 5.007499694824219
training step: 8771, total_loss: 3.7413458824157715
training step: 8772, total_loss: 3.972139835357666
training step: 8773, total_loss: 4.327598571777344
training step: 8774, total_loss: 4.7526750564575195
training step: 8775, total_loss: 5.983456134796143
training step: 8776, total_loss: 4.264968395233154
training step: 8777, total_loss: 4.907870292663574
training step: 8778, total_loss: 4.420987129211426
training step: 8779, total_loss: 5.774261951446533
training step: 8780, total_loss: 3.2789855003356934
training step: 8781, total_loss: 4.954879283905029
training step: 8782, total_loss: 4.998835563659668
training step: 8783, total_loss: 5.613666534423828
training step: 8784, total_loss: 5.4201812744140625
training step: 8785, total_loss: 4.989751815795898
training step: 8786, total_loss: 5.318044185638428
training step: 8787, total_loss: 4.220081329345703
training step: 8788, total_loss: 3.9430463314056396
training step: 8789, total_loss: 5.633678913116455
training step: 8790, total_loss: 4.646357536315918
training step: 8791, total_loss: 6.094905853271484
training step: 8792, total_loss: 5.225245475769043
training step: 8793, total_loss: 2.8964180946350098
training step: 8794, total_loss: 7.3216071128845215
training step: 8795, total_loss: 5.169276237487793
training step: 8796, total_loss: 4.822134971618652
training step: 8797, total_loss: 5.782131195068359
training step: 8798, total_loss: 4.8365325927734375
training step: 8799, total_loss: 4.406570911407471
training step: 8800, total_loss: 4.747347831726074
training step: 8801, total_loss: 4.412436008453369
training step: 8802, total_loss: 4.567988395690918
training step: 8803, total_loss: 4.625452995300293
training step: 8804, total_loss: 4.183078289031982
training step: 8805, total_loss: 4.691616058349609
training step: 8806, total_loss: 5.485476493835449
training step: 8807, total_loss: 2.4466497898101807
training step: 8808, total_loss: 4.698458194732666
training step: 8809, total_loss: 5.239437103271484
training step: 8810, total_loss: 5.593219757080078
training step: 8811, total_loss: 4.513925552368164
training step: 8812, total_loss: 3.983065128326416
training step: 8813, total_loss: 5.38753604888916
training step: 8814, total_loss: 4.964211463928223
training step: 8815, total_loss: 4.047536849975586
training step: 8816, total_loss: 3.5654282569885254
training step: 8817, total_loss: 5.18720817565918
training step: 8818, total_loss: 4.386037826538086
training step: 8819, total_loss: 2.9043331146240234
training step: 8820, total_loss: 4.349686622619629
training step: 8821, total_loss: 4.416592121124268
training step: 8822, total_loss: 4.235434055328369
training step: 8823, total_loss: 5.4276580810546875
training step: 8824, total_loss: 4.017778396606445
training step: 8825, total_loss: 4.766225814819336
training step: 8826, total_loss: 4.631448268890381
training step: 8827, total_loss: 4.501493453979492
training step: 8828, total_loss: 4.834769248962402
training step: 8829, total_loss: 5.522151947021484
training step: 8830, total_loss: 5.512064456939697
training step: 8831, total_loss: 4.501283645629883
training step: 8832, total_loss: 5.942388534545898
training step: 8833, total_loss: 5.913873195648193
training step: 8834, total_loss: 5.885373115539551
training step: 8835, total_loss: 4.093626022338867
training step: 8836, total_loss: 5.443704128265381
training step: 8837, total_loss: 4.88694953918457
training step: 8838, total_loss: 2.9296464920043945
training step: 8839, total_loss: 4.663510799407959
training step: 8840, total_loss: 6.183646202087402
training step: 8841, total_loss: 2.735055446624756
training step: 8842, total_loss: 3.5178964138031006
training step: 8843, total_loss: 5.245699882507324
training step: 8844, total_loss: 4.91961669921875
training step: 8845, total_loss: 5.529395580291748
training step: 8846, total_loss: 5.088003635406494
training step: 8847, total_loss: 5.411660671234131
training step: 8848, total_loss: 2.0760350227355957
training step: 8849, total_loss: 5.0782036781311035
training step: 8850, total_loss: 3.5621814727783203
training step: 8851, total_loss: 5.584995269775391
training step: 8852, total_loss: 4.589158058166504
training step: 8853, total_loss: 7.129546165466309
training step: 8854, total_loss: 4.031649112701416
training step: 8855, total_loss: 5.25129508972168
training step: 8856, total_loss: 4.439210891723633
training step: 8857, total_loss: 3.8763256072998047
training step: 8858, total_loss: 3.817927598953247
training step: 8859, total_loss: 5.0272440910339355
training step: 8860, total_loss: 5.1002421379089355
training step: 8861, total_loss: 5.57220458984375
training step: 8862, total_loss: 4.6925177574157715
training step: 8863, total_loss: 5.344199180603027
training step: 8864, total_loss: 5.022596836090088
training step: 8865, total_loss: 4.485877513885498
training step: 8866, total_loss: 6.163600921630859
training step: 8867, total_loss: 5.133574485778809
training step: 8868, total_loss: 6.565781116485596
training step: 8869, total_loss: 5.463452339172363
training step: 8870, total_loss: 5.1971588134765625
training step: 8871, total_loss: 6.362673282623291
training step: 8872, total_loss: 6.122629642486572
training step: 8873, total_loss: 5.766803741455078
training step: 8874, total_loss: 5.219799518585205
training step: 8875, total_loss: 5.4562835693359375
training step: 8876, total_loss: 3.6669955253601074
training step: 8877, total_loss: 4.680543422698975
training step: 8878, total_loss: 5.378368854522705
training step: 8879, total_loss: 1.483002781867981
training step: 8880, total_loss: 5.273935317993164
training step: 8881, total_loss: 4.544243812561035
training step: 8882, total_loss: 5.141866683959961
training step: 8883, total_loss: 3.2152087688446045
training step: 8884, total_loss: 5.4784955978393555
training step: 8885, total_loss: 6.020866394042969
training step: 8886, total_loss: 5.332035064697266
training step: 8887, total_loss: 4.303386688232422
training step: 8888, total_loss: 5.1805009841918945
training step: 8889, total_loss: 2.632575035095215
training step: 8890, total_loss: 5.318037509918213
training step: 8891, total_loss: 4.988722801208496
training step: 8892, total_loss: 5.548537731170654
training step: 8893, total_loss: 1.6231513023376465
training step: 8894, total_loss: 5.322864532470703
training step: 8895, total_loss: 4.000922679901123
training step: 8896, total_loss: 3.5217995643615723
training step: 8897, total_loss: 4.520374298095703
training step: 8898, total_loss: 4.841704368591309
training step: 8899, total_loss: 5.1512627601623535
training step: 8900, total_loss: 4.476076602935791
training step: 8901, total_loss: 5.613590240478516
training step: 8902, total_loss: 4.595026969909668
training step: 8903, total_loss: 5.619292259216309
training step: 8904, total_loss: 5.373331069946289
training step: 8905, total_loss: 5.607109069824219
training step: 8906, total_loss: 4.020646095275879
training step: 8907, total_loss: 3.547341823577881
training step: 8908, total_loss: 4.652304649353027
training step: 8909, total_loss: 4.382053375244141
training step: 8910, total_loss: 4.767136573791504
training step: 8911, total_loss: 4.821105003356934
training step: 8912, total_loss: 6.189476013183594
training step: 8913, total_loss: 2.9239349365234375
training step: 8914, total_loss: 5.301538944244385
training step: 8915, total_loss: 6.128792762756348
training step: 8916, total_loss: 5.641546726226807
training step: 8917, total_loss: 4.18807315826416
training step: 8918, total_loss: 5.204568862915039
training step: 8919, total_loss: 5.282234191894531
training step: 8920, total_loss: 4.090880393981934
training step: 8921, total_loss: 4.47769832611084
training step: 8922, total_loss: 5.826035022735596
training step: 8923, total_loss: 5.438411712646484
training step: 8924, total_loss: 3.930759906768799
training step: 8925, total_loss: 3.65118670463562
training step: 8926, total_loss: 5.139691352844238
training step: 8927, total_loss: 5.05068826675415
training step: 8928, total_loss: 3.5224597454071045
training step: 8929, total_loss: 4.334305286407471
training step: 8930, total_loss: 5.552727699279785
training step: 8931, total_loss: 5.125679969787598
training step: 8932, total_loss: 4.340163230895996
training step: 8933, total_loss: 4.124305725097656
training step: 8934, total_loss: 4.098333835601807
training step: 8935, total_loss: 5.923430442810059
training step: 8936, total_loss: 6.03409481048584
training step: 8937, total_loss: 4.827186584472656
training step: 8938, total_loss: 4.096443176269531
training step: 8939, total_loss: 4.672989368438721
training step: 8940, total_loss: 5.340244770050049
training step: 8941, total_loss: 4.924106597900391
training step: 8942, total_loss: 4.342032432556152
training step: 8943, total_loss: 4.028744697570801
training step: 8944, total_loss: 5.913190841674805
training step: 8945, total_loss: 4.39082145690918
training step: 8946, total_loss: 5.729132175445557
training step: 8947, total_loss: 4.636013984680176
training step: 8948, total_loss: 3.376148223876953
training step: 8949, total_loss: 6.338657379150391
training step: 8950, total_loss: 5.481494903564453
training step: 8951, total_loss: 4.655383110046387
training step: 8952, total_loss: 5.100192546844482
training step: 8953, total_loss: 6.138301849365234
training step: 8954, total_loss: 4.76810359954834
training step: 8955, total_loss: 3.6516687870025635
training step: 8956, total_loss: 6.155084609985352
training step: 8957, total_loss: 4.944271564483643
training step: 8958, total_loss: 4.041553497314453
training step: 8959, total_loss: 5.473340034484863
training step: 8960, total_loss: 5.054887771606445
training step: 8961, total_loss: 4.386046409606934
training step: 8962, total_loss: 3.724172592163086
training step: 8963, total_loss: 4.012781620025635
training step: 8964, total_loss: 5.647730827331543
training step: 8965, total_loss: 4.763998985290527
training step: 8966, total_loss: 3.850534677505493
training step: 8967, total_loss: 3.1603989601135254
training step: 8968, total_loss: 4.279163360595703
training step: 8969, total_loss: 3.8773272037506104
training step: 8970, total_loss: 4.549759864807129
training step: 8971, total_loss: 4.435719013214111
training step: 8972, total_loss: 3.31294584274292
training step: 8973, total_loss: 5.4270477294921875
training step: 8974, total_loss: 5.821244239807129
training step: 8975, total_loss: 5.321173667907715
training step: 8976, total_loss: 5.196256637573242
training step: 8977, total_loss: 5.549587249755859
training step: 8978, total_loss: 4.861018657684326
training step: 8979, total_loss: 4.363948345184326
training step: 8980, total_loss: 3.426649808883667
training step: 8981, total_loss: 3.7420120239257812
training step: 8982, total_loss: 4.738731861114502
training step: 8983, total_loss: 4.531377792358398
training step: 8984, total_loss: 4.771485328674316
training step: 8985, total_loss: 5.084773540496826
training step: 8986, total_loss: 4.674241065979004
training step: 8987, total_loss: 4.193056106567383
training step: 8988, total_loss: 6.886169910430908
training step: 8989, total_loss: 5.68804931640625
training step: 8990, total_loss: 4.841204643249512
training step: 8991, total_loss: 4.560868263244629
training step: 8992, total_loss: 4.618101119995117
training step: 8993, total_loss: 4.031206130981445
training step: 8994, total_loss: 4.523562431335449
training step: 8995, total_loss: 5.240687370300293
training step: 8996, total_loss: 4.92227840423584
training step: 8997, total_loss: 4.012232780456543
training step: 8998, total_loss: 3.73128080368042
training step: 8999, total_loss: 4.957408428192139
training step: 9000, total_loss: 4.357466697692871
training step: 9001, total_loss: 5.367614269256592
training step: 9002, total_loss: 6.074443817138672
training step: 9003, total_loss: 4.230828285217285
training step: 9004, total_loss: 3.9062962532043457
training step: 9005, total_loss: 3.283276319503784
training step: 9006, total_loss: 5.7225494384765625
training step: 9007, total_loss: 3.5430474281311035
training step: 9008, total_loss: 5.379265308380127
training step: 9009, total_loss: 3.4666686058044434
training step: 9010, total_loss: 4.390357494354248
training step: 9011, total_loss: 4.542488098144531
training step: 9012, total_loss: 4.219663143157959
training step: 9013, total_loss: 5.286640167236328
training step: 9014, total_loss: 4.71212100982666
training step: 9015, total_loss: 4.652433395385742
training step: 9016, total_loss: 4.774142265319824
training step: 9017, total_loss: 5.012842178344727
training step: 9018, total_loss: 4.337056636810303
training step: 9019, total_loss: 4.449466705322266
training step: 9020, total_loss: 4.406939506530762
training step: 9021, total_loss: 4.822271823883057
training step: 9022, total_loss: 3.5614423751831055
training step: 9023, total_loss: 4.358404159545898
training step: 9024, total_loss: 3.3761720657348633
training step: 9025, total_loss: 5.913570404052734
training step: 9026, total_loss: 5.384374618530273
training step: 9027, total_loss: 4.57225227355957
training step: 9028, total_loss: 5.011501312255859
training step: 9029, total_loss: 3.481607437133789
training step: 9030, total_loss: 2.6633520126342773
training step: 9031, total_loss: 2.832643985748291
training step: 9032, total_loss: 5.175149917602539
training step: 9033, total_loss: 4.834756851196289
training step: 9034, total_loss: 4.460382461547852
training step: 9035, total_loss: 5.368890762329102
training step: 9036, total_loss: 3.7881975173950195
training step: 9037, total_loss: 3.463078737258911
training step: 9038, total_loss: 5.341333389282227
training step: 9039, total_loss: 3.354592800140381
training step: 9040, total_loss: 4.187530994415283
training step: 9041, total_loss: 3.6139702796936035
training step: 9042, total_loss: 2.590224504470825
training step: 9043, total_loss: 5.022572994232178
training step: 9044, total_loss: 5.621644496917725
training step: 9045, total_loss: 5.166086196899414
training step: 9046, total_loss: 2.5180788040161133
training step: 9047, total_loss: 3.611631393432617
training step: 9048, total_loss: 5.7059478759765625
training step: 9049, total_loss: 6.150548934936523
training step: 9050, total_loss: 4.025649070739746
training step: 9051, total_loss: 4.3975982666015625
training step: 9052, total_loss: 4.172434329986572
training step: 9053, total_loss: 4.750075817108154
training step: 9054, total_loss: 1.9719409942626953
training step: 9055, total_loss: 3.1039693355560303
training step: 9056, total_loss: 4.143703937530518
training step: 9057, total_loss: 5.0846967697143555
training step: 9058, total_loss: 4.588773727416992
training step: 9059, total_loss: 3.897937297821045
training step: 9060, total_loss: 4.33223819732666
training step: 9061, total_loss: 5.553535461425781
training step: 9062, total_loss: 6.319979667663574
training step: 9063, total_loss: 4.463921546936035
training step: 9064, total_loss: 3.8556408882141113
training step: 9065, total_loss: 4.392742156982422
training step: 9066, total_loss: 4.691750526428223
training step: 9067, total_loss: 6.110583305358887
training step: 9068, total_loss: 4.602482795715332
training step: 9069, total_loss: 5.1380205154418945
training step: 9070, total_loss: 4.784994125366211
training step: 9071, total_loss: 4.861210823059082
training step: 9072, total_loss: 4.124567985534668
training step: 9073, total_loss: 4.479307651519775
training step: 9074, total_loss: 5.0649003982543945
training step: 9075, total_loss: 4.323895454406738
training step: 9076, total_loss: 4.9430036544799805
training step: 9077, total_loss: 3.8736283779144287
training step: 9078, total_loss: 5.598350524902344
training step: 9079, total_loss: 3.504142999649048
training step: 9080, total_loss: 3.7645654678344727
training step: 9081, total_loss: 4.82647705078125
training step: 9082, total_loss: 4.910346031188965
training step: 9083, total_loss: 5.374885559082031
training step: 9084, total_loss: 5.09569787979126
training step: 9085, total_loss: 4.816765308380127
training step: 9086, total_loss: 5.409611701965332
training step: 9087, total_loss: 1.214159369468689
training step: 9088, total_loss: 3.437999725341797
training step: 9089, total_loss: 5.110172271728516
training step: 9090, total_loss: 3.682405710220337
training step: 9091, total_loss: 5.517114162445068
training step: 9092, total_loss: 4.9453959465026855
training step: 9093, total_loss: 3.974209785461426
training step: 9094, total_loss: 4.883236885070801
training step: 9095, total_loss: 3.557629346847534
training step: 9096, total_loss: 4.0317182540893555
training step: 9097, total_loss: 4.412837505340576
training step: 9098, total_loss: 5.107187747955322
training step: 9099, total_loss: 4.7180938720703125
training step: 9100, total_loss: 4.9644365310668945
training step: 9101, total_loss: 3.858370065689087
training step: 9102, total_loss: 5.9364118576049805
training step: 9103, total_loss: 4.514456748962402
training step: 9104, total_loss: 5.296942710876465
training step: 9105, total_loss: 4.9011125564575195
training step: 9106, total_loss: 3.6711297035217285
training step: 9107, total_loss: 4.100118160247803
training step: 9108, total_loss: 4.7573981285095215
training step: 9109, total_loss: 5.594805717468262
training step: 9110, total_loss: 5.316892147064209
training step: 9111, total_loss: 4.588857173919678
training step: 9112, total_loss: 4.1025285720825195
training step: 9113, total_loss: 4.547568321228027
training step: 9114, total_loss: 4.404350280761719
training step: 9115, total_loss: 5.372095108032227
training step: 9116, total_loss: 4.980864524841309
training step: 9117, total_loss: 4.052079677581787
training step: 9118, total_loss: 4.954266548156738
training step: 9119, total_loss: 4.687044143676758
training step: 9120, total_loss: 5.098085880279541
training step: 9121, total_loss: 2.7350916862487793
training step: 9122, total_loss: 4.121286392211914
training step: 9123, total_loss: 4.842048645019531
training step: 9124, total_loss: 5.370861053466797
training step: 9125, total_loss: 5.751270294189453
training step: 9126, total_loss: 6.1300201416015625
training step: 9127, total_loss: 4.834892272949219
training step: 9128, total_loss: 1.7750682830810547
training step: 9129, total_loss: 4.520709037780762
training step: 9130, total_loss: 3.951315402984619
training step: 9131, total_loss: 5.605564594268799
training step: 9132, total_loss: 4.64338493347168
training step: 9133, total_loss: 4.946335315704346
training step: 9134, total_loss: 4.243081092834473
training step: 9135, total_loss: 5.020477294921875
training step: 9136, total_loss: 5.394275665283203
training step: 9137, total_loss: 5.685388565063477
training step: 9138, total_loss: 4.646383762359619
training step: 9139, total_loss: 4.697577476501465
training step: 9140, total_loss: 4.4430155754089355
training step: 9141, total_loss: 5.4648118019104
training step: 9142, total_loss: 4.5998992919921875
training step: 9143, total_loss: 4.313878059387207
training step: 9144, total_loss: 3.8450727462768555
training step: 9145, total_loss: 4.860731601715088
training step: 9146, total_loss: 4.774259567260742
training step: 9147, total_loss: 4.850483417510986
training step: 9148, total_loss: 5.168756008148193
training step: 9149, total_loss: 5.830565452575684
training step: 9150, total_loss: 5.620302200317383
training step: 9151, total_loss: 4.381932258605957
training step: 9152, total_loss: 4.792925834655762
training step: 9153, total_loss: 3.7222671508789062
training step: 9154, total_loss: 4.093838691711426
training step: 9155, total_loss: 3.1260180473327637
training step: 9156, total_loss: 5.462045669555664
training step: 9157, total_loss: 6.409848213195801
training step: 9158, total_loss: 5.20782470703125
training step: 9159, total_loss: 4.800850868225098
training step: 9160, total_loss: 4.617141246795654
training step: 9161, total_loss: 3.226992607116699
training step: 9162, total_loss: 3.2147216796875
training step: 9163, total_loss: 4.499645233154297
training step: 9164, total_loss: 3.95074462890625
training step: 9165, total_loss: 4.960289001464844
training step: 9166, total_loss: 5.232873916625977
training step: 9167, total_loss: 4.980066299438477
training step: 9168, total_loss: 3.0074658393859863
training step: 9169, total_loss: 5.380237579345703
training step: 9170, total_loss: 3.7155375480651855
training step: 9171, total_loss: 5.724453926086426
training step: 9172, total_loss: 5.121387481689453
training step: 9173, total_loss: 5.0282111167907715
training step: 9174, total_loss: 1.4728660583496094
training step: 9175, total_loss: 4.920400619506836
training step: 9176, total_loss: 4.94757080078125
training step: 9177, total_loss: 5.6364946365356445
training step: 9178, total_loss: 4.121527194976807
training step: 9179, total_loss: 5.802977561950684
training step: 9180, total_loss: 5.510406494140625
training step: 9181, total_loss: 4.930849552154541
training step: 9182, total_loss: 4.855252265930176
training step: 9183, total_loss: 4.929370880126953
training step: 9184, total_loss: 3.003072500228882
training step: 9185, total_loss: 4.771790504455566
training step: 9186, total_loss: 4.434336185455322
training step: 9187, total_loss: 4.428839683532715
training step: 9188, total_loss: 4.104682445526123
training step: 9189, total_loss: 4.793349266052246
training step: 9190, total_loss: 5.3411126136779785
training step: 9191, total_loss: 3.347428798675537
training step: 9192, total_loss: 5.879986763000488
training step: 9193, total_loss: 5.181114673614502
training step: 9194, total_loss: 4.6745500564575195
training step: 9195, total_loss: 6.142068862915039
training step: 9196, total_loss: 4.9249396324157715
training step: 9197, total_loss: 4.639786720275879
training step: 9198, total_loss: 4.8906636238098145
training step: 9199, total_loss: 5.623456001281738
training step: 9200, total_loss: 4.416845798492432
training step: 9201, total_loss: 5.177562713623047
training step: 9202, total_loss: 4.950758934020996
training step: 9203, total_loss: 3.859208583831787
training step: 9204, total_loss: 5.134102821350098
training step: 9205, total_loss: 4.272787094116211
training step: 9206, total_loss: 5.071434497833252
training step: 9207, total_loss: 5.138758182525635
training step: 9208, total_loss: 4.64028787612915
training step: 9209, total_loss: 4.715580940246582
training step: 9210, total_loss: 3.8639535903930664
training step: 9211, total_loss: 5.295633316040039
training step: 9212, total_loss: 5.358837127685547
training step: 9213, total_loss: 5.442651748657227
training step: 9214, total_loss: 3.4116110801696777
training step: 9215, total_loss: 4.4846601486206055
training step: 9216, total_loss: 5.118257522583008
training step: 9217, total_loss: 5.566594123840332
training step: 9218, total_loss: 3.9381608963012695
training step: 9219, total_loss: 5.090511322021484
training step: 9220, total_loss: 4.5467529296875
training step: 9221, total_loss: 3.8418874740600586
training step: 9222, total_loss: 4.283023834228516
training step: 9223, total_loss: 5.806797504425049
training step: 9224, total_loss: 2.9341073036193848
training step: 9225, total_loss: 4.501891136169434
training step: 9226, total_loss: 4.730563163757324
training step: 9227, total_loss: 4.855630874633789
training step: 9228, total_loss: 4.813433647155762
training step: 9229, total_loss: 4.488018035888672
training step: 9230, total_loss: 5.893398284912109
training step: 9231, total_loss: 4.5221967697143555
training step: 9232, total_loss: 4.59073543548584
training step: 9233, total_loss: 4.159787178039551
training step: 9234, total_loss: 3.927604913711548
training step: 9235, total_loss: 5.626049518585205
training step: 9236, total_loss: 4.421678066253662
training step: 9237, total_loss: 3.911090135574341
training step: 9238, total_loss: 6.171860694885254
training step: 9239, total_loss: 4.299942970275879
training step: 9240, total_loss: 3.3322596549987793
training step: 9241, total_loss: 5.058442115783691
training step: 9242, total_loss: 4.375160217285156
training step: 9243, total_loss: 4.278563976287842
training step: 9244, total_loss: 5.800803184509277
training step: 9245, total_loss: 4.0150909423828125
training step: 9246, total_loss: 5.891273021697998
training step: 9247, total_loss: 3.7885489463806152
training step: 9248, total_loss: 4.182790756225586
training step: 9249, total_loss: 4.80528450012207
training step: 9250, total_loss: 4.391733169555664
training step: 9251, total_loss: 5.42523193359375
training step: 9252, total_loss: 3.5792295932769775
training step: 9253, total_loss: 6.183176517486572
training step: 9254, total_loss: 6.622430801391602
training step: 9255, total_loss: 5.246397972106934
training step: 9256, total_loss: 4.170462131500244
training step: 9257, total_loss: 6.274989128112793
training step: 9258, total_loss: 4.290874481201172
training step: 9259, total_loss: 5.05403995513916
training step: 9260, total_loss: 5.40103816986084
training step: 9261, total_loss: 3.79707407951355
training step: 9262, total_loss: 5.857886791229248
training step: 9263, total_loss: 5.142775535583496
training step: 9264, total_loss: 4.5296549797058105
training step: 9265, total_loss: 3.9638171195983887
training step: 9266, total_loss: 4.231830596923828
training step: 9267, total_loss: 4.621809005737305
training step: 9268, total_loss: 4.425295829772949
training step: 9269, total_loss: 4.695840835571289
training step: 9270, total_loss: 4.524841785430908
training step: 9271, total_loss: 4.839125156402588
training step: 9272, total_loss: 5.28292179107666
training step: 9273, total_loss: 4.530673980712891
training step: 9274, total_loss: 3.2742581367492676
training step: 9275, total_loss: 5.353130340576172
training step: 9276, total_loss: 4.440558433532715
training step: 9277, total_loss: 3.5721940994262695
training step: 9278, total_loss: 5.151191711425781
training step: 9279, total_loss: 5.213312149047852
training step: 9280, total_loss: 5.904787063598633
training step: 9281, total_loss: 5.822450637817383
training step: 9282, total_loss: 4.421211242675781
training step: 9283, total_loss: 3.926151990890503
training step: 9284, total_loss: 5.036944389343262
training step: 9285, total_loss: 5.131577014923096
training step: 9286, total_loss: 4.689528465270996
training step: 9287, total_loss: 4.744555950164795
training step: 9288, total_loss: 4.405230522155762
training step: 9289, total_loss: 4.995028495788574
training step: 9290, total_loss: 3.477966070175171
training step: 9291, total_loss: 4.958232879638672
training step: 9292, total_loss: 4.669503211975098
training step: 9293, total_loss: 5.441699981689453
training step: 9294, total_loss: 5.054939270019531
training step: 9295, total_loss: 3.786529541015625
training step: 9296, total_loss: 4.8437180519104
training step: 9297, total_loss: 4.904363632202148
training step: 9298, total_loss: 4.754406929016113
training step: 9299, total_loss: 5.1234049797058105
training step: 9300, total_loss: 5.050605297088623
training step: 9301, total_loss: 5.070517539978027
training step: 9302, total_loss: 4.412596702575684
training step: 9303, total_loss: 4.130192756652832
training step: 9304, total_loss: 3.822267532348633
training step: 9305, total_loss: 4.595933437347412
training step: 9306, total_loss: 3.412342071533203
training step: 9307, total_loss: 3.4685418605804443
training step: 9308, total_loss: 4.5123186111450195
training step: 9309, total_loss: 5.009360313415527
training step: 9310, total_loss: 5.36421012878418
training step: 9311, total_loss: 3.587344169616699
training step: 9312, total_loss: 4.660617828369141
training step: 9313, total_loss: 3.807281970977783
training step: 9314, total_loss: 7.445859909057617
training step: 9315, total_loss: 5.527656555175781
training step: 9316, total_loss: 4.276488780975342
training step: 9317, total_loss: 3.9596753120422363
training step: 9318, total_loss: 4.484827518463135
training step: 9319, total_loss: 4.749747276306152
training step: 9320, total_loss: 4.296324729919434
training step: 9321, total_loss: 5.382294654846191
training step: 9322, total_loss: 4.083130836486816
training step: 9323, total_loss: 5.406523704528809
training step: 9324, total_loss: 4.83466911315918
training step: 9325, total_loss: 4.912909507751465
training step: 9326, total_loss: 4.124030113220215
training step: 9327, total_loss: 4.614917755126953
training step: 9328, total_loss: 4.996744155883789
training step: 9329, total_loss: 4.894854545593262
training step: 9330, total_loss: 4.68358850479126
training step: 9331, total_loss: 4.38049840927124
training step: 9332, total_loss: 4.849189758300781
training step: 9333, total_loss: 5.976421356201172
training step: 9334, total_loss: 3.5704522132873535
training step: 9335, total_loss: 5.313078880310059
training step: 9336, total_loss: 5.297267913818359
training step: 9337, total_loss: 5.287632942199707
training step: 9338, total_loss: 3.7274551391601562
training step: 9339, total_loss: 4.810169219970703
training step: 9340, total_loss: 4.719722270965576
training step: 9341, total_loss: 5.277339935302734
training step: 9342, total_loss: 4.9816718101501465
training step: 9343, total_loss: 4.105936050415039
training step: 9344, total_loss: 4.790835857391357
training step: 9345, total_loss: 4.799114227294922
training step: 9346, total_loss: 5.729848861694336
training step: 9347, total_loss: 3.9727401733398438
training step: 9348, total_loss: 4.23425817489624
training step: 9349, total_loss: 5.137789726257324
training step: 9350, total_loss: 3.2717862129211426
training step: 9351, total_loss: 6.5659708976745605
training step: 9352, total_loss: 4.896796226501465
training step: 9353, total_loss: 6.920182228088379
training step: 9354, total_loss: 4.604792594909668
training step: 9355, total_loss: 6.486489295959473
training step: 9356, total_loss: 5.933133125305176
training step: 9357, total_loss: 4.689902305603027
training step: 9358, total_loss: 4.589529514312744
training step: 9359, total_loss: 5.572625160217285
training step: 9360, total_loss: 4.432364463806152
training step: 9361, total_loss: 4.849758148193359
training step: 9362, total_loss: 4.380086898803711
training step: 9363, total_loss: 4.016551494598389
training step: 9364, total_loss: 4.101799011230469
training step: 9365, total_loss: 4.768983840942383
training step: 9366, total_loss: 6.153779983520508
training step: 9367, total_loss: 4.935635089874268
training step: 9368, total_loss: 4.500200271606445
training step: 9369, total_loss: 3.6847057342529297
training step: 9370, total_loss: 5.184072017669678
training step: 9371, total_loss: 4.360638618469238
training step: 9372, total_loss: 4.720636367797852
training step: 9373, total_loss: 3.8387162685394287
training step: 9374, total_loss: 2.7037532329559326
training step: 9375, total_loss: 4.614747047424316
training step: 9376, total_loss: 3.335218906402588
training step: 9377, total_loss: 4.830924034118652
training step: 9378, total_loss: 4.8826904296875
training step: 9379, total_loss: 4.390202522277832
training step: 9380, total_loss: 4.392405986785889
training step: 9381, total_loss: 5.848002910614014
training step: 9382, total_loss: 3.2950782775878906
training step: 9383, total_loss: 5.510964393615723
training step: 9384, total_loss: 6.546201229095459
training step: 9385, total_loss: 5.661737442016602
training step: 9386, total_loss: 5.731734275817871
training step: 9387, total_loss: 5.025511264801025
training step: 9388, total_loss: 4.447238922119141
training step: 9389, total_loss: 4.670783042907715
training step: 9390, total_loss: 5.276102542877197
training step: 9391, total_loss: 2.195578098297119
training step: 9392, total_loss: 5.288388252258301
training step: 9393, total_loss: 5.498424530029297
training step: 9394, total_loss: 4.380863189697266
training step: 9395, total_loss: 5.40897274017334
training step: 9396, total_loss: 5.594220161437988
training step: 9397, total_loss: 3.2026872634887695
training step: 9398, total_loss: 2.7829771041870117
training step: 9399, total_loss: 4.828034400939941
training step: 9400, total_loss: 4.69106388092041
training step: 9401, total_loss: 4.946196556091309
training step: 9402, total_loss: 4.535617828369141
training step: 9403, total_loss: 5.570066452026367
training step: 9404, total_loss: 5.24210262298584
training step: 9405, total_loss: 4.9110894203186035
training step: 9406, total_loss: 5.250566482543945
training step: 9407, total_loss: 5.353520393371582
training step: 9408, total_loss: 5.864230155944824
training step: 9409, total_loss: 4.70389461517334
training step: 9410, total_loss: 5.710472106933594
training step: 9411, total_loss: 4.787676811218262
training step: 9412, total_loss: 5.258533477783203
training step: 9413, total_loss: 4.732969760894775
training step: 9414, total_loss: 2.2914586067199707
training step: 9415, total_loss: 5.139805793762207
training step: 9416, total_loss: 4.792227745056152
training step: 9417, total_loss: 3.536536931991577
training step: 9418, total_loss: 6.008345127105713
training step: 9419, total_loss: 5.57858943939209
training step: 9420, total_loss: 3.532571792602539
training step: 9421, total_loss: 4.478761672973633
training step: 9422, total_loss: 5.715089797973633
training step: 9423, total_loss: 5.266673564910889
training step: 9424, total_loss: 4.145325183868408
training step: 9425, total_loss: 5.16759729385376
training step: 9426, total_loss: 4.295286655426025
training step: 9427, total_loss: 3.399554491043091
training step: 9428, total_loss: 4.731240272521973
training step: 9429, total_loss: 5.955167770385742
training step: 9430, total_loss: 3.118889331817627
training step: 9431, total_loss: 2.26200532913208
training step: 9432, total_loss: 3.137777090072632
training step: 9433, total_loss: 1.4572365283966064
training step: 9434, total_loss: 3.977111577987671
training step: 9435, total_loss: 4.639615535736084
training step: 9436, total_loss: 4.949436187744141
training step: 9437, total_loss: 4.8115081787109375
training step: 9438, total_loss: 5.588818550109863
training step: 9439, total_loss: 4.7707414627075195
training step: 9440, total_loss: 4.653563022613525
training step: 9441, total_loss: 4.830136775970459
training step: 9442, total_loss: 4.730410575866699
training step: 9443, total_loss: 4.982108116149902
training step: 9444, total_loss: 5.118061065673828
training step: 9445, total_loss: 4.998456001281738
training step: 9446, total_loss: 5.024057388305664
training step: 9447, total_loss: 4.9408674240112305
training step: 9448, total_loss: 3.5263116359710693
training step: 9449, total_loss: 3.7790260314941406
training step: 9450, total_loss: 6.510669708251953
training step: 9451, total_loss: 5.2388105392456055
training step: 9452, total_loss: 4.124671459197998
training step: 9453, total_loss: 5.027365684509277
training step: 9454, total_loss: 5.525639057159424
training step: 9455, total_loss: 5.471560001373291
training step: 9456, total_loss: 4.773136138916016
training step: 9457, total_loss: 4.923666954040527
training step: 9458, total_loss: 5.0493879318237305
training step: 9459, total_loss: 5.093474388122559
training step: 9460, total_loss: 4.90785551071167
training step: 9461, total_loss: 4.352106094360352
training step: 9462, total_loss: 5.762840270996094
training step: 9463, total_loss: 3.764263391494751
training step: 9464, total_loss: 4.106291770935059
training step: 9465, total_loss: 5.632565975189209
training step: 9466, total_loss: 5.085305213928223
training step: 9467, total_loss: 4.436823844909668
training step: 9468, total_loss: 5.264811992645264
training step: 9469, total_loss: 4.164039611816406
training step: 9470, total_loss: 3.131707191467285
training step: 9471, total_loss: 3.929006338119507
training step: 9472, total_loss: 5.582625389099121
training step: 9473, total_loss: 5.319904804229736
training step: 9474, total_loss: 4.902218818664551
training step: 9475, total_loss: 4.85773229598999
training step: 9476, total_loss: 3.622274398803711
training step: 9477, total_loss: 3.953547954559326
training step: 9478, total_loss: 5.211773872375488
training step: 9479, total_loss: 4.702887535095215
training step: 9480, total_loss: 4.585896968841553
training step: 9481, total_loss: 4.415722370147705
training step: 9482, total_loss: 4.1930389404296875
training step: 9483, total_loss: 5.920334815979004
training step: 9484, total_loss: 5.249795436859131
training step: 9485, total_loss: 5.068155288696289
training step: 9486, total_loss: 5.13781213760376
training step: 9487, total_loss: 3.724337577819824
training step: 9488, total_loss: 4.045367240905762
training step: 9489, total_loss: 4.377362251281738
training step: 9490, total_loss: 3.5950584411621094
training step: 9491, total_loss: 4.76199197769165
training step: 9492, total_loss: 5.061366081237793
training step: 9493, total_loss: 5.213515281677246
training step: 9494, total_loss: 4.954574108123779
training step: 9495, total_loss: 3.7272286415100098
training step: 9496, total_loss: 5.003820419311523
training step: 9497, total_loss: 5.551839828491211
training step: 9498, total_loss: 2.0809850692749023
training step: 9499, total_loss: 4.412057399749756
training step: 9500, total_loss: 3.9892420768737793
training step: 9501, total_loss: 5.577335357666016
training step: 9502, total_loss: 4.279684066772461
training step: 9503, total_loss: 4.542792320251465
training step: 9504, total_loss: 4.458347797393799
training step: 9505, total_loss: 4.214869499206543
training step: 9506, total_loss: 3.4556915760040283
training step: 9507, total_loss: 4.744109630584717
training step: 9508, total_loss: 4.5480637550354
training step: 9509, total_loss: 3.5629072189331055
training step: 9510, total_loss: 4.729513645172119
training step: 9511, total_loss: 5.000255584716797
training step: 9512, total_loss: 4.249076843261719
training step: 9513, total_loss: 4.154772758483887
training step: 9514, total_loss: 4.38895320892334
training step: 9515, total_loss: 5.204504013061523
training step: 9516, total_loss: 3.5361127853393555
training step: 9517, total_loss: 5.386300086975098
training step: 9518, total_loss: 4.947744369506836
training step: 9519, total_loss: 3.578660488128662
training step: 9520, total_loss: 4.746685028076172
training step: 9521, total_loss: 4.646991729736328
training step: 9522, total_loss: 4.592704772949219
training step: 9523, total_loss: 5.1373291015625
training step: 9524, total_loss: 7.840351104736328
training step: 9525, total_loss: 3.380361795425415
training step: 9526, total_loss: 3.9524924755096436
training step: 9527, total_loss: 6.05242919921875
training step: 9528, total_loss: 4.705487251281738
training step: 9529, total_loss: 2.790104866027832
training step: 9530, total_loss: 4.284974098205566
training step: 9531, total_loss: 4.134260654449463
training step: 9532, total_loss: 4.168579578399658
training step: 9533, total_loss: 5.2140727043151855
training step: 9534, total_loss: 4.91798210144043
training step: 9535, total_loss: 5.192089080810547
training step: 9536, total_loss: 5.613142490386963
training step: 9537, total_loss: 4.419969081878662
training step: 9538, total_loss: 4.662372589111328
training step: 9539, total_loss: 4.140964031219482
training step: 9540, total_loss: 5.371944427490234
training step: 9541, total_loss: 1.8074570894241333
training step: 9542, total_loss: 3.230283260345459
training step: 9543, total_loss: 4.641146659851074
training step: 9544, total_loss: 4.657454490661621
training step: 9545, total_loss: 4.894391059875488
training step: 9546, total_loss: 3.299933433532715
training step: 9547, total_loss: 4.727725028991699
training step: 9548, total_loss: 3.648777961730957
training step: 9549, total_loss: 5.334230422973633
training step: 9550, total_loss: 4.00892972946167
training step: 9551, total_loss: 4.705909252166748
training step: 9552, total_loss: 1.1406316757202148
training step: 9553, total_loss: 5.773143768310547
training step: 9554, total_loss: 4.6247453689575195
training step: 9555, total_loss: 4.633411407470703
training step: 9556, total_loss: 5.663459777832031
training step: 9557, total_loss: 5.726998329162598
training step: 9558, total_loss: 5.08243465423584
training step: 9559, total_loss: 5.155397891998291
training step: 9560, total_loss: 4.6855854988098145
training step: 9561, total_loss: 6.0062174797058105
training step: 9562, total_loss: 4.105520248413086
training step: 9563, total_loss: 3.281050443649292
training step: 9564, total_loss: 4.022688865661621
training step: 9565, total_loss: 5.688097953796387
training step: 9566, total_loss: 6.073746681213379
training step: 9567, total_loss: 4.546659469604492
training step: 9568, total_loss: 5.064087390899658
training step: 9569, total_loss: 4.621415615081787
training step: 9570, total_loss: 4.005971431732178
training step: 9571, total_loss: 4.895438194274902
training step: 9572, total_loss: 3.9195556640625
training step: 9573, total_loss: 4.682447910308838
training step: 9574, total_loss: 3.7551140785217285
training step: 9575, total_loss: 5.0787177085876465
training step: 9576, total_loss: 3.8770852088928223
training step: 9577, total_loss: 5.218732833862305
training step: 9578, total_loss: 5.379921913146973
training step: 9579, total_loss: 3.057507038116455
training step: 9580, total_loss: 4.518425941467285
training step: 9581, total_loss: 5.4684600830078125
training step: 9582, total_loss: 4.312889575958252
training step: 9583, total_loss: 3.4875941276550293
training step: 9584, total_loss: 6.202358245849609
training step: 9585, total_loss: 3.959111213684082
training step: 9586, total_loss: 5.115076065063477
training step: 9587, total_loss: 5.217467784881592
training step: 9588, total_loss: 5.267996788024902
training step: 9589, total_loss: 3.9373092651367188
training step: 9590, total_loss: 4.2368011474609375
training step: 9591, total_loss: 5.705723285675049
training step: 9592, total_loss: 5.119870185852051
training step: 9593, total_loss: 3.918670654296875
training step: 9594, total_loss: 5.407332420349121
training step: 9595, total_loss: 4.4679365158081055
training step: 9596, total_loss: 4.785208225250244
training step: 9597, total_loss: 4.336923599243164
training step: 9598, total_loss: 4.47890043258667
training step: 9599, total_loss: 4.255453109741211
training step: 9600, total_loss: 3.540928840637207
training step: 9601, total_loss: 4.539577484130859
training step: 9602, total_loss: 5.250268936157227
training step: 9603, total_loss: 5.549055576324463
training step: 9604, total_loss: 4.5085344314575195
training step: 9605, total_loss: 4.98919677734375
training step: 9606, total_loss: 4.142011642456055
training step: 9607, total_loss: 2.6627604961395264
training step: 9608, total_loss: 5.465424537658691
training step: 9609, total_loss: 4.398879051208496
training step: 9610, total_loss: 3.3505797386169434
training step: 9611, total_loss: 4.4618988037109375
training step: 9612, total_loss: 3.8905386924743652
training step: 9613, total_loss: 5.299960613250732
training step: 9614, total_loss: 4.1855292320251465
training step: 9615, total_loss: 4.340605735778809
training step: 9616, total_loss: 4.772429466247559
training step: 9617, total_loss: 4.785689353942871
training step: 9618, total_loss: 3.2217929363250732
training step: 9619, total_loss: 5.378243923187256
training step: 9620, total_loss: 5.446894645690918
training step: 9621, total_loss: 4.5884222984313965
training step: 9622, total_loss: 5.653754234313965
training step: 9623, total_loss: 5.1733598709106445
training step: 9624, total_loss: 5.337510108947754
training step: 9625, total_loss: 5.170851707458496
training step: 9626, total_loss: 4.802535057067871
training step: 9627, total_loss: 5.932005882263184
training step: 9628, total_loss: 5.226677894592285
training step: 9629, total_loss: 4.524096965789795
training step: 9630, total_loss: 3.7558746337890625
training step: 9631, total_loss: 5.0952229499816895
training step: 9632, total_loss: 4.527945041656494
training step: 9633, total_loss: 4.847058296203613
training step: 9634, total_loss: 4.329888343811035
training step: 9635, total_loss: 4.752584457397461
training step: 9636, total_loss: 4.562215328216553
training step: 9637, total_loss: 4.990898132324219
training step: 9638, total_loss: 4.877623081207275
training step: 9639, total_loss: 5.7217116355896
training step: 9640, total_loss: 3.4198625087738037
training step: 9641, total_loss: 4.697292327880859
training step: 9642, total_loss: 5.445363998413086
training step: 9643, total_loss: 4.981527328491211
training step: 9644, total_loss: 4.548572540283203
training step: 9645, total_loss: 5.510998725891113
training step: 9646, total_loss: 5.075079917907715
training step: 9647, total_loss: 4.358939170837402
training step: 9648, total_loss: 5.566184043884277
training step: 9649, total_loss: 5.274822235107422
training step: 9650, total_loss: 3.825896739959717
training step: 9651, total_loss: 4.551053047180176
training step: 9652, total_loss: 5.346920967102051
training step: 9653, total_loss: 5.164342403411865
training step: 9654, total_loss: 3.2111458778381348
training step: 9655, total_loss: 4.583309173583984
training step: 9656, total_loss: 5.273597717285156
training step: 9657, total_loss: 5.095081329345703
training step: 9658, total_loss: 4.065307140350342
training step: 9659, total_loss: 5.155250072479248
training step: 9660, total_loss: 3.198681354522705
training step: 9661, total_loss: 4.327020645141602
training step: 9662, total_loss: 5.319936275482178
training step: 9663, total_loss: 5.790188789367676
training step: 9664, total_loss: 4.7956976890563965
training step: 9665, total_loss: 4.504572868347168
training step: 9666, total_loss: 4.503028392791748
training step: 9667, total_loss: 4.498868465423584
training step: 9668, total_loss: 6.045644283294678
training step: 9669, total_loss: 4.051429271697998
training step: 9670, total_loss: 4.818385601043701
training step: 9671, total_loss: 5.280134677886963
training step: 9672, total_loss: 4.68548059463501
training step: 9673, total_loss: 5.984524726867676
training step: 9674, total_loss: 4.136981010437012
training step: 9675, total_loss: 4.748210430145264
training step: 9676, total_loss: 5.414647102355957
training step: 9677, total_loss: 4.497278213500977
training step: 9678, total_loss: 4.105461120605469
training step: 9679, total_loss: 4.631033897399902
training step: 9680, total_loss: 4.1145339012146
training step: 9681, total_loss: 3.760366678237915
training step: 9682, total_loss: 4.435403823852539
training step: 9683, total_loss: 5.820587158203125
training step: 9684, total_loss: 4.280832290649414
training step: 9685, total_loss: 5.032632827758789
training step: 9686, total_loss: 4.652496337890625
training step: 9687, total_loss: 5.479909896850586
training step: 9688, total_loss: 4.217138290405273
training step: 9689, total_loss: 3.456259250640869
training step: 9690, total_loss: 4.000259876251221
training step: 9691, total_loss: 5.077159881591797
training step: 9692, total_loss: 5.230815887451172
training step: 9693, total_loss: 3.635097026824951
training step: 9694, total_loss: 5.891915798187256
training step: 9695, total_loss: 4.01425313949585
training step: 9696, total_loss: 4.92722225189209
training step: 9697, total_loss: 5.19271183013916
training step: 9698, total_loss: 4.430324077606201
training step: 9699, total_loss: 4.496983528137207
training step: 9700, total_loss: 4.991611480712891
training step: 9701, total_loss: 5.480133056640625
training step: 9702, total_loss: 5.420985698699951
training step: 9703, total_loss: 3.5003132820129395
training step: 9704, total_loss: 4.5016584396362305
training step: 9705, total_loss: 5.099802494049072
training step: 9706, total_loss: 5.703647613525391
training step: 9707, total_loss: 4.165273189544678
training step: 9708, total_loss: 4.354465484619141
training step: 9709, total_loss: 4.337355136871338
training step: 9710, total_loss: 6.01564359664917
training step: 9711, total_loss: 5.088466167449951
training step: 9712, total_loss: 3.2453231811523438
training step: 9713, total_loss: 6.099279403686523
training step: 9714, total_loss: 4.714970588684082
training step: 9715, total_loss: 3.5767412185668945
training step: 9716, total_loss: 4.384230136871338
training step: 9717, total_loss: 5.5242791175842285
training step: 9718, total_loss: 6.510438919067383
training step: 9719, total_loss: 5.054808616638184
training step: 9720, total_loss: 3.945570468902588
training step: 9721, total_loss: 5.15740966796875
training step: 9722, total_loss: 5.757309436798096
training step: 9723, total_loss: 4.653944969177246
training step: 9724, total_loss: 4.203071594238281
training step: 9725, total_loss: 5.293822765350342
training step: 9726, total_loss: 4.654706954956055
training step: 9727, total_loss: 6.277257919311523
training step: 9728, total_loss: 2.9922118186950684
training step: 9729, total_loss: 4.269453525543213
training step: 9730, total_loss: 4.381246566772461
training step: 9731, total_loss: 4.85770845413208
training step: 9732, total_loss: 3.5750222206115723
training step: 9733, total_loss: 5.572873115539551
training step: 9734, total_loss: 4.7825093269348145
training step: 9735, total_loss: 4.456811428070068
training step: 9736, total_loss: 4.682405471801758
training step: 9737, total_loss: 3.746129035949707
training step: 9738, total_loss: 4.124991416931152
training step: 9739, total_loss: 5.266960144042969
training step: 9740, total_loss: 3.6008338928222656
training step: 9741, total_loss: 5.044632434844971
training step: 9742, total_loss: 3.6239376068115234
training step: 9743, total_loss: 5.404170513153076
training step: 9744, total_loss: 4.276289463043213
training step: 9745, total_loss: 4.845900535583496
training step: 9746, total_loss: 4.712980270385742
training step: 9747, total_loss: 3.9697251319885254
training step: 9748, total_loss: 5.045661926269531
training step: 9749, total_loss: 4.584564685821533
training step: 9750, total_loss: 4.74752140045166
training step: 9751, total_loss: 3.4294869899749756
training step: 9752, total_loss: 3.509394645690918
training step: 9753, total_loss: 5.315649032592773
training step: 9754, total_loss: 4.525633811950684
training step: 9755, total_loss: 3.7859315872192383
training step: 9756, total_loss: 4.217215538024902
training step: 9757, total_loss: 4.797976493835449
training step: 9758, total_loss: 6.528713226318359
training step: 9759, total_loss: 4.946827411651611
training step: 9760, total_loss: 3.209749221801758
training step: 9761, total_loss: 4.67335319519043
training step: 9762, total_loss: 4.9659423828125
training step: 9763, total_loss: 4.688735485076904
training step: 9764, total_loss: 4.282800674438477
training step: 9765, total_loss: 5.995553016662598
training step: 9766, total_loss: 5.216226577758789
training step: 9767, total_loss: 4.153350830078125
training step: 9768, total_loss: 4.841919422149658
training step: 9769, total_loss: 2.6401636600494385
training step: 9770, total_loss: 5.328558444976807
training step: 9771, total_loss: 4.120826721191406
training step: 9772, total_loss: 5.055057048797607
training step: 9773, total_loss: 3.8797359466552734
training step: 9774, total_loss: 5.3724446296691895
training step: 9775, total_loss: 5.600176811218262
training step: 9776, total_loss: 8.103885650634766
training step: 9777, total_loss: 4.393434047698975
training step: 9778, total_loss: 3.709538221359253
training step: 9779, total_loss: 5.7317609786987305
training step: 9780, total_loss: 5.631731986999512
training step: 9781, total_loss: 4.058715343475342
training step: 9782, total_loss: 4.605664253234863
training step: 9783, total_loss: 4.654216766357422
training step: 9784, total_loss: 5.532605171203613
training step: 9785, total_loss: 4.8695173263549805
training step: 9786, total_loss: 3.6525192260742188
training step: 9787, total_loss: 5.10701847076416
training step: 9788, total_loss: 3.4144859313964844
training step: 9789, total_loss: 4.235964775085449
training step: 9790, total_loss: 4.209423065185547
training step: 9791, total_loss: 4.599109172821045
training step: 9792, total_loss: 4.907462120056152
training step: 9793, total_loss: 2.1764676570892334
training step: 9794, total_loss: 4.528307914733887
training step: 9795, total_loss: 5.064200401306152
training step: 9796, total_loss: 3.820794105529785
training step: 9797, total_loss: 5.334934234619141
training step: 9798, total_loss: 4.7933526039123535
training step: 9799, total_loss: 4.148236274719238
training step: 9800, total_loss: 3.7345495223999023
training step: 9801, total_loss: 4.981271743774414
training step: 9802, total_loss: 3.60726261138916
training step: 9803, total_loss: 5.7580156326293945
training step: 9804, total_loss: 7.187006950378418
training step: 9805, total_loss: 5.208912372589111
training step: 9806, total_loss: 4.560609340667725
training step: 9807, total_loss: 4.348183631896973
training step: 9808, total_loss: 5.453761100769043
training step: 9809, total_loss: 5.372978687286377
training step: 9810, total_loss: 5.7507734298706055
training step: 9811, total_loss: 4.0674309730529785
training step: 9812, total_loss: 5.394721031188965
training step: 9813, total_loss: 5.288649082183838
training step: 9814, total_loss: 5.106132984161377
training step: 9815, total_loss: 4.265445232391357
training step: 9816, total_loss: 4.405727386474609
training step: 9817, total_loss: 3.5106654167175293
training step: 9818, total_loss: 3.612208843231201
training step: 9819, total_loss: 4.2185540199279785
training step: 9820, total_loss: 5.351836681365967
training step: 9821, total_loss: 1.9831550121307373
training step: 9822, total_loss: 5.222808837890625
training step: 9823, total_loss: 4.413101673126221
training step: 9824, total_loss: 5.1186442375183105
training step: 9825, total_loss: 5.079122543334961
training step: 9826, total_loss: 4.395204544067383
training step: 9827, total_loss: 5.520312786102295
training step: 9828, total_loss: 2.8758320808410645
training step: 9829, total_loss: 5.133118629455566
training step: 9830, total_loss: 5.513690948486328
training step: 9831, total_loss: 3.3361988067626953
training step: 9832, total_loss: 5.6440582275390625
training step: 9833, total_loss: 4.328978538513184
training step: 9834, total_loss: 4.720541954040527
training step: 9835, total_loss: 3.777276039123535
training step: 9836, total_loss: 3.7698588371276855
training step: 9837, total_loss: 6.111241340637207
training step: 9838, total_loss: 5.4571757316589355
training step: 9839, total_loss: 3.431032180786133
training step: 9840, total_loss: 5.334068775177002
training step: 9841, total_loss: 4.539142608642578
training step: 9842, total_loss: 2.554610013961792
training step: 9843, total_loss: 4.924756050109863
training step: 9844, total_loss: 4.7435221672058105
training step: 9845, total_loss: 3.7300820350646973
training step: 9846, total_loss: 4.998239994049072
training step: 9847, total_loss: 4.36945915222168
training step: 9848, total_loss: 4.381178379058838
training step: 9849, total_loss: 3.3290367126464844
training step: 9850, total_loss: 4.651821136474609
training step: 9851, total_loss: 4.572281837463379
training step: 9852, total_loss: 6.49412727355957
training step: 9853, total_loss: 3.884643077850342
training step: 9854, total_loss: 5.422811031341553
training step: 9855, total_loss: 5.196145534515381
training step: 9856, total_loss: 3.964385509490967
training step: 9857, total_loss: 5.880950927734375
training step: 9858, total_loss: 5.084971904754639
training step: 9859, total_loss: 4.142818927764893
training step: 9860, total_loss: 5.131567001342773
training step: 9861, total_loss: 3.837660789489746
training step: 9862, total_loss: 5.033172607421875
training step: 9863, total_loss: 4.525204181671143
training step: 9864, total_loss: 3.997015953063965
training step: 9865, total_loss: 5.035609245300293
training step: 9866, total_loss: 4.392759323120117
training step: 9867, total_loss: 5.636872291564941
training step: 9868, total_loss: 4.2674641609191895
training step: 9869, total_loss: 4.9031267166137695
training step: 9870, total_loss: 5.511873245239258
training step: 9871, total_loss: 4.699604511260986
training step: 9872, total_loss: 4.572113037109375
training step: 9873, total_loss: 4.784698486328125
training step: 9874, total_loss: 4.705601692199707
training step: 9875, total_loss: 4.679990768432617
training step: 9876, total_loss: 6.644402503967285
training step: 9877, total_loss: 5.462806701660156
training step: 9878, total_loss: 1.406570315361023
training step: 9879, total_loss: 3.9366579055786133
training step: 9880, total_loss: 4.492807865142822
training step: 9881, total_loss: 5.015604019165039
training step: 9882, total_loss: 4.434183597564697
training step: 9883, total_loss: 6.1117048263549805
training step: 9884, total_loss: 5.799566268920898
training step: 9885, total_loss: 4.543116569519043
training step: 9886, total_loss: 3.2830910682678223
training step: 9887, total_loss: 4.417909622192383
training step: 9888, total_loss: 2.9233322143554688
training step: 9889, total_loss: 4.5287885665893555
training step: 9890, total_loss: 4.776736259460449
training step: 9891, total_loss: 5.4376630783081055
training step: 9892, total_loss: 4.6287522315979
training step: 9893, total_loss: 3.682955026626587
training step: 9894, total_loss: 3.7337253093719482
training step: 9895, total_loss: 5.203298568725586
training step: 9896, total_loss: 5.445648670196533
training step: 9897, total_loss: 3.8600802421569824
training step: 9898, total_loss: 4.733012676239014
training step: 9899, total_loss: 4.935847759246826
training step: 9900, total_loss: 5.362397193908691
training step: 9901, total_loss: 4.684304714202881
training step: 9902, total_loss: 5.250389099121094
training step: 9903, total_loss: 4.861583709716797
training step: 9904, total_loss: 4.159352779388428
training step: 9905, total_loss: 4.850290298461914
training step: 9906, total_loss: 2.8520126342773438
training step: 9907, total_loss: 4.3096022605896
training step: 9908, total_loss: 4.000359058380127
training step: 9909, total_loss: 4.223757743835449
training step: 9910, total_loss: 4.044006824493408
training step: 9911, total_loss: 3.5619685649871826
training step: 9912, total_loss: 4.901011943817139
training step: 9913, total_loss: 5.7242841720581055
training step: 9914, total_loss: 3.2708888053894043
training step: 9915, total_loss: 5.800899028778076
training step: 9916, total_loss: 4.673460006713867
training step: 9917, total_loss: 4.671633720397949
training step: 9918, total_loss: 3.6829640865325928
training step: 9919, total_loss: 5.04520320892334
training step: 9920, total_loss: 6.062775611877441
training step: 9921, total_loss: 6.47026252746582
training step: 9922, total_loss: 4.848511219024658
training step: 9923, total_loss: 4.017589569091797
training step: 9924, total_loss: 6.188013076782227
training step: 9925, total_loss: 5.205955505371094
training step: 9926, total_loss: 2.314303398132324
training step: 9927, total_loss: 5.591133117675781
training step: 9928, total_loss: 3.679335594177246
training step: 9929, total_loss: 3.913296937942505
training step: 9930, total_loss: 4.992456436157227
training step: 9931, total_loss: 5.357963562011719
training step: 9932, total_loss: 2.7787134647369385
training step: 9933, total_loss: 3.774465560913086
training step: 9934, total_loss: 4.417900085449219
training step: 9935, total_loss: 4.572414875030518
training step: 9936, total_loss: 6.104705333709717
training step: 9937, total_loss: 6.737833023071289
training step: 9938, total_loss: 4.554495811462402
training step: 9939, total_loss: 4.05338716506958
training step: 9940, total_loss: 3.744025230407715
training step: 9941, total_loss: 4.014309406280518
training step: 9942, total_loss: 4.662046432495117
training step: 9943, total_loss: 5.319696426391602
training step: 9944, total_loss: 5.273087978363037
training step: 9945, total_loss: 4.488032341003418
training step: 9946, total_loss: 6.538572311401367
training step: 9947, total_loss: 3.7579336166381836
training step: 9948, total_loss: 4.448202133178711
training step: 9949, total_loss: 4.639575004577637
training step: 9950, total_loss: 3.7001662254333496
training step: 9951, total_loss: 3.1776108741760254
training step: 9952, total_loss: 4.115809917449951
training step: 9953, total_loss: 3.9180030822753906
training step: 9954, total_loss: 4.439397811889648
training step: 9955, total_loss: 6.396571159362793
training step: 9956, total_loss: 3.7827746868133545
training step: 9957, total_loss: 5.533975601196289
training step: 9958, total_loss: 3.925816059112549
training step: 9959, total_loss: 3.781404972076416
training step: 9960, total_loss: 2.9446632862091064
training step: 9961, total_loss: 0.628929853439331
training step: 9962, total_loss: 4.3889970779418945
training step: 9963, total_loss: 4.655884265899658
training step: 9964, total_loss: 4.586251258850098
training step: 9965, total_loss: 5.173774719238281
training step: 9966, total_loss: 2.5040283203125
training step: 9967, total_loss: 5.130454063415527
training step: 9968, total_loss: 6.036518573760986
training step: 9969, total_loss: 4.561356544494629
training step: 9970, total_loss: 3.2638368606567383
training step: 9971, total_loss: 1.3219822645187378
training step: 9972, total_loss: 2.5957729816436768
training step: 9973, total_loss: 4.678670883178711
training step: 9974, total_loss: 4.8861823081970215
training step: 9975, total_loss: 5.557955741882324
training step: 9976, total_loss: 5.502045154571533
training step: 9977, total_loss: 4.618823051452637
training step: 9978, total_loss: 7.103225231170654
training step: 9979, total_loss: 5.6663384437561035
training step: 9980, total_loss: 3.7594096660614014
training step: 9981, total_loss: 4.422723770141602
training step: 9982, total_loss: 5.00008487701416
training step: 9983, total_loss: 4.738120079040527
training step: 9984, total_loss: 4.554477691650391
training step: 9985, total_loss: 3.7057347297668457
training step: 9986, total_loss: 5.790643215179443
training step: 9987, total_loss: 3.858898639678955
training step: 9988, total_loss: 5.120161533355713
training step: 9989, total_loss: 5.4212751388549805
training step: 9990, total_loss: 6.301054000854492
training step: 9991, total_loss: 5.078049182891846
training step: 9992, total_loss: 6.141611576080322
training step: 9993, total_loss: 5.026025772094727
training step: 9994, total_loss: 2.1537694931030273
training step: 9995, total_loss: 5.010876655578613
training step: 9996, total_loss: 4.998080730438232
training step: 9997, total_loss: 4.466697692871094
training step: 9998, total_loss: 6.509581565856934
training step: 9999, total_loss: 4.435535907745361
training step: 10000, total_loss: 3.146181583404541
training step: 10001, total_loss: 5.779762268066406
training step: 10002, total_loss: 3.6729862689971924
training step: 10003, total_loss: 4.410588264465332
training step: 10004, total_loss: 4.478273391723633
training step: 10005, total_loss: 4.0561017990112305
training step: 10006, total_loss: 4.807238578796387
training step: 10007, total_loss: 5.309845924377441
training step: 10008, total_loss: 4.230859756469727
training step: 10009, total_loss: 6.1647868156433105
training step: 10010, total_loss: 5.480663776397705
training step: 10011, total_loss: 2.8827500343322754
training step: 10012, total_loss: 5.39788818359375
training step: 10013, total_loss: 4.960256576538086
training step: 10014, total_loss: 5.098754405975342
training step: 10015, total_loss: 4.861984729766846
training step: 10016, total_loss: 3.457629680633545
training step: 10017, total_loss: 4.531707763671875
training step: 10018, total_loss: 4.757185935974121
training step: 10019, total_loss: 5.676687240600586
training step: 10020, total_loss: 4.892862319946289
training step: 10021, total_loss: 5.695465564727783
training step: 10022, total_loss: 5.456171035766602
training step: 10023, total_loss: 4.109208106994629
training step: 10024, total_loss: 4.687525749206543
training step: 10025, total_loss: 3.86572527885437
training step: 10026, total_loss: 5.183021545410156
training step: 10027, total_loss: 5.605234146118164
training step: 10028, total_loss: 4.359561920166016
training step: 10029, total_loss: 4.859271049499512
training step: 10030, total_loss: 4.998676300048828
training step: 10031, total_loss: 4.389507293701172
training step: 10032, total_loss: 3.361191987991333
training step: 10033, total_loss: 4.931705474853516
training step: 10034, total_loss: 5.488437652587891
training step: 10035, total_loss: 4.69028377532959
training step: 10036, total_loss: 4.85438346862793
training step: 10037, total_loss: 3.8908567428588867
training step: 10038, total_loss: 3.86152720451355
training step: 10039, total_loss: 6.544032096862793
training step: 10040, total_loss: 5.070319175720215
training step: 10041, total_loss: 5.07154655456543
training step: 10042, total_loss: 5.061080455780029
training step: 10043, total_loss: 4.783048152923584
training step: 10044, total_loss: 5.162644386291504
training step: 10045, total_loss: 3.270092010498047
training step: 10046, total_loss: 5.278173446655273
training step: 10047, total_loss: 4.628759860992432
training step: 10048, total_loss: 4.885872840881348
training step: 10049, total_loss: 5.057729721069336
training step: 10050, total_loss: 4.388512134552002
training step: 10051, total_loss: 4.785573482513428
training step: 10052, total_loss: 4.2612409591674805
training step: 10053, total_loss: 5.691249847412109
training step: 10054, total_loss: 4.435458183288574
training step: 10055, total_loss: 5.864509582519531
training step: 10056, total_loss: 4.615142822265625
training step: 10057, total_loss: 5.088707447052002
training step: 10058, total_loss: 5.170341491699219
training step: 10059, total_loss: 3.3987178802490234
training step: 10060, total_loss: 4.544183731079102
training step: 10061, total_loss: 4.958484649658203
training step: 10062, total_loss: 4.92911434173584
training step: 10063, total_loss: 4.810403823852539
training step: 10064, total_loss: 4.355235576629639
training step: 10065, total_loss: 4.226500988006592
training step: 10066, total_loss: 4.044251441955566
training step: 10067, total_loss: 4.4776411056518555
training step: 10068, total_loss: 5.197977066040039
training step: 10069, total_loss: 5.5951642990112305
training step: 10070, total_loss: 4.767518997192383
training step: 10071, total_loss: 4.958361625671387
training step: 10072, total_loss: 4.471436500549316
training step: 10073, total_loss: 4.571496963500977
training step: 10074, total_loss: 4.463357925415039
training step: 10075, total_loss: 4.784645080566406
training step: 10076, total_loss: 4.711194038391113
training step: 10077, total_loss: 3.917296886444092
training step: 10078, total_loss: 4.541082382202148
training step: 10079, total_loss: 4.776898384094238
training step: 10080, total_loss: 4.851802825927734
training step: 10081, total_loss: 3.613553047180176
training step: 10082, total_loss: 5.040103912353516
training step: 10083, total_loss: 4.139833927154541
training step: 10084, total_loss: 4.467581272125244
training step: 10085, total_loss: 4.4488115310668945
training step: 10086, total_loss: 4.296184062957764
training step: 10087, total_loss: 4.535881996154785
training step: 10088, total_loss: 5.149393558502197
training step: 10089, total_loss: 2.9732954502105713
training step: 10090, total_loss: 4.646751403808594
training step: 10091, total_loss: 4.381089210510254
training step: 10092, total_loss: 5.466342926025391
training step: 10093, total_loss: 4.670461654663086
training step: 10094, total_loss: 4.811169147491455
training step: 10095, total_loss: 6.043879985809326
training step: 10096, total_loss: 2.5299036502838135
training step: 10097, total_loss: 4.606142997741699
training step: 10098, total_loss: 2.476914167404175
training step: 10099, total_loss: 5.214098930358887
training step: 10100, total_loss: 4.698829650878906
training step: 10101, total_loss: 4.741831302642822
training step: 10102, total_loss: 3.222804307937622
training step: 10103, total_loss: 5.0940842628479
training step: 10104, total_loss: 4.527482509613037
training step: 10105, total_loss: 4.3021345138549805
training step: 10106, total_loss: 4.2199482917785645
training step: 10107, total_loss: 4.917259216308594
training step: 10108, total_loss: 2.1860365867614746
training step: 10109, total_loss: 4.37480354309082
training step: 10110, total_loss: 4.1035003662109375
training step: 10111, total_loss: 4.470524311065674
training step: 10112, total_loss: 5.418580532073975
training step: 10113, total_loss: 3.7843992710113525
training step: 10114, total_loss: 4.995594024658203
training step: 10115, total_loss: 4.754203796386719
training step: 10116, total_loss: 3.6060118675231934
training step: 10117, total_loss: 4.170340538024902
training step: 10118, total_loss: 4.544569492340088
training step: 10119, total_loss: 5.01522159576416
training step: 10120, total_loss: 5.01713752746582
training step: 10121, total_loss: 5.254049777984619
training step: 10122, total_loss: 3.257011890411377
training step: 10123, total_loss: 4.997091770172119
training step: 10124, total_loss: 3.077335834503174
training step: 10125, total_loss: 5.353306293487549
training step: 10126, total_loss: 4.910853385925293
training step: 10127, total_loss: 3.5906004905700684
training step: 10128, total_loss: 4.2775068283081055
training step: 10129, total_loss: 4.251986503601074
training step: 10130, total_loss: 4.99714469909668
training step: 10131, total_loss: 5.605786323547363
training step: 10132, total_loss: 5.70961856842041
training step: 10133, total_loss: 3.592543601989746
training step: 10134, total_loss: 4.264912128448486
training step: 10135, total_loss: 5.158987998962402
training step: 10136, total_loss: 4.111051559448242
training step: 10137, total_loss: 4.008002758026123
training step: 10138, total_loss: 3.8786263465881348
training step: 10139, total_loss: 5.436436176300049
training step: 10140, total_loss: 4.432144641876221
training step: 10141, total_loss: 5.399326801300049
training step: 10142, total_loss: 6.209816932678223
training step: 10143, total_loss: 4.638299465179443
training step: 10144, total_loss: 4.441168785095215
training step: 10145, total_loss: 1.5615687370300293
training step: 10146, total_loss: 4.8391008377075195
training step: 10147, total_loss: 6.550806999206543
training step: 10148, total_loss: 4.964914321899414
training step: 10149, total_loss: 4.870850563049316
training step: 10150, total_loss: 4.728620529174805
training step: 10151, total_loss: 5.028762340545654
training step: 10152, total_loss: 5.07984733581543
training step: 10153, total_loss: 6.402475357055664
training step: 10154, total_loss: 4.696164608001709
training step: 10155, total_loss: 4.969095706939697
training step: 10156, total_loss: 5.193418502807617
training step: 10157, total_loss: 5.958102703094482
training step: 10158, total_loss: 4.691014289855957
training step: 10159, total_loss: 4.4500298500061035
training step: 10160, total_loss: 4.748910903930664
training step: 10161, total_loss: 5.028594017028809
training step: 10162, total_loss: 5.159668922424316
training step: 10163, total_loss: 5.753316879272461
training step: 10164, total_loss: 4.204110622406006
training step: 10165, total_loss: 5.751952171325684
training step: 10166, total_loss: 4.730720043182373
training step: 10167, total_loss: 4.649357795715332
training step: 10168, total_loss: 5.002362251281738
training step: 10169, total_loss: 4.215013027191162
training step: 10170, total_loss: 4.955716609954834
training step: 10171, total_loss: 5.067452430725098
training step: 10172, total_loss: 4.888581275939941
training step: 10173, total_loss: 2.9862208366394043
training step: 10174, total_loss: 4.144864082336426
training step: 10175, total_loss: 4.1873064041137695
training step: 10176, total_loss: 4.306211471557617
training step: 10177, total_loss: 3.3453292846679688
training step: 10178, total_loss: 5.344534397125244
training step: 10179, total_loss: 4.412691593170166
training step: 10180, total_loss: 3.9325194358825684
training step: 10181, total_loss: 3.4559617042541504
training step: 10182, total_loss: 4.758856296539307
training step: 10183, total_loss: 4.1649274826049805
training step: 10184, total_loss: 5.174976825714111
training step: 10185, total_loss: 4.946648597717285
training step: 10186, total_loss: 3.9851839542388916
training step: 10187, total_loss: 4.473502159118652
training step: 10188, total_loss: 5.160955429077148
training step: 10189, total_loss: 5.985089302062988
training step: 10190, total_loss: 3.6003565788269043
training step: 10191, total_loss: 4.182073593139648
training step: 10192, total_loss: 6.483774185180664
training step: 10193, total_loss: 3.772568464279175
training step: 10194, total_loss: 5.641333103179932
training step: 10195, total_loss: 3.548154354095459
training step: 10196, total_loss: 4.183635234832764
training step: 10197, total_loss: 5.367807388305664
training step: 10198, total_loss: 1.4061756134033203
training step: 10199, total_loss: 3.9516985416412354
training step: 10200, total_loss: 5.099249839782715
training step: 10201, total_loss: 3.751058578491211
training step: 10202, total_loss: 4.202441215515137
training step: 10203, total_loss: 3.328937530517578
training step: 10204, total_loss: 4.561542510986328
training step: 10205, total_loss: 4.390094757080078
training step: 10206, total_loss: 1.1184992790222168
training step: 10207, total_loss: 5.613276958465576
training step: 10208, total_loss: 3.1976335048675537
training step: 10209, total_loss: 4.58000373840332
training step: 10210, total_loss: 5.737356185913086
training step: 10211, total_loss: 6.154569625854492
training step: 10212, total_loss: 5.762662410736084
training step: 10213, total_loss: 4.889415740966797
training step: 10214, total_loss: 4.301200866699219
training step: 10215, total_loss: 4.890727519989014
training step: 10216, total_loss: 3.9040603637695312
training step: 10217, total_loss: 2.7690038681030273
training step: 10218, total_loss: 4.119100570678711
training step: 10219, total_loss: 5.1982269287109375
training step: 10220, total_loss: 5.853519439697266
training step: 10221, total_loss: 4.695221900939941
training step: 10222, total_loss: 2.880751132965088
training step: 10223, total_loss: 4.6433868408203125
training step: 10224, total_loss: 5.740108013153076
training step: 10225, total_loss: 4.592700004577637
training step: 10226, total_loss: 4.383544921875
training step: 10227, total_loss: 6.416474342346191
training step: 10228, total_loss: 4.593737602233887
training step: 10229, total_loss: 5.269159317016602
training step: 10230, total_loss: 4.023649215698242
training step: 10231, total_loss: 5.073080539703369
training step: 10232, total_loss: 5.185683250427246
training step: 10233, total_loss: 4.89548397064209
training step: 10234, total_loss: 0.9624133706092834
training step: 10235, total_loss: 5.0617594718933105
training step: 10236, total_loss: 4.445670127868652
training step: 10237, total_loss: 4.639333724975586
training step: 10238, total_loss: 4.657814025878906
training step: 10239, total_loss: 5.0349273681640625
training step: 10240, total_loss: 4.18122673034668
training step: 10241, total_loss: 4.065513610839844
training step: 10242, total_loss: 3.5412168502807617
training step: 10243, total_loss: 5.252898216247559
training step: 10244, total_loss: 4.1605424880981445
training step: 10245, total_loss: 4.7942914962768555
training step: 10246, total_loss: 5.146857738494873
training step: 10247, total_loss: 4.466690540313721
training step: 10248, total_loss: 5.294048309326172
training step: 10249, total_loss: 4.259376525878906
training step: 10250, total_loss: 6.104472637176514
training step: 10251, total_loss: 3.917971611022949
training step: 10252, total_loss: 3.6292366981506348
training step: 10253, total_loss: 4.7098188400268555
training step: 10254, total_loss: 4.737324237823486
training step: 10255, total_loss: 4.564095497131348
training step: 10256, total_loss: 4.788382530212402
training step: 10257, total_loss: 5.371982574462891
training step: 10258, total_loss: 4.945954322814941
training step: 10259, total_loss: 4.494043350219727
training step: 10260, total_loss: 5.4822797775268555
training step: 10261, total_loss: 3.149472713470459
training step: 10262, total_loss: 3.900653600692749
training step: 10263, total_loss: 4.803528785705566
training step: 10264, total_loss: 4.907778739929199
training step: 10265, total_loss: 6.019295692443848
training step: 10266, total_loss: 4.675546646118164
training step: 10267, total_loss: 4.556075572967529
training step: 10268, total_loss: 2.327853202819824
training step: 10269, total_loss: 4.528383731842041
training step: 10270, total_loss: 5.311368942260742
training step: 10271, total_loss: 4.028996467590332
training step: 10272, total_loss: 5.356813430786133
training step: 10273, total_loss: 3.912053108215332
training step: 10274, total_loss: 4.40816068649292
training step: 10275, total_loss: 4.3139448165893555
training step: 10276, total_loss: 5.986978054046631
training step: 10277, total_loss: 5.847629070281982
training step: 10278, total_loss: 4.475262641906738
training step: 10279, total_loss: 5.138627052307129
training step: 10280, total_loss: 5.096217632293701
training step: 10281, total_loss: 3.176595687866211
training step: 10282, total_loss: 6.0930047035217285
training step: 10283, total_loss: 3.1227526664733887
training step: 10284, total_loss: 4.43454647064209
training step: 10285, total_loss: 4.732300281524658
training step: 10286, total_loss: 4.873012542724609
training step: 10287, total_loss: 5.392391204833984
training step: 10288, total_loss: 3.9003233909606934
training step: 10289, total_loss: 4.5693817138671875
training step: 10290, total_loss: 5.569443225860596
training step: 10291, total_loss: 3.58123779296875
training step: 10292, total_loss: 5.925591468811035
training step: 10293, total_loss: 5.824369430541992
training step: 10294, total_loss: 6.201934814453125
training step: 10295, total_loss: 5.241094589233398
training step: 10296, total_loss: 1.366574764251709
training step: 10297, total_loss: 5.233686447143555
training step: 10298, total_loss: 3.946622371673584
training step: 10299, total_loss: 4.3250627517700195
training step: 10300, total_loss: 2.7259035110473633
training step: 10301, total_loss: 3.434370994567871
training step: 10302, total_loss: 3.710888385772705
training step: 10303, total_loss: 4.5863752365112305
training step: 10304, total_loss: 5.703229904174805
training step: 10305, total_loss: 2.793865203857422
training step: 10306, total_loss: 4.442091941833496
training step: 10307, total_loss: 5.6051106452941895
training step: 10308, total_loss: 6.672616004943848
training step: 10309, total_loss: 5.304502487182617
training step: 10310, total_loss: 6.121338367462158
training step: 10311, total_loss: 3.508254051208496
training step: 10312, total_loss: 4.482077121734619
training step: 10313, total_loss: 4.7204766273498535
training step: 10314, total_loss: 5.114577293395996
training step: 10315, total_loss: 4.747136116027832
training step: 10316, total_loss: 4.554032325744629
training step: 10317, total_loss: 4.760159492492676
training step: 10318, total_loss: 4.917581081390381
training step: 10319, total_loss: 3.7898316383361816
training step: 10320, total_loss: 5.370666027069092
training step: 10321, total_loss: 6.545847415924072
training step: 10322, total_loss: 5.068386554718018
training step: 10323, total_loss: 4.908312797546387
training step: 10324, total_loss: 5.4584150314331055
training step: 10325, total_loss: 4.569629669189453
training step: 10326, total_loss: 4.938345432281494
training step: 10327, total_loss: 4.8720703125
training step: 10328, total_loss: 5.089208602905273
training step: 10329, total_loss: 4.817485809326172
training step: 10330, total_loss: 5.047300338745117
training step: 10331, total_loss: 4.568001747131348
training step: 10332, total_loss: 4.549228668212891
training step: 10333, total_loss: 3.0071282386779785
training step: 10334, total_loss: 4.841466903686523
training step: 10335, total_loss: 5.063820838928223
training step: 10336, total_loss: 5.326651573181152
training step: 10337, total_loss: 4.138432502746582
training step: 10338, total_loss: 3.4214892387390137
training step: 10339, total_loss: 3.7130329608917236
training step: 10340, total_loss: 4.765495777130127
training step: 10341, total_loss: 4.242124557495117
training step: 10342, total_loss: 5.204095840454102
training step: 10343, total_loss: 5.849081993103027
training step: 10344, total_loss: 4.70736026763916
training step: 10345, total_loss: 1.6218719482421875
training step: 10346, total_loss: 3.8831963539123535
training step: 10347, total_loss: 5.557855129241943
training step: 10348, total_loss: 4.808034896850586
training step: 10349, total_loss: 5.140009880065918
training step: 10350, total_loss: 5.4760847091674805
training step: 10351, total_loss: 2.3973121643066406
training step: 10352, total_loss: 4.1967597007751465
training step: 10353, total_loss: 4.594749927520752
training step: 10354, total_loss: 5.66301155090332
training step: 10355, total_loss: 5.794273376464844
training step: 10356, total_loss: 3.957113742828369
training step: 10357, total_loss: 4.198128700256348
training step: 10358, total_loss: 1.9967663288116455
training step: 10359, total_loss: 4.552431106567383
training step: 10360, total_loss: 4.778163433074951
training step: 10361, total_loss: 3.4337759017944336
training step: 10362, total_loss: 3.9674339294433594
training step: 10363, total_loss: 2.4915266036987305
training step: 10364, total_loss: 3.665949821472168
training step: 10365, total_loss: 5.396797180175781
training step: 10366, total_loss: 3.5732779502868652
training step: 10367, total_loss: 4.802551746368408
training step: 10368, total_loss: 3.721007823944092
training step: 10369, total_loss: 6.313811302185059
training step: 10370, total_loss: 3.359142303466797
training step: 10371, total_loss: 4.692303657531738
training step: 10372, total_loss: 5.9557623863220215
training step: 10373, total_loss: 5.037976264953613
training step: 10374, total_loss: 3.9652457237243652
training step: 10375, total_loss: 4.915792465209961
training step: 10376, total_loss: 4.634190082550049
training step: 10377, total_loss: 4.319771766662598
training step: 10378, total_loss: 5.167290687561035
training step: 10379, total_loss: 5.293560028076172
training step: 10380, total_loss: 4.223899841308594
training step: 10381, total_loss: 3.7460038661956787
training step: 10382, total_loss: 5.098482131958008
training step: 10383, total_loss: 3.9333858489990234
training step: 10384, total_loss: 6.0721940994262695
training step: 10385, total_loss: 4.604639530181885
training step: 10386, total_loss: 5.812408924102783
training step: 10387, total_loss: 3.6955089569091797
training step: 10388, total_loss: 5.658410549163818
training step: 10389, total_loss: 3.226912021636963
training step: 10390, total_loss: 4.351936340332031
training step: 10391, total_loss: 3.4582085609436035
training step: 10392, total_loss: 3.1832988262176514
training step: 10393, total_loss: 4.154388427734375
training step: 10394, total_loss: 3.924980401992798
training step: 10395, total_loss: 6.464189052581787
training step: 10396, total_loss: 6.7377238273620605
training step: 10397, total_loss: 5.057535171508789
training step: 10398, total_loss: 4.404838562011719
training step: 10399, total_loss: 5.234921932220459
training step: 10400, total_loss: 5.796056270599365
training step: 10401, total_loss: 4.4904937744140625
training step: 10402, total_loss: 5.537253379821777
training step: 10403, total_loss: 5.529888153076172
training step: 10404, total_loss: 4.038688659667969
training step: 10405, total_loss: 2.8612475395202637
training step: 10406, total_loss: 4.166398048400879
training step: 10407, total_loss: 3.8190360069274902
training step: 10408, total_loss: 3.1597118377685547
training step: 10409, total_loss: 4.410365581512451
training step: 10410, total_loss: 4.121002197265625
training step: 10411, total_loss: 5.150322914123535
training step: 10412, total_loss: 4.511606216430664
training step: 10413, total_loss: 4.9784345626831055
training step: 10414, total_loss: 7.941715717315674
training step: 10415, total_loss: 4.423911094665527
training step: 10416, total_loss: 5.182278633117676
training step: 10417, total_loss: 5.07773494720459
training step: 10418, total_loss: 3.813434600830078
training step: 10419, total_loss: 3.7781901359558105
training step: 10420, total_loss: 4.815755367279053
training step: 10421, total_loss: 3.120789051055908
training step: 10422, total_loss: 3.693309783935547
training step: 10423, total_loss: 3.69329833984375
training step: 10424, total_loss: 3.97806978225708
training step: 10425, total_loss: 4.45482063293457
training step: 10426, total_loss: 5.566253662109375
training step: 10427, total_loss: 4.299002647399902
training step: 10428, total_loss: 2.8402957916259766
training step: 10429, total_loss: 4.436501502990723
training step: 10430, total_loss: 2.1478264331817627
training step: 10431, total_loss: 2.8795857429504395
training step: 10432, total_loss: 4.926512718200684
training step: 10433, total_loss: 5.738903999328613
training step: 10434, total_loss: 5.468918800354004
training step: 10435, total_loss: 3.2089359760284424
training step: 10436, total_loss: 6.7139177322387695
training step: 10437, total_loss: 5.5274457931518555
training step: 10438, total_loss: 3.6630849838256836
training step: 10439, total_loss: 4.968016624450684
training step: 10440, total_loss: 3.0001845359802246
training step: 10441, total_loss: 5.639486789703369
training step: 10442, total_loss: 5.5584516525268555
training step: 10443, total_loss: 3.9167656898498535
training step: 10444, total_loss: 3.9488697052001953
training step: 10445, total_loss: 5.234072685241699
training step: 10446, total_loss: 4.441878318786621
training step: 10447, total_loss: 4.429455280303955
training step: 10448, total_loss: 5.185065269470215
training step: 10449, total_loss: 3.417667865753174
training step: 10450, total_loss: 4.037432670593262
training step: 10451, total_loss: 5.221585273742676
training step: 10452, total_loss: 3.7576379776000977
training step: 10453, total_loss: 3.9021260738372803
training step: 10454, total_loss: 6.395912170410156
training step: 10455, total_loss: 5.425647735595703
training step: 10456, total_loss: 5.371762275695801
training step: 10457, total_loss: 4.632169723510742
training step: 10458, total_loss: 3.9703807830810547
training step: 10459, total_loss: 4.650506019592285
training step: 10460, total_loss: 1.398706316947937
training step: 10461, total_loss: 4.966537952423096
training step: 10462, total_loss: 3.7179512977600098
training step: 10463, total_loss: 4.075613975524902
training step: 10464, total_loss: 4.70767068862915
training step: 10465, total_loss: 3.771078586578369
training step: 10466, total_loss: 5.353666305541992
training step: 10467, total_loss: 4.723669528961182
training step: 10468, total_loss: 4.885589599609375
training step: 10469, total_loss: 4.455766201019287
training step: 10470, total_loss: 5.022649765014648
training step: 10471, total_loss: 4.627790451049805
training step: 10472, total_loss: 5.11557674407959
training step: 10473, total_loss: 5.07338285446167
training step: 10474, total_loss: 4.734565734863281
training step: 10475, total_loss: 5.606498718261719
training step: 10476, total_loss: 4.231928825378418
training step: 10477, total_loss: 4.444068908691406
training step: 10478, total_loss: 4.743854522705078
training step: 10479, total_loss: 3.8346853256225586
training step: 10480, total_loss: 5.913311958312988
training step: 10481, total_loss: 4.835337162017822
training step: 10482, total_loss: 3.2553892135620117
training step: 10483, total_loss: 4.898623943328857
training step: 10484, total_loss: 4.158125400543213
training step: 10485, total_loss: 4.563957214355469
training step: 10486, total_loss: 4.679107189178467
training step: 10487, total_loss: 4.233310699462891
training step: 10488, total_loss: 5.467706680297852
training step: 10489, total_loss: 3.4399900436401367
training step: 10490, total_loss: 5.382006645202637
training step: 10491, total_loss: 5.15310525894165
training step: 10492, total_loss: 4.859841346740723
training step: 10493, total_loss: 4.738923072814941
training step: 10494, total_loss: 6.442745208740234
training step: 10495, total_loss: 4.559318542480469
training step: 10496, total_loss: 4.54376220703125
training step: 10497, total_loss: 4.655596733093262
training step: 10498, total_loss: 5.4337077140808105
training step: 10499, total_loss: 5.903056621551514
training step: 10500, total_loss: 5.133749961853027
training step: 10501, total_loss: 5.262199401855469
training step: 10502, total_loss: 4.686025142669678
training step: 10503, total_loss: 6.036410808563232
training step: 10504, total_loss: 5.037034511566162
training step: 10505, total_loss: 4.788198471069336
training step: 10506, total_loss: 4.582961082458496
training step: 10507, total_loss: 3.724586009979248
training step: 10508, total_loss: 5.027370929718018
training step: 10509, total_loss: 4.077779769897461
training step: 10510, total_loss: 4.427487373352051
training step: 10511, total_loss: 4.511807441711426
training step: 10512, total_loss: 5.163726806640625
training step: 10513, total_loss: 4.861711025238037
training step: 10514, total_loss: 2.8499250411987305
training step: 10515, total_loss: 2.8909192085266113
training step: 10516, total_loss: 5.593728542327881
training step: 10517, total_loss: 5.037458419799805
training step: 10518, total_loss: 5.6790876388549805
training step: 10519, total_loss: 3.556257724761963
training step: 10520, total_loss: 4.104946613311768
training step: 10521, total_loss: 5.316258907318115
training step: 10522, total_loss: 3.9411120414733887
training step: 10523, total_loss: 4.672858238220215
training step: 10524, total_loss: 4.876459121704102
training step: 10525, total_loss: 3.8992719650268555
training step: 10526, total_loss: 3.9607605934143066
training step: 10527, total_loss: 2.498105525970459
training step: 10528, total_loss: 5.339834213256836
training step: 10529, total_loss: 3.076389789581299
training step: 10530, total_loss: 6.43216609954834
training step: 10531, total_loss: 3.4866065979003906
training step: 10532, total_loss: 6.144529342651367
training step: 10533, total_loss: 4.728142738342285
training step: 10534, total_loss: 3.1376614570617676
training step: 10535, total_loss: 2.5339179039001465
training step: 10536, total_loss: 4.501041412353516
training step: 10537, total_loss: 5.3395490646362305
training step: 10538, total_loss: 4.323284149169922
training step: 10539, total_loss: 1.6239311695098877
training step: 10540, total_loss: 2.3784635066986084
training step: 10541, total_loss: 3.0860676765441895
training step: 10542, total_loss: 6.435978412628174
training step: 10543, total_loss: 4.675228118896484
training step: 10544, total_loss: 4.3058037757873535
training step: 10545, total_loss: 5.009702682495117
training step: 10546, total_loss: 6.241476058959961
training step: 10547, total_loss: 6.748456954956055
training step: 10548, total_loss: 2.7805140018463135
training step: 10549, total_loss: 5.027846813201904
training step: 10550, total_loss: 4.693427562713623
training step: 10551, total_loss: 4.5482072830200195
training step: 10552, total_loss: 4.786839008331299
training step: 10553, total_loss: 4.263355731964111
training step: 10554, total_loss: 5.294624328613281
training step: 10555, total_loss: 3.9216809272766113
training step: 10556, total_loss: 4.840478897094727
training step: 10557, total_loss: 4.986199855804443
training step: 10558, total_loss: 3.307917594909668
training step: 10559, total_loss: 4.585024356842041
training step: 10560, total_loss: 3.8089423179626465
training step: 10561, total_loss: 5.092548847198486
training step: 10562, total_loss: 1.342498779296875
training step: 10563, total_loss: 5.382032871246338
training step: 10564, total_loss: 5.184237480163574
training step: 10565, total_loss: 5.239519119262695
training step: 10566, total_loss: 3.8793840408325195
training step: 10567, total_loss: 4.509515762329102
training step: 10568, total_loss: 3.268252372741699
training step: 10569, total_loss: 4.5164794921875
training step: 10570, total_loss: 3.195018768310547
training step: 10571, total_loss: 3.517807960510254
training step: 10572, total_loss: 1.2658413648605347
training step: 10573, total_loss: 4.94020938873291
training step: 10574, total_loss: 5.241211891174316
training step: 10575, total_loss: 5.207996368408203
training step: 10576, total_loss: 3.181340456008911
training step: 10577, total_loss: 4.668681621551514
training step: 10578, total_loss: 5.2622480392456055
training step: 10579, total_loss: 5.240372657775879
training step: 10580, total_loss: 4.987035751342773
training step: 10581, total_loss: 4.015352249145508
training step: 10582, total_loss: 4.248370170593262
training step: 10583, total_loss: 4.842617034912109
training step: 10584, total_loss: 4.7068376541137695
training step: 10585, total_loss: 3.2616307735443115
training step: 10586, total_loss: 4.699124336242676
training step: 10587, total_loss: 4.643162250518799
training step: 10588, total_loss: 3.772125482559204
training step: 10589, total_loss: 2.1090590953826904
training step: 10590, total_loss: 4.7053656578063965
training step: 10591, total_loss: 4.481536865234375
training step: 10592, total_loss: 3.907076358795166
training step: 10593, total_loss: 5.053994178771973
training step: 10594, total_loss: 5.165300369262695
training step: 10595, total_loss: 5.616905212402344
training step: 10596, total_loss: 5.30595588684082
training step: 10597, total_loss: 5.3809814453125
training step: 10598, total_loss: 4.140291213989258
training step: 10599, total_loss: 5.605721950531006
training step: 10600, total_loss: 3.761824607849121
training step: 10601, total_loss: 5.192239284515381
training step: 10602, total_loss: 3.53599214553833
training step: 10603, total_loss: 3.9585177898406982
training step: 10604, total_loss: 4.962652683258057
training step: 10605, total_loss: 4.002869606018066
training step: 10606, total_loss: 5.344186782836914
training step: 10607, total_loss: 4.91605281829834
training step: 10608, total_loss: 4.9376020431518555
training step: 10609, total_loss: 3.904240846633911
training step: 10610, total_loss: 4.162017822265625
training step: 10611, total_loss: 4.347827911376953
training step: 10612, total_loss: 3.9065134525299072
training step: 10613, total_loss: 4.5828537940979
training step: 10614, total_loss: 5.778044700622559
training step: 10615, total_loss: 4.498139381408691
training step: 10616, total_loss: 5.634521484375
training step: 10617, total_loss: 4.11871862411499
training step: 10618, total_loss: 6.991858959197998
training step: 10619, total_loss: 4.935680389404297
training step: 10620, total_loss: 2.361299514770508
training step: 10621, total_loss: 4.054082870483398
training step: 10622, total_loss: 4.40559196472168
training step: 10623, total_loss: 6.755098342895508
training step: 10624, total_loss: 4.346813201904297
training step: 10625, total_loss: 5.048515796661377
training step: 10626, total_loss: 4.958922386169434
training step: 10627, total_loss: 4.541797637939453
training step: 10628, total_loss: 2.700977325439453
training step: 10629, total_loss: 4.641116619110107
training step: 10630, total_loss: 4.361878395080566
training step: 10631, total_loss: 6.742676258087158
training step: 10632, total_loss: 5.194778919219971
training step: 10633, total_loss: 4.149040222167969
training step: 10634, total_loss: 4.697447776794434
training step: 10635, total_loss: 6.326594352722168
training step: 10636, total_loss: 1.702319860458374
training step: 10637, total_loss: 3.4060301780700684
training step: 10638, total_loss: 1.700924277305603
training step: 10639, total_loss: 4.585055351257324
training step: 10640, total_loss: 1.6064000129699707
training step: 10641, total_loss: 7.2545928955078125
training step: 10642, total_loss: 3.9443297386169434
training step: 10643, total_loss: 5.042613506317139
training step: 10644, total_loss: 5.156865119934082
training step: 10645, total_loss: 5.338397026062012
training step: 10646, total_loss: 4.326040267944336
training step: 10647, total_loss: 6.0463972091674805
training step: 10648, total_loss: 6.161418914794922
training step: 10649, total_loss: 5.2869720458984375
training step: 10650, total_loss: 3.6427810192108154
training step: 10651, total_loss: 4.17446756362915
training step: 10652, total_loss: 4.270077705383301
training step: 10653, total_loss: 5.018261909484863
training step: 10654, total_loss: 5.5035014152526855
training step: 10655, total_loss: 3.91355037689209
training step: 10656, total_loss: 4.6914753913879395
training step: 10657, total_loss: 4.297934055328369
training step: 10658, total_loss: 4.867367744445801
training step: 10659, total_loss: 5.327024459838867
training step: 10660, total_loss: 4.458747863769531
training step: 10661, total_loss: 5.357904434204102
training step: 10662, total_loss: 4.024262428283691
training step: 10663, total_loss: 4.247428894042969
training step: 10664, total_loss: 5.051568508148193
training step: 10665, total_loss: 4.3296027183532715
training step: 10666, total_loss: 3.2302229404449463
training step: 10667, total_loss: 4.849465847015381
training step: 10668, total_loss: 4.820252418518066
training step: 10669, total_loss: 6.19194221496582
training step: 10670, total_loss: 3.861581325531006
training step: 10671, total_loss: 5.810736179351807
training step: 10672, total_loss: 4.378714561462402
training step: 10673, total_loss: 3.579653739929199
training step: 10674, total_loss: 4.891645908355713
training step: 10675, total_loss: 5.120844841003418
training step: 10676, total_loss: 4.725490570068359
training step: 10677, total_loss: 2.8147430419921875
training step: 10678, total_loss: 5.102231025695801
training step: 10679, total_loss: 4.7981109619140625
training step: 10680, total_loss: 4.322843074798584
training step: 10681, total_loss: 5.135559558868408
training step: 10682, total_loss: 3.9311580657958984
training step: 10683, total_loss: 3.1335701942443848
training step: 10684, total_loss: 4.3571577072143555
training step: 10685, total_loss: 5.110348701477051
training step: 10686, total_loss: 5.340236663818359
training step: 10687, total_loss: 1.0533230304718018
training step: 10688, total_loss: 3.1968417167663574
training step: 10689, total_loss: 4.668451309204102
training step: 10690, total_loss: 3.1639623641967773
training step: 10691, total_loss: 4.679644584655762
training step: 10692, total_loss: 4.19761323928833
training step: 10693, total_loss: 3.5399460792541504
training step: 10694, total_loss: 5.318594455718994
training step: 10695, total_loss: 3.968047618865967
training step: 10696, total_loss: 4.909923076629639
training step: 10697, total_loss: 2.729658603668213
training step: 10698, total_loss: 3.7883706092834473
training step: 10699, total_loss: 4.476920127868652
training step: 10700, total_loss: 3.9784860610961914
training step: 10701, total_loss: 3.7573766708374023
training step: 10702, total_loss: 4.5329413414001465
training step: 10703, total_loss: 6.398672580718994
training step: 10704, total_loss: 4.231924057006836
training step: 10705, total_loss: 4.2103071212768555
training step: 10706, total_loss: 5.9456787109375
training step: 10707, total_loss: 5.623230934143066
training step: 10708, total_loss: 4.581996917724609
training step: 10709, total_loss: 4.2493672370910645
training step: 10710, total_loss: 3.277268886566162
training step: 10711, total_loss: 5.849977493286133
training step: 10712, total_loss: 6.3593220710754395
training step: 10713, total_loss: 4.739828109741211
training step: 10714, total_loss: 3.454622745513916
training step: 10715, total_loss: 3.730295181274414
training step: 10716, total_loss: 5.036013603210449
training step: 10717, total_loss: 3.2927894592285156
training step: 10718, total_loss: 3.6231589317321777
training step: 10719, total_loss: 4.766817092895508
training step: 10720, total_loss: 4.172336101531982
training step: 10721, total_loss: 4.7287917137146
training step: 10722, total_loss: 6.443220138549805
training step: 10723, total_loss: 3.3950982093811035
training step: 10724, total_loss: 5.643149375915527
training step: 10725, total_loss: 5.240570068359375
training step: 10726, total_loss: 4.370914936065674
training step: 10727, total_loss: 5.280292510986328
training step: 10728, total_loss: 4.883946895599365
training step: 10729, total_loss: 5.181055068969727
training step: 10730, total_loss: 4.032257080078125
training step: 10731, total_loss: 5.331398010253906
training step: 10732, total_loss: 4.8064680099487305
training step: 10733, total_loss: 4.241383075714111
training step: 10734, total_loss: 5.560459613800049
training step: 10735, total_loss: 4.848672389984131
training step: 10736, total_loss: 4.795341491699219
training step: 10737, total_loss: 1.1934071779251099
training step: 10738, total_loss: 3.7346181869506836
training step: 10739, total_loss: 5.544365882873535
training step: 10740, total_loss: 1.7476434707641602
training step: 10741, total_loss: 4.810062885284424
training step: 10742, total_loss: 4.904840469360352
training step: 10743, total_loss: 4.453617095947266
training step: 10744, total_loss: 3.0598926544189453
training step: 10745, total_loss: 5.4570536613464355
training step: 10746, total_loss: 4.766912937164307
training step: 10747, total_loss: 3.9357993602752686
training step: 10748, total_loss: 3.8896572589874268
training step: 10749, total_loss: 5.355215072631836
training step: 10750, total_loss: 4.291722297668457
training step: 10751, total_loss: 4.80322790145874
training step: 10752, total_loss: 4.690833568572998
training step: 10753, total_loss: 4.672793388366699
training step: 10754, total_loss: 3.398620128631592
training step: 10755, total_loss: 4.132105827331543
training step: 10756, total_loss: 4.755533695220947
training step: 10757, total_loss: 4.509770393371582
training step: 10758, total_loss: 4.768471717834473
training step: 10759, total_loss: 4.3499650955200195
training step: 10760, total_loss: 5.476304054260254
training step: 10761, total_loss: 2.192532777786255
training step: 10762, total_loss: 5.242094993591309
training step: 10763, total_loss: 4.2486090660095215
training step: 10764, total_loss: 4.439960956573486
training step: 10765, total_loss: 3.2339320182800293
training step: 10766, total_loss: 2.000638961791992
training step: 10767, total_loss: 4.336345672607422
training step: 10768, total_loss: 5.695812225341797
training step: 10769, total_loss: 7.2083635330200195
training step: 10770, total_loss: 4.409412860870361
training step: 10771, total_loss: 5.598897457122803
training step: 10772, total_loss: 5.022335052490234
training step: 10773, total_loss: 6.631455898284912
training step: 10774, total_loss: 5.486101150512695
training step: 10775, total_loss: 4.216917991638184
training step: 10776, total_loss: 4.71120548248291
training step: 10777, total_loss: 4.650064468383789
training step: 10778, total_loss: 2.128143310546875
training step: 10779, total_loss: 5.1382222175598145
training step: 10780, total_loss: 4.88032341003418
training step: 10781, total_loss: 4.562640190124512
training step: 10782, total_loss: 5.568896293640137
training step: 10783, total_loss: 5.168216705322266
training step: 10784, total_loss: 4.993217468261719
training step: 10785, total_loss: 4.87882137298584
training step: 10786, total_loss: 4.0487213134765625
training step: 10787, total_loss: 3.08272385597229
training step: 10788, total_loss: 3.9477663040161133
training step: 10789, total_loss: 5.717010498046875
training step: 10790, total_loss: 4.627205848693848
training step: 10791, total_loss: 4.387861728668213
training step: 10792, total_loss: 4.6876702308654785
training step: 10793, total_loss: 5.426352500915527
training step: 10794, total_loss: 4.415222644805908
training step: 10795, total_loss: 4.996474266052246
training step: 10796, total_loss: 4.8739118576049805
training step: 10797, total_loss: 4.699497222900391
training step: 10798, total_loss: 6.240967750549316
training step: 10799, total_loss: 4.900762557983398
training step: 10800, total_loss: 4.234368324279785
training step: 10801, total_loss: 4.493128776550293
training step: 10802, total_loss: 4.22953462600708
training step: 10803, total_loss: 4.8288068771362305
training step: 10804, total_loss: 3.990058660507202
training step: 10805, total_loss: 4.060392379760742
training step: 10806, total_loss: 3.823152780532837
training step: 10807, total_loss: 3.918860673904419
training step: 10808, total_loss: 4.947309494018555
training step: 10809, total_loss: 4.958472728729248
training step: 10810, total_loss: 4.484800338745117
training step: 10811, total_loss: 1.7467405796051025
training step: 10812, total_loss: 4.233185291290283
training step: 10813, total_loss: 7.37614631652832
training step: 10814, total_loss: 3.5479342937469482
training step: 10815, total_loss: 4.703629493713379
training step: 10816, total_loss: 6.179556369781494
training step: 10817, total_loss: 6.432538032531738
training step: 10818, total_loss: 4.543252944946289
training step: 10819, total_loss: 3.9146487712860107
training step: 10820, total_loss: 4.299618721008301
training step: 10821, total_loss: 6.00454044342041
training step: 10822, total_loss: 5.451564311981201
training step: 10823, total_loss: 5.0826945304870605
training step: 10824, total_loss: 5.485756874084473
training step: 10825, total_loss: 3.045510768890381
training step: 10826, total_loss: 4.589083194732666
training step: 10827, total_loss: 5.225957870483398
training step: 10828, total_loss: 5.106087684631348
training step: 10829, total_loss: 5.622173309326172
training step: 10830, total_loss: 4.5231523513793945
training step: 10831, total_loss: 4.5922040939331055
training step: 10832, total_loss: 3.82948899269104
training step: 10833, total_loss: 4.921326160430908
training step: 10834, total_loss: 4.851065158843994
training step: 10835, total_loss: 3.597372055053711
training step: 10836, total_loss: 5.3723649978637695
training step: 10837, total_loss: 4.3942952156066895
training step: 10838, total_loss: 5.5495147705078125
training step: 10839, total_loss: 4.354173183441162
training step: 10840, total_loss: 4.244495391845703
training step: 10841, total_loss: 4.2200164794921875
training step: 10842, total_loss: 4.322086811065674
training step: 10843, total_loss: 4.816120147705078
training step: 10844, total_loss: 4.295716762542725
training step: 10845, total_loss: 5.4037933349609375
training step: 10846, total_loss: 2.880680561065674
training step: 10847, total_loss: 5.756467819213867
training step: 10848, total_loss: 2.6413612365722656
training step: 10849, total_loss: 5.403545379638672
training step: 10850, total_loss: 4.354563236236572
training step: 10851, total_loss: 5.600654125213623
training step: 10852, total_loss: 3.1243958473205566
training step: 10853, total_loss: 4.66966438293457
training step: 10854, total_loss: 5.57432746887207
training step: 10855, total_loss: 6.673923492431641
training step: 10856, total_loss: 5.140737056732178
training step: 10857, total_loss: 4.810661792755127
training step: 10858, total_loss: 5.967611312866211
training step: 10859, total_loss: 4.720245361328125
training step: 10860, total_loss: 5.671058177947998
training step: 10861, total_loss: 4.568750381469727
training step: 10862, total_loss: 5.861607074737549
training step: 10863, total_loss: 4.089841365814209
training step: 10864, total_loss: 2.332468032836914
training step: 10865, total_loss: 3.9799695014953613
training step: 10866, total_loss: 2.9975199699401855
training step: 10867, total_loss: 4.897922515869141
training step: 10868, total_loss: 3.9839019775390625
training step: 10869, total_loss: 5.527355194091797
training step: 10870, total_loss: 5.084395408630371
training step: 10871, total_loss: 5.453538417816162
training step: 10872, total_loss: 2.0347399711608887
training step: 10873, total_loss: 5.516870498657227
training step: 10874, total_loss: 3.005833148956299
training step: 10875, total_loss: 5.188414573669434
training step: 10876, total_loss: 5.7294721603393555
training step: 10877, total_loss: 5.017733097076416
training step: 10878, total_loss: 3.4947257041931152
training step: 10879, total_loss: 5.553193092346191
training step: 10880, total_loss: 4.457712173461914
training step: 10881, total_loss: 4.581122875213623
training step: 10882, total_loss: 3.4272165298461914
training step: 10883, total_loss: 2.916597843170166
training step: 10884, total_loss: 4.21864652633667
training step: 10885, total_loss: 5.914850234985352
training step: 10886, total_loss: 3.9561996459960938
training step: 10887, total_loss: 4.394179344177246
training step: 10888, total_loss: 4.65575647354126
training step: 10889, total_loss: 4.433379173278809
training step: 10890, total_loss: 4.641529083251953
training step: 10891, total_loss: 4.9076433181762695
training step: 10892, total_loss: 6.103168964385986
training step: 10893, total_loss: 4.643021583557129
training step: 10894, total_loss: 4.216890811920166
training step: 10895, total_loss: 5.2520647048950195
training step: 10896, total_loss: 4.482590675354004
training step: 10897, total_loss: 5.296723365783691
training step: 10898, total_loss: 4.8309326171875
training step: 10899, total_loss: 4.784495830535889
training step: 10900, total_loss: 1.1972185373306274
training step: 10901, total_loss: 1.2777819633483887
training step: 10902, total_loss: 4.109254837036133
training step: 10903, total_loss: 5.659008026123047
training step: 10904, total_loss: 4.643074035644531
training step: 10905, total_loss: 5.7720232009887695
training step: 10906, total_loss: 4.773402214050293
training step: 10907, total_loss: 5.3980913162231445
training step: 10908, total_loss: 4.219130992889404
training step: 10909, total_loss: 3.6865673065185547
training step: 10910, total_loss: 4.420315265655518
training step: 10911, total_loss: 4.261634349822998
training step: 10912, total_loss: 3.657578468322754
training step: 10913, total_loss: 4.535952568054199
training step: 10914, total_loss: 4.8830060958862305
training step: 10915, total_loss: 2.8976097106933594
training step: 10916, total_loss: 6.1947736740112305
training step: 10917, total_loss: 3.9788565635681152
training step: 10918, total_loss: 6.021191596984863
training step: 10919, total_loss: 5.42597770690918
training step: 10920, total_loss: 3.5277247428894043
training step: 10921, total_loss: 5.317985534667969
training step: 10922, total_loss: 4.883110523223877
training step: 10923, total_loss: 3.5536673069000244
training step: 10924, total_loss: 4.007263660430908
training step: 10925, total_loss: 4.444972515106201
training step: 10926, total_loss: 3.6708006858825684
training step: 10927, total_loss: 4.686225891113281
training step: 10928, total_loss: 3.931119918823242
training step: 10929, total_loss: 5.777890205383301
training step: 10930, total_loss: 3.9242453575134277
training step: 10931, total_loss: 6.181815147399902
training step: 10932, total_loss: 4.489014148712158
training step: 10933, total_loss: 5.739742279052734
training step: 10934, total_loss: 5.378938674926758
training step: 10935, total_loss: 5.179007530212402
training step: 10936, total_loss: 5.04550838470459
training step: 10937, total_loss: 5.037110328674316
training step: 10938, total_loss: 4.443569183349609
training step: 10939, total_loss: 2.862771511077881
training step: 10940, total_loss: 4.571457862854004
training step: 10941, total_loss: 6.081518173217773
training step: 10942, total_loss: 5.494228363037109
training step: 10943, total_loss: 5.245498180389404
training step: 10944, total_loss: 5.715274810791016
training step: 10945, total_loss: 5.712559700012207
training step: 10946, total_loss: 2.4549410343170166
training step: 10947, total_loss: 4.754653453826904
training step: 10948, total_loss: 3.6216516494750977
training step: 10949, total_loss: 4.205695152282715
training step: 10950, total_loss: 4.808103561401367
training step: 10951, total_loss: 5.010700225830078
training step: 10952, total_loss: 4.5247673988342285
training step: 10953, total_loss: 5.432354927062988
training step: 10954, total_loss: 4.121678352355957
training step: 10955, total_loss: 5.480898857116699
training step: 10956, total_loss: 5.460540771484375
training step: 10957, total_loss: 5.065380573272705
training step: 10958, total_loss: 3.6921231746673584
training step: 10959, total_loss: 5.986415863037109
training step: 10960, total_loss: 4.719432830810547
training step: 10961, total_loss: 3.7872226238250732
training step: 10962, total_loss: 3.655989170074463
training step: 10963, total_loss: 4.989686012268066
training step: 10964, total_loss: 4.812497138977051
training step: 10965, total_loss: 4.410426139831543
training step: 10966, total_loss: 2.9057137966156006
training step: 10967, total_loss: 5.251683235168457
training step: 10968, total_loss: 5.05226993560791
training step: 10969, total_loss: 2.8169708251953125
training step: 10970, total_loss: 5.519008636474609
training step: 10971, total_loss: 5.415816307067871
training step: 10972, total_loss: 2.865924835205078
training step: 10973, total_loss: 4.393393516540527
training step: 10974, total_loss: 4.333494663238525
training step: 10975, total_loss: 5.239508628845215
training step: 10976, total_loss: 3.7323148250579834
training step: 10977, total_loss: 5.650759696960449
training step: 10978, total_loss: 3.708752155303955
training step: 10979, total_loss: 4.520133972167969
training step: 10980, total_loss: 5.757812023162842
training step: 10981, total_loss: 5.7370195388793945
training step: 10982, total_loss: 3.6502726078033447
training step: 10983, total_loss: 3.861071825027466
training step: 10984, total_loss: 6.323674201965332
training step: 10985, total_loss: 5.412015438079834
training step: 10986, total_loss: 3.3363027572631836
training step: 10987, total_loss: 5.362963676452637
training step: 10988, total_loss: 2.899303436279297
training step: 10989, total_loss: 3.9765148162841797
training step: 10990, total_loss: 4.040472984313965
training step: 10991, total_loss: 4.994957447052002
training step: 10992, total_loss: 4.700332164764404
training step: 10993, total_loss: 4.145360946655273
training step: 10994, total_loss: 6.144876480102539
training step: 10995, total_loss: 3.6943163871765137
training step: 10996, total_loss: 4.241505146026611
training step: 10997, total_loss: 5.750096797943115
training step: 10998, total_loss: 5.022869110107422
training step: 10999, total_loss: 2.0171194076538086
training step: 11000, total_loss: 4.969407081604004
training step: 11001, total_loss: 4.79808235168457
training step: 11002, total_loss: 5.115013122558594
training step: 11003, total_loss: 2.404168128967285
training step: 11004, total_loss: 5.017173767089844
training step: 11005, total_loss: 7.92016077041626
training step: 11006, total_loss: 4.813026428222656
training step: 11007, total_loss: 2.3595974445343018
training step: 11008, total_loss: 5.242197513580322
training step: 11009, total_loss: 6.069980621337891
training step: 11010, total_loss: 4.94529390335083
training step: 11011, total_loss: 4.654577732086182
training step: 11012, total_loss: 4.313999176025391
training step: 11013, total_loss: 4.289155960083008
training step: 11014, total_loss: 5.293999671936035
training step: 11015, total_loss: 5.357390880584717
training step: 11016, total_loss: 4.175032138824463
training step: 11017, total_loss: 5.784999370574951
training step: 11018, total_loss: 4.421732425689697
training step: 11019, total_loss: 3.0578250885009766
training step: 11020, total_loss: 3.1408684253692627
training step: 11021, total_loss: 4.703877925872803
training step: 11022, total_loss: 3.5221076011657715
training step: 11023, total_loss: 3.337709903717041
training step: 11024, total_loss: 4.326650142669678
training step: 11025, total_loss: 5.23396635055542
training step: 11026, total_loss: 3.8356528282165527
training step: 11027, total_loss: 6.378727912902832
training step: 11028, total_loss: 4.64570951461792
training step: 11029, total_loss: 4.857512474060059
training step: 11030, total_loss: 4.646554946899414
training step: 11031, total_loss: 4.456146240234375
training step: 11032, total_loss: 4.8663105964660645
training step: 11033, total_loss: 5.558429718017578
training step: 11034, total_loss: 5.183636665344238
training step: 11035, total_loss: 5.666225433349609
training step: 11036, total_loss: 5.008274555206299
training step: 11037, total_loss: 3.8742172718048096
training step: 11038, total_loss: 5.068140029907227
training step: 11039, total_loss: 4.820196151733398
training step: 11040, total_loss: 4.538569450378418
training step: 11041, total_loss: 4.764779090881348
training step: 11042, total_loss: 5.186800003051758
training step: 11043, total_loss: 2.609032154083252
training step: 11044, total_loss: 7.281134605407715
training step: 11045, total_loss: 5.415691375732422
training step: 11046, total_loss: 5.103063583374023
training step: 11047, total_loss: 3.9336986541748047
training step: 11048, total_loss: 4.90570592880249
training step: 11049, total_loss: 5.37132453918457
training step: 11050, total_loss: 5.196148872375488
training step: 11051, total_loss: 3.33207368850708
training step: 11052, total_loss: 5.979516983032227
training step: 11053, total_loss: 5.6052350997924805
training step: 11054, total_loss: 5.041813850402832
training step: 11055, total_loss: 4.090519905090332
training step: 11056, total_loss: 5.426723480224609
training step: 11057, total_loss: 5.368989944458008
training step: 11058, total_loss: 4.384645462036133
training step: 11059, total_loss: 3.78458309173584
training step: 11060, total_loss: 4.588583946228027
training step: 11061, total_loss: 5.190305233001709
training step: 11062, total_loss: 4.417250633239746
training step: 11063, total_loss: 5.13026237487793
training step: 11064, total_loss: 4.35822868347168
training step: 11065, total_loss: 4.640523433685303
training step: 11066, total_loss: 4.524613380432129
training step: 11067, total_loss: 3.6108765602111816
training step: 11068, total_loss: 5.193072319030762
training step: 11069, total_loss: 4.888954162597656
training step: 11070, total_loss: 4.756333827972412
training step: 11071, total_loss: 6.9755144119262695
training step: 11072, total_loss: 5.587395668029785
training step: 11073, total_loss: 4.477846145629883
training step: 11074, total_loss: 5.169565677642822
training step: 11075, total_loss: 4.7665205001831055
training step: 11076, total_loss: 1.5993505716323853
training step: 11077, total_loss: 3.6778366565704346
training step: 11078, total_loss: 6.122364044189453
training step: 11079, total_loss: 4.556103706359863
training step: 11080, total_loss: 4.420690536499023
training step: 11081, total_loss: 2.87580943107605
training step: 11082, total_loss: 4.519862174987793
training step: 11083, total_loss: 5.067034721374512
training step: 11084, total_loss: 5.3469438552856445
training step: 11085, total_loss: 3.401118516921997
training step: 11086, total_loss: 4.2752814292907715
training step: 11087, total_loss: 5.008591651916504
training step: 11088, total_loss: 4.92867374420166
training step: 11089, total_loss: 4.697796821594238
training step: 11090, total_loss: 5.23561954498291
training step: 11091, total_loss: 3.747734308242798
training step: 11092, total_loss: 4.238511085510254
training step: 11093, total_loss: 2.941568613052368
training step: 11094, total_loss: 4.292384147644043
training step: 11095, total_loss: 4.349917411804199
training step: 11096, total_loss: 5.083288192749023
training step: 11097, total_loss: 5.054237365722656
training step: 11098, total_loss: 3.2465932369232178
training step: 11099, total_loss: 3.5163769721984863
training step: 11100, total_loss: 4.734673500061035
training step: 11101, total_loss: 4.196568489074707
training step: 11102, total_loss: 3.7044177055358887
training step: 11103, total_loss: 5.699850082397461
training step: 11104, total_loss: 4.242737293243408
training step: 11105, total_loss: 3.8727927207946777
training step: 11106, total_loss: 5.735170364379883
training step: 11107, total_loss: 4.011284351348877
training step: 11108, total_loss: 3.809393882751465
training step: 11109, total_loss: 4.8082380294799805
training step: 11110, total_loss: 4.6264448165893555
training step: 11111, total_loss: 2.9508891105651855
training step: 11112, total_loss: 4.988264083862305
training step: 11113, total_loss: 3.145062208175659
training step: 11114, total_loss: 4.004637718200684
training step: 11115, total_loss: 4.1928534507751465
training step: 11116, total_loss: 5.620024681091309
training step: 11117, total_loss: 5.076831817626953
training step: 11118, total_loss: 3.343191146850586
training step: 11119, total_loss: 3.6641883850097656
training step: 11120, total_loss: 5.696616172790527
training step: 11121, total_loss: 4.787700653076172
training step: 11122, total_loss: 5.475933074951172
training step: 11123, total_loss: 4.5642008781433105
training step: 11124, total_loss: 4.605978965759277
training step: 11125, total_loss: 5.063488006591797
training step: 11126, total_loss: 5.421896457672119
training step: 11127, total_loss: 3.718843698501587
training step: 11128, total_loss: 2.674582004547119
training step: 11129, total_loss: 4.705167770385742
training step: 11130, total_loss: 5.645550727844238
training step: 11131, total_loss: 3.966262102127075
training step: 11132, total_loss: 5.620787620544434
training step: 11133, total_loss: 4.855189323425293
training step: 11134, total_loss: 4.836625099182129
training step: 11135, total_loss: 4.117448329925537
training step: 11136, total_loss: 4.525385856628418
training step: 11137, total_loss: 4.649186134338379
training step: 11138, total_loss: 5.274094581604004
training step: 11139, total_loss: 4.3586225509643555
training step: 11140, total_loss: 3.951272964477539
training step: 11141, total_loss: 5.75324821472168
training step: 11142, total_loss: 4.01192569732666
training step: 11143, total_loss: 4.026088714599609
training step: 11144, total_loss: 4.391268730163574
training step: 11145, total_loss: 3.5841546058654785
training step: 11146, total_loss: 4.313204765319824
training step: 11147, total_loss: 3.4185025691986084
training step: 11148, total_loss: 4.97209358215332
training step: 11149, total_loss: 3.5959153175354004
training step: 11150, total_loss: 5.176054954528809
training step: 11151, total_loss: 6.237261772155762
training step: 11152, total_loss: 5.37032413482666
training step: 11153, total_loss: 4.608643531799316
training step: 11154, total_loss: 4.791902542114258
training step: 11155, total_loss: 3.4552416801452637
training step: 11156, total_loss: 5.00483512878418
training step: 11157, total_loss: 5.296830654144287
training step: 11158, total_loss: 3.941169500350952
training step: 11159, total_loss: 5.7802629470825195
training step: 11160, total_loss: 3.4296844005584717
training step: 11161, total_loss: 3.864272356033325
training step: 11162, total_loss: 5.5210723876953125
training step: 11163, total_loss: 4.376733779907227
training step: 11164, total_loss: 4.217153549194336
training step: 11165, total_loss: 5.366145133972168
training step: 11166, total_loss: 5.152644157409668
training step: 11167, total_loss: 4.40598201751709
training step: 11168, total_loss: 5.563311576843262
training step: 11169, total_loss: 5.246248245239258
training step: 11170, total_loss: 4.094113349914551
training step: 11171, total_loss: 2.8264012336730957
training step: 11172, total_loss: 4.142399787902832
training step: 11173, total_loss: 3.9330878257751465
training step: 11174, total_loss: 4.550301551818848
training step: 11175, total_loss: 4.0982747077941895
training step: 11176, total_loss: 2.437439441680908
training step: 11177, total_loss: 3.5722687244415283
training step: 11178, total_loss: 4.166000843048096
training step: 11179, total_loss: 3.3087515830993652
training step: 11180, total_loss: 4.733191967010498
training step: 11181, total_loss: 5.748713493347168
training step: 11182, total_loss: 4.4813337326049805
training step: 11183, total_loss: 3.3737008571624756
training step: 11184, total_loss: 4.501567840576172
training step: 11185, total_loss: 4.416394233703613
training step: 11186, total_loss: 4.831414222717285
training step: 11187, total_loss: 5.60087776184082
training step: 11188, total_loss: 4.37681770324707
training step: 11189, total_loss: 3.0507326126098633
training step: 11190, total_loss: 4.806511878967285
training step: 11191, total_loss: 4.293900489807129
training step: 11192, total_loss: 5.756126880645752
training step: 11193, total_loss: 4.125380992889404
training step: 11194, total_loss: 4.5008544921875
training step: 11195, total_loss: 5.373429775238037
training step: 11196, total_loss: 4.34036922454834
training step: 11197, total_loss: 4.026653289794922
training step: 11198, total_loss: 5.8504252433776855
training step: 11199, total_loss: 5.587973594665527
training step: 11200, total_loss: 4.925306797027588
training step: 11201, total_loss: 3.1286187171936035
training step: 11202, total_loss: 4.206936836242676
training step: 11203, total_loss: 4.601482391357422
training step: 11204, total_loss: 5.4663777351379395
training step: 11205, total_loss: 3.998039484024048
training step: 11206, total_loss: 5.325800895690918
training step: 11207, total_loss: 4.833217620849609
training step: 11208, total_loss: 4.022719383239746
training step: 11209, total_loss: 3.596670627593994
training step: 11210, total_loss: 5.122217178344727
training step: 11211, total_loss: 3.4880824089050293
training step: 11212, total_loss: 1.065142035484314
training step: 11213, total_loss: 4.011578559875488
training step: 11214, total_loss: 6.807350158691406
training step: 11215, total_loss: 4.107755661010742
training step: 11216, total_loss: 4.63964319229126
training step: 11217, total_loss: 5.231619834899902
training step: 11218, total_loss: 4.902963638305664
training step: 11219, total_loss: 4.690407752990723
training step: 11220, total_loss: 2.8020291328430176
training step: 11221, total_loss: 3.462080955505371
training step: 11222, total_loss: 4.98013162612915
training step: 11223, total_loss: 5.026068687438965
training step: 11224, total_loss: 6.192139625549316
training step: 11225, total_loss: 4.0987772941589355
training step: 11226, total_loss: 4.684114933013916
training step: 11227, total_loss: 4.349055290222168
training step: 11228, total_loss: 4.570986747741699
training step: 11229, total_loss: 4.188370704650879
training step: 11230, total_loss: 5.107251167297363
training step: 11231, total_loss: 4.017662048339844
training step: 11232, total_loss: 5.215424060821533
training step: 11233, total_loss: 5.459538459777832
training step: 11234, total_loss: 4.894109725952148
training step: 11235, total_loss: 5.034311294555664
training step: 11236, total_loss: 5.0698466300964355
training step: 11237, total_loss: 5.230042934417725
training step: 11238, total_loss: 4.250231742858887
training step: 11239, total_loss: 4.592287063598633
training step: 11240, total_loss: 4.258231163024902
training step: 11241, total_loss: 4.255509853363037
training step: 11242, total_loss: 3.290027379989624
training step: 11243, total_loss: 6.251119613647461
training step: 11244, total_loss: 3.794769763946533
training step: 11245, total_loss: 6.2107744216918945
training step: 11246, total_loss: 3.9104795455932617
training step: 11247, total_loss: 3.4081122875213623
training step: 11248, total_loss: 4.3330535888671875
training step: 11249, total_loss: 3.8443474769592285
training step: 11250, total_loss: 3.6546149253845215
training step: 11251, total_loss: 1.369422435760498
training step: 11252, total_loss: 3.9826841354370117
training step: 11253, total_loss: 4.851930618286133
training step: 11254, total_loss: 4.192063331604004
training step: 11255, total_loss: 4.683588981628418
training step: 11256, total_loss: 4.675106048583984
training step: 11257, total_loss: 5.391757488250732
training step: 11258, total_loss: 4.194939613342285
training step: 11259, total_loss: 3.3284733295440674
training step: 11260, total_loss: 7.85499382019043
training step: 11261, total_loss: 4.671622276306152
training step: 11262, total_loss: 3.827805519104004
training step: 11263, total_loss: 4.942810535430908
training step: 11264, total_loss: 4.270357131958008
training step: 11265, total_loss: 3.57077693939209
training step: 11266, total_loss: 4.098050117492676
training step: 11267, total_loss: 4.072906494140625
training step: 11268, total_loss: 5.838153839111328
training step: 11269, total_loss: 3.4660162925720215
training step: 11270, total_loss: 4.25546932220459
training step: 11271, total_loss: 5.473444938659668
training step: 11272, total_loss: 4.437971115112305
training step: 11273, total_loss: 5.154297828674316
training step: 11274, total_loss: 5.411972999572754
training step: 11275, total_loss: 6.079657077789307
training step: 11276, total_loss: 4.3167924880981445
training step: 11277, total_loss: 4.0267014503479
training step: 11278, total_loss: 5.934004783630371
training step: 11279, total_loss: 6.918825149536133
training step: 11280, total_loss: 5.5473127365112305
training step: 11281, total_loss: 4.552382469177246
training step: 11282, total_loss: 4.616642951965332
training step: 11283, total_loss: 4.836773872375488
training step: 11284, total_loss: 4.954493999481201
training step: 11285, total_loss: 5.612388610839844
training step: 11286, total_loss: 5.920844078063965
training step: 11287, total_loss: 5.036319732666016
training step: 11288, total_loss: 4.806978225708008
training step: 11289, total_loss: 3.03875732421875
training step: 11290, total_loss: 4.088129043579102
training step: 11291, total_loss: 4.677699089050293
training step: 11292, total_loss: 6.030968189239502
training step: 11293, total_loss: 5.069546699523926
training step: 11294, total_loss: 4.010074138641357
training step: 11295, total_loss: 7.423907279968262
training step: 11296, total_loss: 3.5804800987243652
training step: 11297, total_loss: 5.286944389343262
training step: 11298, total_loss: 4.723309516906738
training step: 11299, total_loss: 4.224156379699707
training step: 11300, total_loss: 5.218481540679932
training step: 11301, total_loss: 4.223606109619141
training step: 11302, total_loss: 4.825268745422363
training step: 11303, total_loss: 3.8297622203826904
training step: 11304, total_loss: 4.946185111999512
training step: 11305, total_loss: 3.031644344329834
training step: 11306, total_loss: 5.021150588989258
training step: 11307, total_loss: 4.1409912109375
training step: 11308, total_loss: 4.354729175567627
training step: 11309, total_loss: 4.693716049194336
training step: 11310, total_loss: 5.610312461853027
training step: 11311, total_loss: 3.826477527618408
training step: 11312, total_loss: 4.431062698364258
training step: 11313, total_loss: 5.216123580932617
training step: 11314, total_loss: 3.5372626781463623
training step: 11315, total_loss: 4.266401290893555
training step: 11316, total_loss: 4.027040481567383
training step: 11317, total_loss: 4.357519149780273
training step: 11318, total_loss: 3.968505859375
training step: 11319, total_loss: 5.9788103103637695
training step: 11320, total_loss: 3.4148178100585938
training step: 11321, total_loss: 3.0526185035705566
training step: 11322, total_loss: 5.093050479888916
training step: 11323, total_loss: 4.804407596588135
training step: 11324, total_loss: 4.6258039474487305
training step: 11325, total_loss: 2.273869514465332
training step: 11326, total_loss: 5.103821277618408
training step: 11327, total_loss: 4.348718643188477
training step: 11328, total_loss: 4.469389915466309
training step: 11329, total_loss: 4.874822616577148
training step: 11330, total_loss: 2.9378061294555664
training step: 11331, total_loss: 5.357875823974609
training step: 11332, total_loss: 4.646929740905762
training step: 11333, total_loss: 3.111271381378174
training step: 11334, total_loss: 5.640868186950684
training step: 11335, total_loss: 3.8616647720336914
training step: 11336, total_loss: 5.604363441467285
training step: 11337, total_loss: 3.1839847564697266
training step: 11338, total_loss: 6.323783874511719
training step: 11339, total_loss: 5.547253608703613
training step: 11340, total_loss: 5.789853096008301
training step: 11341, total_loss: 7.449809551239014
training step: 11342, total_loss: 5.62766170501709
training step: 11343, total_loss: 5.307409763336182
training step: 11344, total_loss: 5.093656539916992
training step: 11345, total_loss: 4.650204181671143
training step: 11346, total_loss: 4.699627876281738
training step: 11347, total_loss: 5.730503559112549
training step: 11348, total_loss: 5.091301918029785
training step: 11349, total_loss: 5.050187110900879
training step: 11350, total_loss: 5.399219512939453
training step: 11351, total_loss: 5.294980049133301
training step: 11352, total_loss: 5.45751428604126
training step: 11353, total_loss: 5.62045955657959
training step: 11354, total_loss: 5.716482162475586
training step: 11355, total_loss: 5.262081623077393
training step: 11356, total_loss: 4.455284118652344
training step: 11357, total_loss: 5.030638217926025
training step: 11358, total_loss: 5.997384548187256
training step: 11359, total_loss: 4.633892059326172
training step: 11360, total_loss: 7.177978992462158
training step: 11361, total_loss: 4.935248374938965
training step: 11362, total_loss: 5.812994003295898
training step: 11363, total_loss: 4.840989112854004
training step: 11364, total_loss: 5.259597301483154
training step: 11365, total_loss: 5.520096778869629
training step: 11366, total_loss: 4.8701982498168945
training step: 11367, total_loss: 5.65273380279541
training step: 11368, total_loss: 5.329402923583984
training step: 11369, total_loss: 4.763577461242676
training step: 11370, total_loss: 4.984206199645996
training step: 11371, total_loss: 5.238577842712402
training step: 11372, total_loss: 4.114120006561279
training step: 11373, total_loss: 5.4439544677734375
training step: 11374, total_loss: 5.323594093322754
training step: 11375, total_loss: 4.657440185546875
training step: 11376, total_loss: 5.549764633178711
training step: 11377, total_loss: 5.102610111236572
training step: 11378, total_loss: 4.838588714599609
training step: 11379, total_loss: 5.317477226257324
training step: 11380, total_loss: 4.970467567443848
training step: 11381, total_loss: 4.7032318115234375
training step: 11382, total_loss: 5.034955024719238
training step: 11383, total_loss: 4.215627193450928
training step: 11384, total_loss: 4.158869743347168
training step: 11385, total_loss: 4.757234573364258
training step: 11386, total_loss: 6.219354629516602
training step: 11387, total_loss: 4.6335062980651855
training step: 11388, total_loss: 5.002920627593994
training step: 11389, total_loss: 5.069094657897949
training step: 11390, total_loss: 6.858246803283691
training step: 11391, total_loss: 5.989192485809326
training step: 11392, total_loss: 3.82486891746521
training step: 11393, total_loss: 4.231860160827637
training step: 11394, total_loss: 4.3860297203063965
training step: 11395, total_loss: 4.440350532531738
training step: 11396, total_loss: 5.676352500915527
training step: 11397, total_loss: 4.378383636474609
training step: 11398, total_loss: 5.588187217712402
training step: 11399, total_loss: 4.220634937286377
training step: 11400, total_loss: 4.888845443725586
training step: 11401, total_loss: 5.671747207641602
training step: 11402, total_loss: 5.993636131286621
training step: 11403, total_loss: 5.40482234954834
training step: 11404, total_loss: 3.3714993000030518
training step: 11405, total_loss: 4.241076469421387
training step: 11406, total_loss: 3.7168383598327637
training step: 11407, total_loss: 4.854877471923828
training step: 11408, total_loss: 5.327306747436523
training step: 11409, total_loss: 3.8711907863616943
training step: 11410, total_loss: 5.102100372314453
training step: 11411, total_loss: 5.086903095245361
training step: 11412, total_loss: 5.88222074508667
training step: 11413, total_loss: 4.846559524536133
training step: 11414, total_loss: 3.9907093048095703
training step: 11415, total_loss: 4.577526569366455
training step: 11416, total_loss: 3.3615221977233887
training step: 11417, total_loss: 4.430753707885742
training step: 11418, total_loss: 3.0253443717956543
training step: 11419, total_loss: 4.776675701141357
training step: 11420, total_loss: 3.6714560985565186
training step: 11421, total_loss: 4.2250776290893555
training step: 11422, total_loss: 4.1987810134887695
training step: 11423, total_loss: 5.671885967254639
training step: 11424, total_loss: 5.042985916137695
training step: 11425, total_loss: 4.997660160064697
training step: 11426, total_loss: 3.077970504760742
training step: 11427, total_loss: 4.586602210998535
training step: 11428, total_loss: 4.799549102783203
training step: 11429, total_loss: 5.988775253295898
training step: 11430, total_loss: 3.50535249710083
training step: 11431, total_loss: 3.3027753829956055
training step: 11432, total_loss: 5.130393981933594
training step: 11433, total_loss: 5.66942024230957
training step: 11434, total_loss: 6.636713981628418
training step: 11435, total_loss: 4.1779985427856445
training step: 11436, total_loss: 5.483964920043945
training step: 11437, total_loss: 4.892747402191162
training step: 11438, total_loss: 5.176164627075195
training step: 11439, total_loss: 4.480377674102783
training step: 11440, total_loss: 7.172571182250977
training step: 11441, total_loss: 5.428380966186523
training step: 11442, total_loss: 4.461272239685059
training step: 11443, total_loss: 4.547122001647949
training step: 11444, total_loss: 4.6126298904418945
training step: 11445, total_loss: 4.267495632171631
training step: 11446, total_loss: 5.326416969299316
training step: 11447, total_loss: 4.901576995849609
training step: 11448, total_loss: 4.793129920959473
training step: 11449, total_loss: 4.377963066101074
training step: 11450, total_loss: 4.733860969543457
training step: 11451, total_loss: 5.281542778015137
training step: 11452, total_loss: 1.9933555126190186
training step: 11453, total_loss: 4.136720180511475
training step: 11454, total_loss: 4.731074333190918
training step: 11455, total_loss: 4.358867645263672
training step: 11456, total_loss: 5.427638053894043
training step: 11457, total_loss: 4.116290092468262
training step: 11458, total_loss: 4.626710414886475
training step: 11459, total_loss: 5.241293907165527
training step: 11460, total_loss: 4.03538703918457
training step: 11461, total_loss: 4.468234062194824
training step: 11462, total_loss: 4.351798057556152
training step: 11463, total_loss: 2.1245439052581787
training step: 11464, total_loss: 6.350440979003906
training step: 11465, total_loss: 4.368496894836426
training step: 11466, total_loss: 5.375548362731934
training step: 11467, total_loss: 5.01094913482666
training step: 11468, total_loss: 4.70538330078125
training step: 11469, total_loss: 5.92317533493042
training step: 11470, total_loss: 4.680320739746094
training step: 11471, total_loss: 5.325944900512695
training step: 11472, total_loss: 4.532064914703369
training step: 11473, total_loss: 4.575517177581787
training step: 11474, total_loss: 6.293542385101318
training step: 11475, total_loss: 6.240144729614258
training step: 11476, total_loss: 4.955096244812012
training step: 11477, total_loss: 4.82763671875
training step: 11478, total_loss: 4.03910493850708
training step: 11479, total_loss: 3.8563921451568604
training step: 11480, total_loss: 2.7860097885131836
training step: 11481, total_loss: 1.8578977584838867
training step: 11482, total_loss: 4.707326412200928
training step: 11483, total_loss: 4.879086494445801
training step: 11484, total_loss: 5.282571315765381
training step: 11485, total_loss: 6.006953239440918
training step: 11486, total_loss: 3.9181854724884033
training step: 11487, total_loss: 2.9763031005859375
training step: 11488, total_loss: 4.055611610412598
training step: 11489, total_loss: 4.533156394958496
training step: 11490, total_loss: 1.1972070932388306
training step: 11491, total_loss: 4.626983642578125
training step: 11492, total_loss: 4.091368675231934
training step: 11493, total_loss: 4.7340922355651855
training step: 11494, total_loss: 6.505282402038574
training step: 11495, total_loss: 3.8866727352142334
training step: 11496, total_loss: 4.291989326477051
training step: 11497, total_loss: 4.614359378814697
training step: 11498, total_loss: 4.441945552825928
training step: 11499, total_loss: 4.635857105255127
training step: 11500, total_loss: 1.371015191078186
training step: 11501, total_loss: 4.073619842529297
training step: 11502, total_loss: 2.7662198543548584
training step: 11503, total_loss: 4.05568790435791
training step: 11504, total_loss: 4.032861709594727
training step: 11505, total_loss: 5.45429801940918
training step: 11506, total_loss: 3.4610915184020996
training step: 11507, total_loss: 4.5215229988098145
training step: 11508, total_loss: 3.889397382736206
training step: 11509, total_loss: 4.06479549407959
training step: 11510, total_loss: 4.099496364593506
training step: 11511, total_loss: 3.903204917907715
training step: 11512, total_loss: 4.662167072296143
training step: 11513, total_loss: 4.355957508087158
training step: 11514, total_loss: 4.935947418212891
training step: 11515, total_loss: 4.93319034576416
training step: 11516, total_loss: 5.084715366363525
training step: 11517, total_loss: 4.788223743438721
training step: 11518, total_loss: 4.84636116027832
training step: 11519, total_loss: 7.090150833129883
training step: 11520, total_loss: 4.514685153961182
training step: 11521, total_loss: 4.556090354919434
training step: 11522, total_loss: 4.642223358154297
training step: 11523, total_loss: 5.603729248046875
training step: 11524, total_loss: 3.975215196609497
training step: 11525, total_loss: 3.743502616882324
training step: 11526, total_loss: 3.521871328353882
training step: 11527, total_loss: 5.579074859619141
training step: 11528, total_loss: 3.8020029067993164
training step: 11529, total_loss: 5.83616828918457
training step: 11530, total_loss: 4.437427520751953
training step: 11531, total_loss: 5.573779582977295
training step: 11532, total_loss: 3.949716806411743
training step: 11533, total_loss: 4.83066987991333
training step: 11534, total_loss: 1.0593628883361816
training step: 11535, total_loss: 3.9355392456054688
training step: 11536, total_loss: 4.181085586547852
training step: 11537, total_loss: 5.094692230224609
training step: 11538, total_loss: 5.231484413146973
training step: 11539, total_loss: 3.8338723182678223
training step: 11540, total_loss: 5.038625717163086
training step: 11541, total_loss: 4.864587306976318
training step: 11542, total_loss: 5.508791923522949
training step: 11543, total_loss: 5.332785129547119
training step: 11544, total_loss: 5.056108474731445
training step: 11545, total_loss: 4.139034748077393
training step: 11546, total_loss: 4.493307113647461
training step: 11547, total_loss: 4.723781585693359
training step: 11548, total_loss: 4.200113296508789
training step: 11549, total_loss: 4.825466156005859
training step: 11550, total_loss: 5.953126907348633
training step: 11551, total_loss: 4.604432582855225
training step: 11552, total_loss: 4.515409469604492
training step: 11553, total_loss: 5.159430980682373
training step: 11554, total_loss: 4.328644752502441
training step: 11555, total_loss: 5.292348861694336
training step: 11556, total_loss: 6.01467227935791
training step: 11557, total_loss: 4.236167907714844
training step: 11558, total_loss: 5.280961990356445
training step: 11559, total_loss: 3.6996593475341797
training step: 11560, total_loss: 5.806718349456787
training step: 11561, total_loss: 6.480613708496094
training step: 11562, total_loss: 4.4915771484375
training step: 11563, total_loss: 4.69705867767334
training step: 11564, total_loss: 5.476140022277832
training step: 11565, total_loss: 4.281274318695068
training step: 11566, total_loss: 3.4256205558776855
training step: 11567, total_loss: 4.681994438171387
training step: 11568, total_loss: 5.296604156494141
training step: 11569, total_loss: 4.938642501831055
training step: 11570, total_loss: 4.275721549987793
training step: 11571, total_loss: 5.060585021972656
training step: 11572, total_loss: 3.923314332962036
training step: 11573, total_loss: 4.794429779052734
training step: 11574, total_loss: 5.1890435218811035
training step: 11575, total_loss: 4.84285831451416
training step: 11576, total_loss: 4.714241981506348
training step: 11577, total_loss: 4.49143123626709
training step: 11578, total_loss: 4.367941856384277
training step: 11579, total_loss: 5.876359939575195
training step: 11580, total_loss: 4.209674835205078
training step: 11581, total_loss: 2.8513216972351074
training step: 11582, total_loss: 3.0595314502716064
training step: 11583, total_loss: 2.9636101722717285
training step: 11584, total_loss: 2.9531476497650146
training step: 11585, total_loss: 5.330307483673096
training step: 11586, total_loss: 4.715240955352783
training step: 11587, total_loss: 4.9723615646362305
training step: 11588, total_loss: 5.334630012512207
training step: 11589, total_loss: 4.4269514083862305
training step: 11590, total_loss: 6.235134601593018
training step: 11591, total_loss: 5.664213180541992
training step: 11592, total_loss: 4.21707010269165
training step: 11593, total_loss: 4.493688583374023
training step: 11594, total_loss: 4.195949554443359
training step: 11595, total_loss: 3.6125059127807617
training step: 11596, total_loss: 4.748190402984619
training step: 11597, total_loss: 4.792482376098633
training step: 11598, total_loss: 3.9521665573120117
training step: 11599, total_loss: 4.166348457336426
training step: 11600, total_loss: 4.944870471954346
training step: 11601, total_loss: 4.852352619171143
training step: 11602, total_loss: 5.141262054443359
training step: 11603, total_loss: 4.1660590171813965
training step: 11604, total_loss: 5.539022445678711
training step: 11605, total_loss: 4.85526180267334
training step: 11606, total_loss: 5.057493209838867
training step: 11607, total_loss: 1.7218130826950073
training step: 11608, total_loss: 2.2912511825561523
training step: 11609, total_loss: 2.656294822692871
training step: 11610, total_loss: 3.621123790740967
training step: 11611, total_loss: 4.687728404998779
training step: 11612, total_loss: 6.70479679107666
training step: 11613, total_loss: 4.793682098388672
training step: 11614, total_loss: 5.419868469238281
training step: 11615, total_loss: 4.983857154846191
training step: 11616, total_loss: 5.509490966796875
training step: 11617, total_loss: 4.709025859832764
training step: 11618, total_loss: 5.03862190246582
training step: 11619, total_loss: 5.178228378295898
training step: 11620, total_loss: 3.9833269119262695
training step: 11621, total_loss: 5.2339019775390625
training step: 11622, total_loss: 4.533760070800781
training step: 11623, total_loss: 1.245889663696289
training step: 11624, total_loss: 4.795051574707031
training step: 11625, total_loss: 4.157398700714111
training step: 11626, total_loss: 3.7480075359344482
training step: 11627, total_loss: 5.7821173667907715
training step: 11628, total_loss: 1.1345207691192627
training step: 11629, total_loss: 4.658159255981445
training step: 11630, total_loss: 4.409895896911621
training step: 11631, total_loss: 4.471890449523926
training step: 11632, total_loss: 4.15632438659668
training step: 11633, total_loss: 4.092273712158203
training step: 11634, total_loss: 5.574786186218262
training step: 11635, total_loss: 4.876689910888672
training step: 11636, total_loss: 5.422043323516846
training step: 11637, total_loss: 4.897327423095703
training step: 11638, total_loss: 5.190499305725098
training step: 11639, total_loss: 4.764965534210205
training step: 11640, total_loss: 6.146348476409912
training step: 11641, total_loss: 4.011651992797852
training step: 11642, total_loss: 3.5765490531921387
training step: 11643, total_loss: 4.8656535148620605
training step: 11644, total_loss: 1.4575035572052002
training step: 11645, total_loss: 3.1602635383605957
training step: 11646, total_loss: 5.421182155609131
training step: 11647, total_loss: 5.801510810852051
training step: 11648, total_loss: 1.0114479064941406
training step: 11649, total_loss: 3.9945178031921387
training step: 11650, total_loss: 4.210700988769531
training step: 11651, total_loss: 2.6699233055114746
training step: 11652, total_loss: 5.090732574462891
training step: 11653, total_loss: 4.56876802444458
training step: 11654, total_loss: 3.055356979370117
training step: 11655, total_loss: 5.146448135375977
training step: 11656, total_loss: 4.099023342132568
training step: 11657, total_loss: 5.370576858520508
training step: 11658, total_loss: 4.718501091003418
training step: 11659, total_loss: 2.6064751148223877
training step: 11660, total_loss: 5.801894187927246
training step: 11661, total_loss: 4.966451168060303
training step: 11662, total_loss: 3.588754415512085
training step: 11663, total_loss: 4.495234966278076
training step: 11664, total_loss: 5.357325077056885
training step: 11665, total_loss: 4.833534240722656
training step: 11666, total_loss: 4.466033458709717
training step: 11667, total_loss: 5.324989318847656
training step: 11668, total_loss: 3.7746477127075195
training step: 11669, total_loss: 4.624153137207031
training step: 11670, total_loss: 2.4517600536346436
training step: 11671, total_loss: 3.8470821380615234
training step: 11672, total_loss: 5.110492706298828
training step: 11673, total_loss: 5.030726909637451
training step: 11674, total_loss: 6.709576606750488
training step: 11675, total_loss: 6.588000297546387
training step: 11676, total_loss: 5.64280891418457
training step: 11677, total_loss: 6.023007392883301
training step: 11678, total_loss: 4.029212951660156
training step: 11679, total_loss: 5.257759094238281
training step: 11680, total_loss: 2.7284884452819824
training step: 11681, total_loss: 5.247402191162109
training step: 11682, total_loss: 3.5154213905334473
training step: 11683, total_loss: 5.809109210968018
training step: 11684, total_loss: 2.9399490356445312
training step: 11685, total_loss: 5.298430442810059
training step: 11686, total_loss: 5.408870697021484
training step: 11687, total_loss: 2.5128817558288574
training step: 11688, total_loss: 4.903088092803955
training step: 11689, total_loss: 5.709453582763672
training step: 11690, total_loss: 4.87787389755249
training step: 11691, total_loss: 4.402728080749512
training step: 11692, total_loss: 6.165101051330566
training step: 11693, total_loss: 4.6639404296875
training step: 11694, total_loss: 4.774319648742676
training step: 11695, total_loss: 5.242751598358154
training step: 11696, total_loss: 5.462296485900879
training step: 11697, total_loss: 2.879507541656494
training step: 11698, total_loss: 4.306466102600098
training step: 11699, total_loss: 2.4692749977111816
training step: 11700, total_loss: 5.179090976715088
training step: 11701, total_loss: 4.128330230712891
training step: 11702, total_loss: 1.000675916671753
training step: 11703, total_loss: 4.015398025512695
training step: 11704, total_loss: 4.828700065612793
training step: 11705, total_loss: 5.009112358093262
training step: 11706, total_loss: 5.346001148223877
training step: 11707, total_loss: 3.2498838901519775
training step: 11708, total_loss: 6.759467124938965
training step: 11709, total_loss: 4.010545253753662
training step: 11710, total_loss: 4.960310459136963
training step: 11711, total_loss: 5.537192344665527
training step: 11712, total_loss: 4.804793357849121
training step: 11713, total_loss: 0.738709568977356
training step: 11714, total_loss: 4.693709373474121
training step: 11715, total_loss: 3.42270565032959
training step: 11716, total_loss: 5.604809761047363
training step: 11717, total_loss: 3.458643913269043
training step: 11718, total_loss: 4.341574668884277
training step: 11719, total_loss: 4.657906532287598
training step: 11720, total_loss: 4.277166366577148
training step: 11721, total_loss: 3.553744316101074
training step: 11722, total_loss: 4.149074554443359
training step: 11723, total_loss: 3.0844459533691406
training step: 11724, total_loss: 3.2184715270996094
training step: 11725, total_loss: 4.246140003204346
training step: 11726, total_loss: 4.451188087463379
training step: 11727, total_loss: 3.1067442893981934
training step: 11728, total_loss: 2.798318386077881
training step: 11729, total_loss: 4.791313648223877
training step: 11730, total_loss: 3.3722710609436035
training step: 11731, total_loss: 4.823965072631836
training step: 11732, total_loss: 4.288959503173828
training step: 11733, total_loss: 4.456441402435303
training step: 11734, total_loss: 2.166536808013916
training step: 11735, total_loss: 5.684308052062988
training step: 11736, total_loss: 4.019203186035156
training step: 11737, total_loss: 6.765369415283203
training step: 11738, total_loss: 3.5835213661193848
training step: 11739, total_loss: 5.2538909912109375
training step: 11740, total_loss: 4.523334503173828
training step: 11741, total_loss: 6.1524739265441895
training step: 11742, total_loss: 6.181830406188965
training step: 11743, total_loss: 5.4392218589782715
training step: 11744, total_loss: 5.994439125061035
training step: 11745, total_loss: 5.294632911682129
training step: 11746, total_loss: 4.539427280426025
training step: 11747, total_loss: 7.427390098571777
training step: 11748, total_loss: 4.866702079772949
training step: 11749, total_loss: 4.108692169189453
training step: 11750, total_loss: 2.080320119857788
training step: 11751, total_loss: 7.112851619720459
training step: 11752, total_loss: 2.577763080596924
training step: 11753, total_loss: 4.825104236602783
training step: 11754, total_loss: 5.974351406097412
training step: 11755, total_loss: 4.056155681610107
training step: 11756, total_loss: 3.541904926300049
training step: 11757, total_loss: 4.8367390632629395
training step: 11758, total_loss: 5.132617950439453
training step: 11759, total_loss: 5.973074436187744
training step: 11760, total_loss: 5.0177130699157715
training step: 11761, total_loss: 6.035487174987793
training step: 11762, total_loss: 3.9053173065185547
training step: 11763, total_loss: 5.86899995803833
training step: 11764, total_loss: 3.8081655502319336
training step: 11765, total_loss: 3.741093873977661
training step: 11766, total_loss: 4.975462436676025
training step: 11767, total_loss: 4.486207008361816
training step: 11768, total_loss: 6.277337551116943
training step: 11769, total_loss: 4.702805519104004
training step: 11770, total_loss: 4.787847518920898
training step: 11771, total_loss: 5.685192108154297
training step: 11772, total_loss: 2.9815311431884766
training step: 11773, total_loss: 3.5615479946136475
training step: 11774, total_loss: 3.8483502864837646
training step: 11775, total_loss: 4.58170223236084
training step: 11776, total_loss: 4.06898307800293
training step: 11777, total_loss: 5.064659118652344
training step: 11778, total_loss: 4.459592819213867
training step: 11779, total_loss: 3.656768321990967
training step: 11780, total_loss: 0.9679460525512695
training step: 11781, total_loss: 3.1470766067504883
training step: 11782, total_loss: 4.192461967468262
training step: 11783, total_loss: 5.161813259124756
training step: 11784, total_loss: 5.320303916931152
training step: 11785, total_loss: 4.998563766479492
training step: 11786, total_loss: 5.087052345275879
training step: 11787, total_loss: 5.011224746704102
training step: 11788, total_loss: 4.573565483093262
training step: 11789, total_loss: 3.487445116043091
training step: 11790, total_loss: 4.319678783416748
training step: 11791, total_loss: 4.9373698234558105
training step: 11792, total_loss: 4.805053234100342
training step: 11793, total_loss: 4.466745376586914
training step: 11794, total_loss: 5.002985000610352
training step: 11795, total_loss: 5.412869453430176
training step: 11796, total_loss: 5.254493236541748
training step: 11797, total_loss: 6.026233196258545
training step: 11798, total_loss: 6.489442825317383
training step: 11799, total_loss: 4.9595136642456055
training step: 11800, total_loss: 6.019996643066406
training step: 11801, total_loss: 5.324873924255371
training step: 11802, total_loss: 5.511647701263428
training step: 11803, total_loss: 5.953289031982422
training step: 11804, total_loss: 0.7490782737731934
training step: 11805, total_loss: 4.366909027099609
training step: 11806, total_loss: 4.58693790435791
training step: 11807, total_loss: 5.2168803215026855
training step: 11808, total_loss: 4.810530662536621
training step: 11809, total_loss: 4.714907169342041
training step: 11810, total_loss: 4.389531135559082
training step: 11811, total_loss: 5.0457763671875
training step: 11812, total_loss: 0.8153649568557739
training step: 11813, total_loss: 6.769833564758301
training step: 11814, total_loss: 4.289427280426025
training step: 11815, total_loss: 5.2779541015625
training step: 11816, total_loss: 4.975648403167725
training step: 11817, total_loss: 5.089450836181641
training step: 11818, total_loss: 4.512516498565674
training step: 11819, total_loss: 1.2674446105957031
training step: 11820, total_loss: 5.1979475021362305
training step: 11821, total_loss: 5.207342624664307
training step: 11822, total_loss: 5.730166435241699
training step: 11823, total_loss: 4.5110602378845215
training step: 11824, total_loss: 4.434722900390625
training step: 11825, total_loss: 4.363675594329834
training step: 11826, total_loss: 5.644016265869141
training step: 11827, total_loss: 4.4711809158325195
training step: 11828, total_loss: 4.779108047485352
training step: 11829, total_loss: 4.443158149719238
training step: 11830, total_loss: 4.736854553222656
training step: 11831, total_loss: 4.601653099060059
training step: 11832, total_loss: 3.7867801189422607
training step: 11833, total_loss: 5.072443008422852
training step: 11834, total_loss: 3.9645299911499023
training step: 11835, total_loss: 4.2362961769104
training step: 11836, total_loss: 5.620725631713867
training step: 11837, total_loss: 3.9923863410949707
training step: 11838, total_loss: 4.095558166503906
training step: 11839, total_loss: 6.163239479064941
training step: 11840, total_loss: 5.091070652008057
training step: 11841, total_loss: 5.103939056396484
training step: 11842, total_loss: 4.69789981842041
training step: 11843, total_loss: 4.893000602722168
training step: 11844, total_loss: 3.5261518955230713
training step: 11845, total_loss: 5.125988006591797
training step: 11846, total_loss: 4.292154312133789
training step: 11847, total_loss: 3.7854254245758057
training step: 11848, total_loss: 4.079383850097656
training step: 11849, total_loss: 3.4939377307891846
training step: 11850, total_loss: 3.9645910263061523
training step: 11851, total_loss: 5.365634918212891
training step: 11852, total_loss: 3.791511058807373
training step: 11853, total_loss: 6.130260467529297
training step: 11854, total_loss: 3.756361961364746
training step: 11855, total_loss: 5.084856033325195
training step: 11856, total_loss: 3.4756999015808105
training step: 11857, total_loss: 4.092083930969238
training step: 11858, total_loss: 2.1214776039123535
training step: 11859, total_loss: 4.937777519226074
training step: 11860, total_loss: 3.065861940383911
training step: 11861, total_loss: 4.545515537261963
training step: 11862, total_loss: 5.067026138305664
training step: 11863, total_loss: 4.483204364776611
training step: 11864, total_loss: 5.210805416107178
training step: 11865, total_loss: 4.903538703918457
training step: 11866, total_loss: 4.613917827606201
training step: 11867, total_loss: 5.409618377685547
training step: 11868, total_loss: 4.921306610107422
training step: 11869, total_loss: 7.363821506500244
training step: 11870, total_loss: 4.548248291015625
training step: 11871, total_loss: 5.826171875
training step: 11872, total_loss: 3.051262855529785
training step: 11873, total_loss: 4.778087615966797
training step: 11874, total_loss: 4.17019510269165
training step: 11875, total_loss: 5.720562934875488
training step: 11876, total_loss: 4.592913627624512
training step: 11877, total_loss: 4.678167819976807
training step: 11878, total_loss: 5.396202087402344
training step: 11879, total_loss: 4.9332356452941895
training step: 11880, total_loss: 2.9057717323303223
training step: 11881, total_loss: 4.992831230163574
training step: 11882, total_loss: 5.455085754394531
training step: 11883, total_loss: 3.611339807510376
training step: 11884, total_loss: 4.532920837402344
training step: 11885, total_loss: 6.281295299530029
training step: 11886, total_loss: 5.25526237487793
training step: 11887, total_loss: 4.514655113220215
training step: 11888, total_loss: 3.9641613960266113
training step: 11889, total_loss: 4.880102634429932
training step: 11890, total_loss: 5.246715545654297
training step: 11891, total_loss: 5.73796272277832
training step: 11892, total_loss: 4.3508620262146
training step: 11893, total_loss: 5.5535888671875
training step: 11894, total_loss: 2.1587915420532227
training step: 11895, total_loss: 4.974113941192627
training step: 11896, total_loss: 5.634974002838135
training step: 11897, total_loss: 4.450222015380859
training step: 11898, total_loss: 4.340695858001709
training step: 11899, total_loss: 5.787640571594238
training step: 11900, total_loss: 4.763120651245117
training step: 11901, total_loss: 4.290863513946533
training step: 11902, total_loss: 2.9346914291381836
training step: 11903, total_loss: 3.594764232635498
training step: 11904, total_loss: 4.927333354949951
training step: 11905, total_loss: 5.451510429382324
training step: 11906, total_loss: 5.632687091827393
training step: 11907, total_loss: 5.00706148147583
training step: 11908, total_loss: 4.825937271118164
training step: 11909, total_loss: 4.383628845214844
training step: 11910, total_loss: 7.104707717895508
training step: 11911, total_loss: 4.355035781860352
training step: 11912, total_loss: 5.090317726135254
training step: 11913, total_loss: 4.803679466247559
training step: 11914, total_loss: 4.857356548309326
training step: 11915, total_loss: 4.586502552032471
training step: 11916, total_loss: 4.650513648986816
training step: 11917, total_loss: 5.5324506759643555
training step: 11918, total_loss: 5.193561553955078
training step: 11919, total_loss: 6.5639753341674805
training step: 11920, total_loss: 4.334830284118652
training step: 11921, total_loss: 4.886663436889648
training step: 11922, total_loss: 4.514153003692627
training step: 11923, total_loss: 3.98911714553833
training step: 11924, total_loss: 3.3301541805267334
training step: 11925, total_loss: 5.0613813400268555
training step: 11926, total_loss: 4.319104194641113
training step: 11927, total_loss: 5.2801055908203125
training step: 11928, total_loss: 4.1450347900390625
training step: 11929, total_loss: 3.0291645526885986
training step: 11930, total_loss: 1.1776723861694336
training step: 11931, total_loss: 5.429774284362793
training step: 11932, total_loss: 5.9184794425964355
training step: 11933, total_loss: 3.034111976623535
training step: 11934, total_loss: 5.49027156829834
training step: 11935, total_loss: 5.383261680603027
training step: 11936, total_loss: 4.589203834533691
training step: 11937, total_loss: 6.125293731689453
training step: 11938, total_loss: 6.011232852935791
training step: 11939, total_loss: 3.6851446628570557
training step: 11940, total_loss: 5.5123443603515625
training step: 11941, total_loss: 5.342501163482666
training step: 11942, total_loss: 3.918482780456543
training step: 11943, total_loss: 4.827531337738037
training step: 11944, total_loss: 4.897712707519531
training step: 11945, total_loss: 4.219892501831055
training step: 11946, total_loss: 4.843794822692871
training step: 11947, total_loss: 2.8523004055023193
training step: 11948, total_loss: 5.292996406555176
training step: 11949, total_loss: 3.5004830360412598
training step: 11950, total_loss: 3.6074984073638916
training step: 11951, total_loss: 5.652836799621582
training step: 11952, total_loss: 3.2205300331115723
training step: 11953, total_loss: 4.598972797393799
training step: 11954, total_loss: 5.022055625915527
training step: 11955, total_loss: 4.458006858825684
training step: 11956, total_loss: 4.678092956542969
training step: 11957, total_loss: 4.206783294677734
training step: 11958, total_loss: 5.062582015991211
training step: 11959, total_loss: 4.383941650390625
training step: 11960, total_loss: 4.361232280731201
training step: 11961, total_loss: 3.69486141204834
training step: 11962, total_loss: 5.226470470428467
training step: 11963, total_loss: 4.713393688201904
training step: 11964, total_loss: 3.9681079387664795
training step: 11965, total_loss: 5.63562536239624
training step: 11966, total_loss: 5.054181098937988
training step: 11967, total_loss: 5.267797470092773
training step: 11968, total_loss: 4.187063694000244
training step: 11969, total_loss: 4.576343059539795
training step: 11970, total_loss: 4.807431221008301
training step: 11971, total_loss: 5.58265495300293
training step: 11972, total_loss: 4.466111183166504
training step: 11973, total_loss: 4.042838096618652
training step: 11974, total_loss: 5.183811187744141
training step: 11975, total_loss: 5.753426551818848
training step: 11976, total_loss: 4.182788848876953
training step: 11977, total_loss: 4.72576379776001
training step: 11978, total_loss: 4.3663225173950195
training step: 11979, total_loss: 4.054485321044922
training step: 11980, total_loss: 3.286201000213623
training step: 11981, total_loss: 5.361753940582275
training step: 11982, total_loss: 4.357448577880859
training step: 11983, total_loss: 4.681366920471191
training step: 11984, total_loss: 5.099671363830566
training step: 11985, total_loss: 3.6737751960754395
training step: 11986, total_loss: 4.868900775909424
training step: 11987, total_loss: 3.2089781761169434
training step: 11988, total_loss: 3.9146575927734375
training step: 11989, total_loss: 4.114971160888672
training step: 11990, total_loss: 4.971395015716553
training step: 11991, total_loss: 4.544522762298584
training step: 11992, total_loss: 5.687273979187012
training step: 11993, total_loss: 3.9855093955993652
training step: 11994, total_loss: 5.083887577056885
training step: 11995, total_loss: 5.419317722320557
training step: 11996, total_loss: 4.079530715942383
training step: 11997, total_loss: 5.554276466369629
training step: 11998, total_loss: 5.289752960205078
training step: 11999, total_loss: 4.126753807067871
training step: 12000, total_loss: 6.1478729248046875
training step: 12001, total_loss: 3.693538188934326
training step: 12002, total_loss: 4.135215759277344
training step: 12003, total_loss: 6.3169684410095215
training step: 12004, total_loss: 4.55970573425293
training step: 12005, total_loss: 6.509108543395996
training step: 12006, total_loss: 3.8978583812713623
training step: 12007, total_loss: 3.691568374633789
training step: 12008, total_loss: 4.6655426025390625
training step: 12009, total_loss: 4.9613800048828125
training step: 12010, total_loss: 3.981539726257324
training step: 12011, total_loss: 3.0418009757995605
training step: 12012, total_loss: 5.283358097076416
training step: 12013, total_loss: 3.8372015953063965
training step: 12014, total_loss: 4.004454612731934
training step: 12015, total_loss: 4.9593071937561035
training step: 12016, total_loss: 4.245059967041016
training step: 12017, total_loss: 2.6387267112731934
training step: 12018, total_loss: 5.692804336547852
training step: 12019, total_loss: 4.732222557067871
training step: 12020, total_loss: 4.510289192199707
training step: 12021, total_loss: 5.1010026931762695
training step: 12022, total_loss: 5.37678337097168
training step: 12023, total_loss: 4.825262069702148
training step: 12024, total_loss: 3.872844696044922
training step: 12025, total_loss: 3.9703893661499023
training step: 12026, total_loss: 5.843728065490723
training step: 12027, total_loss: 5.838500022888184
training step: 12028, total_loss: 4.51989221572876
training step: 12029, total_loss: 4.8937788009643555
training step: 12030, total_loss: 4.474971771240234
training step: 12031, total_loss: 5.091436386108398
training step: 12032, total_loss: 4.437682151794434
training step: 12033, total_loss: 4.666509628295898
training step: 12034, total_loss: 4.217962265014648
training step: 12035, total_loss: 3.5305681228637695
training step: 12036, total_loss: 4.476079940795898
training step: 12037, total_loss: 5.577000141143799
training step: 12038, total_loss: 4.104435920715332
training step: 12039, total_loss: 4.862404823303223
training step: 12040, total_loss: 3.750504970550537
training step: 12041, total_loss: 4.0886640548706055
training step: 12042, total_loss: 2.6221137046813965
training step: 12043, total_loss: 3.6082370281219482
training step: 12044, total_loss: 4.897899150848389
training step: 12045, total_loss: 4.434433937072754
training step: 12046, total_loss: 3.9041543006896973
training step: 12047, total_loss: 4.776087760925293
training step: 12048, total_loss: 4.0474042892456055
training step: 12049, total_loss: 1.779624104499817
training step: 12050, total_loss: 5.637179374694824
training step: 12051, total_loss: 5.305346488952637
training step: 12052, total_loss: 3.8702635765075684
training step: 12053, total_loss: 4.321090221405029
training step: 12054, total_loss: 5.255839824676514
training step: 12055, total_loss: 5.236492156982422
training step: 12056, total_loss: 3.382905960083008
training step: 12057, total_loss: 6.446759223937988
training step: 12058, total_loss: 3.134921073913574
training step: 12059, total_loss: 4.389434814453125
training step: 12060, total_loss: 5.694093704223633
training step: 12061, total_loss: 5.961989879608154
training step: 12062, total_loss: 3.77270770072937
training step: 12063, total_loss: 5.989495754241943
training step: 12064, total_loss: 5.328394889831543
training step: 12065, total_loss: 4.4006218910217285
training step: 12066, total_loss: 4.582392692565918
training step: 12067, total_loss: 5.605119228363037
training step: 12068, total_loss: 4.6406168937683105
training step: 12069, total_loss: 4.074673652648926
training step: 12070, total_loss: 4.600635051727295
training step: 12071, total_loss: 5.384004592895508
training step: 12072, total_loss: 5.754491806030273
training step: 12073, total_loss: 4.205046653747559
training step: 12074, total_loss: 4.151095867156982
training step: 12075, total_loss: 4.785767555236816
training step: 12076, total_loss: 5.844841003417969
training step: 12077, total_loss: 4.892751693725586
training step: 12078, total_loss: 6.066923141479492
training step: 12079, total_loss: 4.568464279174805
training step: 12080, total_loss: 4.656739234924316
training step: 12081, total_loss: 3.46256160736084
training step: 12082, total_loss: 4.837637901306152
training step: 12083, total_loss: 3.903092861175537
training step: 12084, total_loss: 3.2778799533843994
training step: 12085, total_loss: 5.304433822631836
training step: 12086, total_loss: 5.707944393157959
training step: 12087, total_loss: 4.920459747314453
training step: 12088, total_loss: 5.248705863952637
training step: 12089, total_loss: 5.016679286956787
training step: 12090, total_loss: 4.532599925994873
training step: 12091, total_loss: 4.732229232788086
training step: 12092, total_loss: 3.8876755237579346
training step: 12093, total_loss: 3.9714019298553467
training step: 12094, total_loss: 3.4696044921875
training step: 12095, total_loss: 2.7512192726135254
training step: 12096, total_loss: 4.4234466552734375
training step: 12097, total_loss: 5.172049522399902
training step: 12098, total_loss: 7.274621963500977
training step: 12099, total_loss: 4.33566951751709
training step: 12100, total_loss: 4.9337053298950195
training step: 12101, total_loss: 5.962885856628418
training step: 12102, total_loss: 4.085219383239746
training step: 12103, total_loss: 3.163701295852661
training step: 12104, total_loss: 4.402275085449219
training step: 12105, total_loss: 5.377540588378906
training step: 12106, total_loss: 3.6955573558807373
training step: 12107, total_loss: 5.129890441894531
training step: 12108, total_loss: 4.84821081161499
training step: 12109, total_loss: 3.4378843307495117
training step: 12110, total_loss: 4.641973495483398
training step: 12111, total_loss: 5.0456013679504395
training step: 12112, total_loss: 4.783587455749512
training step: 12113, total_loss: 4.735014915466309
training step: 12114, total_loss: 3.570167064666748
training step: 12115, total_loss: 4.313996315002441
training step: 12116, total_loss: 4.281116485595703
training step: 12117, total_loss: 3.4851911067962646
training step: 12118, total_loss: 3.8812637329101562
training step: 12119, total_loss: 5.643263339996338
training step: 12120, total_loss: 5.353906631469727
training step: 12121, total_loss: 2.783769369125366
training step: 12122, total_loss: 6.199461936950684
training step: 12123, total_loss: 2.6528282165527344
training step: 12124, total_loss: 4.6196184158325195
training step: 12125, total_loss: 4.095821380615234
training step: 12126, total_loss: 5.892305374145508
training step: 12127, total_loss: 4.087148666381836
training step: 12128, total_loss: 4.948575019836426
training step: 12129, total_loss: 3.2938051223754883
training step: 12130, total_loss: 3.84757924079895
training step: 12131, total_loss: 4.159014701843262
training step: 12132, total_loss: 4.173182487487793
training step: 12133, total_loss: 5.781740188598633
training step: 12134, total_loss: 3.989668607711792
training step: 12135, total_loss: 3.367527484893799
training step: 12136, total_loss: 5.130746841430664
training step: 12137, total_loss: 3.8278250694274902
training step: 12138, total_loss: 4.793105602264404
training step: 12139, total_loss: 4.53338623046875
training step: 12140, total_loss: 4.51479959487915
training step: 12141, total_loss: 4.427949905395508
training step: 12142, total_loss: 3.0879712104797363
training step: 12143, total_loss: 3.0755391120910645
training step: 12144, total_loss: 4.830679893493652
training step: 12145, total_loss: 3.940365791320801
training step: 12146, total_loss: 4.694895267486572
training step: 12147, total_loss: 4.5701398849487305
training step: 12148, total_loss: 4.79978609085083
training step: 12149, total_loss: 4.405049800872803
training step: 12150, total_loss: 2.9716787338256836
training step: 12151, total_loss: 0.886387825012207
training step: 12152, total_loss: 3.676844358444214
training step: 12153, total_loss: 4.29578971862793
training step: 12154, total_loss: 6.796161651611328
training step: 12155, total_loss: 4.916045188903809
training step: 12156, total_loss: 4.04987907409668
training step: 12157, total_loss: 4.784975051879883
training step: 12158, total_loss: 5.869655609130859
training step: 12159, total_loss: 6.981739044189453
training step: 12160, total_loss: 4.464913368225098
training step: 12161, total_loss: 4.5837507247924805
training step: 12162, total_loss: 4.839289665222168
training step: 12163, total_loss: 5.107265472412109
training step: 12164, total_loss: 7.182224273681641
training step: 12165, total_loss: 4.973850250244141
training step: 12166, total_loss: 5.794153690338135
training step: 12167, total_loss: 4.874173164367676
training step: 12168, total_loss: 4.119731426239014
training step: 12169, total_loss: 4.5232253074646
training step: 12170, total_loss: 3.179107666015625
training step: 12171, total_loss: 4.001394748687744
training step: 12172, total_loss: 5.53995943069458
training step: 12173, total_loss: 4.551057815551758
training step: 12174, total_loss: 4.82145881652832
training step: 12175, total_loss: 4.710860729217529
training step: 12176, total_loss: 5.505417823791504
training step: 12177, total_loss: 2.9070777893066406
training step: 12178, total_loss: 4.675120830535889
training step: 12179, total_loss: 5.493115425109863
training step: 12180, total_loss: 5.2214250564575195
training step: 12181, total_loss: 4.775061130523682
training step: 12182, total_loss: 4.187247276306152
training step: 12183, total_loss: 3.227667808532715
training step: 12184, total_loss: 4.122101783752441
training step: 12185, total_loss: 4.484918594360352
training step: 12186, total_loss: 5.389779090881348
training step: 12187, total_loss: 2.7672786712646484
training step: 12188, total_loss: 4.56080436706543
training step: 12189, total_loss: 5.148764610290527
training step: 12190, total_loss: 5.809237003326416
training step: 12191, total_loss: 5.492123603820801
training step: 12192, total_loss: 3.9032113552093506
training step: 12193, total_loss: 4.897651672363281
training step: 12194, total_loss: 5.375523567199707
training step: 12195, total_loss: 5.162806034088135
training step: 12196, total_loss: 3.4482314586639404
training step: 12197, total_loss: 4.518527984619141
training step: 12198, total_loss: 5.539572238922119
training step: 12199, total_loss: 4.558677673339844
training step: 12200, total_loss: 5.657630920410156
training step: 12201, total_loss: 3.795764923095703
training step: 12202, total_loss: 4.6172919273376465
training step: 12203, total_loss: 4.855079650878906
training step: 12204, total_loss: 5.290684700012207
training step: 12205, total_loss: 6.374800205230713
training step: 12206, total_loss: 5.574591159820557
training step: 12207, total_loss: 5.2238383293151855
training step: 12208, total_loss: 4.036457061767578
training step: 12209, total_loss: 4.803596496582031
training step: 12210, total_loss: 6.310173511505127
training step: 12211, total_loss: 3.24755859375
training step: 12212, total_loss: 5.4755144119262695
training step: 12213, total_loss: 4.795464515686035
training step: 12214, total_loss: 1.165002465248108
training step: 12215, total_loss: 3.060457229614258
training step: 12216, total_loss: 5.175813674926758
training step: 12217, total_loss: 5.155551910400391
training step: 12218, total_loss: 6.325658798217773
training step: 12219, total_loss: 4.713205337524414
training step: 12220, total_loss: 5.195966720581055
training step: 12221, total_loss: 5.428425312042236
training step: 12222, total_loss: 2.486738920211792
training step: 12223, total_loss: 5.157609939575195
training step: 12224, total_loss: 5.142782688140869
training step: 12225, total_loss: 3.547839641571045
training step: 12226, total_loss: 3.652573585510254
training step: 12227, total_loss: 5.513816833496094
training step: 12228, total_loss: 2.992521286010742
training step: 12229, total_loss: 4.867603302001953
training step: 12230, total_loss: 5.191547393798828
training step: 12231, total_loss: 3.459642171859741
training step: 12232, total_loss: 4.281030178070068
training step: 12233, total_loss: 4.84053897857666
training step: 12234, total_loss: 1.430647373199463
training step: 12235, total_loss: 5.667949676513672
training step: 12236, total_loss: 3.301156520843506
training step: 12237, total_loss: 3.714728832244873
training step: 12238, total_loss: 5.844326972961426
training step: 12239, total_loss: 3.4762282371520996
training step: 12240, total_loss: 4.437591075897217
training step: 12241, total_loss: 4.498459339141846
training step: 12242, total_loss: 4.259943962097168
training step: 12243, total_loss: 3.599200963973999
training step: 12244, total_loss: 6.332150936126709
training step: 12245, total_loss: 4.204901695251465
training step: 12246, total_loss: 6.4426374435424805
training step: 12247, total_loss: 4.416942596435547
training step: 12248, total_loss: 2.965789794921875
training step: 12249, total_loss: 4.8675336837768555
training step: 12250, total_loss: 4.881319046020508
training step: 12251, total_loss: 4.612203598022461
training step: 12252, total_loss: 2.8783719539642334
training step: 12253, total_loss: 1.178969144821167
training step: 12254, total_loss: 5.931285858154297
training step: 12255, total_loss: 4.374279499053955
training step: 12256, total_loss: 5.92289400100708
training step: 12257, total_loss: 4.1089959144592285
training step: 12258, total_loss: 3.1552228927612305
training step: 12259, total_loss: 5.508764266967773
training step: 12260, total_loss: 3.947324275970459
training step: 12261, total_loss: 5.4903178215026855
training step: 12262, total_loss: 3.239574432373047
training step: 12263, total_loss: 4.961751937866211
training step: 12264, total_loss: 4.870588302612305
training step: 12265, total_loss: 4.301603317260742
training step: 12266, total_loss: 3.6877002716064453
training step: 12267, total_loss: 4.101342678070068
training step: 12268, total_loss: 4.457146644592285
training step: 12269, total_loss: 0.47756674885749817
training step: 12270, total_loss: 4.859386920928955
training step: 12271, total_loss: 4.9693498611450195
training step: 12272, total_loss: 4.986240386962891
training step: 12273, total_loss: 3.194308280944824
training step: 12274, total_loss: 4.714022159576416
training step: 12275, total_loss: 4.978205680847168
training step: 12276, total_loss: 4.3692216873168945
training step: 12277, total_loss: 5.343777656555176
training step: 12278, total_loss: 6.164697647094727
training step: 12279, total_loss: 5.613059043884277
training step: 12280, total_loss: 2.7358407974243164
training step: 12281, total_loss: 3.706911087036133
training step: 12282, total_loss: 2.721339225769043
training step: 12283, total_loss: 5.423280239105225
training step: 12284, total_loss: 5.557733535766602
training step: 12285, total_loss: 5.250424385070801
training step: 12286, total_loss: 5.148472785949707
training step: 12287, total_loss: 3.595837116241455
training step: 12288, total_loss: 4.957165718078613
training step: 12289, total_loss: 5.042466640472412
training step: 12290, total_loss: 5.696051597595215
training step: 12291, total_loss: 5.865855693817139
training step: 12292, total_loss: 6.0404767990112305
training step: 12293, total_loss: 3.638864755630493
training step: 12294, total_loss: 5.1378984451293945
training step: 12295, total_loss: 4.180708885192871
training step: 12296, total_loss: 4.173119068145752
training step: 12297, total_loss: 5.3776068687438965
training step: 12298, total_loss: 4.132235527038574
training step: 12299, total_loss: 6.811809539794922
training step: 12300, total_loss: 3.7962470054626465
training step: 12301, total_loss: 3.9498376846313477
training step: 12302, total_loss: 2.1589853763580322
training step: 12303, total_loss: 4.70002555847168
training step: 12304, total_loss: 4.9237775802612305
training step: 12305, total_loss: 4.35696268081665
training step: 12306, total_loss: 5.117077827453613
training step: 12307, total_loss: 3.658371925354004
training step: 12308, total_loss: 4.201094150543213
training step: 12309, total_loss: 4.758072376251221
training step: 12310, total_loss: 4.686222076416016
training step: 12311, total_loss: 7.118917465209961
training step: 12312, total_loss: 4.189178943634033
training step: 12313, total_loss: 3.8562440872192383
training step: 12314, total_loss: 5.63121223449707
training step: 12315, total_loss: 5.52654504776001
training step: 12316, total_loss: 4.377063751220703
training step: 12317, total_loss: 5.195764541625977
training step: 12318, total_loss: 5.0564751625061035
training step: 12319, total_loss: 5.0764923095703125
training step: 12320, total_loss: 4.417871475219727
training step: 12321, total_loss: 1.0122839212417603
training step: 12322, total_loss: 5.1114606857299805
training step: 12323, total_loss: 4.875910758972168
training step: 12324, total_loss: 4.459956645965576
training step: 12325, total_loss: 5.23583984375
training step: 12326, total_loss: 5.497920036315918
training step: 12327, total_loss: 4.064793586730957
training step: 12328, total_loss: 4.141127586364746
training step: 12329, total_loss: 3.429553985595703
training step: 12330, total_loss: 3.3608226776123047
training step: 12331, total_loss: 4.917616844177246
training step: 12332, total_loss: 4.4391326904296875
training step: 12333, total_loss: 4.078551769256592
training step: 12334, total_loss: 3.104029417037964
training step: 12335, total_loss: 5.827422142028809
training step: 12336, total_loss: 5.697242736816406
training step: 12337, total_loss: 4.289641380310059
training step: 12338, total_loss: 4.815142631530762
training step: 12339, total_loss: 5.1535234451293945
training step: 12340, total_loss: 4.2891845703125
training step: 12341, total_loss: 3.3781867027282715
training step: 12342, total_loss: 3.013756275177002
training step: 12343, total_loss: 5.096449851989746
training step: 12344, total_loss: 7.5316009521484375
training step: 12345, total_loss: 5.157731056213379
training step: 12346, total_loss: 2.9143810272216797
training step: 12347, total_loss: 6.386296272277832
training step: 12348, total_loss: 4.417051792144775
training step: 12349, total_loss: 4.320559501647949
training step: 12350, total_loss: 5.05472469329834
training step: 12351, total_loss: 4.090433120727539
training step: 12352, total_loss: 3.260801315307617
training step: 12353, total_loss: 5.189957141876221
training step: 12354, total_loss: 4.940742015838623
training step: 12355, total_loss: 4.066712379455566
training step: 12356, total_loss: 5.3360981941223145
training step: 12357, total_loss: 4.407716274261475
training step: 12358, total_loss: 4.427399635314941
training step: 12359, total_loss: 4.293023109436035
training step: 12360, total_loss: 4.902791976928711
training step: 12361, total_loss: 3.665841579437256
training step: 12362, total_loss: 3.366271495819092
training step: 12363, total_loss: 6.200474739074707
training step: 12364, total_loss: 3.8168253898620605
training step: 12365, total_loss: 4.675045013427734
training step: 12366, total_loss: 4.161972999572754
training step: 12367, total_loss: 4.375787734985352
training step: 12368, total_loss: 4.285763263702393
training step: 12369, total_loss: 4.813391208648682
training step: 12370, total_loss: 5.405891418457031
training step: 12371, total_loss: 4.011669158935547
training step: 12372, total_loss: 3.9450409412384033
training step: 12373, total_loss: 4.612749099731445
training step: 12374, total_loss: 2.7681944370269775
training step: 12375, total_loss: 5.477147102355957
training step: 12376, total_loss: 3.796743631362915
training step: 12377, total_loss: 5.364312648773193
training step: 12378, total_loss: 2.524693012237549
training step: 12379, total_loss: 4.044381141662598
training step: 12380, total_loss: 3.020198106765747
training step: 12381, total_loss: 4.105359077453613
training step: 12382, total_loss: 4.184154510498047
training step: 12383, total_loss: 5.402441501617432
training step: 12384, total_loss: 5.376086235046387
training step: 12385, total_loss: 5.757170677185059
training step: 12386, total_loss: 3.9414620399475098
training step: 12387, total_loss: 5.7350006103515625
training step: 12388, total_loss: 5.713878631591797
training step: 12389, total_loss: 5.399808883666992
training step: 12390, total_loss: 5.889439582824707
training step: 12391, total_loss: 5.110561847686768
training step: 12392, total_loss: 3.457714080810547
training step: 12393, total_loss: 4.999785423278809
training step: 12394, total_loss: 4.4214887619018555
training step: 12395, total_loss: 5.251938343048096
training step: 12396, total_loss: 4.162503719329834
training step: 12397, total_loss: 4.844974517822266
training step: 12398, total_loss: 4.104008197784424
training step: 12399, total_loss: 4.182987689971924
training step: 12400, total_loss: 5.248108863830566
training step: 12401, total_loss: 5.262640476226807
training step: 12402, total_loss: 3.9797985553741455
training step: 12403, total_loss: 4.771520614624023
training step: 12404, total_loss: 5.635677337646484
training step: 12405, total_loss: 3.6880784034729004
training step: 12406, total_loss: 6.157527923583984
training step: 12407, total_loss: 3.990894079208374
training step: 12408, total_loss: 4.585302829742432
training step: 12409, total_loss: 4.984621524810791
training step: 12410, total_loss: 4.909515857696533
training step: 12411, total_loss: 5.443264961242676
training step: 12412, total_loss: 4.515450954437256
training step: 12413, total_loss: 5.314967155456543
training step: 12414, total_loss: 5.14053201675415
training step: 12415, total_loss: 3.361128330230713
training step: 12416, total_loss: 2.6414380073547363
training step: 12417, total_loss: 4.805843353271484
training step: 12418, total_loss: 4.927824020385742
training step: 12419, total_loss: 5.085727691650391
training step: 12420, total_loss: 3.810750961303711
training step: 12421, total_loss: 3.7234997749328613
training step: 12422, total_loss: 1.5333127975463867
training step: 12423, total_loss: 4.974276542663574
training step: 12424, total_loss: 3.651927947998047
training step: 12425, total_loss: 4.993989944458008
training step: 12426, total_loss: 4.5975022315979
training step: 12427, total_loss: 4.873983860015869
training step: 12428, total_loss: 5.403897285461426
training step: 12429, total_loss: 3.521522283554077
training step: 12430, total_loss: 5.749408721923828
training step: 12431, total_loss: 4.489544868469238
training step: 12432, total_loss: 4.887670040130615
training step: 12433, total_loss: 4.684950828552246
training step: 12434, total_loss: 4.364398956298828
training step: 12435, total_loss: 4.551188945770264
training step: 12436, total_loss: 3.977252960205078
training step: 12437, total_loss: 4.758737087249756
training step: 12438, total_loss: 5.152719497680664
training step: 12439, total_loss: 4.263436317443848
training step: 12440, total_loss: 3.117086887359619
training step: 12441, total_loss: 4.836899280548096
training step: 12442, total_loss: 2.8782646656036377
training step: 12443, total_loss: 4.688157081604004
training step: 12444, total_loss: 4.251375198364258
training step: 12445, total_loss: 5.310274600982666
training step: 12446, total_loss: 3.0182833671569824
training step: 12447, total_loss: 5.096004486083984
training step: 12448, total_loss: 4.114623069763184
training step: 12449, total_loss: 4.378566741943359
training step: 12450, total_loss: 4.776587009429932
training step: 12451, total_loss: 5.138912200927734
training step: 12452, total_loss: 3.6721086502075195
training step: 12453, total_loss: 0.8660517334938049
training step: 12454, total_loss: 4.213324546813965
training step: 12455, total_loss: 1.0998212099075317
training step: 12456, total_loss: 4.879521369934082
training step: 12457, total_loss: 5.264902114868164
training step: 12458, total_loss: 6.005636692047119
training step: 12459, total_loss: 3.1778621673583984
training step: 12460, total_loss: 4.366468906402588
training step: 12461, total_loss: 4.311098098754883
training step: 12462, total_loss: 3.5676803588867188
training step: 12463, total_loss: 5.595476150512695
training step: 12464, total_loss: 5.359449863433838
training step: 12465, total_loss: 4.510552406311035
training step: 12466, total_loss: 3.3092164993286133
training step: 12467, total_loss: 3.458406686782837
training step: 12468, total_loss: 4.801290512084961
training step: 12469, total_loss: 1.7281451225280762
training step: 12470, total_loss: 4.588127136230469
training step: 12471, total_loss: 0.5555559992790222
training step: 12472, total_loss: 7.300457954406738
training step: 12473, total_loss: 7.251737594604492
training step: 12474, total_loss: 3.3878514766693115
training step: 12475, total_loss: 5.491593360900879
training step: 12476, total_loss: 3.807997941970825
training step: 12477, total_loss: 4.00521183013916
training step: 12478, total_loss: 3.7677664756774902
training step: 12479, total_loss: 4.655916213989258
training step: 12480, total_loss: 5.691420555114746
training step: 12481, total_loss: 2.222831964492798
training step: 12482, total_loss: 2.809131145477295
training step: 12483, total_loss: 3.1535398960113525
training step: 12484, total_loss: 3.927882671356201
training step: 12485, total_loss: 5.340258598327637
training step: 12486, total_loss: 6.594111442565918
training step: 12487, total_loss: 3.854543447494507
training step: 12488, total_loss: 2.8088231086730957
training step: 12489, total_loss: 5.664312839508057
training step: 12490, total_loss: 5.361845970153809
training step: 12491, total_loss: 4.6538591384887695
training step: 12492, total_loss: 5.386950969696045
training step: 12493, total_loss: 4.327456951141357
training step: 12494, total_loss: 4.4643659591674805
training step: 12495, total_loss: 4.486725807189941
training step: 12496, total_loss: 6.563980579376221
training step: 12497, total_loss: 5.209629058837891
training step: 12498, total_loss: 5.003113746643066
training step: 12499, total_loss: 3.3891496658325195
training step: 12500, total_loss: 3.6037399768829346
training step: 12501, total_loss: 6.3088531494140625
training step: 12502, total_loss: 4.785669326782227
training step: 12503, total_loss: 4.153375625610352
training step: 12504, total_loss: 4.513919830322266
training step: 12505, total_loss: 3.8207671642303467
training step: 12506, total_loss: 4.844124794006348
training step: 12507, total_loss: 5.1921539306640625
training step: 12508, total_loss: 5.014420509338379
training step: 12509, total_loss: 5.024886131286621
training step: 12510, total_loss: 4.709911346435547
training step: 12511, total_loss: 3.2492012977600098
training step: 12512, total_loss: 3.7313995361328125
training step: 12513, total_loss: 5.710219383239746
training step: 12514, total_loss: 4.162456512451172
training step: 12515, total_loss: 4.965669631958008
training step: 12516, total_loss: 5.071150302886963
training step: 12517, total_loss: 4.828021049499512
training step: 12518, total_loss: 5.851125717163086
training step: 12519, total_loss: 3.720507860183716
training step: 12520, total_loss: 4.840786933898926
training step: 12521, total_loss: 5.44904899597168
training step: 12522, total_loss: 4.558047294616699
training step: 12523, total_loss: 3.0636539459228516
training step: 12524, total_loss: 5.587544918060303
training step: 12525, total_loss: 4.874990463256836
training step: 12526, total_loss: 4.2495903968811035
training step: 12527, total_loss: 4.504186153411865
training step: 12528, total_loss: 4.811546325683594
training step: 12529, total_loss: 4.869762420654297
training step: 12530, total_loss: 4.786754608154297
training step: 12531, total_loss: 5.661858558654785
training step: 12532, total_loss: 4.639243125915527
training step: 12533, total_loss: 4.552489280700684
training step: 12534, total_loss: 5.0052032470703125
training step: 12535, total_loss: 6.599190711975098
training step: 12536, total_loss: 3.9994280338287354
training step: 12537, total_loss: 3.8996341228485107
training step: 12538, total_loss: 5.762422561645508
training step: 12539, total_loss: 5.37626838684082
training step: 12540, total_loss: 3.5833377838134766
training step: 12541, total_loss: 4.462604522705078
training step: 12542, total_loss: 4.50081205368042
training step: 12543, total_loss: 4.2061309814453125
training step: 12544, total_loss: 2.6005353927612305
training step: 12545, total_loss: 1.5792210102081299
training step: 12546, total_loss: 5.1217546463012695
training step: 12547, total_loss: 2.7366857528686523
training step: 12548, total_loss: 2.975170612335205
training step: 12549, total_loss: 4.67319393157959
training step: 12550, total_loss: 4.806206703186035
training step: 12551, total_loss: 4.7725324630737305
training step: 12552, total_loss: 5.418351650238037
training step: 12553, total_loss: 5.514711856842041
training step: 12554, total_loss: 5.016454696655273
training step: 12555, total_loss: 3.8928284645080566
training step: 12556, total_loss: 5.308423042297363
training step: 12557, total_loss: 4.338889122009277
training step: 12558, total_loss: 3.8788652420043945
training step: 12559, total_loss: 4.46958065032959
training step: 12560, total_loss: 4.540047645568848
training step: 12561, total_loss: 4.5754594802856445
training step: 12562, total_loss: 4.509611129760742
training step: 12563, total_loss: 5.619009017944336
training step: 12564, total_loss: 3.995849132537842
training step: 12565, total_loss: 3.6038668155670166
training step: 12566, total_loss: 4.386005401611328
training step: 12567, total_loss: 4.596034526824951
training step: 12568, total_loss: 3.7322959899902344
training step: 12569, total_loss: 4.467653274536133
training step: 12570, total_loss: 5.527441024780273
training step: 12571, total_loss: 2.6478824615478516
training step: 12572, total_loss: 5.7543158531188965
training step: 12573, total_loss: 5.8478851318359375
training step: 12574, total_loss: 6.130760192871094
training step: 12575, total_loss: 5.725127696990967
training step: 12576, total_loss: 5.817461967468262
training step: 12577, total_loss: 4.1805315017700195
training step: 12578, total_loss: 3.9444961547851562
training step: 12579, total_loss: 3.9184579849243164
training step: 12580, total_loss: 3.9186534881591797
training step: 12581, total_loss: 4.677494525909424
training step: 12582, total_loss: 4.606626510620117
training step: 12583, total_loss: 5.676918983459473
training step: 12584, total_loss: 4.292825222015381
training step: 12585, total_loss: 4.918729782104492
training step: 12586, total_loss: 4.904654502868652
training step: 12587, total_loss: 4.365785598754883
training step: 12588, total_loss: 5.246139049530029
training step: 12589, total_loss: 3.124260425567627
training step: 12590, total_loss: 5.004427909851074
training step: 12591, total_loss: 3.822016716003418
training step: 12592, total_loss: 5.631659030914307
training step: 12593, total_loss: 4.397682189941406
training step: 12594, total_loss: 3.7502856254577637
training step: 12595, total_loss: 3.2235565185546875
training step: 12596, total_loss: 3.2239456176757812
training step: 12597, total_loss: 4.690133094787598
training step: 12598, total_loss: 5.15811824798584
training step: 12599, total_loss: 5.1573615074157715
training step: 12600, total_loss: 4.170151710510254
training step: 12601, total_loss: 3.7042946815490723
training step: 12602, total_loss: 4.407406330108643
training step: 12603, total_loss: 4.145334243774414
training step: 12604, total_loss: 4.8381147384643555
training step: 12605, total_loss: 3.808593988418579
training step: 12606, total_loss: 4.325669765472412
training step: 12607, total_loss: 5.155597686767578
training step: 12608, total_loss: 2.303050994873047
training step: 12609, total_loss: 5.834904193878174
training step: 12610, total_loss: 5.5531463623046875
training step: 12611, total_loss: 5.191492557525635
training step: 12612, total_loss: 4.918034553527832
training step: 12613, total_loss: 6.0916900634765625
training step: 12614, total_loss: 3.568272829055786
training step: 12615, total_loss: 3.6788277626037598
training step: 12616, total_loss: 3.9458489418029785
training step: 12617, total_loss: 5.356953144073486
training step: 12618, total_loss: 3.0194625854492188
training step: 12619, total_loss: 5.433945178985596
training step: 12620, total_loss: 3.9841549396514893
training step: 12621, total_loss: 5.794973373413086
training step: 12622, total_loss: 3.9277446269989014
training step: 12623, total_loss: 5.383194923400879
training step: 12624, total_loss: 4.451509475708008
training step: 12625, total_loss: 1.162109136581421
training step: 12626, total_loss: 3.7025084495544434
training step: 12627, total_loss: 3.592975616455078
training step: 12628, total_loss: 4.839761734008789
training step: 12629, total_loss: 3.2364654541015625
training step: 12630, total_loss: 4.8862104415893555
training step: 12631, total_loss: 5.261212348937988
training step: 12632, total_loss: 5.443751335144043
training step: 12633, total_loss: 5.860812187194824
training step: 12634, total_loss: 4.573488712310791
training step: 12635, total_loss: 4.9698333740234375
training step: 12636, total_loss: 4.660341262817383
training step: 12637, total_loss: 4.141429901123047
training step: 12638, total_loss: 3.5094106197357178
training step: 12639, total_loss: 5.227478981018066
training step: 12640, total_loss: 5.625544548034668
training step: 12641, total_loss: 2.3576056957244873
training step: 12642, total_loss: 2.1655945777893066
training step: 12643, total_loss: 6.363442420959473
training step: 12644, total_loss: 4.42879581451416
training step: 12645, total_loss: 5.348621368408203
training step: 12646, total_loss: 3.7041478157043457
training step: 12647, total_loss: 4.669075965881348
training step: 12648, total_loss: 3.997714042663574
training step: 12649, total_loss: 5.325218200683594
training step: 12650, total_loss: 3.4181268215179443
training step: 12651, total_loss: 5.027186393737793
training step: 12652, total_loss: 5.214016914367676
training step: 12653, total_loss: 4.084419250488281
training step: 12654, total_loss: 3.874868869781494
training step: 12655, total_loss: 4.7337775230407715
training step: 12656, total_loss: 5.83687686920166
training step: 12657, total_loss: 4.382320404052734
training step: 12658, total_loss: 5.211760520935059
training step: 12659, total_loss: 3.713364601135254
training step: 12660, total_loss: 5.419391632080078
training step: 12661, total_loss: 4.438545227050781
training step: 12662, total_loss: 3.077690601348877
training step: 12663, total_loss: 4.674352645874023
training step: 12664, total_loss: 4.615288734436035
training step: 12665, total_loss: 5.181200981140137
training step: 12666, total_loss: 3.7866439819335938
training step: 12667, total_loss: 4.680581092834473
training step: 12668, total_loss: 5.594032287597656
training step: 12669, total_loss: 3.090893268585205
training step: 12670, total_loss: 5.0866804122924805
training step: 12671, total_loss: 5.351707458496094
training step: 12672, total_loss: 6.045108795166016
training step: 12673, total_loss: 2.869633436203003
training step: 12674, total_loss: 3.847195863723755
training step: 12675, total_loss: 5.354170799255371
training step: 12676, total_loss: 4.3484272956848145
training step: 12677, total_loss: 5.097867488861084
training step: 12678, total_loss: 4.841993808746338
training step: 12679, total_loss: 4.04518461227417
training step: 12680, total_loss: 5.4940643310546875
training step: 12681, total_loss: 5.045282363891602
training step: 12682, total_loss: 5.262162208557129
training step: 12683, total_loss: 4.559176921844482
training step: 12684, total_loss: 3.575779914855957
training step: 12685, total_loss: 3.460527181625366
training step: 12686, total_loss: 3.9596331119537354
training step: 12687, total_loss: 5.816107273101807
training step: 12688, total_loss: 4.432128429412842
training step: 12689, total_loss: 3.8816661834716797
training step: 12690, total_loss: 5.461301803588867
training step: 12691, total_loss: 5.106655120849609
training step: 12692, total_loss: 1.899717926979065
training step: 12693, total_loss: 5.698668479919434
training step: 12694, total_loss: 4.4678144454956055
training step: 12695, total_loss: 4.517543792724609
training step: 12696, total_loss: 4.801841735839844
training step: 12697, total_loss: 5.135699272155762
training step: 12698, total_loss: 5.9022674560546875
training step: 12699, total_loss: 4.330486297607422
training step: 12700, total_loss: 4.35054349899292
training step: 12701, total_loss: 4.968013763427734
training step: 12702, total_loss: 5.580522537231445
training step: 12703, total_loss: 5.355730056762695
training step: 12704, total_loss: 5.36453914642334
training step: 12705, total_loss: 2.944709062576294
training step: 12706, total_loss: 4.03915548324585
training step: 12707, total_loss: 4.066150665283203
training step: 12708, total_loss: 3.8584933280944824
training step: 12709, total_loss: 5.06082820892334
training step: 12710, total_loss: 1.6457886695861816
training step: 12711, total_loss: 4.732687473297119
training step: 12712, total_loss: 5.353527069091797
training step: 12713, total_loss: 4.450469970703125
training step: 12714, total_loss: 5.251336097717285
training step: 12715, total_loss: 2.867723226547241
training step: 12716, total_loss: 4.777795791625977
training step: 12717, total_loss: 4.85663366317749
training step: 12718, total_loss: 4.514939308166504
training step: 12719, total_loss: 4.640228748321533
training step: 12720, total_loss: 3.070753812789917
training step: 12721, total_loss: 6.14289665222168
training step: 12722, total_loss: 6.323344707489014
training step: 12723, total_loss: 6.9789018630981445
training step: 12724, total_loss: 0.9747121334075928
training step: 12725, total_loss: 5.434393405914307
training step: 12726, total_loss: 3.54376482963562
training step: 12727, total_loss: 4.983221054077148
training step: 12728, total_loss: 4.948200225830078
training step: 12729, total_loss: 4.864906311035156
training step: 12730, total_loss: 1.170691967010498
training step: 12731, total_loss: 4.187619686126709
training step: 12732, total_loss: 5.608098983764648
training step: 12733, total_loss: 5.142421722412109
training step: 12734, total_loss: 4.152980327606201
training step: 12735, total_loss: 4.03903865814209
training step: 12736, total_loss: 4.22036075592041
training step: 12737, total_loss: 5.532995223999023
training step: 12738, total_loss: 5.2787675857543945
training step: 12739, total_loss: 4.920425891876221
training step: 12740, total_loss: 5.9371232986450195
training step: 12741, total_loss: 4.4614949226379395
training step: 12742, total_loss: 5.463655471801758
training step: 12743, total_loss: 5.1878228187561035
training step: 12744, total_loss: 2.0288162231445312
training step: 12745, total_loss: 5.291258811950684
training step: 12746, total_loss: 3.9128193855285645
training step: 12747, total_loss: 5.53432035446167
training step: 12748, total_loss: 5.490597724914551
training step: 12749, total_loss: 3.562108278274536
training step: 12750, total_loss: 2.427382469177246
training step: 12751, total_loss: 4.655317783355713
training step: 12752, total_loss: 3.758265495300293
training step: 12753, total_loss: 5.176711082458496
training step: 12754, total_loss: 4.194686412811279
training step: 12755, total_loss: 4.588162899017334
training step: 12756, total_loss: 4.3544020652771
training step: 12757, total_loss: 4.623152732849121
training step: 12758, total_loss: 2.6521596908569336
training step: 12759, total_loss: 5.478210926055908
training step: 12760, total_loss: 5.787439346313477
training step: 12761, total_loss: 4.445282936096191
training step: 12762, total_loss: 4.713545799255371
training step: 12763, total_loss: 4.227585792541504
training step: 12764, total_loss: 3.2412495613098145
training step: 12765, total_loss: 5.589624404907227
training step: 12766, total_loss: 4.405574798583984
training step: 12767, total_loss: 5.658114433288574
training step: 12768, total_loss: 4.223544120788574
training step: 12769, total_loss: 4.022552490234375
training step: 12770, total_loss: 3.274094581604004
training step: 12771, total_loss: 6.232200622558594
training step: 12772, total_loss: 5.503533363342285
training step: 12773, total_loss: 4.724083423614502
training step: 12774, total_loss: 3.5126354694366455
training step: 12775, total_loss: 4.751041889190674
training step: 12776, total_loss: 5.394614219665527
training step: 12777, total_loss: 4.167342662811279
training step: 12778, total_loss: 4.944914817810059
training step: 12779, total_loss: 3.070997714996338
training step: 12780, total_loss: 4.1539225578308105
training step: 12781, total_loss: 3.7410593032836914
training step: 12782, total_loss: 4.4767937660217285
training step: 12783, total_loss: 4.412269592285156
training step: 12784, total_loss: 2.799626350402832
training step: 12785, total_loss: 3.7447140216827393
training step: 12786, total_loss: 3.8790383338928223
training step: 12787, total_loss: 3.733807325363159
training step: 12788, total_loss: 6.52896785736084
training step: 12789, total_loss: 4.246647357940674
training step: 12790, total_loss: 3.0816922187805176
training step: 12791, total_loss: 1.2359853982925415
training step: 12792, total_loss: 4.356359004974365
training step: 12793, total_loss: 4.329954147338867
training step: 12794, total_loss: 4.262908935546875
training step: 12795, total_loss: 5.122618675231934
training step: 12796, total_loss: 3.8530170917510986
training step: 12797, total_loss: 3.998450517654419
training step: 12798, total_loss: 4.045314788818359
training step: 12799, total_loss: 3.8757190704345703
training step: 12800, total_loss: 3.8093338012695312
training step: 12801, total_loss: 7.285629749298096
training step: 12802, total_loss: 4.894805908203125
training step: 12803, total_loss: 4.2052459716796875
training step: 12804, total_loss: 4.827414512634277
training step: 12805, total_loss: 4.380031585693359
training step: 12806, total_loss: 5.265634536743164
training step: 12807, total_loss: 3.349299192428589
training step: 12808, total_loss: 4.906601905822754
training step: 12809, total_loss: 4.908255577087402
training step: 12810, total_loss: 4.875974655151367
training step: 12811, total_loss: 4.566486358642578
training step: 12812, total_loss: 3.9194798469543457
training step: 12813, total_loss: 4.157516956329346
training step: 12814, total_loss: 4.379551887512207
training step: 12815, total_loss: 5.006985664367676
training step: 12816, total_loss: 3.3096065521240234
training step: 12817, total_loss: 4.1677961349487305
training step: 12818, total_loss: 5.315185546875
training step: 12819, total_loss: 4.676723957061768
training step: 12820, total_loss: 4.626734733581543
training step: 12821, total_loss: 4.548702239990234
training step: 12822, total_loss: 4.149404525756836
training step: 12823, total_loss: 4.582456111907959
training step: 12824, total_loss: 3.6746346950531006
training step: 12825, total_loss: 4.2627363204956055
training step: 12826, total_loss: 5.003912925720215
training step: 12827, total_loss: 5.735229969024658
training step: 12828, total_loss: 0.9365462064743042
training step: 12829, total_loss: 5.9152727127075195
training step: 12830, total_loss: 3.9730801582336426
training step: 12831, total_loss: 4.53997802734375
training step: 12832, total_loss: 6.164619445800781
training step: 12833, total_loss: 4.6381731033325195
training step: 12834, total_loss: 3.6262929439544678
training step: 12835, total_loss: 4.334325790405273
training step: 12836, total_loss: 3.820157051086426
training step: 12837, total_loss: 2.458061456680298
training step: 12838, total_loss: 5.444772720336914
training step: 12839, total_loss: 5.117766380310059
training step: 12840, total_loss: 5.595211505889893
training step: 12841, total_loss: 3.630845546722412
training step: 12842, total_loss: 6.012486457824707
training step: 12843, total_loss: 7.060685634613037
training step: 12844, total_loss: 5.469249248504639
training step: 12845, total_loss: 2.5034239292144775
training step: 12846, total_loss: 3.7348432540893555
training step: 12847, total_loss: 5.000385284423828
training step: 12848, total_loss: 3.8793282508850098
training step: 12849, total_loss: 5.338620185852051
training step: 12850, total_loss: 5.602590560913086
training step: 12851, total_loss: 4.8577070236206055
training step: 12852, total_loss: 4.699743270874023
training step: 12853, total_loss: 3.535773754119873
training step: 12854, total_loss: 4.368179798126221
training step: 12855, total_loss: 5.159852981567383
training step: 12856, total_loss: 5.595609664916992
training step: 12857, total_loss: 5.204420566558838
training step: 12858, total_loss: 4.516351699829102
training step: 12859, total_loss: 3.2346463203430176
training step: 12860, total_loss: 6.185272693634033
training step: 12861, total_loss: 4.429901123046875
training step: 12862, total_loss: 5.459534645080566
training step: 12863, total_loss: 4.8752241134643555
training step: 12864, total_loss: 3.285748243331909
training step: 12865, total_loss: 6.140013217926025
training step: 12866, total_loss: 5.29488468170166
training step: 12867, total_loss: 4.624095916748047
training step: 12868, total_loss: 4.2833476066589355
training step: 12869, total_loss: 4.569092750549316
training step: 12870, total_loss: 4.586376190185547
training step: 12871, total_loss: 4.025299072265625
training step: 12872, total_loss: 4.102270126342773
training step: 12873, total_loss: 5.127011299133301
training step: 12874, total_loss: 5.189752578735352
training step: 12875, total_loss: 1.9621860980987549
training step: 12876, total_loss: 3.7049055099487305
training step: 12877, total_loss: 3.950944185256958
training step: 12878, total_loss: 6.033670425415039
training step: 12879, total_loss: 4.962917327880859
training step: 12880, total_loss: 4.486242771148682
training step: 12881, total_loss: 5.121965408325195
training step: 12882, total_loss: 3.0032639503479004
training step: 12883, total_loss: 5.354072093963623
training step: 12884, total_loss: 5.626286029815674
training step: 12885, total_loss: 1.332430124282837
training step: 12886, total_loss: 3.8921241760253906
training step: 12887, total_loss: 5.083497047424316
training step: 12888, total_loss: 5.978950500488281
training step: 12889, total_loss: 3.7881479263305664
training step: 12890, total_loss: 4.3401713371276855
training step: 12891, total_loss: 5.449602127075195
training step: 12892, total_loss: 3.9833250045776367
training step: 12893, total_loss: 5.27708101272583
training step: 12894, total_loss: 4.8258442878723145
training step: 12895, total_loss: 5.566108226776123
training step: 12896, total_loss: 4.942042827606201
training step: 12897, total_loss: 5.992096424102783
training step: 12898, total_loss: 5.00489616394043
training step: 12899, total_loss: 5.8757004737854
training step: 12900, total_loss: 2.7087717056274414
training step: 12901, total_loss: 5.545051097869873
training step: 12902, total_loss: 4.368869781494141
training step: 12903, total_loss: 5.5347900390625
training step: 12904, total_loss: 5.446284294128418
training step: 12905, total_loss: 6.207784652709961
training step: 12906, total_loss: 5.114086627960205
training step: 12907, total_loss: 4.374310493469238
training step: 12908, total_loss: 4.235405445098877
training step: 12909, total_loss: 4.269697189331055
training step: 12910, total_loss: 4.04640007019043
training step: 12911, total_loss: 4.61887264251709
training step: 12912, total_loss: 5.725771903991699
training step: 12913, total_loss: 3.6538305282592773
training step: 12914, total_loss: 4.957266807556152
training step: 12915, total_loss: 5.110124588012695
training step: 12916, total_loss: 2.969219923019409
training step: 12917, total_loss: 4.930850982666016
training step: 12918, total_loss: 4.158987045288086
training step: 12919, total_loss: 3.312225341796875
training step: 12920, total_loss: 5.36518669128418
training step: 12921, total_loss: 5.20512580871582
training step: 12922, total_loss: 5.706043243408203
training step: 12923, total_loss: 3.1686840057373047
training step: 12924, total_loss: 4.600985050201416
training step: 12925, total_loss: 5.085023403167725
training step: 12926, total_loss: 4.988324165344238
training step: 12927, total_loss: 3.641472816467285
training step: 12928, total_loss: 4.562335014343262
training step: 12929, total_loss: 5.84229850769043
training step: 12930, total_loss: 5.099021911621094
training step: 12931, total_loss: 2.6674633026123047
training step: 12932, total_loss: 1.2213902473449707
training step: 12933, total_loss: 6.761743545532227
training step: 12934, total_loss: 4.977022171020508
training step: 12935, total_loss: 5.157825946807861
training step: 12936, total_loss: 3.8791356086730957
training step: 12937, total_loss: 4.436565399169922
training step: 12938, total_loss: 3.9139771461486816
training step: 12939, total_loss: 4.660866737365723
training step: 12940, total_loss: 5.646427154541016
training step: 12941, total_loss: 3.712308645248413
training step: 12942, total_loss: 4.751687526702881
training step: 12943, total_loss: 3.707507610321045
training step: 12944, total_loss: 4.487357139587402
training step: 12945, total_loss: 5.926424026489258
training step: 12946, total_loss: 3.6174163818359375
training step: 12947, total_loss: 5.565769672393799
training step: 12948, total_loss: 4.0254807472229
training step: 12949, total_loss: 4.29424524307251
training step: 12950, total_loss: 4.814424991607666
training step: 12951, total_loss: 4.152346134185791
training step: 12952, total_loss: 4.162838935852051
training step: 12953, total_loss: 3.2923903465270996
training step: 12954, total_loss: 4.647267818450928
training step: 12955, total_loss: 4.607194423675537
training step: 12956, total_loss: 5.880936622619629
training step: 12957, total_loss: 5.651110649108887
training step: 12958, total_loss: 5.597592830657959
training step: 12959, total_loss: 5.199082374572754
training step: 12960, total_loss: 4.533177852630615
training step: 12961, total_loss: 1.0924928188323975
training step: 12962, total_loss: 5.30324649810791
training step: 12963, total_loss: 4.942176342010498
training step: 12964, total_loss: 5.047857761383057
training step: 12965, total_loss: 3.5035791397094727
training step: 12966, total_loss: 6.739347457885742
training step: 12967, total_loss: 5.901960849761963
training step: 12968, total_loss: 5.549895286560059
training step: 12969, total_loss: 4.197652339935303
training step: 12970, total_loss: 4.782951831817627
training step: 12971, total_loss: 3.954120635986328
training step: 12972, total_loss: 5.31160831451416
training step: 12973, total_loss: 5.144645690917969
training step: 12974, total_loss: 4.944026947021484
training step: 12975, total_loss: 5.133016586303711
training step: 12976, total_loss: 5.605813503265381
training step: 12977, total_loss: 4.670558929443359
training step: 12978, total_loss: 4.318907260894775
training step: 12979, total_loss: 5.08489990234375
training step: 12980, total_loss: 4.91768741607666
training step: 12981, total_loss: 4.969630241394043
training step: 12982, total_loss: 6.923569202423096
training step: 12983, total_loss: 4.047708511352539
training step: 12984, total_loss: 4.84723424911499
training step: 12985, total_loss: 4.6794233322143555
training step: 12986, total_loss: 5.4192986488342285
training step: 12987, total_loss: 4.549124717712402
training step: 12988, total_loss: 4.486917018890381
training step: 12989, total_loss: 3.6791634559631348
training step: 12990, total_loss: 4.3309173583984375
training step: 12991, total_loss: 4.234891414642334
training step: 12992, total_loss: 4.2031755447387695
training step: 12993, total_loss: 6.36007022857666
training step: 12994, total_loss: 4.262937545776367
training step: 12995, total_loss: 4.841832637786865
training step: 12996, total_loss: 4.971692085266113
training step: 12997, total_loss: 5.624095916748047
training step: 12998, total_loss: 4.6577229499816895
training step: 12999, total_loss: 3.2843017578125
training step: 13000, total_loss: 5.600976943969727
training step: 13001, total_loss: 4.618790149688721
training step: 13002, total_loss: 4.886842250823975
training step: 13003, total_loss: 3.818405866622925
training step: 13004, total_loss: 3.3917324542999268
training step: 13005, total_loss: 4.508086681365967
training step: 13006, total_loss: 5.304269313812256
training step: 13007, total_loss: 3.8953378200531006
training step: 13008, total_loss: 6.084185600280762
training step: 13009, total_loss: 5.606205463409424
training step: 13010, total_loss: 4.827396869659424
training step: 13011, total_loss: 4.926629066467285
training step: 13012, total_loss: 4.524161338806152
training step: 13013, total_loss: 4.983151435852051
training step: 13014, total_loss: 4.574872016906738
training step: 13015, total_loss: 5.247709274291992
training step: 13016, total_loss: 5.269809246063232
training step: 13017, total_loss: 3.5235755443573
training step: 13018, total_loss: 5.16418981552124
training step: 13019, total_loss: 4.56456184387207
training step: 13020, total_loss: 4.659221172332764
training step: 13021, total_loss: 4.864651679992676
training step: 13022, total_loss: 5.550751686096191
training step: 13023, total_loss: 4.736108303070068
training step: 13024, total_loss: 4.345483303070068
training step: 13025, total_loss: 5.148819923400879
training step: 13026, total_loss: 4.982119560241699
training step: 13027, total_loss: 5.204264163970947
training step: 13028, total_loss: 4.744565010070801
training step: 13029, total_loss: 4.226528167724609
training step: 13030, total_loss: 4.036180019378662
training step: 13031, total_loss: 4.716733455657959
training step: 13032, total_loss: 3.9848456382751465
training step: 13033, total_loss: 4.413495063781738
training step: 13034, total_loss: 4.072764873504639
training step: 13035, total_loss: 3.8844118118286133
training step: 13036, total_loss: 1.7887483835220337
training step: 13037, total_loss: 4.21526575088501
training step: 13038, total_loss: 5.026594161987305
training step: 13039, total_loss: 4.822981357574463
training step: 13040, total_loss: 4.693299293518066
training step: 13041, total_loss: 5.254281044006348
training step: 13042, total_loss: 5.101835250854492
training step: 13043, total_loss: 5.0164475440979
training step: 13044, total_loss: 5.407400131225586
training step: 13045, total_loss: 2.7880325317382812
training step: 13046, total_loss: 4.184986114501953
training step: 13047, total_loss: 5.207983493804932
training step: 13048, total_loss: 4.092129707336426
training step: 13049, total_loss: 4.261995315551758
training step: 13050, total_loss: 3.5619702339172363
training step: 13051, total_loss: 4.668386459350586
training step: 13052, total_loss: 4.221166133880615
training step: 13053, total_loss: 4.861063003540039
training step: 13054, total_loss: 5.026821136474609
training step: 13055, total_loss: 3.268012046813965
training step: 13056, total_loss: 3.98526668548584
training step: 13057, total_loss: 4.554823398590088
training step: 13058, total_loss: 4.138550758361816
training step: 13059, total_loss: 3.0265579223632812
training step: 13060, total_loss: 4.303725242614746
training step: 13061, total_loss: 3.5097882747650146
training step: 13062, total_loss: 3.072488784790039
training step: 13063, total_loss: 4.43945837020874
training step: 13064, total_loss: 5.6558732986450195
training step: 13065, total_loss: 3.649580955505371
training step: 13066, total_loss: 4.495429992675781
training step: 13067, total_loss: 5.726511001586914
training step: 13068, total_loss: 4.996660232543945
training step: 13069, total_loss: 4.409557342529297
training step: 13070, total_loss: 4.9396772384643555
training step: 13071, total_loss: 3.7361249923706055
training step: 13072, total_loss: 4.091434478759766
training step: 13073, total_loss: 4.392465591430664
training step: 13074, total_loss: 5.343894004821777
training step: 13075, total_loss: 4.516481876373291
training step: 13076, total_loss: 5.06904935836792
training step: 13077, total_loss: 4.8721466064453125
training step: 13078, total_loss: 2.8646116256713867
training step: 13079, total_loss: 5.283451557159424
training step: 13080, total_loss: 4.939086437225342
training step: 13081, total_loss: 5.499807357788086
training step: 13082, total_loss: 4.611823081970215
training step: 13083, total_loss: 4.136894702911377
training step: 13084, total_loss: 5.534374237060547
training step: 13085, total_loss: 1.5084891319274902
training step: 13086, total_loss: 3.7285852432250977
training step: 13087, total_loss: 4.91328239440918
training step: 13088, total_loss: 4.518522262573242
training step: 13089, total_loss: 4.231153964996338
training step: 13090, total_loss: 4.094446659088135
training step: 13091, total_loss: 2.944444179534912
training step: 13092, total_loss: 5.254770278930664
training step: 13093, total_loss: 5.012542247772217
training step: 13094, total_loss: 4.009197235107422
training step: 13095, total_loss: 2.626692056655884
training step: 13096, total_loss: 4.342166900634766
training step: 13097, total_loss: 0.9862217903137207
training step: 13098, total_loss: 5.6655988693237305
training step: 13099, total_loss: 3.755605697631836
training step: 13100, total_loss: 5.001924991607666
training step: 13101, total_loss: 3.97503662109375
training step: 13102, total_loss: 4.31959342956543
training step: 13103, total_loss: 4.3898773193359375
training step: 13104, total_loss: 4.730270862579346
training step: 13105, total_loss: 3.5911786556243896
training step: 13106, total_loss: 4.838860511779785
training step: 13107, total_loss: 0.8668633699417114
training step: 13108, total_loss: 3.2995152473449707
training step: 13109, total_loss: 6.154094696044922
training step: 13110, total_loss: 3.526369333267212
training step: 13111, total_loss: 4.310046195983887
training step: 13112, total_loss: 5.408036708831787
training step: 13113, total_loss: 4.633678913116455
training step: 13114, total_loss: 3.6162376403808594
training step: 13115, total_loss: 6.718474388122559
training step: 13116, total_loss: 4.2834978103637695
training step: 13117, total_loss: 3.456853151321411
training step: 13118, total_loss: 3.8133907318115234
training step: 13119, total_loss: 4.647406101226807
training step: 13120, total_loss: 4.969873428344727
training step: 13121, total_loss: 5.039708137512207
training step: 13122, total_loss: 5.514265060424805
training step: 13123, total_loss: 4.575564384460449
training step: 13124, total_loss: 5.10961389541626
training step: 13125, total_loss: 5.232296943664551
training step: 13126, total_loss: 5.475451469421387
training step: 13127, total_loss: 4.153905391693115
training step: 13128, total_loss: 3.9677157402038574
training step: 13129, total_loss: 4.541950225830078
training step: 13130, total_loss: 4.549472808837891
training step: 13131, total_loss: 5.350153923034668
training step: 13132, total_loss: 4.424571990966797
training step: 13133, total_loss: 4.640885829925537
training step: 13134, total_loss: 5.135101795196533
training step: 13135, total_loss: 3.3686842918395996
training step: 13136, total_loss: 1.092956304550171
training step: 13137, total_loss: 5.160423755645752
training step: 13138, total_loss: 5.493005275726318
training step: 13139, total_loss: 6.062600135803223
training step: 13140, total_loss: 4.025733470916748
training step: 13141, total_loss: 4.657865524291992
training step: 13142, total_loss: 5.442520618438721
training step: 13143, total_loss: 1.3636770248413086
training step: 13144, total_loss: 4.511419296264648
training step: 13145, total_loss: 2.463426113128662
training step: 13146, total_loss: 5.6976213455200195
training step: 13147, total_loss: 5.895753860473633
training step: 13148, total_loss: 6.032279968261719
training step: 13149, total_loss: 4.863286972045898
training step: 13150, total_loss: 4.259578227996826
training step: 13151, total_loss: 3.0180671215057373
training step: 13152, total_loss: 4.711839199066162
training step: 13153, total_loss: 3.958955764770508
training step: 13154, total_loss: 2.344780445098877
training step: 13155, total_loss: 5.256213665008545
training step: 13156, total_loss: 5.109648704528809
training step: 13157, total_loss: 4.192591667175293
training step: 13158, total_loss: 3.521678924560547
training step: 13159, total_loss: 4.967974662780762
training step: 13160, total_loss: 4.542245864868164
training step: 13161, total_loss: 5.15966796875
training step: 13162, total_loss: 4.659164905548096
training step: 13163, total_loss: 4.435534477233887
training step: 13164, total_loss: 5.374124526977539
training step: 13165, total_loss: 6.579673767089844
training step: 13166, total_loss: 4.798117637634277
training step: 13167, total_loss: 5.722136974334717
training step: 13168, total_loss: 4.161046028137207
training step: 13169, total_loss: 4.874760627746582
training step: 13170, total_loss: 4.657323837280273
training step: 13171, total_loss: 4.760258674621582
training step: 13172, total_loss: 3.9282336235046387
training step: 13173, total_loss: 3.402132272720337
training step: 13174, total_loss: 6.729918956756592
training step: 13175, total_loss: 3.7671327590942383
training step: 13176, total_loss: 3.558396339416504
training step: 13177, total_loss: 6.03364896774292
training step: 13178, total_loss: 5.134079933166504
training step: 13179, total_loss: 4.383728981018066
training step: 13180, total_loss: 5.243608474731445
training step: 13181, total_loss: 4.514655113220215
training step: 13182, total_loss: 4.354823112487793
training step: 13183, total_loss: 3.336794376373291
training step: 13184, total_loss: 4.053047180175781
training step: 13185, total_loss: 5.149769306182861
training step: 13186, total_loss: 4.7841901779174805
training step: 13187, total_loss: 3.661891460418701
training step: 13188, total_loss: 5.2171173095703125
training step: 13189, total_loss: 4.340157985687256
training step: 13190, total_loss: 4.326706409454346
training step: 13191, total_loss: 3.1713051795959473
training step: 13192, total_loss: 5.917728424072266
training step: 13193, total_loss: 5.532071113586426
training step: 13194, total_loss: 3.4579038619995117
training step: 13195, total_loss: 4.250883102416992
training step: 13196, total_loss: 5.370169639587402
training step: 13197, total_loss: 3.8122525215148926
training step: 13198, total_loss: 6.378506660461426
training step: 13199, total_loss: 4.636091709136963
training step: 13200, total_loss: 4.6604509353637695
training step: 13201, total_loss: 5.242791175842285
training step: 13202, total_loss: 5.228410720825195
training step: 13203, total_loss: 4.828184127807617
training step: 13204, total_loss: 4.711301803588867
training step: 13205, total_loss: 4.731176376342773
training step: 13206, total_loss: 4.087103843688965
training step: 13207, total_loss: 4.21457576751709
training step: 13208, total_loss: 3.2293148040771484
training step: 13209, total_loss: 5.4995317459106445
training step: 13210, total_loss: 6.190882682800293
training step: 13211, total_loss: 3.6223607063293457
training step: 13212, total_loss: 3.9936881065368652
training step: 13213, total_loss: 5.478532791137695
training step: 13214, total_loss: 4.1959004402160645
training step: 13215, total_loss: 6.1178436279296875
training step: 13216, total_loss: 4.921640396118164
training step: 13217, total_loss: 4.048778533935547
training step: 13218, total_loss: 6.153069019317627
training step: 13219, total_loss: 2.834357500076294
training step: 13220, total_loss: 4.765189170837402
training step: 13221, total_loss: 5.773586273193359
training step: 13222, total_loss: 5.079054832458496
training step: 13223, total_loss: 4.517511367797852
training step: 13224, total_loss: 4.153080463409424
training step: 13225, total_loss: 4.713726043701172
training step: 13226, total_loss: 3.768643379211426
training step: 13227, total_loss: 5.134044647216797
training step: 13228, total_loss: 5.965146064758301
training step: 13229, total_loss: 6.274473190307617
training step: 13230, total_loss: 5.456107139587402
training step: 13231, total_loss: 3.9304094314575195
training step: 13232, total_loss: 4.57958984375
training step: 13233, total_loss: 3.2072906494140625
training step: 13234, total_loss: 6.468935966491699
training step: 13235, total_loss: 4.789398193359375
training step: 13236, total_loss: 4.22372579574585
training step: 13237, total_loss: 4.3964715003967285
training step: 13238, total_loss: 3.9627060890197754
training step: 13239, total_loss: 4.434788703918457
training step: 13240, total_loss: 4.003005027770996
training step: 13241, total_loss: 5.493474960327148
training step: 13242, total_loss: 5.356198787689209
training step: 13243, total_loss: 4.736378192901611
training step: 13244, total_loss: 2.0122764110565186
training step: 13245, total_loss: 3.807427406311035
training step: 13246, total_loss: 5.366512775421143
training step: 13247, total_loss: 5.372060298919678
training step: 13248, total_loss: 5.1207194328308105
training step: 13249, total_loss: 2.8658981323242188
training step: 13250, total_loss: 4.835669994354248
training step: 13251, total_loss: 4.208738327026367
training step: 13252, total_loss: 4.477634429931641
training step: 13253, total_loss: 4.532402992248535
training step: 13254, total_loss: 5.658102035522461
training step: 13255, total_loss: 4.977653503417969
training step: 13256, total_loss: 4.6285505294799805
training step: 13257, total_loss: 5.605069637298584
training step: 13258, total_loss: 4.945959568023682
training step: 13259, total_loss: 7.145443916320801
training step: 13260, total_loss: 4.67645263671875
training step: 13261, total_loss: 3.9405226707458496
training step: 13262, total_loss: 2.576256275177002
training step: 13263, total_loss: 5.428784370422363
training step: 13264, total_loss: 1.3611690998077393
training step: 13265, total_loss: 4.509705543518066
training step: 13266, total_loss: 4.71632194519043
training step: 13267, total_loss: 5.002555847167969
training step: 13268, total_loss: 4.594851016998291
training step: 13269, total_loss: 1.127901315689087
training step: 13270, total_loss: 4.467065811157227
training step: 13271, total_loss: 3.362323760986328
training step: 13272, total_loss: 6.065988540649414
training step: 13273, total_loss: 4.357611179351807
training step: 13274, total_loss: 4.992733955383301
training step: 13275, total_loss: 6.102375030517578
training step: 13276, total_loss: 4.898305416107178
training step: 13277, total_loss: 5.121393203735352
training step: 13278, total_loss: 5.462551116943359
training step: 13279, total_loss: 4.303867340087891
training step: 13280, total_loss: 5.224031448364258
training step: 13281, total_loss: 4.587779521942139
training step: 13282, total_loss: 4.779964447021484
training step: 13283, total_loss: 4.2070393562316895
training step: 13284, total_loss: 4.411429405212402
training step: 13285, total_loss: 5.609184741973877
training step: 13286, total_loss: 4.580317497253418
training step: 13287, total_loss: 3.096524715423584
training step: 13288, total_loss: 5.893851280212402
training step: 13289, total_loss: 4.631462097167969
training step: 13290, total_loss: 4.825562953948975
training step: 13291, total_loss: 4.963222026824951
training step: 13292, total_loss: 2.7024192810058594
training step: 13293, total_loss: 4.276110649108887
training step: 13294, total_loss: 3.4717860221862793
training step: 13295, total_loss: 2.9181580543518066
training step: 13296, total_loss: 3.693342685699463
training step: 13297, total_loss: 2.3767290115356445
training step: 13298, total_loss: 5.653290271759033
training step: 13299, total_loss: 4.952878952026367
training step: 13300, total_loss: 5.916918754577637
training step: 13301, total_loss: 5.89821720123291
training step: 13302, total_loss: 4.136404514312744
training step: 13303, total_loss: 5.207322120666504
training step: 13304, total_loss: 4.893798828125
training step: 13305, total_loss: 3.174459934234619
training step: 13306, total_loss: 4.484145164489746
training step: 13307, total_loss: 5.324524402618408
training step: 13308, total_loss: 6.525375843048096
training step: 13309, total_loss: 3.2496368885040283
training step: 13310, total_loss: 6.143360137939453
training step: 13311, total_loss: 5.323535919189453
training step: 13312, total_loss: 5.933157920837402
training step: 13313, total_loss: 3.9144632816314697
training step: 13314, total_loss: 6.099985122680664
training step: 13315, total_loss: 4.601852893829346
training step: 13316, total_loss: 3.897937774658203
training step: 13317, total_loss: 3.3473000526428223
training step: 13318, total_loss: 0.9993404150009155
training step: 13319, total_loss: 5.698746681213379
training step: 13320, total_loss: 4.558012962341309
training step: 13321, total_loss: 4.07598876953125
training step: 13322, total_loss: 3.7149672508239746
training step: 13323, total_loss: 5.549434185028076
training step: 13324, total_loss: 4.564096927642822
training step: 13325, total_loss: 7.217544078826904
training step: 13326, total_loss: 3.492136240005493
training step: 13327, total_loss: 4.146816730499268
training step: 13328, total_loss: 5.770785331726074
training step: 13329, total_loss: 5.157121181488037
training step: 13330, total_loss: 3.0393905639648438
training step: 13331, total_loss: 5.2091383934021
training step: 13332, total_loss: 4.267752647399902
training step: 13333, total_loss: 5.138575077056885
training step: 13334, total_loss: 5.581717491149902
training step: 13335, total_loss: 5.298385143280029
training step: 13336, total_loss: 0.8872308731079102
training step: 13337, total_loss: 4.431988716125488
training step: 13338, total_loss: 6.247855186462402
training step: 13339, total_loss: 4.978555202484131
training step: 13340, total_loss: 4.6784515380859375
training step: 13341, total_loss: 2.5939488410949707
training step: 13342, total_loss: 4.461006164550781
training step: 13343, total_loss: 5.093706130981445
training step: 13344, total_loss: 4.133755683898926
training step: 13345, total_loss: 5.103241920471191
training step: 13346, total_loss: 5.023614406585693
training step: 13347, total_loss: 3.8398919105529785
training step: 13348, total_loss: 5.04649543762207
training step: 13349, total_loss: 4.227144241333008
training step: 13350, total_loss: 3.6198062896728516
training step: 13351, total_loss: 3.486544609069824
training step: 13352, total_loss: 5.162580490112305
training step: 13353, total_loss: 5.07749605178833
training step: 13354, total_loss: 4.392467498779297
training step: 13355, total_loss: 6.519471168518066
training step: 13356, total_loss: 3.7089853286743164
training step: 13357, total_loss: 3.560753345489502
training step: 13358, total_loss: 5.316196441650391
training step: 13359, total_loss: 3.208569049835205
training step: 13360, total_loss: 3.695438861846924
training step: 13361, total_loss: 4.005486011505127
training step: 13362, total_loss: 5.900969505310059
training step: 13363, total_loss: 3.2287702560424805
training step: 13364, total_loss: 5.567145347595215
training step: 13365, total_loss: 6.282018661499023
training step: 13366, total_loss: 5.552590370178223
training step: 13367, total_loss: 4.824681282043457
training step: 13368, total_loss: 4.061835765838623
training step: 13369, total_loss: 3.7172839641571045
training step: 13370, total_loss: 3.0622382164001465
training step: 13371, total_loss: 4.2928924560546875
training step: 13372, total_loss: 4.090789794921875
training step: 13373, total_loss: 4.703002452850342
training step: 13374, total_loss: 5.258721351623535
training step: 13375, total_loss: 5.136602401733398
training step: 13376, total_loss: 4.494784832000732
training step: 13377, total_loss: 4.049330711364746
training step: 13378, total_loss: 5.430288314819336
training step: 13379, total_loss: 5.0213117599487305
training step: 13380, total_loss: 4.480006217956543
training step: 13381, total_loss: 3.2510037422180176
training step: 13382, total_loss: 5.550939559936523
training step: 13383, total_loss: 4.691458702087402
training step: 13384, total_loss: 4.57681941986084
training step: 13385, total_loss: 1.4566704034805298
training step: 13386, total_loss: 5.204657554626465
training step: 13387, total_loss: 4.716923713684082
training step: 13388, total_loss: 3.701110601425171
training step: 13389, total_loss: 5.528989791870117
training step: 13390, total_loss: 3.512070894241333
training step: 13391, total_loss: 4.624312400817871
training step: 13392, total_loss: 5.13686990737915
training step: 13393, total_loss: 4.4804816246032715
training step: 13394, total_loss: 6.118285179138184
training step: 13395, total_loss: 4.943628311157227
training step: 13396, total_loss: 2.66723895072937
training step: 13397, total_loss: 5.200331211090088
training step: 13398, total_loss: 2.688127279281616
training step: 13399, total_loss: 3.9350266456604004
training step: 13400, total_loss: 5.148556709289551
training step: 13401, total_loss: 5.696130752563477
training step: 13402, total_loss: 3.9356417655944824
training step: 13403, total_loss: 4.020688056945801
training step: 13404, total_loss: 5.095412731170654
training step: 13405, total_loss: 3.647996425628662
training step: 13406, total_loss: 3.799593448638916
training step: 13407, total_loss: 5.28954553604126
training step: 13408, total_loss: 4.940953254699707
training step: 13409, total_loss: 4.963351249694824
training step: 13410, total_loss: 3.326021671295166
training step: 13411, total_loss: 4.379509449005127
training step: 13412, total_loss: 3.4450266361236572
training step: 13413, total_loss: 6.690910339355469
training step: 13414, total_loss: 5.009863376617432
training step: 13415, total_loss: 5.128046035766602
training step: 13416, total_loss: 4.099297523498535
training step: 13417, total_loss: 3.555802345275879
training step: 13418, total_loss: 5.562213897705078
training step: 13419, total_loss: 6.799784183502197
training step: 13420, total_loss: 2.9631266593933105
training step: 13421, total_loss: 5.481914043426514
training step: 13422, total_loss: 5.322425365447998
training step: 13423, total_loss: 5.510896682739258
training step: 13424, total_loss: 4.508608818054199
training step: 13425, total_loss: 4.49169397354126
training step: 13426, total_loss: 3.9318721294403076
training step: 13427, total_loss: 6.606227874755859
training step: 13428, total_loss: 4.486550331115723
training step: 13429, total_loss: 5.419076442718506
training step: 13430, total_loss: 3.230365753173828
training step: 13431, total_loss: 5.60010290145874
training step: 13432, total_loss: 5.160274028778076
training step: 13433, total_loss: 4.7528533935546875
training step: 13434, total_loss: 4.465944766998291
training step: 13435, total_loss: 2.009453296661377
training step: 13436, total_loss: 4.864593505859375
training step: 13437, total_loss: 4.349836349487305
training step: 13438, total_loss: 5.344457626342773
training step: 13439, total_loss: 4.208042144775391
training step: 13440, total_loss: 4.7233076095581055
training step: 13441, total_loss: 5.115164756774902
training step: 13442, total_loss: 4.981945991516113
training step: 13443, total_loss: 4.615249156951904
training step: 13444, total_loss: 5.5475544929504395
training step: 13445, total_loss: 3.9041500091552734
training step: 13446, total_loss: 4.4413299560546875
training step: 13447, total_loss: 4.5999250411987305
training step: 13448, total_loss: 4.182644844055176
training step: 13449, total_loss: 5.522558689117432
training step: 13450, total_loss: 1.3053843975067139
training step: 13451, total_loss: 4.153162956237793
training step: 13452, total_loss: 3.5521340370178223
training step: 13453, total_loss: 4.839353561401367
training step: 13454, total_loss: 5.077402114868164
training step: 13455, total_loss: 6.002833366394043
training step: 13456, total_loss: 3.933387041091919
training step: 13457, total_loss: 5.048909664154053
training step: 13458, total_loss: 5.011892318725586
training step: 13459, total_loss: 5.370649337768555
training step: 13460, total_loss: 3.7426042556762695
training step: 13461, total_loss: 4.974121570587158
training step: 13462, total_loss: 4.846752166748047
training step: 13463, total_loss: 3.691431999206543
training step: 13464, total_loss: 4.959527015686035
training step: 13465, total_loss: 7.1538777351379395
training step: 13466, total_loss: 1.1208692789077759
training step: 13467, total_loss: 4.646855354309082
training step: 13468, total_loss: 5.4898858070373535
training step: 13469, total_loss: 4.878232002258301
training step: 13470, total_loss: 4.383938789367676
training step: 13471, total_loss: 3.2066152095794678
training step: 13472, total_loss: 3.84934663772583
training step: 13473, total_loss: 2.7190277576446533
training step: 13474, total_loss: 4.653667449951172
training step: 13475, total_loss: 5.98549222946167
training step: 13476, total_loss: 5.468311309814453
training step: 13477, total_loss: 3.7788078784942627
training step: 13478, total_loss: 3.9826204776763916
training step: 13479, total_loss: 6.215686798095703
training step: 13480, total_loss: 2.359414577484131
training step: 13481, total_loss: 5.137547492980957
training step: 13482, total_loss: 4.833263397216797
training step: 13483, total_loss: 6.748687744140625
training step: 13484, total_loss: 5.5022406578063965
training step: 13485, total_loss: 5.9214935302734375
training step: 13486, total_loss: 6.527188777923584
training step: 13487, total_loss: 5.871477127075195
training step: 13488, total_loss: 5.281767845153809
training step: 13489, total_loss: 4.004133224487305
training step: 13490, total_loss: 4.277346134185791
training step: 13491, total_loss: 5.17470121383667
training step: 13492, total_loss: 5.384831428527832
training step: 13493, total_loss: 4.548871994018555
training step: 13494, total_loss: 5.130147933959961
training step: 13495, total_loss: 2.475886344909668
training step: 13496, total_loss: 6.013207912445068
training step: 13497, total_loss: 1.3047294616699219
training step: 13498, total_loss: 5.5001726150512695
training step: 13499, total_loss: 5.536630630493164
training step: 13500, total_loss: 4.520029544830322
training step: 13501, total_loss: 4.275506019592285
training step: 13502, total_loss: 4.053364276885986
training step: 13503, total_loss: 4.667204856872559
training step: 13504, total_loss: 5.355709075927734
training step: 13505, total_loss: 5.188454627990723
training step: 13506, total_loss: 5.262436866760254
training step: 13507, total_loss: 4.5589494705200195
training step: 13508, total_loss: 4.804386615753174
training step: 13509, total_loss: 3.9583945274353027
training step: 13510, total_loss: 3.9895694255828857
training step: 13511, total_loss: 4.380620002746582
training step: 13512, total_loss: 2.9904327392578125
training step: 13513, total_loss: 4.753341197967529
training step: 13514, total_loss: 4.801374912261963
training step: 13515, total_loss: 4.247570514678955
training step: 13516, total_loss: 5.479345321655273
training step: 13517, total_loss: 3.045797824859619
training step: 13518, total_loss: 4.440846920013428
training step: 13519, total_loss: 4.752927780151367
training step: 13520, total_loss: 4.226109504699707
training step: 13521, total_loss: 4.709736347198486
training step: 13522, total_loss: 4.366144180297852
training step: 13523, total_loss: 4.468576431274414
training step: 13524, total_loss: 5.156594276428223
training step: 13525, total_loss: 5.994706630706787
training step: 13526, total_loss: 5.331933975219727
training step: 13527, total_loss: 2.7121200561523438
training step: 13528, total_loss: 6.501461029052734
training step: 13529, total_loss: 4.8706560134887695
training step: 13530, total_loss: 4.779342174530029
training step: 13531, total_loss: 5.1461591720581055
training step: 13532, total_loss: 4.077715873718262
training step: 13533, total_loss: 4.107642650604248
training step: 13534, total_loss: 4.711910724639893
training step: 13535, total_loss: 4.909328460693359
training step: 13536, total_loss: 2.738785982131958
training step: 13537, total_loss: 5.185119152069092
training step: 13538, total_loss: 4.424716472625732
training step: 13539, total_loss: 4.1066365242004395
training step: 13540, total_loss: 5.346648216247559
training step: 13541, total_loss: 4.5456390380859375
training step: 13542, total_loss: 3.949146270751953
training step: 13543, total_loss: 5.510234832763672
training step: 13544, total_loss: 4.8904314041137695
training step: 13545, total_loss: 5.162106513977051
training step: 13546, total_loss: 3.618119478225708
training step: 13547, total_loss: 4.641465187072754
training step: 13548, total_loss: 4.568038463592529
training step: 13549, total_loss: 5.530708312988281
training step: 13550, total_loss: 1.857961654663086
training step: 13551, total_loss: 4.524534225463867
training step: 13552, total_loss: 6.115298271179199
training step: 13553, total_loss: 4.4430694580078125
training step: 13554, total_loss: 4.1892619132995605
training step: 13555, total_loss: 4.822745323181152
training step: 13556, total_loss: 2.5299458503723145
training step: 13557, total_loss: 6.009944438934326
training step: 13558, total_loss: 2.8676679134368896
training step: 13559, total_loss: 1.6496435403823853
training step: 13560, total_loss: 4.369844913482666
training step: 13561, total_loss: 4.278459548950195
training step: 13562, total_loss: 3.5850439071655273
training step: 13563, total_loss: 5.259456157684326
training step: 13564, total_loss: 3.8760933876037598
training step: 13565, total_loss: 5.480152130126953
training step: 13566, total_loss: 3.350841999053955
training step: 13567, total_loss: 5.076545715332031
training step: 13568, total_loss: 4.659944534301758
training step: 13569, total_loss: 4.64158821105957
training step: 13570, total_loss: 4.629263401031494
training step: 13571, total_loss: 6.751396179199219
training step: 13572, total_loss: 2.9128847122192383
training step: 13573, total_loss: 5.0521087646484375
training step: 13574, total_loss: 2.4801225662231445
training step: 13575, total_loss: 4.865889549255371
training step: 13576, total_loss: 2.624809503555298
training step: 13577, total_loss: 2.4233241081237793
training step: 13578, total_loss: 5.1458821296691895
training step: 13579, total_loss: 4.572211742401123
training step: 13580, total_loss: 4.29147481918335
training step: 13581, total_loss: 1.9671729803085327
training step: 13582, total_loss: 4.699217796325684
training step: 13583, total_loss: 3.3032891750335693
training step: 13584, total_loss: 3.9701972007751465
training step: 13585, total_loss: 4.929182052612305
training step: 13586, total_loss: 5.0226945877075195
training step: 13587, total_loss: 4.437887191772461
training step: 13588, total_loss: 2.863616704940796
training step: 13589, total_loss: 2.8309526443481445
training step: 13590, total_loss: 4.514435768127441
training step: 13591, total_loss: 4.671860694885254
training step: 13592, total_loss: 5.29772424697876
training step: 13593, total_loss: 5.054725646972656
training step: 13594, total_loss: 4.473956108093262
training step: 13595, total_loss: 4.757673740386963
training step: 13596, total_loss: 5.023028373718262
training step: 13597, total_loss: 4.326710224151611
training step: 13598, total_loss: 4.391785621643066
training step: 13599, total_loss: 4.204996585845947
training step: 13600, total_loss: 5.231433868408203
training step: 13601, total_loss: 4.4408063888549805
training step: 13602, total_loss: 4.540785312652588
training step: 13603, total_loss: 4.403557777404785
training step: 13604, total_loss: 4.053713321685791
training step: 13605, total_loss: 3.8679683208465576
training step: 13606, total_loss: 3.9026830196380615
training step: 13607, total_loss: 5.293879508972168
training step: 13608, total_loss: 7.573764801025391
training step: 13609, total_loss: 4.890843391418457
training step: 13610, total_loss: 5.564146041870117
training step: 13611, total_loss: 5.618597984313965
training step: 13612, total_loss: 4.49853515625
training step: 13613, total_loss: 5.01570463180542
training step: 13614, total_loss: 4.338700294494629
training step: 13615, total_loss: 4.6157612800598145
training step: 13616, total_loss: 5.086960792541504
training step: 13617, total_loss: 3.941988706588745
training step: 13618, total_loss: 3.5606703758239746
training step: 13619, total_loss: 4.9337158203125
training step: 13620, total_loss: 5.539796829223633
training step: 13621, total_loss: 6.602384090423584
training step: 13622, total_loss: 3.004201889038086
training step: 13623, total_loss: 5.054978370666504
training step: 13624, total_loss: 5.157750129699707
training step: 13625, total_loss: 6.020089149475098
training step: 13626, total_loss: 4.324428558349609
training step: 13627, total_loss: 3.831000566482544
training step: 13628, total_loss: 5.628232955932617
training step: 13629, total_loss: 6.250639915466309
training step: 13630, total_loss: 1.3752589225769043
training step: 13631, total_loss: 4.494596004486084
training step: 13632, total_loss: 4.041689395904541
training step: 13633, total_loss: 4.0623369216918945
training step: 13634, total_loss: 3.536665916442871
training step: 13635, total_loss: 4.093734264373779
training step: 13636, total_loss: 3.9087183475494385
training step: 13637, total_loss: 1.2157292366027832
training step: 13638, total_loss: 4.868508338928223
training step: 13639, total_loss: 5.652150630950928
training step: 13640, total_loss: 4.6633453369140625
training step: 13641, total_loss: 3.976513147354126
training step: 13642, total_loss: 4.975533962249756
training step: 13643, total_loss: 4.922484874725342
training step: 13644, total_loss: 3.866351366043091
training step: 13645, total_loss: 4.200177192687988
training step: 13646, total_loss: 4.680287837982178
training step: 13647, total_loss: 4.595251083374023
training step: 13648, total_loss: 4.268647193908691
training step: 13649, total_loss: 5.165275573730469
training step: 13650, total_loss: 3.7908716201782227
training step: 13651, total_loss: 5.524792671203613
training step: 13652, total_loss: 4.436962127685547
training step: 13653, total_loss: 2.977499008178711
training step: 13654, total_loss: 3.219388723373413
training step: 13655, total_loss: 4.4673919677734375
training step: 13656, total_loss: 5.03425931930542
training step: 13657, total_loss: 4.404882907867432
training step: 13658, total_loss: 5.059218406677246
training step: 13659, total_loss: 2.403463125228882
training step: 13660, total_loss: 5.311161994934082
training step: 13661, total_loss: 1.5794776678085327
training step: 13662, total_loss: 4.096501350402832
training step: 13663, total_loss: 4.246020317077637
training step: 13664, total_loss: 5.391400337219238
training step: 13665, total_loss: 5.071324348449707
training step: 13666, total_loss: 3.3558056354522705
training step: 13667, total_loss: 3.387023687362671
training step: 13668, total_loss: 5.360007286071777
training step: 13669, total_loss: 4.299522399902344
training step: 13670, total_loss: 3.9899978637695312
training step: 13671, total_loss: 4.613553047180176
training step: 13672, total_loss: 3.782151937484741
training step: 13673, total_loss: 4.5689826011657715
training step: 13674, total_loss: 4.60558557510376
training step: 13675, total_loss: 5.2005181312561035
training step: 13676, total_loss: 5.754560470581055
training step: 13677, total_loss: 3.89870548248291
training step: 13678, total_loss: 6.405208587646484
training step: 13679, total_loss: 5.0865478515625
training step: 13680, total_loss: 5.241556167602539
training step: 13681, total_loss: 4.3046793937683105
training step: 13682, total_loss: 3.706681728363037
training step: 13683, total_loss: 5.835241794586182
training step: 13684, total_loss: 2.4254002571105957
training step: 13685, total_loss: 5.065805912017822
training step: 13686, total_loss: 2.9763689041137695
training step: 13687, total_loss: 4.859553337097168
training step: 13688, total_loss: 5.285687446594238
training step: 13689, total_loss: 3.8906311988830566
training step: 13690, total_loss: 4.274296283721924
training step: 13691, total_loss: 3.758371353149414
training step: 13692, total_loss: 4.6624345779418945
training step: 13693, total_loss: 4.497145652770996
training step: 13694, total_loss: 3.9423253536224365
training step: 13695, total_loss: 5.285193920135498
training step: 13696, total_loss: 4.512103080749512
training step: 13697, total_loss: 3.983245849609375
training step: 13698, total_loss: 4.492204189300537
training step: 13699, total_loss: 3.037152051925659
training step: 13700, total_loss: 4.014764785766602
training step: 13701, total_loss: 3.076590061187744
training step: 13702, total_loss: 5.8592143058776855
training step: 13703, total_loss: 4.205683708190918
training step: 13704, total_loss: 4.797123432159424
training step: 13705, total_loss: 4.350216865539551
training step: 13706, total_loss: 4.7472076416015625
training step: 13707, total_loss: 4.358612537384033
training step: 13708, total_loss: 4.096726417541504
training step: 13709, total_loss: 5.801511764526367
training step: 13710, total_loss: 6.078354358673096
training step: 13711, total_loss: 2.811753988265991
training step: 13712, total_loss: 4.846704483032227
training step: 13713, total_loss: 2.860076427459717
training step: 13714, total_loss: 3.1414592266082764
training step: 13715, total_loss: 4.472168922424316
training step: 13716, total_loss: 2.0682694911956787
training step: 13717, total_loss: 4.705619812011719
training step: 13718, total_loss: 5.261297702789307
training step: 13719, total_loss: 4.83754301071167
training step: 13720, total_loss: 3.923689126968384
training step: 13721, total_loss: 5.455477237701416
training step: 13722, total_loss: 4.838581562042236
training step: 13723, total_loss: 4.600264072418213
training step: 13724, total_loss: 4.190084934234619
training step: 13725, total_loss: 3.754272937774658
training step: 13726, total_loss: 3.727449417114258
training step: 13727, total_loss: 2.308863639831543
training step: 13728, total_loss: 5.037526607513428
training step: 13729, total_loss: 6.484293460845947
training step: 13730, total_loss: 4.748675346374512
training step: 13731, total_loss: 4.837716102600098
training step: 13732, total_loss: 4.776354789733887
training step: 13733, total_loss: 5.255695343017578
training step: 13734, total_loss: 4.146262168884277
training step: 13735, total_loss: 4.896666526794434
training step: 13736, total_loss: 4.091991901397705
training step: 13737, total_loss: 4.681766033172607
training step: 13738, total_loss: 4.171274662017822
training step: 13739, total_loss: 3.745149850845337
training step: 13740, total_loss: 4.895135402679443
training step: 13741, total_loss: 4.506680011749268
training step: 13742, total_loss: 4.062029838562012
training step: 13743, total_loss: 4.08847713470459
training step: 13744, total_loss: 2.939842462539673
training step: 13745, total_loss: 3.2727503776550293
training step: 13746, total_loss: 4.741340160369873
training step: 13747, total_loss: 5.735467910766602
training step: 13748, total_loss: 5.181554794311523
training step: 13749, total_loss: 6.870367527008057
training step: 13750, total_loss: 4.134191513061523
training step: 13751, total_loss: 4.337950229644775
training step: 13752, total_loss: 5.353638648986816
training step: 13753, total_loss: 3.7749805450439453
training step: 13754, total_loss: 2.3090009689331055
training step: 13755, total_loss: 3.369788646697998
training step: 13756, total_loss: 3.978618860244751
training step: 13757, total_loss: 2.9328157901763916
training step: 13758, total_loss: 0.8377590179443359
training step: 13759, total_loss: 4.645134925842285
training step: 13760, total_loss: 4.046622276306152
training step: 13761, total_loss: 4.541558265686035
training step: 13762, total_loss: 4.540930271148682
training step: 13763, total_loss: 4.808965682983398
training step: 13764, total_loss: 5.13375186920166
training step: 13765, total_loss: 1.2336761951446533
training step: 13766, total_loss: 4.432168483734131
training step: 13767, total_loss: 4.589001655578613
training step: 13768, total_loss: 5.561532974243164
training step: 13769, total_loss: 4.722851276397705
training step: 13770, total_loss: 4.786972999572754
training step: 13771, total_loss: 3.9114208221435547
training step: 13772, total_loss: 5.900002956390381
training step: 13773, total_loss: 4.2894086837768555
training step: 13774, total_loss: 4.4777607917785645
training step: 13775, total_loss: 4.89872932434082
training step: 13776, total_loss: 4.045663356781006
training step: 13777, total_loss: 3.8955256938934326
training step: 13778, total_loss: 4.279318332672119
training step: 13779, total_loss: 4.017304420471191
training step: 13780, total_loss: 4.630340099334717
training step: 13781, total_loss: 4.983603477478027
training step: 13782, total_loss: 5.126097202301025
training step: 13783, total_loss: 5.688664436340332
training step: 13784, total_loss: 4.529074668884277
training step: 13785, total_loss: 4.497364521026611
training step: 13786, total_loss: 3.971590757369995
training step: 13787, total_loss: 4.813596248626709
training step: 13788, total_loss: 4.97371244430542
training step: 13789, total_loss: 4.619237422943115
training step: 13790, total_loss: 3.5995841026306152
training step: 13791, total_loss: 5.003787994384766
training step: 13792, total_loss: 4.071577072143555
training step: 13793, total_loss: 4.182534217834473
training step: 13794, total_loss: 4.693967819213867
training step: 13795, total_loss: 6.9123687744140625
training step: 13796, total_loss: 4.962327480316162
training step: 13797, total_loss: 4.5252366065979
training step: 13798, total_loss: 5.09903621673584
training step: 13799, total_loss: 6.293213367462158
training step: 13800, total_loss: 4.398763656616211
training step: 13801, total_loss: 6.560656547546387
training step: 13802, total_loss: 5.005741119384766
training step: 13803, total_loss: 4.607142925262451
training step: 13804, total_loss: 2.184229850769043
training step: 13805, total_loss: 5.251605033874512
training step: 13806, total_loss: 4.952011585235596
training step: 13807, total_loss: 3.221625328063965
training step: 13808, total_loss: 5.4041643142700195
training step: 13809, total_loss: 5.43882942199707
training step: 13810, total_loss: 4.148296356201172
training step: 13811, total_loss: 3.580747127532959
training step: 13812, total_loss: 4.94102668762207
training step: 13813, total_loss: 5.119934558868408
training step: 13814, total_loss: 5.841010093688965
training step: 13815, total_loss: 4.468006134033203
training step: 13816, total_loss: 4.265532493591309
training step: 13817, total_loss: 4.1612701416015625
training step: 13818, total_loss: 4.731056213378906
training step: 13819, total_loss: 4.4673566818237305
training step: 13820, total_loss: 5.293068885803223
training step: 13821, total_loss: 3.8509912490844727
training step: 13822, total_loss: 4.511288166046143
training step: 13823, total_loss: 6.061284065246582
training step: 13824, total_loss: 4.235564708709717
training step: 13825, total_loss: 5.234088897705078
training step: 13826, total_loss: 4.204325199127197
training step: 13827, total_loss: 4.617366313934326
training step: 13828, total_loss: 5.336398124694824
training step: 13829, total_loss: 4.442257404327393
training step: 13830, total_loss: 4.88222074508667
training step: 13831, total_loss: 3.245074510574341
training step: 13832, total_loss: 5.521683692932129
training step: 13833, total_loss: 4.740260124206543
training step: 13834, total_loss: 5.184196472167969
training step: 13835, total_loss: 4.359325885772705
training step: 13836, total_loss: 6.097185134887695
training step: 13837, total_loss: 4.286069869995117
training step: 13838, total_loss: 5.767489433288574
training step: 13839, total_loss: 4.187097549438477
training step: 13840, total_loss: 4.046472549438477
training step: 13841, total_loss: 2.923954963684082
training step: 13842, total_loss: 3.1199231147766113
training step: 13843, total_loss: 4.167374610900879
training step: 13844, total_loss: 4.224822044372559
training step: 13845, total_loss: 6.234643936157227
training step: 13846, total_loss: 5.4581990242004395
training step: 13847, total_loss: 5.686856746673584
training step: 13848, total_loss: 4.947976589202881
training step: 13849, total_loss: 3.6368298530578613
training step: 13850, total_loss: 4.856305122375488
training step: 13851, total_loss: 1.3760957717895508
training step: 13852, total_loss: 5.464543342590332
training step: 13853, total_loss: 3.7517056465148926
training step: 13854, total_loss: 5.614819049835205
training step: 13855, total_loss: 4.91874885559082
training step: 13856, total_loss: 4.3094611167907715
training step: 13857, total_loss: 6.017365455627441
training step: 13858, total_loss: 4.367432594299316
training step: 13859, total_loss: 4.124378204345703
training step: 13860, total_loss: 4.232830047607422
training step: 13861, total_loss: 5.085887908935547
training step: 13862, total_loss: 2.7970163822174072
training step: 13863, total_loss: 3.974970579147339
training step: 13864, total_loss: 4.148235321044922
training step: 13865, total_loss: 3.9478025436401367
training step: 13866, total_loss: 3.405763626098633
training step: 13867, total_loss: 4.69999361038208
training step: 13868, total_loss: 4.698894500732422
training step: 13869, total_loss: 6.234012603759766
training step: 13870, total_loss: 4.8700432777404785
training step: 13871, total_loss: 3.6150121688842773
training step: 13872, total_loss: 5.878779411315918
training step: 13873, total_loss: 2.8281826972961426
training step: 13874, total_loss: 1.3135416507720947
training step: 13875, total_loss: 4.714210510253906
training step: 13876, total_loss: 1.1161794662475586
training step: 13877, total_loss: 4.904685974121094
training step: 13878, total_loss: 3.6546616554260254
training step: 13879, total_loss: 0.8582011461257935
training step: 13880, total_loss: 5.305637359619141
training step: 13881, total_loss: 4.2822980880737305
training step: 13882, total_loss: 3.910689115524292
training step: 13883, total_loss: 5.698328018188477
training step: 13884, total_loss: 4.46928596496582
training step: 13885, total_loss: 3.3264341354370117
training step: 13886, total_loss: 4.572921276092529
training step: 13887, total_loss: 6.01953125
training step: 13888, total_loss: 5.819591999053955
training step: 13889, total_loss: 4.030002593994141
training step: 13890, total_loss: 3.8804922103881836
training step: 13891, total_loss: 3.792045831680298
training step: 13892, total_loss: 4.079483985900879
training step: 13893, total_loss: 3.9205589294433594
training step: 13894, total_loss: 5.498699188232422
training step: 13895, total_loss: 5.950889587402344
training step: 13896, total_loss: 4.393119812011719
training step: 13897, total_loss: 4.5786919593811035
training step: 13898, total_loss: 4.609565258026123
training step: 13899, total_loss: 2.083974838256836
training step: 13900, total_loss: 5.53562068939209
training step: 13901, total_loss: 3.6840555667877197
training step: 13902, total_loss: 5.166018962860107
training step: 13903, total_loss: 6.119633674621582
training step: 13904, total_loss: 3.0943241119384766
training step: 13905, total_loss: 5.740237236022949
training step: 13906, total_loss: 4.4524383544921875
training step: 13907, total_loss: 4.324014663696289
training step: 13908, total_loss: 4.572152614593506
training step: 13909, total_loss: 3.3258118629455566
training step: 13910, total_loss: 3.6911983489990234
training step: 13911, total_loss: 5.553990364074707
training step: 13912, total_loss: 4.792381763458252
training step: 13913, total_loss: 3.098200798034668
training step: 13914, total_loss: 4.8371381759643555
training step: 13915, total_loss: 4.306249618530273
training step: 13916, total_loss: 5.017693519592285
training step: 13917, total_loss: 4.444153308868408
training step: 13918, total_loss: 4.562921524047852
training step: 13919, total_loss: 5.257918357849121
training step: 13920, total_loss: 5.842472076416016
training step: 13921, total_loss: 6.852688789367676
training step: 13922, total_loss: 6.117095947265625
training step: 13923, total_loss: 3.2620532512664795
training step: 13924, total_loss: 4.505489349365234
training step: 13925, total_loss: 2.7481470108032227
training step: 13926, total_loss: 5.087223529815674
training step: 13927, total_loss: 2.981839179992676
training step: 13928, total_loss: 4.880660057067871
training step: 13929, total_loss: 1.2438530921936035
training step: 13930, total_loss: 4.726013660430908
training step: 13931, total_loss: 5.251917362213135
training step: 13932, total_loss: 4.208178520202637
training step: 13933, total_loss: 4.655581474304199
training step: 13934, total_loss: 4.3596954345703125
training step: 13935, total_loss: 5.300882339477539
training step: 13936, total_loss: 4.68526554107666
training step: 13937, total_loss: 0.867329478263855
training step: 13938, total_loss: 5.346914291381836
training step: 13939, total_loss: 6.310885429382324
training step: 13940, total_loss: 5.2656331062316895
training step: 13941, total_loss: 4.825385570526123
training step: 13942, total_loss: 4.090272903442383
training step: 13943, total_loss: 5.554712295532227
training step: 13944, total_loss: 2.8856215476989746
training step: 13945, total_loss: 4.54309606552124
training step: 13946, total_loss: 5.2807297706604
training step: 13947, total_loss: 5.4713239669799805
training step: 13948, total_loss: 6.387763977050781
training step: 13949, total_loss: 3.2236368656158447
training step: 13950, total_loss: 5.10047721862793
training step: 13951, total_loss: 4.747481346130371
training step: 13952, total_loss: 7.227494239807129
training step: 13953, total_loss: 4.101008415222168
training step: 13954, total_loss: 4.393664360046387
training step: 13955, total_loss: 4.751703262329102
training step: 13956, total_loss: 7.107237815856934
training step: 13957, total_loss: 4.693197250366211
training step: 13958, total_loss: 4.879433631896973
training step: 13959, total_loss: 4.281670093536377
training step: 13960, total_loss: 4.011457443237305
training step: 13961, total_loss: 5.230719089508057
training step: 13962, total_loss: 3.1487722396850586
training step: 13963, total_loss: 5.547371864318848
training step: 13964, total_loss: 5.185087203979492
training step: 13965, total_loss: 3.9331371784210205
training step: 13966, total_loss: 5.614093780517578
training step: 13967, total_loss: 0.918911337852478
training step: 13968, total_loss: 3.278702735900879
training step: 13969, total_loss: 4.95790958404541
training step: 13970, total_loss: 6.059820175170898
training step: 13971, total_loss: 4.298944473266602
training step: 13972, total_loss: 4.899604797363281
training step: 13973, total_loss: 4.572353839874268
training step: 13974, total_loss: 5.212703227996826
training step: 13975, total_loss: 3.5226080417633057
training step: 13976, total_loss: 4.3563079833984375
training step: 13977, total_loss: 5.075661659240723
training step: 13978, total_loss: 5.0611677169799805
training step: 13979, total_loss: 2.5380754470825195
training step: 13980, total_loss: 3.4911248683929443
training step: 13981, total_loss: 3.8494532108306885
training step: 13982, total_loss: 4.26774263381958
training step: 13983, total_loss: 4.512362480163574
training step: 13984, total_loss: 6.144623279571533
training step: 13985, total_loss: 4.3951334953308105
training step: 13986, total_loss: 6.05798864364624
training step: 13987, total_loss: 5.296159744262695
training step: 13988, total_loss: 4.4022297859191895
training step: 13989, total_loss: 4.833481788635254
training step: 13990, total_loss: 3.882159471511841
training step: 13991, total_loss: 5.1881208419799805
training step: 13992, total_loss: 4.1867194175720215
training step: 13993, total_loss: 5.194087028503418
training step: 13994, total_loss: 5.621710300445557
training step: 13995, total_loss: 6.396565914154053
training step: 13996, total_loss: 4.611089706420898
training step: 13997, total_loss: 5.155857563018799
training step: 13998, total_loss: 5.175915241241455
training step: 13999, total_loss: 4.320926666259766
training step: 14000, total_loss: 2.467849016189575
training step: 14001, total_loss: 5.106114387512207
training step: 14002, total_loss: 3.4943628311157227
training step: 14003, total_loss: 2.394235849380493
training step: 14004, total_loss: 6.4051642417907715
training step: 14005, total_loss: 5.402327060699463
training step: 14006, total_loss: 3.248478412628174
training step: 14007, total_loss: 7.1335906982421875
training step: 14008, total_loss: 3.8605005741119385
training step: 14009, total_loss: 3.665281057357788
training step: 14010, total_loss: 4.457493782043457
training step: 14011, total_loss: 5.292379379272461
training step: 14012, total_loss: 5.875616073608398
training step: 14013, total_loss: 3.9198195934295654
training step: 14014, total_loss: 5.219429016113281
training step: 14015, total_loss: 5.807336807250977
training step: 14016, total_loss: 5.093886375427246
training step: 14017, total_loss: 4.303855895996094
training step: 14018, total_loss: 5.063886642456055
training step: 14019, total_loss: 4.497101306915283
training step: 14020, total_loss: 5.1091508865356445
training step: 14021, total_loss: 5.647797584533691
training step: 14022, total_loss: 1.2202184200286865
training step: 14023, total_loss: 3.4199585914611816
training step: 14024, total_loss: 5.741997718811035
training step: 14025, total_loss: 2.6530652046203613
training step: 14026, total_loss: 4.330313205718994
training step: 14027, total_loss: 4.318638801574707
training step: 14028, total_loss: 4.266476631164551
training step: 14029, total_loss: 4.168158531188965
training step: 14030, total_loss: 5.049246311187744
training step: 14031, total_loss: 4.963931560516357
training step: 14032, total_loss: 4.501180648803711
training step: 14033, total_loss: 4.945713043212891
training step: 14034, total_loss: 3.3598523139953613
training step: 14035, total_loss: 4.307592391967773
training step: 14036, total_loss: 6.320702075958252
training step: 14037, total_loss: 3.730961799621582
training step: 14038, total_loss: 4.563122749328613
training step: 14039, total_loss: 4.649676322937012
training step: 14040, total_loss: 4.436523914337158
training step: 14041, total_loss: 4.570990562438965
training step: 14042, total_loss: 1.0551007986068726
training step: 14043, total_loss: 3.883789539337158
training step: 14044, total_loss: 3.9515528678894043
training step: 14045, total_loss: 4.483091354370117
training step: 14046, total_loss: 5.278679847717285
training step: 14047, total_loss: 3.776550531387329
training step: 14048, total_loss: 4.632229328155518
training step: 14049, total_loss: 4.398171424865723
training step: 14050, total_loss: 4.174400329589844
training step: 14051, total_loss: 2.3707547187805176
training step: 14052, total_loss: 3.219947338104248
training step: 14053, total_loss: 3.6411542892456055
training step: 14054, total_loss: 4.989362716674805
training step: 14055, total_loss: 4.129923343658447
training step: 14056, total_loss: 3.672229290008545
training step: 14057, total_loss: 3.4619035720825195
training step: 14058, total_loss: 4.5935258865356445
training step: 14059, total_loss: 4.599283218383789
training step: 14060, total_loss: 6.859758377075195
training step: 14061, total_loss: 4.96811056137085
training step: 14062, total_loss: 3.767759323120117
training step: 14063, total_loss: 4.134219646453857
training step: 14064, total_loss: 3.998213529586792
training step: 14065, total_loss: 5.406245231628418
training step: 14066, total_loss: 3.9607338905334473
training step: 14067, total_loss: 5.4379072189331055
training step: 14068, total_loss: 4.78743839263916
training step: 14069, total_loss: 5.127008438110352
training step: 14070, total_loss: 6.00604772567749
training step: 14071, total_loss: 4.905773162841797
training step: 14072, total_loss: 4.886006832122803
training step: 14073, total_loss: 3.6927051544189453
training step: 14074, total_loss: 4.255922794342041
training step: 14075, total_loss: 5.01209831237793
training step: 14076, total_loss: 4.514468669891357
training step: 14077, total_loss: 6.421710014343262
training step: 14078, total_loss: 5.772575855255127
training step: 14079, total_loss: 4.367753505706787
training step: 14080, total_loss: 4.023368835449219
training step: 14081, total_loss: 3.9867069721221924
training step: 14082, total_loss: 4.011843681335449
training step: 14083, total_loss: 4.561092853546143
training step: 14084, total_loss: 4.118101119995117
training step: 14085, total_loss: 4.800468444824219
training step: 14086, total_loss: 4.6124372482299805
training step: 14087, total_loss: 4.777332782745361
training step: 14088, total_loss: 5.47368860244751
training step: 14089, total_loss: 4.428618907928467
training step: 14090, total_loss: 4.820559501647949
training step: 14091, total_loss: 4.581901550292969
training step: 14092, total_loss: 1.9681737422943115
training step: 14093, total_loss: 3.898252010345459
training step: 14094, total_loss: 3.857024669647217
training step: 14095, total_loss: 4.159020900726318
training step: 14096, total_loss: 4.745876312255859
training step: 14097, total_loss: 4.100062847137451
training step: 14098, total_loss: 4.823314666748047
training step: 14099, total_loss: 4.328207015991211
training step: 14100, total_loss: 3.897528886795044
training step: 14101, total_loss: 3.8610639572143555
training step: 14102, total_loss: 4.321197509765625
training step: 14103, total_loss: 3.0441806316375732
training step: 14104, total_loss: 3.535496473312378
training step: 14105, total_loss: 3.5464532375335693
training step: 14106, total_loss: 5.284676551818848
training step: 14107, total_loss: 5.183922290802002
training step: 14108, total_loss: 3.849321126937866
training step: 14109, total_loss: 4.371120452880859
training step: 14110, total_loss: 2.796131134033203
training step: 14111, total_loss: 3.282489061355591
training step: 14112, total_loss: 5.923764228820801
training step: 14113, total_loss: 4.885899543762207
training step: 14114, total_loss: 5.071948051452637
training step: 14115, total_loss: 4.817877292633057
training step: 14116, total_loss: 6.208662986755371
training step: 14117, total_loss: 5.543033599853516
training step: 14118, total_loss: 4.636656761169434
training step: 14119, total_loss: 5.77897310256958
training step: 14120, total_loss: 5.315254211425781
training step: 14121, total_loss: 5.209414005279541
training step: 14122, total_loss: 4.736702919006348
training step: 14123, total_loss: 4.23297119140625
training step: 14124, total_loss: 4.665458679199219
training step: 14125, total_loss: 5.803997039794922
training step: 14126, total_loss: 5.566253185272217
training step: 14127, total_loss: 4.199106216430664
training step: 14128, total_loss: 4.094811916351318
training step: 14129, total_loss: 4.210538387298584
training step: 14130, total_loss: 5.347769737243652
training step: 14131, total_loss: 5.275223731994629
training step: 14132, total_loss: 4.923242568969727
training step: 14133, total_loss: 6.343823432922363
training step: 14134, total_loss: 5.283326625823975
training step: 14135, total_loss: 4.199887275695801
training step: 14136, total_loss: 4.599925518035889
training step: 14137, total_loss: 6.1885480880737305
training step: 14138, total_loss: 5.07456111907959
training step: 14139, total_loss: 2.770503044128418
training step: 14140, total_loss: 4.018014430999756
training step: 14141, total_loss: 4.354115009307861
training step: 14142, total_loss: 4.820103645324707
training step: 14143, total_loss: 4.772315979003906
training step: 14144, total_loss: 3.7436423301696777
training step: 14145, total_loss: 4.386516094207764
training step: 14146, total_loss: 5.716642379760742
training step: 14147, total_loss: 4.156942367553711
training step: 14148, total_loss: 3.8051376342773438
training step: 14149, total_loss: 5.098901271820068
training step: 14150, total_loss: 4.851674556732178
training step: 14151, total_loss: 4.869109153747559
training step: 14152, total_loss: 4.602885723114014
training step: 14153, total_loss: 3.714310646057129
training step: 14154, total_loss: 3.6526966094970703
training step: 14155, total_loss: 3.858516216278076
training step: 14156, total_loss: 5.077796936035156
training step: 14157, total_loss: 3.681826114654541
training step: 14158, total_loss: 3.8438913822174072
training step: 14159, total_loss: 4.012685775756836
training step: 14160, total_loss: 4.811066627502441
training step: 14161, total_loss: 2.8346762657165527
training step: 14162, total_loss: 2.3155879974365234
training step: 14163, total_loss: 4.142734527587891
training step: 14164, total_loss: 4.68856143951416
training step: 14165, total_loss: 4.295792102813721
training step: 14166, total_loss: 2.9483604431152344
training step: 14167, total_loss: 5.276851177215576
training step: 14168, total_loss: 4.851555824279785
training step: 14169, total_loss: 6.175724983215332
training step: 14170, total_loss: 3.034956216812134
training step: 14171, total_loss: 5.2379961013793945
training step: 14172, total_loss: 4.210671901702881
training step: 14173, total_loss: 4.65043830871582
training step: 14174, total_loss: 4.0889739990234375
training step: 14175, total_loss: 7.22429084777832
training step: 14176, total_loss: 1.5929839611053467
training step: 14177, total_loss: 4.737605571746826
training step: 14178, total_loss: 3.612246036529541
training step: 14179, total_loss: 1.1467317342758179
training step: 14180, total_loss: 4.460193157196045
training step: 14181, total_loss: 1.355449914932251
training step: 14182, total_loss: 5.285938262939453
training step: 14183, total_loss: 4.488170146942139
training step: 14184, total_loss: 5.2889180183410645
training step: 14185, total_loss: 2.7676432132720947
training step: 14186, total_loss: 3.16341495513916
training step: 14187, total_loss: 5.04049015045166
training step: 14188, total_loss: 3.462474822998047
training step: 14189, total_loss: 5.088887691497803
training step: 14190, total_loss: 4.387504577636719
training step: 14191, total_loss: 6.07330322265625
training step: 14192, total_loss: 4.525166034698486
training step: 14193, total_loss: 6.665915489196777
training step: 14194, total_loss: 2.9736580848693848
training step: 14195, total_loss: 5.537261009216309
training step: 14196, total_loss: 5.455792427062988
training step: 14197, total_loss: 2.467519760131836
training step: 14198, total_loss: 5.4228315353393555
training step: 14199, total_loss: 4.478102207183838
training step: 14200, total_loss: 4.195810317993164
training step: 14201, total_loss: 4.163297176361084
training step: 14202, total_loss: 4.947372913360596
training step: 14203, total_loss: 4.205059051513672
training step: 14204, total_loss: 3.6098239421844482
training step: 14205, total_loss: 5.527142524719238
training step: 14206, total_loss: 3.6288254261016846
training step: 14207, total_loss: 3.9948067665100098
training step: 14208, total_loss: 5.136872291564941
training step: 14209, total_loss: 6.105845928192139
training step: 14210, total_loss: 4.915376663208008
training step: 14211, total_loss: 5.546159744262695
training step: 14212, total_loss: 2.6470375061035156
training step: 14213, total_loss: 1.3115636110305786
training step: 14214, total_loss: 5.688214302062988
training step: 14215, total_loss: 4.244491100311279
training step: 14216, total_loss: 3.6018781661987305
training step: 14217, total_loss: 5.348308563232422
training step: 14218, total_loss: 5.358570575714111
training step: 14219, total_loss: 4.866302967071533
training step: 14220, total_loss: 6.07778263092041
training step: 14221, total_loss: 4.03311824798584
training step: 14222, total_loss: 3.7779040336608887
training step: 14223, total_loss: 3.25091552734375
training step: 14224, total_loss: 3.970930337905884
training step: 14225, total_loss: 3.2969279289245605
training step: 14226, total_loss: 5.845886707305908
training step: 14227, total_loss: 5.517836570739746
training step: 14228, total_loss: 5.01624059677124
training step: 14229, total_loss: 4.924624443054199
training step: 14230, total_loss: 4.608865737915039
training step: 14231, total_loss: 4.40958309173584
training step: 14232, total_loss: 3.1225457191467285
training step: 14233, total_loss: 5.140154838562012
training step: 14234, total_loss: 5.8617424964904785
training step: 14235, total_loss: 4.8453369140625
training step: 14236, total_loss: 5.603590488433838
training step: 14237, total_loss: 4.418960094451904
training step: 14238, total_loss: 5.121352195739746
training step: 14239, total_loss: 5.030096054077148
training step: 14240, total_loss: 5.337027549743652
training step: 14241, total_loss: 3.998147487640381
training step: 14242, total_loss: 4.866803169250488
training step: 14243, total_loss: 4.760943412780762
training step: 14244, total_loss: 4.0229597091674805
training step: 14245, total_loss: 4.848178863525391
training step: 14246, total_loss: 4.3016204833984375
training step: 14247, total_loss: 3.433339834213257
training step: 14248, total_loss: 4.9848246574401855
training step: 14249, total_loss: 4.39553689956665
training step: 14250, total_loss: 4.521688938140869
training step: 14251, total_loss: 5.010334014892578
training step: 14252, total_loss: 4.174433708190918
training step: 14253, total_loss: 5.086549758911133
training step: 14254, total_loss: 5.381433010101318
training step: 14255, total_loss: 5.07395076751709
training step: 14256, total_loss: 5.746683120727539
training step: 14257, total_loss: 5.4631547927856445
training step: 14258, total_loss: 4.810055255889893
training step: 14259, total_loss: 3.9793477058410645
training step: 14260, total_loss: 3.878178358078003
training step: 14261, total_loss: 3.2248497009277344
training step: 14262, total_loss: 4.518847465515137
training step: 14263, total_loss: 4.228358268737793
training step: 14264, total_loss: 4.644126892089844
training step: 14265, total_loss: 3.6622467041015625
training step: 14266, total_loss: 4.796905517578125
training step: 14267, total_loss: 5.098590850830078
training step: 14268, total_loss: 5.659448623657227
training step: 14269, total_loss: 5.711896896362305
training step: 14270, total_loss: 6.017908573150635
training step: 14271, total_loss: 5.662229537963867
training step: 14272, total_loss: 4.733305931091309
training step: 14273, total_loss: 4.48183536529541
training step: 14274, total_loss: 3.098630905151367
training step: 14275, total_loss: 4.918851852416992
training step: 14276, total_loss: 5.442663192749023
training step: 14277, total_loss: 5.609922409057617
training step: 14278, total_loss: 5.218771934509277
training step: 14279, total_loss: 5.176009178161621
training step: 14280, total_loss: 5.165820598602295
training step: 14281, total_loss: 4.856245517730713
training step: 14282, total_loss: 4.630997657775879
training step: 14283, total_loss: 4.651767253875732
training step: 14284, total_loss: 4.659547805786133
training step: 14285, total_loss: 4.54752254486084
training step: 14286, total_loss: 4.61255407333374
training step: 14287, total_loss: 5.177993297576904
training step: 14288, total_loss: 3.0684328079223633
training step: 14289, total_loss: 4.86588191986084
training step: 14290, total_loss: 5.51133918762207
training step: 14291, total_loss: 5.035070419311523
training step: 14292, total_loss: 4.169965744018555
training step: 14293, total_loss: 5.084013938903809
training step: 14294, total_loss: 4.302289962768555
training step: 14295, total_loss: 6.02255916595459
training step: 14296, total_loss: 1.5587804317474365
training step: 14297, total_loss: 3.106856346130371
training step: 14298, total_loss: 3.5099642276763916
training step: 14299, total_loss: 5.972711086273193
training step: 14300, total_loss: 4.811612129211426
training step: 14301, total_loss: 1.954784870147705
training step: 14302, total_loss: 5.242918014526367
training step: 14303, total_loss: 4.462427616119385
training step: 14304, total_loss: 2.6572136878967285
training step: 14305, total_loss: 4.739142894744873
training step: 14306, total_loss: 5.187700271606445
training step: 14307, total_loss: 4.909369468688965
training step: 14308, total_loss: 4.777773857116699
training step: 14309, total_loss: 4.411115646362305
training step: 14310, total_loss: 3.970486640930176
training step: 14311, total_loss: 4.614521026611328
training step: 14312, total_loss: 5.4797563552856445
training step: 14313, total_loss: 5.402595043182373
training step: 14314, total_loss: 4.924552917480469
training step: 14315, total_loss: 4.358700752258301
training step: 14316, total_loss: 1.1873698234558105
training step: 14317, total_loss: 4.486063003540039
training step: 14318, total_loss: 4.359424591064453
training step: 14319, total_loss: 3.612729549407959
training step: 14320, total_loss: 4.932094573974609
training step: 14321, total_loss: 4.450601100921631
training step: 14322, total_loss: 4.332350254058838
training step: 14323, total_loss: 5.193985462188721
training step: 14324, total_loss: 5.360134124755859
training step: 14325, total_loss: 3.2876315116882324
training step: 14326, total_loss: 4.991839408874512
training step: 14327, total_loss: 8.055018424987793
training step: 14328, total_loss: 4.191150665283203
training step: 14329, total_loss: 5.376706123352051
training step: 14330, total_loss: 4.79090690612793
training step: 14331, total_loss: 6.290185928344727
training step: 14332, total_loss: 4.573085784912109
training step: 14333, total_loss: 4.1423163414001465
training step: 14334, total_loss: 5.250526428222656
training step: 14335, total_loss: 5.4194865226745605
training step: 14336, total_loss: 1.6832395792007446
training step: 14337, total_loss: 4.621035575866699
training step: 14338, total_loss: 5.469921112060547
training step: 14339, total_loss: 3.614790439605713
training step: 14340, total_loss: 4.449982643127441
training step: 14341, total_loss: 2.440526008605957
training step: 14342, total_loss: 4.908376693725586
training step: 14343, total_loss: 4.981817245483398
training step: 14344, total_loss: 4.610051155090332
training step: 14345, total_loss: 4.363084316253662
training step: 14346, total_loss: 5.1027984619140625
training step: 14347, total_loss: 4.9147539138793945
training step: 14348, total_loss: 4.905904769897461
training step: 14349, total_loss: 4.38852596282959
training step: 14350, total_loss: 3.2309165000915527
training step: 14351, total_loss: 4.761383056640625
training step: 14352, total_loss: 4.792186737060547
training step: 14353, total_loss: 4.6474289894104
training step: 14354, total_loss: 2.1317801475524902
training step: 14355, total_loss: 3.4315218925476074
training step: 14356, total_loss: 3.937377691268921
training step: 14357, total_loss: 5.338688850402832
training step: 14358, total_loss: 5.214853286743164
training step: 14359, total_loss: 4.512569904327393
training step: 14360, total_loss: 4.863736152648926
training step: 14361, total_loss: 4.333852767944336
training step: 14362, total_loss: 4.486602783203125
training step: 14363, total_loss: 5.427011489868164
training step: 14364, total_loss: 3.629624843597412
training step: 14365, total_loss: 4.941819190979004
training step: 14366, total_loss: 5.243472576141357
training step: 14367, total_loss: 3.6463510990142822
training step: 14368, total_loss: 0.8881797194480896
training step: 14369, total_loss: 5.299293041229248
training step: 14370, total_loss: 5.316143989562988
training step: 14371, total_loss: 5.329392433166504
training step: 14372, total_loss: 4.99904727935791
training step: 14373, total_loss: 5.067373752593994
training step: 14374, total_loss: 4.78550910949707
training step: 14375, total_loss: 4.861774444580078
training step: 14376, total_loss: 4.588766098022461
training step: 14377, total_loss: 4.826704978942871
training step: 14378, total_loss: 2.7928032875061035
training step: 14379, total_loss: 4.589315414428711
training step: 14380, total_loss: 6.321224689483643
training step: 14381, total_loss: 3.0104823112487793
training step: 14382, total_loss: 4.844632625579834
training step: 14383, total_loss: 4.3688740730285645
training step: 14384, total_loss: 5.905787467956543
training step: 14385, total_loss: 4.36138391494751
training step: 14386, total_loss: 5.395344257354736
training step: 14387, total_loss: 4.6531901359558105
training step: 14388, total_loss: 4.097192764282227
training step: 14389, total_loss: 5.126186370849609
training step: 14390, total_loss: 3.379441499710083
training step: 14391, total_loss: 6.3484954833984375
training step: 14392, total_loss: 5.707452297210693
training step: 14393, total_loss: 4.353488922119141
training step: 14394, total_loss: 3.7383131980895996
training step: 14395, total_loss: 4.7478132247924805
training step: 14396, total_loss: 5.435845375061035
training step: 14397, total_loss: 4.5260329246521
training step: 14398, total_loss: 5.759047508239746
training step: 14399, total_loss: 4.789675235748291
training step: 14400, total_loss: 5.2386674880981445
training step: 14401, total_loss: 5.142541885375977
training step: 14402, total_loss: 4.447864532470703
training step: 14403, total_loss: 5.658559799194336
training step: 14404, total_loss: 4.840557098388672
training step: 14405, total_loss: 4.059295654296875
training step: 14406, total_loss: 3.6779346466064453
training step: 14407, total_loss: 4.898015975952148
training step: 14408, total_loss: 5.140716552734375
training step: 14409, total_loss: 5.008457183837891
training step: 14410, total_loss: 4.937077522277832
training step: 14411, total_loss: 2.271103620529175
training step: 14412, total_loss: 4.245401382446289
training step: 14413, total_loss: 4.688541412353516
training step: 14414, total_loss: 5.604363918304443
training step: 14415, total_loss: 4.816590309143066
training step: 14416, total_loss: 5.9028778076171875
training step: 14417, total_loss: 6.426715850830078
training step: 14418, total_loss: 4.558173179626465
training step: 14419, total_loss: 5.568739891052246
training step: 14420, total_loss: 4.482582092285156
training step: 14421, total_loss: 4.976338863372803
training step: 14422, total_loss: 5.785226821899414
training step: 14423, total_loss: 4.2122483253479
training step: 14424, total_loss: 4.55891227722168
training step: 14425, total_loss: 2.937079906463623
training step: 14426, total_loss: 4.395595550537109
training step: 14427, total_loss: 6.050166130065918
training step: 14428, total_loss: 2.962360143661499
training step: 14429, total_loss: 5.5179948806762695
training step: 14430, total_loss: 4.868562698364258
training step: 14431, total_loss: 6.581690311431885
training step: 14432, total_loss: 4.715309143066406
training step: 14433, total_loss: 2.006160259246826
training step: 14434, total_loss: 4.399847030639648
training step: 14435, total_loss: 3.1422088146209717
training step: 14436, total_loss: 5.528463363647461
training step: 14437, total_loss: 5.209841728210449
training step: 14438, total_loss: 4.425987243652344
training step: 14439, total_loss: 4.990194320678711
training step: 14440, total_loss: 3.1379942893981934
training step: 14441, total_loss: 4.41857385635376
training step: 14442, total_loss: 4.185977458953857
training step: 14443, total_loss: 4.460905075073242
training step: 14444, total_loss: 3.6559677124023438
training step: 14445, total_loss: 6.221592426300049
training step: 14446, total_loss: 5.231719017028809
training step: 14447, total_loss: 4.3259663581848145
training step: 14448, total_loss: 4.761297225952148
training step: 14449, total_loss: 4.690558433532715
training step: 14450, total_loss: 4.943615913391113
training step: 14451, total_loss: 4.139150619506836
training step: 14452, total_loss: 4.5815653800964355
training step: 14453, total_loss: 3.8025612831115723
training step: 14454, total_loss: 4.377377033233643
training step: 14455, total_loss: 7.139564514160156
training step: 14456, total_loss: 4.848607063293457
training step: 14457, total_loss: 3.3815720081329346
training step: 14458, total_loss: 3.4734721183776855
training step: 14459, total_loss: 4.535826683044434
training step: 14460, total_loss: 4.341545104980469
training step: 14461, total_loss: 5.043513298034668
training step: 14462, total_loss: 4.775428295135498
training step: 14463, total_loss: 4.422990798950195
training step: 14464, total_loss: 4.927579879760742
training step: 14465, total_loss: 7.368571758270264
training step: 14466, total_loss: 4.799856662750244
training step: 14467, total_loss: 5.393783092498779
training step: 14468, total_loss: 4.292472839355469
training step: 14469, total_loss: 5.076590061187744
training step: 14470, total_loss: 3.884550094604492
training step: 14471, total_loss: 5.40678596496582
training step: 14472, total_loss: 4.451076984405518
training step: 14473, total_loss: 4.6121368408203125
training step: 14474, total_loss: 5.631020545959473
training step: 14475, total_loss: 5.113076210021973
training step: 14476, total_loss: 5.7492475509643555
training step: 14477, total_loss: 5.389064788818359
training step: 14478, total_loss: 4.191066741943359
training step: 14479, total_loss: 5.2103681564331055
training step: 14480, total_loss: 4.114391326904297
training step: 14481, total_loss: 5.700109481811523
training step: 14482, total_loss: 5.581274032592773
training step: 14483, total_loss: 4.873018264770508
training step: 14484, total_loss: 7.4124836921691895
training step: 14485, total_loss: 4.06917667388916
training step: 14486, total_loss: 4.734356880187988
training step: 14487, total_loss: 4.069472312927246
training step: 14488, total_loss: 4.94856071472168
training step: 14489, total_loss: 4.637698173522949
training step: 14490, total_loss: 4.3190836906433105
training step: 14491, total_loss: 5.489936351776123
training step: 14492, total_loss: 5.9975056648254395
training step: 14493, total_loss: 3.7747411727905273
training step: 14494, total_loss: 3.9916257858276367
training step: 14495, total_loss: 4.099445343017578
training step: 14496, total_loss: 4.032264232635498
training step: 14497, total_loss: 7.144195556640625
training step: 14498, total_loss: 4.470746994018555
training step: 14499, total_loss: 1.5324962139129639
training step: 14500, total_loss: 3.949105739593506
training step: 14501, total_loss: 4.055440425872803
training step: 14502, total_loss: 4.985902309417725
training step: 14503, total_loss: 2.440685749053955
training step: 14504, total_loss: 5.335422515869141
training step: 14505, total_loss: 3.6516079902648926
training step: 14506, total_loss: 1.4370450973510742
training step: 14507, total_loss: 3.7079575061798096
training step: 14508, total_loss: 3.9280550479888916
training step: 14509, total_loss: 6.526506423950195
training step: 14510, total_loss: 4.702162742614746
training step: 14511, total_loss: 4.238934516906738
training step: 14512, total_loss: 3.8058977127075195
training step: 14513, total_loss: 4.205104351043701
training step: 14514, total_loss: 4.820176124572754
training step: 14515, total_loss: 3.069049835205078
training step: 14516, total_loss: 4.335714340209961
training step: 14517, total_loss: 4.176693916320801
training step: 14518, total_loss: 5.330557346343994
training step: 14519, total_loss: 5.296121597290039
training step: 14520, total_loss: 4.266400337219238
training step: 14521, total_loss: 3.081542491912842
training step: 14522, total_loss: 4.663182258605957
training step: 14523, total_loss: 4.6067376136779785
training step: 14524, total_loss: 4.4072794914245605
training step: 14525, total_loss: 6.371723175048828
training step: 14526, total_loss: 3.8539416790008545
training step: 14527, total_loss: 3.309086322784424
training step: 14528, total_loss: 5.150809288024902
training step: 14529, total_loss: 4.200981140136719
training step: 14530, total_loss: 4.639111518859863
training step: 14531, total_loss: 4.686221599578857
training step: 14532, total_loss: 4.475430011749268
training step: 14533, total_loss: 4.82736873626709
training step: 14534, total_loss: 4.958918571472168
training step: 14535, total_loss: 4.448618412017822
training step: 14536, total_loss: 4.558450698852539
training step: 14537, total_loss: 6.046232223510742
training step: 14538, total_loss: 4.1059489250183105
training step: 14539, total_loss: 4.072546482086182
training step: 14540, total_loss: 4.36820650100708
training step: 14541, total_loss: 5.087987899780273
training step: 14542, total_loss: 4.329739093780518
training step: 14543, total_loss: 3.70361590385437
training step: 14544, total_loss: 4.154563903808594
training step: 14545, total_loss: 6.447151184082031
training step: 14546, total_loss: 4.718106269836426
training step: 14547, total_loss: 5.027705192565918
training step: 14548, total_loss: 5.134997367858887
training step: 14549, total_loss: 4.17757511138916
training step: 14550, total_loss: 3.485495090484619
training step: 14551, total_loss: 7.1047515869140625
training step: 14552, total_loss: 3.1096386909484863
training step: 14553, total_loss: 6.454052925109863
training step: 14554, total_loss: 5.314113616943359
training step: 14555, total_loss: 4.857909202575684
training step: 14556, total_loss: 4.243783950805664
training step: 14557, total_loss: 6.124785423278809
training step: 14558, total_loss: 3.882716178894043
training step: 14559, total_loss: 3.9500718116760254
training step: 14560, total_loss: 4.547059059143066
training step: 14561, total_loss: 4.236083984375
training step: 14562, total_loss: 5.395788669586182
training step: 14563, total_loss: 3.776301860809326
training step: 14564, total_loss: 4.486012935638428
training step: 14565, total_loss: 6.044770240783691
training step: 14566, total_loss: 3.873772144317627
training step: 14567, total_loss: 6.326186656951904
training step: 14568, total_loss: 4.885261058807373
training step: 14569, total_loss: 4.615550994873047
training step: 14570, total_loss: 3.336508274078369
training step: 14571, total_loss: 4.5000505447387695
training step: 14572, total_loss: 4.6194071769714355
training step: 14573, total_loss: 6.62748908996582
training step: 14574, total_loss: 4.762049198150635
training step: 14575, total_loss: 5.129017353057861
training step: 14576, total_loss: 1.333202600479126
training step: 14577, total_loss: 4.093278884887695
training step: 14578, total_loss: 4.5545268058776855
training step: 14579, total_loss: 4.941723823547363
training step: 14580, total_loss: 4.714877128601074
training step: 14581, total_loss: 4.623981475830078
training step: 14582, total_loss: 5.306917190551758
training step: 14583, total_loss: 3.284698963165283
training step: 14584, total_loss: 3.786269187927246
training step: 14585, total_loss: 3.7013697624206543
training step: 14586, total_loss: 4.574465751647949
training step: 14587, total_loss: 4.825272560119629
training step: 14588, total_loss: 4.226150035858154
training step: 14589, total_loss: 4.3846845626831055
training step: 14590, total_loss: 4.492530822753906
training step: 14591, total_loss: 4.45316743850708
training step: 14592, total_loss: 5.0434980392456055
training step: 14593, total_loss: 4.174720287322998
training step: 14594, total_loss: 4.740323066711426
training step: 14595, total_loss: 5.6278276443481445
training step: 14596, total_loss: 5.8367156982421875
training step: 14597, total_loss: 6.197644233703613
training step: 14598, total_loss: 3.2159335613250732
training step: 14599, total_loss: 4.441140174865723
training step: 14600, total_loss: 4.6902031898498535
training step: 14601, total_loss: 4.929471492767334
training step: 14602, total_loss: 4.151848316192627
training step: 14603, total_loss: 5.075389862060547
training step: 14604, total_loss: 4.57243537902832
training step: 14605, total_loss: 6.185044288635254
training step: 14606, total_loss: 4.6651787757873535
training step: 14607, total_loss: 4.400017738342285
training step: 14608, total_loss: 5.787996768951416
training step: 14609, total_loss: 3.366410255432129
training step: 14610, total_loss: 5.101105690002441
training step: 14611, total_loss: 5.4726409912109375
training step: 14612, total_loss: 4.882757186889648
training step: 14613, total_loss: 3.6977663040161133
training step: 14614, total_loss: 4.634814262390137
training step: 14615, total_loss: 4.431622505187988
training step: 14616, total_loss: 4.646848201751709
training step: 14617, total_loss: 4.883817195892334
training step: 14618, total_loss: 4.490081787109375
training step: 14619, total_loss: 3.0737528800964355
training step: 14620, total_loss: 4.523649215698242
training step: 14621, total_loss: 4.886537551879883
training step: 14622, total_loss: 4.821976661682129
training step: 14623, total_loss: 3.6193490028381348
training step: 14624, total_loss: 4.381742477416992
training step: 14625, total_loss: 5.417381286621094
training step: 14626, total_loss: 4.633976936340332
training step: 14627, total_loss: 6.318629264831543
training step: 14628, total_loss: 6.58152961730957
training step: 14629, total_loss: 2.773118019104004
training step: 14630, total_loss: 5.0636162757873535
training step: 14631, total_loss: 4.770458698272705
training step: 14632, total_loss: 7.10418701171875
training step: 14633, total_loss: 4.730620384216309
training step: 14634, total_loss: 2.2493884563446045
training step: 14635, total_loss: 5.589362621307373
training step: 14636, total_loss: 4.199431896209717
training step: 14637, total_loss: 1.6135661602020264
training step: 14638, total_loss: 4.346565246582031
training step: 14639, total_loss: 5.045571327209473
training step: 14640, total_loss: 4.375749111175537
training step: 14641, total_loss: 4.030307769775391
training step: 14642, total_loss: 5.061954975128174
training step: 14643, total_loss: 5.596285820007324
training step: 14644, total_loss: 6.423312187194824
training step: 14645, total_loss: 4.617188930511475
training step: 14646, total_loss: 3.972017288208008
training step: 14647, total_loss: 4.235075950622559
training step: 14648, total_loss: 4.7907938957214355
training step: 14649, total_loss: 4.524606227874756
training step: 14650, total_loss: 5.024419784545898
training step: 14651, total_loss: 3.5176329612731934
training step: 14652, total_loss: 4.1426801681518555
training step: 14653, total_loss: 5.9701948165893555
training step: 14654, total_loss: 2.827052116394043
training step: 14655, total_loss: 3.7495603561401367
training step: 14656, total_loss: 3.7407612800598145
training step: 14657, total_loss: 3.839223623275757
training step: 14658, total_loss: 4.071002006530762
training step: 14659, total_loss: 4.316834926605225
training step: 14660, total_loss: 4.482830047607422
training step: 14661, total_loss: 4.827855587005615
training step: 14662, total_loss: 1.4327077865600586
training step: 14663, total_loss: 3.969472646713257
training step: 14664, total_loss: 4.7927350997924805
training step: 14665, total_loss: 5.178250789642334
training step: 14666, total_loss: 4.3819379806518555
training step: 14667, total_loss: 4.211063385009766
training step: 14668, total_loss: 3.363520383834839
training step: 14669, total_loss: 5.557880401611328
training step: 14670, total_loss: 4.758393287658691
training step: 14671, total_loss: 3.397157669067383
training step: 14672, total_loss: 4.582918167114258
training step: 14673, total_loss: 3.8708393573760986
training step: 14674, total_loss: 5.167439937591553
training step: 14675, total_loss: 4.230297088623047
training step: 14676, total_loss: 4.8198747634887695
training step: 14677, total_loss: 5.450347900390625
training step: 14678, total_loss: 2.2954301834106445
training step: 14679, total_loss: 5.461029052734375
training step: 14680, total_loss: 4.57466983795166
training step: 14681, total_loss: 6.956358432769775
training step: 14682, total_loss: 4.4378204345703125
training step: 14683, total_loss: 4.31215238571167
training step: 14684, total_loss: 4.660841941833496
training step: 14685, total_loss: 4.32973575592041
training step: 14686, total_loss: 7.464852333068848
training step: 14687, total_loss: 3.9229073524475098
training step: 14688, total_loss: 4.676421165466309
training step: 14689, total_loss: 5.41439151763916
training step: 14690, total_loss: 3.547586679458618
training step: 14691, total_loss: 4.739223480224609
training step: 14692, total_loss: 1.0674978494644165
training step: 14693, total_loss: 3.396667003631592
training step: 14694, total_loss: 4.919978141784668
training step: 14695, total_loss: 4.522807598114014
training step: 14696, total_loss: 4.0548810958862305
training step: 14697, total_loss: 5.200292110443115
training step: 14698, total_loss: 6.661866188049316
training step: 14699, total_loss: 3.7099080085754395
training step: 14700, total_loss: 4.72080135345459
training step: 14701, total_loss: 4.340350151062012
training step: 14702, total_loss: 6.6670684814453125
training step: 14703, total_loss: 5.264225959777832
training step: 14704, total_loss: 3.6255383491516113
training step: 14705, total_loss: 5.787252426147461
training step: 14706, total_loss: 5.364123344421387
training step: 14707, total_loss: 5.921799659729004
training step: 14708, total_loss: 5.000885486602783
training step: 14709, total_loss: 5.247978210449219
training step: 14710, total_loss: 6.278747081756592
training step: 14711, total_loss: 5.263982772827148
training step: 14712, total_loss: 3.770172119140625
training step: 14713, total_loss: 4.575474739074707
training step: 14714, total_loss: 4.49225378036499
training step: 14715, total_loss: 5.17057466506958
training step: 14716, total_loss: 4.198239803314209
training step: 14717, total_loss: 5.910724639892578
training step: 14718, total_loss: 4.216402530670166
training step: 14719, total_loss: 4.177801132202148
training step: 14720, total_loss: 4.549611568450928
training step: 14721, total_loss: 5.374841690063477
training step: 14722, total_loss: 4.841571807861328
training step: 14723, total_loss: 2.1950955390930176
training step: 14724, total_loss: 1.2056918144226074
training step: 14725, total_loss: 3.8991856575012207
training step: 14726, total_loss: 4.492980003356934
training step: 14727, total_loss: 5.153403282165527
training step: 14728, total_loss: 4.421141147613525
training step: 14729, total_loss: 4.269261837005615
training step: 14730, total_loss: 4.1626386642456055
training step: 14731, total_loss: 5.429668426513672
training step: 14732, total_loss: 2.7085914611816406
training step: 14733, total_loss: 5.338068008422852
training step: 14734, total_loss: 4.5911455154418945
training step: 14735, total_loss: 0.809272050857544
training step: 14736, total_loss: 4.370905876159668
training step: 14737, total_loss: 5.444762706756592
training step: 14738, total_loss: 3.8294575214385986
training step: 14739, total_loss: 4.706648826599121
training step: 14740, total_loss: 4.835319519042969
training step: 14741, total_loss: 3.265031337738037
training step: 14742, total_loss: 6.124464988708496
training step: 14743, total_loss: 5.309306621551514
training step: 14744, total_loss: 5.378414154052734
training step: 14745, total_loss: 5.208276748657227
training step: 14746, total_loss: 4.5182719230651855
training step: 14747, total_loss: 5.886610507965088
training step: 14748, total_loss: 4.186463832855225
training step: 14749, total_loss: 4.409908294677734
training step: 14750, total_loss: 4.562117576599121
training step: 14751, total_loss: 3.7341489791870117
training step: 14752, total_loss: 4.969316005706787
training step: 14753, total_loss: 5.667178630828857
training step: 14754, total_loss: 4.635219573974609
training step: 14755, total_loss: 5.042729377746582
training step: 14756, total_loss: 4.32353401184082
training step: 14757, total_loss: 4.378763675689697
training step: 14758, total_loss: 5.117026329040527
training step: 14759, total_loss: 4.04732084274292
training step: 14760, total_loss: 4.97259521484375
training step: 14761, total_loss: 3.351250171661377
training step: 14762, total_loss: 3.556386947631836
training step: 14763, total_loss: 4.17324161529541
training step: 14764, total_loss: 2.602247714996338
training step: 14765, total_loss: 6.204680442810059
training step: 14766, total_loss: 4.717166423797607
training step: 14767, total_loss: 4.176272392272949
training step: 14768, total_loss: 4.333518028259277
training step: 14769, total_loss: 4.24735164642334
training step: 14770, total_loss: 3.933993101119995
training step: 14771, total_loss: 4.985857963562012
training step: 14772, total_loss: 5.891565322875977
training step: 14773, total_loss: 3.422903060913086
training step: 14774, total_loss: 4.816468238830566
training step: 14775, total_loss: 3.982602834701538
training step: 14776, total_loss: 5.380805969238281
training step: 14777, total_loss: 5.540597915649414
training step: 14778, total_loss: 4.672207355499268
training step: 14779, total_loss: 3.1322178840637207
training step: 14780, total_loss: 3.8753976821899414
training step: 14781, total_loss: 5.822979927062988
training step: 14782, total_loss: 4.229478359222412
training step: 14783, total_loss: 3.357168197631836
training step: 14784, total_loss: 3.9889445304870605
training step: 14785, total_loss: 3.2379164695739746
training step: 14786, total_loss: 4.726943492889404
training step: 14787, total_loss: 4.607626438140869
training step: 14788, total_loss: 6.477108955383301
training step: 14789, total_loss: 4.722060203552246
training step: 14790, total_loss: 6.404102802276611
training step: 14791, total_loss: 6.947260856628418
training step: 14792, total_loss: 4.119575023651123
training step: 14793, total_loss: 5.987943649291992
training step: 14794, total_loss: 4.510777473449707
training step: 14795, total_loss: 3.8205525875091553
training step: 14796, total_loss: 3.2356348037719727
training step: 14797, total_loss: 4.972192764282227
training step: 14798, total_loss: 4.144304275512695
training step: 14799, total_loss: 4.609514236450195
training step: 14800, total_loss: 5.473453044891357
training step: 14801, total_loss: 4.540349006652832
training step: 14802, total_loss: 3.8617606163024902
training step: 14803, total_loss: 3.9562275409698486
training step: 14804, total_loss: 5.116897106170654
training step: 14805, total_loss: 2.0610764026641846
training step: 14806, total_loss: 5.003598213195801
training step: 14807, total_loss: 5.288936614990234
training step: 14808, total_loss: 4.159084320068359
training step: 14809, total_loss: 4.667400360107422
training step: 14810, total_loss: 4.095426082611084
training step: 14811, total_loss: 4.296324253082275
training step: 14812, total_loss: 5.942929744720459
training step: 14813, total_loss: 4.577267169952393
training step: 14814, total_loss: 5.142845153808594
training step: 14815, total_loss: 4.293826103210449
training step: 14816, total_loss: 1.3120076656341553
training step: 14817, total_loss: 3.5197927951812744
training step: 14818, total_loss: 2.98561429977417
training step: 14819, total_loss: 3.481126070022583
training step: 14820, total_loss: 4.212988376617432
training step: 14821, total_loss: 4.1463189125061035
training step: 14822, total_loss: 3.2538375854492188
training step: 14823, total_loss: 3.821280002593994
training step: 14824, total_loss: 3.7647924423217773
training step: 14825, total_loss: 7.082300662994385
training step: 14826, total_loss: 3.726700782775879
training step: 14827, total_loss: 3.7549052238464355
training step: 14828, total_loss: 4.7201080322265625
training step: 14829, total_loss: 2.821964740753174
training step: 14830, total_loss: 4.576318740844727
training step: 14831, total_loss: 5.360255241394043
training step: 14832, total_loss: 5.514410018920898
training step: 14833, total_loss: 3.589905023574829
training step: 14834, total_loss: 4.250270843505859
training step: 14835, total_loss: 3.985673427581787
training step: 14836, total_loss: 4.424184799194336
training step: 14837, total_loss: 5.1812357902526855
training step: 14838, total_loss: 5.432826042175293
training step: 14839, total_loss: 4.03248405456543
training step: 14840, total_loss: 3.938966751098633
training step: 14841, total_loss: 4.451215744018555
training step: 14842, total_loss: 5.318380832672119
training step: 14843, total_loss: 3.790266990661621
training step: 14844, total_loss: 4.581448554992676
training step: 14845, total_loss: 4.568679332733154
training step: 14846, total_loss: 4.2054595947265625
training step: 14847, total_loss: 3.8820996284484863
training step: 14848, total_loss: 3.714834213256836
training step: 14849, total_loss: 4.393113613128662
training step: 14850, total_loss: 3.3797507286071777
training step: 14851, total_loss: 4.605035781860352
training step: 14852, total_loss: 3.944007396697998
training step: 14853, total_loss: 4.843091011047363
training step: 14854, total_loss: 5.5839409828186035
training step: 14855, total_loss: 5.984501838684082
training step: 14856, total_loss: 5.252026081085205
training step: 14857, total_loss: 6.498929023742676
training step: 14858, total_loss: 4.211628437042236
training step: 14859, total_loss: 4.8485798835754395
training step: 14860, total_loss: 3.2978103160858154
training step: 14861, total_loss: 4.103010177612305
training step: 14862, total_loss: 5.5699005126953125
training step: 14863, total_loss: 0.8846770524978638
training step: 14864, total_loss: 5.37869930267334
training step: 14865, total_loss: 5.454209327697754
training step: 14866, total_loss: 3.8473918437957764
training step: 14867, total_loss: 5.364709854125977
training step: 14868, total_loss: 4.900079727172852
training step: 14869, total_loss: 4.195552825927734
training step: 14870, total_loss: 5.226271152496338
training step: 14871, total_loss: 3.291517734527588
training step: 14872, total_loss: 4.004739284515381
training step: 14873, total_loss: 4.104693412780762
training step: 14874, total_loss: 5.253852367401123
training step: 14875, total_loss: 4.372426986694336
training step: 14876, total_loss: 4.369690895080566
training step: 14877, total_loss: 4.736559867858887
training step: 14878, total_loss: 5.109284400939941
training step: 14879, total_loss: 3.953594207763672
training step: 14880, total_loss: 4.4869704246521
training step: 14881, total_loss: 5.198374271392822
training step: 14882, total_loss: 4.769475936889648
training step: 14883, total_loss: 3.5189831256866455
training step: 14884, total_loss: 6.032865524291992
training step: 14885, total_loss: 4.586576461791992
training step: 14886, total_loss: 4.55711555480957
training step: 14887, total_loss: 5.305549621582031
training step: 14888, total_loss: 5.124551296234131
training step: 14889, total_loss: 4.606657981872559
training step: 14890, total_loss: 1.592897891998291
training step: 14891, total_loss: 3.120826244354248
training step: 14892, total_loss: 4.209085464477539
training step: 14893, total_loss: 5.511763572692871
training step: 14894, total_loss: 4.409102439880371
training step: 14895, total_loss: 4.659961700439453
training step: 14896, total_loss: 7.057504653930664
training step: 14897, total_loss: 5.354581356048584
training step: 14898, total_loss: 5.266960620880127
training step: 14899, total_loss: 4.772500038146973
training step: 14900, total_loss: 4.871895790100098
training step: 14901, total_loss: 4.803990364074707
training step: 14902, total_loss: 0.9236277937889099
training step: 14903, total_loss: 4.514397621154785
training step: 14904, total_loss: 4.685282230377197
training step: 14905, total_loss: 5.116331100463867
training step: 14906, total_loss: 3.813093423843384
training step: 14907, total_loss: 4.751489639282227
training step: 14908, total_loss: 4.588793754577637
training step: 14909, total_loss: 3.892656087875366
training step: 14910, total_loss: 5.63631534576416
training step: 14911, total_loss: 3.7554893493652344
training step: 14912, total_loss: 5.56934928894043
training step: 14913, total_loss: 5.406097412109375
training step: 14914, total_loss: 4.7107133865356445
training step: 14915, total_loss: 6.600926399230957
training step: 14916, total_loss: 4.65930700302124
training step: 14917, total_loss: 4.348854064941406
training step: 14918, total_loss: 4.325168132781982
training step: 14919, total_loss: 5.612925052642822
training step: 14920, total_loss: 3.259490489959717
training step: 14921, total_loss: 5.196229934692383
training step: 14922, total_loss: 4.858960151672363
training step: 14923, total_loss: 2.6932451725006104
training step: 14924, total_loss: 3.9053306579589844
training step: 14925, total_loss: 4.2539963722229
training step: 14926, total_loss: 4.206512928009033
training step: 14927, total_loss: 3.281363010406494
training step: 14928, total_loss: 5.048436164855957
training step: 14929, total_loss: 6.290029525756836
training step: 14930, total_loss: 4.376959800720215
training step: 14931, total_loss: 5.1536173820495605
training step: 14932, total_loss: 5.362917900085449
training step: 14933, total_loss: 4.071280479431152
training step: 14934, total_loss: 2.944532632827759
training step: 14935, total_loss: 4.388821601867676
training step: 14936, total_loss: 4.037599086761475
training step: 14937, total_loss: 4.433048248291016
training step: 14938, total_loss: 4.494021415710449
training step: 14939, total_loss: 3.393501043319702
training step: 14940, total_loss: 3.850987434387207
training step: 14941, total_loss: 5.363148212432861
training step: 14942, total_loss: 4.882936477661133
training step: 14943, total_loss: 4.231507301330566
training step: 14944, total_loss: 5.246827125549316
training step: 14945, total_loss: 5.263430595397949
training step: 14946, total_loss: 3.8111352920532227
training step: 14947, total_loss: 3.166591167449951
training step: 14948, total_loss: 4.607354164123535
training step: 14949, total_loss: 5.556217670440674
training step: 14950, total_loss: 4.22176456451416
training step: 14951, total_loss: 4.150175094604492
training step: 14952, total_loss: 5.616972923278809
training step: 14953, total_loss: 3.661531925201416
training step: 14954, total_loss: 3.7506356239318848
training step: 14955, total_loss: 4.656838417053223
training step: 14956, total_loss: 3.4556827545166016
training step: 14957, total_loss: 4.542075157165527
training step: 14958, total_loss: 4.4566192626953125
training step: 14959, total_loss: 0.7068312764167786
training step: 14960, total_loss: 5.332685947418213
training step: 14961, total_loss: 3.262239456176758
training step: 14962, total_loss: 6.191136837005615
training step: 14963, total_loss: 4.893845558166504
training step: 14964, total_loss: 5.336723804473877
training step: 14965, total_loss: 3.686094284057617
training step: 14966, total_loss: 4.601806640625
training step: 14967, total_loss: 5.230691909790039
training step: 14968, total_loss: 4.068213939666748
training step: 14969, total_loss: 3.1279196739196777
training step: 14970, total_loss: 3.8722646236419678
training step: 14971, total_loss: 0.9760844707489014
training step: 14972, total_loss: 5.5434370040893555
training step: 14973, total_loss: 4.753113746643066
training step: 14974, total_loss: 4.378686904907227
training step: 14975, total_loss: 5.608661651611328
training step: 14976, total_loss: 6.383889198303223
training step: 14977, total_loss: 5.547441482543945
training step: 14978, total_loss: 5.025270462036133
training step: 14979, total_loss: 5.362582683563232
training step: 14980, total_loss: 5.2708282470703125
training step: 14981, total_loss: 3.2465884685516357
training step: 14982, total_loss: 4.388476371765137
training step: 14983, total_loss: 5.579024314880371
training step: 14984, total_loss: 5.546627044677734
training step: 14985, total_loss: 3.5901296138763428
training step: 14986, total_loss: 5.078134059906006
training step: 14987, total_loss: 5.709458351135254
training step: 14988, total_loss: 5.1068525314331055
training step: 14989, total_loss: 3.7281675338745117
training step: 14990, total_loss: 4.7791852951049805
training step: 14991, total_loss: 4.524527549743652
training step: 14992, total_loss: 4.166755199432373
training step: 14993, total_loss: 4.96514892578125
training step: 14994, total_loss: 5.079083442687988
training step: 14995, total_loss: 4.101527214050293
training step: 14996, total_loss: 3.633744478225708
training step: 14997, total_loss: 5.22784948348999
training step: 14998, total_loss: 4.440774917602539
training step: 14999, total_loss: 4.376196384429932
training step: 15000, total_loss: 4.67742919921875
training step: 15001, total_loss: 4.74468994140625
training step: 15002, total_loss: 4.383298873901367
training step: 15003, total_loss: 4.39200496673584
training step: 15004, total_loss: 5.425225257873535
training step: 15005, total_loss: 2.8248825073242188
training step: 15006, total_loss: 4.56673526763916
training step: 15007, total_loss: 4.652216911315918
training step: 15008, total_loss: 4.7761359214782715
training step: 15009, total_loss: 4.695514678955078
training step: 15010, total_loss: 4.689944267272949
training step: 15011, total_loss: 3.26169490814209
training step: 15012, total_loss: 4.6927690505981445
training step: 15013, total_loss: 5.134357929229736
training step: 15014, total_loss: 4.810528755187988
training step: 15015, total_loss: 4.687496185302734
training step: 15016, total_loss: 4.928483009338379
training step: 15017, total_loss: 5.918213367462158
training step: 15018, total_loss: 4.743836402893066
training step: 15019, total_loss: 7.129000663757324
training step: 15020, total_loss: 3.971336841583252
training step: 15021, total_loss: 4.682995796203613
training step: 15022, total_loss: 3.590547561645508
training step: 15023, total_loss: 5.564788341522217
training step: 15024, total_loss: 4.820423126220703
training step: 15025, total_loss: 3.7156829833984375
training step: 15026, total_loss: 4.629223823547363
training step: 15027, total_loss: 5.437028884887695
training step: 15028, total_loss: 5.513088226318359
training step: 15029, total_loss: 4.745948791503906
training step: 15030, total_loss: 3.9776761531829834
training step: 15031, total_loss: 3.916019916534424
training step: 15032, total_loss: 5.523625373840332
training step: 15033, total_loss: 4.583693504333496
training step: 15034, total_loss: 4.927929401397705
training step: 15035, total_loss: 5.019205093383789
training step: 15036, total_loss: 4.457596302032471
training step: 15037, total_loss: 4.5395827293396
training step: 15038, total_loss: 6.1087751388549805
training step: 15039, total_loss: 4.421306610107422
training step: 15040, total_loss: 5.344546794891357
training step: 15041, total_loss: 4.434417247772217
training step: 15042, total_loss: 3.8712198734283447
training step: 15043, total_loss: 4.2229743003845215
training step: 15044, total_loss: 3.5031654834747314
training step: 15045, total_loss: 4.044291019439697
training step: 15046, total_loss: 4.74582576751709
training step: 15047, total_loss: 5.369678974151611
training step: 15048, total_loss: 3.614877462387085
training step: 15049, total_loss: 4.179035186767578
training step: 15050, total_loss: 5.502867698669434
training step: 15051, total_loss: 3.4546432495117188
training step: 15052, total_loss: 4.111601829528809
training step: 15053, total_loss: 5.288678169250488
training step: 15054, total_loss: 5.752892971038818
training step: 15055, total_loss: 6.837968826293945
training step: 15056, total_loss: 3.664494276046753
training step: 15057, total_loss: 5.037668704986572
training step: 15058, total_loss: 5.012229919433594
training step: 15059, total_loss: 3.8445281982421875
training step: 15060, total_loss: 4.581279754638672
training step: 15061, total_loss: 3.2601375579833984
training step: 15062, total_loss: 5.4041972160339355
training step: 15063, total_loss: 4.578549385070801
training step: 15064, total_loss: 5.416140556335449
training step: 15065, total_loss: 6.226707458496094
training step: 15066, total_loss: 4.608641624450684
training step: 15067, total_loss: 5.439916610717773
training step: 15068, total_loss: 6.334527015686035
training step: 15069, total_loss: 5.034090042114258
training step: 15070, total_loss: 3.760324001312256
training step: 15071, total_loss: 4.5006537437438965
training step: 15072, total_loss: 4.66780948638916
training step: 15073, total_loss: 5.170888423919678
training step: 15074, total_loss: 5.084468841552734
training step: 15075, total_loss: 4.553091049194336
training step: 15076, total_loss: 4.204592704772949
training step: 15077, total_loss: 4.5931901931762695
training step: 15078, total_loss: 5.512938499450684
training step: 15079, total_loss: 4.435905933380127
training step: 15080, total_loss: 4.077022552490234
training step: 15081, total_loss: 4.933298110961914
training step: 15082, total_loss: 5.347875595092773
training step: 15083, total_loss: 4.073305606842041
training step: 15084, total_loss: 4.909636974334717
training step: 15085, total_loss: 3.7201483249664307
training step: 15086, total_loss: 2.749875783920288
training step: 15087, total_loss: 4.088699817657471
training step: 15088, total_loss: 4.837992191314697
training step: 15089, total_loss: 5.637163162231445
training step: 15090, total_loss: 4.677973747253418
training step: 15091, total_loss: 3.577423095703125
training step: 15092, total_loss: 3.8537395000457764
training step: 15093, total_loss: 4.143922805786133
training step: 15094, total_loss: 5.001033782958984
training step: 15095, total_loss: 4.205802917480469
training step: 15096, total_loss: 4.065115451812744
training step: 15097, total_loss: 5.273736000061035
training step: 15098, total_loss: 4.684039115905762
training step: 15099, total_loss: 5.403606414794922
training step: 15100, total_loss: 5.238393306732178
training step: 15101, total_loss: 3.766120433807373
training step: 15102, total_loss: 2.9438843727111816
training step: 15103, total_loss: 4.245516777038574
training step: 15104, total_loss: 4.027400970458984
training step: 15105, total_loss: 3.9563660621643066
training step: 15106, total_loss: 3.9941654205322266
training step: 15107, total_loss: 4.679061412811279
training step: 15108, total_loss: 4.24682092666626
training step: 15109, total_loss: 4.648006916046143
training step: 15110, total_loss: 4.3020148277282715
training step: 15111, total_loss: 4.942014694213867
training step: 15112, total_loss: 4.528359413146973
training step: 15113, total_loss: 3.9523367881774902
training step: 15114, total_loss: 5.351791858673096
training step: 15115, total_loss: 2.298003673553467
training step: 15116, total_loss: 5.2307233810424805
training step: 15117, total_loss: 3.7106425762176514
training step: 15118, total_loss: 4.8940229415893555
training step: 15119, total_loss: 5.174927234649658
training step: 15120, total_loss: 4.510007858276367
training step: 15121, total_loss: 3.1767055988311768
training step: 15122, total_loss: 4.341032981872559
training step: 15123, total_loss: 5.100893974304199
training step: 15124, total_loss: 3.852421760559082
training step: 15125, total_loss: 4.363780975341797
training step: 15126, total_loss: 4.908313274383545
training step: 15127, total_loss: 4.051013946533203
training step: 15128, total_loss: 4.709242820739746
training step: 15129, total_loss: 2.61122989654541
training step: 15130, total_loss: 5.119494438171387
training step: 15131, total_loss: 3.6052730083465576
training step: 15132, total_loss: 4.754336833953857
training step: 15133, total_loss: 4.921925067901611
training step: 15134, total_loss: 6.294212341308594
training step: 15135, total_loss: 3.980867862701416
training step: 15136, total_loss: 3.8933138847351074
training step: 15137, total_loss: 5.91478157043457
training step: 15138, total_loss: 5.552712917327881
training step: 15139, total_loss: 4.666189193725586
training step: 15140, total_loss: 3.773057222366333
training step: 15141, total_loss: 1.4320590496063232
training step: 15142, total_loss: 4.351197719573975
training step: 15143, total_loss: 3.880990982055664
training step: 15144, total_loss: 4.6871137619018555
training step: 15145, total_loss: 2.550807476043701
training step: 15146, total_loss: 5.628204345703125
training step: 15147, total_loss: 1.3752694129943848
training step: 15148, total_loss: 2.8230533599853516
training step: 15149, total_loss: 5.273918628692627
training step: 15150, total_loss: 5.309060573577881
training step: 15151, total_loss: 3.872737169265747
training step: 15152, total_loss: 4.961428642272949
training step: 15153, total_loss: 5.0525970458984375
training step: 15154, total_loss: 4.765801906585693
training step: 15155, total_loss: 5.155811309814453
training step: 15156, total_loss: 4.919378280639648
training step: 15157, total_loss: 5.057794570922852
training step: 15158, total_loss: 5.927419662475586
training step: 15159, total_loss: 4.351449966430664
training step: 15160, total_loss: 2.856232166290283
training step: 15161, total_loss: 2.804333209991455
training step: 15162, total_loss: 5.487400531768799
training step: 15163, total_loss: 4.72736930847168
training step: 15164, total_loss: 3.216060161590576
training step: 15165, total_loss: 4.2697529792785645
training step: 15166, total_loss: 5.578472137451172
training step: 15167, total_loss: 6.188797950744629
training step: 15168, total_loss: 4.563690662384033
training step: 15169, total_loss: 4.452140808105469
training step: 15170, total_loss: 3.8449559211730957
training step: 15171, total_loss: 6.759131908416748
training step: 15172, total_loss: 3.2663025856018066
training step: 15173, total_loss: 5.170694351196289
training step: 15174, total_loss: 5.258380889892578
training step: 15175, total_loss: 5.3709211349487305
training step: 15176, total_loss: 4.195592880249023
training step: 15177, total_loss: 4.375784873962402
training step: 15178, total_loss: 4.268638610839844
training step: 15179, total_loss: 4.060823917388916
training step: 15180, total_loss: 2.999178409576416
training step: 15181, total_loss: 4.690680980682373
training step: 15182, total_loss: 4.439728736877441
training step: 15183, total_loss: 6.7196946144104
training step: 15184, total_loss: 4.458268642425537
training step: 15185, total_loss: 4.981717586517334
training step: 15186, total_loss: 5.166701793670654
training step: 15187, total_loss: 4.882763862609863
training step: 15188, total_loss: 5.037105083465576
training step: 15189, total_loss: 4.937665939331055
training step: 15190, total_loss: 5.498147010803223
training step: 15191, total_loss: 4.385026454925537
training step: 15192, total_loss: 4.364659309387207
training step: 15193, total_loss: 3.851935386657715
training step: 15194, total_loss: 3.440608501434326
training step: 15195, total_loss: 5.30604362487793
training step: 15196, total_loss: 5.051792144775391
training step: 15197, total_loss: 5.2969489097595215
training step: 15198, total_loss: 5.170357704162598
training step: 15199, total_loss: 4.387145042419434
training step: 15200, total_loss: 5.228957653045654
training step: 15201, total_loss: 4.532716274261475
training step: 15202, total_loss: 6.133639812469482
training step: 15203, total_loss: 4.631313323974609
training step: 15204, total_loss: 5.651537895202637
training step: 15205, total_loss: 3.4030022621154785
training step: 15206, total_loss: 5.409336090087891
training step: 15207, total_loss: 1.431447982788086
training step: 15208, total_loss: 4.401634693145752
training step: 15209, total_loss: 4.826470851898193
training step: 15210, total_loss: 5.067969799041748
training step: 15211, total_loss: 3.531975030899048
training step: 15212, total_loss: 4.641193866729736
training step: 15213, total_loss: 5.116735458374023
training step: 15214, total_loss: 1.4027554988861084
training step: 15215, total_loss: 5.107505798339844
training step: 15216, total_loss: 3.964841604232788
training step: 15217, total_loss: 5.492321968078613
training step: 15218, total_loss: 2.925116777420044
training step: 15219, total_loss: 4.403494834899902
training step: 15220, total_loss: 4.78948974609375
training step: 15221, total_loss: 4.323523044586182
training step: 15222, total_loss: 5.1019392013549805
training step: 15223, total_loss: 4.7474260330200195
training step: 15224, total_loss: 4.9143218994140625
training step: 15225, total_loss: 2.8440299034118652
training step: 15226, total_loss: 2.598306179046631
training step: 15227, total_loss: 4.491260528564453
training step: 15228, total_loss: 3.404046058654785
training step: 15229, total_loss: 5.280513286590576
training step: 15230, total_loss: 4.097123146057129
training step: 15231, total_loss: 4.387706756591797
training step: 15232, total_loss: 5.405606746673584
training step: 15233, total_loss: 4.824243545532227
training step: 15234, total_loss: 4.196972846984863
training step: 15235, total_loss: 5.347072124481201
training step: 15236, total_loss: 2.9746837615966797
training step: 15237, total_loss: 4.397459983825684
training step: 15238, total_loss: 5.009917736053467
training step: 15239, total_loss: 5.422735691070557
training step: 15240, total_loss: 5.8846845626831055
training step: 15241, total_loss: 5.680686950683594
training step: 15242, total_loss: 4.723466396331787
training step: 15243, total_loss: 5.213469982147217
training step: 15244, total_loss: 4.344740390777588
training step: 15245, total_loss: 4.054574489593506
training step: 15246, total_loss: 4.429769515991211
training step: 15247, total_loss: 4.225192070007324
training step: 15248, total_loss: 4.905151844024658
training step: 15249, total_loss: 3.6480908393859863
training step: 15250, total_loss: 4.5493669509887695
training step: 15251, total_loss: 4.964360237121582
training step: 15252, total_loss: 5.234576225280762
training step: 15253, total_loss: 7.3229475021362305
training step: 15254, total_loss: 5.0044379234313965
training step: 15255, total_loss: 1.5205918550491333
training step: 15256, total_loss: 7.282297134399414
training step: 15257, total_loss: 6.098067283630371
training step: 15258, total_loss: 5.534609794616699
training step: 15259, total_loss: 4.671224117279053
training step: 15260, total_loss: 2.3532094955444336
training step: 15261, total_loss: 3.891779899597168
training step: 15262, total_loss: 4.487725257873535
training step: 15263, total_loss: 5.019879341125488
training step: 15264, total_loss: 4.1331095695495605
training step: 15265, total_loss: 4.290909767150879
training step: 15266, total_loss: 4.530037879943848
training step: 15267, total_loss: 4.578815937042236
training step: 15268, total_loss: 6.728616237640381
training step: 15269, total_loss: 5.415676116943359
training step: 15270, total_loss: 3.603757381439209
training step: 15271, total_loss: 4.539700508117676
training step: 15272, total_loss: 5.481769561767578
training step: 15273, total_loss: 2.5186986923217773
training step: 15274, total_loss: 3.8234081268310547
training step: 15275, total_loss: 5.661419868469238
training step: 15276, total_loss: 5.548208713531494
training step: 15277, total_loss: 5.119843482971191
training step: 15278, total_loss: 3.080219268798828
training step: 15279, total_loss: 5.165343284606934
training step: 15280, total_loss: 3.8347504138946533
training step: 15281, total_loss: 4.486652374267578
training step: 15282, total_loss: 4.180056095123291
training step: 15283, total_loss: 5.902935981750488
training step: 15284, total_loss: 5.457098007202148
training step: 15285, total_loss: 6.84182071685791
training step: 15286, total_loss: 5.008970260620117
training step: 15287, total_loss: 4.941987991333008
training step: 15288, total_loss: 6.365505695343018
training step: 15289, total_loss: 4.718266487121582
training step: 15290, total_loss: 3.337430953979492
training step: 15291, total_loss: 4.933398246765137
training step: 15292, total_loss: 4.4712419509887695
training step: 15293, total_loss: 4.936392784118652
training step: 15294, total_loss: 5.082596778869629
training step: 15295, total_loss: 2.7697155475616455
training step: 15296, total_loss: 6.549734115600586
training step: 15297, total_loss: 4.628801345825195
training step: 15298, total_loss: 4.485511302947998
training step: 15299, total_loss: 4.7348785400390625
training step: 15300, total_loss: 5.290350914001465
training step: 15301, total_loss: 5.601585388183594
training step: 15302, total_loss: 4.357874870300293
training step: 15303, total_loss: 5.652064800262451
training step: 15304, total_loss: 4.35315465927124
training step: 15305, total_loss: 3.0815980434417725
training step: 15306, total_loss: 3.7335989475250244
training step: 15307, total_loss: 5.1516523361206055
training step: 15308, total_loss: 3.3595871925354004
training step: 15309, total_loss: 2.690075397491455
training step: 15310, total_loss: 5.634921550750732
training step: 15311, total_loss: 4.3885498046875
training step: 15312, total_loss: 3.063370704650879
training step: 15313, total_loss: 5.348127841949463
training step: 15314, total_loss: 4.651650428771973
training step: 15315, total_loss: 4.11153507232666
training step: 15316, total_loss: 5.111422538757324
training step: 15317, total_loss: 5.737129211425781
training step: 15318, total_loss: 6.098293304443359
training step: 15319, total_loss: 5.115907669067383
training step: 15320, total_loss: 2.942190170288086
training step: 15321, total_loss: 4.1194376945495605
training step: 15322, total_loss: 4.406249046325684
training step: 15323, total_loss: 4.938202381134033
training step: 15324, total_loss: 4.443698883056641
training step: 15325, total_loss: 3.305906295776367
training step: 15326, total_loss: 4.075747489929199
training step: 15327, total_loss: 2.8550705909729004
training step: 15328, total_loss: 5.3296074867248535
training step: 15329, total_loss: 5.160521507263184
training step: 15330, total_loss: 4.514920234680176
training step: 15331, total_loss: 2.1914572715759277
training step: 15332, total_loss: 3.257075786590576
training step: 15333, total_loss: 2.655280828475952
training step: 15334, total_loss: 6.652508735656738
training step: 15335, total_loss: 3.473970890045166
training step: 15336, total_loss: 4.351248264312744
training step: 15337, total_loss: 4.928106784820557
training step: 15338, total_loss: 3.3009114265441895
training step: 15339, total_loss: 4.0992021560668945
training step: 15340, total_loss: 2.9095382690429688
training step: 15341, total_loss: 5.037535190582275
training step: 15342, total_loss: 3.872225284576416
training step: 15343, total_loss: 4.757195949554443
training step: 15344, total_loss: 4.464300632476807
training step: 15345, total_loss: 5.034354209899902
training step: 15346, total_loss: 5.522763252258301
training step: 15347, total_loss: 5.140597820281982
training step: 15348, total_loss: 6.022286415100098
training step: 15349, total_loss: 3.704636573791504
training step: 15350, total_loss: 4.733447074890137
training step: 15351, total_loss: 5.466937065124512
training step: 15352, total_loss: 4.163793563842773
training step: 15353, total_loss: 5.634493350982666
training step: 15354, total_loss: 3.785616397857666
training step: 15355, total_loss: 5.6946611404418945
training step: 15356, total_loss: 4.6805219650268555
training step: 15357, total_loss: 4.617023468017578
training step: 15358, total_loss: 4.490462303161621
training step: 15359, total_loss: 4.99459981918335
training step: 15360, total_loss: 1.2218756675720215
training step: 15361, total_loss: 4.539315700531006
training step: 15362, total_loss: 5.968250751495361
training step: 15363, total_loss: 5.214351654052734
training step: 15364, total_loss: 3.971357822418213
training step: 15365, total_loss: 2.7842087745666504
training step: 15366, total_loss: 3.0346927642822266
training step: 15367, total_loss: 3.8341569900512695
training step: 15368, total_loss: 4.590111255645752
training step: 15369, total_loss: 5.403290271759033
training step: 15370, total_loss: 6.093915939331055
training step: 15371, total_loss: 6.162622928619385
training step: 15372, total_loss: 2.8667826652526855
training step: 15373, total_loss: 5.720986366271973
training step: 15374, total_loss: 5.858048439025879
training step: 15375, total_loss: 0.7323330640792847
training step: 15376, total_loss: 4.995131492614746
training step: 15377, total_loss: 2.9135985374450684
training step: 15378, total_loss: 5.146321773529053
training step: 15379, total_loss: 5.271878242492676
training step: 15380, total_loss: 4.752474784851074
training step: 15381, total_loss: 4.353891372680664
training step: 15382, total_loss: 3.7956674098968506
training step: 15383, total_loss: 5.486493110656738
training step: 15384, total_loss: 4.526523590087891
training step: 15385, total_loss: 5.496230125427246
training step: 15386, total_loss: 5.30994987487793
training step: 15387, total_loss: 3.1446094512939453
training step: 15388, total_loss: 4.741888523101807
training step: 15389, total_loss: 5.062542915344238
training step: 15390, total_loss: 2.2573938369750977
training step: 15391, total_loss: 5.678267955780029
training step: 15392, total_loss: 5.027702331542969
training step: 15393, total_loss: 4.335050582885742
training step: 15394, total_loss: 3.1701431274414062
training step: 15395, total_loss: 4.31907844543457
training step: 15396, total_loss: 4.608132362365723
training step: 15397, total_loss: 5.074894905090332
training step: 15398, total_loss: 3.646705150604248
training step: 15399, total_loss: 4.0655622482299805
training step: 15400, total_loss: 5.345685005187988
training step: 15401, total_loss: 4.77619743347168
training step: 15402, total_loss: 3.494483470916748
training step: 15403, total_loss: 6.323600769042969
training step: 15404, total_loss: 4.267218589782715
training step: 15405, total_loss: 5.030961513519287
training step: 15406, total_loss: 4.71417236328125
training step: 15407, total_loss: 4.6865434646606445
training step: 15408, total_loss: 3.136063575744629
training step: 15409, total_loss: 4.232489585876465
training step: 15410, total_loss: 5.041547775268555
training step: 15411, total_loss: 5.225184440612793
training step: 15412, total_loss: 5.102388858795166
training step: 15413, total_loss: 4.399472713470459
training step: 15414, total_loss: 4.24078893661499
training step: 15415, total_loss: 5.881858825683594
training step: 15416, total_loss: 2.7141668796539307
training step: 15417, total_loss: 6.25202751159668
training step: 15418, total_loss: 4.182772636413574
training step: 15419, total_loss: 5.117397308349609
training step: 15420, total_loss: 5.346203327178955
training step: 15421, total_loss: 3.5202198028564453
training step: 15422, total_loss: 4.098791599273682
training step: 15423, total_loss: 4.935192584991455
training step: 15424, total_loss: 4.586575031280518
training step: 15425, total_loss: 3.63543701171875
training step: 15426, total_loss: 5.44548225402832
training step: 15427, total_loss: 4.270739555358887
training step: 15428, total_loss: 4.5858917236328125
training step: 15429, total_loss: 3.736130714416504
training step: 15430, total_loss: 4.477592468261719
training step: 15431, total_loss: 5.955674171447754
training step: 15432, total_loss: 3.2790708541870117
training step: 15433, total_loss: 4.291817665100098
training step: 15434, total_loss: 3.7865543365478516
training step: 15435, total_loss: 4.184570789337158
training step: 15436, total_loss: 5.233375549316406
training step: 15437, total_loss: 3.837470531463623
training step: 15438, total_loss: 3.39632511138916
training step: 15439, total_loss: 4.405970096588135
training step: 15440, total_loss: 1.4664990901947021
training step: 15441, total_loss: 4.282196998596191
training step: 15442, total_loss: 4.486682415008545
training step: 15443, total_loss: 3.212477684020996
training step: 15444, total_loss: 4.335956573486328
training step: 15445, total_loss: 4.553773880004883
training step: 15446, total_loss: 6.383975028991699
training step: 15447, total_loss: 5.605184555053711
training step: 15448, total_loss: 2.210142135620117
training step: 15449, total_loss: 4.403269290924072
training step: 15450, total_loss: 5.793004989624023
training step: 15451, total_loss: 4.887840270996094
training step: 15452, total_loss: 4.700511932373047
training step: 15453, total_loss: 4.753907680511475
training step: 15454, total_loss: 4.1694440841674805
training step: 15455, total_loss: 3.809126377105713
training step: 15456, total_loss: 4.889672756195068
training step: 15457, total_loss: 5.244026184082031
training step: 15458, total_loss: 4.40452241897583
training step: 15459, total_loss: 5.598330020904541
training step: 15460, total_loss: 7.023319244384766
training step: 15461, total_loss: 3.3673548698425293
training step: 15462, total_loss: 4.583737373352051
training step: 15463, total_loss: 5.454766273498535
training step: 15464, total_loss: 4.825304985046387
training step: 15465, total_loss: 3.763791561126709
training step: 15466, total_loss: 3.5377330780029297
training step: 15467, total_loss: 4.605068683624268
training step: 15468, total_loss: 4.932596206665039
training step: 15469, total_loss: 3.151014804840088
training step: 15470, total_loss: 4.994112014770508
training step: 15471, total_loss: 6.9679388999938965
training step: 15472, total_loss: 4.934211730957031
training step: 15473, total_loss: 5.197084426879883
training step: 15474, total_loss: 5.098653793334961
training step: 15475, total_loss: 4.682709693908691
training step: 15476, total_loss: 4.358717441558838
training step: 15477, total_loss: 4.368976593017578
training step: 15478, total_loss: 1.6263914108276367
training step: 15479, total_loss: 4.349583625793457
training step: 15480, total_loss: 4.367887496948242
training step: 15481, total_loss: 4.024605751037598
training step: 15482, total_loss: 4.4435133934021
training step: 15483, total_loss: 5.054774284362793
training step: 15484, total_loss: 4.666083812713623
training step: 15485, total_loss: 4.971336364746094
training step: 15486, total_loss: 4.516528129577637
training step: 15487, total_loss: 4.354792594909668
training step: 15488, total_loss: 6.469610691070557
training step: 15489, total_loss: 4.909475326538086
training step: 15490, total_loss: 5.116416931152344
training step: 15491, total_loss: 4.317599296569824
training step: 15492, total_loss: 3.5242600440979004
training step: 15493, total_loss: 5.295976638793945
training step: 15494, total_loss: 4.59151554107666
training step: 15495, total_loss: 4.512922763824463
training step: 15496, total_loss: 4.354691028594971
training step: 15497, total_loss: 3.7207000255584717
training step: 15498, total_loss: 3.6044962406158447
training step: 15499, total_loss: 4.199520111083984
training step: 15500, total_loss: 4.4950480461120605
training step: 15501, total_loss: 4.123128414154053
training step: 15502, total_loss: 5.849635124206543
training step: 15503, total_loss: 5.393092155456543
training step: 15504, total_loss: 5.016801357269287
training step: 15505, total_loss: 3.854165554046631
training step: 15506, total_loss: 5.569215297698975
training step: 15507, total_loss: 5.453457832336426
training step: 15508, total_loss: 4.508694648742676
training step: 15509, total_loss: 4.546682357788086
training step: 15510, total_loss: 5.3895769119262695
training step: 15511, total_loss: 3.0872511863708496
training step: 15512, total_loss: 4.957317352294922
training step: 15513, total_loss: 3.957521438598633
training step: 15514, total_loss: 6.908425807952881
training step: 15515, total_loss: 5.087564945220947
training step: 15516, total_loss: 3.90655255317688
training step: 15517, total_loss: 4.397308826446533
training step: 15518, total_loss: 4.599259853363037
training step: 15519, total_loss: 5.359448432922363
training step: 15520, total_loss: 4.704100608825684
training step: 15521, total_loss: 3.863399028778076
training step: 15522, total_loss: 3.533541679382324
training step: 15523, total_loss: 4.667733669281006
training step: 15524, total_loss: 4.165843963623047
training step: 15525, total_loss: 5.106314659118652
training step: 15526, total_loss: 5.450883865356445
training step: 15527, total_loss: 4.5606465339660645
training step: 15528, total_loss: 4.141304969787598
training step: 15529, total_loss: 4.984917640686035
training step: 15530, total_loss: 4.9932332038879395
training step: 15531, total_loss: 4.013949871063232
training step: 15532, total_loss: 5.112215042114258
training step: 15533, total_loss: 3.6734020709991455
training step: 15534, total_loss: 3.6065926551818848
training step: 15535, total_loss: 4.032185077667236
training step: 15536, total_loss: 5.346314907073975
training step: 15537, total_loss: 4.284304141998291
training step: 15538, total_loss: 4.675893306732178
training step: 15539, total_loss: 4.674485206604004
training step: 15540, total_loss: 4.8121185302734375
training step: 15541, total_loss: 3.8488082885742188
training step: 15542, total_loss: 4.317132472991943
training step: 15543, total_loss: 3.4953675270080566
training step: 15544, total_loss: 2.881178379058838
training step: 15545, total_loss: 4.471541404724121
training step: 15546, total_loss: 4.419530868530273
training step: 15547, total_loss: 5.092940330505371
training step: 15548, total_loss: 3.9009828567504883
training step: 15549, total_loss: 5.699382305145264
training step: 15550, total_loss: 1.2666683197021484
training step: 15551, total_loss: 5.487659454345703
training step: 15552, total_loss: 3.9124531745910645
training step: 15553, total_loss: 3.252434730529785
training step: 15554, total_loss: 5.515409469604492
training step: 15555, total_loss: 4.812704563140869
training step: 15556, total_loss: 2.3299431800842285
training step: 15557, total_loss: 4.4680562019348145
training step: 15558, total_loss: 4.098204612731934
training step: 15559, total_loss: 2.972679376602173
training step: 15560, total_loss: 4.355401039123535
training step: 15561, total_loss: 4.532463073730469
training step: 15562, total_loss: 4.5811872482299805
training step: 15563, total_loss: 5.318609714508057
training step: 15564, total_loss: 5.334296226501465
training step: 15565, total_loss: 4.000332832336426
training step: 15566, total_loss: 3.1671676635742188
training step: 15567, total_loss: 4.763652324676514
training step: 15568, total_loss: 3.5182442665100098
training step: 15569, total_loss: 3.372696876525879
training step: 15570, total_loss: 3.9174270629882812
training step: 15571, total_loss: 4.726035118103027
training step: 15572, total_loss: 4.8101067543029785
training step: 15573, total_loss: 3.8491339683532715
training step: 15574, total_loss: 4.7866997718811035
training step: 15575, total_loss: 5.675759315490723
training step: 15576, total_loss: 4.6169891357421875
training step: 15577, total_loss: 5.4092488288879395
training step: 15578, total_loss: 4.559358596801758
training step: 15579, total_loss: 4.328364849090576
training step: 15580, total_loss: 4.498363494873047
training step: 15581, total_loss: 5.329998016357422
training step: 15582, total_loss: 2.9278783798217773
training step: 15583, total_loss: 4.531558036804199
training step: 15584, total_loss: 4.715816974639893
training step: 15585, total_loss: 4.72540807723999
training step: 15586, total_loss: 4.136778354644775
training step: 15587, total_loss: 4.628838539123535
training step: 15588, total_loss: 5.1346330642700195
training step: 15589, total_loss: 3.8027796745300293
training step: 15590, total_loss: 7.0736236572265625
training step: 15591, total_loss: 4.462311267852783
training step: 15592, total_loss: 5.29626989364624
training step: 15593, total_loss: 5.270947456359863
training step: 15594, total_loss: 3.133089303970337
training step: 15595, total_loss: 6.369542121887207
training step: 15596, total_loss: 4.016462802886963
training step: 15597, total_loss: 4.731152057647705
training step: 15598, total_loss: 5.052464008331299
training step: 15599, total_loss: 4.727149486541748
training step: 15600, total_loss: 5.065156936645508
training step: 15601, total_loss: 4.078248977661133
training step: 15602, total_loss: 4.610860347747803
training step: 15603, total_loss: 1.4819976091384888
training step: 15604, total_loss: 4.589575290679932
training step: 15605, total_loss: 3.82474946975708
training step: 15606, total_loss: 3.8761308193206787
training step: 15607, total_loss: 1.1780781745910645
training step: 15608, total_loss: 5.328547477722168
training step: 15609, total_loss: 3.4100799560546875
training step: 15610, total_loss: 3.888005018234253
training step: 15611, total_loss: 4.966834545135498
training step: 15612, total_loss: 1.315661907196045
training step: 15613, total_loss: 0.943730890750885
training step: 15614, total_loss: 4.696711540222168
training step: 15615, total_loss: 2.8283867835998535
training step: 15616, total_loss: 5.36995792388916
training step: 15617, total_loss: 2.764791965484619
training step: 15618, total_loss: 5.088372707366943
training step: 15619, total_loss: 5.697652816772461
training step: 15620, total_loss: 4.488618850708008
training step: 15621, total_loss: 0.6831656694412231
training step: 15622, total_loss: 5.05606746673584
training step: 15623, total_loss: 4.719110488891602
training step: 15624, total_loss: 4.673299789428711
training step: 15625, total_loss: 3.7638587951660156
training step: 15626, total_loss: 5.232629299163818
training step: 15627, total_loss: 4.68631649017334
training step: 15628, total_loss: 5.116317272186279
training step: 15629, total_loss: 4.017648220062256
training step: 15630, total_loss: 2.451535701751709
training step: 15631, total_loss: 5.117666721343994
training step: 15632, total_loss: 2.862736701965332
training step: 15633, total_loss: 4.886977195739746
training step: 15634, total_loss: 5.261848449707031
training step: 15635, total_loss: 5.440160751342773
training step: 15636, total_loss: 4.2907586097717285
training step: 15637, total_loss: 5.502560615539551
training step: 15638, total_loss: 4.691701889038086
training step: 15639, total_loss: 5.033929347991943
training step: 15640, total_loss: 3.1542956829071045
training step: 15641, total_loss: 4.680989742279053
training step: 15642, total_loss: 5.014864444732666
training step: 15643, total_loss: 4.819042205810547
training step: 15644, total_loss: 4.5240983963012695
training step: 15645, total_loss: 5.25766658782959
training step: 15646, total_loss: 5.087647438049316
training step: 15647, total_loss: 3.8570427894592285
training step: 15648, total_loss: 4.845469951629639
training step: 15649, total_loss: 4.141429901123047
training step: 15650, total_loss: 2.396984577178955
training step: 15651, total_loss: 3.3862757682800293
training step: 15652, total_loss: 4.625045299530029
training step: 15653, total_loss: 4.416045188903809
training step: 15654, total_loss: 4.2445268630981445
training step: 15655, total_loss: 4.6837663650512695
training step: 15656, total_loss: 4.897247314453125
training step: 15657, total_loss: 5.255100250244141
training step: 15658, total_loss: 4.485699653625488
training step: 15659, total_loss: 4.4211931228637695
training step: 15660, total_loss: 3.8261001110076904
training step: 15661, total_loss: 3.064295768737793
training step: 15662, total_loss: 4.71480131149292
training step: 15663, total_loss: 4.431414604187012
training step: 15664, total_loss: 3.798903465270996
training step: 15665, total_loss: 4.39411735534668
training step: 15666, total_loss: 5.164607048034668
training step: 15667, total_loss: 4.961392402648926
training step: 15668, total_loss: 4.672820091247559
training step: 15669, total_loss: 3.314774990081787
training step: 15670, total_loss: 5.851472854614258
training step: 15671, total_loss: 5.733541488647461
training step: 15672, total_loss: 2.4139928817749023
training step: 15673, total_loss: 3.237511157989502
training step: 15674, total_loss: 3.899834632873535
training step: 15675, total_loss: 4.319762229919434
training step: 15676, total_loss: 4.044408321380615
training step: 15677, total_loss: 5.417459487915039
training step: 15678, total_loss: 3.9425199031829834
training step: 15679, total_loss: 4.388178825378418
training step: 15680, total_loss: 3.7476611137390137
training step: 15681, total_loss: 3.814629077911377
training step: 15682, total_loss: 6.632112503051758
training step: 15683, total_loss: 4.622939586639404
training step: 15684, total_loss: 3.260735034942627
training step: 15685, total_loss: 5.700857162475586
training step: 15686, total_loss: 3.7609357833862305
training step: 15687, total_loss: 7.133209228515625
training step: 15688, total_loss: 4.89393424987793
training step: 15689, total_loss: 4.922702312469482
training step: 15690, total_loss: 4.045392036437988
training step: 15691, total_loss: 5.449452877044678
training step: 15692, total_loss: 4.634190559387207
training step: 15693, total_loss: 4.303079128265381
training step: 15694, total_loss: 4.7285356521606445
training step: 15695, total_loss: 2.888747215270996
training step: 15696, total_loss: 4.401280403137207
training step: 15697, total_loss: 5.4231390953063965
training step: 15698, total_loss: 4.1344170570373535
training step: 15699, total_loss: 1.8679074048995972
training step: 15700, total_loss: 4.814493656158447
training step: 15701, total_loss: 4.493198394775391
training step: 15702, total_loss: 3.97285532951355
training step: 15703, total_loss: 4.494917869567871
training step: 15704, total_loss: 4.427931785583496
training step: 15705, total_loss: 4.4991230964660645
training step: 15706, total_loss: 1.0208711624145508
training step: 15707, total_loss: 4.421911239624023
training step: 15708, total_loss: 2.326272487640381
training step: 15709, total_loss: 4.3186140060424805
training step: 15710, total_loss: 3.8415398597717285
training step: 15711, total_loss: 5.850136756896973
training step: 15712, total_loss: 5.316071510314941
training step: 15713, total_loss: 5.336024284362793
training step: 15714, total_loss: 5.412712097167969
training step: 15715, total_loss: 5.5403594970703125
training step: 15716, total_loss: 3.8681490421295166
training step: 15717, total_loss: 4.300354957580566
training step: 15718, total_loss: 4.161124229431152
training step: 15719, total_loss: 6.259983062744141
training step: 15720, total_loss: 0.9573430418968201
training step: 15721, total_loss: 5.402749061584473
training step: 15722, total_loss: 3.7206273078918457
training step: 15723, total_loss: 5.165463924407959
training step: 15724, total_loss: 3.7601470947265625
training step: 15725, total_loss: 3.884255886077881
training step: 15726, total_loss: 3.6557421684265137
training step: 15727, total_loss: 5.185715675354004
training step: 15728, total_loss: 5.939968109130859
training step: 15729, total_loss: 5.7167134284973145
training step: 15730, total_loss: 5.457559108734131
training step: 15731, total_loss: 3.9125587940216064
training step: 15732, total_loss: 5.984565258026123
training step: 15733, total_loss: 3.041386127471924
training step: 15734, total_loss: 4.290472030639648
training step: 15735, total_loss: 5.002182960510254
training step: 15736, total_loss: 4.176333427429199
training step: 15737, total_loss: 4.19085693359375
training step: 15738, total_loss: 4.366856098175049
training step: 15739, total_loss: 5.224842548370361
training step: 15740, total_loss: 4.602359771728516
training step: 15741, total_loss: 4.94195556640625
training step: 15742, total_loss: 4.601430416107178
training step: 15743, total_loss: 6.233217239379883
training step: 15744, total_loss: 4.9245524406433105
training step: 15745, total_loss: 5.094729900360107
training step: 15746, total_loss: 5.501321792602539
training step: 15747, total_loss: 5.428492546081543
training step: 15748, total_loss: 4.681145668029785
training step: 15749, total_loss: 4.838634490966797
training step: 15750, total_loss: 4.0413713455200195
training step: 15751, total_loss: 4.24009370803833
training step: 15752, total_loss: 5.176345348358154
training step: 15753, total_loss: 5.195981025695801
training step: 15754, total_loss: 3.7689101696014404
training step: 15755, total_loss: 5.261083126068115
training step: 15756, total_loss: 4.143792629241943
training step: 15757, total_loss: 4.013855934143066
training step: 15758, total_loss: 4.506994724273682
training step: 15759, total_loss: 4.525381565093994
training step: 15760, total_loss: 4.235415935516357
training step: 15761, total_loss: 4.729494571685791
training step: 15762, total_loss: 5.78045654296875
training step: 15763, total_loss: 4.292420387268066
training step: 15764, total_loss: 5.233015537261963
training step: 15765, total_loss: 3.5977706909179688
training step: 15766, total_loss: 4.317773818969727
training step: 15767, total_loss: 5.941965579986572
training step: 15768, total_loss: 5.457668304443359
training step: 15769, total_loss: 6.461044788360596
training step: 15770, total_loss: 3.5935168266296387
training step: 15771, total_loss: 3.817309617996216
training step: 15772, total_loss: 4.536308288574219
training step: 15773, total_loss: 4.038931846618652
training step: 15774, total_loss: 3.778881072998047
training step: 15775, total_loss: 3.818941593170166
training step: 15776, total_loss: 5.63166618347168
training step: 15777, total_loss: 3.7159905433654785
training step: 15778, total_loss: 5.168516159057617
training step: 15779, total_loss: 5.056699752807617
training step: 15780, total_loss: 5.001106262207031
training step: 15781, total_loss: 5.062623500823975
training step: 15782, total_loss: 5.158224582672119
training step: 15783, total_loss: 4.641510009765625
training step: 15784, total_loss: 3.4773941040039062
training step: 15785, total_loss: 4.503401756286621
training step: 15786, total_loss: 4.092401504516602
training step: 15787, total_loss: 4.29460334777832
training step: 15788, total_loss: 4.8151774406433105
training step: 15789, total_loss: 3.173879861831665
training step: 15790, total_loss: 2.843210220336914
training step: 15791, total_loss: 3.8895745277404785
training step: 15792, total_loss: 4.026907444000244
training step: 15793, total_loss: 1.1451761722564697
training step: 15794, total_loss: 4.736909866333008
training step: 15795, total_loss: 3.4222185611724854
training step: 15796, total_loss: 1.8243751525878906
training step: 15797, total_loss: 5.357268333435059
training step: 15798, total_loss: 3.658445358276367
training step: 15799, total_loss: 2.3589601516723633
training step: 15800, total_loss: 4.976919174194336
training step: 15801, total_loss: 3.6095242500305176
training step: 15802, total_loss: 5.218894958496094
training step: 15803, total_loss: 3.223407745361328
training step: 15804, total_loss: 5.345466136932373
training step: 15805, total_loss: 4.494889259338379
training step: 15806, total_loss: 3.2642526626586914
training step: 15807, total_loss: 1.9191480875015259
training step: 15808, total_loss: 3.104870080947876
training step: 15809, total_loss: 4.853534698486328
training step: 15810, total_loss: 4.463742256164551
training step: 15811, total_loss: 0.7749447822570801
training step: 15812, total_loss: 2.4261062145233154
training step: 15813, total_loss: 5.614398956298828
training step: 15814, total_loss: 3.67018985748291
training step: 15815, total_loss: 5.5420403480529785
training step: 15816, total_loss: 2.8238494396209717
training step: 15817, total_loss: 4.500876426696777
training step: 15818, total_loss: 5.3647308349609375
training step: 15819, total_loss: 7.481498718261719
training step: 15820, total_loss: 6.084074020385742
training step: 15821, total_loss: 5.668948173522949
training step: 15822, total_loss: 5.193803310394287
training step: 15823, total_loss: 0.5392696261405945
training step: 15824, total_loss: 5.228771209716797
training step: 15825, total_loss: 4.15955924987793
training step: 15826, total_loss: 4.873382568359375
training step: 15827, total_loss: 4.553255081176758
training step: 15828, total_loss: 3.0406737327575684
training step: 15829, total_loss: 3.0282962322235107
training step: 15830, total_loss: 5.513210773468018
training step: 15831, total_loss: 4.434537410736084
training step: 15832, total_loss: 6.6293110847473145
training step: 15833, total_loss: 4.591179847717285
training step: 15834, total_loss: 3.7160468101501465
training step: 15835, total_loss: 4.135849952697754
training step: 15836, total_loss: 4.760385036468506
training step: 15837, total_loss: 4.932754039764404
training step: 15838, total_loss: 4.973455905914307
training step: 15839, total_loss: 4.189985275268555
training step: 15840, total_loss: 3.3172526359558105
training step: 15841, total_loss: 5.194512367248535
training step: 15842, total_loss: 3.083573818206787
training step: 15843, total_loss: 4.716102600097656
training step: 15844, total_loss: 3.724669933319092
training step: 15845, total_loss: 3.8113856315612793
training step: 15846, total_loss: 5.677600383758545
training step: 15847, total_loss: 5.3888654708862305
training step: 15848, total_loss: 2.9868240356445312
training step: 15849, total_loss: 5.384075164794922
training step: 15850, total_loss: 0.7379615306854248
training step: 15851, total_loss: 4.4784746170043945
training step: 15852, total_loss: 4.9109296798706055
training step: 15853, total_loss: 5.653054237365723
training step: 15854, total_loss: 5.429697036743164
training step: 15855, total_loss: 4.826115131378174
training step: 15856, total_loss: 5.533257484436035
training step: 15857, total_loss: 4.006030082702637
training step: 15858, total_loss: 5.881792068481445
training step: 15859, total_loss: 5.254064083099365
training step: 15860, total_loss: 4.086459159851074
training step: 15861, total_loss: 3.5537197589874268
training step: 15862, total_loss: 4.622864246368408
training step: 15863, total_loss: 4.358982086181641
training step: 15864, total_loss: 4.517124176025391
training step: 15865, total_loss: 4.817821979522705
training step: 15866, total_loss: 4.352667331695557
training step: 15867, total_loss: 4.497604846954346
training step: 15868, total_loss: 4.738770484924316
training step: 15869, total_loss: 6.213082313537598
training step: 15870, total_loss: 4.636183738708496
training step: 15871, total_loss: 5.303496360778809
training step: 15872, total_loss: 5.009352684020996
training step: 15873, total_loss: 4.767775535583496
training step: 15874, total_loss: 4.597749710083008
training step: 15875, total_loss: 4.195597171783447
training step: 15876, total_loss: 6.4734015464782715
training step: 15877, total_loss: 3.877845287322998
training step: 15878, total_loss: 6.471282005310059
training step: 15879, total_loss: 4.45133113861084
training step: 15880, total_loss: 4.26279878616333
training step: 15881, total_loss: 3.7981555461883545
training step: 15882, total_loss: 4.836724281311035
training step: 15883, total_loss: 4.8887939453125
training step: 15884, total_loss: 4.418605804443359
training step: 15885, total_loss: 3.1038503646850586
training step: 15886, total_loss: 4.65927267074585
training step: 15887, total_loss: 5.876062393188477
training step: 15888, total_loss: 6.078359603881836
training step: 15889, total_loss: 3.915747880935669
training step: 15890, total_loss: 5.598575115203857
training step: 15891, total_loss: 5.66269588470459
training step: 15892, total_loss: 6.3504838943481445
training step: 15893, total_loss: 4.994935989379883
training step: 15894, total_loss: 4.377008438110352
training step: 15895, total_loss: 5.206509590148926
training step: 15896, total_loss: 7.129848480224609
training step: 15897, total_loss: 4.269706726074219
training step: 15898, total_loss: 2.700082302093506
training step: 15899, total_loss: 3.791748523712158
training step: 15900, total_loss: 5.412578105926514
training step: 15901, total_loss: 4.054856300354004
training step: 15902, total_loss: 5.052891731262207
training step: 15903, total_loss: 5.051237106323242
training step: 15904, total_loss: 3.69917893409729
training step: 15905, total_loss: 5.420619964599609
training step: 15906, total_loss: 4.293064117431641
training step: 15907, total_loss: 4.253742218017578
training step: 15908, total_loss: 4.692329406738281
training step: 15909, total_loss: 4.864715576171875
training step: 15910, total_loss: 4.80459451675415
training step: 15911, total_loss: 5.532857894897461
training step: 15912, total_loss: 4.568218231201172
training step: 15913, total_loss: 3.9763190746307373
training step: 15914, total_loss: 3.936669111251831
training step: 15915, total_loss: 4.798761367797852
training step: 15916, total_loss: 5.083710670471191
training step: 15917, total_loss: 4.808971405029297
training step: 15918, total_loss: 3.5063300132751465
training step: 15919, total_loss: 3.701639413833618
training step: 15920, total_loss: 3.233156204223633
training step: 15921, total_loss: 4.106377124786377
training step: 15922, total_loss: 4.670401573181152
training step: 15923, total_loss: 5.955085277557373
training step: 15924, total_loss: 4.751091957092285
training step: 15925, total_loss: 4.4421868324279785
training step: 15926, total_loss: 4.065797328948975
training step: 15927, total_loss: 5.242337226867676
training step: 15928, total_loss: 3.7915587425231934
training step: 15929, total_loss: 3.567045211791992
training step: 15930, total_loss: 5.357359886169434
training step: 15931, total_loss: 5.559892177581787
training step: 15932, total_loss: 3.7912211418151855
training step: 15933, total_loss: 3.5916647911071777
training step: 15934, total_loss: 4.418275356292725
training step: 15935, total_loss: 5.682216167449951
training step: 15936, total_loss: 3.126948833465576
training step: 15937, total_loss: 4.263955116271973
training step: 15938, total_loss: 3.6507229804992676
training step: 15939, total_loss: 1.10493004322052
training step: 15940, total_loss: 3.583714008331299
training step: 15941, total_loss: 5.045241355895996
training step: 15942, total_loss: 4.631227970123291
training step: 15943, total_loss: 3.797062397003174
training step: 15944, total_loss: 3.149223804473877
training step: 15945, total_loss: 5.1480512619018555
training step: 15946, total_loss: 4.475722312927246
training step: 15947, total_loss: 6.661007881164551
training step: 15948, total_loss: 5.377361297607422
training step: 15949, total_loss: 6.453261852264404
training step: 15950, total_loss: 6.320479869842529
training step: 15951, total_loss: 4.011818885803223
training step: 15952, total_loss: 5.083446025848389
training step: 15953, total_loss: 4.432162284851074
training step: 15954, total_loss: 1.4641146659851074
training step: 15955, total_loss: 3.762260913848877
training step: 15956, total_loss: 4.864396095275879
training step: 15957, total_loss: 4.870405197143555
training step: 15958, total_loss: 4.209902286529541
training step: 15959, total_loss: 4.944385051727295
training step: 15960, total_loss: 3.712592601776123
training step: 15961, total_loss: 5.157954216003418
training step: 15962, total_loss: 4.8695454597473145
training step: 15963, total_loss: 4.836940288543701
training step: 15964, total_loss: 3.152618408203125
training step: 15965, total_loss: 6.362298488616943
training step: 15966, total_loss: 5.25244140625
training step: 15967, total_loss: 4.319794654846191
training step: 15968, total_loss: 6.4526777267456055
training step: 15969, total_loss: 1.131333351135254
training step: 15970, total_loss: 4.325055122375488
training step: 15971, total_loss: 5.863971710205078
training step: 15972, total_loss: 4.968141555786133
training step: 15973, total_loss: 4.726305961608887
training step: 15974, total_loss: 5.123780250549316
training step: 15975, total_loss: 3.3246593475341797
training step: 15976, total_loss: 3.6617836952209473
training step: 15977, total_loss: 4.237412452697754
training step: 15978, total_loss: 4.053016662597656
training step: 15979, total_loss: 4.852212905883789
training step: 15980, total_loss: 5.346429824829102
training step: 15981, total_loss: 4.538859844207764
training step: 15982, total_loss: 4.351783752441406
training step: 15983, total_loss: 4.6057353019714355
training step: 15984, total_loss: 4.709351539611816
training step: 15985, total_loss: 4.410639762878418
training step: 15986, total_loss: 4.99553108215332
training step: 15987, total_loss: 2.2254302501678467
training step: 15988, total_loss: 5.7181172370910645
training step: 15989, total_loss: 3.067023754119873
training step: 15990, total_loss: 4.67734432220459
training step: 15991, total_loss: 5.801757335662842
training step: 15992, total_loss: 4.347690582275391
training step: 15993, total_loss: 4.947212219238281
training step: 15994, total_loss: 4.705018043518066
training step: 15995, total_loss: 4.494019031524658
training step: 15996, total_loss: 3.2396187782287598
training step: 15997, total_loss: 6.060720443725586
training step: 15998, total_loss: 4.930515289306641
training step: 15999, total_loss: 4.202877044677734
training step: 16000, total_loss: 2.6490211486816406
training step: 16001, total_loss: 5.533062934875488
training step: 16002, total_loss: 4.499481201171875
training step: 16003, total_loss: 4.993960380554199
training step: 16004, total_loss: 4.168570041656494
training step: 16005, total_loss: 4.931613445281982
training step: 16006, total_loss: 4.7591328620910645
training step: 16007, total_loss: 4.771142482757568
training step: 16008, total_loss: 5.409134864807129
training step: 16009, total_loss: 5.106937408447266
training step: 16010, total_loss: 3.686918258666992
training step: 16011, total_loss: 5.071985244750977
training step: 16012, total_loss: 1.2595343589782715
training step: 16013, total_loss: 3.9170656204223633
training step: 16014, total_loss: 1.3400025367736816
training step: 16015, total_loss: 4.388764381408691
training step: 16016, total_loss: 4.574592590332031
training step: 16017, total_loss: 4.428238868713379
training step: 16018, total_loss: 3.117776393890381
training step: 16019, total_loss: 4.301934242248535
training step: 16020, total_loss: 4.3777384757995605
training step: 16021, total_loss: 5.692799091339111
training step: 16022, total_loss: 4.571488380432129
training step: 16023, total_loss: 4.8409295082092285
training step: 16024, total_loss: 4.599757671356201
training step: 16025, total_loss: 4.800531387329102
training step: 16026, total_loss: 4.83263635635376
training step: 16027, total_loss: 6.3483500480651855
training step: 16028, total_loss: 4.890170097351074
training step: 16029, total_loss: 3.234785318374634
training step: 16030, total_loss: 5.190892696380615
training step: 16031, total_loss: 5.029999256134033
training step: 16032, total_loss: 6.507127285003662
training step: 16033, total_loss: 1.384995460510254
training step: 16034, total_loss: 4.355273723602295
training step: 16035, total_loss: 4.673733711242676
training step: 16036, total_loss: 4.3964338302612305
training step: 16037, total_loss: 5.25036096572876
training step: 16038, total_loss: 6.205319404602051
training step: 16039, total_loss: 5.003374099731445
training step: 16040, total_loss: 3.9354000091552734
training step: 16041, total_loss: 5.853218078613281
training step: 16042, total_loss: 6.372253894805908
training step: 16043, total_loss: 6.103167533874512
training step: 16044, total_loss: 4.588803291320801
training step: 16045, total_loss: 4.7921648025512695
training step: 16046, total_loss: 3.606684684753418
training step: 16047, total_loss: 4.919878005981445
training step: 16048, total_loss: 4.926615238189697
training step: 16049, total_loss: 4.959939479827881
training step: 16050, total_loss: 5.139013290405273
training step: 16051, total_loss: 5.144935607910156
training step: 16052, total_loss: 5.369001388549805
training step: 16053, total_loss: 5.232808589935303
training step: 16054, total_loss: 4.311123371124268
training step: 16055, total_loss: 4.773316860198975
training step: 16056, total_loss: 4.585300445556641
training step: 16057, total_loss: 4.336355686187744
training step: 16058, total_loss: 5.379396438598633
training step: 16059, total_loss: 5.452390670776367
training step: 16060, total_loss: 6.71923828125
training step: 16061, total_loss: 4.222084045410156
training step: 16062, total_loss: 5.082685470581055
training step: 16063, total_loss: 4.176448822021484
training step: 16064, total_loss: 3.1029772758483887
training step: 16065, total_loss: 5.0546979904174805
training step: 16066, total_loss: 5.067008018493652
training step: 16067, total_loss: 4.966002464294434
training step: 16068, total_loss: 3.7875895500183105
training step: 16069, total_loss: 4.928132057189941
training step: 16070, total_loss: 6.075229644775391
training step: 16071, total_loss: 3.99747371673584
training step: 16072, total_loss: 3.068830966949463
training step: 16073, total_loss: 3.0286383628845215
training step: 16074, total_loss: 5.16091251373291
training step: 16075, total_loss: 2.958681583404541
training step: 16076, total_loss: 5.797891139984131
training step: 16077, total_loss: 3.8049721717834473
training step: 16078, total_loss: 5.231947898864746
training step: 16079, total_loss: 4.8492431640625
training step: 16080, total_loss: 3.580772638320923
training step: 16081, total_loss: 5.302563667297363
training step: 16082, total_loss: 5.568775177001953
training step: 16083, total_loss: 6.068232536315918
training step: 16084, total_loss: 4.439600944519043
training step: 16085, total_loss: 6.289687633514404
training step: 16086, total_loss: 4.4155778884887695
training step: 16087, total_loss: 3.778097152709961
training step: 16088, total_loss: 3.152951717376709
training step: 16089, total_loss: 5.506681442260742
training step: 16090, total_loss: 4.948724269866943
training step: 16091, total_loss: 3.8235414028167725
training step: 16092, total_loss: 3.4709815979003906
training step: 16093, total_loss: 4.339691162109375
training step: 16094, total_loss: 4.118512153625488
training step: 16095, total_loss: 5.113981246948242
training step: 16096, total_loss: 5.188650608062744
training step: 16097, total_loss: 4.415106296539307
training step: 16098, total_loss: 3.797323226928711
training step: 16099, total_loss: 4.04172420501709
training step: 16100, total_loss: 2.5397586822509766
training step: 16101, total_loss: 4.340240955352783
training step: 16102, total_loss: 1.3191673755645752
training step: 16103, total_loss: 4.13081169128418
training step: 16104, total_loss: 4.167112827301025
training step: 16105, total_loss: 4.7373046875
training step: 16106, total_loss: 5.898019790649414
training step: 16107, total_loss: 4.294723987579346
training step: 16108, total_loss: 5.135105133056641
training step: 16109, total_loss: 3.4698755741119385
training step: 16110, total_loss: 6.23717737197876
training step: 16111, total_loss: 4.53687047958374
training step: 16112, total_loss: 3.576629400253296
training step: 16113, total_loss: 6.10601806640625
training step: 16114, total_loss: 5.227530479431152
training step: 16115, total_loss: 3.6748855113983154
training step: 16116, total_loss: 4.180468559265137
training step: 16117, total_loss: 5.21778678894043
training step: 16118, total_loss: 3.3919677734375
training step: 16119, total_loss: 3.062389373779297
training step: 16120, total_loss: 4.412984371185303
training step: 16121, total_loss: 5.438366889953613
training step: 16122, total_loss: 4.537318229675293
training step: 16123, total_loss: 5.320843696594238
training step: 16124, total_loss: 5.589764595031738
training step: 16125, total_loss: 5.031534194946289
training step: 16126, total_loss: 4.135923385620117
training step: 16127, total_loss: 4.275088310241699
training step: 16128, total_loss: 3.5167760848999023
training step: 16129, total_loss: 6.954073905944824
training step: 16130, total_loss: 5.766858100891113
training step: 16131, total_loss: 3.1078662872314453
training step: 16132, total_loss: 3.722895860671997
training step: 16133, total_loss: 3.847949981689453
training step: 16134, total_loss: 5.665651321411133
training step: 16135, total_loss: 3.7559430599212646
training step: 16136, total_loss: 2.149573802947998
training step: 16137, total_loss: 4.026525020599365
training step: 16138, total_loss: 3.9253578186035156
training step: 16139, total_loss: 5.537628173828125
training step: 16140, total_loss: 4.958698749542236
training step: 16141, total_loss: 5.711368560791016
training step: 16142, total_loss: 4.153809547424316
training step: 16143, total_loss: 3.8221287727355957
training step: 16144, total_loss: 5.242626667022705
training step: 16145, total_loss: 3.3418993949890137
training step: 16146, total_loss: 4.843375205993652
training step: 16147, total_loss: 2.7877750396728516
training step: 16148, total_loss: 1.1463617086410522
training step: 16149, total_loss: 4.164998531341553
training step: 16150, total_loss: 3.1333255767822266
training step: 16151, total_loss: 4.855672836303711
training step: 16152, total_loss: 3.690291404724121
training step: 16153, total_loss: 5.58884334564209
training step: 16154, total_loss: 4.633270263671875
training step: 16155, total_loss: 3.999229669570923
training step: 16156, total_loss: 5.305238723754883
training step: 16157, total_loss: 4.188530445098877
training step: 16158, total_loss: 3.012080430984497
training step: 16159, total_loss: 3.562795877456665
training step: 16160, total_loss: 5.784311771392822
training step: 16161, total_loss: 4.439839839935303
training step: 16162, total_loss: 4.089607238769531
training step: 16163, total_loss: 3.731827735900879
training step: 16164, total_loss: 3.147768974304199
training step: 16165, total_loss: 3.6999871730804443
training step: 16166, total_loss: 4.913773536682129
training step: 16167, total_loss: 4.786868095397949
training step: 16168, total_loss: 5.161511421203613
training step: 16169, total_loss: 4.2845964431762695
training step: 16170, total_loss: 4.00535774230957
training step: 16171, total_loss: 4.467996597290039
training step: 16172, total_loss: 5.083652973175049
training step: 16173, total_loss: 3.6487386226654053
training step: 16174, total_loss: 4.8641862869262695
training step: 16175, total_loss: 4.742673873901367
training step: 16176, total_loss: 4.679756164550781
training step: 16177, total_loss: 4.648833274841309
training step: 16178, total_loss: 3.992823600769043
training step: 16179, total_loss: 1.1866285800933838
training step: 16180, total_loss: 4.234894275665283
training step: 16181, total_loss: 4.794131755828857
training step: 16182, total_loss: 5.704379081726074
training step: 16183, total_loss: 3.2096076011657715
training step: 16184, total_loss: 4.790905475616455
training step: 16185, total_loss: 5.491812705993652
training step: 16186, total_loss: 2.7286102771759033
training step: 16187, total_loss: 4.904431343078613
training step: 16188, total_loss: 3.9454345703125
training step: 16189, total_loss: 3.934997797012329
training step: 16190, total_loss: 5.349076271057129
training step: 16191, total_loss: 4.217789173126221
training step: 16192, total_loss: 4.742115020751953
training step: 16193, total_loss: 4.308596611022949
training step: 16194, total_loss: 3.8074471950531006
training step: 16195, total_loss: 5.032133102416992
training step: 16196, total_loss: 4.548740863800049
training step: 16197, total_loss: 3.7340197563171387
training step: 16198, total_loss: 4.560525417327881
training step: 16199, total_loss: 4.775666236877441
training step: 16200, total_loss: 4.779916763305664
training step: 16201, total_loss: 3.7731146812438965
training step: 16202, total_loss: 5.4367146492004395
training step: 16203, total_loss: 3.2452096939086914
training step: 16204, total_loss: 2.9515085220336914
training step: 16205, total_loss: 3.700477123260498
training step: 16206, total_loss: 4.849973678588867
training step: 16207, total_loss: 4.32611083984375
training step: 16208, total_loss: 2.881547451019287
training step: 16209, total_loss: 4.432437896728516
training step: 16210, total_loss: 4.673300743103027
training step: 16211, total_loss: 2.637157917022705
training step: 16212, total_loss: 2.8809494972229004
training step: 16213, total_loss: 4.886536598205566
training step: 16214, total_loss: 3.4744648933410645
training step: 16215, total_loss: 4.945728302001953
training step: 16216, total_loss: 4.4841084480285645
training step: 16217, total_loss: 4.707481384277344
training step: 16218, total_loss: 4.931667327880859
training step: 16219, total_loss: 4.338619232177734
training step: 16220, total_loss: 4.604480266571045
training step: 16221, total_loss: 4.815027236938477
training step: 16222, total_loss: 3.7527661323547363
training step: 16223, total_loss: 4.971552848815918
training step: 16224, total_loss: 4.029084205627441
training step: 16225, total_loss: 4.446589946746826
training step: 16226, total_loss: 4.101132392883301
training step: 16227, total_loss: 2.877584218978882
training step: 16228, total_loss: 4.675218105316162
training step: 16229, total_loss: 5.638925075531006
training step: 16230, total_loss: 5.024594306945801
training step: 16231, total_loss: 3.9296131134033203
training step: 16232, total_loss: 4.386594295501709
training step: 16233, total_loss: 6.920635223388672
training step: 16234, total_loss: 7.905566215515137
training step: 16235, total_loss: 4.427009582519531
training step: 16236, total_loss: 4.244915962219238
training step: 16237, total_loss: 4.183169841766357
training step: 16238, total_loss: 4.310349941253662
training step: 16239, total_loss: 5.248629570007324
training step: 16240, total_loss: 5.150274753570557
training step: 16241, total_loss: 4.719723224639893
training step: 16242, total_loss: 4.5147705078125
training step: 16243, total_loss: 5.19927978515625
training step: 16244, total_loss: 4.879538536071777
training step: 16245, total_loss: 5.43001651763916
training step: 16246, total_loss: 2.753664255142212
training step: 16247, total_loss: 3.2509138584136963
training step: 16248, total_loss: 4.401446342468262
training step: 16249, total_loss: 5.532989501953125
training step: 16250, total_loss: 4.458351135253906
training step: 16251, total_loss: 5.39449405670166
training step: 16252, total_loss: 5.6217498779296875
training step: 16253, total_loss: 5.023268699645996
training step: 16254, total_loss: 4.193952560424805
training step: 16255, total_loss: 4.961389541625977
training step: 16256, total_loss: 5.070659160614014
training step: 16257, total_loss: 5.222503185272217
training step: 16258, total_loss: 3.134324073791504
training step: 16259, total_loss: 5.083706378936768
training step: 16260, total_loss: 3.3994998931884766
training step: 16261, total_loss: 3.672978162765503
training step: 16262, total_loss: 4.457009792327881
training step: 16263, total_loss: 3.8577795028686523
training step: 16264, total_loss: 3.7033023834228516
training step: 16265, total_loss: 3.3336925506591797
training step: 16266, total_loss: 7.134039402008057
training step: 16267, total_loss: 6.547107696533203
training step: 16268, total_loss: 4.5894293785095215
training step: 16269, total_loss: 5.519081115722656
training step: 16270, total_loss: 3.7538094520568848
training step: 16271, total_loss: 3.975162982940674
training step: 16272, total_loss: 3.7117409706115723
training step: 16273, total_loss: 4.310754299163818
training step: 16274, total_loss: 4.909996032714844
training step: 16275, total_loss: 3.7313456535339355
training step: 16276, total_loss: 1.6295135021209717
training step: 16277, total_loss: 6.221873760223389
training step: 16278, total_loss: 6.612180709838867
training step: 16279, total_loss: 5.20741081237793
training step: 16280, total_loss: 4.636845588684082
training step: 16281, total_loss: 5.063941478729248
training step: 16282, total_loss: 4.122182369232178
training step: 16283, total_loss: 2.6344878673553467
training step: 16284, total_loss: 4.689105987548828
training step: 16285, total_loss: 5.3334197998046875
training step: 16286, total_loss: 6.271475315093994
training step: 16287, total_loss: 2.83090877532959
training step: 16288, total_loss: 2.947054386138916
training step: 16289, total_loss: 5.326565742492676
training step: 16290, total_loss: 4.073709487915039
training step: 16291, total_loss: 3.9310834407806396
training step: 16292, total_loss: 4.274944305419922
training step: 16293, total_loss: 2.6957828998565674
training step: 16294, total_loss: 5.304161548614502
training step: 16295, total_loss: 4.515354156494141
training step: 16296, total_loss: 4.359772682189941
training step: 16297, total_loss: 4.880576133728027
training step: 16298, total_loss: 3.867145538330078
training step: 16299, total_loss: 4.532786846160889
training step: 16300, total_loss: 3.673459529876709
training step: 16301, total_loss: 4.004753112792969
training step: 16302, total_loss: 4.9162068367004395
training step: 16303, total_loss: 3.016345500946045
training step: 16304, total_loss: 3.0582358837127686
training step: 16305, total_loss: 5.221940994262695
training step: 16306, total_loss: 4.406761169433594
training step: 16307, total_loss: 4.818146705627441
training step: 16308, total_loss: 4.062855243682861
training step: 16309, total_loss: 3.623670816421509
training step: 16310, total_loss: 4.583907127380371
training step: 16311, total_loss: 3.75683856010437
training step: 16312, total_loss: 4.904327392578125
training step: 16313, total_loss: 3.5625123977661133
training step: 16314, total_loss: 4.328500270843506
training step: 16315, total_loss: 5.250166893005371
training step: 16316, total_loss: 5.448356628417969
training step: 16317, total_loss: 4.4495015144348145
training step: 16318, total_loss: 3.7401859760284424
training step: 16319, total_loss: 3.369964599609375
training step: 16320, total_loss: 3.878938913345337
training step: 16321, total_loss: 3.420738458633423
training step: 16322, total_loss: 4.865847110748291
training step: 16323, total_loss: 5.592660427093506
training step: 16324, total_loss: 5.815908908843994
training step: 16325, total_loss: 4.903040885925293
training step: 16326, total_loss: 2.910853862762451
training step: 16327, total_loss: 4.976593494415283
training step: 16328, total_loss: 4.71359920501709
training step: 16329, total_loss: 4.482389450073242
training step: 16330, total_loss: 5.017019271850586
training step: 16331, total_loss: 3.45339298248291
training step: 16332, total_loss: 5.027314186096191
training step: 16333, total_loss: 4.5135955810546875
training step: 16334, total_loss: 4.6409010887146
training step: 16335, total_loss: 4.408266067504883
training step: 16336, total_loss: 4.23679256439209
training step: 16337, total_loss: 4.031538963317871
training step: 16338, total_loss: 3.824981927871704
training step: 16339, total_loss: 5.329608917236328
training step: 16340, total_loss: 4.677122116088867
training step: 16341, total_loss: 4.236432075500488
training step: 16342, total_loss: 4.544419765472412
training step: 16343, total_loss: 3.685396671295166
training step: 16344, total_loss: 5.239802837371826
training step: 16345, total_loss: 4.7680840492248535
training step: 16346, total_loss: 5.603493690490723
training step: 16347, total_loss: 4.9481682777404785
training step: 16348, total_loss: 3.1730144023895264
training step: 16349, total_loss: 5.116764068603516
training step: 16350, total_loss: 5.244938373565674
training step: 16351, total_loss: 4.106159687042236
training step: 16352, total_loss: 3.059736728668213
training step: 16353, total_loss: 4.708572864532471
training step: 16354, total_loss: 5.2631120681762695
training step: 16355, total_loss: 2.7760210037231445
training step: 16356, total_loss: 4.2048468589782715
training step: 16357, total_loss: 4.782739639282227
training step: 16358, total_loss: 4.28959321975708
training step: 16359, total_loss: 5.894818305969238
training step: 16360, total_loss: 2.413926124572754
training step: 16361, total_loss: 5.277634620666504
training step: 16362, total_loss: 4.846754550933838
training step: 16363, total_loss: 4.665840148925781
training step: 16364, total_loss: 2.7260849475860596
training step: 16365, total_loss: 5.810464859008789
training step: 16366, total_loss: 2.0690085887908936
training step: 16367, total_loss: 5.183958053588867
training step: 16368, total_loss: 3.3582541942596436
training step: 16369, total_loss: 4.987239837646484
training step: 16370, total_loss: 5.291347503662109
training step: 16371, total_loss: 5.089375972747803
training step: 16372, total_loss: 3.0726823806762695
training step: 16373, total_loss: 3.913165330886841
training step: 16374, total_loss: 5.015388488769531
training step: 16375, total_loss: 5.597352504730225
training step: 16376, total_loss: 4.765313148498535
training step: 16377, total_loss: 5.808434009552002
training step: 16378, total_loss: 4.62380313873291
training step: 16379, total_loss: 4.314802169799805
training step: 16380, total_loss: 4.428062438964844
training step: 16381, total_loss: 4.910643577575684
training step: 16382, total_loss: 3.4943289756774902
training step: 16383, total_loss: 4.513785362243652
training step: 16384, total_loss: 4.880945205688477
training step: 16385, total_loss: 5.664534568786621
training step: 16386, total_loss: 3.1434707641601562
training step: 16387, total_loss: 5.218618392944336
training step: 16388, total_loss: 4.663232803344727
training step: 16389, total_loss: 6.073837757110596
training step: 16390, total_loss: 6.341577529907227
training step: 16391, total_loss: 3.5578598976135254
training step: 16392, total_loss: 4.154332637786865
training step: 16393, total_loss: 5.89330530166626
training step: 16394, total_loss: 3.8936924934387207
training step: 16395, total_loss: 3.408186435699463
training step: 16396, total_loss: 2.900369644165039
training step: 16397, total_loss: 4.694948673248291
training step: 16398, total_loss: 5.423064708709717
training step: 16399, total_loss: 6.62400484085083
training step: 16400, total_loss: 4.601496696472168
training step: 16401, total_loss: 3.2633678913116455
training step: 16402, total_loss: 2.9299213886260986
training step: 16403, total_loss: 3.2291316986083984
training step: 16404, total_loss: 4.525843620300293
training step: 16405, total_loss: 4.70869779586792
training step: 16406, total_loss: 4.701709270477295
training step: 16407, total_loss: 4.031280994415283
training step: 16408, total_loss: 4.77301025390625
training step: 16409, total_loss: 5.185674667358398
training step: 16410, total_loss: 4.118509292602539
training step: 16411, total_loss: 4.4537763595581055
training step: 16412, total_loss: 5.031207084655762
training step: 16413, total_loss: 6.931907653808594
training step: 16414, total_loss: 3.820878267288208
training step: 16415, total_loss: 4.712322235107422
training step: 16416, total_loss: 4.787844657897949
training step: 16417, total_loss: 5.552803039550781
training step: 16418, total_loss: 4.305112838745117
training step: 16419, total_loss: 6.072251319885254
training step: 16420, total_loss: 4.751691818237305
training step: 16421, total_loss: 2.028398036956787
training step: 16422, total_loss: 1.285900592803955
training step: 16423, total_loss: 4.246916770935059
training step: 16424, total_loss: 4.685870170593262
training step: 16425, total_loss: 3.968471050262451
training step: 16426, total_loss: 3.9199512004852295
training step: 16427, total_loss: 4.033864974975586
training step: 16428, total_loss: 5.054755210876465
training step: 16429, total_loss: 3.766244411468506
training step: 16430, total_loss: 1.3540873527526855
training step: 16431, total_loss: 1.5793570280075073
training step: 16432, total_loss: 3.7650890350341797
training step: 16433, total_loss: 6.04807710647583
training step: 16434, total_loss: 5.976783752441406
training step: 16435, total_loss: 5.072314739227295
training step: 16436, total_loss: 3.1999268531799316
training step: 16437, total_loss: 5.137689113616943
training step: 16438, total_loss: 5.432439804077148
training step: 16439, total_loss: 3.0654773712158203
training step: 16440, total_loss: 4.1915788650512695
training step: 16441, total_loss: 5.613671779632568
training step: 16442, total_loss: 7.045098781585693
training step: 16443, total_loss: 3.2941596508026123
training step: 16444, total_loss: 6.024288177490234
training step: 16445, total_loss: 4.314608573913574
training step: 16446, total_loss: 5.7415876388549805
training step: 16447, total_loss: 5.262261390686035
training step: 16448, total_loss: 4.034921646118164
training step: 16449, total_loss: 5.352771759033203
training step: 16450, total_loss: 4.823050022125244
training step: 16451, total_loss: 4.256808757781982
training step: 16452, total_loss: 3.3877763748168945
training step: 16453, total_loss: 4.986703872680664
training step: 16454, total_loss: 4.731750011444092
training step: 16455, total_loss: 3.447479248046875
training step: 16456, total_loss: 4.901430130004883
training step: 16457, total_loss: 4.527489185333252
training step: 16458, total_loss: 5.902087211608887
training step: 16459, total_loss: 4.303936958312988
training step: 16460, total_loss: 4.506209850311279
training step: 16461, total_loss: 3.722917079925537
training step: 16462, total_loss: 5.122313976287842
training step: 16463, total_loss: 6.018603324890137
training step: 16464, total_loss: 4.941754341125488
training step: 16465, total_loss: 5.951622009277344
training step: 16466, total_loss: 3.6247503757476807
training step: 16467, total_loss: 6.194650173187256
training step: 16468, total_loss: 3.095928430557251
training step: 16469, total_loss: 4.663705348968506
training step: 16470, total_loss: 4.617198944091797
training step: 16471, total_loss: 4.689858913421631
training step: 16472, total_loss: 4.1797895431518555
training step: 16473, total_loss: 3.350193977355957
training step: 16474, total_loss: 4.221688270568848
training step: 16475, total_loss: 2.748934268951416
training step: 16476, total_loss: 4.507858753204346
training step: 16477, total_loss: 5.274075508117676
training step: 16478, total_loss: 4.105714797973633
training step: 16479, total_loss: 4.016246795654297
training step: 16480, total_loss: 4.603757381439209
training step: 16481, total_loss: 3.4091358184814453
training step: 16482, total_loss: 4.67811393737793
training step: 16483, total_loss: 5.270113945007324
training step: 16484, total_loss: 5.137944221496582
training step: 16485, total_loss: 4.739314079284668
training step: 16486, total_loss: 5.155084609985352
training step: 16487, total_loss: 5.015079975128174
training step: 16488, total_loss: 6.593380928039551
training step: 16489, total_loss: 4.970404624938965
training step: 16490, total_loss: 3.306997299194336
training step: 16491, total_loss: 4.439654350280762
training step: 16492, total_loss: 4.412691593170166
training step: 16493, total_loss: 6.114376544952393
training step: 16494, total_loss: 6.973867893218994
training step: 16495, total_loss: 5.62630558013916
training step: 16496, total_loss: 4.761134147644043
training step: 16497, total_loss: 3.304500102996826
training step: 16498, total_loss: 4.844736099243164
training step: 16499, total_loss: 4.259024620056152
training step: 16500, total_loss: 4.958732604980469
training step: 16501, total_loss: 7.030770778656006
training step: 16502, total_loss: 4.652764797210693
training step: 16503, total_loss: 5.3210601806640625
training step: 16504, total_loss: 2.9181978702545166
training step: 16505, total_loss: 2.845792293548584
training step: 16506, total_loss: 4.142574787139893
training step: 16507, total_loss: 5.701010704040527
training step: 16508, total_loss: 3.7835700511932373
training step: 16509, total_loss: 5.347857475280762
training step: 16510, total_loss: 5.725697994232178
training step: 16511, total_loss: 1.245316505432129
training step: 16512, total_loss: 4.4604620933532715
training step: 16513, total_loss: 5.875565528869629
training step: 16514, total_loss: 4.285374641418457
training step: 16515, total_loss: 4.461211204528809
training step: 16516, total_loss: 4.241917610168457
training step: 16517, total_loss: 3.3226184844970703
training step: 16518, total_loss: 4.50121545791626
training step: 16519, total_loss: 4.078586578369141
training step: 16520, total_loss: 4.621842384338379
training step: 16521, total_loss: 2.636627674102783
training step: 16522, total_loss: 4.391537189483643
training step: 16523, total_loss: 5.099480152130127
training step: 16524, total_loss: 5.260706901550293
training step: 16525, total_loss: 3.3328299522399902
training step: 16526, total_loss: 3.4157514572143555
training step: 16527, total_loss: 4.915609359741211
training step: 16528, total_loss: 4.340922832489014
training step: 16529, total_loss: 5.520183086395264
training step: 16530, total_loss: 4.352871894836426
training step: 16531, total_loss: 3.968508005142212
training step: 16532, total_loss: 2.89859676361084
training step: 16533, total_loss: 5.1538872718811035
training step: 16534, total_loss: 4.739595413208008
training step: 16535, total_loss: 5.22144079208374
training step: 16536, total_loss: 4.016950607299805
training step: 16537, total_loss: 4.265018463134766
training step: 16538, total_loss: 3.847283124923706
training step: 16539, total_loss: 5.340513706207275
training step: 16540, total_loss: 4.648530960083008
training step: 16541, total_loss: 2.6826281547546387
training step: 16542, total_loss: 4.1967058181762695
training step: 16543, total_loss: 2.918644905090332
training step: 16544, total_loss: 3.91605281829834
training step: 16545, total_loss: 5.672215461730957
training step: 16546, total_loss: 3.99178409576416
training step: 16547, total_loss: 2.818239450454712
training step: 16548, total_loss: 4.526095390319824
training step: 16549, total_loss: 3.2427191734313965
training step: 16550, total_loss: 2.929410934448242
training step: 16551, total_loss: 6.498987197875977
training step: 16552, total_loss: 4.962145805358887
training step: 16553, total_loss: 4.905702590942383
training step: 16554, total_loss: 3.7536325454711914
training step: 16555, total_loss: 4.617167949676514
training step: 16556, total_loss: 3.935439109802246
training step: 16557, total_loss: 5.289310932159424
training step: 16558, total_loss: 4.455920696258545
training step: 16559, total_loss: 4.465579509735107
training step: 16560, total_loss: 3.938951253890991
training step: 16561, total_loss: 2.623544216156006
training step: 16562, total_loss: 3.9208455085754395
training step: 16563, total_loss: 5.487975120544434
training step: 16564, total_loss: 3.556565046310425
training step: 16565, total_loss: 6.563475131988525
training step: 16566, total_loss: 5.19009256362915
training step: 16567, total_loss: 5.34238338470459
training step: 16568, total_loss: 5.311431884765625
training step: 16569, total_loss: 3.950594425201416
training step: 16570, total_loss: 3.8320257663726807
training step: 16571, total_loss: 5.336860656738281
training step: 16572, total_loss: 5.554143905639648
training step: 16573, total_loss: 5.009011745452881
training step: 16574, total_loss: 3.9555206298828125
training step: 16575, total_loss: 3.2781920433044434
training step: 16576, total_loss: 4.819986343383789
training step: 16577, total_loss: 4.577602386474609
training step: 16578, total_loss: 5.521176338195801
training step: 16579, total_loss: 4.816444396972656
training step: 16580, total_loss: 4.135142803192139
training step: 16581, total_loss: 5.149044036865234
training step: 16582, total_loss: 4.765359401702881
training step: 16583, total_loss: 2.3234667778015137
training step: 16584, total_loss: 4.673727989196777
training step: 16585, total_loss: 5.163727283477783
training step: 16586, total_loss: 4.912967681884766
training step: 16587, total_loss: 5.0564656257629395
training step: 16588, total_loss: 6.800583839416504
training step: 16589, total_loss: 6.29763126373291
training step: 16590, total_loss: 4.487880706787109
training step: 16591, total_loss: 2.336646795272827
training step: 16592, total_loss: 4.068248748779297
training step: 16593, total_loss: 5.061312198638916
training step: 16594, total_loss: 3.8446502685546875
training step: 16595, total_loss: 3.4373083114624023
training step: 16596, total_loss: 4.910833358764648
training step: 16597, total_loss: 4.8009185791015625
training step: 16598, total_loss: 4.164668083190918
training step: 16599, total_loss: 4.709324836730957
training step: 16600, total_loss: 3.4347286224365234
training step: 16601, total_loss: 4.385490894317627
training step: 16602, total_loss: 3.7562077045440674
training step: 16603, total_loss: 5.981623649597168
training step: 16604, total_loss: 4.7425336837768555
training step: 16605, total_loss: 5.0438361167907715
training step: 16606, total_loss: 4.9872636795043945
training step: 16607, total_loss: 3.467064380645752
training step: 16608, total_loss: 3.006763458251953
training step: 16609, total_loss: 4.672009468078613
training step: 16610, total_loss: 5.6131391525268555
training step: 16611, total_loss: 3.8902840614318848
training step: 16612, total_loss: 3.567507266998291
training step: 16613, total_loss: 5.174647331237793
training step: 16614, total_loss: 4.998305797576904
training step: 16615, total_loss: 2.6445350646972656
training step: 16616, total_loss: 5.307952404022217
training step: 16617, total_loss: 5.432818412780762
training step: 16618, total_loss: 4.91121768951416
training step: 16619, total_loss: 3.1170105934143066
training step: 16620, total_loss: 4.3850603103637695
training step: 16621, total_loss: 7.1054182052612305
training step: 16622, total_loss: 3.9733083248138428
training step: 16623, total_loss: 5.242847919464111
training step: 16624, total_loss: 2.0695323944091797
training step: 16625, total_loss: 4.93102502822876
training step: 16626, total_loss: 4.377752304077148
training step: 16627, total_loss: 5.365444660186768
training step: 16628, total_loss: 6.781050682067871
training step: 16629, total_loss: 5.362843036651611
training step: 16630, total_loss: 3.6897101402282715
training step: 16631, total_loss: 4.133625507354736
training step: 16632, total_loss: 5.311639785766602
training step: 16633, total_loss: 4.445333480834961
training step: 16634, total_loss: 4.219277381896973
training step: 16635, total_loss: 1.6051853895187378
training step: 16636, total_loss: 4.508232116699219
training step: 16637, total_loss: 4.897636413574219
training step: 16638, total_loss: 5.308925628662109
training step: 16639, total_loss: 4.877090930938721
training step: 16640, total_loss: 3.0268826484680176
training step: 16641, total_loss: 2.711322784423828
training step: 16642, total_loss: 5.1908793449401855
training step: 16643, total_loss: 5.026524543762207
training step: 16644, total_loss: 3.7248668670654297
training step: 16645, total_loss: 3.859034538269043
training step: 16646, total_loss: 4.44415807723999
training step: 16647, total_loss: 5.223044395446777
training step: 16648, total_loss: 5.969484329223633
training step: 16649, total_loss: 5.1495680809021
training step: 16650, total_loss: 5.300736427307129
training step: 16651, total_loss: 5.583620071411133
training step: 16652, total_loss: 4.825286865234375
training step: 16653, total_loss: 4.114325523376465
training step: 16654, total_loss: 5.360548973083496
training step: 16655, total_loss: 3.88328218460083
training step: 16656, total_loss: 4.2670111656188965
training step: 16657, total_loss: 5.241623878479004
training step: 16658, total_loss: 4.297895908355713
training step: 16659, total_loss: 4.673751354217529
training step: 16660, total_loss: 4.796481132507324
training step: 16661, total_loss: 2.697600841522217
training step: 16662, total_loss: 4.3057146072387695
training step: 16663, total_loss: 5.555850505828857
training step: 16664, total_loss: 5.9379353523254395
training step: 16665, total_loss: 3.8314146995544434
training step: 16666, total_loss: 5.24272346496582
training step: 16667, total_loss: 4.306889533996582
training step: 16668, total_loss: 3.4010419845581055
training step: 16669, total_loss: 3.4383857250213623
training step: 16670, total_loss: 3.2940797805786133
training step: 16671, total_loss: 4.688660621643066
training step: 16672, total_loss: 3.3086228370666504
training step: 16673, total_loss: 4.967800617218018
training step: 16674, total_loss: 3.7284836769104004
training step: 16675, total_loss: 5.871195316314697
training step: 16676, total_loss: 4.004494667053223
training step: 16677, total_loss: 5.870083808898926
training step: 16678, total_loss: 5.238243103027344
training step: 16679, total_loss: 3.985488176345825
training step: 16680, total_loss: 4.751681327819824
training step: 16681, total_loss: 3.574557304382324
training step: 16682, total_loss: 4.4500203132629395
training step: 16683, total_loss: 3.794072151184082
training step: 16684, total_loss: 3.8489723205566406
training step: 16685, total_loss: 5.37989616394043
training step: 16686, total_loss: 5.25299596786499
training step: 16687, total_loss: 3.884659767150879
training step: 16688, total_loss: 3.9915711879730225
training step: 16689, total_loss: 5.6471405029296875
training step: 16690, total_loss: 5.323822975158691
training step: 16691, total_loss: 3.500826835632324
training step: 16692, total_loss: 4.519132137298584
training step: 16693, total_loss: 3.7657175064086914
training step: 16694, total_loss: 1.4031412601470947
training step: 16695, total_loss: 5.3373703956604
training step: 16696, total_loss: 4.39640998840332
training step: 16697, total_loss: 3.030642032623291
training step: 16698, total_loss: 5.839559555053711
training step: 16699, total_loss: 4.931119441986084
training step: 16700, total_loss: 1.9251219034194946
training step: 16701, total_loss: 4.488166809082031
training step: 16702, total_loss: 1.0872611999511719
training step: 16703, total_loss: 4.660908222198486
training step: 16704, total_loss: 5.844965934753418
training step: 16705, total_loss: 5.312533378601074
training step: 16706, total_loss: 5.852038383483887
training step: 16707, total_loss: 5.416172981262207
training step: 16708, total_loss: 4.973909854888916
training step: 16709, total_loss: 4.210076808929443
training step: 16710, total_loss: 4.033840656280518
training step: 16711, total_loss: 5.184159278869629
training step: 16712, total_loss: 5.32843017578125
training step: 16713, total_loss: 4.902462482452393
training step: 16714, total_loss: 4.924808502197266
training step: 16715, total_loss: 3.571134567260742
training step: 16716, total_loss: 6.201311111450195
training step: 16717, total_loss: 4.63719367980957
training step: 16718, total_loss: 5.098562240600586
training step: 16719, total_loss: 4.940983295440674
training step: 16720, total_loss: 4.757100582122803
training step: 16721, total_loss: 3.1441807746887207
training step: 16722, total_loss: 3.3491311073303223
training step: 16723, total_loss: 3.3987300395965576
training step: 16724, total_loss: 3.6490187644958496
training step: 16725, total_loss: 3.8926074504852295
training step: 16726, total_loss: 5.371828079223633
training step: 16727, total_loss: 1.8691272735595703
training step: 16728, total_loss: 6.078024387359619
training step: 16729, total_loss: 4.509072303771973
training step: 16730, total_loss: 3.5199713706970215
training step: 16731, total_loss: 4.887307167053223
training step: 16732, total_loss: 3.7335991859436035
training step: 16733, total_loss: 4.957947254180908
training step: 16734, total_loss: 4.20974588394165
training step: 16735, total_loss: 4.257427215576172
training step: 16736, total_loss: 4.921021461486816
training step: 16737, total_loss: 4.9566650390625
training step: 16738, total_loss: 1.6140704154968262
training step: 16739, total_loss: 6.902865886688232
training step: 16740, total_loss: 4.6991376876831055
training step: 16741, total_loss: 4.002710342407227
training step: 16742, total_loss: 3.8328871726989746
training step: 16743, total_loss: 4.086056709289551
training step: 16744, total_loss: 4.475729942321777
training step: 16745, total_loss: 3.597162961959839
training step: 16746, total_loss: 4.879255294799805
training step: 16747, total_loss: 4.72162389755249
training step: 16748, total_loss: 4.419219493865967
training step: 16749, total_loss: 4.939986228942871
training step: 16750, total_loss: 3.9845666885375977
training step: 16751, total_loss: 4.732496738433838
training step: 16752, total_loss: 5.659720420837402
training step: 16753, total_loss: 4.635427474975586
training step: 16754, total_loss: 4.143082618713379
training step: 16755, total_loss: 3.912749767303467
training step: 16756, total_loss: 1.2233060598373413
training step: 16757, total_loss: 3.999650001525879
training step: 16758, total_loss: 3.966585159301758
training step: 16759, total_loss: 3.81524395942688
training step: 16760, total_loss: 3.977598190307617
training step: 16761, total_loss: 5.254277229309082
training step: 16762, total_loss: 5.166632175445557
training step: 16763, total_loss: 2.9120371341705322
training step: 16764, total_loss: 3.733274459838867
training step: 16765, total_loss: 4.036920547485352
training step: 16766, total_loss: 4.320343017578125
training step: 16767, total_loss: 4.9443864822387695
training step: 16768, total_loss: 3.9669339656829834
training step: 16769, total_loss: 3.3288471698760986
training step: 16770, total_loss: 2.27117657661438
training step: 16771, total_loss: 4.125435829162598
training step: 16772, total_loss: 3.208019733428955
training step: 16773, total_loss: 1.721410870552063
training step: 16774, total_loss: 5.962130546569824
training step: 16775, total_loss: 4.23271369934082
training step: 16776, total_loss: 3.8875977993011475
training step: 16777, total_loss: 2.934075355529785
training step: 16778, total_loss: 6.0270538330078125
training step: 16779, total_loss: 3.518615245819092
training step: 16780, total_loss: 4.181144714355469
training step: 16781, total_loss: 4.675542831420898
training step: 16782, total_loss: 3.2934370040893555
training step: 16783, total_loss: 3.364276885986328
training step: 16784, total_loss: 4.606599807739258
training step: 16785, total_loss: 6.770944595336914
training step: 16786, total_loss: 0.8693039417266846
training step: 16787, total_loss: 5.76362419128418
training step: 16788, total_loss: 6.097659111022949
training step: 16789, total_loss: 4.080301284790039
training step: 16790, total_loss: 4.6840925216674805
training step: 16791, total_loss: 2.62642765045166
training step: 16792, total_loss: 4.44795036315918
training step: 16793, total_loss: 4.542910099029541
training step: 16794, total_loss: 5.445019721984863
training step: 16795, total_loss: 3.9940762519836426
training step: 16796, total_loss: 4.678292274475098
training step: 16797, total_loss: 4.4571099281311035
training step: 16798, total_loss: 4.947662830352783
training step: 16799, total_loss: 2.7721164226531982
training step: 16800, total_loss: 5.1217756271362305
training step: 16801, total_loss: 5.569066047668457
training step: 16802, total_loss: 4.420067310333252
training step: 16803, total_loss: 4.699927806854248
training step: 16804, total_loss: 6.039663314819336
training step: 16805, total_loss: 5.08712100982666
training step: 16806, total_loss: 3.7467641830444336
training step: 16807, total_loss: 5.101662635803223
training step: 16808, total_loss: 5.8216657638549805
training step: 16809, total_loss: 4.182580947875977
training step: 16810, total_loss: 5.4177727699279785
training step: 16811, total_loss: 3.5433783531188965
training step: 16812, total_loss: 5.261565208435059
training step: 16813, total_loss: 3.410903215408325
training step: 16814, total_loss: 4.294032573699951
training step: 16815, total_loss: 4.3739471435546875
training step: 16816, total_loss: 4.876605987548828
training step: 16817, total_loss: 5.679791450500488
training step: 16818, total_loss: 4.311705112457275
training step: 16819, total_loss: 4.6333699226379395
training step: 16820, total_loss: 4.034237384796143
training step: 16821, total_loss: 4.203093528747559
training step: 16822, total_loss: 4.078333377838135
training step: 16823, total_loss: 4.7612762451171875
training step: 16824, total_loss: 4.297724723815918
training step: 16825, total_loss: 5.858120441436768
training step: 16826, total_loss: 4.0785675048828125
training step: 16827, total_loss: 1.1896255016326904
training step: 16828, total_loss: 6.077942371368408
training step: 16829, total_loss: 3.398679733276367
training step: 16830, total_loss: 4.844724178314209
training step: 16831, total_loss: 4.055722713470459
training step: 16832, total_loss: 5.55838680267334
training step: 16833, total_loss: 5.810667037963867
training step: 16834, total_loss: 4.341437339782715
training step: 16835, total_loss: 3.498436212539673
training step: 16836, total_loss: 3.434095859527588
training step: 16837, total_loss: 4.202630519866943
training step: 16838, total_loss: 3.173748254776001
training step: 16839, total_loss: 3.4656569957733154
training step: 16840, total_loss: 5.389662742614746
training step: 16841, total_loss: 4.768674850463867
training step: 16842, total_loss: 4.397026062011719
training step: 16843, total_loss: 5.605905532836914
training step: 16844, total_loss: 3.8453118801116943
training step: 16845, total_loss: 3.7111048698425293
training step: 16846, total_loss: 3.1398653984069824
training step: 16847, total_loss: 3.8860254287719727
training step: 16848, total_loss: 3.4558920860290527
training step: 16849, total_loss: 4.619829177856445
training step: 16850, total_loss: 6.202795505523682
training step: 16851, total_loss: 3.901872396469116
training step: 16852, total_loss: 4.158690452575684
training step: 16853, total_loss: 4.576229095458984
training step: 16854, total_loss: 3.8067617416381836
training step: 16855, total_loss: 5.042483329772949
training step: 16856, total_loss: 2.9420056343078613
training step: 16857, total_loss: 4.719756126403809
training step: 16858, total_loss: 5.8015055656433105
training step: 16859, total_loss: 3.7232816219329834
training step: 16860, total_loss: 4.792448997497559
training step: 16861, total_loss: 4.45578145980835
training step: 16862, total_loss: 5.285000324249268
training step: 16863, total_loss: 1.4598661661148071
training step: 16864, total_loss: 4.235166549682617
training step: 16865, total_loss: 5.335170269012451
training step: 16866, total_loss: 5.075657844543457
training step: 16867, total_loss: 4.227845191955566
training step: 16868, total_loss: 4.902439117431641
training step: 16869, total_loss: 5.192699432373047
training step: 16870, total_loss: 4.043158531188965
training step: 16871, total_loss: 4.536446571350098
training step: 16872, total_loss: 5.944443225860596
training step: 16873, total_loss: 4.653233528137207
training step: 16874, total_loss: 4.353350639343262
training step: 16875, total_loss: 1.6425652503967285
training step: 16876, total_loss: 5.488424777984619
training step: 16877, total_loss: 6.233354568481445
training step: 16878, total_loss: 4.553560733795166
training step: 16879, total_loss: 3.6388635635375977
training step: 16880, total_loss: 4.684494972229004
training step: 16881, total_loss: 4.080021381378174
training step: 16882, total_loss: 4.464474678039551
training step: 16883, total_loss: 5.171534061431885
training step: 16884, total_loss: 5.846897125244141
training step: 16885, total_loss: 5.538338661193848
training step: 16886, total_loss: 4.434658050537109
training step: 16887, total_loss: 4.911214828491211
training step: 16888, total_loss: 5.755946636199951
training step: 16889, total_loss: 1.0619796514511108
training step: 16890, total_loss: 2.4391069412231445
training step: 16891, total_loss: 4.562124729156494
training step: 16892, total_loss: 4.406668186187744
training step: 16893, total_loss: 0.9100285172462463
training step: 16894, total_loss: 5.895692825317383
training step: 16895, total_loss: 5.547263145446777
training step: 16896, total_loss: 5.23256778717041
training step: 16897, total_loss: 3.4256420135498047
training step: 16898, total_loss: 5.133370399475098
training step: 16899, total_loss: 4.444580078125
training step: 16900, total_loss: 4.217503547668457
training step: 16901, total_loss: 3.100584030151367
training step: 16902, total_loss: 4.731273174285889
training step: 16903, total_loss: 5.191542148590088
training step: 16904, total_loss: 3.35330867767334
training step: 16905, total_loss: 2.6940255165100098
training step: 16906, total_loss: 5.29555082321167
training step: 16907, total_loss: 4.423673629760742
training step: 16908, total_loss: 5.368370532989502
training step: 16909, total_loss: 4.249365329742432
training step: 16910, total_loss: 4.091271877288818
training step: 16911, total_loss: 4.461464881896973
training step: 16912, total_loss: 5.766933917999268
training step: 16913, total_loss: 4.433608055114746
training step: 16914, total_loss: 5.294951438903809
training step: 16915, total_loss: 6.124451637268066
training step: 16916, total_loss: 4.339294910430908
training step: 16917, total_loss: 4.811616897583008
training step: 16918, total_loss: 4.098821640014648
training step: 16919, total_loss: 5.06668758392334
training step: 16920, total_loss: 3.3775031566619873
training step: 16921, total_loss: 2.8754701614379883
training step: 16922, total_loss: 5.930212020874023
training step: 16923, total_loss: 4.63720703125
training step: 16924, total_loss: 5.6464996337890625
training step: 16925, total_loss: 4.726509094238281
training step: 16926, total_loss: 4.242751121520996
training step: 16927, total_loss: 4.969712257385254
training step: 16928, total_loss: 4.974320411682129
training step: 16929, total_loss: 4.641965866088867
training step: 16930, total_loss: 4.399975299835205
training step: 16931, total_loss: 6.606878280639648
training step: 16932, total_loss: 1.2813119888305664
training step: 16933, total_loss: 6.410898208618164
training step: 16934, total_loss: 5.8552727699279785
training step: 16935, total_loss: 4.488828659057617
training step: 16936, total_loss: 4.683340072631836
training step: 16937, total_loss: 4.557676315307617
training step: 16938, total_loss: 4.922197341918945
training step: 16939, total_loss: 4.397288799285889
training step: 16940, total_loss: 5.847417831420898
training step: 16941, total_loss: 5.068656921386719
training step: 16942, total_loss: 5.063213348388672
training step: 16943, total_loss: 5.8055739402771
training step: 16944, total_loss: 5.89327335357666
training step: 16945, total_loss: 1.25779128074646
training step: 16946, total_loss: 5.280413627624512
training step: 16947, total_loss: 5.073605537414551
training step: 16948, total_loss: 4.190499305725098
training step: 16949, total_loss: 3.6036558151245117
training step: 16950, total_loss: 4.396739959716797
training step: 16951, total_loss: 4.622801780700684
training step: 16952, total_loss: 4.350640773773193
training step: 16953, total_loss: 4.926529884338379
training step: 16954, total_loss: 3.5183749198913574
training step: 16955, total_loss: 4.65798282623291
training step: 16956, total_loss: 3.797431468963623
training step: 16957, total_loss: 3.7168054580688477
training step: 16958, total_loss: 4.071438312530518
training step: 16959, total_loss: 4.479238510131836
training step: 16960, total_loss: 3.557274580001831
training step: 16961, total_loss: 5.6619462966918945
training step: 16962, total_loss: 3.4946298599243164
training step: 16963, total_loss: 3.482734203338623
training step: 16964, total_loss: 5.628631591796875
training step: 16965, total_loss: 4.924623489379883
training step: 16966, total_loss: 5.1981048583984375
training step: 16967, total_loss: 4.5940446853637695
training step: 16968, total_loss: 4.882101058959961
training step: 16969, total_loss: 5.408894062042236
training step: 16970, total_loss: 6.113213539123535
training step: 16971, total_loss: 5.114640235900879
training step: 16972, total_loss: 1.3957545757293701
training step: 16973, total_loss: 5.557159900665283
training step: 16974, total_loss: 5.963016986846924
training step: 16975, total_loss: 2.365802764892578
training step: 16976, total_loss: 5.735043048858643
training step: 16977, total_loss: 2.584613800048828
training step: 16978, total_loss: 3.894646406173706
training step: 16979, total_loss: 4.852900505065918
training step: 16980, total_loss: 3.9153404235839844
training step: 16981, total_loss: 4.955302715301514
training step: 16982, total_loss: 4.184086322784424
training step: 16983, total_loss: 3.314507007598877
training step: 16984, total_loss: 4.719233512878418
training step: 16985, total_loss: 4.012260913848877
training step: 16986, total_loss: 4.0191545486450195
training step: 16987, total_loss: 3.8648252487182617
training step: 16988, total_loss: 4.103346347808838
training step: 16989, total_loss: 4.427809715270996
training step: 16990, total_loss: 3.6707890033721924
training step: 16991, total_loss: 3.9803452491760254
training step: 16992, total_loss: 3.474870204925537
training step: 16993, total_loss: 4.512770652770996
training step: 16994, total_loss: 0.9493186473846436
training step: 16995, total_loss: 3.5756096839904785
training step: 16996, total_loss: 3.8792824745178223
training step: 16997, total_loss: 4.35335111618042
training step: 16998, total_loss: 4.70607852935791
training step: 16999, total_loss: 2.3017873764038086
training step: 17000, total_loss: 3.76308012008667
training step: 17001, total_loss: 5.004827499389648
training step: 17002, total_loss: 4.870428562164307
training step: 17003, total_loss: 4.661931991577148
training step: 17004, total_loss: 4.299433708190918
training step: 17005, total_loss: 2.855985164642334
training step: 17006, total_loss: 5.859130382537842
training step: 17007, total_loss: 4.02154541015625
training step: 17008, total_loss: 5.1693434715271
training step: 17009, total_loss: 3.0647332668304443
training step: 17010, total_loss: 4.886215686798096
training step: 17011, total_loss: 5.09888219833374
training step: 17012, total_loss: 6.704093933105469
training step: 17013, total_loss: 3.857404947280884
training step: 17014, total_loss: 5.087885856628418
training step: 17015, total_loss: 3.9031920433044434
training step: 17016, total_loss: 4.932871341705322
training step: 17017, total_loss: 3.4839062690734863
training step: 17018, total_loss: 4.335675239562988
training step: 17019, total_loss: 4.411248683929443
training step: 17020, total_loss: 3.808370590209961
training step: 17021, total_loss: 3.934525489807129
training step: 17022, total_loss: 5.10096549987793
training step: 17023, total_loss: 5.653654098510742
training step: 17024, total_loss: 5.3921427726745605
training step: 17025, total_loss: 4.98093843460083
training step: 17026, total_loss: 5.471315860748291
training step: 17027, total_loss: 4.784520626068115
training step: 17028, total_loss: 5.148611068725586
training step: 17029, total_loss: 5.436071395874023
training step: 17030, total_loss: 5.101263999938965
training step: 17031, total_loss: 5.120758056640625
training step: 17032, total_loss: 0.7796884775161743
training step: 17033, total_loss: 4.362735271453857
training step: 17034, total_loss: 5.427043437957764
training step: 17035, total_loss: 4.024285316467285
training step: 17036, total_loss: 4.951768398284912
training step: 17037, total_loss: 3.932507038116455
training step: 17038, total_loss: 5.790994644165039
training step: 17039, total_loss: 5.254742622375488
training step: 17040, total_loss: 3.916750431060791
training step: 17041, total_loss: 4.781907558441162
training step: 17042, total_loss: 4.196167945861816
training step: 17043, total_loss: 0.7105894088745117
training step: 17044, total_loss: 3.1032960414886475
training step: 17045, total_loss: 3.2928624153137207
training step: 17046, total_loss: 2.4660818576812744
training step: 17047, total_loss: 5.885694980621338
training step: 17048, total_loss: 5.545205116271973
training step: 17049, total_loss: 4.830976486206055
training step: 17050, total_loss: 5.501933574676514
training step: 17051, total_loss: 4.46176815032959
training step: 17052, total_loss: 4.819721698760986
training step: 17053, total_loss: 2.368662118911743
training step: 17054, total_loss: 5.521655082702637
training step: 17055, total_loss: 5.544528484344482
training step: 17056, total_loss: 4.895509243011475
training step: 17057, total_loss: 6.530553817749023
training step: 17058, total_loss: 5.295928001403809
training step: 17059, total_loss: 5.5901360511779785
training step: 17060, total_loss: 4.397418975830078
training step: 17061, total_loss: 5.630007743835449
training step: 17062, total_loss: 4.405886650085449
training step: 17063, total_loss: 4.344367980957031
training step: 17064, total_loss: 4.793747901916504
training step: 17065, total_loss: 4.970452785491943
training step: 17066, total_loss: 5.031649112701416
training step: 17067, total_loss: 3.874087333679199
training step: 17068, total_loss: 4.690907955169678
training step: 17069, total_loss: 3.707634687423706
training step: 17070, total_loss: 5.905876159667969
training step: 17071, total_loss: 0.7924249172210693
training step: 17072, total_loss: 4.771288871765137
training step: 17073, total_loss: 4.916077613830566
training step: 17074, total_loss: 5.074365615844727
training step: 17075, total_loss: 4.642784118652344
training step: 17076, total_loss: 4.241580486297607
training step: 17077, total_loss: 4.988204002380371
training step: 17078, total_loss: 6.425439357757568
training step: 17079, total_loss: 5.237191200256348
training step: 17080, total_loss: 3.8780806064605713
training step: 17081, total_loss: 5.450512886047363
training step: 17082, total_loss: 4.970159530639648
training step: 17083, total_loss: 5.021757125854492
training step: 17084, total_loss: 4.713789463043213
training step: 17085, total_loss: 4.701689720153809
training step: 17086, total_loss: 5.900341987609863
training step: 17087, total_loss: 5.7946038246154785
training step: 17088, total_loss: 5.474881172180176
training step: 17089, total_loss: 5.414798259735107
training step: 17090, total_loss: 3.8424432277679443
training step: 17091, total_loss: 4.6658935546875
training step: 17092, total_loss: 6.257220268249512
training step: 17093, total_loss: 4.037164688110352
training step: 17094, total_loss: 3.6214144229888916
training step: 17095, total_loss: 4.352779865264893
training step: 17096, total_loss: 3.1735129356384277
training step: 17097, total_loss: 4.192681312561035
training step: 17098, total_loss: 5.296342849731445
training step: 17099, total_loss: 6.257506370544434
training step: 17100, total_loss: 4.437821865081787
training step: 17101, total_loss: 5.587446689605713
training step: 17102, total_loss: 4.97281551361084
training step: 17103, total_loss: 5.088765621185303
training step: 17104, total_loss: 6.092917442321777
training step: 17105, total_loss: 4.9805192947387695
training step: 17106, total_loss: 4.159695148468018
training step: 17107, total_loss: 3.1862988471984863
training step: 17108, total_loss: 6.556157112121582
training step: 17109, total_loss: 3.5657787322998047
training step: 17110, total_loss: 4.451371192932129
training step: 17111, total_loss: 3.5516693592071533
training step: 17112, total_loss: 4.393462181091309
training step: 17113, total_loss: 4.277239799499512
training step: 17114, total_loss: 6.542171478271484
training step: 17115, total_loss: 4.465837478637695
training step: 17116, total_loss: 4.318597793579102
training step: 17117, total_loss: 5.102461338043213
training step: 17118, total_loss: 4.8082275390625
training step: 17119, total_loss: 3.3397750854492188
training step: 17120, total_loss: 4.283693313598633
training step: 17121, total_loss: 5.111074447631836
training step: 17122, total_loss: 4.638601779937744
training step: 17123, total_loss: 5.223767280578613
training step: 17124, total_loss: 5.488428592681885
training step: 17125, total_loss: 4.955761432647705
training step: 17126, total_loss: 4.321897029876709
training step: 17127, total_loss: 4.161149024963379
training step: 17128, total_loss: 4.121567726135254
training step: 17129, total_loss: 5.619501113891602
training step: 17130, total_loss: 4.7078351974487305
training step: 17131, total_loss: 1.606186866760254
training step: 17132, total_loss: 4.5020751953125
training step: 17133, total_loss: 5.610161781311035
training step: 17134, total_loss: 4.271117210388184
training step: 17135, total_loss: 5.107461452484131
training step: 17136, total_loss: 4.076168537139893
training step: 17137, total_loss: 4.441339492797852
training step: 17138, total_loss: 4.446333885192871
training step: 17139, total_loss: 4.258708953857422
training step: 17140, total_loss: 4.484440803527832
training step: 17141, total_loss: 3.7142887115478516
training step: 17142, total_loss: 4.2067108154296875
training step: 17143, total_loss: 3.8903188705444336
training step: 17144, total_loss: 5.493953227996826
training step: 17145, total_loss: 4.545311450958252
training step: 17146, total_loss: 6.089804649353027
training step: 17147, total_loss: 2.3648858070373535
training step: 17148, total_loss: 4.852472305297852
training step: 17149, total_loss: 4.186824798583984
training step: 17150, total_loss: 5.068760871887207
training step: 17151, total_loss: 6.1190338134765625
training step: 17152, total_loss: 4.37315559387207
training step: 17153, total_loss: 4.470423698425293
training step: 17154, total_loss: 4.56739616394043
training step: 17155, total_loss: 5.232436180114746
training step: 17156, total_loss: 4.676163673400879
training step: 17157, total_loss: 4.938083648681641
training step: 17158, total_loss: 2.934192180633545
training step: 17159, total_loss: 4.496081352233887
training step: 17160, total_loss: 4.783694267272949
training step: 17161, total_loss: 4.739314556121826
training step: 17162, total_loss: 4.730635643005371
training step: 17163, total_loss: 5.474939346313477
training step: 17164, total_loss: 5.773979187011719
training step: 17165, total_loss: 4.545506477355957
training step: 17166, total_loss: 5.586495399475098
training step: 17167, total_loss: 3.8779497146606445
training step: 17168, total_loss: 3.512934684753418
training step: 17169, total_loss: 5.6204142570495605
training step: 17170, total_loss: 4.699605941772461
training step: 17171, total_loss: 3.8823323249816895
training step: 17172, total_loss: 3.6517841815948486
training step: 17173, total_loss: 4.261704921722412
training step: 17174, total_loss: 3.8313262462615967
training step: 17175, total_loss: 4.015979766845703
training step: 17176, total_loss: 5.805172920227051
training step: 17177, total_loss: 4.341524600982666
training step: 17178, total_loss: 4.666249752044678
training step: 17179, total_loss: 3.779323101043701
training step: 17180, total_loss: 5.506579399108887
training step: 17181, total_loss: 4.3339385986328125
training step: 17182, total_loss: 4.748522758483887
training step: 17183, total_loss: 4.285715103149414
training step: 17184, total_loss: 4.531981945037842
training step: 17185, total_loss: 5.392426490783691
training step: 17186, total_loss: 4.539292812347412
training step: 17187, total_loss: 5.0145978927612305
training step: 17188, total_loss: 2.947556734085083
training step: 17189, total_loss: 4.0704851150512695
training step: 17190, total_loss: 4.0830583572387695
training step: 17191, total_loss: 4.193643569946289
training step: 17192, total_loss: 2.834836006164551
training step: 17193, total_loss: 4.8123016357421875
training step: 17194, total_loss: 5.5229692459106445
training step: 17195, total_loss: 4.1577348709106445
training step: 17196, total_loss: 4.80048131942749
training step: 17197, total_loss: 4.562530994415283
training step: 17198, total_loss: 4.9720354080200195
training step: 17199, total_loss: 4.4473066329956055
training step: 17200, total_loss: 3.7465662956237793
training step: 17201, total_loss: 4.477841377258301
training step: 17202, total_loss: 5.222116947174072
training step: 17203, total_loss: 4.423429489135742
training step: 17204, total_loss: 4.730360984802246
training step: 17205, total_loss: 4.6926045417785645
training step: 17206, total_loss: 5.25515079498291
training step: 17207, total_loss: 3.858842372894287
training step: 17208, total_loss: 6.104707717895508
training step: 17209, total_loss: 3.466113567352295
training step: 17210, total_loss: 5.547987937927246
training step: 17211, total_loss: 5.176992416381836
training step: 17212, total_loss: 3.0829081535339355
training step: 17213, total_loss: 4.942749977111816
training step: 17214, total_loss: 3.956871509552002
training step: 17215, total_loss: 2.8683691024780273
training step: 17216, total_loss: 3.676647663116455
training step: 17217, total_loss: 4.424770355224609
training step: 17218, total_loss: 5.517945766448975
training step: 17219, total_loss: 5.765597343444824
training step: 17220, total_loss: 4.067118167877197
training step: 17221, total_loss: 4.635575294494629
training step: 17222, total_loss: 4.516214847564697
training step: 17223, total_loss: 4.802485942840576
training step: 17224, total_loss: 4.981585502624512
training step: 17225, total_loss: 4.238088130950928
training step: 17226, total_loss: 4.188105583190918
training step: 17227, total_loss: 4.325766563415527
training step: 17228, total_loss: 3.4640774726867676
training step: 17229, total_loss: 5.901623725891113
training step: 17230, total_loss: 3.537348508834839
training step: 17231, total_loss: 4.8128838539123535
training step: 17232, total_loss: 4.619589328765869
training step: 17233, total_loss: 3.6895108222961426
training step: 17234, total_loss: 4.299157619476318
training step: 17235, total_loss: 4.334306240081787
training step: 17236, total_loss: 3.8942229747772217
training step: 17237, total_loss: 4.937498092651367
training step: 17238, total_loss: 5.80674934387207
training step: 17239, total_loss: 5.062555313110352
training step: 17240, total_loss: 2.673478841781616
training step: 17241, total_loss: 3.7360761165618896
training step: 17242, total_loss: 4.778923034667969
training step: 17243, total_loss: 5.521479606628418
training step: 17244, total_loss: 4.715982437133789
training step: 17245, total_loss: 5.68229866027832
training step: 17246, total_loss: 3.7722697257995605
training step: 17247, total_loss: 6.069382667541504
training step: 17248, total_loss: 4.108798027038574
training step: 17249, total_loss: 4.729801177978516
training step: 17250, total_loss: 5.043586730957031
training step: 17251, total_loss: 2.6267828941345215
training step: 17252, total_loss: 4.118951797485352
training step: 17253, total_loss: 4.54252815246582
training step: 17254, total_loss: 4.314673900604248
training step: 17255, total_loss: 6.386501312255859
training step: 17256, total_loss: 5.290132999420166
training step: 17257, total_loss: 5.6799774169921875
training step: 17258, total_loss: 4.260041236877441
training step: 17259, total_loss: 2.684842348098755
training step: 17260, total_loss: 4.762190818786621
training step: 17261, total_loss: 4.479691028594971
training step: 17262, total_loss: 4.121318340301514
training step: 17263, total_loss: 3.3836116790771484
training step: 17264, total_loss: 3.6237049102783203
training step: 17265, total_loss: 4.304816246032715
training step: 17266, total_loss: 3.727410316467285
training step: 17267, total_loss: 4.993649005889893
training step: 17268, total_loss: 4.187624454498291
training step: 17269, total_loss: 3.571147918701172
training step: 17270, total_loss: 3.6477904319763184
training step: 17271, total_loss: 2.7052643299102783
training step: 17272, total_loss: 4.066739082336426
training step: 17273, total_loss: 4.91721248626709
training step: 17274, total_loss: 4.09599494934082
training step: 17275, total_loss: 2.537161111831665
training step: 17276, total_loss: 4.425335884094238
training step: 17277, total_loss: 3.7801566123962402
training step: 17278, total_loss: 4.126431941986084
training step: 17279, total_loss: 5.103885650634766
training step: 17280, total_loss: 1.2271676063537598
training step: 17281, total_loss: 1.2513047456741333
training step: 17282, total_loss: 3.5600080490112305
training step: 17283, total_loss: 4.6437177658081055
training step: 17284, total_loss: 3.632143974304199
training step: 17285, total_loss: 5.07697868347168
training step: 17286, total_loss: 4.614614963531494
training step: 17287, total_loss: 4.932644367218018
training step: 17288, total_loss: 4.7019500732421875
training step: 17289, total_loss: 4.401661396026611
training step: 17290, total_loss: 4.713675022125244
training step: 17291, total_loss: 6.145897388458252
training step: 17292, total_loss: 4.976369857788086
training step: 17293, total_loss: 4.0654296875
training step: 17294, total_loss: 4.853516578674316
training step: 17295, total_loss: 4.182379722595215
training step: 17296, total_loss: 4.16684627532959
training step: 17297, total_loss: 4.209096908569336
training step: 17298, total_loss: 6.388542652130127
training step: 17299, total_loss: 4.8138017654418945
training step: 17300, total_loss: 2.6106350421905518
training step: 17301, total_loss: 1.0651124715805054
training step: 17302, total_loss: 5.23043155670166
training step: 17303, total_loss: 4.255011558532715
training step: 17304, total_loss: 4.987464904785156
training step: 17305, total_loss: 4.079401969909668
training step: 17306, total_loss: 4.735944747924805
training step: 17307, total_loss: 4.301753044128418
training step: 17308, total_loss: 5.08296012878418
training step: 17309, total_loss: 3.8699328899383545
training step: 17310, total_loss: 4.605720520019531
training step: 17311, total_loss: 5.47424840927124
training step: 17312, total_loss: 4.385136127471924
training step: 17313, total_loss: 3.5281190872192383
training step: 17314, total_loss: 5.324995040893555
training step: 17315, total_loss: 3.8884787559509277
training step: 17316, total_loss: 3.8186521530151367
training step: 17317, total_loss: 6.0277557373046875
training step: 17318, total_loss: 1.8408339023590088
training step: 17319, total_loss: 3.8883769512176514
training step: 17320, total_loss: 4.943699359893799
training step: 17321, total_loss: 4.105897426605225
training step: 17322, total_loss: 5.196111679077148
training step: 17323, total_loss: 5.313928604125977
training step: 17324, total_loss: 4.514743804931641
training step: 17325, total_loss: 4.765928268432617
training step: 17326, total_loss: 6.309330940246582
training step: 17327, total_loss: 4.765381813049316
training step: 17328, total_loss: 3.6507420539855957
training step: 17329, total_loss: 2.8802926540374756
training step: 17330, total_loss: 1.3482370376586914
training step: 17331, total_loss: 4.0371856689453125
training step: 17332, total_loss: 4.927572250366211
training step: 17333, total_loss: 6.798943519592285
training step: 17334, total_loss: 4.184563636779785
training step: 17335, total_loss: 4.56141996383667
training step: 17336, total_loss: 5.003132343292236
training step: 17337, total_loss: 7.201204776763916
training step: 17338, total_loss: 4.003809928894043
training step: 17339, total_loss: 4.916008472442627
training step: 17340, total_loss: 3.580651044845581
training step: 17341, total_loss: 4.395320892333984
training step: 17342, total_loss: 1.0497148036956787
training step: 17343, total_loss: 4.0661845207214355
training step: 17344, total_loss: 4.687849044799805
training step: 17345, total_loss: 4.956233978271484
training step: 17346, total_loss: 2.4397614002227783
training step: 17347, total_loss: 4.238744735717773
training step: 17348, total_loss: 5.26796817779541
training step: 17349, total_loss: 5.280778884887695
training step: 17350, total_loss: 3.173914909362793
training step: 17351, total_loss: 4.014795303344727
training step: 17352, total_loss: 4.4655232429504395
training step: 17353, total_loss: 5.160411834716797
training step: 17354, total_loss: 3.981058359146118
training step: 17355, total_loss: 3.7705020904541016
training step: 17356, total_loss: 4.739903926849365
training step: 17357, total_loss: 4.496124267578125
training step: 17358, total_loss: 3.143465518951416
training step: 17359, total_loss: 4.364847183227539
training step: 17360, total_loss: 4.498092174530029
training step: 17361, total_loss: 4.973455905914307
training step: 17362, total_loss: 5.7238287925720215
training step: 17363, total_loss: 6.124144554138184
training step: 17364, total_loss: 4.829768180847168
training step: 17365, total_loss: 4.553030014038086
training step: 17366, total_loss: 5.9929399490356445
training step: 17367, total_loss: 6.634768009185791
training step: 17368, total_loss: 3.720770835876465
training step: 17369, total_loss: 4.086538791656494
training step: 17370, total_loss: 4.5041093826293945
training step: 17371, total_loss: 4.7599310874938965
training step: 17372, total_loss: 6.117044448852539
training step: 17373, total_loss: 5.645791530609131
training step: 17374, total_loss: 4.600562572479248
training step: 17375, total_loss: 3.4896504878997803
training step: 17376, total_loss: 1.5723788738250732
training step: 17377, total_loss: 3.7267420291900635
training step: 17378, total_loss: 3.5853090286254883
training step: 17379, total_loss: 3.599148750305176
training step: 17380, total_loss: 3.7447028160095215
training step: 17381, total_loss: 3.6453566551208496
training step: 17382, total_loss: 4.761266708374023
training step: 17383, total_loss: 3.8657078742980957
training step: 17384, total_loss: 4.553042888641357
training step: 17385, total_loss: 1.765797734260559
training step: 17386, total_loss: 3.5819482803344727
training step: 17387, total_loss: 2.0836799144744873
training step: 17388, total_loss: 4.167876720428467
training step: 17389, total_loss: 5.102835178375244
training step: 17390, total_loss: 5.418769359588623
training step: 17391, total_loss: 5.409111022949219
training step: 17392, total_loss: 3.804302215576172
training step: 17393, total_loss: 4.885064125061035
training step: 17394, total_loss: 5.010248184204102
training step: 17395, total_loss: 6.957045555114746
training step: 17396, total_loss: 3.2978901863098145
training step: 17397, total_loss: 4.193534851074219
training step: 17398, total_loss: 2.9732837677001953
training step: 17399, total_loss: 4.346025466918945
training step: 17400, total_loss: 3.2140541076660156
training step: 17401, total_loss: 3.5969738960266113
training step: 17402, total_loss: 4.349628448486328
training step: 17403, total_loss: 3.9916117191314697
training step: 17404, total_loss: 4.173749923706055
training step: 17405, total_loss: 2.374305009841919
training step: 17406, total_loss: 5.582527160644531
training step: 17407, total_loss: 3.5255684852600098
training step: 17408, total_loss: 3.914557456970215
training step: 17409, total_loss: 4.771700382232666
training step: 17410, total_loss: 3.744274377822876
training step: 17411, total_loss: 4.562887191772461
training step: 17412, total_loss: 4.458168983459473
training step: 17413, total_loss: 2.83319091796875
training step: 17414, total_loss: 0.9293427467346191
training step: 17415, total_loss: 5.490840911865234
training step: 17416, total_loss: 6.120265960693359
training step: 17417, total_loss: 4.6952314376831055
training step: 17418, total_loss: 3.456368923187256
training step: 17419, total_loss: 4.974086761474609
training step: 17420, total_loss: 4.87214994430542
training step: 17421, total_loss: 4.968892574310303
training step: 17422, total_loss: 6.088797569274902
training step: 17423, total_loss: 3.94826602935791
training step: 17424, total_loss: 4.753112316131592
training step: 17425, total_loss: 4.519680976867676
training step: 17426, total_loss: 4.686886787414551
training step: 17427, total_loss: 3.7877254486083984
training step: 17428, total_loss: 4.831789493560791
training step: 17429, total_loss: 4.674627304077148
training step: 17430, total_loss: 3.546421766281128
training step: 17431, total_loss: 4.218148231506348
training step: 17432, total_loss: 4.871967315673828
training step: 17433, total_loss: 2.1871142387390137
training step: 17434, total_loss: 2.524399518966675
training step: 17435, total_loss: 3.5182411670684814
training step: 17436, total_loss: 2.8499155044555664
training step: 17437, total_loss: 3.234656572341919
training step: 17438, total_loss: 3.1745686531066895
training step: 17439, total_loss: 4.658881187438965
training step: 17440, total_loss: 4.741987228393555
training step: 17441, total_loss: 6.374819755554199
training step: 17442, total_loss: 5.23857307434082
training step: 17443, total_loss: 5.34953498840332
training step: 17444, total_loss: 6.011935234069824
training step: 17445, total_loss: 1.1528383493423462
training step: 17446, total_loss: 3.641796112060547
training step: 17447, total_loss: 1.317918300628662
training step: 17448, total_loss: 5.297328948974609
training step: 17449, total_loss: 6.508113861083984
training step: 17450, total_loss: 6.078818321228027
training step: 17451, total_loss: 3.389852523803711
training step: 17452, total_loss: 4.2468156814575195
training step: 17453, total_loss: 4.3190083503723145
training step: 17454, total_loss: 7.34139347076416
training step: 17455, total_loss: 4.812926769256592
training step: 17456, total_loss: 3.8810324668884277
training step: 17457, total_loss: 0.9377068877220154
training step: 17458, total_loss: 3.6236000061035156
training step: 17459, total_loss: 6.016622543334961
training step: 17460, total_loss: 5.264875411987305
training step: 17461, total_loss: 5.1454057693481445
training step: 17462, total_loss: 4.809917449951172
training step: 17463, total_loss: 4.6160993576049805
training step: 17464, total_loss: 3.8447060585021973
training step: 17465, total_loss: 5.623025417327881
training step: 17466, total_loss: 4.501372337341309
training step: 17467, total_loss: 5.330198287963867
training step: 17468, total_loss: 5.465424537658691
training step: 17469, total_loss: 5.53800106048584
training step: 17470, total_loss: 3.8664064407348633
training step: 17471, total_loss: 4.555685520172119
training step: 17472, total_loss: 4.845780372619629
training step: 17473, total_loss: 4.735544204711914
training step: 17474, total_loss: 2.804960250854492
training step: 17475, total_loss: 5.069924831390381
training step: 17476, total_loss: 5.084023952484131
training step: 17477, total_loss: 4.87401008605957
training step: 17478, total_loss: 4.29694938659668
training step: 17479, total_loss: 4.443869113922119
training step: 17480, total_loss: 4.842261791229248
training step: 17481, total_loss: 2.5089309215545654
training step: 17482, total_loss: 4.711315155029297
training step: 17483, total_loss: 2.4893112182617188
training step: 17484, total_loss: 4.054420471191406
training step: 17485, total_loss: 5.017758846282959
training step: 17486, total_loss: 4.585301876068115
training step: 17487, total_loss: 3.8682727813720703
training step: 17488, total_loss: 4.826362609863281
training step: 17489, total_loss: 5.643009185791016
training step: 17490, total_loss: 2.8229079246520996
training step: 17491, total_loss: 4.834194183349609
training step: 17492, total_loss: 5.014683723449707
training step: 17493, total_loss: 4.873732566833496
training step: 17494, total_loss: 5.002536296844482
training step: 17495, total_loss: 4.568563461303711
training step: 17496, total_loss: 6.586871147155762
training step: 17497, total_loss: 4.678400993347168
training step: 17498, total_loss: 4.953354835510254
training step: 17499, total_loss: 3.5021138191223145
training step: 17500, total_loss: 5.179037094116211
training step: 17501, total_loss: 4.24156379699707
training step: 17502, total_loss: 4.958347320556641
training step: 17503, total_loss: 5.594463348388672
training step: 17504, total_loss: 4.8805646896362305
training step: 17505, total_loss: 5.719362258911133
training step: 17506, total_loss: 3.690974712371826
training step: 17507, total_loss: 3.772660732269287
training step: 17508, total_loss: 4.99960470199585
training step: 17509, total_loss: 5.250011444091797
training step: 17510, total_loss: 4.688536643981934
training step: 17511, total_loss: 5.546199798583984
training step: 17512, total_loss: 5.86877965927124
training step: 17513, total_loss: 2.536299228668213
training step: 17514, total_loss: 5.335450649261475
training step: 17515, total_loss: 5.448251724243164
training step: 17516, total_loss: 5.176380157470703
training step: 17517, total_loss: 0.9299480319023132
training step: 17518, total_loss: 5.302044868469238
training step: 17519, total_loss: 4.926612377166748
training step: 17520, total_loss: 4.703671932220459
training step: 17521, total_loss: 3.9763472080230713
training step: 17522, total_loss: 4.91842794418335
training step: 17523, total_loss: 3.3876006603240967
training step: 17524, total_loss: 5.552826881408691
training step: 17525, total_loss: 3.491334915161133
training step: 17526, total_loss: 4.871455192565918
training step: 17527, total_loss: 4.728407859802246
training step: 17528, total_loss: 3.7850401401519775
training step: 17529, total_loss: 3.7722342014312744
training step: 17530, total_loss: 5.840121269226074
training step: 17531, total_loss: 4.06898307800293
training step: 17532, total_loss: 4.70637845993042
training step: 17533, total_loss: 4.566760063171387
training step: 17534, total_loss: 3.9755616188049316
training step: 17535, total_loss: 4.845585346221924
training step: 17536, total_loss: 3.5253424644470215
training step: 17537, total_loss: 4.458178997039795
training step: 17538, total_loss: 3.730715751647949
training step: 17539, total_loss: 2.706063747406006
training step: 17540, total_loss: 5.922433853149414
training step: 17541, total_loss: 4.403360366821289
training step: 17542, total_loss: 3.340972661972046
training step: 17543, total_loss: 4.304164886474609
training step: 17544, total_loss: 4.8866658210754395
training step: 17545, total_loss: 4.84539270401001
training step: 17546, total_loss: 4.942863464355469
training step: 17547, total_loss: 4.68679141998291
training step: 17548, total_loss: 5.548841953277588
training step: 17549, total_loss: 6.354239463806152
training step: 17550, total_loss: 5.357935428619385
training step: 17551, total_loss: 4.27374792098999
training step: 17552, total_loss: 3.34606671333313
training step: 17553, total_loss: 5.052259922027588
training step: 17554, total_loss: 2.840552806854248
training step: 17555, total_loss: 5.361753463745117
training step: 17556, total_loss: 4.439967155456543
training step: 17557, total_loss: 4.283072471618652
training step: 17558, total_loss: 4.167740821838379
training step: 17559, total_loss: 5.229226589202881
training step: 17560, total_loss: 3.225033760070801
training step: 17561, total_loss: 5.2163262367248535
training step: 17562, total_loss: 5.845109939575195
training step: 17563, total_loss: 5.224096298217773
training step: 17564, total_loss: 5.291847229003906
training step: 17565, total_loss: 5.425708770751953
training step: 17566, total_loss: 5.113858222961426
training step: 17567, total_loss: 5.207649230957031
training step: 17568, total_loss: 6.260676860809326
training step: 17569, total_loss: 5.722106456756592
training step: 17570, total_loss: 4.471202850341797
training step: 17571, total_loss: 4.042530536651611
training step: 17572, total_loss: 0.8413154482841492
training step: 17573, total_loss: 4.560856342315674
training step: 17574, total_loss: 4.518049240112305
training step: 17575, total_loss: 5.414678573608398
training step: 17576, total_loss: 2.6146140098571777
training step: 17577, total_loss: 3.9962825775146484
training step: 17578, total_loss: 4.102415561676025
training step: 17579, total_loss: 3.949901580810547
training step: 17580, total_loss: 4.899261474609375
training step: 17581, total_loss: 5.576465606689453
training step: 17582, total_loss: 2.7835116386413574
training step: 17583, total_loss: 4.684270858764648
training step: 17584, total_loss: 4.525084972381592
training step: 17585, total_loss: 4.994559288024902
training step: 17586, total_loss: 3.0702381134033203
training step: 17587, total_loss: 4.522278785705566
training step: 17588, total_loss: 5.415654182434082
training step: 17589, total_loss: 5.4422607421875
training step: 17590, total_loss: 4.737680912017822
training step: 17591, total_loss: 3.7946784496307373
training step: 17592, total_loss: 3.2588067054748535
training step: 17593, total_loss: 4.501473903656006
training step: 17594, total_loss: 4.978445053100586
training step: 17595, total_loss: 2.8968913555145264
training step: 17596, total_loss: 4.35905647277832
training step: 17597, total_loss: 1.3480679988861084
training step: 17598, total_loss: 3.8172402381896973
training step: 17599, total_loss: 5.8912882804870605
training step: 17600, total_loss: 4.853175640106201
training step: 17601, total_loss: 1.5991307497024536
training step: 17602, total_loss: 5.156929969787598
training step: 17603, total_loss: 5.0821733474731445
training step: 17604, total_loss: 3.54557728767395
training step: 17605, total_loss: 4.985153675079346
training step: 17606, total_loss: 4.527081489562988
training step: 17607, total_loss: 5.761696815490723
training step: 17608, total_loss: 3.866499900817871
training step: 17609, total_loss: 4.319925308227539
training step: 17610, total_loss: 5.0947065353393555
training step: 17611, total_loss: 3.572153329849243
training step: 17612, total_loss: 5.01486873626709
training step: 17613, total_loss: 2.8778092861175537
training step: 17614, total_loss: 4.800241947174072
training step: 17615, total_loss: 5.047219276428223
training step: 17616, total_loss: 4.397849082946777
training step: 17617, total_loss: 4.850846767425537
training step: 17618, total_loss: 4.765786647796631
training step: 17619, total_loss: 5.696804046630859
training step: 17620, total_loss: 5.367364406585693
training step: 17621, total_loss: 4.297768592834473
training step: 17622, total_loss: 4.162531852722168
training step: 17623, total_loss: 3.3393592834472656
training step: 17624, total_loss: 4.474273204803467
training step: 17625, total_loss: 5.744583606719971
training step: 17626, total_loss: 5.904865264892578
training step: 17627, total_loss: 5.106194972991943
training step: 17628, total_loss: 4.392293930053711
training step: 17629, total_loss: 4.308605670928955
training step: 17630, total_loss: 5.497291564941406
training step: 17631, total_loss: 3.81862473487854
training step: 17632, total_loss: 1.3708915710449219
training step: 17633, total_loss: 4.2869038581848145
training step: 17634, total_loss: 4.31393575668335
training step: 17635, total_loss: 2.7653427124023438
training step: 17636, total_loss: 3.775698661804199
training step: 17637, total_loss: 4.729014873504639
training step: 17638, total_loss: 4.239304542541504
training step: 17639, total_loss: 5.204629898071289
training step: 17640, total_loss: 4.849801063537598
training step: 17641, total_loss: 5.824326992034912
training step: 17642, total_loss: 4.550324440002441
training step: 17643, total_loss: 4.792046546936035
training step: 17644, total_loss: 4.505930423736572
training step: 17645, total_loss: 3.4698123931884766
training step: 17646, total_loss: 4.605740547180176
training step: 17647, total_loss: 4.152447700500488
training step: 17648, total_loss: 3.8471879959106445
training step: 17649, total_loss: 3.961111307144165
training step: 17650, total_loss: 5.267609596252441
training step: 17651, total_loss: 4.790374755859375
training step: 17652, total_loss: 3.603585958480835
training step: 17653, total_loss: 5.197568893432617
training step: 17654, total_loss: 4.548698902130127
training step: 17655, total_loss: 4.071664333343506
training step: 17656, total_loss: 4.352018356323242
training step: 17657, total_loss: 4.625669479370117
training step: 17658, total_loss: 3.991894245147705
training step: 17659, total_loss: 4.4907331466674805
training step: 17660, total_loss: 4.41180419921875
training step: 17661, total_loss: 5.463925361633301
training step: 17662, total_loss: 3.389939308166504
training step: 17663, total_loss: 5.267768383026123
training step: 17664, total_loss: 2.840965747833252
training step: 17665, total_loss: 6.170914649963379
training step: 17666, total_loss: 5.475779056549072
training step: 17667, total_loss: 5.155383110046387
training step: 17668, total_loss: 3.681898355484009
training step: 17669, total_loss: 5.068606376647949
training step: 17670, total_loss: 4.753655433654785
training step: 17671, total_loss: 4.497176647186279
training step: 17672, total_loss: 4.873595714569092
training step: 17673, total_loss: 5.45777702331543
training step: 17674, total_loss: 3.688579559326172
training step: 17675, total_loss: 4.8941802978515625
training step: 17676, total_loss: 5.127032279968262
training step: 17677, total_loss: 5.908824443817139
training step: 17678, total_loss: 4.136641979217529
training step: 17679, total_loss: 4.771607398986816
training step: 17680, total_loss: 4.447528839111328
training step: 17681, total_loss: 3.959303140640259
training step: 17682, total_loss: 5.654388427734375
training step: 17683, total_loss: 4.812572956085205
training step: 17684, total_loss: 3.748927593231201
training step: 17685, total_loss: 5.0939788818359375
training step: 17686, total_loss: 3.3640570640563965
training step: 17687, total_loss: 3.847574234008789
training step: 17688, total_loss: 4.674853801727295
training step: 17689, total_loss: 5.811903953552246
training step: 17690, total_loss: 5.0321044921875
training step: 17691, total_loss: 4.742763519287109
training step: 17692, total_loss: 5.0765604972839355
training step: 17693, total_loss: 4.823773384094238
training step: 17694, total_loss: 3.933260917663574
training step: 17695, total_loss: 3.4117987155914307
training step: 17696, total_loss: 4.082255840301514
training step: 17697, total_loss: 5.333935737609863
training step: 17698, total_loss: 4.919631481170654
training step: 17699, total_loss: 4.978650093078613
training step: 17700, total_loss: 4.849330902099609
training step: 17701, total_loss: 5.0263214111328125
training step: 17702, total_loss: 4.754847526550293
training step: 17703, total_loss: 3.778571128845215
training step: 17704, total_loss: 4.138983726501465
training step: 17705, total_loss: 5.615373611450195
training step: 17706, total_loss: 5.206609725952148
training step: 17707, total_loss: 4.000272750854492
training step: 17708, total_loss: 4.052124977111816
training step: 17709, total_loss: 4.1290364265441895
training step: 17710, total_loss: 4.215574264526367
training step: 17711, total_loss: 3.43804931640625
training step: 17712, total_loss: 6.246490478515625
training step: 17713, total_loss: 3.454047441482544
training step: 17714, total_loss: 4.572101593017578
training step: 17715, total_loss: 3.9033660888671875
training step: 17716, total_loss: 3.3341116905212402
training step: 17717, total_loss: 4.695371150970459
training step: 17718, total_loss: 4.185347557067871
training step: 17719, total_loss: 4.3953046798706055
training step: 17720, total_loss: 4.880838394165039
training step: 17721, total_loss: 5.95134162902832
training step: 17722, total_loss: 4.502560615539551
training step: 17723, total_loss: 3.6661124229431152
training step: 17724, total_loss: 5.468059539794922
training step: 17725, total_loss: 4.232114315032959
training step: 17726, total_loss: 4.32713508605957
training step: 17727, total_loss: 3.032227039337158
training step: 17728, total_loss: 2.7566323280334473
training step: 17729, total_loss: 4.3960113525390625
training step: 17730, total_loss: 4.525888442993164
training step: 17731, total_loss: 6.245782852172852
training step: 17732, total_loss: 4.026271820068359
training step: 17733, total_loss: 4.123229026794434
training step: 17734, total_loss: 3.880840539932251
training step: 17735, total_loss: 4.327368259429932
training step: 17736, total_loss: 6.458489418029785
training step: 17737, total_loss: 4.186148166656494
training step: 17738, total_loss: 4.833454132080078
training step: 17739, total_loss: 4.925717353820801
training step: 17740, total_loss: 5.087889671325684
training step: 17741, total_loss: 4.906553268432617
training step: 17742, total_loss: 4.120953559875488
training step: 17743, total_loss: 4.538755416870117
training step: 17744, total_loss: 3.5527262687683105
training step: 17745, total_loss: 4.8801774978637695
training step: 17746, total_loss: 4.842077255249023
training step: 17747, total_loss: 1.2136242389678955
training step: 17748, total_loss: 4.926361083984375
training step: 17749, total_loss: 5.199186325073242
training step: 17750, total_loss: 2.359123945236206
training step: 17751, total_loss: 4.81672477722168
training step: 17752, total_loss: 3.906125545501709
training step: 17753, total_loss: 5.585989952087402
training step: 17754, total_loss: 4.466240406036377
training step: 17755, total_loss: 5.3033366203308105
training step: 17756, total_loss: 6.133984565734863
training step: 17757, total_loss: 4.3770952224731445
training step: 17758, total_loss: 1.3019258975982666
training step: 17759, total_loss: 5.693776607513428
training step: 17760, total_loss: 3.8085522651672363
training step: 17761, total_loss: 4.741329193115234
training step: 17762, total_loss: 4.981280326843262
training step: 17763, total_loss: 4.412446022033691
training step: 17764, total_loss: 4.404197692871094
training step: 17765, total_loss: 4.416219711303711
training step: 17766, total_loss: 3.0500380992889404
training step: 17767, total_loss: 4.853551864624023
training step: 17768, total_loss: 5.471663951873779
training step: 17769, total_loss: 4.7713541984558105
training step: 17770, total_loss: 5.349332332611084
training step: 17771, total_loss: 4.217182159423828
training step: 17772, total_loss: 4.194794654846191
training step: 17773, total_loss: 4.326410293579102
training step: 17774, total_loss: 4.499605178833008
training step: 17775, total_loss: 4.688251495361328
training step: 17776, total_loss: 4.865549087524414
training step: 17777, total_loss: 4.477791786193848
training step: 17778, total_loss: 5.163481712341309
training step: 17779, total_loss: 6.230906009674072
training step: 17780, total_loss: 4.947161674499512
training step: 17781, total_loss: 2.906275749206543
training step: 17782, total_loss: 3.110962390899658
training step: 17783, total_loss: 5.244588851928711
training step: 17784, total_loss: 4.880326747894287
training step: 17785, total_loss: 5.1513872146606445
training step: 17786, total_loss: 4.730584144592285
training step: 17787, total_loss: 5.158434867858887
training step: 17788, total_loss: 5.7656378746032715
training step: 17789, total_loss: 5.579597473144531
training step: 17790, total_loss: 4.060333251953125
training step: 17791, total_loss: 5.595426082611084
training step: 17792, total_loss: 4.034300327301025
training step: 17793, total_loss: 5.233078956604004
training step: 17794, total_loss: 3.8539822101593018
training step: 17795, total_loss: 5.165882110595703
training step: 17796, total_loss: 5.067819595336914
training step: 17797, total_loss: 4.724191665649414
training step: 17798, total_loss: 4.557496070861816
training step: 17799, total_loss: 3.282376766204834
training step: 17800, total_loss: 4.433727264404297
training step: 17801, total_loss: 4.652364730834961
training step: 17802, total_loss: 4.256983757019043
training step: 17803, total_loss: 5.239081382751465
training step: 17804, total_loss: 6.695126533508301
training step: 17805, total_loss: 1.141645908355713
training step: 17806, total_loss: 5.5042009353637695
training step: 17807, total_loss: 4.5038299560546875
training step: 17808, total_loss: 5.160513877868652
training step: 17809, total_loss: 2.1396021842956543
training step: 17810, total_loss: 4.037035942077637
training step: 17811, total_loss: 5.213562488555908
training step: 17812, total_loss: 3.0951180458068848
training step: 17813, total_loss: 5.155788421630859
training step: 17814, total_loss: 4.8892412185668945
training step: 17815, total_loss: 4.771718502044678
training step: 17816, total_loss: 5.245680809020996
training step: 17817, total_loss: 4.982873916625977
training step: 17818, total_loss: 1.2002006769180298
training step: 17819, total_loss: 4.904881954193115
training step: 17820, total_loss: 4.372076034545898
training step: 17821, total_loss: 2.706221342086792
training step: 17822, total_loss: 4.670514106750488
training step: 17823, total_loss: 4.53129768371582
training step: 17824, total_loss: 4.388453483581543
training step: 17825, total_loss: 4.811175346374512
training step: 17826, total_loss: 3.864029884338379
training step: 17827, total_loss: 3.4982993602752686
training step: 17828, total_loss: 4.6869425773620605
training step: 17829, total_loss: 3.162994861602783
training step: 17830, total_loss: 3.0808088779449463
training step: 17831, total_loss: 5.681443691253662
training step: 17832, total_loss: 5.688372611999512
training step: 17833, total_loss: 0.9321684837341309
training step: 17834, total_loss: 3.7836294174194336
training step: 17835, total_loss: 5.343029975891113
training step: 17836, total_loss: 2.2369983196258545
training step: 17837, total_loss: 5.8462910652160645
training step: 17838, total_loss: 4.6088738441467285
training step: 17839, total_loss: 6.3269476890563965
training step: 17840, total_loss: 5.335430145263672
training step: 17841, total_loss: 3.8854222297668457
training step: 17842, total_loss: 4.7560319900512695
training step: 17843, total_loss: 4.243407249450684
training step: 17844, total_loss: 5.060171127319336
training step: 17845, total_loss: 2.6035075187683105
training step: 17846, total_loss: 4.235617637634277
training step: 17847, total_loss: 2.361624002456665
training step: 17848, total_loss: 4.838812351226807
training step: 17849, total_loss: 6.415703773498535
training step: 17850, total_loss: 3.9860122203826904
training step: 17851, total_loss: 5.349921226501465
training step: 17852, total_loss: 5.266078472137451
training step: 17853, total_loss: 3.812406063079834
training step: 17854, total_loss: 2.948035955429077
training step: 17855, total_loss: 4.411583423614502
training step: 17856, total_loss: 4.699399471282959
training step: 17857, total_loss: 2.849203109741211
training step: 17858, total_loss: 4.7118659019470215
training step: 17859, total_loss: 2.034727096557617
training step: 17860, total_loss: 6.3687639236450195
training step: 17861, total_loss: 5.004455089569092
training step: 17862, total_loss: 4.701226711273193
training step: 17863, total_loss: 4.5569071769714355
training step: 17864, total_loss: 4.693662166595459
training step: 17865, total_loss: 5.166848182678223
training step: 17866, total_loss: 6.010560035705566
training step: 17867, total_loss: 4.499539375305176
training step: 17868, total_loss: 4.678365707397461
training step: 17869, total_loss: 4.534002304077148
training step: 17870, total_loss: 4.219873905181885
training step: 17871, total_loss: 4.482587814331055
training step: 17872, total_loss: 5.1519012451171875
training step: 17873, total_loss: 3.8773117065429688
training step: 17874, total_loss: 2.8915939331054688
training step: 17875, total_loss: 4.868546485900879
training step: 17876, total_loss: 4.75627326965332
training step: 17877, total_loss: 5.818048477172852
training step: 17878, total_loss: 4.573037147521973
training step: 17879, total_loss: 4.693350315093994
training step: 17880, total_loss: 5.282680988311768
training step: 17881, total_loss: 5.453855514526367
training step: 17882, total_loss: 4.006253242492676
training step: 17883, total_loss: 4.420989036560059
training step: 17884, total_loss: 4.162083625793457
training step: 17885, total_loss: 3.853388547897339
training step: 17886, total_loss: 4.309723377227783
training step: 17887, total_loss: 6.0054612159729
training step: 17888, total_loss: 5.284462928771973
training step: 17889, total_loss: 3.3454885482788086
training step: 17890, total_loss: 4.681977272033691
training step: 17891, total_loss: 2.602971076965332
training step: 17892, total_loss: 5.307938575744629
training step: 17893, total_loss: 5.531148910522461
training step: 17894, total_loss: 4.8149518966674805
training step: 17895, total_loss: 4.617258548736572
training step: 17896, total_loss: 3.318084716796875
training step: 17897, total_loss: 4.956764221191406
training step: 17898, total_loss: 4.232370853424072
training step: 17899, total_loss: 3.6096701622009277
training step: 17900, total_loss: 4.6869425773620605
training step: 17901, total_loss: 3.697389841079712
training step: 17902, total_loss: 4.012509822845459
training step: 17903, total_loss: 3.8205699920654297
training step: 17904, total_loss: 4.232476234436035
training step: 17905, total_loss: 4.274406433105469
training step: 17906, total_loss: 4.338655471801758
training step: 17907, total_loss: 4.223276615142822
training step: 17908, total_loss: 4.341947555541992
training step: 17909, total_loss: 3.2664718627929688
training step: 17910, total_loss: 3.7573800086975098
training step: 17911, total_loss: 2.5923967361450195
training step: 17912, total_loss: 4.116668224334717
training step: 17913, total_loss: 4.6857500076293945
training step: 17914, total_loss: 4.140619277954102
training step: 17915, total_loss: 4.426639556884766
training step: 17916, total_loss: 4.188720703125
training step: 17917, total_loss: 3.096499443054199
training step: 17918, total_loss: 4.299407482147217
training step: 17919, total_loss: 4.822742938995361
training step: 17920, total_loss: 1.0262157917022705
training step: 17921, total_loss: 3.497645616531372
training step: 17922, total_loss: 6.433772563934326
training step: 17923, total_loss: 4.256192684173584
training step: 17924, total_loss: 3.6802196502685547
training step: 17925, total_loss: 2.5608904361724854
training step: 17926, total_loss: 2.3466830253601074
training step: 17927, total_loss: 5.819983959197998
training step: 17928, total_loss: 3.87292218208313
training step: 17929, total_loss: 5.680187225341797
training step: 17930, total_loss: 5.541266918182373
training step: 17931, total_loss: 5.140804290771484
training step: 17932, total_loss: 3.3334805965423584
training step: 17933, total_loss: 5.111433982849121
training step: 17934, total_loss: 4.90806770324707
training step: 17935, total_loss: 5.284638404846191
training step: 17936, total_loss: 0.5540331602096558
training step: 17937, total_loss: 4.047758102416992
training step: 17938, total_loss: 4.373721599578857
training step: 17939, total_loss: 5.548013687133789
training step: 17940, total_loss: 4.076557159423828
training step: 17941, total_loss: 4.601596355438232
training step: 17942, total_loss: 4.483356475830078
training step: 17943, total_loss: 5.375110626220703
training step: 17944, total_loss: 5.058304786682129
training step: 17945, total_loss: 4.734359264373779
training step: 17946, total_loss: 6.828548431396484
training step: 17947, total_loss: 4.4434099197387695
training step: 17948, total_loss: 4.8231000900268555
training step: 17949, total_loss: 5.022975921630859
training step: 17950, total_loss: 3.3941893577575684
training step: 17951, total_loss: 5.400660991668701
training step: 17952, total_loss: 3.4237279891967773
training step: 17953, total_loss: 4.047427177429199
training step: 17954, total_loss: 3.9838361740112305
training step: 17955, total_loss: 5.179103851318359
training step: 17956, total_loss: 5.1291327476501465
training step: 17957, total_loss: 4.895938873291016
training step: 17958, total_loss: 3.5586957931518555
training step: 17959, total_loss: 0.6054872870445251
training step: 17960, total_loss: 3.8246679306030273
training step: 17961, total_loss: 4.5187506675720215
training step: 17962, total_loss: 5.051855087280273
training step: 17963, total_loss: 5.2501935958862305
training step: 17964, total_loss: 5.871232986450195
training step: 17965, total_loss: 5.353106498718262
training step: 17966, total_loss: 5.460547924041748
training step: 17967, total_loss: 2.351675510406494
training step: 17968, total_loss: 4.684784889221191
training step: 17969, total_loss: 4.095086574554443
training step: 17970, total_loss: 4.1643147468566895
training step: 17971, total_loss: 4.851360321044922
training step: 17972, total_loss: 3.523770332336426
training step: 17973, total_loss: 3.5587265491485596
training step: 17974, total_loss: 5.007229804992676
training step: 17975, total_loss: 4.060250759124756
training step: 17976, total_loss: 4.477334022521973
training step: 17977, total_loss: 3.748706102371216
training step: 17978, total_loss: 5.625628471374512
training step: 17979, total_loss: 4.395427703857422
training step: 17980, total_loss: 4.920940399169922
training step: 17981, total_loss: 4.91765022277832
training step: 17982, total_loss: 5.2292094230651855
training step: 17983, total_loss: 4.709080696105957
training step: 17984, total_loss: 4.621185302734375
training step: 17985, total_loss: 5.331911087036133
training step: 17986, total_loss: 4.962337493896484
training step: 17987, total_loss: 4.463380336761475
training step: 17988, total_loss: 3.451066732406616
training step: 17989, total_loss: 5.034367084503174
training step: 17990, total_loss: 3.6412434577941895
training step: 17991, total_loss: 5.791619777679443
training step: 17992, total_loss: 4.671870231628418
training step: 17993, total_loss: 5.9286932945251465
training step: 17994, total_loss: 4.22432279586792
training step: 17995, total_loss: 3.5495026111602783
training step: 17996, total_loss: 0.6103007197380066
training step: 17997, total_loss: 2.8616127967834473
training step: 17998, total_loss: 1.9176948070526123
training step: 17999, total_loss: 4.180235862731934
training step: 18000, total_loss: 4.612945556640625
training step: 18001, total_loss: 2.298766613006592
training step: 18002, total_loss: 5.038191795349121
training step: 18003, total_loss: 3.9372286796569824
training step: 18004, total_loss: 5.165622711181641
training step: 18005, total_loss: 5.90298318862915
training step: 18006, total_loss: 4.699766159057617
training step: 18007, total_loss: 4.8321757316589355
training step: 18008, total_loss: 5.797773361206055
training step: 18009, total_loss: 5.550748825073242
training step: 18010, total_loss: 4.396175384521484
training step: 18011, total_loss: 4.05290412902832
training step: 18012, total_loss: 4.587160110473633
training step: 18013, total_loss: 5.219568252563477
training step: 18014, total_loss: 5.280494689941406
training step: 18015, total_loss: 3.7672159671783447
training step: 18016, total_loss: 4.811534404754639
training step: 18017, total_loss: 4.8215155601501465
training step: 18018, total_loss: 4.775998115539551
training step: 18019, total_loss: 2.6496028900146484
training step: 18020, total_loss: 4.785721778869629
training step: 18021, total_loss: 4.0682878494262695
training step: 18022, total_loss: 4.522660732269287
training step: 18023, total_loss: 5.265363693237305
training step: 18024, total_loss: 2.6874921321868896
training step: 18025, total_loss: 4.276871681213379
training step: 18026, total_loss: 3.5271859169006348
training step: 18027, total_loss: 4.410460948944092
training step: 18028, total_loss: 5.069567680358887
training step: 18029, total_loss: 4.866794586181641
training step: 18030, total_loss: 4.295729637145996
training step: 18031, total_loss: 3.389028787612915
training step: 18032, total_loss: 4.230700969696045
training step: 18033, total_loss: 7.574542999267578
training step: 18034, total_loss: 5.556900501251221
training step: 18035, total_loss: 4.138197422027588
training step: 18036, total_loss: 4.757290840148926
training step: 18037, total_loss: 4.8663330078125
training step: 18038, total_loss: 4.908201694488525
training step: 18039, total_loss: 4.791118621826172
training step: 18040, total_loss: 5.1779327392578125
training step: 18041, total_loss: 2.719994068145752
training step: 18042, total_loss: 4.357760429382324
training step: 18043, total_loss: 4.5090532302856445
training step: 18044, total_loss: 5.176933288574219
training step: 18045, total_loss: 3.386441230773926
training step: 18046, total_loss: 2.9650049209594727
training step: 18047, total_loss: 5.2687835693359375
training step: 18048, total_loss: 4.308060169219971
training step: 18049, total_loss: 5.986916542053223
training step: 18050, total_loss: 4.457681179046631
training step: 18051, total_loss: 4.995748519897461
training step: 18052, total_loss: 3.626124620437622
training step: 18053, total_loss: 4.837930679321289
training step: 18054, total_loss: 4.511593818664551
training step: 18055, total_loss: 4.875619888305664
training step: 18056, total_loss: 3.922851085662842
training step: 18057, total_loss: 5.400503158569336
training step: 18058, total_loss: 4.842471122741699
training step: 18059, total_loss: 4.465619087219238
training step: 18060, total_loss: 4.310810089111328
training step: 18061, total_loss: 7.346779823303223
training step: 18062, total_loss: 4.500283241271973
training step: 18063, total_loss: 4.784302711486816
training step: 18064, total_loss: 5.781664848327637
training step: 18065, total_loss: 4.343935489654541
training step: 18066, total_loss: 4.289813041687012
training step: 18067, total_loss: 6.699963092803955
training step: 18068, total_loss: 4.91771936416626
training step: 18069, total_loss: 5.233733177185059
training step: 18070, total_loss: 2.8111000061035156
training step: 18071, total_loss: 3.6630825996398926
training step: 18072, total_loss: 4.330582618713379
training step: 18073, total_loss: 5.737051010131836
training step: 18074, total_loss: 3.7256951332092285
training step: 18075, total_loss: 4.397692680358887
training step: 18076, total_loss: 4.59365177154541
training step: 18077, total_loss: 4.399379730224609
training step: 18078, total_loss: 5.172711372375488
training step: 18079, total_loss: 4.717711448669434
training step: 18080, total_loss: 3.9637949466705322
training step: 18081, total_loss: 5.1247968673706055
training step: 18082, total_loss: 5.733663558959961
training step: 18083, total_loss: 4.161927223205566
training step: 18084, total_loss: 3.9098262786865234
training step: 18085, total_loss: 4.394662857055664
training step: 18086, total_loss: 4.4167375564575195
training step: 18087, total_loss: 3.7084269523620605
training step: 18088, total_loss: 3.181131362915039
training step: 18089, total_loss: 5.648838520050049
training step: 18090, total_loss: 4.0660271644592285
training step: 18091, total_loss: 4.327239513397217
training step: 18092, total_loss: 4.771440505981445
training step: 18093, total_loss: 4.811670303344727
training step: 18094, total_loss: 4.186566352844238
training step: 18095, total_loss: 2.3159596920013428
training step: 18096, total_loss: 4.2259087562561035
training step: 18097, total_loss: 4.77855920791626
training step: 18098, total_loss: 3.758899211883545
training step: 18099, total_loss: 4.3878278732299805
training step: 18100, total_loss: 4.863154888153076
training step: 18101, total_loss: 5.523835182189941
training step: 18102, total_loss: 3.4390530586242676
training step: 18103, total_loss: 5.903642654418945
training step: 18104, total_loss: 3.5454039573669434
training step: 18105, total_loss: 3.7243590354919434
training step: 18106, total_loss: 4.60970401763916
training step: 18107, total_loss: 3.6162679195404053
training step: 18108, total_loss: 3.2717597484588623
training step: 18109, total_loss: 4.448948860168457
training step: 18110, total_loss: 7.380675792694092
training step: 18111, total_loss: 6.658606052398682
training step: 18112, total_loss: 3.9530744552612305
training step: 18113, total_loss: 4.63511848449707
training step: 18114, total_loss: 4.120204925537109
training step: 18115, total_loss: 4.248237133026123
training step: 18116, total_loss: 3.862788677215576
training step: 18117, total_loss: 5.191866874694824
training step: 18118, total_loss: 4.551531791687012
training step: 18119, total_loss: 6.626230716705322
training step: 18120, total_loss: 4.369029521942139
training step: 18121, total_loss: 4.100564479827881
training step: 18122, total_loss: 4.72353982925415
training step: 18123, total_loss: 4.981466293334961
training step: 18124, total_loss: 3.4073779582977295
training step: 18125, total_loss: 4.549838066101074
training step: 18126, total_loss: 5.139578819274902
training step: 18127, total_loss: 4.139406681060791
training step: 18128, total_loss: 2.598865270614624
training step: 18129, total_loss: 4.411599159240723
training step: 18130, total_loss: 4.162065505981445
training step: 18131, total_loss: 4.10521125793457
training step: 18132, total_loss: 5.4368391036987305
training step: 18133, total_loss: 3.876854419708252
training step: 18134, total_loss: 4.760186195373535
training step: 18135, total_loss: 2.771806001663208
training step: 18136, total_loss: 1.2049403190612793
training step: 18137, total_loss: 4.063695430755615
training step: 18138, total_loss: 5.347975730895996
training step: 18139, total_loss: 4.166770935058594
training step: 18140, total_loss: 4.319930076599121
training step: 18141, total_loss: 5.9049177169799805
training step: 18142, total_loss: 4.300600051879883
training step: 18143, total_loss: 4.692808151245117
training step: 18144, total_loss: 4.59642219543457
training step: 18145, total_loss: 4.029063701629639
training step: 18146, total_loss: 4.603121757507324
training step: 18147, total_loss: 3.5236377716064453
training step: 18148, total_loss: 4.334634780883789
training step: 18149, total_loss: 3.6971423625946045
training step: 18150, total_loss: 3.941382884979248
training step: 18151, total_loss: 5.194196701049805
training step: 18152, total_loss: 4.313342571258545
training step: 18153, total_loss: 3.907318115234375
training step: 18154, total_loss: 5.754673957824707
training step: 18155, total_loss: 5.832919120788574
training step: 18156, total_loss: 4.721835613250732
training step: 18157, total_loss: 4.628398418426514
training step: 18158, total_loss: 5.060921669006348
training step: 18159, total_loss: 5.317373275756836
training step: 18160, total_loss: 3.978386402130127
training step: 18161, total_loss: 5.586648941040039
training step: 18162, total_loss: 4.489177703857422
training step: 18163, total_loss: 3.2152156829833984
training step: 18164, total_loss: 4.466967582702637
training step: 18165, total_loss: 3.72017240524292
training step: 18166, total_loss: 5.265044689178467
training step: 18167, total_loss: 6.3372087478637695
training step: 18168, total_loss: 5.1682586669921875
training step: 18169, total_loss: 3.575610876083374
training step: 18170, total_loss: 5.229920387268066
training step: 18171, total_loss: 3.1703319549560547
training step: 18172, total_loss: 2.5571229457855225
training step: 18173, total_loss: 1.4073902368545532
training step: 18174, total_loss: 3.150376796722412
training step: 18175, total_loss: 4.800901889801025
training step: 18176, total_loss: 4.5329437255859375
training step: 18177, total_loss: 4.061759948730469
training step: 18178, total_loss: 4.160655498504639
training step: 18179, total_loss: 4.0768842697143555
training step: 18180, total_loss: 3.6359968185424805
training step: 18181, total_loss: 3.199704170227051
training step: 18182, total_loss: 5.034307956695557
training step: 18183, total_loss: 1.8949002027511597
training step: 18184, total_loss: 2.0014233589172363
training step: 18185, total_loss: 5.1988725662231445
training step: 18186, total_loss: 3.5253608226776123
training step: 18187, total_loss: 4.7070488929748535
training step: 18188, total_loss: 4.982613563537598
training step: 18189, total_loss: 5.191120147705078
training step: 18190, total_loss: 4.076704025268555
training step: 18191, total_loss: 5.245159149169922
training step: 18192, total_loss: 5.327032089233398
training step: 18193, total_loss: 3.6465463638305664
training step: 18194, total_loss: 4.041924953460693
training step: 18195, total_loss: 4.127208709716797
training step: 18196, total_loss: 3.580925226211548
training step: 18197, total_loss: 3.9840378761291504
training step: 18198, total_loss: 2.315443992614746
training step: 18199, total_loss: 5.727649688720703
training step: 18200, total_loss: 5.627638339996338
training step: 18201, total_loss: 5.054617881774902
training step: 18202, total_loss: 6.038181304931641
training step: 18203, total_loss: 5.335085391998291
training step: 18204, total_loss: 4.679501533508301
training step: 18205, total_loss: 4.462015151977539
training step: 18206, total_loss: 4.603710174560547
training step: 18207, total_loss: 5.046191215515137
training step: 18208, total_loss: 4.9529852867126465
training step: 18209, total_loss: 4.457892894744873
training step: 18210, total_loss: 1.2599308490753174
training step: 18211, total_loss: 3.559560775756836
training step: 18212, total_loss: 7.629060745239258
training step: 18213, total_loss: 4.172965049743652
training step: 18214, total_loss: 4.7892937660217285
training step: 18215, total_loss: 5.711583137512207
training step: 18216, total_loss: 3.83663010597229
training step: 18217, total_loss: 6.534268379211426
training step: 18218, total_loss: 3.2337491512298584
training step: 18219, total_loss: 5.827442169189453
training step: 18220, total_loss: 4.661776542663574
training step: 18221, total_loss: 5.907578945159912
training step: 18222, total_loss: 4.723030090332031
training step: 18223, total_loss: 0.8071231245994568
training step: 18224, total_loss: 5.028633117675781
training step: 18225, total_loss: 5.0845441818237305
training step: 18226, total_loss: 4.6502604484558105
training step: 18227, total_loss: 4.171354293823242
training step: 18228, total_loss: 4.396944046020508
training step: 18229, total_loss: 5.465093612670898
training step: 18230, total_loss: 4.501805782318115
training step: 18231, total_loss: 5.33132266998291
training step: 18232, total_loss: 4.963924884796143
training step: 18233, total_loss: 4.188433647155762
training step: 18234, total_loss: 5.194906234741211
training step: 18235, total_loss: 5.140224456787109
training step: 18236, total_loss: 5.1869001388549805
training step: 18237, total_loss: 4.925259113311768
training step: 18238, total_loss: 4.52554178237915
training step: 18239, total_loss: 4.768451690673828
training step: 18240, total_loss: 5.738443374633789
training step: 18241, total_loss: 3.247788429260254
training step: 18242, total_loss: 5.0085296630859375
training step: 18243, total_loss: 4.616974830627441
training step: 18244, total_loss: 5.764801502227783
training step: 18245, total_loss: 2.5861454010009766
training step: 18246, total_loss: 5.517547607421875
training step: 18247, total_loss: 2.556741237640381
training step: 18248, total_loss: 2.9339942932128906
training step: 18249, total_loss: 5.177338600158691
training step: 18250, total_loss: 3.9037256240844727
training step: 18251, total_loss: 5.428646087646484
training step: 18252, total_loss: 4.977212429046631
training step: 18253, total_loss: 4.955401420593262
training step: 18254, total_loss: 4.670130252838135
training step: 18255, total_loss: 5.205992698669434
training step: 18256, total_loss: 3.823812961578369
training step: 18257, total_loss: 5.126375198364258
training step: 18258, total_loss: 4.774639129638672
training step: 18259, total_loss: 3.7235894203186035
training step: 18260, total_loss: 5.068885803222656
training step: 18261, total_loss: 5.244927406311035
training step: 18262, total_loss: 4.7774977684021
training step: 18263, total_loss: 3.983724355697632
training step: 18264, total_loss: 2.467719554901123
training step: 18265, total_loss: 4.823947429656982
training step: 18266, total_loss: 6.08840274810791
training step: 18267, total_loss: 5.081437110900879
training step: 18268, total_loss: 3.823108196258545
training step: 18269, total_loss: 4.381990432739258
training step: 18270, total_loss: 3.8958241939544678
training step: 18271, total_loss: 4.930455207824707
training step: 18272, total_loss: 3.253136396408081
training step: 18273, total_loss: 5.5801801681518555
training step: 18274, total_loss: 3.8114123344421387
training step: 18275, total_loss: 3.688771963119507
training step: 18276, total_loss: 6.762572288513184
training step: 18277, total_loss: 4.242929935455322
training step: 18278, total_loss: 5.488420486450195
training step: 18279, total_loss: 4.823159694671631
training step: 18280, total_loss: 3.951066017150879
training step: 18281, total_loss: 5.651573181152344
training step: 18282, total_loss: 4.413187026977539
training step: 18283, total_loss: 4.848888874053955
training step: 18284, total_loss: 4.040894508361816
training step: 18285, total_loss: 5.161166191101074
training step: 18286, total_loss: 3.9289355278015137
training step: 18287, total_loss: 3.8007988929748535
training step: 18288, total_loss: 4.562256813049316
training step: 18289, total_loss: 3.7457473278045654
training step: 18290, total_loss: 4.624568939208984
training step: 18291, total_loss: 5.228026866912842
training step: 18292, total_loss: 4.402070999145508
training step: 18293, total_loss: 4.6052703857421875
training step: 18294, total_loss: 4.7218170166015625
training step: 18295, total_loss: 4.066972732543945
training step: 18296, total_loss: 2.6986494064331055
training step: 18297, total_loss: 5.295619010925293
training step: 18298, total_loss: 5.838809013366699
training step: 18299, total_loss: 3.631171226501465
training step: 18300, total_loss: 5.99824333190918
training step: 18301, total_loss: 4.746633529663086
training step: 18302, total_loss: 4.780503749847412
training step: 18303, total_loss: 3.6476407051086426
training step: 18304, total_loss: 4.741333484649658
training step: 18305, total_loss: 1.2101553678512573
training step: 18306, total_loss: 5.630327224731445
training step: 18307, total_loss: 5.450940132141113
training step: 18308, total_loss: 3.899372100830078
training step: 18309, total_loss: 4.478324890136719
training step: 18310, total_loss: 5.637946128845215
training step: 18311, total_loss: 3.8067774772644043
training step: 18312, total_loss: 5.223857402801514
training step: 18313, total_loss: 3.787031412124634
training step: 18314, total_loss: 4.780295372009277
training step: 18315, total_loss: 3.4597063064575195
training step: 18316, total_loss: 4.14924430847168
training step: 18317, total_loss: 5.100430011749268
training step: 18318, total_loss: 4.342102527618408
training step: 18319, total_loss: 5.478115081787109
training step: 18320, total_loss: 3.537519931793213
training step: 18321, total_loss: 4.775721073150635
training step: 18322, total_loss: 5.410037040710449
training step: 18323, total_loss: 4.122316837310791
training step: 18324, total_loss: 3.6704134941101074
training step: 18325, total_loss: 4.462109088897705
training step: 18326, total_loss: 5.117368221282959
training step: 18327, total_loss: 5.101019859313965
training step: 18328, total_loss: 4.472095489501953
training step: 18329, total_loss: 4.616033554077148
training step: 18330, total_loss: 3.815673828125
training step: 18331, total_loss: 5.958842754364014
training step: 18332, total_loss: 1.2387969493865967
training step: 18333, total_loss: 3.7747817039489746
training step: 18334, total_loss: 3.2376151084899902
training step: 18335, total_loss: 4.983076095581055
training step: 18336, total_loss: 6.625807762145996
training step: 18337, total_loss: 5.177145004272461
training step: 18338, total_loss: 4.435650825500488
training step: 18339, total_loss: 4.591767311096191
training step: 18340, total_loss: 2.8559517860412598
training step: 18341, total_loss: 4.748956203460693
training step: 18342, total_loss: 3.7498254776000977
training step: 18343, total_loss: 2.671295166015625
training step: 18344, total_loss: 5.266392707824707
training step: 18345, total_loss: 3.581080436706543
training step: 18346, total_loss: 5.1270246505737305
training step: 18347, total_loss: 4.88642692565918
training step: 18348, total_loss: 4.693144798278809
training step: 18349, total_loss: 4.774936676025391
training step: 18350, total_loss: 4.438394546508789
training step: 18351, total_loss: 4.72357702255249
training step: 18352, total_loss: 6.608917236328125
training step: 18353, total_loss: 5.731456756591797
training step: 18354, total_loss: 4.294977188110352
training step: 18355, total_loss: 5.12448787689209
training step: 18356, total_loss: 2.5104966163635254
training step: 18357, total_loss: 4.309169292449951
training step: 18358, total_loss: 4.382381439208984
training step: 18359, total_loss: 4.256829261779785
training step: 18360, total_loss: 5.080493927001953
training step: 18361, total_loss: 4.055337905883789
training step: 18362, total_loss: 5.566612720489502
training step: 18363, total_loss: 6.148381233215332
training step: 18364, total_loss: 4.510625839233398
training step: 18365, total_loss: 4.8308939933776855
training step: 18366, total_loss: 4.300960540771484
training step: 18367, total_loss: 5.919890403747559
training step: 18368, total_loss: 4.516391277313232
training step: 18369, total_loss: 3.373076915740967
training step: 18370, total_loss: 3.804328203201294
training step: 18371, total_loss: 4.318709850311279
training step: 18372, total_loss: 4.984618186950684
training step: 18373, total_loss: 4.434496879577637
training step: 18374, total_loss: 5.253012657165527
training step: 18375, total_loss: 5.862068176269531
training step: 18376, total_loss: 4.278495788574219
training step: 18377, total_loss: 3.984560966491699
training step: 18378, total_loss: 5.428106307983398
training step: 18379, total_loss: 4.8000030517578125
training step: 18380, total_loss: 3.682101011276245
training step: 18381, total_loss: 5.579821586608887
training step: 18382, total_loss: 4.012650489807129
training step: 18383, total_loss: 4.005600929260254
training step: 18384, total_loss: 4.366472244262695
training step: 18385, total_loss: 4.311652660369873
training step: 18386, total_loss: 3.698533773422241
training step: 18387, total_loss: 5.087264060974121
training step: 18388, total_loss: 4.952717304229736
training step: 18389, total_loss: 4.603509902954102
training step: 18390, total_loss: 5.134739875793457
training step: 18391, total_loss: 6.504265785217285
training step: 18392, total_loss: 5.429297924041748
training step: 18393, total_loss: 2.7894163131713867
training step: 18394, total_loss: 4.64707088470459
training step: 18395, total_loss: 3.9901769161224365
training step: 18396, total_loss: 4.081733703613281
training step: 18397, total_loss: 5.582660675048828
training step: 18398, total_loss: 6.306888580322266
training step: 18399, total_loss: 4.194374084472656
training step: 18400, total_loss: 4.4404683113098145
training step: 18401, total_loss: 4.224588871002197
training step: 18402, total_loss: 4.6887898445129395
training step: 18403, total_loss: 5.5903215408325195
training step: 18404, total_loss: 3.8338003158569336
training step: 18405, total_loss: 4.963068962097168
training step: 18406, total_loss: 4.284300804138184
training step: 18407, total_loss: 4.844755172729492
training step: 18408, total_loss: 5.15437126159668
training step: 18409, total_loss: 6.2559075355529785
training step: 18410, total_loss: 5.884660243988037
training step: 18411, total_loss: 4.418336868286133
training step: 18412, total_loss: 4.100498199462891
training step: 18413, total_loss: 4.2681050300598145
training step: 18414, total_loss: 4.681175231933594
training step: 18415, total_loss: 5.335578441619873
training step: 18416, total_loss: 4.361941814422607
training step: 18417, total_loss: 3.7180161476135254
training step: 18418, total_loss: 4.836320877075195
training step: 18419, total_loss: 5.246382713317871
training step: 18420, total_loss: 4.737518310546875
training step: 18421, total_loss: 4.366143703460693
training step: 18422, total_loss: 5.111541748046875
training step: 18423, total_loss: 3.1726434230804443
training step: 18424, total_loss: 4.366193771362305
training step: 18425, total_loss: 3.524225950241089
training step: 18426, total_loss: 5.5848894119262695
training step: 18427, total_loss: 3.812835216522217
training step: 18428, total_loss: 4.738197326660156
training step: 18429, total_loss: 4.827172756195068
training step: 18430, total_loss: 6.571270942687988
training step: 18431, total_loss: 4.83065938949585
training step: 18432, total_loss: 4.747855186462402
training step: 18433, total_loss: 3.6137924194335938
training step: 18434, total_loss: 4.800960540771484
training step: 18435, total_loss: 4.038347244262695
training step: 18436, total_loss: 5.0739827156066895
training step: 18437, total_loss: 4.884031295776367
training step: 18438, total_loss: 4.898358345031738
training step: 18439, total_loss: 4.811626434326172
training step: 18440, total_loss: 3.56406831741333
training step: 18441, total_loss: 4.92810583114624
training step: 18442, total_loss: 4.5121002197265625
training step: 18443, total_loss: 4.0702128410339355
training step: 18444, total_loss: 5.233928203582764
training step: 18445, total_loss: 5.82706356048584
training step: 18446, total_loss: 3.5557446479797363
training step: 18447, total_loss: 3.272249937057495
training step: 18448, total_loss: 3.8149309158325195
training step: 18449, total_loss: 5.748778343200684
training step: 18450, total_loss: 6.105091571807861
training step: 18451, total_loss: 4.834047317504883
training step: 18452, total_loss: 3.1865551471710205
training step: 18453, total_loss: 5.938961982727051
training step: 18454, total_loss: 3.987231969833374
training step: 18455, total_loss: 4.435027122497559
training step: 18456, total_loss: 7.304027080535889
training step: 18457, total_loss: 4.553435325622559
training step: 18458, total_loss: 4.544529914855957
training step: 18459, total_loss: 5.986212730407715
training step: 18460, total_loss: 5.0941596031188965
training step: 18461, total_loss: 4.2260284423828125
training step: 18462, total_loss: 4.482513427734375
training step: 18463, total_loss: 5.28216552734375
training step: 18464, total_loss: 4.228521823883057
training step: 18465, total_loss: 4.379361629486084
training step: 18466, total_loss: 3.937908887863159
training step: 18467, total_loss: 4.264678478240967
training step: 18468, total_loss: 4.465605735778809
training step: 18469, total_loss: 4.096290588378906
training step: 18470, total_loss: 3.638028144836426
training step: 18471, total_loss: 5.293850898742676
training step: 18472, total_loss: 4.81705904006958
training step: 18473, total_loss: 2.761648178100586
training step: 18474, total_loss: 4.358179569244385
training step: 18475, total_loss: 4.897495746612549
training step: 18476, total_loss: 4.893557548522949
training step: 18477, total_loss: 5.294279098510742
training step: 18478, total_loss: 4.480942726135254
training step: 18479, total_loss: 2.5186548233032227
training step: 18480, total_loss: 4.6499505043029785
training step: 18481, total_loss: 5.491523265838623
training step: 18482, total_loss: 3.3621912002563477
training step: 18483, total_loss: 4.7917351722717285
training step: 18484, total_loss: 3.549041271209717
training step: 18485, total_loss: 4.323067665100098
training step: 18486, total_loss: 4.214519500732422
training step: 18487, total_loss: 2.9464001655578613
training step: 18488, total_loss: 2.8554134368896484
training step: 18489, total_loss: 3.22507643699646
training step: 18490, total_loss: 3.1203439235687256
training step: 18491, total_loss: 3.920635223388672
training step: 18492, total_loss: 4.669847011566162
training step: 18493, total_loss: 4.47615385055542
training step: 18494, total_loss: 4.449769973754883
training step: 18495, total_loss: 5.72871732711792
training step: 18496, total_loss: 3.597306728363037
training step: 18497, total_loss: 4.695338249206543
training step: 18498, total_loss: 3.877084493637085
training step: 18499, total_loss: 5.359567642211914
training step: 18500, total_loss: 4.756922721862793
training step: 18501, total_loss: 5.198654651641846
training step: 18502, total_loss: 3.488809585571289
training step: 18503, total_loss: 4.207308292388916
training step: 18504, total_loss: 4.89693546295166
training step: 18505, total_loss: 3.9895267486572266
training step: 18506, total_loss: 4.200688362121582
training step: 18507, total_loss: 4.860311508178711
training step: 18508, total_loss: 4.674751281738281
training step: 18509, total_loss: 4.070531845092773
training step: 18510, total_loss: 4.924389362335205
training step: 18511, total_loss: 1.2232258319854736
training step: 18512, total_loss: 4.3991498947143555
training step: 18513, total_loss: 3.7784461975097656
training step: 18514, total_loss: 5.030587196350098
training step: 18515, total_loss: 5.319489479064941
training step: 18516, total_loss: 5.489789009094238
training step: 18517, total_loss: 4.493098258972168
training step: 18518, total_loss: 4.294315814971924
training step: 18519, total_loss: 4.776589393615723
training step: 18520, total_loss: 4.692342758178711
training step: 18521, total_loss: 5.3106184005737305
training step: 18522, total_loss: 4.234158515930176
training step: 18523, total_loss: 5.145427703857422
training step: 18524, total_loss: 4.800389289855957
training step: 18525, total_loss: 2.4284493923187256
training step: 18526, total_loss: 2.8215789794921875
training step: 18527, total_loss: 3.469942092895508
training step: 18528, total_loss: 2.5257439613342285
training step: 18529, total_loss: 4.371420860290527
training step: 18530, total_loss: 3.496995449066162
training step: 18531, total_loss: 3.252087116241455
training step: 18532, total_loss: 3.7908437252044678
training step: 18533, total_loss: 5.229022979736328
training step: 18534, total_loss: 3.725529193878174
training step: 18535, total_loss: 4.438691139221191
training step: 18536, total_loss: 1.2149381637573242
training step: 18537, total_loss: 1.0476388931274414
training step: 18538, total_loss: 5.967443943023682
training step: 18539, total_loss: 4.56019926071167
training step: 18540, total_loss: 4.276884078979492
training step: 18541, total_loss: 5.545049667358398
training step: 18542, total_loss: 0.8074652552604675
training step: 18543, total_loss: 4.779287815093994
training step: 18544, total_loss: 4.636084079742432
training step: 18545, total_loss: 4.93766975402832
training step: 18546, total_loss: 7.267643928527832
training step: 18547, total_loss: 4.898353576660156
training step: 18548, total_loss: 5.458059787750244
training step: 18549, total_loss: 4.364853858947754
training step: 18550, total_loss: 3.335176944732666
training step: 18551, total_loss: 5.188972473144531
training step: 18552, total_loss: 5.730515003204346
training step: 18553, total_loss: 2.2855963706970215
training step: 18554, total_loss: 6.286057472229004
training step: 18555, total_loss: 5.059920787811279
training step: 18556, total_loss: 5.565448760986328
training step: 18557, total_loss: 5.68034029006958
training step: 18558, total_loss: 3.4825496673583984
training step: 18559, total_loss: 3.9069182872772217
training step: 18560, total_loss: 4.855559825897217
training step: 18561, total_loss: 1.338545799255371
training step: 18562, total_loss: 4.234848499298096
training step: 18563, total_loss: 4.764758110046387
training step: 18564, total_loss: 5.562465667724609
training step: 18565, total_loss: 4.776040077209473
training step: 18566, total_loss: 3.684746742248535
training step: 18567, total_loss: 4.654013633728027
training step: 18568, total_loss: 3.6131808757781982
training step: 18569, total_loss: 4.146252632141113
training step: 18570, total_loss: 4.7554473876953125
training step: 18571, total_loss: 4.7115678787231445
training step: 18572, total_loss: 5.570559501647949
training step: 18573, total_loss: 5.213386535644531
training step: 18574, total_loss: 4.789894104003906
training step: 18575, total_loss: 5.524057865142822
training step: 18576, total_loss: 4.5079755783081055
training step: 18577, total_loss: 5.260519504547119
training step: 18578, total_loss: 3.604001045227051
training step: 18579, total_loss: 4.914198398590088
training step: 18580, total_loss: 2.0183961391448975
training step: 18581, total_loss: 5.386718273162842
training step: 18582, total_loss: 4.078328609466553
training step: 18583, total_loss: 3.919105052947998
training step: 18584, total_loss: 3.7958803176879883
training step: 18585, total_loss: 3.539954662322998
training step: 18586, total_loss: 3.519375801086426
training step: 18587, total_loss: 5.943235397338867
training step: 18588, total_loss: 6.180630207061768
training step: 18589, total_loss: 4.486610412597656
training step: 18590, total_loss: 5.130640983581543
training step: 18591, total_loss: 5.658288955688477
training step: 18592, total_loss: 4.232234954833984
training step: 18593, total_loss: 6.0967793464660645
training step: 18594, total_loss: 4.1195807456970215
training step: 18595, total_loss: 5.3204193115234375
training step: 18596, total_loss: 4.836558818817139
training step: 18597, total_loss: 4.317551136016846
training step: 18598, total_loss: 4.983616352081299
training step: 18599, total_loss: 4.745051383972168
training step: 18600, total_loss: 4.125654220581055
training step: 18601, total_loss: 5.081343650817871
training step: 18602, total_loss: 4.22697114944458
training step: 18603, total_loss: 3.404001235961914
training step: 18604, total_loss: 6.699136257171631
training step: 18605, total_loss: 4.842122554779053
training step: 18606, total_loss: 4.472657680511475
training step: 18607, total_loss: 4.44174861907959
training step: 18608, total_loss: 4.372557163238525
training step: 18609, total_loss: 4.731853485107422
training step: 18610, total_loss: 5.021590232849121
training step: 18611, total_loss: 4.484921455383301
training step: 18612, total_loss: 4.505731105804443
training step: 18613, total_loss: 3.6059608459472656
training step: 18614, total_loss: 3.2891955375671387
training step: 18615, total_loss: 4.351129531860352
training step: 18616, total_loss: 5.585860252380371
training step: 18617, total_loss: 4.362511157989502
training step: 18618, total_loss: 5.021383762359619
training step: 18619, total_loss: 3.067168712615967
training step: 18620, total_loss: 5.338492393493652
training step: 18621, total_loss: 5.328275680541992
training step: 18622, total_loss: 4.112350940704346
training step: 18623, total_loss: 4.447220325469971
training step: 18624, total_loss: 3.5461113452911377
training step: 18625, total_loss: 4.99018669128418
training step: 18626, total_loss: 5.400970935821533
training step: 18627, total_loss: 4.537911891937256
training step: 18628, total_loss: 4.569013595581055
training step: 18629, total_loss: 5.72096586227417
training step: 18630, total_loss: 3.590635299682617
training step: 18631, total_loss: 4.214138031005859
training step: 18632, total_loss: 4.770627498626709
training step: 18633, total_loss: 5.207581996917725
training step: 18634, total_loss: 4.365962982177734
training step: 18635, total_loss: 3.9644784927368164
training step: 18636, total_loss: 3.905076026916504
training step: 18637, total_loss: 4.213219165802002
training step: 18638, total_loss: 4.0931267738342285
training step: 18639, total_loss: 4.420376300811768
training step: 18640, total_loss: 5.847434043884277
training step: 18641, total_loss: 5.584454536437988
training step: 18642, total_loss: 5.745489597320557
training step: 18643, total_loss: 3.7175114154815674
training step: 18644, total_loss: 4.0472612380981445
training step: 18645, total_loss: 2.439401388168335
training step: 18646, total_loss: 3.5803089141845703
training step: 18647, total_loss: 5.297707557678223
training step: 18648, total_loss: 3.5943305492401123
training step: 18649, total_loss: 2.806657314300537
training step: 18650, total_loss: 4.043979167938232
training step: 18651, total_loss: 4.172488689422607
training step: 18652, total_loss: 4.063711643218994
training step: 18653, total_loss: 5.017244815826416
training step: 18654, total_loss: 6.166304588317871
training step: 18655, total_loss: 4.661130905151367
training step: 18656, total_loss: 4.880570411682129
training step: 18657, total_loss: 5.0073323249816895
training step: 18658, total_loss: 4.098912239074707
training step: 18659, total_loss: 5.158116340637207
training step: 18660, total_loss: 2.153393268585205
training step: 18661, total_loss: 4.844067573547363
training step: 18662, total_loss: 5.512932777404785
training step: 18663, total_loss: 4.034257888793945
training step: 18664, total_loss: 4.6700849533081055
training step: 18665, total_loss: 5.195094108581543
training step: 18666, total_loss: 4.928877830505371
training step: 18667, total_loss: 4.557496547698975
training step: 18668, total_loss: 5.372689247131348
training step: 18669, total_loss: 4.070341110229492
training step: 18670, total_loss: 1.0900894403457642
training step: 18671, total_loss: 4.588244915008545
training step: 18672, total_loss: 5.580716133117676
training step: 18673, total_loss: 1.9920203685760498
training step: 18674, total_loss: 3.759070873260498
training step: 18675, total_loss: 2.9611306190490723
training step: 18676, total_loss: 4.5590338706970215
training step: 18677, total_loss: 3.018486499786377
training step: 18678, total_loss: 5.9153923988342285
training step: 18679, total_loss: 4.238121032714844
training step: 18680, total_loss: 4.379515647888184
training step: 18681, total_loss: 1.3883404731750488
training step: 18682, total_loss: 5.09824275970459
training step: 18683, total_loss: 4.005535125732422
training step: 18684, total_loss: 5.589292049407959
training step: 18685, total_loss: 5.041711807250977
training step: 18686, total_loss: 3.6927852630615234
training step: 18687, total_loss: 5.3045268058776855
training step: 18688, total_loss: 3.7871246337890625
training step: 18689, total_loss: 4.313352108001709
training step: 18690, total_loss: 5.307215690612793
training step: 18691, total_loss: 4.302544593811035
training step: 18692, total_loss: 5.400473594665527
training step: 18693, total_loss: 4.822122573852539
training step: 18694, total_loss: 4.012332916259766
training step: 18695, total_loss: 6.8474907875061035
training step: 18696, total_loss: 3.102993965148926
training step: 18697, total_loss: 6.820822715759277
training step: 18698, total_loss: 3.8851592540740967
training step: 18699, total_loss: 4.4302473068237305
training step: 18700, total_loss: 5.846166610717773
training step: 18701, total_loss: 6.994497299194336
training step: 18702, total_loss: 4.504830360412598
training step: 18703, total_loss: 4.352601528167725
training step: 18704, total_loss: 5.049531936645508
training step: 18705, total_loss: 3.2547531127929688
training step: 18706, total_loss: 3.3894524574279785
training step: 18707, total_loss: 4.770028114318848
training step: 18708, total_loss: 4.583988666534424
training step: 18709, total_loss: 2.8295397758483887
training step: 18710, total_loss: 3.200533866882324
training step: 18711, total_loss: 4.738193511962891
training step: 18712, total_loss: 4.217543601989746
training step: 18713, total_loss: 3.348449945449829
training step: 18714, total_loss: 5.242406845092773
training step: 18715, total_loss: 4.001477241516113
training step: 18716, total_loss: 5.4121904373168945
training step: 18717, total_loss: 5.2469024658203125
training step: 18718, total_loss: 4.756978988647461
training step: 18719, total_loss: 3.824496030807495
training step: 18720, total_loss: 2.92085862159729
training step: 18721, total_loss: 4.405536651611328
training step: 18722, total_loss: 4.442318916320801
training step: 18723, total_loss: 3.7974395751953125
training step: 18724, total_loss: 3.3975253105163574
training step: 18725, total_loss: 3.8390612602233887
training step: 18726, total_loss: 4.334565162658691
training step: 18727, total_loss: 4.379897117614746
training step: 18728, total_loss: 5.338309288024902
training step: 18729, total_loss: 4.214019775390625
training step: 18730, total_loss: 4.045510768890381
training step: 18731, total_loss: 3.84696626663208
training step: 18732, total_loss: 5.826836585998535
training step: 18733, total_loss: 5.6555633544921875
training step: 18734, total_loss: 4.073742866516113
training step: 18735, total_loss: 3.2778306007385254
training step: 18736, total_loss: 5.17984676361084
training step: 18737, total_loss: 5.70428991317749
training step: 18738, total_loss: 4.197564125061035
training step: 18739, total_loss: 7.056974411010742
training step: 18740, total_loss: 4.001076698303223
training step: 18741, total_loss: 4.943118095397949
training step: 18742, total_loss: 4.259139060974121
training step: 18743, total_loss: 4.718401908874512
training step: 18744, total_loss: 5.783092498779297
training step: 18745, total_loss: 4.647180080413818
training step: 18746, total_loss: 5.202838897705078
training step: 18747, total_loss: 4.762131690979004
training step: 18748, total_loss: 5.796692848205566
training step: 18749, total_loss: 7.103850364685059
training step: 18750, total_loss: 4.6271071434021
training step: 18751, total_loss: 4.81889533996582
training step: 18752, total_loss: 4.8246965408325195
training step: 18753, total_loss: 4.640348434448242
training step: 18754, total_loss: 4.312046051025391
training step: 18755, total_loss: 3.1529030799865723
training step: 18756, total_loss: 5.338685512542725
training step: 18757, total_loss: 4.410394191741943
training step: 18758, total_loss: 3.526829957962036
training step: 18759, total_loss: 3.6244964599609375
training step: 18760, total_loss: 3.337475538253784
training step: 18761, total_loss: 3.496455192565918
training step: 18762, total_loss: 2.968144416809082
training step: 18763, total_loss: 4.715616226196289
training step: 18764, total_loss: 4.456075668334961
training step: 18765, total_loss: 3.030036449432373
training step: 18766, total_loss: 2.9765162467956543
training step: 18767, total_loss: 4.702146053314209
training step: 18768, total_loss: 3.8718371391296387
training step: 18769, total_loss: 1.105147361755371
training step: 18770, total_loss: 3.8734524250030518
training step: 18771, total_loss: 3.4681081771850586
training step: 18772, total_loss: 5.666923522949219
training step: 18773, total_loss: 4.683040618896484
training step: 18774, total_loss: 4.504237651824951
training step: 18775, total_loss: 4.078961372375488
training step: 18776, total_loss: 4.224158763885498
training step: 18777, total_loss: 7.909214019775391
training step: 18778, total_loss: 4.6021246910095215
training step: 18779, total_loss: 5.009778022766113
training step: 18780, total_loss: 5.453002452850342
training step: 18781, total_loss: 5.7970991134643555
training step: 18782, total_loss: 4.227752685546875
training step: 18783, total_loss: 4.046091079711914
training step: 18784, total_loss: 5.254185676574707
training step: 18785, total_loss: 5.959678649902344
training step: 18786, total_loss: 3.863532781600952
training step: 18787, total_loss: 6.746650695800781
training step: 18788, total_loss: 3.8702547550201416
training step: 18789, total_loss: 1.2516989707946777
training step: 18790, total_loss: 4.616644859313965
training step: 18791, total_loss: 4.2097039222717285
training step: 18792, total_loss: 5.650651454925537
training step: 18793, total_loss: 4.428625583648682
training step: 18794, total_loss: 1.1712994575500488
training step: 18795, total_loss: 4.797699928283691
training step: 18796, total_loss: 1.0877066850662231
training step: 18797, total_loss: 4.13198709487915
training step: 18798, total_loss: 5.060594081878662
training step: 18799, total_loss: 5.3203558921813965
training step: 18800, total_loss: 4.417998313903809
training step: 18801, total_loss: 2.5794105529785156
training step: 18802, total_loss: 6.044368743896484
training step: 18803, total_loss: 4.0401763916015625
training step: 18804, total_loss: 3.8850631713867188
training step: 18805, total_loss: 4.954455852508545
training step: 18806, total_loss: 4.321235656738281
training step: 18807, total_loss: 5.900388717651367
training step: 18808, total_loss: 6.38942813873291
training step: 18809, total_loss: 5.255667686462402
training step: 18810, total_loss: 5.423679351806641
training step: 18811, total_loss: 5.510585308074951
training step: 18812, total_loss: 4.298487186431885
training step: 18813, total_loss: 4.832015514373779
training step: 18814, total_loss: 4.937402248382568
training step: 18815, total_loss: 5.547473907470703
training step: 18816, total_loss: 3.7120790481567383
training step: 18817, total_loss: 4.907016754150391
training step: 18818, total_loss: 5.223278522491455
training step: 18819, total_loss: 2.848825216293335
training step: 18820, total_loss: 5.2003493309021
training step: 18821, total_loss: 6.25312614440918
training step: 18822, total_loss: 0.9554497003555298
training step: 18823, total_loss: 2.972740650177002
training step: 18824, total_loss: 4.603618621826172
training step: 18825, total_loss: 3.4234678745269775
training step: 18826, total_loss: 4.843289375305176
training step: 18827, total_loss: 5.4814772605896
training step: 18828, total_loss: 4.051470756530762
training step: 18829, total_loss: 5.450996398925781
training step: 18830, total_loss: 3.2184457778930664
training step: 18831, total_loss: 4.575973987579346
training step: 18832, total_loss: 4.369260787963867
training step: 18833, total_loss: 4.013796806335449
training step: 18834, total_loss: 3.1403846740722656
training step: 18835, total_loss: 1.9180388450622559
training step: 18836, total_loss: 3.567676067352295
training step: 18837, total_loss: 4.341296195983887
training step: 18838, total_loss: 2.6099207401275635
training step: 18839, total_loss: 5.002725601196289
training step: 18840, total_loss: 5.1263275146484375
training step: 18841, total_loss: 3.41624116897583
training step: 18842, total_loss: 5.002394676208496
training step: 18843, total_loss: 5.2628374099731445
training step: 18844, total_loss: 5.21026611328125
training step: 18845, total_loss: 4.357938289642334
training step: 18846, total_loss: 2.7285356521606445
training step: 18847, total_loss: 4.941773891448975
training step: 18848, total_loss: 4.661733627319336
training step: 18849, total_loss: 6.014744758605957
training step: 18850, total_loss: 4.654176235198975
training step: 18851, total_loss: 4.535724639892578
training step: 18852, total_loss: 2.5537045001983643
training step: 18853, total_loss: 5.681251049041748
training step: 18854, total_loss: 4.605829238891602
training step: 18855, total_loss: 5.559202671051025
training step: 18856, total_loss: 0.8177997469902039
training step: 18857, total_loss: 4.871031284332275
training step: 18858, total_loss: 4.93136739730835
training step: 18859, total_loss: 5.308656692504883
training step: 18860, total_loss: 4.7625885009765625
training step: 18861, total_loss: 6.666144847869873
training step: 18862, total_loss: 4.996547698974609
training step: 18863, total_loss: 4.532644271850586
training step: 18864, total_loss: 2.5794410705566406
training step: 18865, total_loss: 3.5293917655944824
training step: 18866, total_loss: 3.93447208404541
training step: 18867, total_loss: 3.4573419094085693
training step: 18868, total_loss: 5.61612606048584
training step: 18869, total_loss: 3.4542112350463867
training step: 18870, total_loss: 5.100113868713379
training step: 18871, total_loss: 4.052818775177002
training step: 18872, total_loss: 4.797694206237793
training step: 18873, total_loss: 5.91270637512207
training step: 18874, total_loss: 4.054296016693115
training step: 18875, total_loss: 1.1510916948318481
training step: 18876, total_loss: 4.3236565589904785
training step: 18877, total_loss: 1.8802769184112549
training step: 18878, total_loss: 4.522714614868164
training step: 18879, total_loss: 4.850505828857422
training step: 18880, total_loss: 4.859241485595703
training step: 18881, total_loss: 6.632341384887695
training step: 18882, total_loss: 3.1415939331054688
training step: 18883, total_loss: 4.802122116088867
training step: 18884, total_loss: 4.555350303649902
training step: 18885, total_loss: 4.98394775390625
training step: 18886, total_loss: 5.326630592346191
training step: 18887, total_loss: 4.105227470397949
training step: 18888, total_loss: 5.0731072425842285
training step: 18889, total_loss: 6.074676990509033
training step: 18890, total_loss: 5.008706092834473
training step: 18891, total_loss: 2.8675105571746826
training step: 18892, total_loss: 2.833061456680298
training step: 18893, total_loss: 4.313204765319824
training step: 18894, total_loss: 5.936590194702148
training step: 18895, total_loss: 3.730556011199951
training step: 18896, total_loss: 4.421786785125732
training step: 18897, total_loss: 4.4808549880981445
training step: 18898, total_loss: 5.153135299682617
training step: 18899, total_loss: 4.983706951141357
training step: 18900, total_loss: 4.528209209442139
training step: 18901, total_loss: 5.083190441131592
training step: 18902, total_loss: 5.499626159667969
training step: 18903, total_loss: 4.800738334655762
training step: 18904, total_loss: 7.150782585144043
training step: 18905, total_loss: 4.4473676681518555
training step: 18906, total_loss: 3.8707542419433594
training step: 18907, total_loss: 5.297537803649902
training step: 18908, total_loss: 3.8654391765594482
training step: 18909, total_loss: 5.873557090759277
training step: 18910, total_loss: 5.449149131774902
training step: 18911, total_loss: 3.9265832901000977
training step: 18912, total_loss: 4.482456207275391
training step: 18913, total_loss: 3.658663511276245
training step: 18914, total_loss: 4.099788665771484
training step: 18915, total_loss: 4.358592510223389
training step: 18916, total_loss: 4.491863250732422
training step: 18917, total_loss: 5.274166107177734
training step: 18918, total_loss: 4.536391735076904
training step: 18919, total_loss: 5.666678428649902
training step: 18920, total_loss: 4.780823707580566
training step: 18921, total_loss: 4.469582557678223
training step: 18922, total_loss: 3.883854866027832
training step: 18923, total_loss: 4.60952615737915
training step: 18924, total_loss: 4.153339862823486
training step: 18925, total_loss: 3.3659801483154297
training step: 18926, total_loss: 4.335727691650391
training step: 18927, total_loss: 3.7154572010040283
training step: 18928, total_loss: 3.385662078857422
training step: 18929, total_loss: 3.1457180976867676
training step: 18930, total_loss: 4.072705268859863
training step: 18931, total_loss: 5.238790512084961
training step: 18932, total_loss: 5.02441930770874
training step: 18933, total_loss: 3.1198570728302
training step: 18934, total_loss: 4.365416049957275
training step: 18935, total_loss: 4.975500106811523
training step: 18936, total_loss: 5.501743316650391
training step: 18937, total_loss: 2.221005439758301
training step: 18938, total_loss: 4.070751190185547
training step: 18939, total_loss: 4.070121765136719
training step: 18940, total_loss: 6.10385799407959
training step: 18941, total_loss: 3.6677465438842773
training step: 18942, total_loss: 6.0279860496521
training step: 18943, total_loss: 3.812204360961914
training step: 18944, total_loss: 5.389703750610352
training step: 18945, total_loss: 3.849620819091797
training step: 18946, total_loss: 4.398311614990234
training step: 18947, total_loss: 4.967483043670654
training step: 18948, total_loss: 4.695137023925781
training step: 18949, total_loss: 3.8884024620056152
training step: 18950, total_loss: 4.266523361206055
training step: 18951, total_loss: 5.220695495605469
training step: 18952, total_loss: 5.125626564025879
training step: 18953, total_loss: 5.320113658905029
training step: 18954, total_loss: 4.461349010467529
training step: 18955, total_loss: 4.557918548583984
training step: 18956, total_loss: 4.580058574676514
training step: 18957, total_loss: 5.25382661819458
training step: 18958, total_loss: 3.070666790008545
training step: 18959, total_loss: 3.2105398178100586
training step: 18960, total_loss: 4.420348167419434
training step: 18961, total_loss: 3.508617401123047
training step: 18962, total_loss: 4.109317779541016
training step: 18963, total_loss: 3.9518446922302246
training step: 18964, total_loss: 3.09090518951416
training step: 18965, total_loss: 6.234272003173828
training step: 18966, total_loss: 4.582132816314697
training step: 18967, total_loss: 4.923888206481934
training step: 18968, total_loss: 5.133739471435547
training step: 18969, total_loss: 4.489869594573975
training step: 18970, total_loss: 5.167313575744629
training step: 18971, total_loss: 4.059694290161133
training step: 18972, total_loss: 5.7141618728637695
training step: 18973, total_loss: 4.875214576721191
training step: 18974, total_loss: 5.4054646492004395
training step: 18975, total_loss: 4.3748459815979
training step: 18976, total_loss: 3.814727306365967
training step: 18977, total_loss: 4.3104376792907715
training step: 18978, total_loss: 4.718137264251709
training step: 18979, total_loss: 5.931582450866699
training step: 18980, total_loss: 5.298719882965088
training step: 18981, total_loss: 5.220671653747559
training step: 18982, total_loss: 3.4811346530914307
training step: 18983, total_loss: 4.722634315490723
training step: 18984, total_loss: 4.162208557128906
training step: 18985, total_loss: 4.895857334136963
training step: 18986, total_loss: 5.157147407531738
training step: 18987, total_loss: 4.321662902832031
training step: 18988, total_loss: 3.487130880355835
training step: 18989, total_loss: 4.784947395324707
training step: 18990, total_loss: 4.84592342376709
training step: 18991, total_loss: 3.462440252304077
training step: 18992, total_loss: 3.0545687675476074
training step: 18993, total_loss: 5.55362606048584
training step: 18994, total_loss: 4.140487194061279
training step: 18995, total_loss: 4.844568729400635
training step: 18996, total_loss: 4.1893720626831055
training step: 18997, total_loss: 1.0298569202423096
training step: 18998, total_loss: 3.877566337585449
training step: 18999, total_loss: 1.0973801612854004
training step: 19000, total_loss: 6.096280097961426
training step: 19001, total_loss: 4.225765705108643
training step: 19002, total_loss: 3.8006346225738525
training step: 19003, total_loss: 5.249367713928223
training step: 19004, total_loss: 3.051987886428833
training step: 19005, total_loss: 4.044938087463379
training step: 19006, total_loss: 5.433959484100342
training step: 19007, total_loss: 4.480027198791504
training step: 19008, total_loss: 5.505494117736816
training step: 19009, total_loss: 3.3246357440948486
training step: 19010, total_loss: 3.9701356887817383
training step: 19011, total_loss: 4.12784481048584
training step: 19012, total_loss: 5.664215087890625
training step: 19013, total_loss: 3.016162872314453
training step: 19014, total_loss: 4.717012882232666
training step: 19015, total_loss: 4.036774158477783
training step: 19016, total_loss: 1.5094528198242188
training step: 19017, total_loss: 5.069923400878906
training step: 19018, total_loss: 5.876676082611084
training step: 19019, total_loss: 5.108075141906738
training step: 19020, total_loss: 3.9714794158935547
training step: 19021, total_loss: 4.664048194885254
training step: 19022, total_loss: 2.797515869140625
training step: 19023, total_loss: 4.320657730102539
training step: 19024, total_loss: 3.305481433868408
training step: 19025, total_loss: 5.033170700073242
training step: 19026, total_loss: 4.605552673339844
training step: 19027, total_loss: 4.001689434051514
training step: 19028, total_loss: 5.883033752441406
training step: 19029, total_loss: 6.033741474151611
training step: 19030, total_loss: 3.5341532230377197
training step: 19031, total_loss: 4.4637956619262695
training step: 19032, total_loss: 3.3230910301208496
training step: 19033, total_loss: 4.246148109436035
training step: 19034, total_loss: 4.804400444030762
training step: 19035, total_loss: 4.233452320098877
training step: 19036, total_loss: 5.377862930297852
training step: 19037, total_loss: 4.526713848114014
training step: 19038, total_loss: 4.541696548461914
training step: 19039, total_loss: 4.806317329406738
training step: 19040, total_loss: 4.599391937255859
training step: 19041, total_loss: 4.508167743682861
training step: 19042, total_loss: 4.249330520629883
training step: 19043, total_loss: 4.07510232925415
training step: 19044, total_loss: 4.181264400482178
training step: 19045, total_loss: 4.988624572753906
training step: 19046, total_loss: 4.788885116577148
training step: 19047, total_loss: 4.152769088745117
training step: 19048, total_loss: 4.722151756286621
training step: 19049, total_loss: 5.459474563598633
training step: 19050, total_loss: 4.490007400512695
training step: 19051, total_loss: 5.386516571044922
training step: 19052, total_loss: 5.751858711242676
training step: 19053, total_loss: 4.044300556182861
training step: 19054, total_loss: 3.6580822467803955
training step: 19055, total_loss: 6.8183488845825195
training step: 19056, total_loss: 5.622628211975098
training step: 19057, total_loss: 4.671054363250732
training step: 19058, total_loss: 3.7929399013519287
training step: 19059, total_loss: 5.059447288513184
training step: 19060, total_loss: 6.298126220703125
training step: 19061, total_loss: 3.590369701385498
training step: 19062, total_loss: 4.800261974334717
training step: 19063, total_loss: 4.498786926269531
training step: 19064, total_loss: 3.9452476501464844
training step: 19065, total_loss: 3.674978733062744
training step: 19066, total_loss: 4.157476425170898
training step: 19067, total_loss: 5.365971088409424
training step: 19068, total_loss: 4.276210784912109
training step: 19069, total_loss: 3.202610492706299
training step: 19070, total_loss: 3.636251449584961
training step: 19071, total_loss: 4.217214107513428
training step: 19072, total_loss: 4.388588905334473
training step: 19073, total_loss: 3.6241137981414795
training step: 19074, total_loss: 5.452961444854736
training step: 19075, total_loss: 4.1251020431518555
training step: 19076, total_loss: 4.471775531768799
training step: 19077, total_loss: 5.049844741821289
training step: 19078, total_loss: 4.960384368896484
training step: 19079, total_loss: 4.477153778076172
training step: 19080, total_loss: 5.444032669067383
training step: 19081, total_loss: 4.277378082275391
training step: 19082, total_loss: 4.975435256958008
training step: 19083, total_loss: 4.339685916900635
training step: 19084, total_loss: 3.343532085418701
training step: 19085, total_loss: 3.7513232231140137
training step: 19086, total_loss: 4.589353084564209
training step: 19087, total_loss: 4.464481353759766
training step: 19088, total_loss: 4.413146495819092
training step: 19089, total_loss: 4.107695579528809
training step: 19090, total_loss: 2.461209774017334
training step: 19091, total_loss: 5.652111053466797
training step: 19092, total_loss: 5.150579452514648
training step: 19093, total_loss: 5.313957214355469
training step: 19094, total_loss: 4.378901958465576
training step: 19095, total_loss: 5.983662128448486
training step: 19096, total_loss: 5.540314197540283
training step: 19097, total_loss: 5.192117691040039
training step: 19098, total_loss: 3.661146640777588
training step: 19099, total_loss: 3.8765835762023926
training step: 19100, total_loss: 3.6740055084228516
training step: 19101, total_loss: 2.7240447998046875
training step: 19102, total_loss: 3.3436121940612793
training step: 19103, total_loss: 2.4778194427490234
training step: 19104, total_loss: 1.3125474452972412
training step: 19105, total_loss: 5.444872856140137
training step: 19106, total_loss: 3.0860743522644043
training step: 19107, total_loss: 4.765089511871338
training step: 19108, total_loss: 5.780383110046387
training step: 19109, total_loss: 4.114934921264648
training step: 19110, total_loss: 3.2508692741394043
training step: 19111, total_loss: 5.150285720825195
training step: 19112, total_loss: 3.869717836380005
training step: 19113, total_loss: 4.763212203979492
training step: 19114, total_loss: 3.918501615524292
training step: 19115, total_loss: 2.750793933868408
training step: 19116, total_loss: 1.2002971172332764
training step: 19117, total_loss: 4.532041549682617
training step: 19118, total_loss: 3.6759133338928223
training step: 19119, total_loss: 5.596809387207031
training step: 19120, total_loss: 3.9430384635925293
training step: 19121, total_loss: 4.541025161743164
training step: 19122, total_loss: 4.684309005737305
training step: 19123, total_loss: 3.4270942211151123
training step: 19124, total_loss: 3.678891658782959
training step: 19125, total_loss: 3.877436637878418
training step: 19126, total_loss: 4.921755790710449
training step: 19127, total_loss: 4.688136100769043
training step: 19128, total_loss: 3.2754368782043457
training step: 19129, total_loss: 3.3078489303588867
training step: 19130, total_loss: 5.013913631439209
training step: 19131, total_loss: 3.3895716667175293
training step: 19132, total_loss: 2.759408712387085
training step: 19133, total_loss: 4.136801719665527
training step: 19134, total_loss: 5.722563743591309
training step: 19135, total_loss: 5.984230041503906
training step: 19136, total_loss: 3.844529151916504
training step: 19137, total_loss: 6.962808609008789
training step: 19138, total_loss: 5.43916130065918
training step: 19139, total_loss: 4.653958320617676
training step: 19140, total_loss: 3.9411234855651855
training step: 19141, total_loss: 4.9677300453186035
training step: 19142, total_loss: 3.862222194671631
training step: 19143, total_loss: 4.1181640625
training step: 19144, total_loss: 4.2557806968688965
training step: 19145, total_loss: 4.140134334564209
training step: 19146, total_loss: 5.329407215118408
training step: 19147, total_loss: 4.533510684967041
training step: 19148, total_loss: 4.214735984802246
training step: 19149, total_loss: 4.4751458168029785
training step: 19150, total_loss: 4.218478679656982
training step: 19151, total_loss: 4.74853515625
training step: 19152, total_loss: 4.3722639083862305
training step: 19153, total_loss: 3.8768138885498047
training step: 19154, total_loss: 4.132735252380371
training step: 19155, total_loss: 3.5843899250030518
training step: 19156, total_loss: 5.075933456420898
training step: 19157, total_loss: 3.7099828720092773
training step: 19158, total_loss: 5.309317588806152
training step: 19159, total_loss: 5.369386672973633
training step: 19160, total_loss: 4.637009620666504
training step: 19161, total_loss: 4.718100547790527
training step: 19162, total_loss: 4.152449131011963
training step: 19163, total_loss: 5.81766414642334
training step: 19164, total_loss: 3.9463183879852295
training step: 19165, total_loss: 4.374991416931152
training step: 19166, total_loss: 4.51484489440918
training step: 19167, total_loss: 3.524034261703491
training step: 19168, total_loss: 4.248880386352539
training step: 19169, total_loss: 5.7119622230529785
training step: 19170, total_loss: 2.1677446365356445
training step: 19171, total_loss: 7.147687911987305
training step: 19172, total_loss: 4.596719264984131
training step: 19173, total_loss: 6.014782905578613
training step: 19174, total_loss: 5.076258659362793
training step: 19175, total_loss: 5.4107513427734375
training step: 19176, total_loss: 4.040533065795898
training step: 19177, total_loss: 5.786594390869141
training step: 19178, total_loss: 4.580000877380371
training step: 19179, total_loss: 4.802779674530029
training step: 19180, total_loss: 5.381464004516602
training step: 19181, total_loss: 5.071802616119385
training step: 19182, total_loss: 4.195018768310547
training step: 19183, total_loss: 5.053297996520996
training step: 19184, total_loss: 4.697906017303467
training step: 19185, total_loss: 4.184264183044434
training step: 19186, total_loss: 4.746921539306641
training step: 19187, total_loss: 4.871171951293945
training step: 19188, total_loss: 5.398106575012207
training step: 19189, total_loss: 3.5233988761901855
training step: 19190, total_loss: 5.040757656097412
training step: 19191, total_loss: 4.16094970703125
training step: 19192, total_loss: 5.687952995300293
training step: 19193, total_loss: 4.082931995391846
training step: 19194, total_loss: 5.817991256713867
training step: 19195, total_loss: 4.691032409667969
training step: 19196, total_loss: 4.596481800079346
training step: 19197, total_loss: 4.61489200592041
training step: 19198, total_loss: 4.42917537689209
training step: 19199, total_loss: 4.85152006149292
training step: 19200, total_loss: 4.179188251495361
training step: 19201, total_loss: 3.2030553817749023
training step: 19202, total_loss: 4.205541610717773
training step: 19203, total_loss: 3.685926675796509
training step: 19204, total_loss: 5.5857672691345215
training step: 19205, total_loss: 5.126380443572998
training step: 19206, total_loss: 4.758605480194092
training step: 19207, total_loss: 4.263421058654785
training step: 19208, total_loss: 7.971752166748047
training step: 19209, total_loss: 3.4268834590911865
training step: 19210, total_loss: 3.449333429336548
training step: 19211, total_loss: 3.513604164123535
training step: 19212, total_loss: 4.16402006149292
training step: 19213, total_loss: 4.430804252624512
training step: 19214, total_loss: 3.20717716217041
training step: 19215, total_loss: 3.6645853519439697
training step: 19216, total_loss: 5.146141052246094
training step: 19217, total_loss: 4.052753448486328
training step: 19218, total_loss: 3.171109199523926
training step: 19219, total_loss: 4.312110424041748
training step: 19220, total_loss: 4.616106986999512
training step: 19221, total_loss: 4.403646945953369
training step: 19222, total_loss: 5.285881042480469
training step: 19223, total_loss: 4.429945945739746
training step: 19224, total_loss: 3.685591220855713
training step: 19225, total_loss: 1.4022166728973389
training step: 19226, total_loss: 3.856137275695801
training step: 19227, total_loss: 5.006588935852051
training step: 19228, total_loss: 5.544121265411377
training step: 19229, total_loss: 6.5245842933654785
training step: 19230, total_loss: 4.5327630043029785
training step: 19231, total_loss: 4.5629987716674805
training step: 19232, total_loss: 4.099728584289551
training step: 19233, total_loss: 5.6021342277526855
training step: 19234, total_loss: 4.250954627990723
training step: 19235, total_loss: 2.764998197555542
training step: 19236, total_loss: 4.587174415588379
training step: 19237, total_loss: 4.267376899719238
training step: 19238, total_loss: 4.963567733764648
training step: 19239, total_loss: 4.278841018676758
training step: 19240, total_loss: 4.809374809265137
training step: 19241, total_loss: 5.35258150100708
training step: 19242, total_loss: 5.144278526306152
training step: 19243, total_loss: 5.19219446182251
training step: 19244, total_loss: 4.471378326416016
training step: 19245, total_loss: 3.6484785079956055
training step: 19246, total_loss: 3.476520538330078
training step: 19247, total_loss: 3.865513801574707
training step: 19248, total_loss: 4.624939441680908
training step: 19249, total_loss: 1.4353985786437988
training step: 19250, total_loss: 5.469269752502441
training step: 19251, total_loss: 5.372841835021973
training step: 19252, total_loss: 3.0601115226745605
training step: 19253, total_loss: 4.216991901397705
training step: 19254, total_loss: 3.0931732654571533
training step: 19255, total_loss: 5.350013256072998
training step: 19256, total_loss: 4.533215522766113
training step: 19257, total_loss: 4.022092819213867
training step: 19258, total_loss: 3.768735647201538
training step: 19259, total_loss: 5.735975742340088
training step: 19260, total_loss: 3.7476253509521484
training step: 19261, total_loss: 4.15910005569458
training step: 19262, total_loss: 4.93721866607666
training step: 19263, total_loss: 4.048189163208008
training step: 19264, total_loss: 5.329102993011475
training step: 19265, total_loss: 4.593292236328125
training step: 19266, total_loss: 3.5766820907592773
training step: 19267, total_loss: 4.424724578857422
training step: 19268, total_loss: 4.592263698577881
training step: 19269, total_loss: 4.632935047149658
training step: 19270, total_loss: 5.755136966705322
training step: 19271, total_loss: 4.720252513885498
training step: 19272, total_loss: 4.438966751098633
training step: 19273, total_loss: 4.850894927978516
training step: 19274, total_loss: 3.9642627239227295
training step: 19275, total_loss: 5.171604633331299
training step: 19276, total_loss: 3.3665218353271484
training step: 19277, total_loss: 3.469745635986328
training step: 19278, total_loss: 5.636097431182861
training step: 19279, total_loss: 5.207341194152832
training step: 19280, total_loss: 3.2684483528137207
training step: 19281, total_loss: 3.254422187805176
training step: 19282, total_loss: 4.271030426025391
training step: 19283, total_loss: 5.089103698730469
training step: 19284, total_loss: 2.96663236618042
training step: 19285, total_loss: 3.6522793769836426
training step: 19286, total_loss: 4.410606384277344
training step: 19287, total_loss: 5.045480251312256
training step: 19288, total_loss: 5.550951957702637
training step: 19289, total_loss: 4.646245956420898
training step: 19290, total_loss: 3.8227217197418213
training step: 19291, total_loss: 3.9131569862365723
training step: 19292, total_loss: 4.296050071716309
training step: 19293, total_loss: 4.513721466064453
training step: 19294, total_loss: 4.5626420974731445
training step: 19295, total_loss: 4.74254035949707
training step: 19296, total_loss: 3.836859703063965
training step: 19297, total_loss: 4.723400592803955
training step: 19298, total_loss: 3.812251567840576
training step: 19299, total_loss: 4.487722873687744
training step: 19300, total_loss: 4.657558441162109
training step: 19301, total_loss: 4.39451789855957
training step: 19302, total_loss: 4.688079833984375
training step: 19303, total_loss: 6.085910797119141
training step: 19304, total_loss: 2.6900181770324707
training step: 19305, total_loss: 4.842414379119873
training step: 19306, total_loss: 5.603961944580078
training step: 19307, total_loss: 4.1595258712768555
training step: 19308, total_loss: 3.8878560066223145
training step: 19309, total_loss: 5.0856428146362305
training step: 19310, total_loss: 5.860605239868164
training step: 19311, total_loss: 4.200495719909668
training step: 19312, total_loss: 5.035261154174805
training step: 19313, total_loss: 3.6730804443359375
training step: 19314, total_loss: 3.866057872772217
training step: 19315, total_loss: 4.216774940490723
training step: 19316, total_loss: 5.301416873931885
training step: 19317, total_loss: 7.2011613845825195
training step: 19318, total_loss: 7.63753080368042
training step: 19319, total_loss: 2.8604283332824707
training step: 19320, total_loss: 5.072175979614258
training step: 19321, total_loss: 3.7594542503356934
training step: 19322, total_loss: 3.7206192016601562
training step: 19323, total_loss: 3.5037691593170166
training step: 19324, total_loss: 3.615140438079834
training step: 19325, total_loss: 5.0836310386657715
training step: 19326, total_loss: 4.218554496765137
training step: 19327, total_loss: 2.3416695594787598
training step: 19328, total_loss: 5.9259538650512695
training step: 19329, total_loss: 5.585845947265625
training step: 19330, total_loss: 5.7416486740112305
training step: 19331, total_loss: 4.848432540893555
training step: 19332, total_loss: 4.71833610534668
training step: 19333, total_loss: 5.889915943145752
training step: 19334, total_loss: 5.924373626708984
training step: 19335, total_loss: 5.7979512214660645
training step: 19336, total_loss: 5.358707904815674
training step: 19337, total_loss: 4.30799674987793
training step: 19338, total_loss: 4.336117267608643
training step: 19339, total_loss: 3.762988567352295
training step: 19340, total_loss: 5.194148063659668
training step: 19341, total_loss: 5.316918849945068
training step: 19342, total_loss: 4.063136577606201
training step: 19343, total_loss: 3.7197272777557373
training step: 19344, total_loss: 5.776218891143799
training step: 19345, total_loss: 2.8868634700775146
training step: 19346, total_loss: 4.933167457580566
training step: 19347, total_loss: 4.501874923706055
training step: 19348, total_loss: 4.387333869934082
training step: 19349, total_loss: 4.095644474029541
training step: 19350, total_loss: 3.2743258476257324
training step: 19351, total_loss: 5.906869411468506
training step: 19352, total_loss: 6.050105571746826
training step: 19353, total_loss: 3.5599875450134277
training step: 19354, total_loss: 4.9391069412231445
training step: 19355, total_loss: 5.734372138977051
training step: 19356, total_loss: 5.532167911529541
training step: 19357, total_loss: 5.845328330993652
training step: 19358, total_loss: 2.886707305908203
training step: 19359, total_loss: 4.605837821960449
training step: 19360, total_loss: 4.542823314666748
training step: 19361, total_loss: 4.491933822631836
training step: 19362, total_loss: 4.891855239868164
training step: 19363, total_loss: 4.907383918762207
training step: 19364, total_loss: 5.674323081970215
training step: 19365, total_loss: 4.210801601409912
training step: 19366, total_loss: 4.357337951660156
training step: 19367, total_loss: 4.625804901123047
training step: 19368, total_loss: 4.2186079025268555
training step: 19369, total_loss: 4.676823616027832
training step: 19370, total_loss: 4.787102222442627
training step: 19371, total_loss: 4.979118347167969
training step: 19372, total_loss: 5.675528526306152
training step: 19373, total_loss: 3.091747760772705
training step: 19374, total_loss: 4.187861442565918
training step: 19375, total_loss: 4.601449966430664
training step: 19376, total_loss: 5.260050296783447
training step: 19377, total_loss: 4.114652633666992
training step: 19378, total_loss: 3.286160469055176
training step: 19379, total_loss: 4.867458820343018
training step: 19380, total_loss: 3.266101598739624
training step: 19381, total_loss: 5.557447910308838
training step: 19382, total_loss: 4.096158981323242
training step: 19383, total_loss: 4.080015659332275
training step: 19384, total_loss: 4.3051018714904785
training step: 19385, total_loss: 4.324344635009766
training step: 19386, total_loss: 4.613598346710205
training step: 19387, total_loss: 4.872601509094238
training step: 19388, total_loss: 4.6483259201049805
training step: 19389, total_loss: 4.517820358276367
training step: 19390, total_loss: 2.931097984313965
training step: 19391, total_loss: 4.951446056365967
training step: 19392, total_loss: 5.508364200592041
training step: 19393, total_loss: 3.8942675590515137
training step: 19394, total_loss: 3.471494197845459
training step: 19395, total_loss: 3.9512784481048584
training step: 19396, total_loss: 4.191018581390381
training step: 19397, total_loss: 5.298766613006592
training step: 19398, total_loss: 1.624103307723999
training step: 19399, total_loss: 5.86716365814209
training step: 19400, total_loss: 6.231603145599365
training step: 19401, total_loss: 5.849967956542969
training step: 19402, total_loss: 4.974540710449219
training step: 19403, total_loss: 3.7899513244628906
training step: 19404, total_loss: 4.636973857879639
training step: 19405, total_loss: 4.710102081298828
training step: 19406, total_loss: 3.1733272075653076
training step: 19407, total_loss: 5.67788028717041
training step: 19408, total_loss: 4.5449419021606445
training step: 19409, total_loss: 5.192849636077881
training step: 19410, total_loss: 3.721261739730835
training step: 19411, total_loss: 3.2547237873077393
training step: 19412, total_loss: 4.864717960357666
training step: 19413, total_loss: 4.1119184494018555
training step: 19414, total_loss: 4.688837051391602
training step: 19415, total_loss: 3.761573553085327
training step: 19416, total_loss: 5.022598743438721
training step: 19417, total_loss: 5.103928565979004
training step: 19418, total_loss: 4.8442912101745605
training step: 19419, total_loss: 5.05355167388916
training step: 19420, total_loss: 4.278471946716309
training step: 19421, total_loss: 4.120089530944824
training step: 19422, total_loss: 5.332283973693848
training step: 19423, total_loss: 3.6974048614501953
training step: 19424, total_loss: 2.4757843017578125
training step: 19425, total_loss: 3.457162857055664
training step: 19426, total_loss: 2.6632494926452637
training step: 19427, total_loss: 5.16900634765625
training step: 19428, total_loss: 4.110531806945801
training step: 19429, total_loss: 4.593838691711426
training step: 19430, total_loss: 5.927660942077637
training step: 19431, total_loss: 5.198711395263672
training step: 19432, total_loss: 3.914496421813965
training step: 19433, total_loss: 4.924208641052246
training step: 19434, total_loss: 5.246155738830566
training step: 19435, total_loss: 4.090925216674805
training step: 19436, total_loss: 2.9413297176361084
training step: 19437, total_loss: 3.379438877105713
training step: 19438, total_loss: 3.4268651008605957
training step: 19439, total_loss: 4.171639919281006
training step: 19440, total_loss: 3.673888921737671
training step: 19441, total_loss: 4.7063117027282715
training step: 19442, total_loss: 5.12379789352417
training step: 19443, total_loss: 4.9554877281188965
training step: 19444, total_loss: 4.288260459899902
training step: 19445, total_loss: 5.1303486824035645
training step: 19446, total_loss: 3.5314955711364746
training step: 19447, total_loss: 5.473657608032227
training step: 19448, total_loss: 3.5070033073425293
training step: 19449, total_loss: 2.8993024826049805
training step: 19450, total_loss: 5.675366401672363
training step: 19451, total_loss: 5.3479156494140625
training step: 19452, total_loss: 4.734847068786621
training step: 19453, total_loss: 2.912055015563965
training step: 19454, total_loss: 4.9197678565979
training step: 19455, total_loss: 2.4534060955047607
training step: 19456, total_loss: 5.49439811706543
training step: 19457, total_loss: 7.695639133453369
training step: 19458, total_loss: 4.494441032409668
training step: 19459, total_loss: 1.2279839515686035
training step: 19460, total_loss: 3.783912420272827
training step: 19461, total_loss: 5.4565348625183105
training step: 19462, total_loss: 4.01947021484375
training step: 19463, total_loss: 5.201233863830566
training step: 19464, total_loss: 5.032253265380859
training step: 19465, total_loss: 4.5389404296875
training step: 19466, total_loss: 4.241645812988281
training step: 19467, total_loss: 4.101494789123535
training step: 19468, total_loss: 4.261012077331543
training step: 19469, total_loss: 5.303013801574707
training step: 19470, total_loss: 4.673942565917969
training step: 19471, total_loss: 5.910436153411865
training step: 19472, total_loss: 5.106184005737305
training step: 19473, total_loss: 4.227738380432129
training step: 19474, total_loss: 4.685903549194336
training step: 19475, total_loss: 5.428646087646484
training step: 19476, total_loss: 4.40235710144043
training step: 19477, total_loss: 4.885168552398682
training step: 19478, total_loss: 4.481637001037598
training step: 19479, total_loss: 4.4741740226745605
training step: 19480, total_loss: 4.055413246154785
training step: 19481, total_loss: 4.992732524871826
training step: 19482, total_loss: 4.968232154846191
training step: 19483, total_loss: 4.139174938201904
training step: 19484, total_loss: 4.863927841186523
training step: 19485, total_loss: 4.876352787017822
training step: 19486, total_loss: 5.103792667388916
training step: 19487, total_loss: 4.464413642883301
training step: 19488, total_loss: 4.304349422454834
training step: 19489, total_loss: 3.4473958015441895
training step: 19490, total_loss: 4.403848648071289
training step: 19491, total_loss: 5.023375034332275
training step: 19492, total_loss: 4.989681243896484
training step: 19493, total_loss: 5.969407558441162
training step: 19494, total_loss: 3.8466835021972656
training step: 19495, total_loss: 5.333323001861572
training step: 19496, total_loss: 4.291993618011475
training step: 19497, total_loss: 4.978682994842529
training step: 19498, total_loss: 3.5068721771240234
training step: 19499, total_loss: 7.183835983276367
training step: 19500, total_loss: 4.415258407592773
training step: 19501, total_loss: 4.40692138671875
training step: 19502, total_loss: 4.229009628295898
training step: 19503, total_loss: 3.2677054405212402
training step: 19504, total_loss: 4.982151031494141
training step: 19505, total_loss: 4.555810928344727
training step: 19506, total_loss: 4.725214004516602
training step: 19507, total_loss: 5.215191841125488
training step: 19508, total_loss: 3.2198634147644043
training step: 19509, total_loss: 5.161412239074707
training step: 19510, total_loss: 5.778836250305176
training step: 19511, total_loss: 4.600213050842285
training step: 19512, total_loss: 5.129545211791992
training step: 19513, total_loss: 5.893022537231445
training step: 19514, total_loss: 3.9848573207855225
training step: 19515, total_loss: 5.148198127746582
training step: 19516, total_loss: 5.41533088684082
training step: 19517, total_loss: 4.820631504058838
training step: 19518, total_loss: 3.5951313972473145
training step: 19519, total_loss: 5.554599761962891
training step: 19520, total_loss: 5.624454498291016
training step: 19521, total_loss: 6.7606706619262695
training step: 19522, total_loss: 4.432729244232178
training step: 19523, total_loss: 4.7023091316223145
training step: 19524, total_loss: 4.932915210723877
training step: 19525, total_loss: 4.000144004821777
training step: 19526, total_loss: 4.939393043518066
training step: 19527, total_loss: 5.680233955383301
training step: 19528, total_loss: 4.49818229675293
training step: 19529, total_loss: 5.226980209350586
training step: 19530, total_loss: 3.415264129638672
training step: 19531, total_loss: 4.6213059425354
training step: 19532, total_loss: 4.738771438598633
training step: 19533, total_loss: 5.439056873321533
training step: 19534, total_loss: 4.727308750152588
training step: 19535, total_loss: 4.126470565795898
training step: 19536, total_loss: 4.442047119140625
training step: 19537, total_loss: 5.517739295959473
training step: 19538, total_loss: 4.276111602783203
training step: 19539, total_loss: 5.885940074920654
training step: 19540, total_loss: 4.794919013977051
training step: 19541, total_loss: 3.911273956298828
training step: 19542, total_loss: 6.2045512199401855
training step: 19543, total_loss: 5.203036785125732
training step: 19544, total_loss: 5.432244300842285
training step: 19545, total_loss: 4.80535888671875
training step: 19546, total_loss: 4.5111541748046875
training step: 19547, total_loss: 4.669247150421143
training step: 19548, total_loss: 4.221569061279297
training step: 19549, total_loss: 5.3150835037231445
training step: 19550, total_loss: 4.025568962097168
training step: 19551, total_loss: 5.324986457824707
training step: 19552, total_loss: 3.878000259399414
training step: 19553, total_loss: 3.9218058586120605
training step: 19554, total_loss: 3.886939525604248
training step: 19555, total_loss: 4.504717826843262
training step: 19556, total_loss: 5.104183197021484
training step: 19557, total_loss: 3.5415868759155273
training step: 19558, total_loss: 3.330552101135254
training step: 19559, total_loss: 5.674079418182373
training step: 19560, total_loss: 4.612928867340088
training step: 19561, total_loss: 4.365023136138916
training step: 19562, total_loss: 5.755999565124512
training step: 19563, total_loss: 3.8601322174072266
training step: 19564, total_loss: 2.968172550201416
training step: 19565, total_loss: 4.1116437911987305
training step: 19566, total_loss: 4.835162162780762
training step: 19567, total_loss: 2.72206974029541
training step: 19568, total_loss: 5.3463640213012695
training step: 19569, total_loss: 4.044365406036377
training step: 19570, total_loss: 3.7566933631896973
training step: 19571, total_loss: 4.219488620758057
training step: 19572, total_loss: 4.5021748542785645
training step: 19573, total_loss: 4.14987850189209
training step: 19574, total_loss: 4.5238847732543945
training step: 19575, total_loss: 4.773146629333496
training step: 19576, total_loss: 3.1113786697387695
training step: 19577, total_loss: 5.0053510665893555
training step: 19578, total_loss: 4.740533351898193
training step: 19579, total_loss: 3.8735275268554688
training step: 19580, total_loss: 4.1007537841796875
training step: 19581, total_loss: 5.6814985275268555
training step: 19582, total_loss: 5.035597801208496
training step: 19583, total_loss: 3.2439537048339844
training step: 19584, total_loss: 4.33531379699707
training step: 19585, total_loss: 4.594202995300293
training step: 19586, total_loss: 4.103189945220947
training step: 19587, total_loss: 4.049456596374512
training step: 19588, total_loss: 4.402752876281738
training step: 19589, total_loss: 4.026001930236816
training step: 19590, total_loss: 5.002835273742676
training step: 19591, total_loss: 4.5589165687561035
training step: 19592, total_loss: 3.7420291900634766
training step: 19593, total_loss: 4.3173322677612305
training step: 19594, total_loss: 4.211715221405029
training step: 19595, total_loss: 2.8013226985931396
training step: 19596, total_loss: 4.713983535766602
training step: 19597, total_loss: 5.28115177154541
training step: 19598, total_loss: 3.623839855194092
training step: 19599, total_loss: 3.7359542846679688
training step: 19600, total_loss: 7.100335597991943
training step: 19601, total_loss: 3.231128215789795
training step: 19602, total_loss: 3.24300479888916
training step: 19603, total_loss: 3.3886654376983643
training step: 19604, total_loss: 4.341794013977051
training step: 19605, total_loss: 1.6677210330963135
training step: 19606, total_loss: 6.502894401550293
training step: 19607, total_loss: 5.323841094970703
training step: 19608, total_loss: 3.892271041870117
training step: 19609, total_loss: 4.995509147644043
training step: 19610, total_loss: 5.028187274932861
training step: 19611, total_loss: 5.176346302032471
training step: 19612, total_loss: 3.936922550201416
training step: 19613, total_loss: 4.2039103507995605
training step: 19614, total_loss: 7.141796112060547
training step: 19615, total_loss: 6.27980899810791
training step: 19616, total_loss: 6.620220184326172
training step: 19617, total_loss: 1.8235619068145752
training step: 19618, total_loss: 5.209028244018555
training step: 19619, total_loss: 4.64256477355957
training step: 19620, total_loss: 4.3652873039245605
training step: 19621, total_loss: 4.243363380432129
training step: 19622, total_loss: 4.506482124328613
training step: 19623, total_loss: 1.3455617427825928
training step: 19624, total_loss: 3.9633798599243164
training step: 19625, total_loss: 3.674846649169922
training step: 19626, total_loss: 4.953472137451172
training step: 19627, total_loss: 5.382908344268799
training step: 19628, total_loss: 1.417722225189209
training step: 19629, total_loss: 5.683568954467773
training step: 19630, total_loss: 5.925405979156494
training step: 19631, total_loss: 4.2324628829956055
training step: 19632, total_loss: 5.57368278503418
training step: 19633, total_loss: 3.3678202629089355
training step: 19634, total_loss: 5.919952392578125
training step: 19635, total_loss: 1.2715582847595215
training step: 19636, total_loss: 4.906203269958496
training step: 19637, total_loss: 4.134518623352051
training step: 19638, total_loss: 4.532926082611084
training step: 19639, total_loss: 4.271158695220947
training step: 19640, total_loss: 4.466696739196777
training step: 19641, total_loss: 3.8899407386779785
training step: 19642, total_loss: 5.186217784881592
training step: 19643, total_loss: 4.160070896148682
training step: 19644, total_loss: 4.880558013916016
training step: 19645, total_loss: 2.973065137863159
training step: 19646, total_loss: 3.9630837440490723
training step: 19647, total_loss: 5.163504123687744
training step: 19648, total_loss: 4.1850199699401855
training step: 19649, total_loss: 3.594902992248535
training step: 19650, total_loss: 3.3817877769470215
training step: 19651, total_loss: 3.8847575187683105
training step: 19652, total_loss: 5.605655670166016
training step: 19653, total_loss: 4.989773750305176
training step: 19654, total_loss: 4.761268615722656
training step: 19655, total_loss: 5.372494220733643
training step: 19656, total_loss: 5.560450553894043
training step: 19657, total_loss: 4.699479103088379
training step: 19658, total_loss: 2.8403422832489014
training step: 19659, total_loss: 6.368058204650879
training step: 19660, total_loss: 3.206104278564453
training step: 19661, total_loss: 4.344080448150635
training step: 19662, total_loss: 3.5975937843322754
training step: 19663, total_loss: 1.1121681928634644
training step: 19664, total_loss: 2.656522274017334
training step: 19665, total_loss: 4.96041202545166
training step: 19666, total_loss: 4.875836372375488
training step: 19667, total_loss: 6.097682476043701
training step: 19668, total_loss: 4.2459306716918945
training step: 19669, total_loss: 4.633846759796143
training step: 19670, total_loss: 4.556881904602051
training step: 19671, total_loss: 1.1658823490142822
training step: 19672, total_loss: 4.186246871948242
training step: 19673, total_loss: 4.73112678527832
training step: 19674, total_loss: 3.935915946960449
training step: 19675, total_loss: 5.222803592681885
training step: 19676, total_loss: 4.390218257904053
training step: 19677, total_loss: 3.4445104598999023
training step: 19678, total_loss: 4.307750701904297
training step: 19679, total_loss: 2.768233299255371
training step: 19680, total_loss: 3.0548510551452637
training step: 19681, total_loss: 5.0528740882873535
training step: 19682, total_loss: 5.211415767669678
training step: 19683, total_loss: 3.4986541271209717
training step: 19684, total_loss: 4.368892669677734
training step: 19685, total_loss: 6.79490852355957
training step: 19686, total_loss: 5.167256832122803
training step: 19687, total_loss: 4.247419357299805
training step: 19688, total_loss: 5.265377998352051
training step: 19689, total_loss: 2.2899434566497803
training step: 19690, total_loss: 4.189388751983643
training step: 19691, total_loss: 5.273977756500244
training step: 19692, total_loss: 7.202638149261475
training step: 19693, total_loss: 3.2718374729156494
training step: 19694, total_loss: 3.971205711364746
training step: 19695, total_loss: 4.779443740844727
training step: 19696, total_loss: 2.711132049560547
training step: 19697, total_loss: 5.052233695983887
training step: 19698, total_loss: 4.003830909729004
training step: 19699, total_loss: 5.384852409362793
training step: 19700, total_loss: 3.8247904777526855
training step: 19701, total_loss: 4.444479942321777
training step: 19702, total_loss: 4.063298225402832
training step: 19703, total_loss: 6.569170951843262
training step: 19704, total_loss: 5.621837615966797
training step: 19705, total_loss: 3.822415351867676
training step: 19706, total_loss: 4.919745445251465
training step: 19707, total_loss: 4.443288803100586
training step: 19708, total_loss: 3.5957188606262207
training step: 19709, total_loss: 4.946791648864746
training step: 19710, total_loss: 4.8529253005981445
training step: 19711, total_loss: 4.092199802398682
training step: 19712, total_loss: 4.095839500427246
training step: 19713, total_loss: 4.419074535369873
training step: 19714, total_loss: 4.416423797607422
training step: 19715, total_loss: 5.4129838943481445
training step: 19716, total_loss: 6.712578296661377
training step: 19717, total_loss: 5.140841484069824
training step: 19718, total_loss: 5.083538055419922
training step: 19719, total_loss: 5.443673133850098
training step: 19720, total_loss: 5.509615898132324
training step: 19721, total_loss: 3.4766459465026855
training step: 19722, total_loss: 4.000046730041504
training step: 19723, total_loss: 3.644408702850342
training step: 19724, total_loss: 4.728048801422119
training step: 19725, total_loss: 3.7185256481170654
training step: 19726, total_loss: 5.865481376647949
training step: 19727, total_loss: 4.606197834014893
training step: 19728, total_loss: 4.066277027130127
training step: 19729, total_loss: 4.628117084503174
training step: 19730, total_loss: 3.931643009185791
training step: 19731, total_loss: 5.878163814544678
training step: 19732, total_loss: 5.6870551109313965
training step: 19733, total_loss: 3.1320629119873047
training step: 19734, total_loss: 3.1615488529205322
training step: 19735, total_loss: 4.304264545440674
training step: 19736, total_loss: 5.157008171081543
training step: 19737, total_loss: 3.4741053581237793
training step: 19738, total_loss: 2.3954596519470215
training step: 19739, total_loss: 3.7630250453948975
training step: 19740, total_loss: 3.841611385345459
training step: 19741, total_loss: 4.015682697296143
training step: 19742, total_loss: 4.302689075469971
training step: 19743, total_loss: 5.340615272521973
training step: 19744, total_loss: 4.674269676208496
training step: 19745, total_loss: 3.9180727005004883
training step: 19746, total_loss: 1.589099407196045
training step: 19747, total_loss: 3.9396753311157227
training step: 19748, total_loss: 4.610836029052734
training step: 19749, total_loss: 5.2232184410095215
training step: 19750, total_loss: 3.316943407058716
training step: 19751, total_loss: 5.423035621643066
training step: 19752, total_loss: 4.702269554138184
training step: 19753, total_loss: 4.928165435791016
training step: 19754, total_loss: 4.79848051071167
training step: 19755, total_loss: 2.562476396560669
training step: 19756, total_loss: 4.76291036605835
training step: 19757, total_loss: 5.051471710205078
training step: 19758, total_loss: 5.1201887130737305
training step: 19759, total_loss: 5.475371360778809
training step: 19760, total_loss: 4.426743507385254
training step: 19761, total_loss: 4.309129238128662
training step: 19762, total_loss: 3.503166437149048
training step: 19763, total_loss: 3.861104726791382
training step: 19764, total_loss: 3.426673650741577
training step: 19765, total_loss: 4.940267562866211
training step: 19766, total_loss: 4.764593601226807
training step: 19767, total_loss: 4.863356590270996
training step: 19768, total_loss: 5.662599563598633
training step: 19769, total_loss: 5.486747741699219
training step: 19770, total_loss: 4.049405097961426
training step: 19771, total_loss: 2.140029191970825
training step: 19772, total_loss: 4.783759593963623
training step: 19773, total_loss: 4.890610694885254
training step: 19774, total_loss: 5.2204718589782715
training step: 19775, total_loss: 3.126669406890869
training step: 19776, total_loss: 4.208601951599121
training step: 19777, total_loss: 3.9645771980285645
training step: 19778, total_loss: 5.6283416748046875
training step: 19779, total_loss: 4.119492053985596
training step: 19780, total_loss: 4.6126251220703125
training step: 19781, total_loss: 4.433967590332031
training step: 19782, total_loss: 3.5586118698120117
training step: 19783, total_loss: 4.934333801269531
training step: 19784, total_loss: 4.790069580078125
training step: 19785, total_loss: 6.504655838012695
training step: 19786, total_loss: 5.754938125610352
training step: 19787, total_loss: 4.6335368156433105
training step: 19788, total_loss: 4.410813808441162
training step: 19789, total_loss: 4.399048328399658
training step: 19790, total_loss: 4.457552909851074
training step: 19791, total_loss: 5.144233703613281
training step: 19792, total_loss: 3.890460968017578
training step: 19793, total_loss: 2.9882779121398926
training step: 19794, total_loss: 3.1273767948150635
training step: 19795, total_loss: 4.06502628326416
training step: 19796, total_loss: 4.771946907043457
training step: 19797, total_loss: 4.866156578063965
training step: 19798, total_loss: 4.659421920776367
training step: 19799, total_loss: 4.799252986907959
training step: 19800, total_loss: 4.425795555114746
training step: 19801, total_loss: 3.293367385864258
training step: 19802, total_loss: 6.05772590637207
training step: 19803, total_loss: 4.456657886505127
training step: 19804, total_loss: 4.985799789428711
training step: 19805, total_loss: 4.182182788848877
training step: 19806, total_loss: 5.664031505584717
training step: 19807, total_loss: 5.9975361824035645
training step: 19808, total_loss: 4.168780326843262
training step: 19809, total_loss: 4.440614700317383
training step: 19810, total_loss: 3.9766299724578857
training step: 19811, total_loss: 2.9221057891845703
training step: 19812, total_loss: 4.455032825469971
training step: 19813, total_loss: 2.6122636795043945
training step: 19814, total_loss: 4.8700690269470215
training step: 19815, total_loss: 4.595188140869141
training step: 19816, total_loss: 5.573812007904053
training step: 19817, total_loss: 4.946028232574463
training step: 19818, total_loss: 3.7265756130218506
training step: 19819, total_loss: 4.3870930671691895
training step: 19820, total_loss: 5.604742527008057
training step: 19821, total_loss: 4.538696765899658
training step: 19822, total_loss: 3.9077839851379395
training step: 19823, total_loss: 3.01149845123291
training step: 19824, total_loss: 4.676547050476074
training step: 19825, total_loss: 4.001162528991699
training step: 19826, total_loss: 5.091894149780273
training step: 19827, total_loss: 4.703395843505859
training step: 19828, total_loss: 8.020580291748047
training step: 19829, total_loss: 3.9089291095733643
training step: 19830, total_loss: 4.482356071472168
training step: 19831, total_loss: 5.313966751098633
training step: 19832, total_loss: 4.261457443237305
training step: 19833, total_loss: 2.7191720008850098
training step: 19834, total_loss: 4.800840854644775
training step: 19835, total_loss: 1.3015663623809814
training step: 19836, total_loss: 5.879061222076416
training step: 19837, total_loss: 4.558834075927734
training step: 19838, total_loss: 4.734044551849365
training step: 19839, total_loss: 5.365689277648926
training step: 19840, total_loss: 4.431274890899658
training step: 19841, total_loss: 4.48162841796875
training step: 19842, total_loss: 4.609740734100342
training step: 19843, total_loss: 5.339560508728027
training step: 19844, total_loss: 4.0257110595703125
training step: 19845, total_loss: 4.977497100830078
training step: 19846, total_loss: 2.4871158599853516
training step: 19847, total_loss: 4.982758522033691
training step: 19848, total_loss: 4.026886463165283
training step: 19849, total_loss: 4.703093528747559
training step: 19850, total_loss: 6.230022430419922
training step: 19851, total_loss: 4.693353652954102
training step: 19852, total_loss: 4.371690273284912
training step: 19853, total_loss: 4.78859806060791
training step: 19854, total_loss: 3.703096389770508
training step: 19855, total_loss: 4.225466251373291
training step: 19856, total_loss: 3.679297924041748
training step: 19857, total_loss: 2.7731118202209473
training step: 19858, total_loss: 3.3149900436401367
training step: 19859, total_loss: 5.347338676452637
training step: 19860, total_loss: 4.430441856384277
training step: 19861, total_loss: 4.185464382171631
training step: 19862, total_loss: 3.995460033416748
training step: 19863, total_loss: 4.976912498474121
training step: 19864, total_loss: 5.645116806030273
training step: 19865, total_loss: 4.258004188537598
training step: 19866, total_loss: 4.7168498039245605
training step: 19867, total_loss: 5.478578567504883
training step: 19868, total_loss: 5.304681777954102
training step: 19869, total_loss: 6.16127872467041
training step: 19870, total_loss: 4.357234954833984
training step: 19871, total_loss: 4.176776885986328
training step: 19872, total_loss: 3.1072230339050293
training step: 19873, total_loss: 4.242803573608398
training step: 19874, total_loss: 1.0247124433517456
training step: 19875, total_loss: 5.541677474975586
training step: 19876, total_loss: 4.566555976867676
training step: 19877, total_loss: 3.625387191772461
training step: 19878, total_loss: 2.6068527698516846
training step: 19879, total_loss: 4.476495742797852
training step: 19880, total_loss: 5.521954536437988
training step: 19881, total_loss: 4.670135498046875
training step: 19882, total_loss: 4.38898229598999
training step: 19883, total_loss: 5.67679500579834
training step: 19884, total_loss: 3.206605911254883
training step: 19885, total_loss: 2.275747299194336
training step: 19886, total_loss: 4.707177639007568
training step: 19887, total_loss: 5.050947666168213
training step: 19888, total_loss: 3.1745007038116455
training step: 19889, total_loss: 4.284501075744629
training step: 19890, total_loss: 3.1432337760925293
training step: 19891, total_loss: 5.098828315734863
training step: 19892, total_loss: 3.7731456756591797
training step: 19893, total_loss: 4.393794536590576
training step: 19894, total_loss: 4.73601770401001
training step: 19895, total_loss: 3.815211057662964
training step: 19896, total_loss: 4.996731758117676
training step: 19897, total_loss: 3.544754981994629
training step: 19898, total_loss: 5.506624221801758
training step: 19899, total_loss: 5.770493984222412
training step: 19900, total_loss: 5.046173572540283
training step: 19901, total_loss: 5.711183547973633
training step: 19902, total_loss: 5.18613338470459
training step: 19903, total_loss: 3.8670952320098877
training step: 19904, total_loss: 5.061820983886719
training step: 19905, total_loss: 5.395138263702393
training step: 19906, total_loss: 2.4325430393218994
training step: 19907, total_loss: 4.093303203582764
training step: 19908, total_loss: 4.5081868171691895
training step: 19909, total_loss: 6.490933418273926
training step: 19910, total_loss: 4.859065532684326
training step: 19911, total_loss: 5.1636810302734375
training step: 19912, total_loss: 4.137664794921875
training step: 19913, total_loss: 5.905750274658203
training step: 19914, total_loss: 4.974327087402344
training step: 19915, total_loss: 5.095939636230469
training step: 19916, total_loss: 3.3202781677246094
training step: 19917, total_loss: 4.35051965713501
training step: 19918, total_loss: 3.8893966674804688
training step: 19919, total_loss: 4.224433898925781
training step: 19920, total_loss: 4.549117565155029
training step: 19921, total_loss: 3.7322096824645996
training step: 19922, total_loss: 4.805054664611816
training step: 19923, total_loss: 4.313011169433594
training step: 19924, total_loss: 5.989902496337891
training step: 19925, total_loss: 4.943428993225098
training step: 19926, total_loss: 4.543001174926758
training step: 19927, total_loss: 4.29835319519043
training step: 19928, total_loss: 6.102298736572266
training step: 19929, total_loss: 4.0131072998046875
training step: 19930, total_loss: 4.858239650726318
training step: 19931, total_loss: 5.546988487243652
training step: 19932, total_loss: 1.2744700908660889
training step: 19933, total_loss: 4.55455207824707
training step: 19934, total_loss: 5.088644981384277
training step: 19935, total_loss: 5.750097751617432
training step: 19936, total_loss: 4.225306510925293
training step: 19937, total_loss: 4.834356307983398
training step: 19938, total_loss: 3.331225872039795
training step: 19939, total_loss: 5.1205058097839355
training step: 19940, total_loss: 3.9666624069213867
training step: 19941, total_loss: 5.7514848709106445
training step: 19942, total_loss: 3.7967348098754883
training step: 19943, total_loss: 5.395384788513184
training step: 19944, total_loss: 5.195598602294922
training step: 19945, total_loss: 5.341907978057861
training step: 19946, total_loss: 5.486220359802246
training step: 19947, total_loss: 5.074491500854492
training step: 19948, total_loss: 3.499817371368408
training step: 19949, total_loss: 4.179537296295166
training step: 19950, total_loss: 4.515841484069824
training step: 19951, total_loss: 5.084677696228027
training step: 19952, total_loss: 4.8800482749938965
training step: 19953, total_loss: 4.327032089233398
training step: 19954, total_loss: 3.6653389930725098
training step: 19955, total_loss: 4.204611778259277
training step: 19956, total_loss: 3.8669588565826416
training step: 19957, total_loss: 4.3068366050720215
training step: 19958, total_loss: 3.3414337635040283
training step: 19959, total_loss: 4.621832847595215
training step: 19960, total_loss: 4.76698112487793
training step: 19961, total_loss: 4.867302894592285
training step: 19962, total_loss: 5.4919843673706055
training step: 19963, total_loss: 5.926241397857666
training step: 19964, total_loss: 6.1288251876831055
training step: 19965, total_loss: 1.1716153621673584
training step: 19966, total_loss: 5.714203834533691
training step: 19967, total_loss: 4.774118423461914
training step: 19968, total_loss: 4.806367874145508
training step: 19969, total_loss: 5.813509464263916
training step: 19970, total_loss: 5.815276145935059
training step: 19971, total_loss: 4.993776321411133
training step: 19972, total_loss: 4.351504802703857
training step: 19973, total_loss: 5.4027814865112305
training step: 19974, total_loss: 5.0266947746276855
training step: 19975, total_loss: 3.8317220211029053
training step: 19976, total_loss: 5.277411460876465
training step: 19977, total_loss: 4.519028663635254
training step: 19978, total_loss: 4.510254383087158
training step: 19979, total_loss: 5.09450626373291
training step: 19980, total_loss: 3.077099323272705
training step: 19981, total_loss: 4.083670616149902
training step: 19982, total_loss: 5.178831100463867
training step: 19983, total_loss: 4.095603942871094
training step: 19984, total_loss: 4.308475971221924
training step: 19985, total_loss: 4.623274803161621
training step: 19986, total_loss: 3.2989659309387207
training step: 19987, total_loss: 5.446669578552246
training step: 19988, total_loss: 4.616012096405029
training step: 19989, total_loss: 5.359382629394531
training step: 19990, total_loss: 2.883331775665283
training step: 19991, total_loss: 3.0107240676879883
training step: 19992, total_loss: 4.132068634033203
training step: 19993, total_loss: 4.822879314422607
training step: 19994, total_loss: 2.8942432403564453
training step: 19995, total_loss: 2.485015392303467
training step: 19996, total_loss: 3.8553009033203125
training step: 19997, total_loss: 4.796928405761719
training step: 19998, total_loss: 5.025418281555176
training step: 19999, total_loss: 4.896507263183594
training step: 20000, total_loss: 3.9577181339263916
training step: 20001, total_loss: 4.440000534057617
training step: 20002, total_loss: 5.373284339904785
training step: 20003, total_loss: 4.443267822265625
training step: 20004, total_loss: 5.449577331542969
training step: 20005, total_loss: 4.257290840148926
training step: 20006, total_loss: 4.427867889404297
training step: 20007, total_loss: 1.4879107475280762
training step: 20008, total_loss: 4.952917575836182
training step: 20009, total_loss: 3.99318265914917
training step: 20010, total_loss: 5.097877025604248
training step: 20011, total_loss: 4.277099132537842
training step: 20012, total_loss: 4.690480709075928
training step: 20013, total_loss: 3.4472475051879883
training step: 20014, total_loss: 2.913982391357422
training step: 20015, total_loss: 3.9374825954437256
training step: 20016, total_loss: 4.560083389282227
training step: 20017, total_loss: 3.5563998222351074
training step: 20018, total_loss: 4.482975959777832
training step: 20019, total_loss: 3.550616979598999
training step: 20020, total_loss: 2.1856720447540283
training step: 20021, total_loss: 4.756064414978027
training step: 20022, total_loss: 5.222176551818848
training step: 20023, total_loss: 2.221405029296875
training step: 20024, total_loss: 1.8457794189453125
training step: 20025, total_loss: 3.7948317527770996
training step: 20026, total_loss: 3.006751537322998
training step: 20027, total_loss: 3.3368144035339355
training step: 20028, total_loss: 3.400987148284912
training step: 20029, total_loss: 3.2785565853118896
training step: 20030, total_loss: 4.021514892578125
training step: 20031, total_loss: 2.998602867126465
training step: 20032, total_loss: 2.6585090160369873
training step: 20033, total_loss: 3.7428784370422363
training step: 20034, total_loss: 4.706011772155762
training step: 20035, total_loss: 5.596527099609375
training step: 20036, total_loss: 3.8007960319519043
training step: 20037, total_loss: 4.558629035949707
training step: 20038, total_loss: 2.5861644744873047
training step: 20039, total_loss: 2.5515997409820557
training step: 20040, total_loss: 4.314785003662109
training step: 20041, total_loss: 3.7211949825286865
training step: 20042, total_loss: 4.918665885925293
training step: 20043, total_loss: 4.501477241516113
training step: 20044, total_loss: 2.069213390350342
training step: 20045, total_loss: 1.4867585897445679
training step: 20046, total_loss: 4.5036725997924805
training step: 20047, total_loss: 2.8799235820770264
training step: 20048, total_loss: 3.9208717346191406
training step: 20049, total_loss: 6.660076141357422
training step: 20050, total_loss: 5.49518346786499
training step: 20051, total_loss: 4.428186416625977
training step: 20052, total_loss: 5.387147903442383
training step: 20053, total_loss: 6.030605316162109
training step: 20054, total_loss: 6.502771377563477
training step: 20055, total_loss: 4.973978519439697
training step: 20056, total_loss: 3.1292762756347656
training step: 20057, total_loss: 6.280556678771973
training step: 20058, total_loss: 4.173761367797852
training step: 20059, total_loss: 4.131750106811523
training step: 20060, total_loss: 7.067465305328369
training step: 20061, total_loss: 4.828466415405273
training step: 20062, total_loss: 4.711775779724121
training step: 20063, total_loss: 4.075157642364502
training step: 20064, total_loss: 4.401058197021484
training step: 20065, total_loss: 4.3164777755737305
training step: 20066, total_loss: 4.0582780838012695
training step: 20067, total_loss: 6.159514427185059
training step: 20068, total_loss: 5.194100379943848
training step: 20069, total_loss: 4.758147239685059
training step: 20070, total_loss: 4.86369514465332
training step: 20071, total_loss: 4.2661824226379395
training step: 20072, total_loss: 4.822479248046875
training step: 20073, total_loss: 6.721243858337402
training step: 20074, total_loss: 4.413952350616455
training step: 20075, total_loss: 4.005763530731201
training step: 20076, total_loss: 3.2642524242401123
training step: 20077, total_loss: 4.7981367111206055
training step: 20078, total_loss: 5.469415664672852
training step: 20079, total_loss: 3.572824001312256
training step: 20080, total_loss: 4.970093250274658
training step: 20081, total_loss: 4.3845438957214355
training step: 20082, total_loss: 4.742650032043457
training step: 20083, total_loss: 1.7538328170776367
training step: 20084, total_loss: 3.038388252258301
training step: 20085, total_loss: 5.074629783630371
training step: 20086, total_loss: 4.904606819152832
training step: 20087, total_loss: 4.668301582336426
training step: 20088, total_loss: 4.586776256561279
training step: 20089, total_loss: 5.437885761260986
training step: 20090, total_loss: 4.501163005828857
training step: 20091, total_loss: 4.253800392150879
training step: 20092, total_loss: 3.0198192596435547
training step: 20093, total_loss: 4.369116306304932
training step: 20094, total_loss: 3.597862720489502
training step: 20095, total_loss: 3.230238437652588
training step: 20096, total_loss: 4.715941905975342
training step: 20097, total_loss: 3.7416491508483887
training step: 20098, total_loss: 4.952581882476807
training step: 20099, total_loss: 3.541346788406372
training step: 20100, total_loss: 6.838716506958008
training step: 20101, total_loss: 4.914824485778809
training step: 20102, total_loss: 4.349576950073242
training step: 20103, total_loss: 6.117462635040283
training step: 20104, total_loss: 2.9925262928009033
training step: 20105, total_loss: 2.998908758163452
training step: 20106, total_loss: 6.062443733215332
training step: 20107, total_loss: 3.704049587249756
training step: 20108, total_loss: 4.395493507385254
training step: 20109, total_loss: 4.716907024383545
training step: 20110, total_loss: 4.908394813537598
training step: 20111, total_loss: 5.102908134460449
training step: 20112, total_loss: 3.883342981338501
training step: 20113, total_loss: 4.340576648712158
training step: 20114, total_loss: 5.043737888336182
training step: 20115, total_loss: 3.90254545211792
training step: 20116, total_loss: 4.398014068603516
training step: 20117, total_loss: 4.6069464683532715
training step: 20118, total_loss: 3.166411876678467
training step: 20119, total_loss: 5.112273693084717
training step: 20120, total_loss: 3.890389919281006
training step: 20121, total_loss: 3.9191837310791016
training step: 20122, total_loss: 4.934067249298096
training step: 20123, total_loss: 4.33981990814209
training step: 20124, total_loss: 5.6779375076293945
training step: 20125, total_loss: 3.1720781326293945
training step: 20126, total_loss: 6.078373908996582
training step: 20127, total_loss: 4.367239475250244
training step: 20128, total_loss: 4.525232791900635
training step: 20129, total_loss: 4.3239617347717285
training step: 20130, total_loss: 5.645419120788574
training step: 20131, total_loss: 3.5154263973236084
training step: 20132, total_loss: 4.978026866912842
training step: 20133, total_loss: 4.907581329345703
training step: 20134, total_loss: 5.152081489562988
training step: 20135, total_loss: 3.5732603073120117
training step: 20136, total_loss: 4.5356550216674805
training step: 20137, total_loss: 4.653220176696777
training step: 20138, total_loss: 4.619419097900391
training step: 20139, total_loss: 4.263016700744629
training step: 20140, total_loss: 6.88431453704834
training step: 20141, total_loss: 3.1752588748931885
training step: 20142, total_loss: 2.6515207290649414
training step: 20143, total_loss: 4.427033424377441
training step: 20144, total_loss: 3.9133005142211914
training step: 20145, total_loss: 4.28476619720459
training step: 20146, total_loss: 5.628013610839844
training step: 20147, total_loss: 4.009262561798096
training step: 20148, total_loss: 5.8530802726745605
training step: 20149, total_loss: 4.570363521575928
training step: 20150, total_loss: 4.0936479568481445
training step: 20151, total_loss: 4.764382362365723
training step: 20152, total_loss: 5.372441291809082
training step: 20153, total_loss: 4.332135200500488
training step: 20154, total_loss: 4.701851844787598
training step: 20155, total_loss: 3.5743443965911865
training step: 20156, total_loss: 5.492534637451172
training step: 20157, total_loss: 4.573181629180908
training step: 20158, total_loss: 3.6757798194885254
training step: 20159, total_loss: 4.065317630767822
training step: 20160, total_loss: 5.321087837219238
training step: 20161, total_loss: 5.115457534790039
training step: 20162, total_loss: 5.911632537841797
training step: 20163, total_loss: 4.706826210021973
training step: 20164, total_loss: 3.0879406929016113
training step: 20165, total_loss: 1.3174060583114624
training step: 20166, total_loss: 5.650309085845947
training step: 20167, total_loss: 6.5271406173706055
training step: 20168, total_loss: 5.466093063354492
training step: 20169, total_loss: 4.067000389099121
training step: 20170, total_loss: 3.3780770301818848
training step: 20171, total_loss: 4.23829460144043
training step: 20172, total_loss: 4.769132614135742
training step: 20173, total_loss: 4.970134258270264
training step: 20174, total_loss: 3.9213132858276367
training step: 20175, total_loss: 4.503547668457031
training step: 20176, total_loss: 6.3626508712768555
training step: 20177, total_loss: 4.959694862365723
training step: 20178, total_loss: 5.272363662719727
training step: 20179, total_loss: 4.657186508178711
training step: 20180, total_loss: 3.0478463172912598
training step: 20181, total_loss: 3.25260066986084
training step: 20182, total_loss: 3.279484987258911
training step: 20183, total_loss: 3.6192808151245117
training step: 20184, total_loss: 3.6549549102783203
training step: 20185, total_loss: 4.2790374755859375
training step: 20186, total_loss: 4.904905796051025
training step: 20187, total_loss: 1.1079121828079224
training step: 20188, total_loss: 3.687798500061035
training step: 20189, total_loss: 1.1151584386825562
training step: 20190, total_loss: 6.413054466247559
training step: 20191, total_loss: 5.35344123840332
training step: 20192, total_loss: 4.446751594543457
training step: 20193, total_loss: 3.7148208618164062
training step: 20194, total_loss: 4.6631059646606445
training step: 20195, total_loss: 4.615512371063232
training step: 20196, total_loss: 5.5753350257873535
training step: 20197, total_loss: 2.7408056259155273
training step: 20198, total_loss: 4.292778491973877
training step: 20199, total_loss: 4.45284366607666
training step: 20200, total_loss: 5.098845481872559
training step: 20201, total_loss: 5.418210983276367
training step: 20202, total_loss: 4.435022830963135
training step: 20203, total_loss: 2.286834239959717
training step: 20204, total_loss: 5.664249420166016
training step: 20205, total_loss: 5.125700950622559
training step: 20206, total_loss: 5.485644340515137
training step: 20207, total_loss: 4.4120917320251465
training step: 20208, total_loss: 5.089117527008057
training step: 20209, total_loss: 4.680773735046387
training step: 20210, total_loss: 4.6751556396484375
training step: 20211, total_loss: 8.005392074584961
training step: 20212, total_loss: 4.646732330322266
training step: 20213, total_loss: 5.91679573059082
training step: 20214, total_loss: 5.3947858810424805
training step: 20215, total_loss: 2.497483730316162
training step: 20216, total_loss: 4.694007873535156
training step: 20217, total_loss: 4.4346795082092285
training step: 20218, total_loss: 4.80213737487793
training step: 20219, total_loss: 5.2936553955078125
training step: 20220, total_loss: 4.203556537628174
training step: 20221, total_loss: 4.7110700607299805
training step: 20222, total_loss: 1.0904756784439087
training step: 20223, total_loss: 4.006312370300293
training step: 20224, total_loss: 4.485820770263672
training step: 20225, total_loss: 2.3689422607421875
training step: 20226, total_loss: 4.668324947357178
training step: 20227, total_loss: 4.804498672485352
training step: 20228, total_loss: 4.674627304077148
training step: 20229, total_loss: 4.779595375061035
training step: 20230, total_loss: 4.585959434509277
training step: 20231, total_loss: 3.2291359901428223
training step: 20232, total_loss: 5.016516208648682
training step: 20233, total_loss: 6.342844486236572
training step: 20234, total_loss: 4.376910209655762
training step: 20235, total_loss: 4.455231666564941
training step: 20236, total_loss: 3.6445837020874023
training step: 20237, total_loss: 5.038512229919434
training step: 20238, total_loss: 4.320067405700684
training step: 20239, total_loss: 4.620641231536865
training step: 20240, total_loss: 5.265205383300781
training step: 20241, total_loss: 4.590303421020508
training step: 20242, total_loss: 4.535152435302734
training step: 20243, total_loss: 4.819946765899658
training step: 20244, total_loss: 4.5805559158325195
training step: 20245, total_loss: 5.142353057861328
training step: 20246, total_loss: 2.913771629333496
training step: 20247, total_loss: 4.727660179138184
training step: 20248, total_loss: 5.054445266723633
training step: 20249, total_loss: 5.407894134521484
training step: 20250, total_loss: 3.2286267280578613
training step: 20251, total_loss: 4.078710556030273
training step: 20252, total_loss: 4.193167209625244
training step: 20253, total_loss: 3.8288745880126953
training step: 20254, total_loss: 6.626766204833984
training step: 20255, total_loss: 4.515783786773682
training step: 20256, total_loss: 4.115316867828369
training step: 20257, total_loss: 3.559354066848755
training step: 20258, total_loss: 2.7817139625549316
training step: 20259, total_loss: 4.872581481933594
training step: 20260, total_loss: 3.714458465576172
training step: 20261, total_loss: 4.218842506408691
training step: 20262, total_loss: 3.7889678478240967
training step: 20263, total_loss: 3.953498363494873
training step: 20264, total_loss: 5.475738525390625
training step: 20265, total_loss: 5.937073707580566
training step: 20266, total_loss: 4.836684226989746
training step: 20267, total_loss: 5.329127311706543
training step: 20268, total_loss: 3.979405403137207
training step: 20269, total_loss: 3.891524314880371
training step: 20270, total_loss: 4.788853168487549
training step: 20271, total_loss: 5.127762794494629
training step: 20272, total_loss: 6.012554168701172
training step: 20273, total_loss: 4.620828628540039
training step: 20274, total_loss: 4.61447811126709
training step: 20275, total_loss: 4.959837913513184
training step: 20276, total_loss: 5.276849746704102
training step: 20277, total_loss: 5.300652503967285
training step: 20278, total_loss: 5.800443649291992
training step: 20279, total_loss: 6.3916521072387695
training step: 20280, total_loss: 2.6626012325286865
training step: 20281, total_loss: 4.379190444946289
training step: 20282, total_loss: 5.938057899475098
training step: 20283, total_loss: 3.7948553562164307
training step: 20284, total_loss: 4.272476673126221
training step: 20285, total_loss: 3.341343402862549
training step: 20286, total_loss: 3.742265224456787
training step: 20287, total_loss: 4.391936302185059
training step: 20288, total_loss: 1.1390032768249512
training step: 20289, total_loss: 5.262306213378906
training step: 20290, total_loss: 4.246328353881836
training step: 20291, total_loss: 5.948472499847412
training step: 20292, total_loss: 4.870236396789551
training step: 20293, total_loss: 4.023332595825195
training step: 20294, total_loss: 5.1951141357421875
training step: 20295, total_loss: 5.805788993835449
training step: 20296, total_loss: 4.75808572769165
training step: 20297, total_loss: 2.70324969291687
training step: 20298, total_loss: 5.615882873535156
training step: 20299, total_loss: 2.952773332595825
training step: 20300, total_loss: 2.6997833251953125
training step: 20301, total_loss: 4.92012357711792
training step: 20302, total_loss: 4.503340244293213
training step: 20303, total_loss: 6.375800132751465
training step: 20304, total_loss: 5.9759931564331055
training step: 20305, total_loss: 4.705089092254639
training step: 20306, total_loss: 4.4969940185546875
training step: 20307, total_loss: 4.417909622192383
training step: 20308, total_loss: 2.08711314201355
training step: 20309, total_loss: 5.653748989105225
training step: 20310, total_loss: 4.965764999389648
training step: 20311, total_loss: 4.474946022033691
training step: 20312, total_loss: 5.525570869445801
training step: 20313, total_loss: 4.56818962097168
training step: 20314, total_loss: 3.9458956718444824
training step: 20315, total_loss: 4.655850410461426
training step: 20316, total_loss: 1.3221044540405273
training step: 20317, total_loss: 5.837199687957764
training step: 20318, total_loss: 4.010583877563477
training step: 20319, total_loss: 2.6945290565490723
training step: 20320, total_loss: 4.399040222167969
training step: 20321, total_loss: 3.793396234512329
training step: 20322, total_loss: 4.7683539390563965
training step: 20323, total_loss: 3.9994020462036133
training step: 20324, total_loss: 4.813071250915527
training step: 20325, total_loss: 3.6901402473449707
training step: 20326, total_loss: 4.127962589263916
training step: 20327, total_loss: 5.039816856384277
training step: 20328, total_loss: 5.159451484680176
training step: 20329, total_loss: 5.068361282348633
training step: 20330, total_loss: 4.0921101570129395
training step: 20331, total_loss: 5.881717681884766
training step: 20332, total_loss: 5.004607200622559
training step: 20333, total_loss: 3.3938045501708984
training step: 20334, total_loss: 4.275489807128906
training step: 20335, total_loss: 4.284735679626465
training step: 20336, total_loss: 4.946951866149902
training step: 20337, total_loss: 3.8806047439575195
training step: 20338, total_loss: 5.5199103355407715
training step: 20339, total_loss: 3.8136818408966064
training step: 20340, total_loss: 5.376400470733643
training step: 20341, total_loss: 5.63353157043457
training step: 20342, total_loss: 5.009807109832764
training step: 20343, total_loss: 4.904883861541748
training step: 20344, total_loss: 3.905308246612549
training step: 20345, total_loss: 4.459864616394043
training step: 20346, total_loss: 4.809093475341797
training step: 20347, total_loss: 4.1067376136779785
training step: 20348, total_loss: 4.114666938781738
training step: 20349, total_loss: 3.7281951904296875
training step: 20350, total_loss: 3.14017915725708
training step: 20351, total_loss: 4.091953277587891
training step: 20352, total_loss: 4.6764421463012695
training step: 20353, total_loss: 3.012918472290039
training step: 20354, total_loss: 4.196291923522949
training step: 20355, total_loss: 3.1299777030944824
training step: 20356, total_loss: 4.884507179260254
training step: 20357, total_loss: 3.4301111698150635
training step: 20358, total_loss: 4.647907733917236
training step: 20359, total_loss: 3.7788639068603516
training step: 20360, total_loss: 5.273899078369141
training step: 20361, total_loss: 5.096543312072754
training step: 20362, total_loss: 3.7937474250793457
training step: 20363, total_loss: 4.05585241317749
training step: 20364, total_loss: 4.926623344421387
training step: 20365, total_loss: 4.836758613586426
training step: 20366, total_loss: 5.293070316314697
training step: 20367, total_loss: 5.422269821166992
training step: 20368, total_loss: 3.807312488555908
training step: 20369, total_loss: 3.8871779441833496
training step: 20370, total_loss: 2.5361623764038086
training step: 20371, total_loss: 3.953023910522461
training step: 20372, total_loss: 7.161505699157715
training step: 20373, total_loss: 5.076105117797852
training step: 20374, total_loss: 2.103821277618408
training step: 20375, total_loss: 3.4826061725616455
training step: 20376, total_loss: 3.6629815101623535
training step: 20377, total_loss: 6.844761371612549
training step: 20378, total_loss: 3.4831695556640625
training step: 20379, total_loss: 4.413578033447266
training step: 20380, total_loss: 4.411797523498535
training step: 20381, total_loss: 4.5882697105407715
training step: 20382, total_loss: 5.338850975036621
training step: 20383, total_loss: 4.768050670623779
training step: 20384, total_loss: 4.245265960693359
training step: 20385, total_loss: 4.949493408203125
training step: 20386, total_loss: 3.0107126235961914
training step: 20387, total_loss: 5.106328964233398
training step: 20388, total_loss: 5.391997337341309
training step: 20389, total_loss: 5.245970726013184
training step: 20390, total_loss: 4.679034233093262
training step: 20391, total_loss: 4.529459476470947
training step: 20392, total_loss: 1.0320749282836914
training step: 20393, total_loss: 6.532666206359863
training step: 20394, total_loss: 1.1384814977645874
training step: 20395, total_loss: 1.8997364044189453
training step: 20396, total_loss: 5.5535383224487305
training step: 20397, total_loss: 5.258206367492676
training step: 20398, total_loss: 4.634459018707275
training step: 20399, total_loss: 4.262341499328613
training step: 20400, total_loss: 5.546327590942383
training step: 20401, total_loss: 4.4520063400268555
training step: 20402, total_loss: 4.869036674499512
training step: 20403, total_loss: 3.7139859199523926
training step: 20404, total_loss: 3.901945114135742
training step: 20405, total_loss: 4.765801906585693
training step: 20406, total_loss: 4.584826469421387
training step: 20407, total_loss: 6.072222709655762
training step: 20408, total_loss: 4.661792755126953
training step: 20409, total_loss: 4.520124435424805
training step: 20410, total_loss: 4.530882358551025
training step: 20411, total_loss: 3.7259457111358643
training step: 20412, total_loss: 5.447138786315918
training step: 20413, total_loss: 4.443828582763672
training step: 20414, total_loss: 4.53200626373291
training step: 20415, total_loss: 6.034883499145508
training step: 20416, total_loss: 3.576721668243408
training step: 20417, total_loss: 2.0967185497283936
training step: 20418, total_loss: 3.1757640838623047
training step: 20419, total_loss: 4.0186872482299805
training step: 20420, total_loss: 5.271903991699219
training step: 20421, total_loss: 3.8368477821350098
training step: 20422, total_loss: 5.326396942138672
training step: 20423, total_loss: 0.8357363939285278
training step: 20424, total_loss: 2.826448440551758
training step: 20425, total_loss: 4.9103240966796875
training step: 20426, total_loss: 2.7670164108276367
training step: 20427, total_loss: 3.2480037212371826
training step: 20428, total_loss: 4.1969099044799805
training step: 20429, total_loss: 4.596965789794922
training step: 20430, total_loss: 5.187655448913574
training step: 20431, total_loss: 3.4649720191955566
training step: 20432, total_loss: 4.836082458496094
training step: 20433, total_loss: 2.848390817642212
training step: 20434, total_loss: 5.049747467041016
training step: 20435, total_loss: 4.24821662902832
training step: 20436, total_loss: 4.219969749450684
training step: 20437, total_loss: 4.981684684753418
training step: 20438, total_loss: 3.4059336185455322
training step: 20439, total_loss: 2.9356045722961426
training step: 20440, total_loss: 4.742404937744141
training step: 20441, total_loss: 4.465057373046875
training step: 20442, total_loss: 3.3284592628479004
training step: 20443, total_loss: 4.977400779724121
training step: 20444, total_loss: 3.426180839538574
training step: 20445, total_loss: 5.146176338195801
training step: 20446, total_loss: 6.167717933654785
training step: 20447, total_loss: 4.663741111755371
training step: 20448, total_loss: 4.6039886474609375
training step: 20449, total_loss: 8.09126091003418
training step: 20450, total_loss: 5.3888397216796875
training step: 20451, total_loss: 5.266469955444336
training step: 20452, total_loss: 3.3789403438568115
training step: 20453, total_loss: 4.368454456329346
training step: 20454, total_loss: 5.164304256439209
training step: 20455, total_loss: 4.871561050415039
training step: 20456, total_loss: 3.7615599632263184
training step: 20457, total_loss: 4.702683448791504
training step: 20458, total_loss: 4.0532331466674805
training step: 20459, total_loss: 4.779548645019531
training step: 20460, total_loss: 5.436776161193848
training step: 20461, total_loss: 4.558932304382324
training step: 20462, total_loss: 4.793383598327637
training step: 20463, total_loss: 5.325127124786377
training step: 20464, total_loss: 1.2148404121398926
training step: 20465, total_loss: 6.0242085456848145
training step: 20466, total_loss: 4.15247917175293
training step: 20467, total_loss: 5.398978233337402
training step: 20468, total_loss: 3.8417458534240723
training step: 20469, total_loss: 3.8212947845458984
training step: 20470, total_loss: 6.004080295562744
training step: 20471, total_loss: 5.367883205413818
training step: 20472, total_loss: 3.319159507751465
training step: 20473, total_loss: 4.839229106903076
training step: 20474, total_loss: 4.313753128051758
training step: 20475, total_loss: 4.837815284729004
training step: 20476, total_loss: 4.330155372619629
training step: 20477, total_loss: 4.682272911071777
training step: 20478, total_loss: 2.61560320854187
training step: 20479, total_loss: 4.5666890144348145
training step: 20480, total_loss: 5.035828590393066
training step: 20481, total_loss: 4.050069332122803
training step: 20482, total_loss: 1.0907536745071411
training step: 20483, total_loss: 4.343173980712891
training step: 20484, total_loss: 3.962470531463623
training step: 20485, total_loss: 4.180309772491455
training step: 20486, total_loss: 2.6941261291503906
training step: 20487, total_loss: 4.52009391784668
training step: 20488, total_loss: 3.949147939682007
training step: 20489, total_loss: 2.5229744911193848
training step: 20490, total_loss: 4.847286224365234
training step: 20491, total_loss: 4.744953155517578
training step: 20492, total_loss: 4.865466117858887
training step: 20493, total_loss: 6.245113372802734
training step: 20494, total_loss: 4.599392414093018
training step: 20495, total_loss: 4.262691020965576
training step: 20496, total_loss: 4.319613456726074
training step: 20497, total_loss: 5.614833354949951
training step: 20498, total_loss: 4.954726219177246
training step: 20499, total_loss: 4.619746685028076
training step: 20500, total_loss: 5.446608543395996
training step: 20501, total_loss: 4.771539211273193
training step: 20502, total_loss: 4.964025497436523
training step: 20503, total_loss: 5.605352878570557
training step: 20504, total_loss: 4.422665596008301
training step: 20505, total_loss: 3.407837152481079
training step: 20506, total_loss: 3.121671676635742
training step: 20507, total_loss: 4.527634620666504
training step: 20508, total_loss: 4.969294548034668
training step: 20509, total_loss: 3.8545403480529785
training step: 20510, total_loss: 2.5338311195373535
training step: 20511, total_loss: 4.1124372482299805
training step: 20512, total_loss: 5.094930648803711
training step: 20513, total_loss: 4.163023948669434
training step: 20514, total_loss: 5.754721641540527
training step: 20515, total_loss: 5.924860000610352
training step: 20516, total_loss: 4.592044830322266
training step: 20517, total_loss: 4.915271759033203
training step: 20518, total_loss: 5.379658222198486
training step: 20519, total_loss: 2.10127854347229
training step: 20520, total_loss: 5.702004432678223
training step: 20521, total_loss: 5.59784460067749
training step: 20522, total_loss: 3.1746435165405273
training step: 20523, total_loss: 3.5684022903442383
training step: 20524, total_loss: 5.292802810668945
training step: 20525, total_loss: 5.497354507446289
training step: 20526, total_loss: 4.5785746574401855
training step: 20527, total_loss: 4.373766899108887
training step: 20528, total_loss: 4.770406246185303
training step: 20529, total_loss: 7.536380767822266
training step: 20530, total_loss: 4.559782981872559
training step: 20531, total_loss: 3.32401180267334
training step: 20532, total_loss: 4.332841396331787
training step: 20533, total_loss: 4.930907249450684
training step: 20534, total_loss: 4.432354927062988
training step: 20535, total_loss: 3.8857874870300293
training step: 20536, total_loss: 4.0031280517578125
training step: 20537, total_loss: 4.740112781524658
training step: 20538, total_loss: 4.217781066894531
training step: 20539, total_loss: 3.9428720474243164
training step: 20540, total_loss: 3.191472053527832
training step: 20541, total_loss: 3.066798448562622
training step: 20542, total_loss: 5.151993274688721
training step: 20543, total_loss: 4.107600212097168
training step: 20544, total_loss: 5.265782356262207
training step: 20545, total_loss: 4.250972270965576
training step: 20546, total_loss: 4.93052864074707
training step: 20547, total_loss: 4.569582462310791
training step: 20548, total_loss: 3.8777990341186523
training step: 20549, total_loss: 5.2397661209106445
training step: 20550, total_loss: 4.303093910217285
training step: 20551, total_loss: 5.211813926696777
training step: 20552, total_loss: 5.284197807312012
training step: 20553, total_loss: 4.272075176239014
training step: 20554, total_loss: 5.187577724456787
training step: 20555, total_loss: 4.855025768280029
training step: 20556, total_loss: 3.615760326385498
training step: 20557, total_loss: 4.353625774383545
training step: 20558, total_loss: 4.2301201820373535
training step: 20559, total_loss: 7.0037760734558105
training step: 20560, total_loss: 4.7219109535217285
training step: 20561, total_loss: 4.126531600952148
training step: 20562, total_loss: 5.916929244995117
training step: 20563, total_loss: 4.899504661560059
training step: 20564, total_loss: 4.592381000518799
training step: 20565, total_loss: 3.867100715637207
training step: 20566, total_loss: 3.885749340057373
training step: 20567, total_loss: 4.283811092376709
training step: 20568, total_loss: 4.174735069274902
training step: 20569, total_loss: 3.111496925354004
training step: 20570, total_loss: 3.6841492652893066
training step: 20571, total_loss: 5.66823148727417
training step: 20572, total_loss: 4.627932548522949
training step: 20573, total_loss: 4.983131408691406
training step: 20574, total_loss: 4.545886039733887
training step: 20575, total_loss: 4.5770158767700195
training step: 20576, total_loss: 2.7085254192352295
training step: 20577, total_loss: 4.379184722900391
training step: 20578, total_loss: 4.188933849334717
training step: 20579, total_loss: 4.3144121170043945
training step: 20580, total_loss: 3.001697301864624
training step: 20581, total_loss: 5.2566728591918945
training step: 20582, total_loss: 3.83115553855896
training step: 20583, total_loss: 5.2449541091918945
training step: 20584, total_loss: 5.338982105255127
training step: 20585, total_loss: 4.594532012939453
training step: 20586, total_loss: 4.145253658294678
training step: 20587, total_loss: 3.9741995334625244
training step: 20588, total_loss: 5.016997814178467
training step: 20589, total_loss: 3.7766480445861816
training step: 20590, total_loss: 3.5550222396850586
training step: 20591, total_loss: 4.115118980407715
training step: 20592, total_loss: 2.9895973205566406
training step: 20593, total_loss: 3.3873085975646973
training step: 20594, total_loss: 3.8607993125915527
training step: 20595, total_loss: 4.906928062438965
training step: 20596, total_loss: 5.522526264190674
training step: 20597, total_loss: 4.394038200378418
training step: 20598, total_loss: 3.390988826751709
training step: 20599, total_loss: 6.2112321853637695
training step: 20600, total_loss: 4.713583946228027
training step: 20601, total_loss: 4.759523868560791
training step: 20602, total_loss: 3.123643398284912
training step: 20603, total_loss: 4.754631996154785
training step: 20604, total_loss: 3.52734637260437
training step: 20605, total_loss: 3.6668801307678223
training step: 20606, total_loss: 3.881566047668457
training step: 20607, total_loss: 4.803753852844238
training step: 20608, total_loss: 5.58852481842041
training step: 20609, total_loss: 4.07723331451416
training step: 20610, total_loss: 4.757679462432861
training step: 20611, total_loss: 4.259998321533203
training step: 20612, total_loss: 4.7701826095581055
training step: 20613, total_loss: 5.279931545257568
training step: 20614, total_loss: 4.758865833282471
training step: 20615, total_loss: 5.606973648071289
training step: 20616, total_loss: 6.405143737792969
training step: 20617, total_loss: 3.4772987365722656
training step: 20618, total_loss: 5.279487133026123
training step: 20619, total_loss: 2.9505887031555176
training step: 20620, total_loss: 3.675565242767334
training step: 20621, total_loss: 2.7877097129821777
training step: 20622, total_loss: 2.923008680343628
training step: 20623, total_loss: 3.6337075233459473
training step: 20624, total_loss: 4.21949577331543
training step: 20625, total_loss: 5.7196855545043945
training step: 20626, total_loss: 5.027261734008789
training step: 20627, total_loss: 4.198866844177246
training step: 20628, total_loss: 3.596096992492676
training step: 20629, total_loss: 4.874460220336914
training step: 20630, total_loss: 4.794527530670166
training step: 20631, total_loss: 1.0307891368865967
training step: 20632, total_loss: 4.918514251708984
training step: 20633, total_loss: 5.629352569580078
training step: 20634, total_loss: 5.660175323486328
training step: 20635, total_loss: 3.566629409790039
training step: 20636, total_loss: 3.1392197608947754
training step: 20637, total_loss: 4.03639554977417
training step: 20638, total_loss: 3.14985990524292
training step: 20639, total_loss: 5.381453514099121
training step: 20640, total_loss: 1.0216307640075684
training step: 20641, total_loss: 3.6187615394592285
training step: 20642, total_loss: 3.9854626655578613
training step: 20643, total_loss: 5.063141822814941
training step: 20644, total_loss: 4.740875244140625
training step: 20645, total_loss: 3.4212660789489746
training step: 20646, total_loss: 2.7673583030700684
training step: 20647, total_loss: 3.0551528930664062
training step: 20648, total_loss: 3.8421764373779297
training step: 20649, total_loss: 4.461684226989746
training step: 20650, total_loss: 6.337066650390625
training step: 20651, total_loss: 5.315244674682617
training step: 20652, total_loss: 6.362936973571777
training step: 20653, total_loss: 3.8741369247436523
training step: 20654, total_loss: 5.602235794067383
training step: 20655, total_loss: 4.464566230773926
training step: 20656, total_loss: 5.260595321655273
training step: 20657, total_loss: 5.73051643371582
training step: 20658, total_loss: 4.626546859741211
training step: 20659, total_loss: 5.044447898864746
training step: 20660, total_loss: 5.383576393127441
training step: 20661, total_loss: 5.219902992248535
training step: 20662, total_loss: 5.036086082458496
training step: 20663, total_loss: 5.219422817230225
training step: 20664, total_loss: 5.039980888366699
training step: 20665, total_loss: 5.922539710998535
training step: 20666, total_loss: 6.938536167144775
training step: 20667, total_loss: 5.542244911193848
training step: 20668, total_loss: 4.332189083099365
training step: 20669, total_loss: 4.721312999725342
training step: 20670, total_loss: 2.3812642097473145
training step: 20671, total_loss: 4.564833641052246
training step: 20672, total_loss: 4.706233978271484
training step: 20673, total_loss: 6.010614395141602
training step: 20674, total_loss: 4.819573879241943
training step: 20675, total_loss: 3.646212100982666
training step: 20676, total_loss: 3.620880603790283
training step: 20677, total_loss: 3.002429246902466
training step: 20678, total_loss: 4.45377254486084
training step: 20679, total_loss: 5.886647701263428
training step: 20680, total_loss: 5.315471649169922
training step: 20681, total_loss: 4.578889846801758
training step: 20682, total_loss: 5.847021579742432
training step: 20683, total_loss: 2.758129835128784
training step: 20684, total_loss: 4.760870933532715
training step: 20685, total_loss: 0.9609388709068298
training step: 20686, total_loss: 4.251541614532471
training step: 20687, total_loss: 4.167886734008789
training step: 20688, total_loss: 5.017502784729004
training step: 20689, total_loss: 5.16949462890625
training step: 20690, total_loss: 4.604263782501221
training step: 20691, total_loss: 5.77591609954834
training step: 20692, total_loss: 6.2028303146362305
training step: 20693, total_loss: 5.159515380859375
training step: 20694, total_loss: 4.296271324157715
training step: 20695, total_loss: 5.52423095703125
training step: 20696, total_loss: 4.5402984619140625
training step: 20697, total_loss: 4.491273880004883
training step: 20698, total_loss: 5.841465950012207
training step: 20699, total_loss: 4.927988052368164
training step: 20700, total_loss: 1.1164000034332275
training step: 20701, total_loss: 5.272872447967529
training step: 20702, total_loss: 5.080021858215332
training step: 20703, total_loss: 6.048821449279785
training step: 20704, total_loss: 4.715888977050781
training step: 20705, total_loss: 4.892407417297363
training step: 20706, total_loss: 5.014032363891602
training step: 20707, total_loss: 4.635547637939453
training step: 20708, total_loss: 3.7758407592773438
training step: 20709, total_loss: 3.852189779281616
training step: 20710, total_loss: 3.6363492012023926
training step: 20711, total_loss: 5.974729537963867
training step: 20712, total_loss: 3.7712740898132324
training step: 20713, total_loss: 4.024384021759033
training step: 20714, total_loss: 4.960669040679932
training step: 20715, total_loss: 3.121159076690674
training step: 20716, total_loss: 5.306229591369629
training step: 20717, total_loss: 4.560490608215332
training step: 20718, total_loss: 4.6871442794799805
training step: 20719, total_loss: 4.691810131072998
training step: 20720, total_loss: 5.422039031982422
training step: 20721, total_loss: 5.515379905700684
training step: 20722, total_loss: 5.194997787475586
training step: 20723, total_loss: 4.830698013305664
training step: 20724, total_loss: 5.10578727722168
training step: 20725, total_loss: 2.6589560508728027
training step: 20726, total_loss: 4.109775543212891
training step: 20727, total_loss: 3.247588872909546
training step: 20728, total_loss: 5.461764812469482
training step: 20729, total_loss: 3.56777024269104
training step: 20730, total_loss: 3.7538869380950928
training step: 20731, total_loss: 5.955806732177734
training step: 20732, total_loss: 3.961914539337158
training step: 20733, total_loss: 4.934338569641113
training step: 20734, total_loss: 5.022847652435303
training step: 20735, total_loss: 2.2414326667785645
training step: 20736, total_loss: 3.98331618309021
training step: 20737, total_loss: 5.25393533706665
training step: 20738, total_loss: 4.91446590423584
training step: 20739, total_loss: 3.768872022628784
training step: 20740, total_loss: 4.635434150695801
training step: 20741, total_loss: 6.012367248535156
training step: 20742, total_loss: 4.1987152099609375
training step: 20743, total_loss: 3.511737823486328
training step: 20744, total_loss: 4.840127944946289
training step: 20745, total_loss: 5.576283931732178
training step: 20746, total_loss: 4.131588935852051
training step: 20747, total_loss: 4.915750503540039
training step: 20748, total_loss: 6.0062713623046875
training step: 20749, total_loss: 5.9812469482421875
training step: 20750, total_loss: 5.130584239959717
training step: 20751, total_loss: 5.264612197875977
training step: 20752, total_loss: 5.914342880249023
training step: 20753, total_loss: 4.994518280029297
training step: 20754, total_loss: 4.583348751068115
training step: 20755, total_loss: 3.6400818824768066
training step: 20756, total_loss: 4.684146881103516
training step: 20757, total_loss: 5.242439270019531
training step: 20758, total_loss: 4.619372367858887
training step: 20759, total_loss: 4.949284553527832
training step: 20760, total_loss: 4.69771671295166
training step: 20761, total_loss: 1.7293715476989746
training step: 20762, total_loss: 4.825018882751465
training step: 20763, total_loss: 4.6482415199279785
training step: 20764, total_loss: 4.473563194274902
training step: 20765, total_loss: 5.510947227478027
training step: 20766, total_loss: 3.8430097103118896
training step: 20767, total_loss: 4.97683572769165
training step: 20768, total_loss: 4.946098327636719
training step: 20769, total_loss: 6.49970817565918
training step: 20770, total_loss: 5.667669773101807
training step: 20771, total_loss: 5.041272163391113
training step: 20772, total_loss: 4.870295524597168
training step: 20773, total_loss: 5.087404727935791
training step: 20774, total_loss: 4.863213539123535
training step: 20775, total_loss: 4.777140140533447
training step: 20776, total_loss: 2.702106237411499
training step: 20777, total_loss: 4.806999206542969
training step: 20778, total_loss: 4.630252838134766
training step: 20779, total_loss: 4.536863327026367
training step: 20780, total_loss: 4.269723415374756
training step: 20781, total_loss: 3.420888900756836
training step: 20782, total_loss: 3.3746161460876465
training step: 20783, total_loss: 5.071510314941406
training step: 20784, total_loss: 4.049922943115234
training step: 20785, total_loss: 3.5356192588806152
training step: 20786, total_loss: 4.038303375244141
training step: 20787, total_loss: 4.673297882080078
training step: 20788, total_loss: 4.9151482582092285
training step: 20789, total_loss: 3.6822896003723145
training step: 20790, total_loss: 5.90673303604126
training step: 20791, total_loss: 4.150670051574707
training step: 20792, total_loss: 3.5769760608673096
training step: 20793, total_loss: 4.325076103210449
training step: 20794, total_loss: 4.018460273742676
training step: 20795, total_loss: 4.1966447830200195
training step: 20796, total_loss: 5.24141788482666
training step: 20797, total_loss: 4.003170013427734
training step: 20798, total_loss: 4.751866817474365
training step: 20799, total_loss: 3.4604978561401367
training step: 20800, total_loss: 4.330741882324219
training step: 20801, total_loss: 3.412868022918701
training step: 20802, total_loss: 3.2218222618103027
training step: 20803, total_loss: 4.959805488586426
training step: 20804, total_loss: 3.4959354400634766
training step: 20805, total_loss: 5.915872573852539
training step: 20806, total_loss: 4.8318352699279785
training step: 20807, total_loss: 4.750435829162598
training step: 20808, total_loss: 5.142770767211914
training step: 20809, total_loss: 4.862116813659668
training step: 20810, total_loss: 4.076934814453125
training step: 20811, total_loss: 4.537609100341797
training step: 20812, total_loss: 4.386092185974121
training step: 20813, total_loss: 5.374440670013428
training step: 20814, total_loss: 3.953212261199951
training step: 20815, total_loss: 5.1145405769348145
training step: 20816, total_loss: 5.819817543029785
training step: 20817, total_loss: 3.7835495471954346
training step: 20818, total_loss: 4.1013078689575195
training step: 20819, total_loss: 3.6845932006835938
training step: 20820, total_loss: 4.782445907592773
training step: 20821, total_loss: 5.020676136016846
training step: 20822, total_loss: 4.668797969818115
training step: 20823, total_loss: 4.106317043304443
training step: 20824, total_loss: 5.494873046875
training step: 20825, total_loss: 4.474353790283203
training step: 20826, total_loss: 4.68433952331543
training step: 20827, total_loss: 4.858908176422119
training step: 20828, total_loss: 2.892404556274414
training step: 20829, total_loss: 4.548177719116211
training step: 20830, total_loss: 3.9877524375915527
training step: 20831, total_loss: 3.3241100311279297
training step: 20832, total_loss: 4.123373985290527
training step: 20833, total_loss: 4.059581756591797
training step: 20834, total_loss: 5.7226786613464355
training step: 20835, total_loss: 3.9625182151794434
training step: 20836, total_loss: 4.895969867706299
training step: 20837, total_loss: 3.349053382873535
training step: 20838, total_loss: 4.68042516708374
training step: 20839, total_loss: 5.060222148895264
training step: 20840, total_loss: 2.6421055793762207
training step: 20841, total_loss: 3.5525095462799072
training step: 20842, total_loss: 4.710390567779541
training step: 20843, total_loss: 4.8112993240356445
training step: 20844, total_loss: 6.577723979949951
training step: 20845, total_loss: 3.670400381088257
training step: 20846, total_loss: 3.642479419708252
training step: 20847, total_loss: 3.127239227294922
training step: 20848, total_loss: 3.5303964614868164
training step: 20849, total_loss: 4.390760898590088
training step: 20850, total_loss: 2.949049234390259
training step: 20851, total_loss: 2.6868810653686523
training step: 20852, total_loss: 5.185885429382324
training step: 20853, total_loss: 5.076765060424805
training step: 20854, total_loss: 4.137310981750488
training step: 20855, total_loss: 4.867364406585693
training step: 20856, total_loss: 3.1478238105773926
training step: 20857, total_loss: 2.413433790206909
training step: 20858, total_loss: 5.100915908813477
training step: 20859, total_loss: 5.008345603942871
training step: 20860, total_loss: 4.524566650390625
training step: 20861, total_loss: 3.819840669631958
training step: 20862, total_loss: 2.4172613620758057
training step: 20863, total_loss: 5.715723037719727
training step: 20864, total_loss: 4.535689353942871
training step: 20865, total_loss: 5.1863226890563965
training step: 20866, total_loss: 5.932157039642334
training step: 20867, total_loss: 4.700477600097656
training step: 20868, total_loss: 4.229457855224609
training step: 20869, total_loss: 3.238603115081787
training step: 20870, total_loss: 4.997159004211426
training step: 20871, total_loss: 4.168607711791992
training step: 20872, total_loss: 4.796919822692871
training step: 20873, total_loss: 5.554309368133545
training step: 20874, total_loss: 5.944122791290283
training step: 20875, total_loss: 3.9577696323394775
training step: 20876, total_loss: 4.268077850341797
training step: 20877, total_loss: 4.634522438049316
training step: 20878, total_loss: 3.8832688331604004
training step: 20879, total_loss: 4.928877830505371
training step: 20880, total_loss: 3.6515707969665527
training step: 20881, total_loss: 5.589076042175293
training step: 20882, total_loss: 4.650938034057617
training step: 20883, total_loss: 4.124930381774902
training step: 20884, total_loss: 4.963860511779785
training step: 20885, total_loss: 4.177597522735596
training step: 20886, total_loss: 3.9138121604919434
training step: 20887, total_loss: 3.792731285095215
training step: 20888, total_loss: 4.597588062286377
training step: 20889, total_loss: 4.441668510437012
training step: 20890, total_loss: 4.930330276489258
training step: 20891, total_loss: 3.8485183715820312
training step: 20892, total_loss: 4.890832901000977
training step: 20893, total_loss: 6.043557643890381
training step: 20894, total_loss: 3.5777475833892822
training step: 20895, total_loss: 4.541320323944092
training step: 20896, total_loss: 3.240525960922241
training step: 20897, total_loss: 3.7663371562957764
training step: 20898, total_loss: 6.043126106262207
training step: 20899, total_loss: 1.405539631843567
training step: 20900, total_loss: 4.679586410522461
training step: 20901, total_loss: 5.079814434051514
training step: 20902, total_loss: 4.547411918640137
training step: 20903, total_loss: 5.929780006408691
training step: 20904, total_loss: 6.426004409790039
training step: 20905, total_loss: 5.078295707702637
training step: 20906, total_loss: 2.975395679473877
training step: 20907, total_loss: 2.4462876319885254
training step: 20908, total_loss: 3.7890658378601074
training step: 20909, total_loss: 3.5652503967285156
training step: 20910, total_loss: 4.858811378479004
training step: 20911, total_loss: 4.969459056854248
training step: 20912, total_loss: 2.474198818206787
training step: 20913, total_loss: 4.35203218460083
training step: 20914, total_loss: 1.32059645652771
training step: 20915, total_loss: 4.979945182800293
training step: 20916, total_loss: 3.472658634185791
training step: 20917, total_loss: 5.049838066101074
training step: 20918, total_loss: 4.24995756149292
training step: 20919, total_loss: 3.4760074615478516
training step: 20920, total_loss: 5.681527137756348
training step: 20921, total_loss: 6.464942932128906
training step: 20922, total_loss: 0.8922288417816162
training step: 20923, total_loss: 5.955254554748535
training step: 20924, total_loss: 3.6198108196258545
training step: 20925, total_loss: 4.820781707763672
training step: 20926, total_loss: 4.011063575744629
training step: 20927, total_loss: 3.61332631111145
training step: 20928, total_loss: 6.968576908111572
training step: 20929, total_loss: 2.727170467376709
training step: 20930, total_loss: 4.316758155822754
training step: 20931, total_loss: 3.825894832611084
training step: 20932, total_loss: 2.875868320465088
training step: 20933, total_loss: 4.597718715667725
training step: 20934, total_loss: 2.8590750694274902
training step: 20935, total_loss: 5.173213005065918
training step: 20936, total_loss: 5.724769592285156
training step: 20937, total_loss: 4.525834560394287
training step: 20938, total_loss: 4.698627471923828
training step: 20939, total_loss: 5.570224285125732
training step: 20940, total_loss: 5.478601455688477
training step: 20941, total_loss: 4.737856864929199
training step: 20942, total_loss: 5.888123989105225
training step: 20943, total_loss: 4.077645778656006
training step: 20944, total_loss: 4.4583516120910645
training step: 20945, total_loss: 4.268607139587402
training step: 20946, total_loss: 3.101745843887329
training step: 20947, total_loss: 4.166653156280518
training step: 20948, total_loss: 4.424082279205322
training step: 20949, total_loss: 1.97306489944458
training step: 20950, total_loss: 2.5232431888580322
training step: 20951, total_loss: 4.634070873260498
training step: 20952, total_loss: 6.738190174102783
training step: 20953, total_loss: 4.436397075653076
training step: 20954, total_loss: 5.738955497741699
training step: 20955, total_loss: 4.766681671142578
training step: 20956, total_loss: 5.655342102050781
training step: 20957, total_loss: 5.25782585144043
training step: 20958, total_loss: 5.305458068847656
training step: 20959, total_loss: 5.943118095397949
training step: 20960, total_loss: 5.057450294494629
training step: 20961, total_loss: 5.550538063049316
training step: 20962, total_loss: 2.7289905548095703
training step: 20963, total_loss: 4.659511089324951
training step: 20964, total_loss: 3.6357438564300537
training step: 20965, total_loss: 4.5652642250061035
training step: 20966, total_loss: 3.531097888946533
training step: 20967, total_loss: 4.932740211486816
training step: 20968, total_loss: 5.466756343841553
training step: 20969, total_loss: 4.113948822021484
training step: 20970, total_loss: 5.992412090301514
training step: 20971, total_loss: 4.538760185241699
training step: 20972, total_loss: 2.6730775833129883
training step: 20973, total_loss: 4.629565715789795
training step: 20974, total_loss: 5.407862663269043
training step: 20975, total_loss: 4.1272759437561035
training step: 20976, total_loss: 5.692696571350098
training step: 20977, total_loss: 5.5372185707092285
training step: 20978, total_loss: 4.589842796325684
training step: 20979, total_loss: 4.414536476135254
training step: 20980, total_loss: 4.769979476928711
training step: 20981, total_loss: 4.451053619384766
training step: 20982, total_loss: 4.442111492156982
training step: 20983, total_loss: 5.81578254699707
training step: 20984, total_loss: 4.676614761352539
training step: 20985, total_loss: 5.140637397766113
training step: 20986, total_loss: 6.099809646606445
training step: 20987, total_loss: 5.923537254333496
training step: 20988, total_loss: 4.203702449798584
training step: 20989, total_loss: 5.368800163269043
training step: 20990, total_loss: 3.356708526611328
training step: 20991, total_loss: 8.495671272277832
training step: 20992, total_loss: 3.7252559661865234
training step: 20993, total_loss: 3.7106690406799316
training step: 20994, total_loss: 5.426959037780762
training step: 20995, total_loss: 5.181332588195801
training step: 20996, total_loss: 5.365649223327637
training step: 20997, total_loss: 3.2736692428588867
training step: 20998, total_loss: 4.31591272354126
training step: 20999, total_loss: 5.207667827606201
training step: 21000, total_loss: 1.4460246562957764
training step: 21001, total_loss: 5.068352222442627
training step: 21002, total_loss: 5.121795177459717
training step: 21003, total_loss: 4.727658748626709
training step: 21004, total_loss: 3.2744088172912598
training step: 21005, total_loss: 4.2689738273620605
training step: 21006, total_loss: 5.76387882232666
training step: 21007, total_loss: 3.718615770339966
training step: 21008, total_loss: 3.4644651412963867
training step: 21009, total_loss: 6.299023628234863
training step: 21010, total_loss: 5.303865909576416
training step: 21011, total_loss: 4.3416337966918945
training step: 21012, total_loss: 3.555652618408203
training step: 21013, total_loss: 4.506800174713135
training step: 21014, total_loss: 5.555951118469238
training step: 21015, total_loss: 4.419698715209961
training step: 21016, total_loss: 4.086112976074219
training step: 21017, total_loss: 5.230905532836914
training step: 21018, total_loss: 5.386460304260254
training step: 21019, total_loss: 4.636141300201416
training step: 21020, total_loss: 5.3734846115112305
training step: 21021, total_loss: 5.085165977478027
training step: 21022, total_loss: 5.240749835968018
training step: 21023, total_loss: 5.144640922546387
training step: 21024, total_loss: 3.972054958343506
training step: 21025, total_loss: 4.720900535583496
training step: 21026, total_loss: 5.479537010192871
training step: 21027, total_loss: 5.231993675231934
training step: 21028, total_loss: 5.952341079711914
training step: 21029, total_loss: 4.3169331550598145
training step: 21030, total_loss: 6.168810844421387
training step: 21031, total_loss: 5.35453987121582
training step: 21032, total_loss: 2.540228843688965
training step: 21033, total_loss: 2.4885571002960205
training step: 21034, total_loss: 4.449944496154785
training step: 21035, total_loss: 5.928341865539551
training step: 21036, total_loss: 5.087793350219727
training step: 21037, total_loss: 3.7464613914489746
training step: 21038, total_loss: 4.687514781951904
training step: 21039, total_loss: 3.602635383605957
training step: 21040, total_loss: 5.119994640350342
training step: 21041, total_loss: 1.3636728525161743
training step: 21042, total_loss: 5.97080659866333
training step: 21043, total_loss: 3.539031982421875
training step: 21044, total_loss: 2.8244128227233887
training step: 21045, total_loss: 3.845521926879883
training step: 21046, total_loss: 3.476314067840576
training step: 21047, total_loss: 4.410810470581055
training step: 21048, total_loss: 5.4414963722229
training step: 21049, total_loss: 4.2213358879089355
training step: 21050, total_loss: 4.929598808288574
training step: 21051, total_loss: 4.359265327453613
training step: 21052, total_loss: 5.212685585021973
training step: 21053, total_loss: 5.665363311767578
training step: 21054, total_loss: 4.494472980499268
training step: 21055, total_loss: 5.3637237548828125
training step: 21056, total_loss: 4.642673492431641
training step: 21057, total_loss: 2.4196910858154297
training step: 21058, total_loss: 5.574457168579102
training step: 21059, total_loss: 2.5320966243743896
training step: 21060, total_loss: 4.026969909667969
training step: 21061, total_loss: 4.56661319732666
training step: 21062, total_loss: 5.2670488357543945
training step: 21063, total_loss: 4.8060760498046875
training step: 21064, total_loss: 5.6412353515625
training step: 21065, total_loss: 4.46270227432251
training step: 21066, total_loss: 3.84555721282959
training step: 21067, total_loss: 4.436496257781982
training step: 21068, total_loss: 4.629289627075195
training step: 21069, total_loss: 4.542256832122803
training step: 21070, total_loss: 3.842010974884033
training step: 21071, total_loss: 4.329791069030762
training step: 21072, total_loss: 4.472079277038574
training step: 21073, total_loss: 4.214123725891113
training step: 21074, total_loss: 4.822105884552002
training step: 21075, total_loss: 4.147555351257324
training step: 21076, total_loss: 4.198720932006836
training step: 21077, total_loss: 4.240761756896973
training step: 21078, total_loss: 4.7197418212890625
training step: 21079, total_loss: 3.3631577491760254
training step: 21080, total_loss: 4.6656036376953125
training step: 21081, total_loss: 2.513021469116211
training step: 21082, total_loss: 2.660889148712158
training step: 21083, total_loss: 3.5457823276519775
training step: 21084, total_loss: 5.274925708770752
training step: 21085, total_loss: 3.5072033405303955
training step: 21086, total_loss: 4.14624547958374
training step: 21087, total_loss: 4.564513206481934
training step: 21088, total_loss: 5.0955352783203125
training step: 21089, total_loss: 3.622770309448242
training step: 21090, total_loss: 3.968294858932495
training step: 21091, total_loss: 4.272993087768555
training step: 21092, total_loss: 6.281396865844727
training step: 21093, total_loss: 4.937810897827148
training step: 21094, total_loss: 4.9572319984436035
training step: 21095, total_loss: 5.292157173156738
training step: 21096, total_loss: 3.478280544281006
training step: 21097, total_loss: 4.308502674102783
training step: 21098, total_loss: 2.4488515853881836
training step: 21099, total_loss: 6.214786529541016
training step: 21100, total_loss: 2.59639048576355
training step: 21101, total_loss: 4.336791515350342
training step: 21102, total_loss: 4.417096138000488
training step: 21103, total_loss: 3.140498399734497
training step: 21104, total_loss: 4.46372127532959
training step: 21105, total_loss: 3.981968879699707
training step: 21106, total_loss: 4.166905403137207
training step: 21107, total_loss: 3.906101703643799
training step: 21108, total_loss: 4.323390960693359
training step: 21109, total_loss: 3.7769927978515625
training step: 21110, total_loss: 4.002532482147217
training step: 21111, total_loss: 4.1139349937438965
training step: 21112, total_loss: 5.308324337005615
training step: 21113, total_loss: 4.877715110778809
training step: 21114, total_loss: 2.751063346862793
training step: 21115, total_loss: 5.09477424621582
training step: 21116, total_loss: 4.251158714294434
training step: 21117, total_loss: 4.408737659454346
training step: 21118, total_loss: 4.091816425323486
training step: 21119, total_loss: 4.389592170715332
training step: 21120, total_loss: 6.246358394622803
training step: 21121, total_loss: 2.661363124847412
training step: 21122, total_loss: 3.651902675628662
training step: 21123, total_loss: 4.302853584289551
training step: 21124, total_loss: 4.9123454093933105
training step: 21125, total_loss: 6.286437511444092
training step: 21126, total_loss: 4.211071491241455
training step: 21127, total_loss: 4.972840785980225
training step: 21128, total_loss: 4.266812324523926
training step: 21129, total_loss: 5.073855400085449
training step: 21130, total_loss: 3.619260311126709
training step: 21131, total_loss: 4.390068054199219
training step: 21132, total_loss: 4.841165542602539
training step: 21133, total_loss: 4.438699722290039
training step: 21134, total_loss: 5.086056709289551
training step: 21135, total_loss: 4.35243558883667
training step: 21136, total_loss: 4.168981075286865
training step: 21137, total_loss: 4.2356438636779785
training step: 21138, total_loss: 7.112250804901123
training step: 21139, total_loss: 4.015429496765137
training step: 21140, total_loss: 4.383563995361328
training step: 21141, total_loss: 4.458024024963379
training step: 21142, total_loss: 4.708671569824219
training step: 21143, total_loss: 4.917821884155273
training step: 21144, total_loss: 6.362287521362305
training step: 21145, total_loss: 4.756748676300049
training step: 21146, total_loss: 3.7200703620910645
training step: 21147, total_loss: 5.193148612976074
training step: 21148, total_loss: 4.824029922485352
training step: 21149, total_loss: 5.227654933929443
training step: 21150, total_loss: 4.734837532043457
training step: 21151, total_loss: 4.233400821685791
training step: 21152, total_loss: 4.908628463745117
training step: 21153, total_loss: 3.91646671295166
training step: 21154, total_loss: 3.290844202041626
training step: 21155, total_loss: 5.283933639526367
training step: 21156, total_loss: 2.9168171882629395
training step: 21157, total_loss: 4.545681476593018
training step: 21158, total_loss: 4.0260443687438965
training step: 21159, total_loss: 2.835214614868164
training step: 21160, total_loss: 5.275491714477539
training step: 21161, total_loss: 5.140619277954102
training step: 21162, total_loss: 3.671625852584839
training step: 21163, total_loss: 4.2408037185668945
training step: 21164, total_loss: 4.72471809387207
training step: 21165, total_loss: 4.309246063232422
training step: 21166, total_loss: 4.216029167175293
training step: 21167, total_loss: 4.434948921203613
training step: 21168, total_loss: 3.438002347946167
training step: 21169, total_loss: 5.259133338928223
training step: 21170, total_loss: 3.1972882747650146
training step: 21171, total_loss: 4.863471984863281
training step: 21172, total_loss: 4.792821407318115
training step: 21173, total_loss: 3.838752269744873
training step: 21174, total_loss: 5.614907264709473
training step: 21175, total_loss: 3.089554786682129
training step: 21176, total_loss: 4.574798107147217
training step: 21177, total_loss: 5.987977027893066
training step: 21178, total_loss: 5.9830708503723145
training step: 21179, total_loss: 6.33722448348999
training step: 21180, total_loss: 4.945639610290527
training step: 21181, total_loss: 5.501964092254639
training step: 21182, total_loss: 5.213415145874023
training step: 21183, total_loss: 3.836082696914673
training step: 21184, total_loss: 5.089663505554199
training step: 21185, total_loss: 4.282682418823242
training step: 21186, total_loss: 4.254164695739746
training step: 21187, total_loss: 4.8602094650268555
training step: 21188, total_loss: 4.942836761474609
training step: 21189, total_loss: 4.373833179473877
training step: 21190, total_loss: 3.7619943618774414
training step: 21191, total_loss: 3.977224588394165
training step: 21192, total_loss: 3.4600493907928467
training step: 21193, total_loss: 3.8370041847229004
training step: 21194, total_loss: 3.644228935241699
training step: 21195, total_loss: 5.08932638168335
training step: 21196, total_loss: 1.405241847038269
training step: 21197, total_loss: 3.9457428455352783
training step: 21198, total_loss: 4.205601215362549
training step: 21199, total_loss: 4.162721633911133
training step: 21200, total_loss: 3.456937551498413
training step: 21201, total_loss: 3.806781530380249
training step: 21202, total_loss: 4.735478401184082
training step: 21203, total_loss: 3.3080806732177734
training step: 21204, total_loss: 4.068990707397461
training step: 21205, total_loss: 3.960202217102051
training step: 21206, total_loss: 2.669895648956299
training step: 21207, total_loss: 6.011105537414551
training step: 21208, total_loss: 3.3690314292907715
training step: 21209, total_loss: 5.703413009643555
training step: 21210, total_loss: 4.315031051635742
training step: 21211, total_loss: 3.519824504852295
training step: 21212, total_loss: 3.315824031829834
training step: 21213, total_loss: 5.831862449645996
training step: 21214, total_loss: 5.931119918823242
training step: 21215, total_loss: 6.200181484222412
training step: 21216, total_loss: 3.6110188961029053
training step: 21217, total_loss: 4.703343391418457
training step: 21218, total_loss: 4.437323093414307
training step: 21219, total_loss: 3.3334529399871826
training step: 21220, total_loss: 4.331411361694336
training step: 21221, total_loss: 4.983651161193848
training step: 21222, total_loss: 4.689492702484131
training step: 21223, total_loss: 2.378854274749756
training step: 21224, total_loss: 5.767965316772461
training step: 21225, total_loss: 4.538305282592773
training step: 21226, total_loss: 4.2652268409729
training step: 21227, total_loss: 3.4621901512145996
training step: 21228, total_loss: 3.8567028045654297
training step: 21229, total_loss: 4.5290656089782715
training step: 21230, total_loss: 4.989987850189209
training step: 21231, total_loss: 3.307307720184326
training step: 21232, total_loss: 4.135788917541504
training step: 21233, total_loss: 4.4665207862854
training step: 21234, total_loss: 5.364019870758057
training step: 21235, total_loss: 4.0393571853637695
training step: 21236, total_loss: 4.312510013580322
training step: 21237, total_loss: 4.489274501800537
training step: 21238, total_loss: 5.636173248291016
training step: 21239, total_loss: 1.0474412441253662
training step: 21240, total_loss: 4.711359024047852
training step: 21241, total_loss: 5.532721519470215
training step: 21242, total_loss: 4.546483039855957
training step: 21243, total_loss: 4.55378532409668
training step: 21244, total_loss: 4.1847944259643555
training step: 21245, total_loss: 5.176644325256348
training step: 21246, total_loss: 4.217520236968994
training step: 21247, total_loss: 4.130501747131348
training step: 21248, total_loss: 4.592526435852051
training step: 21249, total_loss: 5.015684127807617
training step: 21250, total_loss: 4.779982089996338
training step: 21251, total_loss: 2.907698631286621
training step: 21252, total_loss: 4.557548522949219
training step: 21253, total_loss: 4.912380218505859
training step: 21254, total_loss: 3.7641987800598145
training step: 21255, total_loss: 3.7236714363098145
training step: 21256, total_loss: 5.404086112976074
training step: 21257, total_loss: 4.969884395599365
training step: 21258, total_loss: 3.905592918395996
training step: 21259, total_loss: 4.446375846862793
training step: 21260, total_loss: 5.813534259796143
training step: 21261, total_loss: 4.720931529998779
training step: 21262, total_loss: 4.103799819946289
training step: 21263, total_loss: 2.367255926132202
training step: 21264, total_loss: 4.848853588104248
training step: 21265, total_loss: 5.7559661865234375
training step: 21266, total_loss: 3.821511745452881
training step: 21267, total_loss: 4.451297760009766
training step: 21268, total_loss: 5.122079849243164
training step: 21269, total_loss: 4.377080917358398
training step: 21270, total_loss: 5.29996395111084
training step: 21271, total_loss: 3.871553421020508
training step: 21272, total_loss: 4.691625595092773
training step: 21273, total_loss: 3.796574115753174
training step: 21274, total_loss: 4.842838287353516
training step: 21275, total_loss: 4.206125736236572
training step: 21276, total_loss: 6.279336452484131
training step: 21277, total_loss: 4.402563095092773
training step: 21278, total_loss: 5.760231018066406
training step: 21279, total_loss: 3.8283486366271973
training step: 21280, total_loss: 5.09867525100708
training step: 21281, total_loss: 5.055235862731934
training step: 21282, total_loss: 4.806160926818848
training step: 21283, total_loss: 5.48593282699585
training step: 21284, total_loss: 2.695661783218384
training step: 21285, total_loss: 5.376977920532227
training step: 21286, total_loss: 3.816801071166992
training step: 21287, total_loss: 3.8089823722839355
training step: 21288, total_loss: 5.138119697570801
training step: 21289, total_loss: 5.1558685302734375
training step: 21290, total_loss: 4.510932922363281
training step: 21291, total_loss: 5.1598734855651855
training step: 21292, total_loss: 5.139220237731934
training step: 21293, total_loss: 4.725058078765869
training step: 21294, total_loss: 5.556435585021973
training step: 21295, total_loss: 5.954385757446289
training step: 21296, total_loss: 2.787909507751465
training step: 21297, total_loss: 4.851411819458008
training step: 21298, total_loss: 4.222575664520264
training step: 21299, total_loss: 1.4144059419631958
training step: 21300, total_loss: 3.6637063026428223
training step: 21301, total_loss: 3.604675054550171
training step: 21302, total_loss: 1.4461557865142822
training step: 21303, total_loss: 2.81912899017334
training step: 21304, total_loss: 3.8951380252838135
training step: 21305, total_loss: 4.296812057495117
training step: 21306, total_loss: 4.062756061553955
training step: 21307, total_loss: 4.4955973625183105
training step: 21308, total_loss: 5.079724311828613
training step: 21309, total_loss: 5.195033073425293
training step: 21310, total_loss: 4.350293159484863
training step: 21311, total_loss: 3.967416286468506
training step: 21312, total_loss: 7.0074567794799805
training step: 21313, total_loss: 4.866291046142578
training step: 21314, total_loss: 4.85432243347168
training step: 21315, total_loss: 3.8922970294952393
training step: 21316, total_loss: 4.77644157409668
training step: 21317, total_loss: 4.361236572265625
training step: 21318, total_loss: 4.163301944732666
training step: 21319, total_loss: 5.003263473510742
training step: 21320, total_loss: 4.389873504638672
training step: 21321, total_loss: 4.700922012329102
training step: 21322, total_loss: 4.210943698883057
training step: 21323, total_loss: 3.4799118041992188
training step: 21324, total_loss: 4.715468406677246
training step: 21325, total_loss: 4.763340950012207
training step: 21326, total_loss: 2.8739302158355713
training step: 21327, total_loss: 5.079429626464844
training step: 21328, total_loss: 3.01119327545166
training step: 21329, total_loss: 4.629706382751465
training step: 21330, total_loss: 4.586706161499023
training step: 21331, total_loss: 3.840860366821289
training step: 21332, total_loss: 5.272003650665283
training step: 21333, total_loss: 4.15459680557251
training step: 21334, total_loss: 4.58920955657959
training step: 21335, total_loss: 4.078021049499512
training step: 21336, total_loss: 5.205732345581055
training step: 21337, total_loss: 4.294610500335693
training step: 21338, total_loss: 4.7048563957214355
training step: 21339, total_loss: 2.585625171661377
training step: 21340, total_loss: 3.344425916671753
training step: 21341, total_loss: 4.864282131195068
training step: 21342, total_loss: 4.71486759185791
training step: 21343, total_loss: 5.1158294677734375
training step: 21344, total_loss: 4.34013557434082
training step: 21345, total_loss: 4.563390731811523
training step: 21346, total_loss: 5.459947109222412
training step: 21347, total_loss: 5.16471004486084
training step: 21348, total_loss: 5.412676811218262
training step: 21349, total_loss: 4.4238739013671875
training step: 21350, total_loss: 4.257160186767578
training step: 21351, total_loss: 4.572378635406494
training step: 21352, total_loss: 6.078145980834961
training step: 21353, total_loss: 4.873897552490234
training step: 21354, total_loss: 3.983485221862793
training step: 21355, total_loss: 3.875154972076416
training step: 21356, total_loss: 4.4136834144592285
training step: 21357, total_loss: 3.9344937801361084
training step: 21358, total_loss: 5.0370330810546875
training step: 21359, total_loss: 4.896203994750977
training step: 21360, total_loss: 4.077544212341309
training step: 21361, total_loss: 4.738250732421875
training step: 21362, total_loss: 4.691026210784912
training step: 21363, total_loss: 3.998936653137207
training step: 21364, total_loss: 5.244503974914551
training step: 21365, total_loss: 4.038804054260254
training step: 21366, total_loss: 4.211376190185547
training step: 21367, total_loss: 5.28634786605835
training step: 21368, total_loss: 4.421337604522705
training step: 21369, total_loss: 3.8710873126983643
training step: 21370, total_loss: 4.1298136711120605
training step: 21371, total_loss: 4.681550025939941
training step: 21372, total_loss: 5.232607364654541
training step: 21373, total_loss: 4.208279609680176
training step: 21374, total_loss: 3.5501890182495117
training step: 21375, total_loss: 4.863646030426025
training step: 21376, total_loss: 4.530431747436523
training step: 21377, total_loss: 4.33601188659668
training step: 21378, total_loss: 4.081831455230713
training step: 21379, total_loss: 3.324228286743164
training step: 21380, total_loss: 5.203936576843262
training step: 21381, total_loss: 4.685360908508301
training step: 21382, total_loss: 5.552355766296387
training step: 21383, total_loss: 2.5141429901123047
training step: 21384, total_loss: 4.864696502685547
training step: 21385, total_loss: 2.7890193462371826
training step: 21386, total_loss: 3.3200368881225586
training step: 21387, total_loss: 4.618008613586426
training step: 21388, total_loss: 5.363890647888184
training step: 21389, total_loss: 5.62713098526001
training step: 21390, total_loss: 5.416983604431152
training step: 21391, total_loss: 4.964861869812012
training step: 21392, total_loss: 4.228611946105957
training step: 21393, total_loss: 3.9648935794830322
training step: 21394, total_loss: 4.893609046936035
training step: 21395, total_loss: 2.4491376876831055
training step: 21396, total_loss: 4.6373982429504395
training step: 21397, total_loss: 5.263910293579102
training step: 21398, total_loss: 5.24556827545166
training step: 21399, total_loss: 6.55235481262207
training step: 21400, total_loss: 3.0857338905334473
training step: 21401, total_loss: 3.122725009918213
training step: 21402, total_loss: 4.801340103149414
training step: 21403, total_loss: 5.559734344482422
training step: 21404, total_loss: 3.574866771697998
training step: 21405, total_loss: 4.819435119628906
training step: 21406, total_loss: 4.743829250335693
training step: 21407, total_loss: 5.1384124755859375
training step: 21408, total_loss: 4.763434886932373
training step: 21409, total_loss: 5.872017860412598
training step: 21410, total_loss: 5.397205829620361
training step: 21411, total_loss: 6.094812393188477
training step: 21412, total_loss: 5.657088756561279
training step: 21413, total_loss: 4.502460479736328
training step: 21414, total_loss: 5.18942928314209
training step: 21415, total_loss: 4.184225559234619
training step: 21416, total_loss: 4.212075233459473
training step: 21417, total_loss: 4.350790977478027
training step: 21418, total_loss: 4.312200546264648
training step: 21419, total_loss: 3.809661388397217
training step: 21420, total_loss: 4.288631439208984
training step: 21421, total_loss: 5.014283180236816
training step: 21422, total_loss: 4.583902835845947
training step: 21423, total_loss: 4.523331642150879
training step: 21424, total_loss: 5.205795764923096
training step: 21425, total_loss: 4.887373924255371
training step: 21426, total_loss: 4.038086891174316
training step: 21427, total_loss: 3.0115935802459717
training step: 21428, total_loss: 4.8575053215026855
training step: 21429, total_loss: 3.911879539489746
training step: 21430, total_loss: 4.483614921569824
training step: 21431, total_loss: 4.693665504455566
training step: 21432, total_loss: 3.7659082412719727
training step: 21433, total_loss: 3.3523831367492676
training step: 21434, total_loss: 2.6064326763153076
training step: 21435, total_loss: 5.641872406005859
training step: 21436, total_loss: 3.6450090408325195
training step: 21437, total_loss: 1.2517518997192383
training step: 21438, total_loss: 2.6606040000915527
training step: 21439, total_loss: 4.218687534332275
training step: 21440, total_loss: 6.757645130157471
training step: 21441, total_loss: 1.3174097537994385
training step: 21442, total_loss: 4.183696269989014
training step: 21443, total_loss: 4.784804821014404
training step: 21444, total_loss: 2.295046091079712
training step: 21445, total_loss: 5.315216064453125
training step: 21446, total_loss: 5.8630523681640625
training step: 21447, total_loss: 0.993847131729126
training step: 21448, total_loss: 3.73498272895813
training step: 21449, total_loss: 5.818358421325684
training step: 21450, total_loss: 4.930930137634277
training step: 21451, total_loss: 3.1871743202209473
training step: 21452, total_loss: 5.308000087738037
training step: 21453, total_loss: 3.013035297393799
training step: 21454, total_loss: 5.677018642425537
training step: 21455, total_loss: 4.613675117492676
training step: 21456, total_loss: 5.00042724609375
training step: 21457, total_loss: 4.536657810211182
training step: 21458, total_loss: 5.234532356262207
training step: 21459, total_loss: 4.245908737182617
training step: 21460, total_loss: 5.516506195068359
training step: 21461, total_loss: 5.899606704711914
training step: 21462, total_loss: 5.078139305114746
training step: 21463, total_loss: 3.586099147796631
training step: 21464, total_loss: 4.27447509765625
training step: 21465, total_loss: 5.512833595275879
training step: 21466, total_loss: 5.252908706665039
training step: 21467, total_loss: 6.908214569091797
training step: 21468, total_loss: 2.0997800827026367
training step: 21469, total_loss: 5.45414924621582
training step: 21470, total_loss: 4.745784759521484
training step: 21471, total_loss: 5.817849636077881
training step: 21472, total_loss: 3.5062623023986816
training step: 21473, total_loss: 4.645590782165527
training step: 21474, total_loss: 4.732349395751953
training step: 21475, total_loss: 4.702289581298828
training step: 21476, total_loss: 5.465676784515381
training step: 21477, total_loss: 5.315609931945801
training step: 21478, total_loss: 4.531630039215088
training step: 21479, total_loss: 5.284681797027588
training step: 21480, total_loss: 4.745821952819824
training step: 21481, total_loss: 3.329562187194824
training step: 21482, total_loss: 3.5789575576782227
training step: 21483, total_loss: 3.6183104515075684
training step: 21484, total_loss: 3.7321009635925293
training step: 21485, total_loss: 4.657610893249512
training step: 21486, total_loss: 4.589422225952148
training step: 21487, total_loss: 4.958113193511963
training step: 21488, total_loss: 4.410286903381348
training step: 21489, total_loss: 3.305546760559082
training step: 21490, total_loss: 4.934980869293213
training step: 21491, total_loss: 4.084166049957275
training step: 21492, total_loss: 5.540743827819824
training step: 21493, total_loss: 1.6806025505065918
training step: 21494, total_loss: 4.318146705627441
training step: 21495, total_loss: 4.133090496063232
training step: 21496, total_loss: 3.9622251987457275
training step: 21497, total_loss: 5.232285976409912
training step: 21498, total_loss: 5.111798286437988
training step: 21499, total_loss: 4.638494491577148
training step: 21500, total_loss: 3.301961898803711
training step: 21501, total_loss: 5.3656697273254395
training step: 21502, total_loss: 3.0092384815216064
training step: 21503, total_loss: 3.730973482131958
training step: 21504, total_loss: 4.55230712890625
training step: 21505, total_loss: 3.521270990371704
training step: 21506, total_loss: 4.582674026489258
training step: 21507, total_loss: 3.282111167907715
training step: 21508, total_loss: 5.3573126792907715
training step: 21509, total_loss: 3.9816575050354004
training step: 21510, total_loss: 3.709425210952759
training step: 21511, total_loss: 5.212249279022217
training step: 21512, total_loss: 5.686516761779785
training step: 21513, total_loss: 6.010015964508057
training step: 21514, total_loss: 4.470463752746582
training step: 21515, total_loss: 4.081737041473389
training step: 21516, total_loss: 5.846905708312988
training step: 21517, total_loss: 4.639989852905273
training step: 21518, total_loss: 3.9694042205810547
training step: 21519, total_loss: 2.7003374099731445
training step: 21520, total_loss: 2.887392997741699
training step: 21521, total_loss: 7.460738182067871
training step: 21522, total_loss: 4.4612016677856445
training step: 21523, total_loss: 4.472352027893066
training step: 21524, total_loss: 4.755698204040527
training step: 21525, total_loss: 2.9102907180786133
training step: 21526, total_loss: 5.050275802612305
training step: 21527, total_loss: 4.10395622253418
training step: 21528, total_loss: 4.680715560913086
training step: 21529, total_loss: 3.6866257190704346
training step: 21530, total_loss: 3.755556583404541
training step: 21531, total_loss: 2.61602783203125
training step: 21532, total_loss: 4.762297630310059
training step: 21533, total_loss: 3.931274890899658
training step: 21534, total_loss: 6.323925018310547
training step: 21535, total_loss: 4.520553112030029
training step: 21536, total_loss: 5.253202438354492
training step: 21537, total_loss: 5.916690826416016
training step: 21538, total_loss: 4.9524760246276855
training step: 21539, total_loss: 4.148716926574707
training step: 21540, total_loss: 5.372666358947754
training step: 21541, total_loss: 4.372988224029541
training step: 21542, total_loss: 3.747720956802368
training step: 21543, total_loss: 4.627912521362305
training step: 21544, total_loss: 4.251598834991455
training step: 21545, total_loss: 4.92739200592041
training step: 21546, total_loss: 5.420396327972412
training step: 21547, total_loss: 4.760697364807129
training step: 21548, total_loss: 5.1537370681762695
training step: 21549, total_loss: 5.0345282554626465
training step: 21550, total_loss: 5.729287147521973
training step: 21551, total_loss: 4.309941291809082
training step: 21552, total_loss: 4.651028156280518
training step: 21553, total_loss: 5.113506317138672
training step: 21554, total_loss: 4.228450298309326
training step: 21555, total_loss: 5.458449363708496
training step: 21556, total_loss: 4.181572437286377
training step: 21557, total_loss: 3.9883527755737305
training step: 21558, total_loss: 4.895218849182129
training step: 21559, total_loss: 6.5155205726623535
training step: 21560, total_loss: 6.126556396484375
training step: 21561, total_loss: 5.252016544342041
training step: 21562, total_loss: 4.70368766784668
training step: 21563, total_loss: 4.502677917480469
training step: 21564, total_loss: 5.604790687561035
training step: 21565, total_loss: 3.8813834190368652
training step: 21566, total_loss: 4.2769999504089355
training step: 21567, total_loss: 7.276205062866211
training step: 21568, total_loss: 4.205348014831543
training step: 21569, total_loss: 3.732637882232666
training step: 21570, total_loss: 5.452258110046387
training step: 21571, total_loss: 4.640850067138672
training step: 21572, total_loss: 4.52340841293335
training step: 21573, total_loss: 4.316514492034912
training step: 21574, total_loss: 4.620490074157715
training step: 21575, total_loss: 2.9586269855499268
training step: 21576, total_loss: 4.814985275268555
training step: 21577, total_loss: 1.0092992782592773
training step: 21578, total_loss: 5.101291656494141
training step: 21579, total_loss: 4.182292461395264
training step: 21580, total_loss: 4.038990020751953
training step: 21581, total_loss: 2.8494601249694824
training step: 21582, total_loss: 4.277754306793213
training step: 21583, total_loss: 4.6132097244262695
training step: 21584, total_loss: 4.802741050720215
training step: 21585, total_loss: 3.8139359951019287
training step: 21586, total_loss: 5.2315874099731445
training step: 21587, total_loss: 5.100858688354492
training step: 21588, total_loss: 5.143477916717529
training step: 21589, total_loss: 4.001827239990234
training step: 21590, total_loss: 2.61421275138855
training step: 21591, total_loss: 5.425686836242676
training step: 21592, total_loss: 4.420656681060791
training step: 21593, total_loss: 6.162038803100586
training step: 21594, total_loss: 6.564587593078613
training step: 21595, total_loss: 3.2399415969848633
training step: 21596, total_loss: 6.0239763259887695
training step: 21597, total_loss: 1.6996434926986694
training step: 21598, total_loss: 6.630719184875488
training step: 21599, total_loss: 4.223311424255371
training step: 21600, total_loss: 4.464913368225098
training step: 21601, total_loss: 3.2164647579193115
training step: 21602, total_loss: 4.926177978515625
training step: 21603, total_loss: 3.94635009765625
training step: 21604, total_loss: 5.1039719581604
training step: 21605, total_loss: 5.274679183959961
training step: 21606, total_loss: 4.908390045166016
training step: 21607, total_loss: 5.081070899963379
training step: 21608, total_loss: 1.1690473556518555
training step: 21609, total_loss: 3.7932815551757812
training step: 21610, total_loss: 4.197601795196533
training step: 21611, total_loss: 3.5739307403564453
training step: 21612, total_loss: 4.979936599731445
training step: 21613, total_loss: 4.480550765991211
training step: 21614, total_loss: 3.247438669204712
training step: 21615, total_loss: 4.291301250457764
training step: 21616, total_loss: 4.104140281677246
training step: 21617, total_loss: 4.489083290100098
training step: 21618, total_loss: 6.938362121582031
training step: 21619, total_loss: 5.006570339202881
training step: 21620, total_loss: 4.005265712738037
training step: 21621, total_loss: 3.2906837463378906
training step: 21622, total_loss: 6.63499641418457
training step: 21623, total_loss: 3.76670503616333
training step: 21624, total_loss: 5.712109565734863
training step: 21625, total_loss: 3.772502899169922
training step: 21626, total_loss: 4.970006465911865
training step: 21627, total_loss: 4.786375045776367
training step: 21628, total_loss: 3.354381561279297
training step: 21629, total_loss: 5.387967109680176
training step: 21630, total_loss: 5.4044599533081055
training step: 21631, total_loss: 4.246230125427246
training step: 21632, total_loss: 4.753761291503906
training step: 21633, total_loss: 3.7722949981689453
training step: 21634, total_loss: 4.295537948608398
training step: 21635, total_loss: 3.5445847511291504
training step: 21636, total_loss: 0.9161033630371094
training step: 21637, total_loss: 0.8873844146728516
training step: 21638, total_loss: 2.8061981201171875
training step: 21639, total_loss: 2.142850160598755
training step: 21640, total_loss: 1.0026285648345947
training step: 21641, total_loss: 4.363771438598633
training step: 21642, total_loss: 4.113598823547363
training step: 21643, total_loss: 5.261544227600098
training step: 21644, total_loss: 4.00592565536499
training step: 21645, total_loss: 3.6493546962738037
training step: 21646, total_loss: 3.928311824798584
training step: 21647, total_loss: 5.371319770812988
training step: 21648, total_loss: 4.936184883117676
training step: 21649, total_loss: 3.744314193725586
training step: 21650, total_loss: 4.73303747177124
training step: 21651, total_loss: 5.8729729652404785
training step: 21652, total_loss: 5.517691612243652
training step: 21653, total_loss: 2.715672731399536
training step: 21654, total_loss: 4.812636375427246
training step: 21655, total_loss: 4.998239517211914
training step: 21656, total_loss: 4.431992530822754
training step: 21657, total_loss: 5.43066930770874
training step: 21658, total_loss: 0.8931710720062256
training step: 21659, total_loss: 2.199380874633789
training step: 21660, total_loss: 5.0041728019714355
training step: 21661, total_loss: 5.229252815246582
training step: 21662, total_loss: 5.885274887084961
training step: 21663, total_loss: 4.684383392333984
training step: 21664, total_loss: 4.597094535827637
training step: 21665, total_loss: 5.162081241607666
training step: 21666, total_loss: 4.7719407081604
training step: 21667, total_loss: 4.865478515625
training step: 21668, total_loss: 4.379857063293457
training step: 21669, total_loss: 3.858085870742798
training step: 21670, total_loss: 4.773719787597656
training step: 21671, total_loss: 5.432923793792725
training step: 21672, total_loss: 3.455512046813965
training step: 21673, total_loss: 3.9022741317749023
training step: 21674, total_loss: 6.449008941650391
training step: 21675, total_loss: 3.001535415649414
training step: 21676, total_loss: 4.29438591003418
training step: 21677, total_loss: 0.6691176295280457
training step: 21678, total_loss: 2.905118465423584
training step: 21679, total_loss: 5.403337478637695
training step: 21680, total_loss: 4.777276039123535
training step: 21681, total_loss: 4.170666217803955
training step: 21682, total_loss: 4.853329658508301
training step: 21683, total_loss: 4.963386535644531
training step: 21684, total_loss: 5.5483245849609375
training step: 21685, total_loss: 2.9783060550689697
training step: 21686, total_loss: 3.7423853874206543
training step: 21687, total_loss: 4.425668716430664
training step: 21688, total_loss: 6.381844520568848
training step: 21689, total_loss: 5.405104160308838
training step: 21690, total_loss: 3.9284982681274414
training step: 21691, total_loss: 2.859747886657715
training step: 21692, total_loss: 4.966282844543457
training step: 21693, total_loss: 4.4907331466674805
training step: 21694, total_loss: 3.230705738067627
training step: 21695, total_loss: 3.0556278228759766
training step: 21696, total_loss: 5.087080001831055
training step: 21697, total_loss: 4.85032844543457
training step: 21698, total_loss: 5.67636775970459
training step: 21699, total_loss: 5.00516939163208
training step: 21700, total_loss: 5.9449567794799805
training step: 21701, total_loss: 3.7766358852386475
training step: 21702, total_loss: 5.828409671783447
training step: 21703, total_loss: 3.8920373916625977
training step: 21704, total_loss: 4.766263961791992
training step: 21705, total_loss: 3.329939365386963
training step: 21706, total_loss: 2.5415401458740234
training step: 21707, total_loss: 3.053372859954834
training step: 21708, total_loss: 2.8457155227661133
training step: 21709, total_loss: 5.1602702140808105
training step: 21710, total_loss: 4.588008403778076
training step: 21711, total_loss: 2.802002429962158
training step: 21712, total_loss: 2.6377267837524414
training step: 21713, total_loss: 5.240052223205566
training step: 21714, total_loss: 5.418040752410889
training step: 21715, total_loss: 5.530966758728027
training step: 21716, total_loss: 2.8804900646209717
training step: 21717, total_loss: 4.638160705566406
training step: 21718, total_loss: 5.20005989074707
training step: 21719, total_loss: 4.672767639160156
training step: 21720, total_loss: 3.7605957984924316
training step: 21721, total_loss: 4.367783546447754
training step: 21722, total_loss: 4.622396469116211
training step: 21723, total_loss: 4.18131160736084
training step: 21724, total_loss: 2.1604037284851074
training step: 21725, total_loss: 6.146119117736816
training step: 21726, total_loss: 7.1676788330078125
training step: 21727, total_loss: 3.2913899421691895
training step: 21728, total_loss: 7.681408882141113
training step: 21729, total_loss: 3.6821470260620117
training step: 21730, total_loss: 4.518147945404053
training step: 21731, total_loss: 4.451501846313477
training step: 21732, total_loss: 2.7510454654693604
training step: 21733, total_loss: 5.090235710144043
training step: 21734, total_loss: 6.578029632568359
training step: 21735, total_loss: 4.905474662780762
training step: 21736, total_loss: 3.0961999893188477
training step: 21737, total_loss: 4.418394088745117
training step: 21738, total_loss: 4.8841023445129395
training step: 21739, total_loss: 3.1020328998565674
training step: 21740, total_loss: 6.652087211608887
training step: 21741, total_loss: 4.095150947570801
training step: 21742, total_loss: 0.7361178994178772
training step: 21743, total_loss: 4.653608322143555
training step: 21744, total_loss: 3.781844139099121
training step: 21745, total_loss: 5.166102886199951
training step: 21746, total_loss: 5.3238043785095215
training step: 21747, total_loss: 4.2539262771606445
training step: 21748, total_loss: 2.942793369293213
training step: 21749, total_loss: 3.466322183609009
training step: 21750, total_loss: 3.5171966552734375
training step: 21751, total_loss: 3.3431596755981445
training step: 21752, total_loss: 4.523487091064453
training step: 21753, total_loss: 4.994709014892578
training step: 21754, total_loss: 4.000216484069824
training step: 21755, total_loss: 3.916903018951416
training step: 21756, total_loss: 5.757108688354492
training step: 21757, total_loss: 4.284297943115234
training step: 21758, total_loss: 5.340170860290527
training step: 21759, total_loss: 4.092921257019043
training step: 21760, total_loss: 3.0091519355773926
training step: 21761, total_loss: 5.123929023742676
training step: 21762, total_loss: 5.918941497802734
training step: 21763, total_loss: 3.0223097801208496
training step: 21764, total_loss: 5.336818695068359
training step: 21765, total_loss: 5.280970096588135
training step: 21766, total_loss: 6.976751327514648
training step: 21767, total_loss: 4.9058051109313965
training step: 21768, total_loss: 3.587390422821045
training step: 21769, total_loss: 4.3052873611450195
training step: 21770, total_loss: 5.589141845703125
training step: 21771, total_loss: 2.726496696472168
training step: 21772, total_loss: 3.994255304336548
training step: 21773, total_loss: 4.503374099731445
training step: 21774, total_loss: 5.056654930114746
training step: 21775, total_loss: 5.24800968170166
training step: 21776, total_loss: 5.450730323791504
training step: 21777, total_loss: 4.272347927093506
training step: 21778, total_loss: 5.896816253662109
training step: 21779, total_loss: 3.682288646697998
training step: 21780, total_loss: 5.519811630249023
training step: 21781, total_loss: 4.025445938110352
training step: 21782, total_loss: 3.7819876670837402
training step: 21783, total_loss: 5.416195869445801
training step: 21784, total_loss: 4.215949058532715
training step: 21785, total_loss: 6.528054237365723
training step: 21786, total_loss: 4.931397438049316
training step: 21787, total_loss: 4.4365434646606445
training step: 21788, total_loss: 5.022865295410156
training step: 21789, total_loss: 4.132742881774902
training step: 21790, total_loss: 6.235968589782715
training step: 21791, total_loss: 3.480165481567383
training step: 21792, total_loss: 4.22214412689209
training step: 21793, total_loss: 5.128688335418701
training step: 21794, total_loss: 4.716373443603516
training step: 21795, total_loss: 5.346834182739258
training step: 21796, total_loss: 3.6357998847961426
training step: 21797, total_loss: 4.737218379974365
training step: 21798, total_loss: 1.9889235496520996
training step: 21799, total_loss: 2.613546371459961
training step: 21800, total_loss: 4.303854942321777
training step: 21801, total_loss: 5.219898223876953
training step: 21802, total_loss: 4.201061725616455
training step: 21803, total_loss: 4.247777462005615
training step: 21804, total_loss: 4.633214950561523
training step: 21805, total_loss: 4.310769081115723
training step: 21806, total_loss: 4.118672847747803
training step: 21807, total_loss: 5.32586669921875
training step: 21808, total_loss: 3.484320640563965
training step: 21809, total_loss: 4.498525619506836
training step: 21810, total_loss: 4.559192180633545
training step: 21811, total_loss: 5.918905258178711
training step: 21812, total_loss: 4.684569358825684
training step: 21813, total_loss: 4.564083099365234
training step: 21814, total_loss: 3.2597055435180664
training step: 21815, total_loss: 3.4872488975524902
training step: 21816, total_loss: 3.755162000656128
training step: 21817, total_loss: 3.7028913497924805
training step: 21818, total_loss: 3.8566975593566895
training step: 21819, total_loss: 4.387059211730957
training step: 21820, total_loss: 3.0758347511291504
training step: 21821, total_loss: 4.807693004608154
training step: 21822, total_loss: 3.839120388031006
training step: 21823, total_loss: 4.011857509613037
training step: 21824, total_loss: 5.87224006652832
training step: 21825, total_loss: 4.994460582733154
training step: 21826, total_loss: 3.6954033374786377
training step: 21827, total_loss: 5.444790840148926
training step: 21828, total_loss: 6.205775737762451
training step: 21829, total_loss: 4.977775573730469
training step: 21830, total_loss: 4.379061698913574
training step: 21831, total_loss: 3.470499277114868
training step: 21832, total_loss: 3.334480047225952
training step: 21833, total_loss: 3.4720683097839355
training step: 21834, total_loss: 3.9449892044067383
training step: 21835, total_loss: 4.417465686798096
training step: 21836, total_loss: 5.391279220581055
training step: 21837, total_loss: 4.343606948852539
training step: 21838, total_loss: 3.9393680095672607
training step: 21839, total_loss: 4.584194660186768
training step: 21840, total_loss: 5.012387275695801
training step: 21841, total_loss: 4.219749450683594
training step: 21842, total_loss: 5.968934059143066
training step: 21843, total_loss: 4.383122444152832
training step: 21844, total_loss: 4.462035179138184
training step: 21845, total_loss: 3.833183765411377
training step: 21846, total_loss: 5.434323310852051
training step: 21847, total_loss: 4.068822860717773
training step: 21848, total_loss: 5.3480939865112305
training step: 21849, total_loss: 6.662779808044434
training step: 21850, total_loss: 3.801314115524292
training step: 21851, total_loss: 4.199100017547607
training step: 21852, total_loss: 5.12952995300293
training step: 21853, total_loss: 4.148916721343994
training step: 21854, total_loss: 4.875004768371582
training step: 21855, total_loss: 3.912693977355957
training step: 21856, total_loss: 1.525187373161316
training step: 21857, total_loss: 2.7114105224609375
training step: 21858, total_loss: 4.755033493041992
training step: 21859, total_loss: 3.302854537963867
training step: 21860, total_loss: 5.790734767913818
training step: 21861, total_loss: 3.27409029006958
training step: 21862, total_loss: 4.737834453582764
training step: 21863, total_loss: 5.254347801208496
training step: 21864, total_loss: 3.982478618621826
training step: 21865, total_loss: 4.0531206130981445
training step: 21866, total_loss: 5.607022285461426
training step: 21867, total_loss: 5.7767181396484375
training step: 21868, total_loss: 3.92148494720459
training step: 21869, total_loss: 4.792006492614746
training step: 21870, total_loss: 4.255334854125977
training step: 21871, total_loss: 2.3740234375
training step: 21872, total_loss: 5.213702201843262
training step: 21873, total_loss: 5.582693576812744
training step: 21874, total_loss: 4.0401129722595215
training step: 21875, total_loss: 4.969032287597656
training step: 21876, total_loss: 5.421531677246094
training step: 21877, total_loss: 4.472598075866699
training step: 21878, total_loss: 5.037202835083008
training step: 21879, total_loss: 5.137933731079102
training step: 21880, total_loss: 2.8929443359375
training step: 21881, total_loss: 3.858137607574463
training step: 21882, total_loss: 5.292279243469238
training step: 21883, total_loss: 4.783071041107178
training step: 21884, total_loss: 4.321965217590332
training step: 21885, total_loss: 3.543097972869873
training step: 21886, total_loss: 2.886040449142456
training step: 21887, total_loss: 6.35684871673584
training step: 21888, total_loss: 4.193660736083984
training step: 21889, total_loss: 2.0403757095336914
training step: 21890, total_loss: 4.697270393371582
training step: 21891, total_loss: 5.137687683105469
training step: 21892, total_loss: 3.7147512435913086
training step: 21893, total_loss: 5.30399227142334
training step: 21894, total_loss: 2.2238194942474365
training step: 21895, total_loss: 4.117007255554199
training step: 21896, total_loss: 5.760845184326172
training step: 21897, total_loss: 4.4205322265625
training step: 21898, total_loss: 4.798365592956543
training step: 21899, total_loss: 4.705015182495117
training step: 21900, total_loss: 3.645758628845215
training step: 21901, total_loss: 4.3207526206970215
training step: 21902, total_loss: 4.074196815490723
training step: 21903, total_loss: 4.634764194488525
training step: 21904, total_loss: 2.439938545227051
training step: 21905, total_loss: 2.839965581893921
training step: 21906, total_loss: 3.6228580474853516
training step: 21907, total_loss: 3.831343173980713
training step: 21908, total_loss: 5.099761009216309
training step: 21909, total_loss: 7.121973991394043
training step: 21910, total_loss: 5.174175262451172
training step: 21911, total_loss: 4.340082168579102
training step: 21912, total_loss: 4.8831987380981445
training step: 21913, total_loss: 3.9860119819641113
training step: 21914, total_loss: 5.356758117675781
training step: 21915, total_loss: 1.1563880443572998
training step: 21916, total_loss: 7.784553050994873
training step: 21917, total_loss: 4.342833042144775
training step: 21918, total_loss: 5.058292388916016
training step: 21919, total_loss: 3.753103494644165
training step: 21920, total_loss: 3.888944149017334
training step: 21921, total_loss: 4.2279534339904785
training step: 21922, total_loss: 5.138593673706055
training step: 21923, total_loss: 3.8686442375183105
training step: 21924, total_loss: 4.4199323654174805
training step: 21925, total_loss: 3.066725730895996
training step: 21926, total_loss: 5.294763565063477
training step: 21927, total_loss: 4.340994358062744
training step: 21928, total_loss: 4.045706748962402
training step: 21929, total_loss: 5.678916931152344
training step: 21930, total_loss: 4.5823187828063965
training step: 21931, total_loss: 5.326870441436768
training step: 21932, total_loss: 2.888617992401123
training step: 21933, total_loss: 4.743772506713867
training step: 21934, total_loss: 4.469585418701172
training step: 21935, total_loss: 3.9120914936065674
training step: 21936, total_loss: 7.076687812805176
training step: 21937, total_loss: 5.109958171844482
training step: 21938, total_loss: 3.763340473175049
training step: 21939, total_loss: 6.45514440536499
training step: 21940, total_loss: 3.434154748916626
training step: 21941, total_loss: 5.168941974639893
training step: 21942, total_loss: 4.8828277587890625
training step: 21943, total_loss: 5.391885757446289
training step: 21944, total_loss: 4.842674255371094
training step: 21945, total_loss: 6.321260452270508
training step: 21946, total_loss: 4.781736373901367
training step: 21947, total_loss: 3.621859073638916
training step: 21948, total_loss: 3.934319019317627
training step: 21949, total_loss: 5.4027323722839355
training step: 21950, total_loss: 4.519871234893799
training step: 21951, total_loss: 3.1557462215423584
training step: 21952, total_loss: 3.005786657333374
training step: 21953, total_loss: 4.619280815124512
training step: 21954, total_loss: 4.468174934387207
training step: 21955, total_loss: 4.5728960037231445
training step: 21956, total_loss: 5.6141767501831055
training step: 21957, total_loss: 4.43424129486084
training step: 21958, total_loss: 1.6355552673339844
training step: 21959, total_loss: 4.27316951751709
training step: 21960, total_loss: 5.7313666343688965
training step: 21961, total_loss: 5.038078308105469
training step: 21962, total_loss: 3.7540335655212402
training step: 21963, total_loss: 4.1612749099731445
training step: 21964, total_loss: 4.201651573181152
training step: 21965, total_loss: 5.496545791625977
training step: 21966, total_loss: 2.4527125358581543
training step: 21967, total_loss: 4.640746116638184
training step: 21968, total_loss: 4.450189590454102
training step: 21969, total_loss: 3.3800158500671387
training step: 21970, total_loss: 5.143736839294434
training step: 21971, total_loss: 3.4836440086364746
training step: 21972, total_loss: 3.7863950729370117
training step: 21973, total_loss: 4.724883079528809
training step: 21974, total_loss: 2.425668239593506
training step: 21975, total_loss: 4.890284061431885
training step: 21976, total_loss: 3.1697680950164795
training step: 21977, total_loss: 4.626032829284668
training step: 21978, total_loss: 2.8924903869628906
training step: 21979, total_loss: 6.07986307144165
training step: 21980, total_loss: 4.116096496582031
training step: 21981, total_loss: 4.825882434844971
training step: 21982, total_loss: 4.464608192443848
training step: 21983, total_loss: 4.585709571838379
training step: 21984, total_loss: 6.795970439910889
training step: 21985, total_loss: 5.071041107177734
training step: 21986, total_loss: 5.071325302124023
training step: 21987, total_loss: 4.214974403381348
training step: 21988, total_loss: 5.6750383377075195
training step: 21989, total_loss: 4.642805576324463
training step: 21990, total_loss: 3.4020044803619385
training step: 21991, total_loss: 4.014382839202881
training step: 21992, total_loss: 3.6857004165649414
training step: 21993, total_loss: 4.36228609085083
training step: 21994, total_loss: 3.8792285919189453
training step: 21995, total_loss: 4.811712741851807
training step: 21996, total_loss: 4.918203353881836
training step: 21997, total_loss: 3.118993043899536
training step: 21998, total_loss: 4.153489112854004
training step: 21999, total_loss: 4.285588264465332
training step: 22000, total_loss: 5.577862739562988
training step: 22001, total_loss: 4.963489532470703
training step: 22002, total_loss: 6.619217395782471
training step: 22003, total_loss: 5.467107772827148
training step: 22004, total_loss: 3.2226171493530273
training step: 22005, total_loss: 4.713653564453125
training step: 22006, total_loss: 5.0428619384765625
training step: 22007, total_loss: 5.282463550567627
training step: 22008, total_loss: 2.4831748008728027
training step: 22009, total_loss: 5.1822052001953125
training step: 22010, total_loss: 4.338057041168213
training step: 22011, total_loss: 5.773849010467529
training step: 22012, total_loss: 3.337489128112793
training step: 22013, total_loss: 5.5413713455200195
training step: 22014, total_loss: 3.955021381378174
training step: 22015, total_loss: 4.639718055725098
training step: 22016, total_loss: 3.1991257667541504
training step: 22017, total_loss: 4.654164791107178
training step: 22018, total_loss: 5.093756675720215
training step: 22019, total_loss: 4.829632759094238
training step: 22020, total_loss: 4.896554946899414
training step: 22021, total_loss: 3.7464561462402344
training step: 22022, total_loss: 3.511727809906006
training step: 22023, total_loss: 2.6936705112457275
training step: 22024, total_loss: 3.7587831020355225
training step: 22025, total_loss: 3.1635875701904297
training step: 22026, total_loss: 5.468802452087402
training step: 22027, total_loss: 3.9293227195739746
training step: 22028, total_loss: 3.5614187717437744
training step: 22029, total_loss: 3.177705764770508
training step: 22030, total_loss: 3.9369900226593018
training step: 22031, total_loss: 4.971555709838867
training step: 22032, total_loss: 6.015924453735352
training step: 22033, total_loss: 4.271780967712402
training step: 22034, total_loss: 5.112671852111816
training step: 22035, total_loss: 6.485367298126221
training step: 22036, total_loss: 6.07804012298584
training step: 22037, total_loss: 4.132151126861572
training step: 22038, total_loss: 4.184267044067383
training step: 22039, total_loss: 3.643960952758789
training step: 22040, total_loss: 4.478447437286377
training step: 22041, total_loss: 3.2632694244384766
training step: 22042, total_loss: 4.683392524719238
training step: 22043, total_loss: 4.944277286529541
training step: 22044, total_loss: 5.092333793640137
training step: 22045, total_loss: 3.259202480316162
training step: 22046, total_loss: 4.484837532043457
training step: 22047, total_loss: 4.66075325012207
training step: 22048, total_loss: 3.7239115238189697
training step: 22049, total_loss: 3.423290252685547
training step: 22050, total_loss: 2.713822364807129
training step: 22051, total_loss: 4.219910621643066
training step: 22052, total_loss: 3.7733755111694336
training step: 22053, total_loss: 2.0143957138061523
training step: 22054, total_loss: 5.578094482421875
training step: 22055, total_loss: 4.768615245819092
training step: 22056, total_loss: 4.729198455810547
training step: 22057, total_loss: 5.159843444824219
training step: 22058, total_loss: 1.467041254043579
training step: 22059, total_loss: 5.4552178382873535
training step: 22060, total_loss: 5.552304267883301
training step: 22061, total_loss: 3.4215385913848877
training step: 22062, total_loss: 5.907543182373047
training step: 22063, total_loss: 5.1492204666137695
training step: 22064, total_loss: 4.3126420974731445
training step: 22065, total_loss: 3.8707778453826904
training step: 22066, total_loss: 3.582603693008423
training step: 22067, total_loss: 4.33651065826416
training step: 22068, total_loss: 3.101675033569336
training step: 22069, total_loss: 3.353586196899414
training step: 22070, total_loss: 4.912787437438965
training step: 22071, total_loss: 0.9818211793899536
training step: 22072, total_loss: 3.361769199371338
training step: 22073, total_loss: 4.71893835067749
training step: 22074, total_loss: 5.283105373382568
training step: 22075, total_loss: 3.676947593688965
training step: 22076, total_loss: 4.131593704223633
training step: 22077, total_loss: 3.2714836597442627
training step: 22078, total_loss: 4.456618309020996
training step: 22079, total_loss: 4.942812919616699
training step: 22080, total_loss: 6.40851354598999
training step: 22081, total_loss: 4.401676654815674
training step: 22082, total_loss: 5.019248962402344
training step: 22083, total_loss: 3.8572885990142822
training step: 22084, total_loss: 4.436331748962402
training step: 22085, total_loss: 4.490161895751953
training step: 22086, total_loss: 4.1561479568481445
training step: 22087, total_loss: 7.1907806396484375
training step: 22088, total_loss: 4.914673805236816
training step: 22089, total_loss: 5.440000534057617
training step: 22090, total_loss: 5.680684566497803
training step: 22091, total_loss: 2.4793198108673096
training step: 22092, total_loss: 4.509174346923828
training step: 22093, total_loss: 5.823126792907715
training step: 22094, total_loss: 3.697641372680664
training step: 22095, total_loss: 4.652158260345459
training step: 22096, total_loss: 4.212699890136719
training step: 22097, total_loss: 5.338611602783203
training step: 22098, total_loss: 3.355557441711426
training step: 22099, total_loss: 4.014398574829102
training step: 22100, total_loss: 4.191723823547363
training step: 22101, total_loss: 4.278153419494629
training step: 22102, total_loss: 3.868593454360962
training step: 22103, total_loss: 3.8886210918426514
training step: 22104, total_loss: 5.108261585235596
training step: 22105, total_loss: 3.956982135772705
training step: 22106, total_loss: 5.493808746337891
training step: 22107, total_loss: 3.776766538619995
training step: 22108, total_loss: 4.98729133605957
training step: 22109, total_loss: 4.791136741638184
training step: 22110, total_loss: 5.114070415496826
training step: 22111, total_loss: 5.386081218719482
training step: 22112, total_loss: 4.663086891174316
training step: 22113, total_loss: 4.066140651702881
training step: 22114, total_loss: 5.244126319885254
training step: 22115, total_loss: 5.533811092376709
training step: 22116, total_loss: 3.9046401977539062
training step: 22117, total_loss: 4.818307876586914
training step: 22118, total_loss: 6.262807369232178
training step: 22119, total_loss: 3.539396286010742
training step: 22120, total_loss: 3.8748586177825928
training step: 22121, total_loss: 5.629673957824707
training step: 22122, total_loss: 4.091033935546875
training step: 22123, total_loss: 4.456121444702148
training step: 22124, total_loss: 5.096385955810547
training step: 22125, total_loss: 4.405330657958984
training step: 22126, total_loss: 3.0860719680786133
training step: 22127, total_loss: 5.156313896179199
training step: 22128, total_loss: 3.7634506225585938
training step: 22129, total_loss: 5.357597351074219
training step: 22130, total_loss: 5.224570274353027
training step: 22131, total_loss: 4.765120506286621
training step: 22132, total_loss: 4.311365127563477
training step: 22133, total_loss: 4.978754997253418
training step: 22134, total_loss: 5.5573320388793945
training step: 22135, total_loss: 3.180391550064087
training step: 22136, total_loss: 4.327016830444336
training step: 22137, total_loss: 4.422438621520996
training step: 22138, total_loss: 4.407967567443848
training step: 22139, total_loss: 4.347983360290527
training step: 22140, total_loss: 4.160895347595215
training step: 22141, total_loss: 4.6850996017456055
training step: 22142, total_loss: 4.428617000579834
training step: 22143, total_loss: 5.031338691711426
training step: 22144, total_loss: 5.071142196655273
training step: 22145, total_loss: 2.9721622467041016
training step: 22146, total_loss: 1.8650000095367432
training step: 22147, total_loss: 4.239570617675781
training step: 22148, total_loss: 3.5191969871520996
training step: 22149, total_loss: 5.189406871795654
training step: 22150, total_loss: 4.917706489562988
training step: 22151, total_loss: 4.67597770690918
training step: 22152, total_loss: 4.4998345375061035
training step: 22153, total_loss: 5.920663833618164
training step: 22154, total_loss: 3.0920889377593994
training step: 22155, total_loss: 2.965028762817383
training step: 22156, total_loss: 3.567678928375244
training step: 22157, total_loss: 4.562161445617676
training step: 22158, total_loss: 4.770984649658203
training step: 22159, total_loss: 1.6417393684387207
training step: 22160, total_loss: 5.461993217468262
training step: 22161, total_loss: 4.134908676147461
training step: 22162, total_loss: 4.476823329925537
training step: 22163, total_loss: 4.625176429748535
training step: 22164, total_loss: 5.366776466369629
training step: 22165, total_loss: 3.9756979942321777
training step: 22166, total_loss: 3.295896053314209
training step: 22167, total_loss: 5.177667617797852
training step: 22168, total_loss: 3.9991440773010254
training step: 22169, total_loss: 4.45622444152832
training step: 22170, total_loss: 5.351870059967041
training step: 22171, total_loss: 3.005413293838501
training step: 22172, total_loss: 5.121872425079346
training step: 22173, total_loss: 4.2005157470703125
training step: 22174, total_loss: 2.6156601905822754
training step: 22175, total_loss: 5.692986011505127
training step: 22176, total_loss: 3.445979356765747
training step: 22177, total_loss: 5.217667579650879
training step: 22178, total_loss: 3.599317789077759
training step: 22179, total_loss: 3.678666591644287
training step: 22180, total_loss: 4.783696174621582
training step: 22181, total_loss: 3.6649551391601562
training step: 22182, total_loss: 4.745167255401611
training step: 22183, total_loss: 4.2584686279296875
training step: 22184, total_loss: 4.663326740264893
training step: 22185, total_loss: 4.746338367462158
training step: 22186, total_loss: 4.332470417022705
training step: 22187, total_loss: 5.123638153076172
training step: 22188, total_loss: 4.401989459991455
training step: 22189, total_loss: 5.419390678405762
training step: 22190, total_loss: 5.553981781005859
training step: 22191, total_loss: 4.177286624908447
training step: 22192, total_loss: 4.2240400314331055
training step: 22193, total_loss: 5.786100387573242
training step: 22194, total_loss: 4.830538749694824
training step: 22195, total_loss: 4.770174980163574
training step: 22196, total_loss: 3.211914539337158
training step: 22197, total_loss: 5.835034370422363
training step: 22198, total_loss: 4.920671463012695
training step: 22199, total_loss: 5.520296573638916
training step: 22200, total_loss: 3.9906373023986816
training step: 22201, total_loss: 4.461833953857422
training step: 22202, total_loss: 4.966744899749756
training step: 22203, total_loss: 2.596491813659668
training step: 22204, total_loss: 5.264255523681641
training step: 22205, total_loss: 4.9344024658203125
training step: 22206, total_loss: 4.971470355987549
training step: 22207, total_loss: 5.971445083618164
training step: 22208, total_loss: 4.992685317993164
training step: 22209, total_loss: 5.096686363220215
training step: 22210, total_loss: 3.0316953659057617
training step: 22211, total_loss: 4.06026554107666
training step: 22212, total_loss: 4.174655914306641
training step: 22213, total_loss: 3.0759525299072266
training step: 22214, total_loss: 5.726187705993652
training step: 22215, total_loss: 4.636852264404297
training step: 22216, total_loss: 4.22769021987915
training step: 22217, total_loss: 4.626761436462402
training step: 22218, total_loss: 3.7920074462890625
training step: 22219, total_loss: 4.9541754722595215
training step: 22220, total_loss: 4.625951766967773
training step: 22221, total_loss: 4.1491546630859375
training step: 22222, total_loss: 3.6649980545043945
training step: 22223, total_loss: 4.202256202697754
training step: 22224, total_loss: 5.144598960876465
training step: 22225, total_loss: 3.475998878479004
training step: 22226, total_loss: 3.2158541679382324
training step: 22227, total_loss: 5.401819705963135
training step: 22228, total_loss: 5.427859306335449
training step: 22229, total_loss: 3.210157871246338
training step: 22230, total_loss: 5.204838752746582
training step: 22231, total_loss: 1.433922529220581
training step: 22232, total_loss: 5.610937595367432
training step: 22233, total_loss: 5.229748725891113
training step: 22234, total_loss: 1.9418895244598389
training step: 22235, total_loss: 4.01837682723999
training step: 22236, total_loss: 4.254621505737305
training step: 22237, total_loss: 6.09500789642334
training step: 22238, total_loss: 1.4631824493408203
training step: 22239, total_loss: 2.2572526931762695
training step: 22240, total_loss: 5.172127723693848
training step: 22241, total_loss: 4.161638259887695
training step: 22242, total_loss: 4.390316009521484
training step: 22243, total_loss: 4.214951515197754
training step: 22244, total_loss: 4.356533050537109
training step: 22245, total_loss: 5.779655456542969
training step: 22246, total_loss: 4.9328742027282715
training step: 22247, total_loss: 4.39422607421875
training step: 22248, total_loss: 4.853381156921387
training step: 22249, total_loss: 4.762599945068359
training step: 22250, total_loss: 4.548517227172852
training step: 22251, total_loss: 3.040573835372925
training step: 22252, total_loss: 0.9375433921813965
training step: 22253, total_loss: 7.467215538024902
training step: 22254, total_loss: 4.491866111755371
training step: 22255, total_loss: 3.9255318641662598
training step: 22256, total_loss: 1.0374590158462524
training step: 22257, total_loss: 5.571206092834473
training step: 22258, total_loss: 0.9203627705574036
training step: 22259, total_loss: 3.316943645477295
training step: 22260, total_loss: 3.6022987365722656
training step: 22261, total_loss: 2.9681787490844727
training step: 22262, total_loss: 4.703598976135254
training step: 22263, total_loss: 4.775311470031738
training step: 22264, total_loss: 4.974588394165039
training step: 22265, total_loss: 4.4002580642700195
training step: 22266, total_loss: 4.272850036621094
training step: 22267, total_loss: 4.936707019805908
training step: 22268, total_loss: 4.5672454833984375
training step: 22269, total_loss: 3.7351608276367188
training step: 22270, total_loss: 2.890578031539917
training step: 22271, total_loss: 4.419730186462402
training step: 22272, total_loss: 4.849321365356445
training step: 22273, total_loss: 5.683409214019775
training step: 22274, total_loss: 6.495709419250488
training step: 22275, total_loss: 3.771519899368286
training step: 22276, total_loss: 4.61248779296875
training step: 22277, total_loss: 5.979443550109863
training step: 22278, total_loss: 3.7364838123321533
training step: 22279, total_loss: 4.755298614501953
training step: 22280, total_loss: 0.7535787224769592
training step: 22281, total_loss: 5.458708763122559
training step: 22282, total_loss: 4.3517961502075195
training step: 22283, total_loss: 3.924981117248535
training step: 22284, total_loss: 5.989695072174072
training step: 22285, total_loss: 6.030378341674805
training step: 22286, total_loss: 4.0711822509765625
training step: 22287, total_loss: 4.7284698486328125
training step: 22288, total_loss: 3.48964786529541
training step: 22289, total_loss: 5.216736793518066
training step: 22290, total_loss: 7.105205059051514
training step: 22291, total_loss: 5.69399881362915
training step: 22292, total_loss: 3.66064715385437
training step: 22293, total_loss: 5.379652976989746
training step: 22294, total_loss: 4.661036491394043
training step: 22295, total_loss: 4.494296550750732
training step: 22296, total_loss: 5.444169998168945
training step: 22297, total_loss: 5.545162200927734
training step: 22298, total_loss: 5.931962966918945
training step: 22299, total_loss: 4.966488361358643
training step: 22300, total_loss: 3.1210179328918457
training step: 22301, total_loss: 3.384080171585083
training step: 22302, total_loss: 5.520956039428711
training step: 22303, total_loss: 5.094854831695557
training step: 22304, total_loss: 4.30014181137085
training step: 22305, total_loss: 5.352334022521973
training step: 22306, total_loss: 5.518982887268066
training step: 22307, total_loss: 5.001184463500977
training step: 22308, total_loss: 5.534395217895508
training step: 22309, total_loss: 4.862115859985352
training step: 22310, total_loss: 5.046426773071289
training step: 22311, total_loss: 4.634121417999268
training step: 22312, total_loss: 4.1986188888549805
training step: 22313, total_loss: 5.364479064941406
training step: 22314, total_loss: 5.553219795227051
training step: 22315, total_loss: 4.886013031005859
training step: 22316, total_loss: 4.361339569091797
training step: 22317, total_loss: 5.544191837310791
training step: 22318, total_loss: 3.8606371879577637
training step: 22319, total_loss: 4.46666145324707
training step: 22320, total_loss: 4.193921089172363
training step: 22321, total_loss: 4.979560375213623
training step: 22322, total_loss: 4.8204874992370605
training step: 22323, total_loss: 5.438108444213867
training step: 22324, total_loss: 4.601449012756348
training step: 22325, total_loss: 4.887494087219238
training step: 22326, total_loss: 6.281968593597412
training step: 22327, total_loss: 4.376086235046387
training step: 22328, total_loss: 5.975578308105469
training step: 22329, total_loss: 6.184256553649902
training step: 22330, total_loss: 4.276688575744629
training step: 22331, total_loss: 3.957752227783203
training step: 22332, total_loss: 4.208225250244141
training step: 22333, total_loss: 4.469027042388916
training step: 22334, total_loss: 5.751214504241943
training step: 22335, total_loss: 4.492636680603027
training step: 22336, total_loss: 5.214491844177246
training step: 22337, total_loss: 4.732034206390381
training step: 22338, total_loss: 3.9489150047302246
training step: 22339, total_loss: 3.848034143447876
training step: 22340, total_loss: 5.108699798583984
training step: 22341, total_loss: 3.5994811058044434
training step: 22342, total_loss: 4.411205291748047
training step: 22343, total_loss: 4.524182319641113
training step: 22344, total_loss: 4.9561448097229
training step: 22345, total_loss: 6.068769454956055
training step: 22346, total_loss: 3.76155424118042
training step: 22347, total_loss: 4.026043891906738
training step: 22348, total_loss: 5.891417503356934
training step: 22349, total_loss: 4.105875015258789
training step: 22350, total_loss: 6.306745529174805
training step: 22351, total_loss: 4.379441261291504
training step: 22352, total_loss: 4.694900989532471
training step: 22353, total_loss: 3.645789623260498
training step: 22354, total_loss: 5.860936164855957
training step: 22355, total_loss: 5.689230918884277
training step: 22356, total_loss: 4.971247673034668
training step: 22357, total_loss: 4.725948333740234
training step: 22358, total_loss: 3.9442362785339355
training step: 22359, total_loss: 4.299189567565918
training step: 22360, total_loss: 4.749152183532715
training step: 22361, total_loss: 3.7858524322509766
training step: 22362, total_loss: 4.690278053283691
training step: 22363, total_loss: 4.141999244689941
training step: 22364, total_loss: 4.312814712524414
training step: 22365, total_loss: 4.517290115356445
training step: 22366, total_loss: 4.5996246337890625
training step: 22367, total_loss: 3.3984827995300293
training step: 22368, total_loss: 3.712669849395752
training step: 22369, total_loss: 3.881333589553833
training step: 22370, total_loss: 4.523387908935547
training step: 22371, total_loss: 5.572017192840576
training step: 22372, total_loss: 4.836175918579102
training step: 22373, total_loss: 4.0010247230529785
training step: 22374, total_loss: 6.03485107421875
training step: 22375, total_loss: 5.789992332458496
training step: 22376, total_loss: 5.326919078826904
training step: 22377, total_loss: 3.1010751724243164
training step: 22378, total_loss: 4.841556549072266
training step: 22379, total_loss: 4.06515645980835
training step: 22380, total_loss: 4.347756385803223
training step: 22381, total_loss: 4.703609466552734
training step: 22382, total_loss: 5.4900712966918945
training step: 22383, total_loss: 4.842765808105469
training step: 22384, total_loss: 4.722186088562012
training step: 22385, total_loss: 4.376400947570801
training step: 22386, total_loss: 5.68205451965332
training step: 22387, total_loss: 3.9830691814422607
training step: 22388, total_loss: 4.767228126525879
training step: 22389, total_loss: 4.390153884887695
training step: 22390, total_loss: 5.056023597717285
training step: 22391, total_loss: 4.605469226837158
training step: 22392, total_loss: 5.66574764251709
training step: 22393, total_loss: 5.106269836425781
training step: 22394, total_loss: 3.2969412803649902
training step: 22395, total_loss: 4.391457557678223
training step: 22396, total_loss: 3.804685592651367
training step: 22397, total_loss: 4.327442646026611
training step: 22398, total_loss: 5.450429916381836
training step: 22399, total_loss: 5.274710178375244
training step: 22400, total_loss: 4.773181915283203
training step: 22401, total_loss: 5.655011177062988
training step: 22402, total_loss: 5.423270225524902
training step: 22403, total_loss: 4.199073791503906
training step: 22404, total_loss: 4.650612831115723
training step: 22405, total_loss: 4.919450759887695
training step: 22406, total_loss: 5.4951019287109375
training step: 22407, total_loss: 3.86122465133667
training step: 22408, total_loss: 3.7298567295074463
training step: 22409, total_loss: 5.270364761352539
training step: 22410, total_loss: 4.173607349395752
training step: 22411, total_loss: 4.224458694458008
training step: 22412, total_loss: 6.189841270446777
training step: 22413, total_loss: 3.992567539215088
training step: 22414, total_loss: 4.201582431793213
training step: 22415, total_loss: 5.417851448059082
training step: 22416, total_loss: 5.002692222595215
training step: 22417, total_loss: 4.3705573081970215
training step: 22418, total_loss: 4.723763942718506
training step: 22419, total_loss: 4.436006546020508
training step: 22420, total_loss: 5.590816974639893
training step: 22421, total_loss: 5.444154739379883
training step: 22422, total_loss: 4.382628440856934
training step: 22423, total_loss: 4.761573314666748
training step: 22424, total_loss: 4.055780410766602
training step: 22425, total_loss: 1.9082279205322266
training step: 22426, total_loss: 4.11872673034668
training step: 22427, total_loss: 3.520164728164673
training step: 22428, total_loss: 5.333162307739258
training step: 22429, total_loss: 3.592719316482544
training step: 22430, total_loss: 4.149406433105469
training step: 22431, total_loss: 4.123927116394043
training step: 22432, total_loss: 5.661062240600586
training step: 22433, total_loss: 5.928201198577881
training step: 22434, total_loss: 4.945984840393066
training step: 22435, total_loss: 4.734715461730957
training step: 22436, total_loss: 5.696270942687988
training step: 22437, total_loss: 4.80645751953125
training step: 22438, total_loss: 4.973670959472656
training step: 22439, total_loss: 5.444840431213379
training step: 22440, total_loss: 5.075957298278809
training step: 22441, total_loss: 5.886936187744141
training step: 22442, total_loss: 2.6952667236328125
training step: 22443, total_loss: 4.442813873291016
training step: 22444, total_loss: 6.213187217712402
training step: 22445, total_loss: 5.367742538452148
training step: 22446, total_loss: 5.516356468200684
training step: 22447, total_loss: 4.724173545837402
training step: 22448, total_loss: 4.046396255493164
training step: 22449, total_loss: 5.126134395599365
training step: 22450, total_loss: 5.832824230194092
training step: 22451, total_loss: 4.152950286865234
training step: 22452, total_loss: 5.3779296875
training step: 22453, total_loss: 4.2083916664123535
training step: 22454, total_loss: 3.8180649280548096
training step: 22455, total_loss: 3.780384063720703
training step: 22456, total_loss: 3.612596035003662
training step: 22457, total_loss: 5.65626335144043
training step: 22458, total_loss: 4.25425386428833
training step: 22459, total_loss: 4.893527984619141
training step: 22460, total_loss: 4.914788246154785
training step: 22461, total_loss: 4.971994400024414
training step: 22462, total_loss: 2.896423816680908
training step: 22463, total_loss: 4.2037811279296875
training step: 22464, total_loss: 3.793071985244751
training step: 22465, total_loss: 3.711555004119873
training step: 22466, total_loss: 4.186261177062988
training step: 22467, total_loss: 1.7786931991577148
training step: 22468, total_loss: 5.10753870010376
training step: 22469, total_loss: 4.527538299560547
training step: 22470, total_loss: 5.8352251052856445
training step: 22471, total_loss: 5.146542549133301
training step: 22472, total_loss: 4.079746723175049
training step: 22473, total_loss: 5.615977764129639
training step: 22474, total_loss: 4.513699531555176
training step: 22475, total_loss: 5.135257244110107
training step: 22476, total_loss: 4.675353527069092
training step: 22477, total_loss: 5.028890609741211
training step: 22478, total_loss: 4.26780891418457
training step: 22479, total_loss: 3.6627392768859863
training step: 22480, total_loss: 3.7169559001922607
training step: 22481, total_loss: 3.9614834785461426
training step: 22482, total_loss: 4.120139122009277
training step: 22483, total_loss: 5.3115129470825195
training step: 22484, total_loss: 5.026715278625488
training step: 22485, total_loss: 5.893457412719727
training step: 22486, total_loss: 2.1917355060577393
training step: 22487, total_loss: 4.547878265380859
training step: 22488, total_loss: 6.908943176269531
training step: 22489, total_loss: 4.285202980041504
training step: 22490, total_loss: 1.254807472229004
training step: 22491, total_loss: 2.614527463912964
training step: 22492, total_loss: 4.755518913269043
training step: 22493, total_loss: 4.327484130859375
training step: 22494, total_loss: 4.181301593780518
training step: 22495, total_loss: 4.400660037994385
training step: 22496, total_loss: 2.2141571044921875
training step: 22497, total_loss: 4.932658672332764
training step: 22498, total_loss: 4.6491570472717285
training step: 22499, total_loss: 3.990400791168213
training step: 22500, total_loss: 3.524378776550293
training step: 22501, total_loss: 7.6197381019592285
training step: 22502, total_loss: 3.9469404220581055
training step: 22503, total_loss: 1.2315889596939087
training step: 22504, total_loss: 4.615176200866699
training step: 22505, total_loss: 4.061178207397461
training step: 22506, total_loss: 4.322914123535156
training step: 22507, total_loss: 4.571796417236328
training step: 22508, total_loss: 5.090191841125488
training step: 22509, total_loss: 4.991005897521973
training step: 22510, total_loss: 5.555779457092285
training step: 22511, total_loss: 4.556049346923828
training step: 22512, total_loss: 4.800477981567383
training step: 22513, total_loss: 5.058884620666504
training step: 22514, total_loss: 4.437235355377197
training step: 22515, total_loss: 6.557635307312012
training step: 22516, total_loss: 3.6549272537231445
training step: 22517, total_loss: 3.988640785217285
training step: 22518, total_loss: 3.403146743774414
training step: 22519, total_loss: 4.2910051345825195
training step: 22520, total_loss: 5.4124555587768555
training step: 22521, total_loss: 5.307097911834717
training step: 22522, total_loss: 2.8949413299560547
training step: 22523, total_loss: 3.9174625873565674
training step: 22524, total_loss: 4.502845287322998
training step: 22525, total_loss: 4.771315574645996
training step: 22526, total_loss: 3.778442859649658
training step: 22527, total_loss: 4.64537239074707
training step: 22528, total_loss: 4.535617828369141
training step: 22529, total_loss: 5.36496639251709
training step: 22530, total_loss: 5.353404998779297
training step: 22531, total_loss: 2.4518823623657227
training step: 22532, total_loss: 4.7427897453308105
training step: 22533, total_loss: 3.2557873725891113
training step: 22534, total_loss: 4.900350570678711
training step: 22535, total_loss: 1.0843312740325928
training step: 22536, total_loss: 5.043999195098877
training step: 22537, total_loss: 5.152802467346191
training step: 22538, total_loss: 4.390166282653809
training step: 22539, total_loss: 4.683835029602051
training step: 22540, total_loss: 4.824125289916992
training step: 22541, total_loss: 4.575079917907715
training step: 22542, total_loss: 3.2143750190734863
training step: 22543, total_loss: 5.637857437133789
training step: 22544, total_loss: 4.401480674743652
training step: 22545, total_loss: 4.79412317276001
training step: 22546, total_loss: 6.35166597366333
training step: 22547, total_loss: 5.302530288696289
training step: 22548, total_loss: 3.4324159622192383
training step: 22549, total_loss: 3.7034177780151367
training step: 22550, total_loss: 4.677382946014404
training step: 22551, total_loss: 5.2653350830078125
training step: 22552, total_loss: 3.560624837875366
training step: 22553, total_loss: 2.7167675495147705
training step: 22554, total_loss: 3.7580511569976807
training step: 22555, total_loss: 2.1965060234069824
training step: 22556, total_loss: 4.35499382019043
training step: 22557, total_loss: 3.195591449737549
training step: 22558, total_loss: 4.557233810424805
training step: 22559, total_loss: 4.20407772064209
training step: 22560, total_loss: 5.123156547546387
training step: 22561, total_loss: 5.809041976928711
training step: 22562, total_loss: 5.364373207092285
training step: 22563, total_loss: 4.752256870269775
training step: 22564, total_loss: 3.9543845653533936
training step: 22565, total_loss: 4.275905609130859
training step: 22566, total_loss: 4.298508644104004
training step: 22567, total_loss: 4.595976829528809
training step: 22568, total_loss: 4.583078384399414
training step: 22569, total_loss: 5.217528343200684
training step: 22570, total_loss: 4.042725563049316
training step: 22571, total_loss: 6.482857704162598
training step: 22572, total_loss: 4.328619003295898
training step: 22573, total_loss: 3.732988119125366
training step: 22574, total_loss: 2.502469778060913
training step: 22575, total_loss: 4.66934871673584
training step: 22576, total_loss: 4.986605167388916
training step: 22577, total_loss: 2.897562026977539
training step: 22578, total_loss: 4.564385414123535
training step: 22579, total_loss: 4.7218427658081055
training step: 22580, total_loss: 4.824823379516602
training step: 22581, total_loss: 5.067563056945801
training step: 22582, total_loss: 6.207784652709961
training step: 22583, total_loss: 4.840153694152832
training step: 22584, total_loss: 3.4167957305908203
training step: 22585, total_loss: 3.733825445175171
training step: 22586, total_loss: 4.129624843597412
training step: 22587, total_loss: 4.023255348205566
training step: 22588, total_loss: 5.184103012084961
training step: 22589, total_loss: 4.322328567504883
training step: 22590, total_loss: 4.986595153808594
training step: 22591, total_loss: 3.781057357788086
training step: 22592, total_loss: 4.957091808319092
training step: 22593, total_loss: 4.618792533874512
training step: 22594, total_loss: 4.845845699310303
training step: 22595, total_loss: 5.030560493469238
training step: 22596, total_loss: 3.000335216522217
training step: 22597, total_loss: 4.080790996551514
training step: 22598, total_loss: 3.56536602973938
training step: 22599, total_loss: 5.0272393226623535
training step: 22600, total_loss: 3.3956186771392822
training step: 22601, total_loss: 4.123717308044434
training step: 22602, total_loss: 2.9600400924682617
training step: 22603, total_loss: 4.13365364074707
training step: 22604, total_loss: 3.82715106010437
training step: 22605, total_loss: 5.069099426269531
training step: 22606, total_loss: 5.06173038482666
training step: 22607, total_loss: 3.8233349323272705
training step: 22608, total_loss: 2.25350284576416
training step: 22609, total_loss: 3.843874931335449
training step: 22610, total_loss: 3.859975576400757
training step: 22611, total_loss: 4.234470367431641
training step: 22612, total_loss: 4.467047214508057
training step: 22613, total_loss: 5.122001647949219
training step: 22614, total_loss: 4.116454124450684
training step: 22615, total_loss: 4.350786209106445
training step: 22616, total_loss: 4.584444522857666
training step: 22617, total_loss: 4.436656951904297
training step: 22618, total_loss: 4.637401103973389
training step: 22619, total_loss: 4.315579891204834
training step: 22620, total_loss: 5.122140884399414
training step: 22621, total_loss: 4.554378986358643
training step: 22622, total_loss: 2.965481758117676
training step: 22623, total_loss: 4.406079292297363
training step: 22624, total_loss: 4.059192657470703
training step: 22625, total_loss: 4.514566421508789
training step: 22626, total_loss: 3.4869251251220703
training step: 22627, total_loss: 4.516425132751465
training step: 22628, total_loss: 4.116319179534912
training step: 22629, total_loss: 4.29871129989624
training step: 22630, total_loss: 1.5656287670135498
training step: 22631, total_loss: 1.4807891845703125
training step: 22632, total_loss: 4.70102596282959
training step: 22633, total_loss: 5.13848352432251
training step: 22634, total_loss: 4.600978374481201
training step: 22635, total_loss: 4.7329607009887695
training step: 22636, total_loss: 4.381557464599609
training step: 22637, total_loss: 5.49658727645874
training step: 22638, total_loss: 5.284241676330566
training step: 22639, total_loss: 4.290737628936768
training step: 22640, total_loss: 3.593050479888916
training step: 22641, total_loss: 4.695189476013184
training step: 22642, total_loss: 5.824066162109375
training step: 22643, total_loss: 4.048578262329102
training step: 22644, total_loss: 4.498174667358398
training step: 22645, total_loss: 3.5530776977539062
training step: 22646, total_loss: 4.114491939544678
training step: 22647, total_loss: 5.636662006378174
training step: 22648, total_loss: 2.270230293273926
training step: 22649, total_loss: 3.8207287788391113
training step: 22650, total_loss: 4.77609920501709
training step: 22651, total_loss: 3.2413511276245117
training step: 22652, total_loss: 4.152510643005371
training step: 22653, total_loss: 4.847146034240723
training step: 22654, total_loss: 5.71171760559082
training step: 22655, total_loss: 4.746156692504883
training step: 22656, total_loss: 4.221823692321777
training step: 22657, total_loss: 5.270071029663086
training step: 22658, total_loss: 4.6821064949035645
training step: 22659, total_loss: 4.836178779602051
training step: 22660, total_loss: 4.586370468139648
training step: 22661, total_loss: 4.090381145477295
training step: 22662, total_loss: 5.915931224822998
training step: 22663, total_loss: 6.220991134643555
training step: 22664, total_loss: 4.3900041580200195
training step: 22665, total_loss: 4.583754062652588
training step: 22666, total_loss: 4.756587505340576
training step: 22667, total_loss: 4.589585781097412
training step: 22668, total_loss: 5.075962066650391
training step: 22669, total_loss: 5.182422637939453
training step: 22670, total_loss: 5.916268348693848
training step: 22671, total_loss: 5.189576625823975
training step: 22672, total_loss: 3.135434627532959
training step: 22673, total_loss: 3.2033045291900635
training step: 22674, total_loss: 4.333369255065918
training step: 22675, total_loss: 4.238907814025879
training step: 22676, total_loss: 5.189764976501465
training step: 22677, total_loss: 3.6015944480895996
training step: 22678, total_loss: 3.694383144378662
training step: 22679, total_loss: 4.717337608337402
training step: 22680, total_loss: 4.471521854400635
training step: 22681, total_loss: 3.9228713512420654
training step: 22682, total_loss: 4.268898963928223
training step: 22683, total_loss: 4.502656936645508
training step: 22684, total_loss: 6.830019950866699
training step: 22685, total_loss: 3.041924476623535
training step: 22686, total_loss: 4.3632049560546875
training step: 22687, total_loss: 4.490235328674316
training step: 22688, total_loss: 4.5179266929626465
training step: 22689, total_loss: 4.765605926513672
training step: 22690, total_loss: 3.420938491821289
training step: 22691, total_loss: 2.769620656967163
training step: 22692, total_loss: 4.342526435852051
training step: 22693, total_loss: 5.850946426391602
training step: 22694, total_loss: 4.978331089019775
training step: 22695, total_loss: 3.814058542251587
training step: 22696, total_loss: 4.815491199493408
training step: 22697, total_loss: 5.095901012420654
training step: 22698, total_loss: 4.18497371673584
training step: 22699, total_loss: 4.287438869476318
training step: 22700, total_loss: 3.0719141960144043
training step: 22701, total_loss: 1.5851011276245117
training step: 22702, total_loss: 4.448524475097656
training step: 22703, total_loss: 3.7771310806274414
training step: 22704, total_loss: 3.8376576900482178
training step: 22705, total_loss: 4.113048076629639
training step: 22706, total_loss: 3.8120670318603516
training step: 22707, total_loss: 3.055314779281616
training step: 22708, total_loss: 4.7093586921691895
training step: 22709, total_loss: 4.073724746704102
training step: 22710, total_loss: 3.8771157264709473
training step: 22711, total_loss: 5.644866943359375
training step: 22712, total_loss: 3.700019359588623
training step: 22713, total_loss: 4.543910503387451
training step: 22714, total_loss: 4.011364459991455
training step: 22715, total_loss: 5.416938304901123
training step: 22716, total_loss: 3.207768440246582
training step: 22717, total_loss: 3.9110701084136963
training step: 22718, total_loss: 4.3053789138793945
training step: 22719, total_loss: 5.58562707901001
training step: 22720, total_loss: 6.164093971252441
training step: 22721, total_loss: 3.7028863430023193
training step: 22722, total_loss: 3.453244924545288
training step: 22723, total_loss: 5.882696628570557
training step: 22724, total_loss: 4.85699462890625
training step: 22725, total_loss: 3.7559008598327637
training step: 22726, total_loss: 4.888734340667725
training step: 22727, total_loss: 4.596558570861816
training step: 22728, total_loss: 4.670917510986328
training step: 22729, total_loss: 5.902017116546631
training step: 22730, total_loss: 3.7648367881774902
training step: 22731, total_loss: 4.420607566833496
training step: 22732, total_loss: 2.1049230098724365
training step: 22733, total_loss: 2.980059862136841
training step: 22734, total_loss: 5.435013294219971
training step: 22735, total_loss: 4.515404224395752
training step: 22736, total_loss: 5.769639015197754
training step: 22737, total_loss: 3.7006497383117676
training step: 22738, total_loss: 3.0553903579711914
training step: 22739, total_loss: 3.358675003051758
training step: 22740, total_loss: 2.8062171936035156
training step: 22741, total_loss: 4.076535224914551
training step: 22742, total_loss: 5.01544713973999
training step: 22743, total_loss: 4.463603973388672
training step: 22744, total_loss: 3.3310928344726562
training step: 22745, total_loss: 4.167549133300781
training step: 22746, total_loss: 3.2984819412231445
training step: 22747, total_loss: 4.683276176452637
training step: 22748, total_loss: 5.008829593658447
training step: 22749, total_loss: 3.834913730621338
training step: 22750, total_loss: 3.702285051345825
training step: 22751, total_loss: 2.9762871265411377
training step: 22752, total_loss: 6.76577091217041
training step: 22753, total_loss: 5.2414350509643555
training step: 22754, total_loss: 3.906449794769287
training step: 22755, total_loss: 2.5545506477355957
training step: 22756, total_loss: 3.909327983856201
training step: 22757, total_loss: 3.945110321044922
training step: 22758, total_loss: 4.405280113220215
training step: 22759, total_loss: 5.272657871246338
training step: 22760, total_loss: 3.8030338287353516
training step: 22761, total_loss: 4.321707248687744
training step: 22762, total_loss: 3.6968438625335693
training step: 22763, total_loss: 2.7295687198638916
training step: 22764, total_loss: 3.2652220726013184
training step: 22765, total_loss: 4.799769401550293
training step: 22766, total_loss: 4.272907257080078
training step: 22767, total_loss: 4.752002239227295
training step: 22768, total_loss: 5.282544136047363
training step: 22769, total_loss: 5.510656356811523
training step: 22770, total_loss: 4.775343418121338
training step: 22771, total_loss: 5.175225257873535
training step: 22772, total_loss: 3.203199863433838
training step: 22773, total_loss: 1.1668295860290527
training step: 22774, total_loss: 6.5901079177856445
training step: 22775, total_loss: 4.458235740661621
training step: 22776, total_loss: 4.940309524536133
training step: 22777, total_loss: 4.806312561035156
training step: 22778, total_loss: 4.527535915374756
training step: 22779, total_loss: 3.4531006813049316
training step: 22780, total_loss: 0.9697607755661011
training step: 22781, total_loss: 4.120414733886719
training step: 22782, total_loss: 4.514865875244141
training step: 22783, total_loss: 4.169801235198975
training step: 22784, total_loss: 5.082951068878174
training step: 22785, total_loss: 3.339838981628418
training step: 22786, total_loss: 6.388073444366455
training step: 22787, total_loss: 2.8816046714782715
training step: 22788, total_loss: 5.211523056030273
training step: 22789, total_loss: 2.8635802268981934
training step: 22790, total_loss: 2.7022457122802734
training step: 22791, total_loss: 4.439449787139893
training step: 22792, total_loss: 4.439169406890869
training step: 22793, total_loss: 4.744918346405029
training step: 22794, total_loss: 4.350838661193848
training step: 22795, total_loss: 3.57405948638916
training step: 22796, total_loss: 5.085174560546875
training step: 22797, total_loss: 3.212653636932373
training step: 22798, total_loss: 5.781588077545166
training step: 22799, total_loss: 5.131207466125488
training step: 22800, total_loss: 2.762493371963501
training step: 22801, total_loss: 5.373193740844727
training step: 22802, total_loss: 2.7847938537597656
training step: 22803, total_loss: 4.510678291320801
training step: 22804, total_loss: 5.365636825561523
training step: 22805, total_loss: 1.9918365478515625
training step: 22806, total_loss: 4.595014572143555
training step: 22807, total_loss: 4.059106826782227
training step: 22808, total_loss: 3.753945827484131
training step: 22809, total_loss: 3.7699079513549805
training step: 22810, total_loss: 4.599945068359375
training step: 22811, total_loss: 4.538217544555664
training step: 22812, total_loss: 2.9823691844940186
training step: 22813, total_loss: 5.528593063354492
training step: 22814, total_loss: 4.652832984924316
training step: 22815, total_loss: 4.026220321655273
training step: 22816, total_loss: 5.758256912231445
training step: 22817, total_loss: 4.218219757080078
training step: 22818, total_loss: 2.497152328491211
training step: 22819, total_loss: 4.153677940368652
training step: 22820, total_loss: 3.8385188579559326
training step: 22821, total_loss: 2.8754022121429443
training step: 22822, total_loss: 4.598874092102051
training step: 22823, total_loss: 4.329516410827637
training step: 22824, total_loss: 5.428520202636719
training step: 22825, total_loss: 5.634836196899414
training step: 22826, total_loss: 5.96232795715332
training step: 22827, total_loss: 5.135599136352539
training step: 22828, total_loss: 5.089706897735596
training step: 22829, total_loss: 3.3125314712524414
training step: 22830, total_loss: 3.670942783355713
training step: 22831, total_loss: 5.02994441986084
training step: 22832, total_loss: 4.895709991455078
training step: 22833, total_loss: 5.448464870452881
training step: 22834, total_loss: 4.530395030975342
training step: 22835, total_loss: 4.287742614746094
training step: 22836, total_loss: 4.127749443054199
training step: 22837, total_loss: 4.478156089782715
training step: 22838, total_loss: 4.343889236450195
training step: 22839, total_loss: 4.847826957702637
training step: 22840, total_loss: 4.808361053466797
training step: 22841, total_loss: 5.339992046356201
training step: 22842, total_loss: 6.541956901550293
training step: 22843, total_loss: 3.5276737213134766
training step: 22844, total_loss: 2.625714063644409
training step: 22845, total_loss: 4.334597587585449
training step: 22846, total_loss: 4.302417755126953
training step: 22847, total_loss: 5.216525077819824
training step: 22848, total_loss: 3.999425172805786
training step: 22849, total_loss: 3.7576632499694824
training step: 22850, total_loss: 3.1277267932891846
training step: 22851, total_loss: 3.57100772857666
training step: 22852, total_loss: 3.596142530441284
training step: 22853, total_loss: 4.13087272644043
training step: 22854, total_loss: 4.974357604980469
training step: 22855, total_loss: 5.270438194274902
training step: 22856, total_loss: 4.843142509460449
training step: 22857, total_loss: 4.507349967956543
training step: 22858, total_loss: 4.82705545425415
training step: 22859, total_loss: 5.095981121063232
training step: 22860, total_loss: 5.106389999389648
training step: 22861, total_loss: 3.9330124855041504
training step: 22862, total_loss: 3.9013376235961914
training step: 22863, total_loss: 4.501964092254639
training step: 22864, total_loss: 2.8816208839416504
training step: 22865, total_loss: 7.109806537628174
training step: 22866, total_loss: 4.853518009185791
training step: 22867, total_loss: 3.008176803588867
training step: 22868, total_loss: 6.950634956359863
training step: 22869, total_loss: 4.343329429626465
training step: 22870, total_loss: 4.640042304992676
training step: 22871, total_loss: 4.3964715003967285
training step: 22872, total_loss: 5.513609886169434
training step: 22873, total_loss: 5.018599510192871
training step: 22874, total_loss: 6.029736518859863
training step: 22875, total_loss: 5.317289352416992
training step: 22876, total_loss: 3.948483943939209
training step: 22877, total_loss: 4.568831920623779
training step: 22878, total_loss: 5.042120933532715
training step: 22879, total_loss: 4.055397033691406
training step: 22880, total_loss: 4.9357194900512695
training step: 22881, total_loss: 2.602848529815674
training step: 22882, total_loss: 4.319126129150391
training step: 22883, total_loss: 2.4445178508758545
training step: 22884, total_loss: 3.3024842739105225
training step: 22885, total_loss: 6.230307102203369
training step: 22886, total_loss: 6.5336713790893555
training step: 22887, total_loss: 3.1022090911865234
training step: 22888, total_loss: 1.8864569664001465
training step: 22889, total_loss: 4.3137593269348145
training step: 22890, total_loss: 4.735379219055176
training step: 22891, total_loss: 4.462151527404785
training step: 22892, total_loss: 4.703695297241211
training step: 22893, total_loss: 4.338604927062988
training step: 22894, total_loss: 0.6820470094680786
training step: 22895, total_loss: 4.561357021331787
training step: 22896, total_loss: 3.63728666305542
training step: 22897, total_loss: 5.038506031036377
training step: 22898, total_loss: 3.9513745307922363
training step: 22899, total_loss: 4.14300537109375
training step: 22900, total_loss: 4.359899044036865
training step: 22901, total_loss: 5.020758152008057
training step: 22902, total_loss: 4.240683078765869
training step: 22903, total_loss: 3.645822763442993
training step: 22904, total_loss: 5.105874061584473
training step: 22905, total_loss: 3.5885720252990723
training step: 22906, total_loss: 4.539002418518066
training step: 22907, total_loss: 7.239828109741211
training step: 22908, total_loss: 3.5128636360168457
training step: 22909, total_loss: 5.204043865203857
training step: 22910, total_loss: 2.7354350090026855
training step: 22911, total_loss: 4.602866172790527
training step: 22912, total_loss: 3.521613121032715
training step: 22913, total_loss: 4.070046901702881
training step: 22914, total_loss: 3.6974854469299316
training step: 22915, total_loss: 3.9014317989349365
training step: 22916, total_loss: 4.04144811630249
training step: 22917, total_loss: 4.500363826751709
training step: 22918, total_loss: 1.4914462566375732
training step: 22919, total_loss: 4.719070911407471
training step: 22920, total_loss: 3.4080727100372314
training step: 22921, total_loss: 6.067462921142578
training step: 22922, total_loss: 5.578716278076172
training step: 22923, total_loss: 4.798854351043701
training step: 22924, total_loss: 5.033154487609863
training step: 22925, total_loss: 3.6900033950805664
training step: 22926, total_loss: 4.196671485900879
training step: 22927, total_loss: 4.447854042053223
training step: 22928, total_loss: 4.643996715545654
training step: 22929, total_loss: 3.359424114227295
training step: 22930, total_loss: 3.987081527709961
training step: 22931, total_loss: 4.336452007293701
training step: 22932, total_loss: 5.551158905029297
training step: 22933, total_loss: 5.230093955993652
training step: 22934, total_loss: 5.177437782287598
training step: 22935, total_loss: 6.266030311584473
training step: 22936, total_loss: 4.055557727813721
training step: 22937, total_loss: 6.9587507247924805
training step: 22938, total_loss: 4.18568229675293
training step: 22939, total_loss: 4.676645278930664
training step: 22940, total_loss: 5.125551700592041
training step: 22941, total_loss: 4.405951023101807
training step: 22942, total_loss: 3.6349496841430664
training step: 22943, total_loss: 6.042532920837402
training step: 22944, total_loss: 5.219052314758301
training step: 22945, total_loss: 4.752223014831543
training step: 22946, total_loss: 3.5911290645599365
training step: 22947, total_loss: 3.2369608879089355
training step: 22948, total_loss: 4.853360176086426
training step: 22949, total_loss: 4.712551593780518
training step: 22950, total_loss: 4.315464973449707
training step: 22951, total_loss: 5.67374324798584
training step: 22952, total_loss: 4.764583110809326
training step: 22953, total_loss: 3.900193691253662
training step: 22954, total_loss: 5.915465354919434
training step: 22955, total_loss: 4.9306111335754395
training step: 22956, total_loss: 3.29819917678833
training step: 22957, total_loss: 3.7967987060546875
training step: 22958, total_loss: 4.18037748336792
training step: 22959, total_loss: 1.2845770120620728
training step: 22960, total_loss: 3.5811543464660645
training step: 22961, total_loss: 4.143603324890137
training step: 22962, total_loss: 5.07815408706665
training step: 22963, total_loss: 4.858870506286621
training step: 22964, total_loss: 4.781923294067383
training step: 22965, total_loss: 3.9354286193847656
training step: 22966, total_loss: 4.780752182006836
training step: 22967, total_loss: 4.317903995513916
training step: 22968, total_loss: 4.568631172180176
training step: 22969, total_loss: 3.780796766281128
training step: 22970, total_loss: 4.002561569213867
training step: 22971, total_loss: 4.75917387008667
training step: 22972, total_loss: 4.803747653961182
training step: 22973, total_loss: 3.953036308288574
training step: 22974, total_loss: 3.6605143547058105
training step: 22975, total_loss: 4.70632791519165
training step: 22976, total_loss: 3.7084381580352783
training step: 22977, total_loss: 5.3389434814453125
training step: 22978, total_loss: 5.138066291809082
training step: 22979, total_loss: 0.8392349481582642
training step: 22980, total_loss: 4.712277412414551
training step: 22981, total_loss: 2.9786314964294434
training step: 22982, total_loss: 3.403543472290039
training step: 22983, total_loss: 4.801958084106445
training step: 22984, total_loss: 4.980390548706055
training step: 22985, total_loss: 3.267390251159668
training step: 22986, total_loss: 3.972842216491699
training step: 22987, total_loss: 6.162797927856445
training step: 22988, total_loss: 5.389644622802734
training step: 22989, total_loss: 2.8848888874053955
training step: 22990, total_loss: 4.4474687576293945
training step: 22991, total_loss: 4.741517066955566
training step: 22992, total_loss: 4.771164894104004
training step: 22993, total_loss: 4.541536331176758
training step: 22994, total_loss: 5.020449638366699
training step: 22995, total_loss: 4.3041672706604
training step: 22996, total_loss: 4.9588422775268555
training step: 22997, total_loss: 4.765608310699463
training step: 22998, total_loss: 7.121217727661133
training step: 22999, total_loss: 5.03533935546875
training step: 23000, total_loss: 4.931702136993408
training step: 23001, total_loss: 3.5748579502105713
training step: 23002, total_loss: 2.615809917449951
training step: 23003, total_loss: 5.360241889953613
training step: 23004, total_loss: 4.216486930847168
training step: 23005, total_loss: 3.4493160247802734
training step: 23006, total_loss: 4.660050392150879
training step: 23007, total_loss: 2.8319671154022217
training step: 23008, total_loss: 6.518682479858398
training step: 23009, total_loss: 4.968782424926758
training step: 23010, total_loss: 5.354846000671387
training step: 23011, total_loss: 4.45296573638916
training step: 23012, total_loss: 4.890017509460449
training step: 23013, total_loss: 5.224705219268799
training step: 23014, total_loss: 4.990618705749512
training step: 23015, total_loss: 5.108818531036377
training step: 23016, total_loss: 2.9871726036071777
training step: 23017, total_loss: 3.3076748847961426
training step: 23018, total_loss: 5.225302696228027
training step: 23019, total_loss: 5.494219779968262
training step: 23020, total_loss: 4.493217468261719
training step: 23021, total_loss: 4.186451435089111
training step: 23022, total_loss: 4.65389347076416
training step: 23023, total_loss: 4.292664527893066
training step: 23024, total_loss: 3.9614410400390625
training step: 23025, total_loss: 4.9790754318237305
training step: 23026, total_loss: 4.645909309387207
training step: 23027, total_loss: 3.9091219902038574
training step: 23028, total_loss: 4.350842475891113
training step: 23029, total_loss: 5.723054885864258
training step: 23030, total_loss: 4.970202445983887
training step: 23031, total_loss: 5.657793998718262
training step: 23032, total_loss: 3.558880567550659
training step: 23033, total_loss: 4.6875834465026855
training step: 23034, total_loss: 2.4658477306365967
training step: 23035, total_loss: 4.862602710723877
training step: 23036, total_loss: 6.485893249511719
training step: 23037, total_loss: 3.861046552658081
training step: 23038, total_loss: 4.227423667907715
training step: 23039, total_loss: 3.8225488662719727
training step: 23040, total_loss: 4.870299816131592
training step: 23041, total_loss: 3.417771816253662
training step: 23042, total_loss: 4.242341995239258
training step: 23043, total_loss: 4.520752906799316
training step: 23044, total_loss: 3.615710735321045
training step: 23045, total_loss: 4.963045597076416
training step: 23046, total_loss: 4.473328590393066
training step: 23047, total_loss: 4.4171319007873535
training step: 23048, total_loss: 5.044943332672119
training step: 23049, total_loss: 5.459328651428223
training step: 23050, total_loss: 4.648656845092773
training step: 23051, total_loss: 4.549325942993164
training step: 23052, total_loss: 5.046941757202148
training step: 23053, total_loss: 4.399681091308594
training step: 23054, total_loss: 4.811761856079102
training step: 23055, total_loss: 5.914344787597656
training step: 23056, total_loss: 4.513514995574951
training step: 23057, total_loss: 5.399394989013672
training step: 23058, total_loss: 6.1411051750183105
training step: 23059, total_loss: 3.6985206604003906
training step: 23060, total_loss: 5.010479927062988
training step: 23061, total_loss: 4.296812057495117
training step: 23062, total_loss: 4.302603244781494
training step: 23063, total_loss: 5.270720481872559
training step: 23064, total_loss: 5.601057529449463
training step: 23065, total_loss: 4.747950553894043
training step: 23066, total_loss: 3.342059373855591
training step: 23067, total_loss: 5.313106060028076
training step: 23068, total_loss: 4.355014324188232
training step: 23069, total_loss: 3.9614481925964355
training step: 23070, total_loss: 4.405913352966309
training step: 23071, total_loss: 5.7694621086120605
training step: 23072, total_loss: 5.18692684173584
training step: 23073, total_loss: 3.780298948287964
training step: 23074, total_loss: 6.095339298248291
training step: 23075, total_loss: 5.603497505187988
training step: 23076, total_loss: 4.395129203796387
training step: 23077, total_loss: 5.562762260437012
training step: 23078, total_loss: 5.473590850830078
training step: 23079, total_loss: 6.011558532714844
training step: 23080, total_loss: 5.846774578094482
training step: 23081, total_loss: 5.527952194213867
training step: 23082, total_loss: 3.77483868598938
training step: 23083, total_loss: 2.7128310203552246
training step: 23084, total_loss: 3.5146138668060303
training step: 23085, total_loss: 4.196827411651611
training step: 23086, total_loss: 5.130766868591309
training step: 23087, total_loss: 4.401230335235596
training step: 23088, total_loss: 4.344785213470459
training step: 23089, total_loss: 7.5803093910217285
training step: 23090, total_loss: 3.379040241241455
training step: 23091, total_loss: 4.602054119110107
training step: 23092, total_loss: 4.724328994750977
training step: 23093, total_loss: 4.925676345825195
training step: 23094, total_loss: 5.857478141784668
training step: 23095, total_loss: 4.064945697784424
training step: 23096, total_loss: 5.3609209060668945
training step: 23097, total_loss: 3.559251308441162
training step: 23098, total_loss: 3.9654550552368164
training step: 23099, total_loss: 4.808315277099609
training step: 23100, total_loss: 4.965194225311279
training step: 23101, total_loss: 3.4819440841674805
training step: 23102, total_loss: 4.304023742675781
training step: 23103, total_loss: 5.227300643920898
training step: 23104, total_loss: 4.228946685791016
training step: 23105, total_loss: 4.634449005126953
training step: 23106, total_loss: 2.9433999061584473
training step: 23107, total_loss: 5.383903503417969
training step: 23108, total_loss: 5.527671813964844
training step: 23109, total_loss: 4.982438087463379
training step: 23110, total_loss: 5.437668323516846
training step: 23111, total_loss: 4.107803821563721
training step: 23112, total_loss: 4.852651596069336
training step: 23113, total_loss: 6.4632110595703125
training step: 23114, total_loss: 4.474647521972656
training step: 23115, total_loss: 3.6949856281280518
training step: 23116, total_loss: 3.647749900817871
training step: 23117, total_loss: 4.372251510620117
training step: 23118, total_loss: 5.660178184509277
training step: 23119, total_loss: 4.375802040100098
training step: 23120, total_loss: 4.624206066131592
training step: 23121, total_loss: 4.258059501647949
training step: 23122, total_loss: 3.586721658706665
training step: 23123, total_loss: 4.140914440155029
training step: 23124, total_loss: 3.813873767852783
training step: 23125, total_loss: 4.180639266967773
training step: 23126, total_loss: 3.630387544631958
training step: 23127, total_loss: 4.821985721588135
training step: 23128, total_loss: 5.287682056427002
training step: 23129, total_loss: 6.02675724029541
training step: 23130, total_loss: 4.604262351989746
training step: 23131, total_loss: 3.6879703998565674
training step: 23132, total_loss: 4.306234836578369
training step: 23133, total_loss: 4.651020050048828
training step: 23134, total_loss: 5.066263198852539
training step: 23135, total_loss: 4.494653701782227
training step: 23136, total_loss: 4.481094837188721
training step: 23137, total_loss: 3.2377853393554688
training step: 23138, total_loss: 4.5003743171691895
training step: 23139, total_loss: 3.4644854068756104
training step: 23140, total_loss: 4.135964393615723
training step: 23141, total_loss: 3.593005895614624
training step: 23142, total_loss: 3.5147242546081543
training step: 23143, total_loss: 5.78770637512207
training step: 23144, total_loss: 4.585277557373047
training step: 23145, total_loss: 5.433190822601318
training step: 23146, total_loss: 5.127906799316406
training step: 23147, total_loss: 4.824680328369141
training step: 23148, total_loss: 7.403439044952393
training step: 23149, total_loss: 4.281968116760254
training step: 23150, total_loss: 2.361142158508301
training step: 23151, total_loss: 3.813406467437744
training step: 23152, total_loss: 5.014848709106445
training step: 23153, total_loss: 4.317243576049805
training step: 23154, total_loss: 3.804818868637085
training step: 23155, total_loss: 1.2824819087982178
training step: 23156, total_loss: 5.415904998779297
training step: 23157, total_loss: 4.0364837646484375
training step: 23158, total_loss: 3.00722074508667
training step: 23159, total_loss: 3.994312286376953
training step: 23160, total_loss: 7.264899253845215
training step: 23161, total_loss: 1.530125379562378
training step: 23162, total_loss: 5.119201183319092
training step: 23163, total_loss: 3.194108009338379
training step: 23164, total_loss: 4.927961349487305
training step: 23165, total_loss: 4.054071426391602
training step: 23166, total_loss: 4.817228317260742
training step: 23167, total_loss: 4.434026718139648
training step: 23168, total_loss: 3.469022750854492
training step: 23169, total_loss: 4.8606767654418945
training step: 23170, total_loss: 1.8927130699157715
training step: 23171, total_loss: 3.771191120147705
training step: 23172, total_loss: 5.25472354888916
training step: 23173, total_loss: 5.183704376220703
training step: 23174, total_loss: 4.481534957885742
training step: 23175, total_loss: 5.479842185974121
training step: 23176, total_loss: 5.525295257568359
training step: 23177, total_loss: 3.609574794769287
training step: 23178, total_loss: 4.530887603759766
training step: 23179, total_loss: 3.764181137084961
training step: 23180, total_loss: 4.996241569519043
training step: 23181, total_loss: 4.441219329833984
training step: 23182, total_loss: 5.481334209442139
training step: 23183, total_loss: 3.302156448364258
training step: 23184, total_loss: 3.896096706390381
training step: 23185, total_loss: 3.6696267127990723
training step: 23186, total_loss: 5.543023109436035
training step: 23187, total_loss: 3.061112642288208
training step: 23188, total_loss: 4.829408645629883
training step: 23189, total_loss: 2.4109082221984863
training step: 23190, total_loss: 3.903156280517578
training step: 23191, total_loss: 5.197879791259766
training step: 23192, total_loss: 0.9275401830673218
training step: 23193, total_loss: 5.43720006942749
training step: 23194, total_loss: 4.711546897888184
training step: 23195, total_loss: 4.357036590576172
training step: 23196, total_loss: 4.265695571899414
training step: 23197, total_loss: 4.937320232391357
training step: 23198, total_loss: 5.338149070739746
training step: 23199, total_loss: 2.244661569595337
training step: 23200, total_loss: 4.201785564422607
training step: 23201, total_loss: 4.851526737213135
training step: 23202, total_loss: 2.7151846885681152
training step: 23203, total_loss: 5.204957485198975
training step: 23204, total_loss: 5.181445121765137
training step: 23205, total_loss: 4.907105445861816
training step: 23206, total_loss: 3.279705047607422
training step: 23207, total_loss: 4.181863307952881
training step: 23208, total_loss: 4.476262092590332
training step: 23209, total_loss: 5.768954753875732
training step: 23210, total_loss: 3.54207444190979
training step: 23211, total_loss: 4.549749851226807
training step: 23212, total_loss: 4.451114177703857
training step: 23213, total_loss: 4.82400369644165
training step: 23214, total_loss: 6.858295440673828
training step: 23215, total_loss: 2.839157819747925
training step: 23216, total_loss: 4.29255485534668
training step: 23217, total_loss: 3.8128929138183594
training step: 23218, total_loss: 5.333269119262695
training step: 23219, total_loss: 4.574831008911133
training step: 23220, total_loss: 4.469870567321777
training step: 23221, total_loss: 4.831631660461426
training step: 23222, total_loss: 4.870889186859131
training step: 23223, total_loss: 4.248537063598633
training step: 23224, total_loss: 5.394758224487305
training step: 23225, total_loss: 4.072404861450195
training step: 23226, total_loss: 2.582733154296875
training step: 23227, total_loss: 2.746586799621582
training step: 23228, total_loss: 3.0372138023376465
training step: 23229, total_loss: 3.8513760566711426
training step: 23230, total_loss: 3.848661184310913
training step: 23231, total_loss: 4.21665096282959
training step: 23232, total_loss: 6.116233825683594
training step: 23233, total_loss: 4.3805389404296875
training step: 23234, total_loss: 3.8452303409576416
training step: 23235, total_loss: 5.214910507202148
training step: 23236, total_loss: 4.3774261474609375
training step: 23237, total_loss: 4.4439592361450195
training step: 23238, total_loss: 4.052458763122559
training step: 23239, total_loss: 4.301814556121826
training step: 23240, total_loss: 3.918815851211548
training step: 23241, total_loss: 1.0942906141281128
training step: 23242, total_loss: 3.848626136779785
training step: 23243, total_loss: 3.788754940032959
training step: 23244, total_loss: 6.4302473068237305
training step: 23245, total_loss: 4.1632843017578125
training step: 23246, total_loss: 4.755760192871094
training step: 23247, total_loss: 4.103034019470215
training step: 23248, total_loss: 3.711303234100342
training step: 23249, total_loss: 4.989668846130371
training step: 23250, total_loss: 4.786726951599121
training step: 23251, total_loss: 1.0084131956100464
training step: 23252, total_loss: 6.28727912902832
training step: 23253, total_loss: 5.504090309143066
training step: 23254, total_loss: 3.60953950881958
training step: 23255, total_loss: 4.295180320739746
training step: 23256, total_loss: 2.1504645347595215
training step: 23257, total_loss: 3.5975475311279297
training step: 23258, total_loss: 3.6719934940338135
training step: 23259, total_loss: 4.599411964416504
training step: 23260, total_loss: 4.754096031188965
training step: 23261, total_loss: 6.327781677246094
training step: 23262, total_loss: 3.1760334968566895
training step: 23263, total_loss: 3.773348093032837
training step: 23264, total_loss: 4.908572196960449
training step: 23265, total_loss: 4.35038423538208
training step: 23266, total_loss: 4.508357048034668
training step: 23267, total_loss: 5.073087692260742
training step: 23268, total_loss: 4.355621337890625
training step: 23269, total_loss: 5.342987060546875
training step: 23270, total_loss: 3.984102249145508
training step: 23271, total_loss: 4.482664108276367
training step: 23272, total_loss: 3.8755414485931396
training step: 23273, total_loss: 4.563880920410156
training step: 23274, total_loss: 4.415729999542236
training step: 23275, total_loss: 5.479267120361328
training step: 23276, total_loss: 3.6737327575683594
training step: 23277, total_loss: 4.611680030822754
training step: 23278, total_loss: 4.794081211090088
training step: 23279, total_loss: 3.5625383853912354
training step: 23280, total_loss: 3.9244751930236816
training step: 23281, total_loss: 4.659031867980957
training step: 23282, total_loss: 5.536593437194824
training step: 23283, total_loss: 4.031608581542969
training step: 23284, total_loss: 4.3516621589660645
training step: 23285, total_loss: 4.933645248413086
training step: 23286, total_loss: 5.2178955078125
training step: 23287, total_loss: 3.721001386642456
training step: 23288, total_loss: 5.2802276611328125
training step: 23289, total_loss: 4.6208930015563965
training step: 23290, total_loss: 4.831662178039551
training step: 23291, total_loss: 3.544485092163086
training step: 23292, total_loss: 5.851874828338623
training step: 23293, total_loss: 1.0683574676513672
training step: 23294, total_loss: 4.436871528625488
training step: 23295, total_loss: 4.587024688720703
training step: 23296, total_loss: 7.563446998596191
training step: 23297, total_loss: 3.8023505210876465
training step: 23298, total_loss: 4.547573566436768
training step: 23299, total_loss: 7.066608905792236
training step: 23300, total_loss: 5.0673675537109375
training step: 23301, total_loss: 5.452690601348877
training step: 23302, total_loss: 4.107403755187988
training step: 23303, total_loss: 4.7059125900268555
training step: 23304, total_loss: 5.511155128479004
training step: 23305, total_loss: 4.9584150314331055
training step: 23306, total_loss: 5.287409782409668
training step: 23307, total_loss: 3.689908742904663
training step: 23308, total_loss: 3.6731936931610107
training step: 23309, total_loss: 3.9687719345092773
training step: 23310, total_loss: 5.32778263092041
training step: 23311, total_loss: 6.049318790435791
training step: 23312, total_loss: 4.8104567527771
training step: 23313, total_loss: 5.158902168273926
training step: 23314, total_loss: 2.288104295730591
training step: 23315, total_loss: 5.605905532836914
training step: 23316, total_loss: 5.349524974822998
training step: 23317, total_loss: 4.947690486907959
training step: 23318, total_loss: 4.693754196166992
training step: 23319, total_loss: 6.076003074645996
training step: 23320, total_loss: 4.806118965148926
training step: 23321, total_loss: 3.562516927719116
training step: 23322, total_loss: 5.2432355880737305
training step: 23323, total_loss: 3.32700777053833
training step: 23324, total_loss: 5.368899345397949
training step: 23325, total_loss: 4.710472106933594
training step: 23326, total_loss: 3.478473663330078
training step: 23327, total_loss: 4.55333137512207
training step: 23328, total_loss: 5.203647613525391
training step: 23329, total_loss: 5.003537178039551
training step: 23330, total_loss: 4.31501579284668
training step: 23331, total_loss: 5.047938346862793
training step: 23332, total_loss: 3.605168342590332
training step: 23333, total_loss: 6.0424275398254395
training step: 23334, total_loss: 5.144850730895996
training step: 23335, total_loss: 5.782328128814697
training step: 23336, total_loss: 5.57590389251709
training step: 23337, total_loss: 4.222078323364258
training step: 23338, total_loss: 3.6184120178222656
training step: 23339, total_loss: 2.805725574493408
training step: 23340, total_loss: 4.651864051818848
training step: 23341, total_loss: 4.6871337890625
training step: 23342, total_loss: 4.391519546508789
training step: 23343, total_loss: 4.371950149536133
training step: 23344, total_loss: 4.128836631774902
training step: 23345, total_loss: 5.954290390014648
training step: 23346, total_loss: 3.903782844543457
training step: 23347, total_loss: 3.9820032119750977
training step: 23348, total_loss: 4.6966166496276855
training step: 23349, total_loss: 4.925369739532471
training step: 23350, total_loss: 4.9296064376831055
training step: 23351, total_loss: 3.8311805725097656
training step: 23352, total_loss: 4.3381805419921875
training step: 23353, total_loss: 4.417192459106445
training step: 23354, total_loss: 4.557765960693359
training step: 23355, total_loss: 4.792375564575195
training step: 23356, total_loss: 3.7032415866851807
training step: 23357, total_loss: 1.7897694110870361
training step: 23358, total_loss: 5.440723419189453
training step: 23359, total_loss: 4.486179351806641
training step: 23360, total_loss: 5.666172981262207
training step: 23361, total_loss: 4.133695125579834
training step: 23362, total_loss: 4.40540885925293
training step: 23363, total_loss: 2.8815841674804688
training step: 23364, total_loss: 3.0416173934936523
training step: 23365, total_loss: 4.491306304931641
training step: 23366, total_loss: 4.529807090759277
training step: 23367, total_loss: 6.7024455070495605
training step: 23368, total_loss: 4.42155647277832
training step: 23369, total_loss: 3.818983316421509
training step: 23370, total_loss: 6.293329238891602
training step: 23371, total_loss: 5.373859882354736
training step: 23372, total_loss: 6.142566204071045
training step: 23373, total_loss: 3.403001070022583
training step: 23374, total_loss: 5.779146671295166
training step: 23375, total_loss: 4.751760482788086
training step: 23376, total_loss: 5.124648094177246
training step: 23377, total_loss: 5.630589962005615
training step: 23378, total_loss: 6.309240341186523
training step: 23379, total_loss: 6.481658458709717
training step: 23380, total_loss: 4.862868309020996
training step: 23381, total_loss: 4.830475807189941
training step: 23382, total_loss: 4.294687747955322
training step: 23383, total_loss: 3.447716236114502
training step: 23384, total_loss: 6.166325092315674
training step: 23385, total_loss: 3.890333890914917
training step: 23386, total_loss: 4.717649936676025
training step: 23387, total_loss: 3.830160140991211
training step: 23388, total_loss: 2.4642956256866455
training step: 23389, total_loss: 3.292079448699951
training step: 23390, total_loss: 5.247946739196777
training step: 23391, total_loss: 3.8943912982940674
training step: 23392, total_loss: 4.001590728759766
training step: 23393, total_loss: 5.068756580352783
training step: 23394, total_loss: 4.833755016326904
training step: 23395, total_loss: 4.094204425811768
training step: 23396, total_loss: 5.399054527282715
training step: 23397, total_loss: 4.432333946228027
training step: 23398, total_loss: 3.3036060333251953
training step: 23399, total_loss: 5.73538875579834
training step: 23400, total_loss: 3.2764792442321777
training step: 23401, total_loss: 3.7367055416107178
training step: 23402, total_loss: 4.602203845977783
training step: 23403, total_loss: 4.798300266265869
training step: 23404, total_loss: 4.81338357925415
training step: 23405, total_loss: 5.329960823059082
training step: 23406, total_loss: 4.4403157234191895
training step: 23407, total_loss: 3.7428081035614014
training step: 23408, total_loss: 3.962597370147705
training step: 23409, total_loss: 4.7057271003723145
training step: 23410, total_loss: 1.75016188621521
training step: 23411, total_loss: 3.410022020339966
training step: 23412, total_loss: 4.339897155761719
training step: 23413, total_loss: 3.4042699337005615
training step: 23414, total_loss: 6.47545051574707
training step: 23415, total_loss: 2.4150166511535645
training step: 23416, total_loss: 4.402843475341797
training step: 23417, total_loss: 5.380836486816406
training step: 23418, total_loss: 5.157339096069336
training step: 23419, total_loss: 5.30988883972168
training step: 23420, total_loss: 5.508180141448975
training step: 23421, total_loss: 2.6435914039611816
training step: 23422, total_loss: 3.8088550567626953
training step: 23423, total_loss: 5.148412227630615
training step: 23424, total_loss: 5.8140435218811035
training step: 23425, total_loss: 4.072283744812012
training step: 23426, total_loss: 4.550485610961914
training step: 23427, total_loss: 5.74744987487793
training step: 23428, total_loss: 5.431015491485596
training step: 23429, total_loss: 4.046082496643066
training step: 23430, total_loss: 5.467677116394043
training step: 23431, total_loss: 4.391389846801758
training step: 23432, total_loss: 4.955905914306641
training step: 23433, total_loss: 4.66897439956665
training step: 23434, total_loss: 3.308039426803589
training step: 23435, total_loss: 5.291153907775879
training step: 23436, total_loss: 5.180614471435547
training step: 23437, total_loss: 1.1364802122116089
training step: 23438, total_loss: 5.448932647705078
training step: 23439, total_loss: 3.6535086631774902
training step: 23440, total_loss: 5.278202056884766
training step: 23441, total_loss: 4.855411529541016
training step: 23442, total_loss: 4.594291687011719
training step: 23443, total_loss: 4.1158013343811035
training step: 23444, total_loss: 4.117750644683838
training step: 23445, total_loss: 5.077902793884277
training step: 23446, total_loss: 6.471555709838867
training step: 23447, total_loss: 3.0701117515563965
training step: 23448, total_loss: 6.330665111541748
training step: 23449, total_loss: 3.7193710803985596
training step: 23450, total_loss: 3.205573081970215
training step: 23451, total_loss: 4.285111427307129
training step: 23452, total_loss: 4.756471633911133
training step: 23453, total_loss: 3.532066822052002
training step: 23454, total_loss: 4.285956859588623
training step: 23455, total_loss: 2.8111205101013184
training step: 23456, total_loss: 3.022977352142334
training step: 23457, total_loss: 4.063193321228027
training step: 23458, total_loss: 5.380064964294434
training step: 23459, total_loss: 4.827429294586182
training step: 23460, total_loss: 3.5956978797912598
training step: 23461, total_loss: 5.330050945281982
training step: 23462, total_loss: 3.8917341232299805
training step: 23463, total_loss: 5.737856864929199
training step: 23464, total_loss: 4.066826820373535
training step: 23465, total_loss: 0.7865908145904541
training step: 23466, total_loss: 5.69109582901001
training step: 23467, total_loss: 2.8699846267700195
training step: 23468, total_loss: 6.079935550689697
training step: 23469, total_loss: 5.648599624633789
training step: 23470, total_loss: 3.5177855491638184
training step: 23471, total_loss: 4.886800765991211
training step: 23472, total_loss: 3.421043872833252
training step: 23473, total_loss: 4.085330486297607
training step: 23474, total_loss: 5.077947616577148
training step: 23475, total_loss: 4.888790130615234
training step: 23476, total_loss: 5.77885627746582
training step: 23477, total_loss: 3.471198558807373
training step: 23478, total_loss: 3.5995025634765625
training step: 23479, total_loss: 3.9695487022399902
training step: 23480, total_loss: 4.106578826904297
training step: 23481, total_loss: 3.5836873054504395
training step: 23482, total_loss: 4.565397262573242
training step: 23483, total_loss: 5.59391450881958
training step: 23484, total_loss: 6.02332067489624
training step: 23485, total_loss: 3.060181140899658
training step: 23486, total_loss: 4.998998641967773
training step: 23487, total_loss: 2.873351573944092
training step: 23488, total_loss: 4.035077095031738
training step: 23489, total_loss: 5.100682258605957
training step: 23490, total_loss: 3.8344340324401855
training step: 23491, total_loss: 5.43959903717041
training step: 23492, total_loss: 4.995645523071289
training step: 23493, total_loss: 3.3531951904296875
training step: 23494, total_loss: 4.705389022827148
training step: 23495, total_loss: 3.6600453853607178
training step: 23496, total_loss: 4.34343957901001
training step: 23497, total_loss: 6.310944557189941
training step: 23498, total_loss: 6.185663223266602
training step: 23499, total_loss: 4.631512641906738
training step: 23500, total_loss: 4.650675296783447
training step: 23501, total_loss: 4.107512474060059
training step: 23502, total_loss: 4.367603778839111
training step: 23503, total_loss: 6.007835388183594
training step: 23504, total_loss: 4.647791862487793
training step: 23505, total_loss: 3.5199928283691406
training step: 23506, total_loss: 4.149670600891113
training step: 23507, total_loss: 4.931527137756348
training step: 23508, total_loss: 4.224181175231934
training step: 23509, total_loss: 5.023967266082764
training step: 23510, total_loss: 0.7703050374984741
training step: 23511, total_loss: 3.176535129547119
training step: 23512, total_loss: 5.196430206298828
training step: 23513, total_loss: 2.9679384231567383
training step: 23514, total_loss: 5.559307098388672
training step: 23515, total_loss: 5.011684894561768
training step: 23516, total_loss: 4.709149360656738
training step: 23517, total_loss: 4.899791717529297
training step: 23518, total_loss: 5.893462657928467
training step: 23519, total_loss: 4.8072686195373535
training step: 23520, total_loss: 4.345148086547852
training step: 23521, total_loss: 4.068889141082764
training step: 23522, total_loss: 4.793422698974609
training step: 23523, total_loss: 4.128113746643066
training step: 23524, total_loss: 0.9995309114456177
training step: 23525, total_loss: 4.39333963394165
training step: 23526, total_loss: 5.0915207862854
training step: 23527, total_loss: 3.871936321258545
training step: 23528, total_loss: 2.837897777557373
training step: 23529, total_loss: 4.942564964294434
training step: 23530, total_loss: 4.241788864135742
training step: 23531, total_loss: 4.15623140335083
training step: 23532, total_loss: 4.945003509521484
training step: 23533, total_loss: 4.654942035675049
training step: 23534, total_loss: 3.2538301944732666
training step: 23535, total_loss: 5.568988800048828
training step: 23536, total_loss: 4.637241840362549
training step: 23537, total_loss: 4.252272129058838
training step: 23538, total_loss: 5.439065456390381
training step: 23539, total_loss: 4.7003045082092285
training step: 23540, total_loss: 4.873588562011719
training step: 23541, total_loss: 4.303572654724121
training step: 23542, total_loss: 5.253754615783691
training step: 23543, total_loss: 4.373065948486328
training step: 23544, total_loss: 3.171266794204712
training step: 23545, total_loss: 6.084787845611572
training step: 23546, total_loss: 6.461605072021484
training step: 23547, total_loss: 3.9356818199157715
training step: 23548, total_loss: 3.3370604515075684
training step: 23549, total_loss: 3.8534486293792725
training step: 23550, total_loss: 4.4313836097717285
training step: 23551, total_loss: 5.416989326477051
training step: 23552, total_loss: 3.970576286315918
training step: 23553, total_loss: 3.9570844173431396
training step: 23554, total_loss: 5.183929443359375
training step: 23555, total_loss: 3.3885421752929688
training step: 23556, total_loss: 4.9977545738220215
training step: 23557, total_loss: 4.886165618896484
training step: 23558, total_loss: 4.656720161437988
training step: 23559, total_loss: 2.555572986602783
training step: 23560, total_loss: 4.482330322265625
training step: 23561, total_loss: 3.2921500205993652
training step: 23562, total_loss: 5.262316703796387
training step: 23563, total_loss: 5.3945207595825195
training step: 23564, total_loss: 4.36644983291626
training step: 23565, total_loss: 4.514843463897705
training step: 23566, total_loss: 4.077301979064941
training step: 23567, total_loss: 4.351612091064453
training step: 23568, total_loss: 5.2863450050354
training step: 23569, total_loss: 6.448577880859375
training step: 23570, total_loss: 3.8430819511413574
training step: 23571, total_loss: 3.659677267074585
training step: 23572, total_loss: 5.121554374694824
training step: 23573, total_loss: 3.7945733070373535
training step: 23574, total_loss: 4.350569725036621
training step: 23575, total_loss: 4.44851016998291
training step: 23576, total_loss: 5.4335713386535645
training step: 23577, total_loss: 4.220221519470215
training step: 23578, total_loss: 2.5694072246551514
training step: 23579, total_loss: 3.927968978881836
training step: 23580, total_loss: 4.503849029541016
training step: 23581, total_loss: 3.7596776485443115
training step: 23582, total_loss: 4.035881042480469
training step: 23583, total_loss: 4.225556373596191
training step: 23584, total_loss: 4.049059867858887
training step: 23585, total_loss: 2.4458351135253906
training step: 23586, total_loss: 1.7836785316467285
training step: 23587, total_loss: 4.059056282043457
training step: 23588, total_loss: 3.9196066856384277
training step: 23589, total_loss: 1.2313966751098633
training step: 23590, total_loss: 4.485894203186035
training step: 23591, total_loss: 4.088197708129883
training step: 23592, total_loss: 3.6031880378723145
training step: 23593, total_loss: 4.23246431350708
training step: 23594, total_loss: 5.559837818145752
training step: 23595, total_loss: 5.167724609375
training step: 23596, total_loss: 4.3383283615112305
training step: 23597, total_loss: 2.670651435852051
training step: 23598, total_loss: 5.056330680847168
training step: 23599, total_loss: 4.483814716339111
training step: 23600, total_loss: 3.472092628479004
training step: 23601, total_loss: 3.165085792541504
training step: 23602, total_loss: 4.814142227172852
training step: 23603, total_loss: 6.076669692993164
training step: 23604, total_loss: 5.3779497146606445
training step: 23605, total_loss: 4.340519905090332
training step: 23606, total_loss: 3.909942388534546
training step: 23607, total_loss: 3.040180206298828
training step: 23608, total_loss: 5.442152976989746
training step: 23609, total_loss: 3.8830442428588867
training step: 23610, total_loss: 2.93389630317688
training step: 23611, total_loss: 4.7900710105896
training step: 23612, total_loss: 1.244676113128662
training step: 23613, total_loss: 4.805486679077148
training step: 23614, total_loss: 4.769803047180176
training step: 23615, total_loss: 4.480306625366211
training step: 23616, total_loss: 6.875389099121094
training step: 23617, total_loss: 3.0981521606445312
training step: 23618, total_loss: 2.931943893432617
training step: 23619, total_loss: 3.890298366546631
training step: 23620, total_loss: 3.851530075073242
training step: 23621, total_loss: 3.529271125793457
training step: 23622, total_loss: 2.250490188598633
training step: 23623, total_loss: 3.60084867477417
training step: 23624, total_loss: 3.8502869606018066
training step: 23625, total_loss: 4.810001373291016
training step: 23626, total_loss: 5.256155490875244
training step: 23627, total_loss: 4.674246311187744
training step: 23628, total_loss: 2.941554069519043
training step: 23629, total_loss: 4.892287254333496
training step: 23630, total_loss: 5.634639739990234
training step: 23631, total_loss: 5.5398454666137695
training step: 23632, total_loss: 6.338956832885742
training step: 23633, total_loss: 5.306796550750732
training step: 23634, total_loss: 5.32171106338501
training step: 23635, total_loss: 4.115079879760742
training step: 23636, total_loss: 6.490231513977051
training step: 23637, total_loss: 4.831620216369629
training step: 23638, total_loss: 2.3353116512298584
training step: 23639, total_loss: 6.341641902923584
training step: 23640, total_loss: 4.209924697875977
training step: 23641, total_loss: 6.698065757751465
training step: 23642, total_loss: 2.766343593597412
training step: 23643, total_loss: 4.2018256187438965
training step: 23644, total_loss: 4.869071960449219
training step: 23645, total_loss: 4.214630126953125
training step: 23646, total_loss: 3.784998893737793
training step: 23647, total_loss: 5.2785797119140625
training step: 23648, total_loss: 2.8693389892578125
training step: 23649, total_loss: 5.035579204559326
training step: 23650, total_loss: 4.697261810302734
training step: 23651, total_loss: 3.843703269958496
training step: 23652, total_loss: 4.4638776779174805
training step: 23653, total_loss: 2.9493489265441895
training step: 23654, total_loss: 5.370987892150879
training step: 23655, total_loss: 3.794086456298828
training step: 23656, total_loss: 3.3813138008117676
training step: 23657, total_loss: 5.4334306716918945
training step: 23658, total_loss: 4.389768123626709
training step: 23659, total_loss: 6.063197135925293
training step: 23660, total_loss: 3.8373093605041504
training step: 23661, total_loss: 3.5473861694335938
training step: 23662, total_loss: 4.97813606262207
training step: 23663, total_loss: 3.937098503112793
training step: 23664, total_loss: 4.137628555297852
training step: 23665, total_loss: 4.630937099456787
training step: 23666, total_loss: 6.33682918548584
training step: 23667, total_loss: 5.026223182678223
training step: 23668, total_loss: 5.061027526855469
training step: 23669, total_loss: 4.454472541809082
training step: 23670, total_loss: 4.137955665588379
training step: 23671, total_loss: 5.423205375671387
training step: 23672, total_loss: 4.255819320678711
training step: 23673, total_loss: 4.375999450683594
training step: 23674, total_loss: 4.640586853027344
training step: 23675, total_loss: 4.727991104125977
training step: 23676, total_loss: 5.328169822692871
training step: 23677, total_loss: 4.825582504272461
training step: 23678, total_loss: 5.0609540939331055
training step: 23679, total_loss: 4.448144435882568
training step: 23680, total_loss: 5.101425647735596
training step: 23681, total_loss: 1.774566888809204
training step: 23682, total_loss: 4.654147148132324
training step: 23683, total_loss: 4.856135845184326
training step: 23684, total_loss: 3.823946475982666
training step: 23685, total_loss: 5.444441318511963
training step: 23686, total_loss: 5.43804931640625
training step: 23687, total_loss: 4.654052257537842
training step: 23688, total_loss: 6.23517370223999
training step: 23689, total_loss: 4.4157395362854
training step: 23690, total_loss: 5.307182312011719
training step: 23691, total_loss: 4.775261402130127
training step: 23692, total_loss: 5.360584259033203
training step: 23693, total_loss: 6.4537200927734375
training step: 23694, total_loss: 4.869409561157227
training step: 23695, total_loss: 5.07619571685791
training step: 23696, total_loss: 5.000913619995117
training step: 23697, total_loss: 3.9023756980895996
training step: 23698, total_loss: 6.064879417419434
training step: 23699, total_loss: 5.289146423339844
training step: 23700, total_loss: 3.130629539489746
training step: 23701, total_loss: 5.435394763946533
training step: 23702, total_loss: 4.1965179443359375
training step: 23703, total_loss: 3.5415923595428467
training step: 23704, total_loss: 2.357168197631836
training step: 23705, total_loss: 5.286686897277832
training step: 23706, total_loss: 3.5873823165893555
training step: 23707, total_loss: 2.5389723777770996
training step: 23708, total_loss: 5.74365234375
training step: 23709, total_loss: 4.919651985168457
training step: 23710, total_loss: 3.1996707916259766
training step: 23711, total_loss: 1.1926249265670776
training step: 23712, total_loss: 4.250040054321289
training step: 23713, total_loss: 5.037205696105957
training step: 23714, total_loss: 4.87306547164917
training step: 23715, total_loss: 6.048257350921631
training step: 23716, total_loss: 4.179029941558838
training step: 23717, total_loss: 4.752364158630371
training step: 23718, total_loss: 3.8126931190490723
training step: 23719, total_loss: 5.106743812561035
training step: 23720, total_loss: 4.372798919677734
training step: 23721, total_loss: 4.110787391662598
training step: 23722, total_loss: 6.336855888366699
training step: 23723, total_loss: 4.943033218383789
training step: 23724, total_loss: 4.983002185821533
training step: 23725, total_loss: 3.7959868907928467
training step: 23726, total_loss: 4.268857002258301
training step: 23727, total_loss: 5.487749099731445
training step: 23728, total_loss: 4.391328811645508
training step: 23729, total_loss: 3.1356568336486816
training step: 23730, total_loss: 4.380767822265625
training step: 23731, total_loss: 2.4323883056640625
training step: 23732, total_loss: 6.570943832397461
training step: 23733, total_loss: 4.672393798828125
training step: 23734, total_loss: 5.20762825012207
training step: 23735, total_loss: 5.059103488922119
training step: 23736, total_loss: 2.4783291816711426
training step: 23737, total_loss: 4.162520408630371
training step: 23738, total_loss: 2.946315288543701
training step: 23739, total_loss: 5.4078216552734375
training step: 23740, total_loss: 4.076334476470947
training step: 23741, total_loss: 3.413625478744507
training step: 23742, total_loss: 5.636936187744141
training step: 23743, total_loss: 3.373847007751465
training step: 23744, total_loss: 4.649794578552246
training step: 23745, total_loss: 5.875800132751465
training step: 23746, total_loss: 5.661538124084473
training step: 23747, total_loss: 2.2398016452789307
training step: 23748, total_loss: 3.809072971343994
training step: 23749, total_loss: 4.448640823364258
training step: 23750, total_loss: 3.106156826019287
training step: 23751, total_loss: 4.613367080688477
training step: 23752, total_loss: 3.3167788982391357
training step: 23753, total_loss: 4.318092346191406
training step: 23754, total_loss: 3.8670549392700195
training step: 23755, total_loss: 3.240487575531006
training step: 23756, total_loss: 3.962191104888916
training step: 23757, total_loss: 4.588641166687012
training step: 23758, total_loss: 5.21068000793457
training step: 23759, total_loss: 3.926989793777466
training step: 23760, total_loss: 6.011460781097412
training step: 23761, total_loss: 5.225644111633301
training step: 23762, total_loss: 2.2442049980163574
training step: 23763, total_loss: 4.3954668045043945
training step: 23764, total_loss: 4.274361610412598
training step: 23765, total_loss: 4.596774101257324
training step: 23766, total_loss: 4.675345420837402
training step: 23767, total_loss: 0.7895712852478027
training step: 23768, total_loss: 3.7431278228759766
training step: 23769, total_loss: 3.8663127422332764
training step: 23770, total_loss: 5.033532619476318
training step: 23771, total_loss: 3.5425667762756348
training step: 23772, total_loss: 0.8906736373901367
training step: 23773, total_loss: 6.186398506164551
training step: 23774, total_loss: 4.178598403930664
training step: 23775, total_loss: 4.067562580108643
training step: 23776, total_loss: 5.383172035217285
training step: 23777, total_loss: 5.170319080352783
training step: 23778, total_loss: 4.731123924255371
training step: 23779, total_loss: 6.235093116760254
training step: 23780, total_loss: 4.029043197631836
training step: 23781, total_loss: 3.0326645374298096
training step: 23782, total_loss: 4.959162712097168
training step: 23783, total_loss: 2.786902904510498
training step: 23784, total_loss: 4.548068523406982
training step: 23785, total_loss: 1.0082731246948242
training step: 23786, total_loss: 5.857675552368164
training step: 23787, total_loss: 5.778032302856445
training step: 23788, total_loss: 3.601802349090576
training step: 23789, total_loss: 5.091393947601318
training step: 23790, total_loss: 6.704095840454102
training step: 23791, total_loss: 6.585092544555664
training step: 23792, total_loss: 5.198508262634277
training step: 23793, total_loss: 3.365133762359619
training step: 23794, total_loss: 4.384747505187988
training step: 23795, total_loss: 5.241274833679199
training step: 23796, total_loss: 2.8343396186828613
training step: 23797, total_loss: 4.6300859451293945
training step: 23798, total_loss: 6.77404260635376
training step: 23799, total_loss: 6.189291954040527
training step: 23800, total_loss: 4.566883563995361
training step: 23801, total_loss: 5.403639793395996
training step: 23802, total_loss: 4.333264350891113
training step: 23803, total_loss: 5.271233558654785
training step: 23804, total_loss: 4.589385032653809
training step: 23805, total_loss: 4.7166876792907715
training step: 23806, total_loss: 3.9733762741088867
training step: 23807, total_loss: 5.207579612731934
training step: 23808, total_loss: 5.145423889160156
training step: 23809, total_loss: 5.100584030151367
training step: 23810, total_loss: 3.050342082977295
training step: 23811, total_loss: 4.396374702453613
training step: 23812, total_loss: 4.427281856536865
training step: 23813, total_loss: 4.59092903137207
training step: 23814, total_loss: 4.2975640296936035
training step: 23815, total_loss: 3.654635190963745
training step: 23816, total_loss: 3.7235355377197266
training step: 23817, total_loss: 5.2480292320251465
training step: 23818, total_loss: 5.289213180541992
training step: 23819, total_loss: 3.153001546859741
training step: 23820, total_loss: 3.9820189476013184
training step: 23821, total_loss: 3.9245641231536865
training step: 23822, total_loss: 4.45996618270874
training step: 23823, total_loss: 4.098053932189941
training step: 23824, total_loss: 3.681302070617676
training step: 23825, total_loss: 4.719322681427002
training step: 23826, total_loss: 4.322959899902344
training step: 23827, total_loss: 3.5816290378570557
training step: 23828, total_loss: 4.25888204574585
training step: 23829, total_loss: 4.567628383636475
training step: 23830, total_loss: 4.105688095092773
training step: 23831, total_loss: 3.99428391456604
training step: 23832, total_loss: 3.114936113357544
training step: 23833, total_loss: 3.260185718536377
training step: 23834, total_loss: 3.8508386611938477
training step: 23835, total_loss: 4.274396896362305
training step: 23836, total_loss: 4.778632164001465
training step: 23837, total_loss: 4.306765556335449
training step: 23838, total_loss: 3.433462619781494
training step: 23839, total_loss: 4.406829833984375
training step: 23840, total_loss: 6.239319801330566
training step: 23841, total_loss: 4.503288269042969
training step: 23842, total_loss: 4.012147426605225
training step: 23843, total_loss: 4.516374111175537
training step: 23844, total_loss: 5.7757439613342285
training step: 23845, total_loss: 5.390000343322754
training step: 23846, total_loss: 4.299355506896973
training step: 23847, total_loss: 4.618362903594971
training step: 23848, total_loss: 7.000698089599609
training step: 23849, total_loss: 4.966616630554199
training step: 23850, total_loss: 5.6736955642700195
training step: 23851, total_loss: 2.8447935581207275
training step: 23852, total_loss: 5.210918426513672
training step: 23853, total_loss: 3.5236191749572754
training step: 23854, total_loss: 4.210758209228516
training step: 23855, total_loss: 3.9432590007781982
training step: 23856, total_loss: 4.241889953613281
training step: 23857, total_loss: 5.247682571411133
training step: 23858, total_loss: 6.413276195526123
training step: 23859, total_loss: 4.285562038421631
training step: 23860, total_loss: 4.2924299240112305
training step: 23861, total_loss: 5.1606950759887695
training step: 23862, total_loss: 4.19638204574585
training step: 23863, total_loss: 4.316128730773926
training step: 23864, total_loss: 4.1418914794921875
training step: 23865, total_loss: 5.969618797302246
training step: 23866, total_loss: 3.0352299213409424
training step: 23867, total_loss: 4.7339558601379395
training step: 23868, total_loss: 2.7069602012634277
training step: 23869, total_loss: 5.909280300140381
training step: 23870, total_loss: 4.978329658508301
training step: 23871, total_loss: 3.0018248558044434
training step: 23872, total_loss: 4.928299427032471
training step: 23873, total_loss: 3.956813335418701
training step: 23874, total_loss: 5.007758617401123
training step: 23875, total_loss: 5.2489423751831055
training step: 23876, total_loss: 4.9090166091918945
training step: 23877, total_loss: 4.779385566711426
training step: 23878, total_loss: 5.352805137634277
training step: 23879, total_loss: 4.544885635375977
training step: 23880, total_loss: 4.362377166748047
training step: 23881, total_loss: 5.625872611999512
training step: 23882, total_loss: 3.9691219329833984
training step: 23883, total_loss: 3.8920257091522217
training step: 23884, total_loss: 5.285737037658691
training step: 23885, total_loss: 4.1044816970825195
training step: 23886, total_loss: 3.707726240158081
training step: 23887, total_loss: 4.831618309020996
training step: 23888, total_loss: 4.539980888366699
training step: 23889, total_loss: 5.118175506591797
training step: 23890, total_loss: 3.919569492340088
training step: 23891, total_loss: 2.6167500019073486
training step: 23892, total_loss: 4.7014946937561035
training step: 23893, total_loss: 4.441444396972656
training step: 23894, total_loss: 4.923086643218994
training step: 23895, total_loss: 4.644306182861328
training step: 23896, total_loss: 3.8111376762390137
training step: 23897, total_loss: 4.221185207366943
training step: 23898, total_loss: 6.950046539306641
training step: 23899, total_loss: 4.727476119995117
training step: 23900, total_loss: 3.2937371730804443
training step: 23901, total_loss: 4.458722114562988
training step: 23902, total_loss: 5.861675262451172
training step: 23903, total_loss: 4.451749324798584
training step: 23904, total_loss: 3.7541351318359375
training step: 23905, total_loss: 4.704314708709717
training step: 23906, total_loss: 3.881129741668701
training step: 23907, total_loss: 3.9716148376464844
training step: 23908, total_loss: 4.440285682678223
training step: 23909, total_loss: 3.5641536712646484
training step: 23910, total_loss: 5.074371814727783
training step: 23911, total_loss: 3.7872836589813232
training step: 23912, total_loss: 4.337179660797119
training step: 23913, total_loss: 4.564540863037109
training step: 23914, total_loss: 5.464664459228516
training step: 23915, total_loss: 4.893880844116211
training step: 23916, total_loss: 3.628622531890869
training step: 23917, total_loss: 5.833664894104004
training step: 23918, total_loss: 4.637117862701416
training step: 23919, total_loss: 4.624175548553467
training step: 23920, total_loss: 4.311822414398193
training step: 23921, total_loss: 5.271611213684082
training step: 23922, total_loss: 3.7873308658599854
training step: 23923, total_loss: 4.988932132720947
training step: 23924, total_loss: 1.7147530317306519
training step: 23925, total_loss: 3.984196662902832
training step: 23926, total_loss: 4.435222625732422
training step: 23927, total_loss: 4.699156284332275
training step: 23928, total_loss: 3.983673572540283
training step: 23929, total_loss: 4.65205717086792
training step: 23930, total_loss: 5.765141010284424
training step: 23931, total_loss: 4.808432579040527
training step: 23932, total_loss: 3.559483051300049
training step: 23933, total_loss: 4.733431816101074
training step: 23934, total_loss: 4.836256980895996
training step: 23935, total_loss: 5.288783550262451
training step: 23936, total_loss: 4.845903396606445
training step: 23937, total_loss: 3.706970691680908
training step: 23938, total_loss: 4.136004447937012
training step: 23939, total_loss: 5.478050231933594
training step: 23940, total_loss: 3.539872407913208
training step: 23941, total_loss: 6.44840669631958
training step: 23942, total_loss: 4.177935600280762
training step: 23943, total_loss: 4.738858222961426
training step: 23944, total_loss: 3.2941768169403076
training step: 23945, total_loss: 4.622913837432861
training step: 23946, total_loss: 4.030735015869141
training step: 23947, total_loss: 4.652079105377197
training step: 23948, total_loss: 4.226900100708008
training step: 23949, total_loss: 5.532808303833008
training step: 23950, total_loss: 4.943655967712402
training step: 23951, total_loss: 4.249277591705322
training step: 23952, total_loss: 5.35622501373291
training step: 23953, total_loss: 1.5721594095230103
training step: 23954, total_loss: 3.7669856548309326
training step: 23955, total_loss: 2.6536922454833984
training step: 23956, total_loss: 3.6216845512390137
training step: 23957, total_loss: 5.720391750335693
training step: 23958, total_loss: 5.398730278015137
training step: 23959, total_loss: 5.77553129196167
training step: 23960, total_loss: 3.9093027114868164
training step: 23961, total_loss: 2.4965031147003174
training step: 23962, total_loss: 4.096441268920898
training step: 23963, total_loss: 6.098231315612793
training step: 23964, total_loss: 4.3650054931640625
training step: 23965, total_loss: 3.624018907546997
training step: 23966, total_loss: 4.791354179382324
training step: 23967, total_loss: 4.771916389465332
training step: 23968, total_loss: 5.364873886108398
training step: 23969, total_loss: 4.478417873382568
training step: 23970, total_loss: 4.994738578796387
training step: 23971, total_loss: 4.083555698394775
training step: 23972, total_loss: 4.963350296020508
training step: 23973, total_loss: 2.934678554534912
training step: 23974, total_loss: 3.973665237426758
training step: 23975, total_loss: 5.5466203689575195
training step: 23976, total_loss: 4.594006538391113
training step: 23977, total_loss: 4.83269739151001
training step: 23978, total_loss: 6.539419174194336
training step: 23979, total_loss: 5.34637975692749
training step: 23980, total_loss: 5.282207489013672
training step: 23981, total_loss: 3.77323055267334
training step: 23982, total_loss: 4.431238651275635
training step: 23983, total_loss: 5.162031650543213
training step: 23984, total_loss: 4.433646202087402
training step: 23985, total_loss: 4.009494781494141
training step: 23986, total_loss: 4.862065315246582
training step: 23987, total_loss: 3.6680867671966553
training step: 23988, total_loss: 2.9967782497406006
training step: 23989, total_loss: 5.1323981285095215
training step: 23990, total_loss: 5.101908206939697
training step: 23991, total_loss: 4.970675945281982
training step: 23992, total_loss: 4.6549530029296875
training step: 23993, total_loss: 4.321619510650635
training step: 23994, total_loss: 5.935631275177002
training step: 23995, total_loss: 3.5807223320007324
training step: 23996, total_loss: 5.300973892211914
training step: 23997, total_loss: 4.356015682220459
training step: 23998, total_loss: 3.562429189682007
training step: 23999, total_loss: 5.405500411987305
training step: 24000, total_loss: 2.4582772254943848
training step: 24001, total_loss: 3.8227434158325195
training step: 24002, total_loss: 4.383277893066406
training step: 24003, total_loss: 5.321737289428711
training step: 24004, total_loss: 3.320148468017578
training step: 24005, total_loss: 5.795302391052246
training step: 24006, total_loss: 6.314012050628662
training step: 24007, total_loss: 4.599557876586914
training step: 24008, total_loss: 3.5005576610565186
training step: 24009, total_loss: 6.900076389312744
training step: 24010, total_loss: 5.34664249420166
training step: 24011, total_loss: 2.74214243888855
training step: 24012, total_loss: 5.718684196472168
training step: 24013, total_loss: 5.2234625816345215
training step: 24014, total_loss: 4.580561637878418
training step: 24015, total_loss: 3.5826942920684814
training step: 24016, total_loss: 3.9358668327331543
training step: 24017, total_loss: 4.764897346496582
training step: 24018, total_loss: 5.4484758377075195
training step: 24019, total_loss: 4.918806076049805
training step: 24020, total_loss: 5.1000261306762695
training step: 24021, total_loss: 4.82612943649292
training step: 24022, total_loss: 5.247057914733887
training step: 24023, total_loss: 4.446058750152588
training step: 24024, total_loss: 5.819639205932617
training step: 24025, total_loss: 4.038547515869141
training step: 24026, total_loss: 4.176369667053223
training step: 24027, total_loss: 4.020160675048828
training step: 24028, total_loss: 4.785055160522461
training step: 24029, total_loss: 4.150193214416504
training step: 24030, total_loss: 4.371298789978027
training step: 24031, total_loss: 4.82729959487915
training step: 24032, total_loss: 4.137509346008301
training step: 24033, total_loss: 5.019234657287598
training step: 24034, total_loss: 4.927486419677734
training step: 24035, total_loss: 4.042860507965088
training step: 24036, total_loss: 5.407622337341309
training step: 24037, total_loss: 4.170444011688232
training step: 24038, total_loss: 4.94000244140625
training step: 24039, total_loss: 4.582112789154053
training step: 24040, total_loss: 4.5146660804748535
training step: 24041, total_loss: 4.668180465698242
training step: 24042, total_loss: 3.6644606590270996
training step: 24043, total_loss: 5.402073860168457
training step: 24044, total_loss: 4.464900970458984
training step: 24045, total_loss: 5.947656631469727
training step: 24046, total_loss: 5.275053977966309
training step: 24047, total_loss: 4.987851619720459
training step: 24048, total_loss: 4.2917656898498535
training step: 24049, total_loss: 3.6918997764587402
training step: 24050, total_loss: 3.3925890922546387
training step: 24051, total_loss: 4.899469375610352
training step: 24052, total_loss: 4.549022197723389
training step: 24053, total_loss: 5.1327033042907715
training step: 24054, total_loss: 4.983184814453125
training step: 24055, total_loss: 5.577967643737793
training step: 24056, total_loss: 4.1711745262146
training step: 24057, total_loss: 4.595647811889648
training step: 24058, total_loss: 3.795560836791992
training step: 24059, total_loss: 3.850205898284912
training step: 24060, total_loss: 5.217660903930664
training step: 24061, total_loss: 4.410852909088135
training step: 24062, total_loss: 4.464846134185791
training step: 24063, total_loss: 5.109659194946289
training step: 24064, total_loss: 4.6502685546875
training step: 24065, total_loss: 4.8771209716796875
training step: 24066, total_loss: 3.940749168395996
training step: 24067, total_loss: 4.745602607727051
training step: 24068, total_loss: 4.180159568786621
training step: 24069, total_loss: 4.981949329376221
training step: 24070, total_loss: 4.047996997833252
training step: 24071, total_loss: 4.053558349609375
training step: 24072, total_loss: 5.885239124298096
training step: 24073, total_loss: 3.78073787689209
training step: 24074, total_loss: 4.700387001037598
training step: 24075, total_loss: 3.853567123413086
training step: 24076, total_loss: 4.033358573913574
training step: 24077, total_loss: 5.797611236572266
training step: 24078, total_loss: 4.510232925415039
training step: 24079, total_loss: 5.213457107543945
training step: 24080, total_loss: 5.926826477050781
training step: 24081, total_loss: 4.3387322425842285
training step: 24082, total_loss: 5.89462423324585
training step: 24083, total_loss: 3.6082987785339355
training step: 24084, total_loss: 1.8827890157699585
training step: 24085, total_loss: 5.158714771270752
training step: 24086, total_loss: 5.0161027908325195
training step: 24087, total_loss: 5.989975929260254
training step: 24088, total_loss: 5.064061164855957
training step: 24089, total_loss: 1.5969316959381104
training step: 24090, total_loss: 5.2561235427856445
training step: 24091, total_loss: 4.764162063598633
training step: 24092, total_loss: 4.663421630859375
training step: 24093, total_loss: 3.1710550785064697
training step: 24094, total_loss: 4.1607866287231445
training step: 24095, total_loss: 4.41550874710083
training step: 24096, total_loss: 7.327305793762207
training step: 24097, total_loss: 2.647416830062866
training step: 24098, total_loss: 5.001655578613281
training step: 24099, total_loss: 3.941413640975952
training step: 24100, total_loss: 4.797063827514648
training step: 24101, total_loss: 3.310532569885254
training step: 24102, total_loss: 4.250972270965576
training step: 24103, total_loss: 5.79170560836792
training step: 24104, total_loss: 3.751408576965332
training step: 24105, total_loss: 5.418037414550781
training step: 24106, total_loss: 4.807651519775391
training step: 24107, total_loss: 2.983452320098877
training step: 24108, total_loss: 5.129945278167725
training step: 24109, total_loss: 4.616097927093506
training step: 24110, total_loss: 3.948218822479248
training step: 24111, total_loss: 5.945584297180176
training step: 24112, total_loss: 1.3657368421554565
training step: 24113, total_loss: 4.4889235496521
training step: 24114, total_loss: 6.418042182922363
training step: 24115, total_loss: 4.789648532867432
training step: 24116, total_loss: 4.670573711395264
training step: 24117, total_loss: 5.006065368652344
training step: 24118, total_loss: 5.089454650878906
training step: 24119, total_loss: 4.156198501586914
training step: 24120, total_loss: 4.61446475982666
training step: 24121, total_loss: 3.7779953479766846
training step: 24122, total_loss: 3.1644790172576904
training step: 24123, total_loss: 3.5881197452545166
training step: 24124, total_loss: 4.455989360809326
training step: 24125, total_loss: 4.8138322830200195
training step: 24126, total_loss: 5.658873558044434
training step: 24127, total_loss: 4.424927711486816
training step: 24128, total_loss: 5.659333229064941
training step: 24129, total_loss: 2.5733911991119385
training step: 24130, total_loss: 5.1718339920043945
training step: 24131, total_loss: 4.985713005065918
training step: 24132, total_loss: 4.659955978393555
training step: 24133, total_loss: 4.213868618011475
training step: 24134, total_loss: 4.912357330322266
training step: 24135, total_loss: 4.770864963531494
training step: 24136, total_loss: 5.10537576675415
training step: 24137, total_loss: 4.528616428375244
training step: 24138, total_loss: 4.309354782104492
training step: 24139, total_loss: 4.485291481018066
training step: 24140, total_loss: 4.864198684692383
training step: 24141, total_loss: 4.657048225402832
training step: 24142, total_loss: 4.595756530761719
training step: 24143, total_loss: 4.610139846801758
training step: 24144, total_loss: 3.545727252960205
training step: 24145, total_loss: 4.904789924621582
training step: 24146, total_loss: 3.710561752319336
training step: 24147, total_loss: 6.015987396240234
training step: 24148, total_loss: 3.216510534286499
training step: 24149, total_loss: 4.118994235992432
training step: 24150, total_loss: 4.5599470138549805
training step: 24151, total_loss: 4.734386444091797
training step: 24152, total_loss: 5.861198425292969
training step: 24153, total_loss: 4.960561752319336
training step: 24154, total_loss: 3.3246564865112305
training step: 24155, total_loss: 4.592103958129883
training step: 24156, total_loss: 4.966225624084473
training step: 24157, total_loss: 4.864814758300781
training step: 24158, total_loss: 5.580448150634766
training step: 24159, total_loss: 5.033249855041504
training step: 24160, total_loss: 5.810172080993652
training step: 24161, total_loss: 4.858245849609375
training step: 24162, total_loss: 5.477799415588379
training step: 24163, total_loss: 4.755059242248535
training step: 24164, total_loss: 1.5756194591522217
training step: 24165, total_loss: 2.447284460067749
training step: 24166, total_loss: 4.613409996032715
training step: 24167, total_loss: 5.655076026916504
training step: 24168, total_loss: 5.177523612976074
training step: 24169, total_loss: 1.2925647497177124
training step: 24170, total_loss: 4.774778842926025
training step: 24171, total_loss: 4.3894453048706055
training step: 24172, total_loss: 4.199911117553711
training step: 24173, total_loss: 4.367871284484863
training step: 24174, total_loss: 3.937910556793213
training step: 24175, total_loss: 3.875864028930664
training step: 24176, total_loss: 4.192217826843262
training step: 24177, total_loss: 4.790569305419922
training step: 24178, total_loss: 5.687457084655762
training step: 24179, total_loss: 4.829179763793945
training step: 24180, total_loss: 6.769329071044922
training step: 24181, total_loss: 4.629794120788574
training step: 24182, total_loss: 4.721507549285889
training step: 24183, total_loss: 4.889277458190918
training step: 24184, total_loss: 4.639167308807373
training step: 24185, total_loss: 3.694110870361328
training step: 24186, total_loss: 3.8899855613708496
training step: 24187, total_loss: 5.141280174255371
training step: 24188, total_loss: 3.9280505180358887
training step: 24189, total_loss: 1.4183992147445679
training step: 24190, total_loss: 3.7698373794555664
training step: 24191, total_loss: 4.518120765686035
training step: 24192, total_loss: 5.149526596069336
training step: 24193, total_loss: 4.062028408050537
training step: 24194, total_loss: 3.180083990097046
training step: 24195, total_loss: 4.7190961837768555
training step: 24196, total_loss: 5.214624404907227
training step: 24197, total_loss: 5.543623924255371
training step: 24198, total_loss: 4.509000778198242
training step: 24199, total_loss: 4.03390645980835
training step: 24200, total_loss: 6.637014389038086
training step: 24201, total_loss: 4.561898231506348
training step: 24202, total_loss: 3.5078787803649902
training step: 24203, total_loss: 4.142721652984619
training step: 24204, total_loss: 4.538820743560791
training step: 24205, total_loss: 4.905348300933838
training step: 24206, total_loss: 3.9548768997192383
training step: 24207, total_loss: 3.703310251235962
training step: 24208, total_loss: 4.1810102462768555
training step: 24209, total_loss: 4.783717155456543
training step: 24210, total_loss: 3.6531529426574707
training step: 24211, total_loss: 4.03385591506958
training step: 24212, total_loss: 4.718058109283447
training step: 24213, total_loss: 4.017120838165283
training step: 24214, total_loss: 5.0253777503967285
training step: 24215, total_loss: 4.799985885620117
training step: 24216, total_loss: 4.816034317016602
training step: 24217, total_loss: 5.53101110458374
training step: 24218, total_loss: 3.2370243072509766
training step: 24219, total_loss: 4.015758991241455
training step: 24220, total_loss: 4.403627395629883
training step: 24221, total_loss: 4.943741798400879
training step: 24222, total_loss: 3.7464466094970703
training step: 24223, total_loss: 5.165940284729004
training step: 24224, total_loss: 4.961195945739746
training step: 24225, total_loss: 3.4414548873901367
training step: 24226, total_loss: 4.869633674621582
training step: 24227, total_loss: 4.286673545837402
training step: 24228, total_loss: 5.879140853881836
training step: 24229, total_loss: 1.4118051528930664
training step: 24230, total_loss: 5.737484931945801
training step: 24231, total_loss: 3.694075345993042
training step: 24232, total_loss: 4.262255668640137
training step: 24233, total_loss: 3.1380045413970947
training step: 24234, total_loss: 1.154991865158081
training step: 24235, total_loss: 3.9733834266662598
training step: 24236, total_loss: 4.675179481506348
training step: 24237, total_loss: 4.20411491394043
training step: 24238, total_loss: 4.151008605957031
training step: 24239, total_loss: 5.010293960571289
training step: 24240, total_loss: 3.2525336742401123
training step: 24241, total_loss: 5.120114326477051
training step: 24242, total_loss: 4.8907270431518555
training step: 24243, total_loss: 3.6098084449768066
training step: 24244, total_loss: 5.173147201538086
training step: 24245, total_loss: 4.647957801818848
training step: 24246, total_loss: 5.111182689666748
training step: 24247, total_loss: 3.9717860221862793
training step: 24248, total_loss: 4.828972816467285
training step: 24249, total_loss: 3.5685195922851562
training step: 24250, total_loss: 4.900444507598877
training step: 24251, total_loss: 5.301131248474121
training step: 24252, total_loss: 4.755311012268066
training step: 24253, total_loss: 4.559425354003906
training step: 24254, total_loss: 4.869489669799805
training step: 24255, total_loss: 4.536772727966309
training step: 24256, total_loss: 5.105803489685059
training step: 24257, total_loss: 6.477830410003662
training step: 24258, total_loss: 5.677207946777344
training step: 24259, total_loss: 4.098755359649658
training step: 24260, total_loss: 5.086416244506836
training step: 24261, total_loss: 3.6285953521728516
training step: 24262, total_loss: 5.4336442947387695
training step: 24263, total_loss: 4.584944725036621
training step: 24264, total_loss: 4.554559230804443
training step: 24265, total_loss: 4.2791829109191895
training step: 24266, total_loss: 4.697286605834961
training step: 24267, total_loss: 4.864235877990723
training step: 24268, total_loss: 4.578212738037109
training step: 24269, total_loss: 4.638315200805664
training step: 24270, total_loss: 5.174505233764648
training step: 24271, total_loss: 3.902574062347412
training step: 24272, total_loss: 4.001822471618652
training step: 24273, total_loss: 4.202162265777588
training step: 24274, total_loss: 3.9847278594970703
training step: 24275, total_loss: 4.995395183563232
training step: 24276, total_loss: 4.760115623474121
training step: 24277, total_loss: 3.3725640773773193
training step: 24278, total_loss: 2.5671305656433105
training step: 24279, total_loss: 2.762619972229004
training step: 24280, total_loss: 3.600269317626953
training step: 24281, total_loss: 4.0771613121032715
training step: 24282, total_loss: 4.5199713706970215
training step: 24283, total_loss: 4.128592014312744
training step: 24284, total_loss: 4.212526798248291
training step: 24285, total_loss: 4.159111976623535
training step: 24286, total_loss: 2.6021828651428223
training step: 24287, total_loss: 4.883584022521973
training step: 24288, total_loss: 4.37839937210083
training step: 24289, total_loss: 3.7847037315368652
training step: 24290, total_loss: 4.109602928161621
training step: 24291, total_loss: 6.742323875427246
training step: 24292, total_loss: 3.850209951400757
training step: 24293, total_loss: 4.547027587890625
training step: 24294, total_loss: 5.073607444763184
training step: 24295, total_loss: 5.397817611694336
training step: 24296, total_loss: 5.537932872772217
training step: 24297, total_loss: 4.929716110229492
training step: 24298, total_loss: 4.679312705993652
training step: 24299, total_loss: 4.182403564453125
training step: 24300, total_loss: 4.624082565307617
training step: 24301, total_loss: 5.195880889892578
training step: 24302, total_loss: 5.321372985839844
training step: 24303, total_loss: 2.7534332275390625
training step: 24304, total_loss: 4.820173263549805
training step: 24305, total_loss: 3.633725881576538
training step: 24306, total_loss: 1.2353312969207764
training step: 24307, total_loss: 3.78701114654541
training step: 24308, total_loss: 5.673540115356445
training step: 24309, total_loss: 4.434362411499023
training step: 24310, total_loss: 5.702242851257324
training step: 24311, total_loss: 4.5044708251953125
training step: 24312, total_loss: 5.411624431610107
training step: 24313, total_loss: 3.6626691818237305
training step: 24314, total_loss: 5.84854793548584
training step: 24315, total_loss: 5.9495015144348145
training step: 24316, total_loss: 5.713115215301514
training step: 24317, total_loss: 5.331921577453613
training step: 24318, total_loss: 3.8014535903930664
training step: 24319, total_loss: 2.709913969039917
training step: 24320, total_loss: 5.755225658416748
training step: 24321, total_loss: 4.512537956237793
training step: 24322, total_loss: 2.884589672088623
training step: 24323, total_loss: 4.34083890914917
training step: 24324, total_loss: 4.215399265289307
training step: 24325, total_loss: 1.4790186882019043
training step: 24326, total_loss: 4.568728446960449
training step: 24327, total_loss: 5.087657928466797
training step: 24328, total_loss: 4.316532135009766
training step: 24329, total_loss: 4.328253746032715
training step: 24330, total_loss: 4.449908256530762
training step: 24331, total_loss: 5.654107093811035
training step: 24332, total_loss: 2.868624210357666
training step: 24333, total_loss: 4.258955955505371
training step: 24334, total_loss: 4.90061092376709
training step: 24335, total_loss: 5.674056529998779
training step: 24336, total_loss: 5.169748306274414
training step: 24337, total_loss: 5.444876194000244
training step: 24338, total_loss: 3.794008731842041
training step: 24339, total_loss: 6.190103054046631
training step: 24340, total_loss: 5.088652610778809
training step: 24341, total_loss: 4.068499565124512
training step: 24342, total_loss: 4.424037933349609
training step: 24343, total_loss: 5.024989128112793
training step: 24344, total_loss: 3.350177764892578
training step: 24345, total_loss: 4.914006233215332
training step: 24346, total_loss: 4.821847915649414
training step: 24347, total_loss: 4.739080905914307
training step: 24348, total_loss: 5.061869144439697
training step: 24349, total_loss: 5.1952223777771
training step: 24350, total_loss: 5.105849266052246
training step: 24351, total_loss: 3.437638759613037
training step: 24352, total_loss: 5.246951103210449
training step: 24353, total_loss: 5.358593463897705
training step: 24354, total_loss: 5.322867393493652
training step: 24355, total_loss: 5.093282222747803
training step: 24356, total_loss: 5.033973217010498
training step: 24357, total_loss: 4.974294662475586
training step: 24358, total_loss: 4.91033935546875
training step: 24359, total_loss: 3.3184680938720703
training step: 24360, total_loss: 3.891526699066162
training step: 24361, total_loss: 5.033175468444824
training step: 24362, total_loss: 4.02365255355835
training step: 24363, total_loss: 4.824192047119141
training step: 24364, total_loss: 5.654269218444824
training step: 24365, total_loss: 3.7817230224609375
training step: 24366, total_loss: 3.1992239952087402
training step: 24367, total_loss: 2.4079713821411133
training step: 24368, total_loss: 5.706703186035156
training step: 24369, total_loss: 4.5189056396484375
training step: 24370, total_loss: 4.6657209396362305
training step: 24371, total_loss: 5.15673828125
training step: 24372, total_loss: 3.4697470664978027
training step: 24373, total_loss: 4.779370307922363
training step: 24374, total_loss: 6.187213897705078
training step: 24375, total_loss: 3.324451446533203
training step: 24376, total_loss: 4.49342679977417
training step: 24377, total_loss: 3.408390760421753
training step: 24378, total_loss: 4.443294525146484
training step: 24379, total_loss: 3.8899621963500977
training step: 24380, total_loss: 4.121205806732178
training step: 24381, total_loss: 5.702947616577148
training step: 24382, total_loss: 4.693722724914551
training step: 24383, total_loss: 5.16743278503418
training step: 24384, total_loss: 4.586683750152588
training step: 24385, total_loss: 2.455443859100342
training step: 24386, total_loss: 4.49710750579834
training step: 24387, total_loss: 5.229561805725098
training step: 24388, total_loss: 3.9808144569396973
training step: 24389, total_loss: 5.677590370178223
training step: 24390, total_loss: 4.182930946350098
training step: 24391, total_loss: 5.548304080963135
training step: 24392, total_loss: 4.882318496704102
training step: 24393, total_loss: 3.6428496837615967
training step: 24394, total_loss: 4.099113464355469
training step: 24395, total_loss: 2.4599268436431885
training step: 24396, total_loss: 5.791859149932861
training step: 24397, total_loss: 4.950429916381836
training step: 24398, total_loss: 4.344642639160156
training step: 24399, total_loss: 5.957221031188965
training step: 24400, total_loss: 4.620457649230957
training step: 24401, total_loss: 4.817310810089111
training step: 24402, total_loss: 4.654252052307129
training step: 24403, total_loss: 3.311727523803711
training step: 24404, total_loss: 5.585273742675781
training step: 24405, total_loss: 4.582934856414795
training step: 24406, total_loss: 5.253155708312988
training step: 24407, total_loss: 1.1867111921310425
training step: 24408, total_loss: 4.594350337982178
training step: 24409, total_loss: 4.686454772949219
training step: 24410, total_loss: 4.410367488861084
training step: 24411, total_loss: 6.474293231964111
training step: 24412, total_loss: 4.5412726402282715
training step: 24413, total_loss: 4.627483367919922
training step: 24414, total_loss: 3.8152618408203125
training step: 24415, total_loss: 4.735437393188477
training step: 24416, total_loss: 5.162103652954102
training step: 24417, total_loss: 3.4907143115997314
training step: 24418, total_loss: 2.9883217811584473
training step: 24419, total_loss: 4.378603458404541
training step: 24420, total_loss: 6.352115631103516
training step: 24421, total_loss: 6.6041765213012695
training step: 24422, total_loss: 1.642871379852295
training step: 24423, total_loss: 4.032999038696289
training step: 24424, total_loss: 3.659609794616699
training step: 24425, total_loss: 5.642213821411133
training step: 24426, total_loss: 4.138993263244629
training step: 24427, total_loss: 4.8060150146484375
training step: 24428, total_loss: 4.308503150939941
training step: 24429, total_loss: 4.459073543548584
training step: 24430, total_loss: 2.9703619480133057
training step: 24431, total_loss: 3.795991897583008
training step: 24432, total_loss: 4.689879417419434
training step: 24433, total_loss: 4.029515743255615
training step: 24434, total_loss: 4.157708168029785
training step: 24435, total_loss: 4.619035720825195
training step: 24436, total_loss: 6.24112606048584
training step: 24437, total_loss: 3.4755260944366455
training step: 24438, total_loss: 5.092920780181885
training step: 24439, total_loss: 5.226197719573975
training step: 24440, total_loss: 4.880149841308594
training step: 24441, total_loss: 2.520637035369873
training step: 24442, total_loss: 4.096341133117676
training step: 24443, total_loss: 5.841253280639648
training step: 24444, total_loss: 4.994318008422852
training step: 24445, total_loss: 5.403772354125977
training step: 24446, total_loss: 4.537888050079346
training step: 24447, total_loss: 5.886716365814209
training step: 24448, total_loss: 4.065117835998535
training step: 24449, total_loss: 4.6346025466918945
training step: 24450, total_loss: 4.323117256164551
training step: 24451, total_loss: 5.338597297668457
training step: 24452, total_loss: 5.0428056716918945
training step: 24453, total_loss: 5.119047164916992
training step: 24454, total_loss: 4.690736770629883
training step: 24455, total_loss: 3.7830007076263428
training step: 24456, total_loss: 4.04530143737793
training step: 24457, total_loss: 4.03666877746582
training step: 24458, total_loss: 5.536874771118164
training step: 24459, total_loss: 3.9384512901306152
training step: 24460, total_loss: 4.866405487060547
training step: 24461, total_loss: 4.994204521179199
training step: 24462, total_loss: 4.4905781745910645
training step: 24463, total_loss: 6.167134761810303
training step: 24464, total_loss: 5.267752170562744
training step: 24465, total_loss: 3.3350741863250732
training step: 24466, total_loss: 5.679686546325684
training step: 24467, total_loss: 4.241917610168457
training step: 24468, total_loss: 3.4057750701904297
training step: 24469, total_loss: 3.6446707248687744
training step: 24470, total_loss: 4.032175064086914
training step: 24471, total_loss: 3.915031909942627
training step: 24472, total_loss: 3.117495536804199
training step: 24473, total_loss: 4.626852989196777
training step: 24474, total_loss: 5.878757476806641
training step: 24475, total_loss: 4.480262279510498
training step: 24476, total_loss: 3.8433563709259033
training step: 24477, total_loss: 5.058403015136719
training step: 24478, total_loss: 5.987847328186035
training step: 24479, total_loss: 4.495677947998047
training step: 24480, total_loss: 4.944744110107422
training step: 24481, total_loss: 5.3030548095703125
training step: 24482, total_loss: 4.807794570922852
training step: 24483, total_loss: 5.224652290344238
training step: 24484, total_loss: 6.19395637512207
training step: 24485, total_loss: 3.580246925354004
training step: 24486, total_loss: 4.508430480957031
training step: 24487, total_loss: 3.599097728729248
training step: 24488, total_loss: 5.3394389152526855
training step: 24489, total_loss: 3.888993501663208
training step: 24490, total_loss: 5.163949012756348
training step: 24491, total_loss: 5.939023017883301
training step: 24492, total_loss: 4.501828193664551
training step: 24493, total_loss: 4.454740524291992
training step: 24494, total_loss: 3.4007201194763184
training step: 24495, total_loss: 6.7012739181518555
training step: 24496, total_loss: 1.4465163946151733
training step: 24497, total_loss: 6.461103439331055
training step: 24498, total_loss: 4.18772029876709
training step: 24499, total_loss: 6.298915863037109
training step: 24500, total_loss: 4.977558135986328
training step: 24501, total_loss: 3.2740941047668457
training step: 24502, total_loss: 4.8647637367248535
training step: 24503, total_loss: 5.62574577331543
training step: 24504, total_loss: 4.745616436004639
training step: 24505, total_loss: 5.442426681518555
training step: 24506, total_loss: 2.9414758682250977
training step: 24507, total_loss: 3.775343894958496
training step: 24508, total_loss: 4.362313270568848
training step: 24509, total_loss: 5.677218437194824
training step: 24510, total_loss: 6.498628616333008
training step: 24511, total_loss: 3.829939126968384
training step: 24512, total_loss: 2.843273639678955
training step: 24513, total_loss: 3.4046738147735596
training step: 24514, total_loss: 5.206538200378418
training step: 24515, total_loss: 4.439346790313721
training step: 24516, total_loss: 5.66099739074707
training step: 24517, total_loss: 5.117186546325684
training step: 24518, total_loss: 5.570112705230713
training step: 24519, total_loss: 4.927498817443848
training step: 24520, total_loss: 3.3705387115478516
training step: 24521, total_loss: 5.209771633148193
training step: 24522, total_loss: 4.924949645996094
training step: 24523, total_loss: 2.965623378753662
training step: 24524, total_loss: 6.043099880218506
training step: 24525, total_loss: 6.112309455871582
training step: 24526, total_loss: 3.349964141845703
training step: 24527, total_loss: 3.892221689224243
training step: 24528, total_loss: 3.3743929862976074
training step: 24529, total_loss: 5.421287536621094
training step: 24530, total_loss: 5.328691482543945
training step: 24531, total_loss: 4.003730773925781
training step: 24532, total_loss: 4.310695648193359
training step: 24533, total_loss: 3.645669937133789
training step: 24534, total_loss: 5.016449451446533
training step: 24535, total_loss: 3.5961148738861084
training step: 24536, total_loss: 4.788995742797852
training step: 24537, total_loss: 3.549330711364746
training step: 24538, total_loss: 6.1070990562438965
training step: 24539, total_loss: 4.154260635375977
training step: 24540, total_loss: 4.640860557556152
training step: 24541, total_loss: 5.194739818572998
training step: 24542, total_loss: 6.203329086303711
training step: 24543, total_loss: 5.07259464263916
training step: 24544, total_loss: 3.6119070053100586
training step: 24545, total_loss: 5.70122766494751
training step: 24546, total_loss: 4.3364362716674805
training step: 24547, total_loss: 4.16813325881958
training step: 24548, total_loss: 4.6934709548950195
training step: 24549, total_loss: 4.081321716308594
training step: 24550, total_loss: 4.321282863616943
training step: 24551, total_loss: 4.442299842834473
training step: 24552, total_loss: 2.7351608276367188
training step: 24553, total_loss: 5.036098003387451
training step: 24554, total_loss: 6.069109916687012
training step: 24555, total_loss: 5.572171211242676
training step: 24556, total_loss: 5.003869533538818
training step: 24557, total_loss: 4.314219951629639
training step: 24558, total_loss: 4.731978893280029
training step: 24559, total_loss: 5.48854923248291
training step: 24560, total_loss: 4.415780067443848
training step: 24561, total_loss: 5.276255130767822
training step: 24562, total_loss: 4.87074613571167
training step: 24563, total_loss: 2.4663496017456055
training step: 24564, total_loss: 4.534573554992676
training step: 24565, total_loss: 4.3707804679870605
training step: 24566, total_loss: 4.271786689758301
training step: 24567, total_loss: 3.45208740234375
training step: 24568, total_loss: 5.386440277099609
training step: 24569, total_loss: 4.638311386108398
training step: 24570, total_loss: 4.8608574867248535
training step: 24571, total_loss: 3.6361424922943115
training step: 24572, total_loss: 5.766180038452148
training step: 24573, total_loss: 5.060027122497559
training step: 24574, total_loss: 3.6912078857421875
training step: 24575, total_loss: 4.2473039627075195
training step: 24576, total_loss: 5.888139724731445
training step: 24577, total_loss: 3.316166639328003
training step: 24578, total_loss: 2.684058666229248
training step: 24579, total_loss: 4.094544410705566
training step: 24580, total_loss: 3.971529483795166
training step: 24581, total_loss: 5.079464912414551
training step: 24582, total_loss: 4.403792381286621
training step: 24583, total_loss: 5.1748175621032715
training step: 24584, total_loss: 5.525247573852539
training step: 24585, total_loss: 5.610935211181641
training step: 24586, total_loss: 4.315462112426758
training step: 24587, total_loss: 4.811916351318359
training step: 24588, total_loss: 4.873545169830322
training step: 24589, total_loss: 5.745314598083496
training step: 24590, total_loss: 4.827919960021973
training step: 24591, total_loss: 7.0483880043029785
training step: 24592, total_loss: 5.081432819366455
training step: 24593, total_loss: 2.7690834999084473
training step: 24594, total_loss: 4.589755058288574
training step: 24595, total_loss: 4.712989807128906
training step: 24596, total_loss: 4.611906051635742
training step: 24597, total_loss: 4.108622074127197
training step: 24598, total_loss: 3.0153446197509766
training step: 24599, total_loss: 2.919106960296631
training step: 24600, total_loss: 4.52055549621582
training step: 24601, total_loss: 4.181125640869141
training step: 24602, total_loss: 4.524930477142334
training step: 24603, total_loss: 3.584355354309082
training step: 24604, total_loss: 4.234792232513428
training step: 24605, total_loss: 4.8260393142700195
training step: 24606, total_loss: 3.7220826148986816
training step: 24607, total_loss: 1.390791416168213
training step: 24608, total_loss: 6.019124507904053
training step: 24609, total_loss: 4.993059158325195
training step: 24610, total_loss: 5.735164642333984
training step: 24611, total_loss: 4.592457294464111
training step: 24612, total_loss: 5.069665908813477
training step: 24613, total_loss: 4.2607269287109375
training step: 24614, total_loss: 3.740100145339966
training step: 24615, total_loss: 4.426024913787842
training step: 24616, total_loss: 4.761695861816406
training step: 24617, total_loss: 4.11749792098999
training step: 24618, total_loss: 4.085025787353516
training step: 24619, total_loss: 4.121883392333984
training step: 24620, total_loss: 4.988701820373535
training step: 24621, total_loss: 1.27968168258667
training step: 24622, total_loss: 5.831997871398926
training step: 24623, total_loss: 3.667835235595703
training step: 24624, total_loss: 3.6562304496765137
training step: 24625, total_loss: 5.122831344604492
training step: 24626, total_loss: 5.7114386558532715
training step: 24627, total_loss: 3.9498002529144287
training step: 24628, total_loss: 5.218539237976074
training step: 24629, total_loss: 5.190677642822266
training step: 24630, total_loss: 4.287191390991211
training step: 24631, total_loss: 4.697638511657715
training step: 24632, total_loss: 5.387134075164795
training step: 24633, total_loss: 5.583063125610352
training step: 24634, total_loss: 4.349921226501465
training step: 24635, total_loss: 4.6743927001953125
training step: 24636, total_loss: 4.036415100097656
training step: 24637, total_loss: 5.629240989685059
training step: 24638, total_loss: 5.4384918212890625
training step: 24639, total_loss: 4.015375137329102
training step: 24640, total_loss: 4.5404157638549805
training step: 24641, total_loss: 4.368330001831055
training step: 24642, total_loss: 4.988725662231445
training step: 24643, total_loss: 3.2210168838500977
training step: 24644, total_loss: 4.657666206359863
training step: 24645, total_loss: 4.969944953918457
training step: 24646, total_loss: 5.693674087524414
training step: 24647, total_loss: 2.3650708198547363
training step: 24648, total_loss: 5.337030410766602
training step: 24649, total_loss: 4.1455769538879395
training step: 24650, total_loss: 4.445644855499268
training step: 24651, total_loss: 4.486353397369385
training step: 24652, total_loss: 2.7140188217163086
training step: 24653, total_loss: 4.854435920715332
training step: 24654, total_loss: 6.461750507354736
training step: 24655, total_loss: 4.636282920837402
training step: 24656, total_loss: 4.494257926940918
training step: 24657, total_loss: 4.435169219970703
training step: 24658, total_loss: 5.42922306060791
training step: 24659, total_loss: 2.951380491256714
training step: 24660, total_loss: 4.134490966796875
training step: 24661, total_loss: 6.281834125518799
training step: 24662, total_loss: 5.5041303634643555
training step: 24663, total_loss: 3.817629098892212
training step: 24664, total_loss: 1.37167489528656
training step: 24665, total_loss: 4.901371002197266
training step: 24666, total_loss: 3.8314619064331055
training step: 24667, total_loss: 4.38073205947876
training step: 24668, total_loss: 4.31511116027832
training step: 24669, total_loss: 5.792102813720703
training step: 24670, total_loss: 4.8832244873046875
training step: 24671, total_loss: 4.207759380340576
training step: 24672, total_loss: 3.939457893371582
training step: 24673, total_loss: 4.778952598571777
training step: 24674, total_loss: 4.538321495056152
training step: 24675, total_loss: 2.1585116386413574
training step: 24676, total_loss: 4.023375511169434
training step: 24677, total_loss: 4.233672142028809
training step: 24678, total_loss: 3.6330018043518066
training step: 24679, total_loss: 5.164219379425049
training step: 24680, total_loss: 5.4255051612854
training step: 24681, total_loss: 4.733608245849609
training step: 24682, total_loss: 2.9778618812561035
training step: 24683, total_loss: 3.9888134002685547
training step: 24684, total_loss: 4.087102890014648
training step: 24685, total_loss: 4.4522929191589355
training step: 24686, total_loss: 4.245128631591797
training step: 24687, total_loss: 5.284386157989502
training step: 24688, total_loss: 4.079209327697754
training step: 24689, total_loss: 5.047423839569092
training step: 24690, total_loss: 5.073105335235596
training step: 24691, total_loss: 1.283778429031372
training step: 24692, total_loss: 4.194676399230957
training step: 24693, total_loss: 1.578598976135254
training step: 24694, total_loss: 2.052084445953369
training step: 24695, total_loss: 4.830761909484863
training step: 24696, total_loss: 4.046059608459473
training step: 24697, total_loss: 3.637082576751709
training step: 24698, total_loss: 4.879590034484863
training step: 24699, total_loss: 2.238981246948242
training step: 24700, total_loss: 4.781355857849121
training step: 24701, total_loss: 4.396808624267578
training step: 24702, total_loss: 5.038596153259277
training step: 24703, total_loss: 5.660557746887207
training step: 24704, total_loss: 5.066957950592041
training step: 24705, total_loss: 3.2265400886535645
training step: 24706, total_loss: 1.8431248664855957
training step: 24707, total_loss: 4.949173927307129
training step: 24708, total_loss: 4.9210920333862305
training step: 24709, total_loss: 5.054927825927734
training step: 24710, total_loss: 4.234209060668945
training step: 24711, total_loss: 5.060710906982422
training step: 24712, total_loss: 4.508291244506836
training step: 24713, total_loss: 4.305578231811523
training step: 24714, total_loss: 3.744370937347412
training step: 24715, total_loss: 3.5975942611694336
training step: 24716, total_loss: 3.2650856971740723
training step: 24717, total_loss: 4.638477325439453
training step: 24718, total_loss: 3.191617965698242
training step: 24719, total_loss: 2.429116725921631
training step: 24720, total_loss: 5.393497467041016
training step: 24721, total_loss: 4.354197978973389
training step: 24722, total_loss: 3.288961410522461
training step: 24723, total_loss: 2.3218841552734375
training step: 24724, total_loss: 3.3983020782470703
training step: 24725, total_loss: 2.2376720905303955
training step: 24726, total_loss: 4.102060794830322
training step: 24727, total_loss: 3.5786356925964355
training step: 24728, total_loss: 6.549555778503418
training step: 24729, total_loss: 5.603555679321289
training step: 24730, total_loss: 5.583205223083496
training step: 24731, total_loss: 4.55122184753418
training step: 24732, total_loss: 4.721670627593994
training step: 24733, total_loss: 3.6612837314605713
training step: 24734, total_loss: 3.587775707244873
training step: 24735, total_loss: 3.2978062629699707
training step: 24736, total_loss: 5.550070762634277
training step: 24737, total_loss: 4.4460062980651855
training step: 24738, total_loss: 3.9246461391448975
training step: 24739, total_loss: 5.065124034881592
training step: 24740, total_loss: 4.349181175231934
training step: 24741, total_loss: 2.2410471439361572
training step: 24742, total_loss: 3.5637879371643066
training step: 24743, total_loss: 5.486464023590088
training step: 24744, total_loss: 6.899824142456055
training step: 24745, total_loss: 6.769426345825195
training step: 24746, total_loss: 4.188593864440918
training step: 24747, total_loss: 4.196229457855225
training step: 24748, total_loss: 3.127814769744873
training step: 24749, total_loss: 2.8875889778137207
training step: 24750, total_loss: 4.708016395568848
training step: 24751, total_loss: 4.9094929695129395
training step: 24752, total_loss: 2.3624730110168457
training step: 24753, total_loss: 3.7747933864593506
training step: 24754, total_loss: 4.827569484710693
training step: 24755, total_loss: 2.5379419326782227
training step: 24756, total_loss: 4.279305458068848
training step: 24757, total_loss: 5.1764702796936035
training step: 24758, total_loss: 5.150670051574707
training step: 24759, total_loss: 4.413771629333496
training step: 24760, total_loss: 3.737640380859375
training step: 24761, total_loss: 5.855781078338623
training step: 24762, total_loss: 3.5500073432922363
training step: 24763, total_loss: 6.0454559326171875
training step: 24764, total_loss: 4.251266956329346
training step: 24765, total_loss: 5.535719871520996
training step: 24766, total_loss: 4.064780235290527
training step: 24767, total_loss: 4.606108665466309
training step: 24768, total_loss: 4.905594825744629
training step: 24769, total_loss: 1.0037461519241333
training step: 24770, total_loss: 3.6523680686950684
training step: 24771, total_loss: 4.198583126068115
training step: 24772, total_loss: 3.5383238792419434
training step: 24773, total_loss: 3.7610459327697754
training step: 24774, total_loss: 5.038125038146973
training step: 24775, total_loss: 4.934268951416016
training step: 24776, total_loss: 4.00110387802124
training step: 24777, total_loss: 4.013003349304199
training step: 24778, total_loss: 5.148718357086182
training step: 24779, total_loss: 1.562579870223999
training step: 24780, total_loss: 5.69344425201416
training step: 24781, total_loss: 4.934747695922852
training step: 24782, total_loss: 4.292602062225342
training step: 24783, total_loss: 4.48765754699707
training step: 24784, total_loss: 4.287553787231445
training step: 24785, total_loss: 4.959044456481934
training step: 24786, total_loss: 3.4006659984588623
training step: 24787, total_loss: 4.94006872177124
training step: 24788, total_loss: 7.5616774559021
training step: 24789, total_loss: 4.599096298217773
training step: 24790, total_loss: 3.897411584854126
training step: 24791, total_loss: 4.27067756652832
training step: 24792, total_loss: 3.3357298374176025
training step: 24793, total_loss: 4.7715888023376465
training step: 24794, total_loss: 5.098000526428223
training step: 24795, total_loss: 3.8360776901245117
training step: 24796, total_loss: 5.064377784729004
training step: 24797, total_loss: 4.638556003570557
training step: 24798, total_loss: 3.780019760131836
training step: 24799, total_loss: 3.0558979511260986
training step: 24800, total_loss: 4.9982733726501465
training step: 24801, total_loss: 3.9131288528442383
training step: 24802, total_loss: 3.3543097972869873
training step: 24803, total_loss: 3.9235832691192627
training step: 24804, total_loss: 7.090003967285156
training step: 24805, total_loss: 2.322202444076538
training step: 24806, total_loss: 5.119771957397461
training step: 24807, total_loss: 3.9661166667938232
training step: 24808, total_loss: 3.382474422454834
training step: 24809, total_loss: 5.516735553741455
training step: 24810, total_loss: 3.8218917846679688
training step: 24811, total_loss: 6.022523403167725
training step: 24812, total_loss: 3.3165297508239746
training step: 24813, total_loss: 3.355696678161621
training step: 24814, total_loss: 4.7547688484191895
training step: 24815, total_loss: 3.359269142150879
training step: 24816, total_loss: 3.4482288360595703
training step: 24817, total_loss: 3.9004220962524414
training step: 24818, total_loss: 4.579834461212158
training step: 24819, total_loss: 4.912076950073242
training step: 24820, total_loss: 3.361616849899292
training step: 24821, total_loss: 3.864046096801758
training step: 24822, total_loss: 4.08806037902832
training step: 24823, total_loss: 5.311280250549316
training step: 24824, total_loss: 4.105249881744385
training step: 24825, total_loss: 5.091554641723633
training step: 24826, total_loss: 3.983128547668457
training step: 24827, total_loss: 4.642109394073486
training step: 24828, total_loss: 3.6951372623443604
training step: 24829, total_loss: 3.693423271179199
training step: 24830, total_loss: 5.309130668640137
training step: 24831, total_loss: 3.0609707832336426
training step: 24832, total_loss: 4.748194694519043
training step: 24833, total_loss: 5.244670867919922
training step: 24834, total_loss: 4.394647121429443
training step: 24835, total_loss: 5.049429893493652
training step: 24836, total_loss: 4.547283172607422
training step: 24837, total_loss: 5.279521942138672
training step: 24838, total_loss: 3.499149799346924
training step: 24839, total_loss: 3.2588610649108887
training step: 24840, total_loss: 6.122677803039551
training step: 24841, total_loss: 4.082716941833496
training step: 24842, total_loss: 3.684140682220459
training step: 24843, total_loss: 3.9802513122558594
training step: 24844, total_loss: 4.412476539611816
training step: 24845, total_loss: 4.688072204589844
training step: 24846, total_loss: 4.802373886108398
training step: 24847, total_loss: 4.087421417236328
training step: 24848, total_loss: 2.085016965866089
training step: 24849, total_loss: 5.886069297790527
training step: 24850, total_loss: 4.722580432891846
training step: 24851, total_loss: 4.875426769256592
training step: 24852, total_loss: 3.704282522201538
training step: 24853, total_loss: 2.4527342319488525
training step: 24854, total_loss: 5.78145694732666
training step: 24855, total_loss: 4.556652069091797
training step: 24856, total_loss: 4.358315467834473
training step: 24857, total_loss: 3.8150737285614014
training step: 24858, total_loss: 3.710533618927002
training step: 24859, total_loss: 4.846907615661621
training step: 24860, total_loss: 3.927733898162842
training step: 24861, total_loss: 5.19195556640625
training step: 24862, total_loss: 5.077962875366211
training step: 24863, total_loss: 3.876772880554199
training step: 24864, total_loss: 4.8496904373168945
training step: 24865, total_loss: 3.5444884300231934
training step: 24866, total_loss: 5.15375280380249
training step: 24867, total_loss: 6.378876686096191
training step: 24868, total_loss: 5.093732833862305
training step: 24869, total_loss: 3.7072699069976807
training step: 24870, total_loss: 4.934242248535156
training step: 24871, total_loss: 4.24444580078125
training step: 24872, total_loss: 1.3480253219604492
training step: 24873, total_loss: 4.918042182922363
training step: 24874, total_loss: 5.046904563903809
training step: 24875, total_loss: 3.6296563148498535
training step: 24876, total_loss: 4.6842145919799805
training step: 24877, total_loss: 5.095449447631836
training step: 24878, total_loss: 6.421574592590332
training step: 24879, total_loss: 4.345602989196777
training step: 24880, total_loss: 4.418242454528809
training step: 24881, total_loss: 2.832831382751465
training step: 24882, total_loss: 3.555861234664917
training step: 24883, total_loss: 5.202291965484619
training step: 24884, total_loss: 3.1808884143829346
training step: 24885, total_loss: 5.408742904663086
training step: 24886, total_loss: 5.351808547973633
training step: 24887, total_loss: 3.6794512271881104
training step: 24888, total_loss: 5.167939186096191
training step: 24889, total_loss: 3.5815157890319824
training step: 24890, total_loss: 5.292125701904297
training step: 24891, total_loss: 4.843340873718262
training step: 24892, total_loss: 3.8878872394561768
training step: 24893, total_loss: 4.579373359680176
training step: 24894, total_loss: 4.598851203918457
training step: 24895, total_loss: 4.412154197692871
training step: 24896, total_loss: 5.434320449829102
training step: 24897, total_loss: 2.3086366653442383
training step: 24898, total_loss: 4.186256408691406
training step: 24899, total_loss: 4.153566837310791
training step: 24900, total_loss: 3.733675241470337
training step: 24901, total_loss: 4.239290237426758
training step: 24902, total_loss: 5.002895355224609
training step: 24903, total_loss: 4.164031982421875
training step: 24904, total_loss: 3.424828052520752
training step: 24905, total_loss: 4.326905250549316
training step: 24906, total_loss: 5.639444828033447
training step: 24907, total_loss: 4.671541213989258
training step: 24908, total_loss: 3.414607524871826
training step: 24909, total_loss: 4.010561466217041
training step: 24910, total_loss: 2.504093647003174
training step: 24911, total_loss: 5.668794631958008
training step: 24912, total_loss: 2.6938958168029785
training step: 24913, total_loss: 4.58399772644043
training step: 24914, total_loss: 4.228084564208984
training step: 24915, total_loss: 2.696176528930664
training step: 24916, total_loss: 7.031400680541992
training step: 24917, total_loss: 3.816469192504883
training step: 24918, total_loss: 4.91152286529541
training step: 24919, total_loss: 3.9997000694274902
training step: 24920, total_loss: 4.319989204406738
training step: 24921, total_loss: 3.233309745788574
training step: 24922, total_loss: 5.219505310058594
training step: 24923, total_loss: 5.432868957519531
training step: 24924, total_loss: 3.151559591293335
training step: 24925, total_loss: 5.635756492614746
training step: 24926, total_loss: 4.3613433837890625
training step: 24927, total_loss: 3.981400489807129
training step: 24928, total_loss: 2.9900259971618652
training step: 24929, total_loss: 3.6349539756774902
training step: 24930, total_loss: 3.929260015487671
training step: 24931, total_loss: 5.309284210205078
training step: 24932, total_loss: 4.611666679382324
training step: 24933, total_loss: 3.8455188274383545
training step: 24934, total_loss: 5.0672197341918945
training step: 24935, total_loss: 1.2316498756408691
training step: 24936, total_loss: 7.36470890045166
training step: 24937, total_loss: 5.877504348754883
training step: 24938, total_loss: 5.340744495391846
training step: 24939, total_loss: 4.222672939300537
training step: 24940, total_loss: 6.882745742797852
training step: 24941, total_loss: 3.033724308013916
training step: 24942, total_loss: 3.578632354736328
training step: 24943, total_loss: 4.574840545654297
training step: 24944, total_loss: 5.376862525939941
training step: 24945, total_loss: 3.596395492553711
training step: 24946, total_loss: 3.3686318397521973
training step: 24947, total_loss: 3.9735875129699707
training step: 24948, total_loss: 5.473337173461914
training step: 24949, total_loss: 0.9675387144088745
training step: 24950, total_loss: 4.823403358459473
training step: 24951, total_loss: 3.7984490394592285
training step: 24952, total_loss: 5.418413162231445
training step: 24953, total_loss: 5.381011009216309
training step: 24954, total_loss: 4.150181770324707
training step: 24955, total_loss: 2.0058183670043945
training step: 24956, total_loss: 6.088104248046875
training step: 24957, total_loss: 4.732253551483154
training step: 24958, total_loss: 3.2122364044189453
training step: 24959, total_loss: 3.657545566558838
training step: 24960, total_loss: 5.2089738845825195
training step: 24961, total_loss: 3.2533938884735107
training step: 24962, total_loss: 4.175433158874512
training step: 24963, total_loss: 4.896328449249268
training step: 24964, total_loss: 4.414371013641357
training step: 24965, total_loss: 4.74495792388916
training step: 24966, total_loss: 5.028335094451904
training step: 24967, total_loss: 4.194103717803955
training step: 24968, total_loss: 4.291934967041016
training step: 24969, total_loss: 4.816790580749512
training step: 24970, total_loss: 1.084890604019165
training step: 24971, total_loss: 3.4296436309814453
training step: 24972, total_loss: 6.13192892074585
training step: 24973, total_loss: 4.9559006690979
training step: 24974, total_loss: 4.705000877380371
training step: 24975, total_loss: 4.179529190063477
training step: 24976, total_loss: 5.734625816345215
training step: 24977, total_loss: 4.573655605316162
training step: 24978, total_loss: 5.657540321350098
training step: 24979, total_loss: 4.651252746582031
training step: 24980, total_loss: 2.845740556716919
training step: 24981, total_loss: 5.183450222015381
training step: 24982, total_loss: 5.456171035766602
training step: 24983, total_loss: 3.681015729904175
training step: 24984, total_loss: 2.468508243560791
training step: 24985, total_loss: 4.2994160652160645
training step: 24986, total_loss: 4.060150146484375
training step: 24987, total_loss: 3.277162551879883
training step: 24988, total_loss: 4.649753093719482
training step: 24989, total_loss: 5.930455207824707
training step: 24990, total_loss: 2.6228456497192383
training step: 24991, total_loss: 4.061936378479004
training step: 24992, total_loss: 3.5793261528015137
training step: 24993, total_loss: 4.164280891418457
training step: 24994, total_loss: 3.6300883293151855
training step: 24995, total_loss: 2.9561004638671875
training step: 24996, total_loss: 3.8999884128570557
training step: 24997, total_loss: 4.065647125244141
training step: 24998, total_loss: 4.520952224731445
training step: 24999, total_loss: 4.658115863800049
training step: 25000, total_loss: 5.229037284851074
training step: 25001, total_loss: 5.456732749938965
training step: 25002, total_loss: 5.309662342071533
training step: 25003, total_loss: 3.2079877853393555
training step: 25004, total_loss: 5.529052257537842
training step: 25005, total_loss: 2.8533639907836914
training step: 25006, total_loss: 4.791191101074219
training step: 25007, total_loss: 6.68674373626709
training step: 25008, total_loss: 3.9826927185058594
training step: 25009, total_loss: 5.9937639236450195
training step: 25010, total_loss: 1.1146042346954346
training step: 25011, total_loss: 7.216333389282227
training step: 25012, total_loss: 6.12110710144043
training step: 25013, total_loss: 3.786677360534668
training step: 25014, total_loss: 3.545109748840332
training step: 25015, total_loss: 3.049731969833374
training step: 25016, total_loss: 3.6820406913757324
training step: 25017, total_loss: 4.620348930358887
training step: 25018, total_loss: 4.368419170379639
training step: 25019, total_loss: 4.447800159454346
training step: 25020, total_loss: 4.316310882568359
training step: 25021, total_loss: 3.6192808151245117
training step: 25022, total_loss: 5.175167083740234
training step: 25023, total_loss: 4.013930320739746
training step: 25024, total_loss: 4.091263771057129
training step: 25025, total_loss: 4.672793388366699
training step: 25026, total_loss: 3.7620275020599365
training step: 25027, total_loss: 1.0263261795043945
training step: 25028, total_loss: 3.152703285217285
training step: 25029, total_loss: 2.3341474533081055
training step: 25030, total_loss: 3.7660131454467773
training step: 25031, total_loss: 3.371828556060791
training step: 25032, total_loss: 4.705924034118652
training step: 25033, total_loss: 4.851345062255859
training step: 25034, total_loss: 4.69243860244751
training step: 25035, total_loss: 4.821516990661621
training step: 25036, total_loss: 5.392560005187988
training step: 25037, total_loss: 4.538366317749023
training step: 25038, total_loss: 2.894021511077881
training step: 25039, total_loss: 3.6541929244995117
training step: 25040, total_loss: 4.074159145355225
training step: 25041, total_loss: 5.010008811950684
training step: 25042, total_loss: 3.4832534790039062
training step: 25043, total_loss: 5.639037132263184
training step: 25044, total_loss: 4.729705810546875
training step: 25045, total_loss: 6.239326477050781
training step: 25046, total_loss: 4.906981468200684
training step: 25047, total_loss: 5.135737895965576
training step: 25048, total_loss: 5.317047119140625
training step: 25049, total_loss: 4.410199165344238
training step: 25050, total_loss: 0.8064115047454834
training step: 25051, total_loss: 5.50563907623291
training step: 25052, total_loss: 4.956641674041748
training step: 25053, total_loss: 4.241326808929443
training step: 25054, total_loss: 5.660038948059082
training step: 25055, total_loss: 7.8675384521484375
training step: 25056, total_loss: 3.607057571411133
training step: 25057, total_loss: 3.4408411979675293
training step: 25058, total_loss: 4.079490661621094
training step: 25059, total_loss: 5.991936683654785
training step: 25060, total_loss: 5.004431247711182
training step: 25061, total_loss: 5.444552898406982
training step: 25062, total_loss: 4.6099371910095215
training step: 25063, total_loss: 3.5791382789611816
training step: 25064, total_loss: 3.3882460594177246
training step: 25065, total_loss: 4.265443325042725
training step: 25066, total_loss: 4.847207546234131
training step: 25067, total_loss: 3.2503788471221924
training step: 25068, total_loss: 5.088625907897949
training step: 25069, total_loss: 3.400906562805176
training step: 25070, total_loss: 4.417659282684326
training step: 25071, total_loss: 4.55397891998291
training step: 25072, total_loss: 3.309997081756592
training step: 25073, total_loss: 4.916790962219238
training step: 25074, total_loss: 2.4251527786254883
training step: 25075, total_loss: 4.958467483520508
training step: 25076, total_loss: 4.759087085723877
training step: 25077, total_loss: 5.90117883682251
training step: 25078, total_loss: 3.917600154876709
training step: 25079, total_loss: 6.304611682891846
training step: 25080, total_loss: 5.683766841888428
training step: 25081, total_loss: 4.621938228607178
training step: 25082, total_loss: 3.979917287826538
training step: 25083, total_loss: 5.9405341148376465
training step: 25084, total_loss: 6.25648307800293
training step: 25085, total_loss: 5.351004600524902
training step: 25086, total_loss: 4.708865165710449
training step: 25087, total_loss: 5.70050048828125
training step: 25088, total_loss: 3.6548380851745605
training step: 25089, total_loss: 3.454470157623291
training step: 25090, total_loss: 4.414358615875244
training step: 25091, total_loss: 3.8809380531311035
training step: 25092, total_loss: 4.199935436248779
training step: 25093, total_loss: 2.7720940113067627
training step: 25094, total_loss: 5.062941551208496
training step: 25095, total_loss: 5.845891952514648
training step: 25096, total_loss: 3.6002755165100098
training step: 25097, total_loss: 5.21570348739624
training step: 25098, total_loss: 5.735581398010254
training step: 25099, total_loss: 4.871028900146484
training step: 25100, total_loss: 4.498507499694824
training step: 25101, total_loss: 2.408461332321167
training step: 25102, total_loss: 5.198977470397949
training step: 25103, total_loss: 4.79682731628418
training step: 25104, total_loss: 3.519712448120117
training step: 25105, total_loss: 5.01731014251709
training step: 25106, total_loss: 3.388766288757324
training step: 25107, total_loss: 4.123594760894775
training step: 25108, total_loss: 3.2667126655578613
training step: 25109, total_loss: 3.392709970474243
training step: 25110, total_loss: 2.4947426319122314
training step: 25111, total_loss: 4.710558891296387
training step: 25112, total_loss: 3.6252269744873047
training step: 25113, total_loss: 4.649691581726074
training step: 25114, total_loss: 4.827445030212402
training step: 25115, total_loss: 4.880873680114746
training step: 25116, total_loss: 3.750552177429199
training step: 25117, total_loss: 4.054075717926025
training step: 25118, total_loss: 3.6251440048217773
training step: 25119, total_loss: 4.690808296203613
training step: 25120, total_loss: 5.0696563720703125
training step: 25121, total_loss: 4.814300537109375
training step: 25122, total_loss: 3.938525676727295
training step: 25123, total_loss: 4.032217502593994
training step: 25124, total_loss: 6.362466335296631
training step: 25125, total_loss: 4.293426513671875
training step: 25126, total_loss: 4.461433410644531
training step: 25127, total_loss: 4.138144493103027
training step: 25128, total_loss: 4.04471492767334
training step: 25129, total_loss: 4.058845520019531
training step: 25130, total_loss: 4.531679153442383
training step: 25131, total_loss: 6.885308742523193
training step: 25132, total_loss: 6.315812110900879
training step: 25133, total_loss: 5.501701354980469
training step: 25134, total_loss: 5.123424530029297
training step: 25135, total_loss: 3.9599146842956543
training step: 25136, total_loss: 4.615867614746094
training step: 25137, total_loss: 5.9427618980407715
training step: 25138, total_loss: 6.598337650299072
training step: 25139, total_loss: 5.009634017944336
training step: 25140, total_loss: 5.135679244995117
training step: 25141, total_loss: 3.9572980403900146
training step: 25142, total_loss: 4.614805221557617
training step: 25143, total_loss: 4.189385414123535
training step: 25144, total_loss: 4.042874336242676
training step: 25145, total_loss: 6.194304466247559
training step: 25146, total_loss: 4.032159328460693
training step: 25147, total_loss: 4.545135974884033
training step: 25148, total_loss: 6.918925762176514
training step: 25149, total_loss: 2.2900893688201904
training step: 25150, total_loss: 5.118041038513184
training step: 25151, total_loss: 4.386152744293213
training step: 25152, total_loss: 4.210587501525879
training step: 25153, total_loss: 3.173574209213257
training step: 25154, total_loss: 2.9251253604888916
training step: 25155, total_loss: 4.786273956298828
training step: 25156, total_loss: 3.7965264320373535
training step: 25157, total_loss: 3.695052146911621
training step: 25158, total_loss: 5.1870551109313965
training step: 25159, total_loss: 5.271527290344238
training step: 25160, total_loss: 4.213712692260742
training step: 25161, total_loss: 6.254775047302246
training step: 25162, total_loss: 4.397488594055176
training step: 25163, total_loss: 4.648000717163086
training step: 25164, total_loss: 4.216850280761719
training step: 25165, total_loss: 4.342784881591797
training step: 25166, total_loss: 4.642951011657715
training step: 25167, total_loss: 3.100341796875
training step: 25168, total_loss: 1.3944039344787598
training step: 25169, total_loss: 5.2218122482299805
training step: 25170, total_loss: 5.551738262176514
training step: 25171, total_loss: 5.689857482910156
training step: 25172, total_loss: 4.736309051513672
training step: 25173, total_loss: 4.131464004516602
training step: 25174, total_loss: 4.163699150085449
training step: 25175, total_loss: 4.855800628662109
training step: 25176, total_loss: 4.113065242767334
training step: 25177, total_loss: 4.435993194580078
training step: 25178, total_loss: 7.785430908203125
training step: 25179, total_loss: 5.120200157165527
training step: 25180, total_loss: 6.028385162353516
training step: 25181, total_loss: 2.838951349258423
training step: 25182, total_loss: 5.251955032348633
training step: 25183, total_loss: 3.504667043685913
training step: 25184, total_loss: 4.639676094055176
training step: 25185, total_loss: 4.087286472320557
training step: 25186, total_loss: 4.423011779785156
training step: 25187, total_loss: 4.033019065856934
training step: 25188, total_loss: 4.928457260131836
training step: 25189, total_loss: 5.359336853027344
training step: 25190, total_loss: 4.371410369873047
training step: 25191, total_loss: 5.107901573181152
training step: 25192, total_loss: 6.911709785461426
training step: 25193, total_loss: 4.149764537811279
training step: 25194, total_loss: 4.329531669616699
training step: 25195, total_loss: 5.246978759765625
training step: 25196, total_loss: 4.0997514724731445
training step: 25197, total_loss: 4.000026226043701
training step: 25198, total_loss: 4.874795436859131
training step: 25199, total_loss: 4.4629669189453125
training step: 25200, total_loss: 4.897830009460449
training step: 25201, total_loss: 5.868295192718506
training step: 25202, total_loss: 4.551332950592041
training step: 25203, total_loss: 4.14674186706543
training step: 25204, total_loss: 4.102023124694824
training step: 25205, total_loss: 4.178929328918457
training step: 25206, total_loss: 4.230196952819824
training step: 25207, total_loss: 4.725796699523926
training step: 25208, total_loss: 4.265378952026367
training step: 25209, total_loss: 6.705944061279297
training step: 25210, total_loss: 4.455930233001709
training step: 25211, total_loss: 3.880150318145752
training step: 25212, total_loss: 3.190032958984375
training step: 25213, total_loss: 5.206363677978516
training step: 25214, total_loss: 3.7516541481018066
training step: 25215, total_loss: 5.690145492553711
training step: 25216, total_loss: 4.6128950119018555
training step: 25217, total_loss: 5.266030311584473
training step: 25218, total_loss: 6.152472972869873
training step: 25219, total_loss: 4.768810272216797
training step: 25220, total_loss: 4.485753059387207
training step: 25221, total_loss: 4.539994239807129
training step: 25222, total_loss: 4.784202575683594
training step: 25223, total_loss: 5.138985633850098
training step: 25224, total_loss: 4.1440606117248535
training step: 25225, total_loss: 5.481467247009277
training step: 25226, total_loss: 5.039501190185547
training step: 25227, total_loss: 5.478972434997559
training step: 25228, total_loss: 4.277641296386719
training step: 25229, total_loss: 3.762057304382324
training step: 25230, total_loss: 4.477658271789551
training step: 25231, total_loss: 4.772015571594238
training step: 25232, total_loss: 3.961945056915283
training step: 25233, total_loss: 3.960899591445923
training step: 25234, total_loss: 4.932868957519531
training step: 25235, total_loss: 3.4306888580322266
training step: 25236, total_loss: 4.612420082092285
training step: 25237, total_loss: 3.511868953704834
training step: 25238, total_loss: 4.734951019287109
training step: 25239, total_loss: 2.0756921768188477
training step: 25240, total_loss: 4.208009719848633
training step: 25241, total_loss: 4.42862606048584
training step: 25242, total_loss: 4.965967178344727
training step: 25243, total_loss: 6.590350151062012
training step: 25244, total_loss: 3.4721004962921143
training step: 25245, total_loss: 5.245969772338867
training step: 25246, total_loss: 1.2737650871276855
training step: 25247, total_loss: 2.7270619869232178
training step: 25248, total_loss: 2.15655255317688
training step: 25249, total_loss: 4.905220985412598
training step: 25250, total_loss: 4.5775861740112305
training step: 25251, total_loss: 4.877043724060059
training step: 25252, total_loss: 2.773752212524414
training step: 25253, total_loss: 5.657575607299805
training step: 25254, total_loss: 3.765979766845703
training step: 25255, total_loss: 1.252589464187622
training step: 25256, total_loss: 5.6197896003723145
training step: 25257, total_loss: 4.453690052032471
training step: 25258, total_loss: 4.938650131225586
training step: 25259, total_loss: 3.9495162963867188
training step: 25260, total_loss: 3.958418369293213
training step: 25261, total_loss: 5.841785907745361
training step: 25262, total_loss: 5.5249528884887695
training step: 25263, total_loss: 4.673287868499756
training step: 25264, total_loss: 3.1719417572021484
training step: 25265, total_loss: 5.566133499145508
training step: 25266, total_loss: 4.255730152130127
training step: 25267, total_loss: 5.298541069030762
training step: 25268, total_loss: 5.555060386657715
training step: 25269, total_loss: 4.027553081512451
training step: 25270, total_loss: 1.241245985031128
training step: 25271, total_loss: 3.8730835914611816
training step: 25272, total_loss: 3.344662666320801
training step: 25273, total_loss: 5.232601165771484
training step: 25274, total_loss: 4.593031406402588
training step: 25275, total_loss: 5.308011054992676
training step: 25276, total_loss: 3.676549196243286
training step: 25277, total_loss: 5.632900714874268
training step: 25278, total_loss: 3.892958164215088
training step: 25279, total_loss: 3.973266363143921
training step: 25280, total_loss: 3.4879140853881836
training step: 25281, total_loss: 4.138034820556641
training step: 25282, total_loss: 2.7352702617645264
training step: 25283, total_loss: 4.83485221862793
training step: 25284, total_loss: 4.024479866027832
training step: 25285, total_loss: 2.089338779449463
training step: 25286, total_loss: 4.585598945617676
training step: 25287, total_loss: 4.449784755706787
training step: 25288, total_loss: 5.4877777099609375
training step: 25289, total_loss: 4.626979351043701
training step: 25290, total_loss: 2.9044642448425293
training step: 25291, total_loss: 5.642565727233887
training step: 25292, total_loss: 3.694972038269043
training step: 25293, total_loss: 3.733274221420288
training step: 25294, total_loss: 4.023167610168457
training step: 25295, total_loss: 4.783782005310059
training step: 25296, total_loss: 2.7232606410980225
training step: 25297, total_loss: 2.971564292907715
training step: 25298, total_loss: 3.5740511417388916
training step: 25299, total_loss: 5.728673934936523
training step: 25300, total_loss: 4.539984703063965
training step: 25301, total_loss: 5.5126495361328125
training step: 25302, total_loss: 4.262285232543945
training step: 25303, total_loss: 6.083202838897705
training step: 25304, total_loss: 4.709156036376953
training step: 25305, total_loss: 2.636056900024414
training step: 25306, total_loss: 2.309528350830078
training step: 25307, total_loss: 3.4102931022644043
training step: 25308, total_loss: 2.8113017082214355
training step: 25309, total_loss: 5.468317985534668
training step: 25310, total_loss: 4.740333557128906
training step: 25311, total_loss: 3.6221463680267334
training step: 25312, total_loss: 4.126868724822998
training step: 25313, total_loss: 4.661279678344727
training step: 25314, total_loss: 4.511061191558838
training step: 25315, total_loss: 5.552506446838379
training step: 25316, total_loss: 2.891106605529785
training step: 25317, total_loss: 4.824921131134033
training step: 25318, total_loss: 5.07489013671875
training step: 25319, total_loss: 4.718605041503906
training step: 25320, total_loss: 5.090784072875977
training step: 25321, total_loss: 4.758294105529785
training step: 25322, total_loss: 5.17327880859375
training step: 25323, total_loss: 4.095059394836426
training step: 25324, total_loss: 4.068828582763672
training step: 25325, total_loss: 5.0832319259643555
training step: 25326, total_loss: 3.6159491539001465
training step: 25327, total_loss: 5.542925834655762
training step: 25328, total_loss: 3.558976173400879
training step: 25329, total_loss: 4.688246250152588
training step: 25330, total_loss: 4.467679023742676
training step: 25331, total_loss: 4.24179220199585
training step: 25332, total_loss: 4.3278608322143555
training step: 25333, total_loss: 5.4602861404418945
training step: 25334, total_loss: 4.8747735023498535
training step: 25335, total_loss: 4.31374454498291
training step: 25336, total_loss: 3.8198587894439697
training step: 25337, total_loss: 5.344917297363281
training step: 25338, total_loss: 2.669281005859375
training step: 25339, total_loss: 5.258108615875244
training step: 25340, total_loss: 5.909799575805664
training step: 25341, total_loss: 3.54754638671875
training step: 25342, total_loss: 5.678353309631348
training step: 25343, total_loss: 4.136653900146484
training step: 25344, total_loss: 4.744744300842285
training step: 25345, total_loss: 4.382932662963867
training step: 25346, total_loss: 6.1226677894592285
training step: 25347, total_loss: 3.9921276569366455
training step: 25348, total_loss: 5.202986717224121
training step: 25349, total_loss: 4.681035041809082
training step: 25350, total_loss: 4.460306167602539
training step: 25351, total_loss: 3.3206562995910645
training step: 25352, total_loss: 3.2178993225097656
training step: 25353, total_loss: 4.360752582550049
training step: 25354, total_loss: 4.30900764465332
training step: 25355, total_loss: 4.109007358551025
training step: 25356, total_loss: 4.614673614501953
training step: 25357, total_loss: 4.184964179992676
training step: 25358, total_loss: 5.774881362915039
training step: 25359, total_loss: 4.821663856506348
training step: 25360, total_loss: 3.0802736282348633
training step: 25361, total_loss: 4.086636066436768
training step: 25362, total_loss: 6.251096248626709
training step: 25363, total_loss: 5.2260212898254395
training step: 25364, total_loss: 4.849942207336426
training step: 25365, total_loss: 4.475018501281738
training step: 25366, total_loss: 5.107592582702637
training step: 25367, total_loss: 5.8491315841674805
training step: 25368, total_loss: 5.473651885986328
training step: 25369, total_loss: 3.630518913269043
training step: 25370, total_loss: 4.857239723205566
training step: 25371, total_loss: 4.319746017456055
training step: 25372, total_loss: 3.8149192333221436
training step: 25373, total_loss: 1.150744915008545
training step: 25374, total_loss: 5.205533027648926
training step: 25375, total_loss: 4.921758651733398
training step: 25376, total_loss: 6.386503219604492
training step: 25377, total_loss: 3.574869155883789
training step: 25378, total_loss: 4.59459924697876
training step: 25379, total_loss: 4.554400444030762
training step: 25380, total_loss: 5.500972270965576
training step: 25381, total_loss: 6.811402320861816
training step: 25382, total_loss: 4.027640342712402
training step: 25383, total_loss: 3.2139830589294434
training step: 25384, total_loss: 1.0378048419952393
training step: 25385, total_loss: 4.844258785247803
training step: 25386, total_loss: 4.299084663391113
training step: 25387, total_loss: 4.391172409057617
training step: 25388, total_loss: 4.447134971618652
training step: 25389, total_loss: 3.662479877471924
training step: 25390, total_loss: 5.360212802886963
training step: 25391, total_loss: 5.054226875305176
training step: 25392, total_loss: 4.779431343078613
training step: 25393, total_loss: 3.488353967666626
training step: 25394, total_loss: 3.046614646911621
training step: 25395, total_loss: 4.419888019561768
training step: 25396, total_loss: 5.025717735290527
training step: 25397, total_loss: 3.8870043754577637
training step: 25398, total_loss: 4.640899658203125
training step: 25399, total_loss: 4.820247650146484
training step: 25400, total_loss: 5.295007705688477
training step: 25401, total_loss: 3.1640100479125977
training step: 25402, total_loss: 6.90202522277832
training step: 25403, total_loss: 6.651719093322754
training step: 25404, total_loss: 4.966508865356445
training step: 25405, total_loss: 3.9232070446014404
training step: 25406, total_loss: 4.377096176147461
training step: 25407, total_loss: 3.309882164001465
training step: 25408, total_loss: 4.51805305480957
training step: 25409, total_loss: 5.3943023681640625
training step: 25410, total_loss: 4.620870590209961
training step: 25411, total_loss: 4.866456031799316
training step: 25412, total_loss: 3.7992396354675293
training step: 25413, total_loss: 2.1602330207824707
training step: 25414, total_loss: 3.8655941486358643
training step: 25415, total_loss: 4.985707759857178
training step: 25416, total_loss: 4.727965354919434
training step: 25417, total_loss: 4.147563457489014
training step: 25418, total_loss: 4.018185615539551
training step: 25419, total_loss: 5.013972282409668
training step: 25420, total_loss: 5.093877792358398
training step: 25421, total_loss: 3.6560556888580322
training step: 25422, total_loss: 3.44518780708313
training step: 25423, total_loss: 4.862335205078125
training step: 25424, total_loss: 4.53674840927124
training step: 25425, total_loss: 4.776730537414551
training step: 25426, total_loss: 3.0871500968933105
training step: 25427, total_loss: 5.523982048034668
training step: 25428, total_loss: 4.966221809387207
training step: 25429, total_loss: 4.9256181716918945
training step: 25430, total_loss: 4.6984357833862305
training step: 25431, total_loss: 4.931099891662598
training step: 25432, total_loss: 7.77398681640625
training step: 25433, total_loss: 5.963107109069824
training step: 25434, total_loss: 4.186350345611572
training step: 25435, total_loss: 4.636312961578369
training step: 25436, total_loss: 4.32658576965332
training step: 25437, total_loss: 4.475854396820068
training step: 25438, total_loss: 5.215054512023926
training step: 25439, total_loss: 2.4597229957580566
training step: 25440, total_loss: 6.019783020019531
training step: 25441, total_loss: 4.775929927825928
training step: 25442, total_loss: 3.2087559700012207
training step: 25443, total_loss: 4.8187031745910645
training step: 25444, total_loss: 5.431789398193359
training step: 25445, total_loss: 4.465289115905762
training step: 25446, total_loss: 3.485342025756836
training step: 25447, total_loss: 4.547181129455566
training step: 25448, total_loss: 5.188574314117432
training step: 25449, total_loss: 5.245843887329102
training step: 25450, total_loss: 5.08940315246582
training step: 25451, total_loss: 3.9449782371520996
training step: 25452, total_loss: 3.6673929691314697
training step: 25453, total_loss: 4.089232444763184
training step: 25454, total_loss: 4.072289943695068
training step: 25455, total_loss: 3.8166518211364746
training step: 25456, total_loss: 3.4213972091674805
training step: 25457, total_loss: 3.666856288909912
training step: 25458, total_loss: 5.723935127258301
training step: 25459, total_loss: 3.5652012825012207
training step: 25460, total_loss: 2.087143898010254
training step: 25461, total_loss: 1.1802699565887451
training step: 25462, total_loss: 4.730316162109375
training step: 25463, total_loss: 3.136444091796875
training step: 25464, total_loss: 3.5616295337677
training step: 25465, total_loss: 4.33342981338501
training step: 25466, total_loss: 5.163980007171631
training step: 25467, total_loss: 4.069966793060303
training step: 25468, total_loss: 5.215373516082764
training step: 25469, total_loss: 4.153642654418945
training step: 25470, total_loss: 5.762479782104492
training step: 25471, total_loss: 4.954458236694336
training step: 25472, total_loss: 4.018517971038818
training step: 25473, total_loss: 4.234357833862305
training step: 25474, total_loss: 5.204277038574219
training step: 25475, total_loss: 2.791954517364502
training step: 25476, total_loss: 4.597224712371826
training step: 25477, total_loss: 3.529848575592041
training step: 25478, total_loss: 4.3004255294799805
training step: 25479, total_loss: 4.04046106338501
training step: 25480, total_loss: 4.982451438903809
training step: 25481, total_loss: 3.3130311965942383
training step: 25482, total_loss: 5.266097068786621
training step: 25483, total_loss: 5.155483245849609
training step: 25484, total_loss: 5.58981466293335
training step: 25485, total_loss: 3.967751979827881
training step: 25486, total_loss: 5.013810157775879
training step: 25487, total_loss: 4.477760314941406
training step: 25488, total_loss: 3.2064878940582275
training step: 25489, total_loss: 5.267345428466797
training step: 25490, total_loss: 5.113554954528809
training step: 25491, total_loss: 5.080647945404053
training step: 25492, total_loss: 6.4584760665893555
training step: 25493, total_loss: 5.638083457946777
training step: 25494, total_loss: 3.8024330139160156
training step: 25495, total_loss: 6.222782611846924
training step: 25496, total_loss: 4.2451276779174805
training step: 25497, total_loss: 4.758780002593994
training step: 25498, total_loss: 5.441150188446045
training step: 25499, total_loss: 5.126894950866699
training step: 25500, total_loss: 4.898526191711426
training step: 25501, total_loss: 4.673630714416504
training step: 25502, total_loss: 5.429571151733398
training step: 25503, total_loss: 4.994500160217285
training step: 25504, total_loss: 4.52910852432251
training step: 25505, total_loss: 4.777565956115723
training step: 25506, total_loss: 1.4601281881332397
training step: 25507, total_loss: 3.8061981201171875
training step: 25508, total_loss: 3.9818239212036133
training step: 25509, total_loss: 4.486611366271973
training step: 25510, total_loss: 2.316592216491699
training step: 25511, total_loss: 2.4962692260742188
training step: 25512, total_loss: 5.679479598999023
training step: 25513, total_loss: 5.062307357788086
training step: 25514, total_loss: 2.9314212799072266
training step: 25515, total_loss: 4.620181560516357
training step: 25516, total_loss: 5.213517189025879
training step: 25517, total_loss: 3.966841459274292
training step: 25518, total_loss: 6.028364658355713
training step: 25519, total_loss: 4.534551620483398
training step: 25520, total_loss: 5.018484592437744
training step: 25521, total_loss: 4.674269199371338
training step: 25522, total_loss: 3.3465137481689453
training step: 25523, total_loss: 2.9655556678771973
training step: 25524, total_loss: 5.824987411499023
training step: 25525, total_loss: 6.177676677703857
training step: 25526, total_loss: 3.122891426086426
training step: 25527, total_loss: 4.348841667175293
training step: 25528, total_loss: 5.722299575805664
training step: 25529, total_loss: 4.350897789001465
training step: 25530, total_loss: 5.4891862869262695
training step: 25531, total_loss: 2.3849735260009766
training step: 25532, total_loss: 4.074235439300537
training step: 25533, total_loss: 4.9357147216796875
training step: 25534, total_loss: 6.570775985717773
training step: 25535, total_loss: 4.177812576293945
training step: 25536, total_loss: 3.6069390773773193
training step: 25537, total_loss: 4.544027328491211
training step: 25538, total_loss: 3.179886817932129
training step: 25539, total_loss: 5.401673793792725
training step: 25540, total_loss: 4.2381134033203125
training step: 25541, total_loss: 2.3692662715911865
training step: 25542, total_loss: 4.269063949584961
training step: 25543, total_loss: 5.081413269042969
training step: 25544, total_loss: 4.190349102020264
training step: 25545, total_loss: 5.034917831420898
training step: 25546, total_loss: 4.7097859382629395
training step: 25547, total_loss: 5.679210662841797
training step: 25548, total_loss: 5.252243995666504
training step: 25549, total_loss: 5.427417755126953
training step: 25550, total_loss: 4.948533535003662
training step: 25551, total_loss: 4.7219157218933105
training step: 25552, total_loss: 0.8574531078338623
training step: 25553, total_loss: 8.354612350463867
training step: 25554, total_loss: 4.9550018310546875
training step: 25555, total_loss: 3.606785774230957
training step: 25556, total_loss: 4.5253825187683105
training step: 25557, total_loss: 4.638934135437012
training step: 25558, total_loss: 2.8811283111572266
training step: 25559, total_loss: 5.170224189758301
training step: 25560, total_loss: 5.338433265686035
training step: 25561, total_loss: 4.230074882507324
training step: 25562, total_loss: 6.173208236694336
training step: 25563, total_loss: 5.528168678283691
training step: 25564, total_loss: 3.8247385025024414
training step: 25565, total_loss: 1.1015286445617676
training step: 25566, total_loss: 4.768019676208496
training step: 25567, total_loss: 4.494040489196777
training step: 25568, total_loss: 2.100310802459717
training step: 25569, total_loss: 5.939188003540039
training step: 25570, total_loss: 4.31424617767334
training step: 25571, total_loss: 5.130798816680908
training step: 25572, total_loss: 4.072497367858887
training step: 25573, total_loss: 5.2270636558532715
training step: 25574, total_loss: 4.047715187072754
training step: 25575, total_loss: 4.28659725189209
training step: 25576, total_loss: 4.665478706359863
training step: 25577, total_loss: 5.027463912963867
training step: 25578, total_loss: 5.345437049865723
training step: 25579, total_loss: 4.457465171813965
training step: 25580, total_loss: 6.636496543884277
training step: 25581, total_loss: 1.77657151222229
training step: 25582, total_loss: 3.8562939167022705
training step: 25583, total_loss: 3.387600898742676
training step: 25584, total_loss: 4.620541095733643
training step: 25585, total_loss: 4.5892157554626465
training step: 25586, total_loss: 5.034907817840576
training step: 25587, total_loss: 4.408609390258789
training step: 25588, total_loss: 4.495327949523926
training step: 25589, total_loss: 4.174555778503418
training step: 25590, total_loss: 4.32748556137085
training step: 25591, total_loss: 4.233828544616699
training step: 25592, total_loss: 5.1049957275390625
training step: 25593, total_loss: 5.910740852355957
training step: 25594, total_loss: 2.512890338897705
training step: 25595, total_loss: 4.518857955932617
training step: 25596, total_loss: 5.515052318572998
training step: 25597, total_loss: 3.563667058944702
training step: 25598, total_loss: 5.21047830581665
training step: 25599, total_loss: 6.671562671661377
training step: 25600, total_loss: 4.746586322784424
training step: 25601, total_loss: 4.56536865234375
training step: 25602, total_loss: 2.382169008255005
training step: 25603, total_loss: 3.868682861328125
training step: 25604, total_loss: 6.9217329025268555
training step: 25605, total_loss: 5.660566329956055
training step: 25606, total_loss: 4.733055591583252
training step: 25607, total_loss: 3.9715611934661865
training step: 25608, total_loss: 5.3416595458984375
training step: 25609, total_loss: 2.4961800575256348
training step: 25610, total_loss: 4.726981163024902
training step: 25611, total_loss: 5.677659034729004
training step: 25612, total_loss: 5.2421674728393555
training step: 25613, total_loss: 4.325141906738281
training step: 25614, total_loss: 5.391961574554443
training step: 25615, total_loss: 3.872119665145874
training step: 25616, total_loss: 3.6382038593292236
training step: 25617, total_loss: 2.7911744117736816
training step: 25618, total_loss: 5.557878494262695
training step: 25619, total_loss: 4.485736846923828
training step: 25620, total_loss: 3.934192180633545
training step: 25621, total_loss: 6.423524379730225
training step: 25622, total_loss: 4.527151584625244
training step: 25623, total_loss: 3.894580841064453
training step: 25624, total_loss: 5.997830867767334
training step: 25625, total_loss: 5.612149238586426
training step: 25626, total_loss: 4.184128761291504
training step: 25627, total_loss: 3.0326285362243652
training step: 25628, total_loss: 2.6110477447509766
training step: 25629, total_loss: 4.654175758361816
training step: 25630, total_loss: 4.41944694519043
training step: 25631, total_loss: 6.451922416687012
training step: 25632, total_loss: 6.442435264587402
training step: 25633, total_loss: 4.767601013183594
training step: 25634, total_loss: 4.039639472961426
training step: 25635, total_loss: 3.1350107192993164
training step: 25636, total_loss: 3.2049052715301514
training step: 25637, total_loss: 4.37733793258667
training step: 25638, total_loss: 5.005462646484375
training step: 25639, total_loss: 3.103317975997925
training step: 25640, total_loss: 2.983677864074707
training step: 25641, total_loss: 4.086429595947266
training step: 25642, total_loss: 4.783909320831299
training step: 25643, total_loss: 4.298532485961914
training step: 25644, total_loss: 4.960484027862549
training step: 25645, total_loss: 4.8211469650268555
training step: 25646, total_loss: 6.091681480407715
training step: 25647, total_loss: 4.554880142211914
training step: 25648, total_loss: 5.111036777496338
training step: 25649, total_loss: 4.377896308898926
training step: 25650, total_loss: 4.448171615600586
training step: 25651, total_loss: 4.838954925537109
training step: 25652, total_loss: 4.271481513977051
training step: 25653, total_loss: 2.8974854946136475
training step: 25654, total_loss: 5.85209846496582
training step: 25655, total_loss: 5.056143760681152
training step: 25656, total_loss: 3.833571434020996
training step: 25657, total_loss: 4.86724853515625
training step: 25658, total_loss: 5.033370494842529
training step: 25659, total_loss: 1.1497914791107178
training step: 25660, total_loss: 4.056621551513672
training step: 25661, total_loss: 5.205148220062256
training step: 25662, total_loss: 4.865555286407471
training step: 25663, total_loss: 2.8966026306152344
training step: 25664, total_loss: 4.014719009399414
training step: 25665, total_loss: 5.249989986419678
training step: 25666, total_loss: 6.011545181274414
training step: 25667, total_loss: 5.541465759277344
training step: 25668, total_loss: 5.382513999938965
training step: 25669, total_loss: 4.0626115798950195
training step: 25670, total_loss: 5.342585563659668
training step: 25671, total_loss: 3.8015005588531494
training step: 25672, total_loss: 4.003723621368408
training step: 25673, total_loss: 4.969241142272949
training step: 25674, total_loss: 4.189793586730957
training step: 25675, total_loss: 3.564680576324463
training step: 25676, total_loss: 4.033486843109131
training step: 25677, total_loss: 4.049227237701416
training step: 25678, total_loss: 2.97288179397583
training step: 25679, total_loss: 4.34596061706543
training step: 25680, total_loss: 5.121184349060059
training step: 25681, total_loss: 4.309033393859863
training step: 25682, total_loss: 4.925140380859375
training step: 25683, total_loss: 4.333230495452881
training step: 25684, total_loss: 4.0655412673950195
training step: 25685, total_loss: 3.6205708980560303
training step: 25686, total_loss: 4.125539779663086
training step: 25687, total_loss: 3.480489730834961
training step: 25688, total_loss: 6.107207298278809
training step: 25689, total_loss: 3.8678369522094727
training step: 25690, total_loss: 4.257079124450684
training step: 25691, total_loss: 5.276275157928467
training step: 25692, total_loss: 4.732346534729004
training step: 25693, total_loss: 4.412169456481934
training step: 25694, total_loss: 3.66192626953125
training step: 25695, total_loss: 4.04824161529541
training step: 25696, total_loss: 4.7805657386779785
training step: 25697, total_loss: 4.054398059844971
training step: 25698, total_loss: 4.863776206970215
training step: 25699, total_loss: 4.081211090087891
training step: 25700, total_loss: 4.98879861831665
training step: 25701, total_loss: 5.589776515960693
training step: 25702, total_loss: 3.9791650772094727
training step: 25703, total_loss: 3.684417247772217
training step: 25704, total_loss: 4.223694801330566
training step: 25705, total_loss: 5.19893741607666
training step: 25706, total_loss: 4.811161518096924
training step: 25707, total_loss: 6.326590538024902
training step: 25708, total_loss: 4.925230979919434
training step: 25709, total_loss: 3.453673839569092
training step: 25710, total_loss: 4.031999111175537
training step: 25711, total_loss: 5.698575973510742
training step: 25712, total_loss: 4.6400299072265625
training step: 25713, total_loss: 5.236821174621582
training step: 25714, total_loss: 4.733799457550049
training step: 25715, total_loss: 4.664913177490234
training step: 25716, total_loss: 5.512515544891357
training step: 25717, total_loss: 5.072140216827393
training step: 25718, total_loss: 4.813140869140625
training step: 25719, total_loss: 4.449899673461914
training step: 25720, total_loss: 5.365647315979004
training step: 25721, total_loss: 3.514357089996338
training step: 25722, total_loss: 4.3043365478515625
training step: 25723, total_loss: 6.021437644958496
training step: 25724, total_loss: 5.75212287902832
training step: 25725, total_loss: 4.713522911071777
training step: 25726, total_loss: 5.515707015991211
training step: 25727, total_loss: 4.2495903968811035
training step: 25728, total_loss: 4.598031997680664
training step: 25729, total_loss: 4.830731391906738
training step: 25730, total_loss: 4.267154216766357
training step: 25731, total_loss: 3.2899608612060547
training step: 25732, total_loss: 4.697092056274414
training step: 25733, total_loss: 5.109025001525879
training step: 25734, total_loss: 5.489525318145752
training step: 25735, total_loss: 4.2889885902404785
training step: 25736, total_loss: 4.666707992553711
training step: 25737, total_loss: 4.572680473327637
training step: 25738, total_loss: 4.30707311630249
training step: 25739, total_loss: 4.308892250061035
training step: 25740, total_loss: 4.049747467041016
training step: 25741, total_loss: 6.053495407104492
training step: 25742, total_loss: 3.9451804161071777
training step: 25743, total_loss: 4.0484161376953125
training step: 25744, total_loss: 5.8352227210998535
training step: 25745, total_loss: 3.817744493484497
training step: 25746, total_loss: 3.9762308597564697
training step: 25747, total_loss: 4.724125862121582
training step: 25748, total_loss: 5.169281959533691
training step: 25749, total_loss: 3.5608744621276855
training step: 25750, total_loss: 4.583662986755371
training step: 25751, total_loss: 4.79810905456543
training step: 25752, total_loss: 6.274416923522949
training step: 25753, total_loss: 5.224455833435059
training step: 25754, total_loss: 3.412051200866699
training step: 25755, total_loss: 4.379268646240234
training step: 25756, total_loss: 4.324756622314453
training step: 25757, total_loss: 5.097823143005371
training step: 25758, total_loss: 5.009726524353027
training step: 25759, total_loss: 4.45120906829834
training step: 25760, total_loss: 4.65580415725708
training step: 25761, total_loss: 4.789393424987793
training step: 25762, total_loss: 3.7226850986480713
training step: 25763, total_loss: 3.864777088165283
training step: 25764, total_loss: 4.5177106857299805
training step: 25765, total_loss: 3.9399726390838623
training step: 25766, total_loss: 4.822885036468506
training step: 25767, total_loss: 3.1817069053649902
training step: 25768, total_loss: 4.58488655090332
training step: 25769, total_loss: 4.431690692901611
training step: 25770, total_loss: 5.207820892333984
training step: 25771, total_loss: 5.202305793762207
training step: 25772, total_loss: 4.994915962219238
training step: 25773, total_loss: 4.750879287719727
training step: 25774, total_loss: 1.7021781206130981
training step: 25775, total_loss: 4.31043815612793
training step: 25776, total_loss: 4.321911334991455
training step: 25777, total_loss: 6.917813777923584
training step: 25778, total_loss: 4.991306781768799
training step: 25779, total_loss: 4.430402755737305
training step: 25780, total_loss: 4.5360541343688965
training step: 25781, total_loss: 6.631224155426025
training step: 25782, total_loss: 3.76869797706604
training step: 25783, total_loss: 1.4756146669387817
training step: 25784, total_loss: 4.058877468109131
training step: 25785, total_loss: 3.3955237865448
training step: 25786, total_loss: 3.794821262359619
training step: 25787, total_loss: 4.931601524353027
training step: 25788, total_loss: 4.4123334884643555
training step: 25789, total_loss: 4.925079345703125
training step: 25790, total_loss: 6.129209518432617
training step: 25791, total_loss: 7.6749749183654785
training step: 25792, total_loss: 4.175286769866943
training step: 25793, total_loss: 4.182824611663818
training step: 25794, total_loss: 5.153141021728516
training step: 25795, total_loss: 4.174115180969238
training step: 25796, total_loss: 5.507345199584961
training step: 25797, total_loss: 5.524789333343506
training step: 25798, total_loss: 4.074961185455322
training step: 25799, total_loss: 4.111295700073242
training step: 25800, total_loss: 5.248421669006348
training step: 25801, total_loss: 4.158762454986572
training step: 25802, total_loss: 3.1173970699310303
training step: 25803, total_loss: 5.009638786315918
training step: 25804, total_loss: 4.059344291687012
training step: 25805, total_loss: 2.8305516242980957
training step: 25806, total_loss: 3.1085705757141113
training step: 25807, total_loss: 5.242948055267334
training step: 25808, total_loss: 5.509469032287598
training step: 25809, total_loss: 5.024615287780762
training step: 25810, total_loss: 5.858405590057373
training step: 25811, total_loss: 5.988726615905762
training step: 25812, total_loss: 2.7901768684387207
training step: 25813, total_loss: 4.586082458496094
training step: 25814, total_loss: 5.063418865203857
training step: 25815, total_loss: 3.821315050125122
training step: 25816, total_loss: 2.614192485809326
training step: 25817, total_loss: 4.103801250457764
training step: 25818, total_loss: 4.673798561096191
training step: 25819, total_loss: 4.574263572692871
training step: 25820, total_loss: 2.3343846797943115
training step: 25821, total_loss: 5.475151062011719
training step: 25822, total_loss: 3.9766273498535156
training step: 25823, total_loss: 4.510512351989746
training step: 25824, total_loss: 5.046971321105957
training step: 25825, total_loss: 4.7645416259765625
training step: 25826, total_loss: 4.1346845626831055
training step: 25827, total_loss: 4.3750410079956055
training step: 25828, total_loss: 4.722208023071289
training step: 25829, total_loss: 3.668064594268799
training step: 25830, total_loss: 4.741439342498779
training step: 25831, total_loss: 4.105343818664551
training step: 25832, total_loss: 3.5007779598236084
training step: 25833, total_loss: 5.425457000732422
training step: 25834, total_loss: 4.461608409881592
training step: 25835, total_loss: 4.207651615142822
training step: 25836, total_loss: 4.401406288146973
training step: 25837, total_loss: 3.8768486976623535
training step: 25838, total_loss: 3.7458012104034424
training step: 25839, total_loss: 3.454346179962158
training step: 25840, total_loss: 2.9597866535186768
training step: 25841, total_loss: 2.979708433151245
training step: 25842, total_loss: 1.3314199447631836
training step: 25843, total_loss: 4.024201393127441
training step: 25844, total_loss: 4.1082963943481445
training step: 25845, total_loss: 4.8797101974487305
training step: 25846, total_loss: 4.296605110168457
training step: 25847, total_loss: 4.819124221801758
training step: 25848, total_loss: 3.093104362487793
training step: 25849, total_loss: 6.496525764465332
training step: 25850, total_loss: 4.158065319061279
training step: 25851, total_loss: 3.2111051082611084
training step: 25852, total_loss: 1.3227503299713135
training step: 25853, total_loss: 1.2096023559570312
training step: 25854, total_loss: 5.224334716796875
training step: 25855, total_loss: 5.161487579345703
training step: 25856, total_loss: 4.52610969543457
training step: 25857, total_loss: 3.537001371383667
training step: 25858, total_loss: 0.8525682687759399
training step: 25859, total_loss: 5.755480766296387
training step: 25860, total_loss: 4.564116477966309
training step: 25861, total_loss: 5.270676136016846
training step: 25862, total_loss: 4.958041191101074
training step: 25863, total_loss: 5.908717632293701
training step: 25864, total_loss: 4.991739273071289
training step: 25865, total_loss: 5.164098739624023
training step: 25866, total_loss: 0.7795366048812866
training step: 25867, total_loss: 4.858438014984131
training step: 25868, total_loss: 2.430055618286133
training step: 25869, total_loss: 4.815379619598389
training step: 25870, total_loss: 4.5796895027160645
training step: 25871, total_loss: 3.7847037315368652
training step: 25872, total_loss: 4.961933135986328
training step: 25873, total_loss: 2.5396318435668945
training step: 25874, total_loss: 4.529359817504883
training step: 25875, total_loss: 4.068037509918213
training step: 25876, total_loss: 3.9841084480285645
training step: 25877, total_loss: 5.2747602462768555
training step: 25878, total_loss: 4.90191125869751
training step: 25879, total_loss: 4.672974586486816
training step: 25880, total_loss: 4.649250030517578
training step: 25881, total_loss: 4.997129440307617
training step: 25882, total_loss: 4.236611366271973
training step: 25883, total_loss: 5.755603313446045
training step: 25884, total_loss: 4.415652275085449
training step: 25885, total_loss: 4.634992599487305
training step: 25886, total_loss: 4.955845832824707
training step: 25887, total_loss: 3.7276973724365234
training step: 25888, total_loss: 3.78442645072937
training step: 25889, total_loss: 3.9468202590942383
training step: 25890, total_loss: 4.169025421142578
training step: 25891, total_loss: 3.453840494155884
training step: 25892, total_loss: 5.100560188293457
training step: 25893, total_loss: 6.380724906921387
training step: 25894, total_loss: 3.4914143085479736
training step: 25895, total_loss: 4.933232307434082
training step: 25896, total_loss: 5.733039855957031
training step: 25897, total_loss: 4.930232048034668
training step: 25898, total_loss: 0.9041080474853516
training step: 25899, total_loss: 5.1141557693481445
training step: 25900, total_loss: 5.996769428253174
training step: 25901, total_loss: 3.5091207027435303
training step: 25902, total_loss: 4.660296440124512
training step: 25903, total_loss: 5.654112339019775
training step: 25904, total_loss: 4.625773906707764
training step: 25905, total_loss: 0.9074479937553406
training step: 25906, total_loss: 4.511691570281982
training step: 25907, total_loss: 5.236594200134277
training step: 25908, total_loss: 4.837637901306152
training step: 25909, total_loss: 6.788212776184082
training step: 25910, total_loss: 5.34883975982666
training step: 25911, total_loss: 4.558053016662598
training step: 25912, total_loss: 3.9995265007019043
training step: 25913, total_loss: 3.8655638694763184
training step: 25914, total_loss: 4.717996597290039
training step: 25915, total_loss: 4.18433952331543
training step: 25916, total_loss: 2.282036066055298
training step: 25917, total_loss: 4.550353527069092
training step: 25918, total_loss: 5.098458290100098
training step: 25919, total_loss: 3.346592664718628
training step: 25920, total_loss: 4.707481384277344
training step: 25921, total_loss: 4.16384220123291
training step: 25922, total_loss: 2.9676260948181152
training step: 25923, total_loss: 4.618687629699707
training step: 25924, total_loss: 5.125832557678223
training step: 25925, total_loss: 4.640212535858154
training step: 25926, total_loss: 5.304025650024414
training step: 25927, total_loss: 0.9400603175163269
training step: 25928, total_loss: 3.952928304672241
training step: 25929, total_loss: 5.123918533325195
training step: 25930, total_loss: 2.4789252281188965
training step: 25931, total_loss: 4.608980178833008
training step: 25932, total_loss: 5.104343891143799
training step: 25933, total_loss: 5.032423973083496
training step: 25934, total_loss: 5.049473762512207
training step: 25935, total_loss: 4.599758148193359
training step: 25936, total_loss: 5.980978012084961
training step: 25937, total_loss: 4.418434143066406
training step: 25938, total_loss: 5.955340385437012
training step: 25939, total_loss: 3.4944748878479004
training step: 25940, total_loss: 4.471813678741455
training step: 25941, total_loss: 3.74550199508667
training step: 25942, total_loss: 4.037830829620361
training step: 25943, total_loss: 5.861969947814941
training step: 25944, total_loss: 4.879668235778809
training step: 25945, total_loss: 4.502888202667236
training step: 25946, total_loss: 4.166699409484863
training step: 25947, total_loss: 3.9537606239318848
training step: 25948, total_loss: 5.117983818054199
training step: 25949, total_loss: 4.796178817749023
training step: 25950, total_loss: 3.9933385848999023
training step: 25951, total_loss: 4.010722637176514
training step: 25952, total_loss: 4.572147369384766
training step: 25953, total_loss: 4.9553446769714355
training step: 25954, total_loss: 2.8831210136413574
training step: 25955, total_loss: 4.593532085418701
training step: 25956, total_loss: 4.213313579559326
training step: 25957, total_loss: 3.858313798904419
training step: 25958, total_loss: 4.0854597091674805
training step: 25959, total_loss: 5.51917839050293
training step: 25960, total_loss: 4.261140823364258
training step: 25961, total_loss: 4.850910663604736
training step: 25962, total_loss: 3.6413755416870117
training step: 25963, total_loss: 3.4616124629974365
training step: 25964, total_loss: 1.210858941078186
training step: 25965, total_loss: 3.7085509300231934
training step: 25966, total_loss: 0.967102587223053
training step: 25967, total_loss: 5.457190990447998
training step: 25968, total_loss: 5.41060733795166
training step: 25969, total_loss: 5.531981468200684
training step: 25970, total_loss: 2.817214012145996
training step: 25971, total_loss: 4.685107231140137
training step: 25972, total_loss: 5.097230911254883
training step: 25973, total_loss: 4.526448726654053
training step: 25974, total_loss: 5.489007949829102
training step: 25975, total_loss: 3.6570992469787598
training step: 25976, total_loss: 5.250133514404297
training step: 25977, total_loss: 3.899142265319824
training step: 25978, total_loss: 4.548151969909668
training step: 25979, total_loss: 5.0465898513793945
training step: 25980, total_loss: 3.2476906776428223
training step: 25981, total_loss: 4.402661323547363
training step: 25982, total_loss: 4.487635612487793
training step: 25983, total_loss: 4.9212799072265625
training step: 25984, total_loss: 2.5522398948669434
training step: 25985, total_loss: 4.5318169593811035
training step: 25986, total_loss: 4.9909348487854
training step: 25987, total_loss: 4.484457969665527
training step: 25988, total_loss: 3.578826904296875
training step: 25989, total_loss: 5.546584129333496
training step: 25990, total_loss: 4.908649444580078
training step: 25991, total_loss: 5.709321975708008
training step: 25992, total_loss: 4.205738544464111
training step: 25993, total_loss: 2.7282750606536865
training step: 25994, total_loss: 3.3367791175842285
training step: 25995, total_loss: 3.837782144546509
training step: 25996, total_loss: 5.399351119995117
training step: 25997, total_loss: 4.675554275512695
training step: 25998, total_loss: 4.641355514526367
training step: 25999, total_loss: 4.214735507965088
training step: 26000, total_loss: 5.5230865478515625
training step: 26001, total_loss: 4.805643558502197
training step: 26002, total_loss: 4.3833818435668945
training step: 26003, total_loss: 5.218616485595703
training step: 26004, total_loss: 4.164921760559082
training step: 26005, total_loss: 4.548425197601318
training step: 26006, total_loss: 4.918546676635742
training step: 26007, total_loss: 3.4233036041259766
training step: 26008, total_loss: 5.21519660949707
training step: 26009, total_loss: 4.751106262207031
training step: 26010, total_loss: 3.2299742698669434
training step: 26011, total_loss: 3.3060927391052246
training step: 26012, total_loss: 1.4019839763641357
training step: 26013, total_loss: 5.44281005859375
training step: 26014, total_loss: 4.065823554992676
training step: 26015, total_loss: 4.868090629577637
training step: 26016, total_loss: 3.767483711242676
training step: 26017, total_loss: 3.866786479949951
training step: 26018, total_loss: 3.3542470932006836
training step: 26019, total_loss: 3.6564409732818604
training step: 26020, total_loss: 4.339225769042969
training step: 26021, total_loss: 3.2794198989868164
training step: 26022, total_loss: 3.1405162811279297
training step: 26023, total_loss: 3.8125505447387695
training step: 26024, total_loss: 6.530566215515137
training step: 26025, total_loss: 3.3954858779907227
training step: 26026, total_loss: 5.139418601989746
training step: 26027, total_loss: 4.728423595428467
training step: 26028, total_loss: 6.607285022735596
training step: 26029, total_loss: 4.852291107177734
training step: 26030, total_loss: 5.118098258972168
training step: 26031, total_loss: 5.42887020111084
training step: 26032, total_loss: 4.344357490539551
training step: 26033, total_loss: 6.4458417892456055
training step: 26034, total_loss: 3.423797130584717
training step: 26035, total_loss: 0.8249154090881348
training step: 26036, total_loss: 5.4157795906066895
training step: 26037, total_loss: 3.1328415870666504
training step: 26038, total_loss: 5.088263034820557
training step: 26039, total_loss: 5.185089111328125
training step: 26040, total_loss: 0.9825505018234253
training step: 26041, total_loss: 4.6912031173706055
training step: 26042, total_loss: 2.894932746887207
training step: 26043, total_loss: 5.3648552894592285
training step: 26044, total_loss: 6.303067207336426
training step: 26045, total_loss: 4.058421611785889
training step: 26046, total_loss: 4.276076316833496
training step: 26047, total_loss: 4.105771064758301
training step: 26048, total_loss: 4.4070353507995605
training step: 26049, total_loss: 3.228848457336426
training step: 26050, total_loss: 5.106396675109863
training step: 26051, total_loss: 4.685783386230469
training step: 26052, total_loss: 3.8259592056274414
training step: 26053, total_loss: 4.354866027832031
training step: 26054, total_loss: 5.829481601715088
training step: 26055, total_loss: 4.319944381713867
training step: 26056, total_loss: 7.102184295654297
training step: 26057, total_loss: 4.302585601806641
training step: 26058, total_loss: 4.568513870239258
training step: 26059, total_loss: 5.217163562774658
training step: 26060, total_loss: 2.002441167831421
training step: 26061, total_loss: 6.655034065246582
training step: 26062, total_loss: 4.211032867431641
training step: 26063, total_loss: 4.773702621459961
training step: 26064, total_loss: 3.6598167419433594
training step: 26065, total_loss: 2.761497974395752
training step: 26066, total_loss: 1.0032265186309814
training step: 26067, total_loss: 2.4709420204162598
training step: 26068, total_loss: 3.6519744396209717
training step: 26069, total_loss: 3.3684167861938477
training step: 26070, total_loss: 4.16728401184082
training step: 26071, total_loss: 5.3233513832092285
training step: 26072, total_loss: 5.261913299560547
training step: 26073, total_loss: 4.448028564453125
training step: 26074, total_loss: 4.545626640319824
training step: 26075, total_loss: 3.22841477394104
training step: 26076, total_loss: 4.443459510803223
training step: 26077, total_loss: 3.9018421173095703
training step: 26078, total_loss: 3.846876382827759
training step: 26079, total_loss: 4.033849239349365
training step: 26080, total_loss: 4.699028015136719
training step: 26081, total_loss: 3.9624338150024414
training step: 26082, total_loss: 4.117070198059082
training step: 26083, total_loss: 3.774853229522705
training step: 26084, total_loss: 5.019789695739746
training step: 26085, total_loss: 4.3138885498046875
training step: 26086, total_loss: 2.7250328063964844
training step: 26087, total_loss: 5.478334903717041
training step: 26088, total_loss: 4.588779449462891
training step: 26089, total_loss: 4.648822784423828
training step: 26090, total_loss: 4.580720901489258
training step: 26091, total_loss: 2.328145980834961
training step: 26092, total_loss: 4.100034713745117
training step: 26093, total_loss: 5.12127685546875
training step: 26094, total_loss: 5.9296345710754395
training step: 26095, total_loss: 5.199028968811035
training step: 26096, total_loss: 5.130885601043701
training step: 26097, total_loss: 2.4347872734069824
training step: 26098, total_loss: 5.726504325866699
training step: 26099, total_loss: 5.425824165344238
training step: 26100, total_loss: 3.283766746520996
training step: 26101, total_loss: 5.256259918212891
training step: 26102, total_loss: 4.7167463302612305
training step: 26103, total_loss: 2.995711326599121
training step: 26104, total_loss: 3.7232086658477783
training step: 26105, total_loss: 5.166092872619629
training step: 26106, total_loss: 4.3934197425842285
training step: 26107, total_loss: 3.4600303173065186
training step: 26108, total_loss: 6.205808162689209
training step: 26109, total_loss: 5.824143409729004
training step: 26110, total_loss: 2.389336585998535
training step: 26111, total_loss: 4.7420334815979
training step: 26112, total_loss: 5.62220573425293
training step: 26113, total_loss: 4.468626022338867
training step: 26114, total_loss: 5.484745025634766
training step: 26115, total_loss: 3.952570915222168
training step: 26116, total_loss: 4.3044843673706055
training step: 26117, total_loss: 4.7664031982421875
training step: 26118, total_loss: 4.327287673950195
training step: 26119, total_loss: 4.014406204223633
training step: 26120, total_loss: 3.962723731994629
training step: 26121, total_loss: 5.029938220977783
training step: 26122, total_loss: 5.130178451538086
training step: 26123, total_loss: 3.9166131019592285
training step: 26124, total_loss: 6.046429634094238
training step: 26125, total_loss: 6.162961006164551
training step: 26126, total_loss: 5.3099517822265625
training step: 26127, total_loss: 3.529416084289551
training step: 26128, total_loss: 4.249490261077881
training step: 26129, total_loss: 4.5099921226501465
training step: 26130, total_loss: 4.151932716369629
training step: 26131, total_loss: 4.157371520996094
training step: 26132, total_loss: 4.288731575012207
training step: 26133, total_loss: 5.016759872436523
training step: 26134, total_loss: 3.807251453399658
training step: 26135, total_loss: 5.135831832885742
training step: 26136, total_loss: 3.1080386638641357
training step: 26137, total_loss: 4.346705436706543
training step: 26138, total_loss: 5.153349876403809
training step: 26139, total_loss: 3.798110008239746
training step: 26140, total_loss: 2.9522576332092285
training step: 26141, total_loss: 3.4612903594970703
training step: 26142, total_loss: 4.513097286224365
training step: 26143, total_loss: 3.3717284202575684
training step: 26144, total_loss: 5.903923511505127
training step: 26145, total_loss: 3.817506790161133
training step: 26146, total_loss: 5.237897872924805
training step: 26147, total_loss: 2.4813146591186523
training step: 26148, total_loss: 4.895216941833496
training step: 26149, total_loss: 2.4785361289978027
training step: 26150, total_loss: 4.301848411560059
training step: 26151, total_loss: 3.7904536724090576
training step: 26152, total_loss: 3.301867961883545
training step: 26153, total_loss: 6.423605442047119
training step: 26154, total_loss: 5.593935012817383
training step: 26155, total_loss: 4.9525580406188965
training step: 26156, total_loss: 6.616272449493408
training step: 26157, total_loss: 4.057072639465332
training step: 26158, total_loss: 6.002533912658691
training step: 26159, total_loss: 2.563094139099121
training step: 26160, total_loss: 1.0274827480316162
training step: 26161, total_loss: 5.973672389984131
training step: 26162, total_loss: 4.914742469787598
training step: 26163, total_loss: 2.9430785179138184
training step: 26164, total_loss: 3.67294979095459
training step: 26165, total_loss: 3.5078508853912354
training step: 26166, total_loss: 4.880470275878906
training step: 26167, total_loss: 4.810856819152832
training step: 26168, total_loss: 4.756547927856445
training step: 26169, total_loss: 5.167633533477783
training step: 26170, total_loss: 5.356159210205078
training step: 26171, total_loss: 4.216778755187988
training step: 26172, total_loss: 3.971228837966919
training step: 26173, total_loss: 3.57089900970459
training step: 26174, total_loss: 4.907530784606934
training step: 26175, total_loss: 4.953339099884033
training step: 26176, total_loss: 4.776674270629883
training step: 26177, total_loss: 3.5748276710510254
training step: 26178, total_loss: 6.150766849517822
training step: 26179, total_loss: 4.526823997497559
training step: 26180, total_loss: 5.527800559997559
training step: 26181, total_loss: 3.9796335697174072
training step: 26182, total_loss: 5.206844329833984
training step: 26183, total_loss: 2.8337578773498535
training step: 26184, total_loss: 5.080600738525391
training step: 26185, total_loss: 4.507772445678711
training step: 26186, total_loss: 4.133549690246582
training step: 26187, total_loss: 5.112841606140137
training step: 26188, total_loss: 4.697898864746094
training step: 26189, total_loss: 3.6691195964813232
training step: 26190, total_loss: 2.7403342723846436
training step: 26191, total_loss: 3.7051477432250977
training step: 26192, total_loss: 3.657022714614868
training step: 26193, total_loss: 4.346096515655518
training step: 26194, total_loss: 4.8852128982543945
training step: 26195, total_loss: 5.486968994140625
training step: 26196, total_loss: 4.162237644195557
training step: 26197, total_loss: 7.500025749206543
training step: 26198, total_loss: 4.73686408996582
training step: 26199, total_loss: 6.0546650886535645
training step: 26200, total_loss: 2.442064046859741
training step: 26201, total_loss: 4.984729290008545
training step: 26202, total_loss: 4.593311309814453
training step: 26203, total_loss: 5.422610282897949
training step: 26204, total_loss: 4.048884868621826
training step: 26205, total_loss: 3.1598033905029297
training step: 26206, total_loss: 7.742711544036865
training step: 26207, total_loss: 5.215864181518555
training step: 26208, total_loss: 4.1919050216674805
training step: 26209, total_loss: 4.323559284210205
training step: 26210, total_loss: 3.0435752868652344
training step: 26211, total_loss: 4.856722354888916
training step: 26212, total_loss: 5.1866912841796875
training step: 26213, total_loss: 3.6865038871765137
training step: 26214, total_loss: 3.5639100074768066
training step: 26215, total_loss: 5.4253997802734375
training step: 26216, total_loss: 3.4701366424560547
training step: 26217, total_loss: 2.5205371379852295
training step: 26218, total_loss: 4.047946929931641
training step: 26219, total_loss: 5.079676151275635
training step: 26220, total_loss: 3.177384614944458
training step: 26221, total_loss: 6.677735328674316
training step: 26222, total_loss: 4.634439468383789
training step: 26223, total_loss: 4.824388027191162
training step: 26224, total_loss: 4.006107807159424
training step: 26225, total_loss: 4.871695041656494
training step: 26226, total_loss: 5.940452575683594
training step: 26227, total_loss: 6.044790267944336
training step: 26228, total_loss: 2.809678554534912
training step: 26229, total_loss: 4.36324405670166
training step: 26230, total_loss: 3.5858254432678223
training step: 26231, total_loss: 4.821310043334961
training step: 26232, total_loss: 3.775020122528076
training step: 26233, total_loss: 5.545960426330566
training step: 26234, total_loss: 4.6808905601501465
training step: 26235, total_loss: 5.480428695678711
training step: 26236, total_loss: 5.294922828674316
training step: 26237, total_loss: 4.763211727142334
training step: 26238, total_loss: 4.17092227935791
training step: 26239, total_loss: 4.391643047332764
training step: 26240, total_loss: 4.5628252029418945
training step: 26241, total_loss: 4.824428558349609
training step: 26242, total_loss: 2.067363739013672
training step: 26243, total_loss: 2.7717278003692627
training step: 26244, total_loss: 4.488667011260986
training step: 26245, total_loss: 3.058255672454834
training step: 26246, total_loss: 4.9184417724609375
training step: 26247, total_loss: 5.076144218444824
training step: 26248, total_loss: 5.517253875732422
training step: 26249, total_loss: 6.80905818939209
training step: 26250, total_loss: 4.471164703369141
training step: 26251, total_loss: 1.8132455348968506
training step: 26252, total_loss: 5.070989608764648
training step: 26253, total_loss: 5.227536678314209
training step: 26254, total_loss: 4.68019962310791
training step: 26255, total_loss: 3.8626599311828613
training step: 26256, total_loss: 4.728527069091797
training step: 26257, total_loss: 3.724435329437256
training step: 26258, total_loss: 5.587259292602539
training step: 26259, total_loss: 2.8870766162872314
training step: 26260, total_loss: 4.356713771820068
training step: 26261, total_loss: 5.184926986694336
training step: 26262, total_loss: 5.827937126159668
training step: 26263, total_loss: 2.792755603790283
training step: 26264, total_loss: 4.041587829589844
training step: 26265, total_loss: 4.3663330078125
training step: 26266, total_loss: 3.448228597640991
training step: 26267, total_loss: 4.469212532043457
training step: 26268, total_loss: 0.8924241065979004
training step: 26269, total_loss: 3.2117035388946533
training step: 26270, total_loss: 4.979981422424316
training step: 26271, total_loss: 4.916390419006348
training step: 26272, total_loss: 6.506903648376465
training step: 26273, total_loss: 3.9865951538085938
training step: 26274, total_loss: 3.845583200454712
training step: 26275, total_loss: 3.118769645690918
training step: 26276, total_loss: 5.00452995300293
training step: 26277, total_loss: 4.527762413024902
training step: 26278, total_loss: 3.9017863273620605
training step: 26279, total_loss: 4.875677108764648
training step: 26280, total_loss: 5.387036323547363
training step: 26281, total_loss: 5.133001804351807
training step: 26282, total_loss: 4.096433639526367
training step: 26283, total_loss: 5.237103462219238
training step: 26284, total_loss: 4.2494401931762695
training step: 26285, total_loss: 3.484225034713745
training step: 26286, total_loss: 4.220369338989258
training step: 26287, total_loss: 4.102144241333008
training step: 26288, total_loss: 5.950109481811523
training step: 26289, total_loss: 4.688529014587402
training step: 26290, total_loss: 5.3783063888549805
training step: 26291, total_loss: 2.614528179168701
training step: 26292, total_loss: 2.820988416671753
training step: 26293, total_loss: 4.2028093338012695
training step: 26294, total_loss: 3.9801862239837646
training step: 26295, total_loss: 4.610759258270264
training step: 26296, total_loss: 4.49384069442749
training step: 26297, total_loss: 3.4833297729492188
training step: 26298, total_loss: 4.141604900360107
training step: 26299, total_loss: 4.9068603515625
training step: 26300, total_loss: 4.300332069396973
training step: 26301, total_loss: 5.194344997406006
training step: 26302, total_loss: 5.204707145690918
training step: 26303, total_loss: 4.637359619140625
training step: 26304, total_loss: 3.758068084716797
training step: 26305, total_loss: 5.175724029541016
training step: 26306, total_loss: 5.326143264770508
training step: 26307, total_loss: 4.61021089553833
training step: 26308, total_loss: 3.9253814220428467
training step: 26309, total_loss: 4.503582954406738
training step: 26310, total_loss: 4.322736740112305
training step: 26311, total_loss: 3.7068567276000977
training step: 26312, total_loss: 3.841639518737793
training step: 26313, total_loss: 4.53212833404541
training step: 26314, total_loss: 4.800798416137695
training step: 26315, total_loss: 4.670034885406494
training step: 26316, total_loss: 4.801861763000488
training step: 26317, total_loss: 4.469363212585449
training step: 26318, total_loss: 1.2108268737792969
training step: 26319, total_loss: 3.5026257038116455
training step: 26320, total_loss: 4.094016075134277
training step: 26321, total_loss: 4.032566547393799
training step: 26322, total_loss: 6.271631240844727
training step: 26323, total_loss: 3.422677755355835
training step: 26324, total_loss: 4.316130638122559
training step: 26325, total_loss: 4.495576858520508
training step: 26326, total_loss: 3.7079524993896484
training step: 26327, total_loss: 5.085762977600098
training step: 26328, total_loss: 4.377208232879639
training step: 26329, total_loss: 3.098018169403076
training step: 26330, total_loss: 3.5819623470306396
training step: 26331, total_loss: 3.9022345542907715
training step: 26332, total_loss: 4.197385787963867
training step: 26333, total_loss: 5.01278829574585
training step: 26334, total_loss: 4.154431343078613
training step: 26335, total_loss: 3.0969901084899902
training step: 26336, total_loss: 5.64877462387085
training step: 26337, total_loss: 5.039436340332031
training step: 26338, total_loss: 5.418510437011719
training step: 26339, total_loss: 2.9516944885253906
training step: 26340, total_loss: 3.9315600395202637
training step: 26341, total_loss: 3.9311397075653076
training step: 26342, total_loss: 5.009320259094238
training step: 26343, total_loss: 3.1811976432800293
training step: 26344, total_loss: 6.533566474914551
training step: 26345, total_loss: 5.726091384887695
training step: 26346, total_loss: 3.049973487854004
training step: 26347, total_loss: 2.3749451637268066
training step: 26348, total_loss: 4.202471733093262
training step: 26349, total_loss: 4.1700615882873535
training step: 26350, total_loss: 6.066459655761719
training step: 26351, total_loss: 4.501526832580566
training step: 26352, total_loss: 5.129152297973633
training step: 26353, total_loss: 3.4839720726013184
training step: 26354, total_loss: 5.5500407218933105
training step: 26355, total_loss: 5.88856315612793
training step: 26356, total_loss: 3.4337823390960693
training step: 26357, total_loss: 5.0193257331848145
training step: 26358, total_loss: 5.497488021850586
training step: 26359, total_loss: 6.168595314025879
training step: 26360, total_loss: 4.997196197509766
training step: 26361, total_loss: 3.3756093978881836
training step: 26362, total_loss: 5.027644634246826
training step: 26363, total_loss: 2.9636154174804688
training step: 26364, total_loss: 5.505202293395996
training step: 26365, total_loss: 4.8915228843688965
training step: 26366, total_loss: 2.6877245903015137
training step: 26367, total_loss: 4.457094669342041
training step: 26368, total_loss: 4.610507965087891
training step: 26369, total_loss: 5.1907124519348145
training step: 26370, total_loss: 5.229060649871826
training step: 26371, total_loss: 4.258049011230469
training step: 26372, total_loss: 5.113771915435791
training step: 26373, total_loss: 2.9719247817993164
training step: 26374, total_loss: 1.7164700031280518
training step: 26375, total_loss: 4.640114784240723
training step: 26376, total_loss: 4.268359661102295
training step: 26377, total_loss: 5.159600257873535
training step: 26378, total_loss: 4.2888383865356445
training step: 26379, total_loss: 4.526203155517578
training step: 26380, total_loss: 3.09352707862854
training step: 26381, total_loss: 4.8674774169921875
training step: 26382, total_loss: 3.8382132053375244
training step: 26383, total_loss: 5.119211673736572
training step: 26384, total_loss: 5.58651065826416
training step: 26385, total_loss: 4.550304412841797
training step: 26386, total_loss: 4.2303056716918945
training step: 26387, total_loss: 5.836395263671875
training step: 26388, total_loss: 2.844850540161133
training step: 26389, total_loss: 3.6544606685638428
training step: 26390, total_loss: 5.243161201477051
training step: 26391, total_loss: 3.5462963581085205
training step: 26392, total_loss: 2.5675108432769775
training step: 26393, total_loss: 4.160872936248779
training step: 26394, total_loss: 5.161391258239746
training step: 26395, total_loss: 4.082842826843262
training step: 26396, total_loss: 4.708806037902832
training step: 26397, total_loss: 4.4985175132751465
training step: 26398, total_loss: 5.085092067718506
training step: 26399, total_loss: 3.611534595489502
training step: 26400, total_loss: 4.642289161682129
training step: 26401, total_loss: 4.897546768188477
training step: 26402, total_loss: 4.183215618133545
training step: 26403, total_loss: 4.365509986877441
training step: 26404, total_loss: 2.280287265777588
training step: 26405, total_loss: 4.544972896575928
training step: 26406, total_loss: 5.506702899932861
training step: 26407, total_loss: 4.3574137687683105
training step: 26408, total_loss: 6.134167194366455
training step: 26409, total_loss: 5.200299263000488
training step: 26410, total_loss: 4.893033981323242
training step: 26411, total_loss: 3.904876708984375
training step: 26412, total_loss: 5.09498929977417
training step: 26413, total_loss: 2.506659507751465
training step: 26414, total_loss: 4.8090620040893555
training step: 26415, total_loss: 4.572300910949707
training step: 26416, total_loss: 5.301822662353516
training step: 26417, total_loss: 3.077101707458496
training step: 26418, total_loss: 3.86600399017334
training step: 26419, total_loss: 4.719033718109131
training step: 26420, total_loss: 4.990516662597656
training step: 26421, total_loss: 6.0493483543396
training step: 26422, total_loss: 3.950007200241089
training step: 26423, total_loss: 3.265754222869873
training step: 26424, total_loss: 4.172879219055176
training step: 26425, total_loss: 4.10596227645874
training step: 26426, total_loss: 4.016430854797363
training step: 26427, total_loss: 4.679579734802246
training step: 26428, total_loss: 3.4428234100341797
training step: 26429, total_loss: 5.161561012268066
training step: 26430, total_loss: 3.3797965049743652
training step: 26431, total_loss: 4.1020402908325195
training step: 26432, total_loss: 3.9884119033813477
training step: 26433, total_loss: 4.58251953125
training step: 26434, total_loss: 4.238795280456543
training step: 26435, total_loss: 2.6117804050445557
training step: 26436, total_loss: 4.98823881149292
training step: 26437, total_loss: 5.2473554611206055
training step: 26438, total_loss: 4.976467609405518
training step: 26439, total_loss: 3.6769351959228516
training step: 26440, total_loss: 3.882567882537842
training step: 26441, total_loss: 5.754509925842285
training step: 26442, total_loss: 5.830585956573486
training step: 26443, total_loss: 5.914370536804199
training step: 26444, total_loss: 3.970486640930176
training step: 26445, total_loss: 4.538941383361816
training step: 26446, total_loss: 5.172764778137207
training step: 26447, total_loss: 5.081791400909424
training step: 26448, total_loss: 6.480619430541992
training step: 26449, total_loss: 4.193130016326904
training step: 26450, total_loss: 5.373559951782227
training step: 26451, total_loss: 4.9668049812316895
training step: 26452, total_loss: 4.714765548706055
training step: 26453, total_loss: 1.3148616552352905
training step: 26454, total_loss: 5.582414150238037
training step: 26455, total_loss: 5.072731018066406
training step: 26456, total_loss: 3.44926381111145
training step: 26457, total_loss: 4.108175277709961
training step: 26458, total_loss: 4.672961235046387
training step: 26459, total_loss: 4.503757953643799
training step: 26460, total_loss: 3.4562482833862305
training step: 26461, total_loss: 4.018804550170898
training step: 26462, total_loss: 4.12546443939209
training step: 26463, total_loss: 4.251718521118164
training step: 26464, total_loss: 3.9815616607666016
training step: 26465, total_loss: 5.892035484313965
training step: 26466, total_loss: 2.820347785949707
training step: 26467, total_loss: 4.294405937194824
training step: 26468, total_loss: 4.492046356201172
training step: 26469, total_loss: 4.441243648529053
training step: 26470, total_loss: 3.753020763397217
training step: 26471, total_loss: 4.7371931076049805
training step: 26472, total_loss: 2.675309181213379
training step: 26473, total_loss: 4.991762161254883
training step: 26474, total_loss: 5.7234697341918945
training step: 26475, total_loss: 5.2309160232543945
training step: 26476, total_loss: 5.39995002746582
training step: 26477, total_loss: 4.804080963134766
training step: 26478, total_loss: 3.3164148330688477
training step: 26479, total_loss: 2.7608611583709717
training step: 26480, total_loss: 3.4128684997558594
training step: 26481, total_loss: 4.287959098815918
training step: 26482, total_loss: 3.929208755493164
training step: 26483, total_loss: 2.6660842895507812
training step: 26484, total_loss: 2.6057443618774414
training step: 26485, total_loss: 4.284099102020264
training step: 26486, total_loss: 5.2093000411987305
training step: 26487, total_loss: 4.4061689376831055
training step: 26488, total_loss: 4.3952741622924805
training step: 26489, total_loss: 5.3915510177612305
training step: 26490, total_loss: 4.560186386108398
training step: 26491, total_loss: 5.4696478843688965
training step: 26492, total_loss: 5.398932456970215
training step: 26493, total_loss: 3.064728260040283
training step: 26494, total_loss: 3.873535633087158
training step: 26495, total_loss: 3.2625949382781982
training step: 26496, total_loss: 1.0955731868743896
training step: 26497, total_loss: 5.019931793212891
training step: 26498, total_loss: 5.404577255249023
training step: 26499, total_loss: 3.8246026039123535
training step: 26500, total_loss: 3.0275678634643555
training step: 26501, total_loss: 3.166317939758301
training step: 26502, total_loss: 3.123023509979248
training step: 26503, total_loss: 3.2982850074768066
training step: 26504, total_loss: 4.762955665588379
training step: 26505, total_loss: 5.357059478759766
training step: 26506, total_loss: 4.379739761352539
training step: 26507, total_loss: 5.705530166625977
training step: 26508, total_loss: 4.941169738769531
training step: 26509, total_loss: 4.230508804321289
training step: 26510, total_loss: 5.8272528648376465
training step: 26511, total_loss: 0.6883347034454346
training step: 26512, total_loss: 4.897998809814453
training step: 26513, total_loss: 4.128236770629883
training step: 26514, total_loss: 4.364588260650635
training step: 26515, total_loss: 4.272330284118652
training step: 26516, total_loss: 3.7635741233825684
training step: 26517, total_loss: 4.556427955627441
training step: 26518, total_loss: 3.9748966693878174
training step: 26519, total_loss: 4.24252986907959
training step: 26520, total_loss: 0.7005840539932251
training step: 26521, total_loss: 5.501437664031982
training step: 26522, total_loss: 4.541378021240234
training step: 26523, total_loss: 6.8724870681762695
training step: 26524, total_loss: 4.4535346031188965
training step: 26525, total_loss: 3.669522523880005
training step: 26526, total_loss: 5.081177234649658
training step: 26527, total_loss: 0.6891095042228699
training step: 26528, total_loss: 5.828233242034912
training step: 26529, total_loss: 2.835780143737793
training step: 26530, total_loss: 2.7600760459899902
training step: 26531, total_loss: 3.6129379272460938
training step: 26532, total_loss: 2.265707015991211
training step: 26533, total_loss: 2.161074161529541
training step: 26534, total_loss: 6.920711517333984
training step: 26535, total_loss: 6.418946266174316
training step: 26536, total_loss: 4.682504653930664
training step: 26537, total_loss: 5.359817028045654
training step: 26538, total_loss: 6.35874605178833
training step: 26539, total_loss: 4.444766044616699
training step: 26540, total_loss: 3.7310595512390137
training step: 26541, total_loss: 7.392236232757568
training step: 26542, total_loss: 4.014814376831055
training step: 26543, total_loss: 5.084822177886963
training step: 26544, total_loss: 4.274921417236328
training step: 26545, total_loss: 5.543766975402832
training step: 26546, total_loss: 3.1531424522399902
training step: 26547, total_loss: 4.577504634857178
training step: 26548, total_loss: 4.803752422332764
training step: 26549, total_loss: 2.5575153827667236
training step: 26550, total_loss: 5.682450771331787
training step: 26551, total_loss: 7.522147178649902
training step: 26552, total_loss: 5.096251487731934
training step: 26553, total_loss: 5.170668601989746
training step: 26554, total_loss: 4.1675825119018555
training step: 26555, total_loss: 3.227405071258545
training step: 26556, total_loss: 5.028205871582031
training step: 26557, total_loss: 4.530472278594971
training step: 26558, total_loss: 3.8905482292175293
training step: 26559, total_loss: 4.376565933227539
training step: 26560, total_loss: 5.1755900382995605
training step: 26561, total_loss: 2.0395560264587402
training step: 26562, total_loss: 4.777342796325684
training step: 26563, total_loss: 4.684640407562256
training step: 26564, total_loss: 5.561601638793945
training step: 26565, total_loss: 4.653342247009277
training step: 26566, total_loss: 4.559266090393066
training step: 26567, total_loss: 5.34857177734375
training step: 26568, total_loss: 4.3949360847473145
training step: 26569, total_loss: 4.512763500213623
training step: 26570, total_loss: 4.269167423248291
training step: 26571, total_loss: 4.678094863891602
training step: 26572, total_loss: 4.755008697509766
training step: 26573, total_loss: 5.053157806396484
training step: 26574, total_loss: 4.89200496673584
training step: 26575, total_loss: 4.637714862823486
training step: 26576, total_loss: 5.284767150878906
training step: 26577, total_loss: 4.527467727661133
training step: 26578, total_loss: 4.8719964027404785
training step: 26579, total_loss: 5.91038179397583
training step: 26580, total_loss: 3.5368051528930664
training step: 26581, total_loss: 4.079125881195068
training step: 26582, total_loss: 5.574780464172363
training step: 26583, total_loss: 4.902233600616455
training step: 26584, total_loss: 5.65467643737793
training step: 26585, total_loss: 3.386312484741211
training step: 26586, total_loss: 5.355020523071289
training step: 26587, total_loss: 4.564323425292969
training step: 26588, total_loss: 4.13580846786499
training step: 26589, total_loss: 2.7227444648742676
training step: 26590, total_loss: 5.302443504333496
training step: 26591, total_loss: 5.636407852172852
training step: 26592, total_loss: 2.6789941787719727
training step: 26593, total_loss: 5.118257999420166
training step: 26594, total_loss: 3.7067501544952393
training step: 26595, total_loss: 5.493022918701172
training step: 26596, total_loss: 3.757221221923828
training step: 26597, total_loss: 4.308858871459961
training step: 26598, total_loss: 3.064919948577881
training step: 26599, total_loss: 5.143867492675781
training step: 26600, total_loss: 4.133325576782227
training step: 26601, total_loss: 4.5791473388671875
training step: 26602, total_loss: 2.3539206981658936
training step: 26603, total_loss: 4.918420314788818
training step: 26604, total_loss: 4.985179424285889
training step: 26605, total_loss: 3.157667636871338
training step: 26606, total_loss: 3.124098062515259
training step: 26607, total_loss: 4.133302211761475
training step: 26608, total_loss: 4.106138229370117
training step: 26609, total_loss: 3.4070568084716797
training step: 26610, total_loss: 4.563431739807129
training step: 26611, total_loss: 4.83872127532959
training step: 26612, total_loss: 3.928330898284912
training step: 26613, total_loss: 3.9128689765930176
training step: 26614, total_loss: 4.449398994445801
training step: 26615, total_loss: 4.1354217529296875
training step: 26616, total_loss: 4.964226722717285
training step: 26617, total_loss: 5.134774208068848
training step: 26618, total_loss: 4.407627105712891
training step: 26619, total_loss: 5.3727030754089355
training step: 26620, total_loss: 2.701234817504883
training step: 26621, total_loss: 4.225851058959961
training step: 26622, total_loss: 2.877206325531006
training step: 26623, total_loss: 3.5676498413085938
training step: 26624, total_loss: 4.378506660461426
training step: 26625, total_loss: 3.5929579734802246
training step: 26626, total_loss: 4.51442813873291
training step: 26627, total_loss: 4.609067440032959
training step: 26628, total_loss: 2.714005470275879
training step: 26629, total_loss: 5.1975812911987305
training step: 26630, total_loss: 4.90394401550293
training step: 26631, total_loss: 4.975330352783203
training step: 26632, total_loss: 4.93734073638916
training step: 26633, total_loss: 3.228346824645996
training step: 26634, total_loss: 5.146920204162598
training step: 26635, total_loss: 6.061330795288086
training step: 26636, total_loss: 5.126093864440918
training step: 26637, total_loss: 3.84425687789917
training step: 26638, total_loss: 3.808004856109619
training step: 26639, total_loss: 2.54579758644104
training step: 26640, total_loss: 2.55631160736084
training step: 26641, total_loss: 6.3871283531188965
training step: 26642, total_loss: 5.885684013366699
training step: 26643, total_loss: 3.5597596168518066
training step: 26644, total_loss: 3.689929485321045
training step: 26645, total_loss: 4.398958206176758
training step: 26646, total_loss: 5.243171691894531
training step: 26647, total_loss: 5.1267218589782715
training step: 26648, total_loss: 4.548636436462402
training step: 26649, total_loss: 3.009658098220825
training step: 26650, total_loss: 4.781019687652588
training step: 26651, total_loss: 4.055059432983398
training step: 26652, total_loss: 6.30446720123291
training step: 26653, total_loss: 4.647810935974121
training step: 26654, total_loss: 3.424419403076172
training step: 26655, total_loss: 5.007297515869141
training step: 26656, total_loss: 3.8817873001098633
training step: 26657, total_loss: 4.3398542404174805
training step: 26658, total_loss: 2.5771255493164062
training step: 26659, total_loss: 4.865210056304932
training step: 26660, total_loss: 4.07704496383667
training step: 26661, total_loss: 4.468388080596924
training step: 26662, total_loss: 4.227841854095459
training step: 26663, total_loss: 4.381511688232422
training step: 26664, total_loss: 4.423363208770752
training step: 26665, total_loss: 4.378293991088867
training step: 26666, total_loss: 4.8940863609313965
training step: 26667, total_loss: 4.018671035766602
training step: 26668, total_loss: 6.3681640625
training step: 26669, total_loss: 4.997612953186035
training step: 26670, total_loss: 3.273564338684082
training step: 26671, total_loss: 4.143207550048828
training step: 26672, total_loss: 3.1142683029174805
training step: 26673, total_loss: 4.775701522827148
training step: 26674, total_loss: 2.8046956062316895
training step: 26675, total_loss: 5.052703380584717
training step: 26676, total_loss: 5.694182395935059
training step: 26677, total_loss: 5.549554824829102
training step: 26678, total_loss: 5.087294578552246
training step: 26679, total_loss: 4.337089538574219
training step: 26680, total_loss: 4.572919845581055
training step: 26681, total_loss: 4.469850063323975
training step: 26682, total_loss: 4.378196716308594
training step: 26683, total_loss: 5.138660430908203
training step: 26684, total_loss: 4.206805229187012
training step: 26685, total_loss: 4.296780586242676
training step: 26686, total_loss: 3.3196330070495605
training step: 26687, total_loss: 2.9200222492218018
training step: 26688, total_loss: 5.512704849243164
training step: 26689, total_loss: 4.21454381942749
training step: 26690, total_loss: 4.238802909851074
training step: 26691, total_loss: 4.360652923583984
training step: 26692, total_loss: 5.369656085968018
training step: 26693, total_loss: 4.659895896911621
training step: 26694, total_loss: 4.4826273918151855
training step: 26695, total_loss: 4.869596481323242
training step: 26696, total_loss: 1.7459107637405396
training step: 26697, total_loss: 3.512282371520996
training step: 26698, total_loss: 5.029910087585449
training step: 26699, total_loss: 3.327023506164551
training step: 26700, total_loss: 5.512179851531982
training step: 26701, total_loss: 4.616368293762207
training step: 26702, total_loss: 3.602828025817871
training step: 26703, total_loss: 4.656582355499268
training step: 26704, total_loss: 4.195390224456787
training step: 26705, total_loss: 4.767590522766113
training step: 26706, total_loss: 4.610207557678223
training step: 26707, total_loss: 5.400173664093018
training step: 26708, total_loss: 4.517237663269043
training step: 26709, total_loss: 2.793797492980957
training step: 26710, total_loss: 4.695390701293945
training step: 26711, total_loss: 4.03920316696167
training step: 26712, total_loss: 5.230635643005371
training step: 26713, total_loss: 2.9017910957336426
training step: 26714, total_loss: 4.374176025390625
training step: 26715, total_loss: 4.693653106689453
training step: 26716, total_loss: 4.080294609069824
training step: 26717, total_loss: 6.292621612548828
training step: 26718, total_loss: 4.3982696533203125
training step: 26719, total_loss: 6.190774917602539
training step: 26720, total_loss: 3.426774501800537
training step: 26721, total_loss: 3.347804546356201
training step: 26722, total_loss: 3.381960868835449
training step: 26723, total_loss: 4.692010402679443
training step: 26724, total_loss: 1.0706284046173096
training step: 26725, total_loss: 4.064157485961914
training step: 26726, total_loss: 4.487665176391602
training step: 26727, total_loss: 5.114117622375488
training step: 26728, total_loss: 4.221840858459473
training step: 26729, total_loss: 4.375643253326416
training step: 26730, total_loss: 5.61884880065918
training step: 26731, total_loss: 4.932116508483887
training step: 26732, total_loss: 4.8780622482299805
training step: 26733, total_loss: 4.4639997482299805
training step: 26734, total_loss: 4.933600425720215
training step: 26735, total_loss: 6.503815174102783
training step: 26736, total_loss: 3.930130958557129
training step: 26737, total_loss: 4.690502166748047
training step: 26738, total_loss: 3.276649236679077
training step: 26739, total_loss: 5.126337051391602
training step: 26740, total_loss: 5.807806015014648
training step: 26741, total_loss: 7.137925624847412
training step: 26742, total_loss: 4.982987880706787
training step: 26743, total_loss: 5.587202072143555
training step: 26744, total_loss: 4.28028678894043
training step: 26745, total_loss: 4.193855285644531
training step: 26746, total_loss: 4.123630523681641
training step: 26747, total_loss: 4.69007682800293
training step: 26748, total_loss: 2.659477949142456
training step: 26749, total_loss: 5.580681800842285
training step: 26750, total_loss: 4.181736946105957
training step: 26751, total_loss: 3.075819730758667
training step: 26752, total_loss: 5.612375736236572
training step: 26753, total_loss: 4.947539329528809
training step: 26754, total_loss: 6.461330413818359
training step: 26755, total_loss: 5.858101844787598
training step: 26756, total_loss: 3.078587055206299
training step: 26757, total_loss: 5.323775768280029
training step: 26758, total_loss: 4.698203086853027
training step: 26759, total_loss: 4.120403289794922
training step: 26760, total_loss: 3.399430513381958
training step: 26761, total_loss: 4.650203704833984
training step: 26762, total_loss: 5.293435096740723
training step: 26763, total_loss: 3.928835391998291
training step: 26764, total_loss: 1.2394306659698486
training step: 26765, total_loss: 4.111529350280762
training step: 26766, total_loss: 3.1943182945251465
training step: 26767, total_loss: 4.266165733337402
training step: 26768, total_loss: 5.020437240600586
training step: 26769, total_loss: 4.173923492431641
training step: 26770, total_loss: 4.636590003967285
training step: 26771, total_loss: 3.9013452529907227
training step: 26772, total_loss: 4.255965232849121
training step: 26773, total_loss: 4.354340553283691
training step: 26774, total_loss: 3.8400955200195312
training step: 26775, total_loss: 4.655786037445068
training step: 26776, total_loss: 4.890471458435059
training step: 26777, total_loss: 7.4017791748046875
training step: 26778, total_loss: 2.982039451599121
training step: 26779, total_loss: 1.396424412727356
training step: 26780, total_loss: 4.251686096191406
training step: 26781, total_loss: 2.9140515327453613
training step: 26782, total_loss: 4.437816143035889
training step: 26783, total_loss: 4.821752548217773
training step: 26784, total_loss: 4.071433067321777
training step: 26785, total_loss: 3.524930477142334
training step: 26786, total_loss: 5.1382246017456055
training step: 26787, total_loss: 5.394294738769531
training step: 26788, total_loss: 3.562816619873047
training step: 26789, total_loss: 3.902162551879883
training step: 26790, total_loss: 4.241067886352539
training step: 26791, total_loss: 5.043201446533203
training step: 26792, total_loss: 6.815106391906738
training step: 26793, total_loss: 5.305846691131592
training step: 26794, total_loss: 4.745951175689697
training step: 26795, total_loss: 5.458191871643066
training step: 26796, total_loss: 4.428154468536377
training step: 26797, total_loss: 3.5624938011169434
training step: 26798, total_loss: 1.1177016496658325
training step: 26799, total_loss: 4.6540141105651855
training step: 26800, total_loss: 4.337606430053711
training step: 26801, total_loss: 4.603674411773682
training step: 26802, total_loss: 5.413508415222168
training step: 26803, total_loss: 3.0461831092834473
training step: 26804, total_loss: 4.321115016937256
training step: 26805, total_loss: 4.366920471191406
training step: 26806, total_loss: 2.3152523040771484
training step: 26807, total_loss: 6.299183368682861
training step: 26808, total_loss: 4.2395100593566895
training step: 26809, total_loss: 2.9024064540863037
training step: 26810, total_loss: 2.3704938888549805
training step: 26811, total_loss: 4.201769828796387
training step: 26812, total_loss: 5.094562530517578
training step: 26813, total_loss: 4.272565841674805
training step: 26814, total_loss: 4.460663795471191
training step: 26815, total_loss: 2.7534477710723877
training step: 26816, total_loss: 5.012854099273682
training step: 26817, total_loss: 3.558903455734253
training step: 26818, total_loss: 4.502188682556152
training step: 26819, total_loss: 3.9384145736694336
training step: 26820, total_loss: 3.1749658584594727
training step: 26821, total_loss: 5.102155685424805
training step: 26822, total_loss: 5.662171363830566
training step: 26823, total_loss: 4.634217262268066
training step: 26824, total_loss: 4.52487850189209
training step: 26825, total_loss: 4.892209529876709
training step: 26826, total_loss: 3.3642020225524902
training step: 26827, total_loss: 4.195412635803223
training step: 26828, total_loss: 4.576722145080566
training step: 26829, total_loss: 4.866413116455078
training step: 26830, total_loss: 3.2520225048065186
training step: 26831, total_loss: 5.674962997436523
training step: 26832, total_loss: 5.038792610168457
training step: 26833, total_loss: 2.5821962356567383
training step: 26834, total_loss: 5.692305564880371
training step: 26835, total_loss: 4.581713676452637
training step: 26836, total_loss: 3.8967881202697754
training step: 26837, total_loss: 1.4651994705200195
training step: 26838, total_loss: 3.811479091644287
training step: 26839, total_loss: 4.845653057098389
training step: 26840, total_loss: 3.5006461143493652
training step: 26841, total_loss: 4.749494552612305
training step: 26842, total_loss: 3.265965461730957
training step: 26843, total_loss: 5.856104373931885
training step: 26844, total_loss: 4.555257797241211
training step: 26845, total_loss: 6.359776496887207
training step: 26846, total_loss: 4.291001319885254
training step: 26847, total_loss: 1.208997368812561
training step: 26848, total_loss: 4.165045738220215
training step: 26849, total_loss: 3.8949148654937744
training step: 26850, total_loss: 3.879701614379883
training step: 26851, total_loss: 2.767829179763794
training step: 26852, total_loss: 1.1026002168655396
training step: 26853, total_loss: 5.1600470542907715
training step: 26854, total_loss: 6.401139259338379
training step: 26855, total_loss: 4.454160213470459
training step: 26856, total_loss: 4.11578893661499
training step: 26857, total_loss: 5.841403007507324
training step: 26858, total_loss: 3.1667001247406006
training step: 26859, total_loss: 5.1065168380737305
training step: 26860, total_loss: 5.333505630493164
training step: 26861, total_loss: 5.0779547691345215
training step: 26862, total_loss: 3.910404682159424
training step: 26863, total_loss: 4.0868377685546875
training step: 26864, total_loss: 6.595317840576172
training step: 26865, total_loss: 4.214786529541016
training step: 26866, total_loss: 4.448920249938965
training step: 26867, total_loss: 4.093918323516846
training step: 26868, total_loss: 2.399557590484619
training step: 26869, total_loss: 3.7390384674072266
training step: 26870, total_loss: 4.3893585205078125
training step: 26871, total_loss: 5.333221435546875
training step: 26872, total_loss: 4.0221757888793945
training step: 26873, total_loss: 5.972107410430908
training step: 26874, total_loss: 4.390419006347656
training step: 26875, total_loss: 4.379436016082764
training step: 26876, total_loss: 5.012381553649902
training step: 26877, total_loss: 1.8589937686920166
training step: 26878, total_loss: 4.312798500061035
training step: 26879, total_loss: 2.609640598297119
training step: 26880, total_loss: 3.697930335998535
training step: 26881, total_loss: 4.858362197875977
training step: 26882, total_loss: 5.384370803833008
training step: 26883, total_loss: 4.383682727813721
training step: 26884, total_loss: 5.577932357788086
training step: 26885, total_loss: 6.047894477844238
training step: 26886, total_loss: 5.097088813781738
training step: 26887, total_loss: 5.178613185882568
training step: 26888, total_loss: 3.7153992652893066
training step: 26889, total_loss: 3.9943127632141113
training step: 26890, total_loss: 5.594492435455322
training step: 26891, total_loss: 2.3255293369293213
training step: 26892, total_loss: 3.627126932144165
training step: 26893, total_loss: 5.327821731567383
training step: 26894, total_loss: 4.34652042388916
training step: 26895, total_loss: 4.917133331298828
training step: 26896, total_loss: 4.637937545776367
training step: 26897, total_loss: 0.8474319577217102
training step: 26898, total_loss: 4.683433532714844
training step: 26899, total_loss: 5.1632843017578125
training step: 26900, total_loss: 3.951019763946533
training step: 26901, total_loss: 5.216568946838379
training step: 26902, total_loss: 4.942221641540527
training step: 26903, total_loss: 5.011859893798828
training step: 26904, total_loss: 4.805148124694824
training step: 26905, total_loss: 4.780810356140137
training step: 26906, total_loss: 5.806008338928223
training step: 26907, total_loss: 3.8297033309936523
training step: 26908, total_loss: 3.6287002563476562
training step: 26909, total_loss: 4.0411882400512695
training step: 26910, total_loss: 4.966347694396973
training step: 26911, total_loss: 5.341207504272461
training step: 26912, total_loss: 4.428681373596191
training step: 26913, total_loss: 4.331061363220215
training step: 26914, total_loss: 4.205882549285889
training step: 26915, total_loss: 0.9661723971366882
training step: 26916, total_loss: 5.05809211730957
training step: 26917, total_loss: 5.230797290802002
training step: 26918, total_loss: 4.247692584991455
training step: 26919, total_loss: 2.897031307220459
training step: 26920, total_loss: 3.6302998065948486
training step: 26921, total_loss: 4.976756572723389
training step: 26922, total_loss: 5.523670196533203
training step: 26923, total_loss: 1.0455576181411743
training step: 26924, total_loss: 4.6147050857543945
training step: 26925, total_loss: 5.485306739807129
training step: 26926, total_loss: 4.9281511306762695
training step: 26927, total_loss: 4.76506233215332
training step: 26928, total_loss: 3.8448452949523926
training step: 26929, total_loss: 4.72144889831543
training step: 26930, total_loss: 5.032270431518555
training step: 26931, total_loss: 3.295860528945923
training step: 26932, total_loss: 4.674152374267578
training step: 26933, total_loss: 4.924299716949463
training step: 26934, total_loss: 3.7973039150238037
training step: 26935, total_loss: 5.205435752868652
training step: 26936, total_loss: 2.871295213699341
training step: 26937, total_loss: 4.334452152252197
training step: 26938, total_loss: 4.374405860900879
training step: 26939, total_loss: 2.3082900047302246
training step: 26940, total_loss: 4.398303031921387
training step: 26941, total_loss: 4.100067138671875
training step: 26942, total_loss: 3.736363649368286
training step: 26943, total_loss: 4.4414591789245605
training step: 26944, total_loss: 4.134029865264893
training step: 26945, total_loss: 2.8621277809143066
training step: 26946, total_loss: 3.660160541534424
training step: 26947, total_loss: 4.94333553314209
training step: 26948, total_loss: 3.91912841796875
training step: 26949, total_loss: 3.2990498542785645
training step: 26950, total_loss: 4.0705766677856445
training step: 26951, total_loss: 2.162975549697876
training step: 26952, total_loss: 5.10004186630249
training step: 26953, total_loss: 2.377044677734375
training step: 26954, total_loss: 6.405508041381836
training step: 26955, total_loss: 5.1466755867004395
training step: 26956, total_loss: 3.4655652046203613
training step: 26957, total_loss: 5.62434196472168
training step: 26958, total_loss: 3.83223295211792
training step: 26959, total_loss: 5.601398468017578
training step: 26960, total_loss: 4.892719268798828
training step: 26961, total_loss: 2.075737476348877
training step: 26962, total_loss: 6.90130090713501
training step: 26963, total_loss: 5.079180717468262
training step: 26964, total_loss: 4.380589962005615
training step: 26965, total_loss: 4.087371826171875
training step: 26966, total_loss: 4.730175495147705
training step: 26967, total_loss: 4.770056247711182
training step: 26968, total_loss: 5.486894607543945
training step: 26969, total_loss: 4.255664825439453
training step: 26970, total_loss: 4.567457675933838
training step: 26971, total_loss: 4.755506992340088
training step: 26972, total_loss: 4.226393699645996
training step: 26973, total_loss: 5.201766490936279
training step: 26974, total_loss: 5.513082504272461
training step: 26975, total_loss: 4.826839447021484
training step: 26976, total_loss: 3.116163730621338
training step: 26977, total_loss: 5.116081237792969
training step: 26978, total_loss: 5.286635398864746
training step: 26979, total_loss: 4.134827613830566
training step: 26980, total_loss: 5.37998628616333
training step: 26981, total_loss: 6.015479564666748
training step: 26982, total_loss: 3.78560733795166
training step: 26983, total_loss: 4.240609645843506
training step: 26984, total_loss: 4.059223175048828
training step: 26985, total_loss: 5.042551040649414
training step: 26986, total_loss: 3.7036561965942383
training step: 26987, total_loss: 2.8912320137023926
training step: 26988, total_loss: 4.043977737426758
training step: 26989, total_loss: 1.1176064014434814
training step: 26990, total_loss: 3.845172882080078
training step: 26991, total_loss: 2.6393556594848633
training step: 26992, total_loss: 4.305054664611816
training step: 26993, total_loss: 1.0009872913360596
training step: 26994, total_loss: 5.722475051879883
training step: 26995, total_loss: 4.647978782653809
training step: 26996, total_loss: 5.0165252685546875
training step: 26997, total_loss: 5.509461402893066
training step: 26998, total_loss: 3.044018268585205
training step: 26999, total_loss: 4.029531478881836
training step: 27000, total_loss: 5.103808403015137
training step: 27001, total_loss: 5.630930423736572
training step: 27002, total_loss: 4.612734794616699
training step: 27003, total_loss: 3.7411670684814453
training step: 27004, total_loss: 3.879696846008301
training step: 27005, total_loss: 5.459364891052246
training step: 27006, total_loss: 6.049964904785156
training step: 27007, total_loss: 4.146734237670898
training step: 27008, total_loss: 0.7649198770523071
training step: 27009, total_loss: 6.714433193206787
training step: 27010, total_loss: 6.741082191467285
training step: 27011, total_loss: 4.985795497894287
training step: 27012, total_loss: 5.499107360839844
training step: 27013, total_loss: 3.993271589279175
training step: 27014, total_loss: 2.455540418624878
training step: 27015, total_loss: 3.9769392013549805
training step: 27016, total_loss: 3.389634847640991
training step: 27017, total_loss: 5.660862922668457
training step: 27018, total_loss: 1.743997573852539
training step: 27019, total_loss: 4.8231000900268555
training step: 27020, total_loss: 4.4365034103393555
training step: 27021, total_loss: 4.973363876342773
training step: 27022, total_loss: 5.771420001983643
training step: 27023, total_loss: 4.917405128479004
training step: 27024, total_loss: 4.927143096923828
training step: 27025, total_loss: 4.475139617919922
training step: 27026, total_loss: 4.8275346755981445
training step: 27027, total_loss: 4.535694122314453
training step: 27028, total_loss: 5.037212371826172
training step: 27029, total_loss: 5.143464088439941
training step: 27030, total_loss: 3.4229626655578613
training step: 27031, total_loss: 5.404321193695068
training step: 27032, total_loss: 3.4578709602355957
training step: 27033, total_loss: 4.759478569030762
training step: 27034, total_loss: 4.240483283996582
training step: 27035, total_loss: 3.9828786849975586
training step: 27036, total_loss: 3.9438438415527344
training step: 27037, total_loss: 3.662343740463257
training step: 27038, total_loss: 6.260553359985352
training step: 27039, total_loss: 4.948086261749268
training step: 27040, total_loss: 5.920387268066406
training step: 27041, total_loss: 4.310641765594482
training step: 27042, total_loss: 4.155415058135986
training step: 27043, total_loss: 4.4777607917785645
training step: 27044, total_loss: 2.6266376972198486
training step: 27045, total_loss: 5.863048553466797
training step: 27046, total_loss: 5.062373161315918
training step: 27047, total_loss: 6.285910129547119
training step: 27048, total_loss: 5.4113545417785645
training step: 27049, total_loss: 2.8666927814483643
training step: 27050, total_loss: 3.904484272003174
training step: 27051, total_loss: 4.667342185974121
training step: 27052, total_loss: 3.1410999298095703
training step: 27053, total_loss: 4.77877140045166
training step: 27054, total_loss: 3.844090461730957
training step: 27055, total_loss: 5.4805498123168945
training step: 27056, total_loss: 0.9878411889076233
training step: 27057, total_loss: 5.212234020233154
training step: 27058, total_loss: 1.3628058433532715
training step: 27059, total_loss: 3.167850971221924
training step: 27060, total_loss: 3.179819107055664
training step: 27061, total_loss: 0.9747911691665649
training step: 27062, total_loss: 4.265213966369629
training step: 27063, total_loss: 2.9456820487976074
training step: 27064, total_loss: 4.543179988861084
training step: 27065, total_loss: 4.091473579406738
training step: 27066, total_loss: 4.882080078125
training step: 27067, total_loss: 5.605623245239258
training step: 27068, total_loss: 5.250759601593018
training step: 27069, total_loss: 4.9961256980896
training step: 27070, total_loss: 5.941989898681641
training step: 27071, total_loss: 4.384068012237549
training step: 27072, total_loss: 3.456047534942627
training step: 27073, total_loss: 5.437280654907227
training step: 27074, total_loss: 5.681516170501709
training step: 27075, total_loss: 4.551741600036621
training step: 27076, total_loss: 3.472200393676758
training step: 27077, total_loss: 3.9625396728515625
training step: 27078, total_loss: 4.015656471252441
training step: 27079, total_loss: 5.671923637390137
training step: 27080, total_loss: 4.5438714027404785
training step: 27081, total_loss: 3.9027719497680664
training step: 27082, total_loss: 4.543702602386475
training step: 27083, total_loss: 5.779968738555908
training step: 27084, total_loss: 5.558861255645752
training step: 27085, total_loss: 3.8546206951141357
training step: 27086, total_loss: 4.274655342102051
training step: 27087, total_loss: 3.92891526222229
training step: 27088, total_loss: 4.4883928298950195
training step: 27089, total_loss: 3.5707552433013916
training step: 27090, total_loss: 5.345324993133545
training step: 27091, total_loss: 4.737740516662598
training step: 27092, total_loss: 4.947793960571289
training step: 27093, total_loss: 4.913808345794678
training step: 27094, total_loss: 4.2942376136779785
training step: 27095, total_loss: 3.7873435020446777
training step: 27096, total_loss: 4.403231143951416
training step: 27097, total_loss: 3.2075729370117188
training step: 27098, total_loss: 4.851430892944336
training step: 27099, total_loss: 4.59489631652832
training step: 27100, total_loss: 3.255760908126831
training step: 27101, total_loss: 4.487872123718262
training step: 27102, total_loss: 3.9683151245117188
training step: 27103, total_loss: 5.513195991516113
training step: 27104, total_loss: 0.9809799194335938
training step: 27105, total_loss: 4.522622108459473
training step: 27106, total_loss: 0.7881832122802734
training step: 27107, total_loss: 3.3959901332855225
training step: 27108, total_loss: 3.734969139099121
training step: 27109, total_loss: 4.649518966674805
training step: 27110, total_loss: 5.8581037521362305
training step: 27111, total_loss: 3.920018196105957
training step: 27112, total_loss: 4.518258094787598
training step: 27113, total_loss: 5.347040176391602
training step: 27114, total_loss: 4.87739896774292
training step: 27115, total_loss: 4.141304969787598
training step: 27116, total_loss: 3.7496891021728516
training step: 27117, total_loss: 5.632994651794434
training step: 27118, total_loss: 6.010663986206055
training step: 27119, total_loss: 3.987013339996338
training step: 27120, total_loss: 5.762776851654053
training step: 27121, total_loss: 5.325788497924805
training step: 27122, total_loss: 5.244523048400879
training step: 27123, total_loss: 4.994623184204102
training step: 27124, total_loss: 5.081279754638672
training step: 27125, total_loss: 4.621277332305908
training step: 27126, total_loss: 1.0784465074539185
training step: 27127, total_loss: 4.0488762855529785
training step: 27128, total_loss: 4.41331148147583
training step: 27129, total_loss: 3.7403581142425537
training step: 27130, total_loss: 4.881049156188965
training step: 27131, total_loss: 5.470731258392334
training step: 27132, total_loss: 5.052319526672363
training step: 27133, total_loss: 3.4693350791931152
training step: 27134, total_loss: 4.716701507568359
training step: 27135, total_loss: 4.0050554275512695
training step: 27136, total_loss: 4.677992820739746
training step: 27137, total_loss: 0.950746476650238
training step: 27138, total_loss: 4.992728233337402
training step: 27139, total_loss: 3.8752126693725586
training step: 27140, total_loss: 3.6990950107574463
training step: 27141, total_loss: 4.023717880249023
training step: 27142, total_loss: 5.654701232910156
training step: 27143, total_loss: 4.009583950042725
training step: 27144, total_loss: 4.673625946044922
training step: 27145, total_loss: 4.468038558959961
training step: 27146, total_loss: 4.133089542388916
training step: 27147, total_loss: 4.393752098083496
training step: 27148, total_loss: 4.722925186157227
training step: 27149, total_loss: 5.591604709625244
training step: 27150, total_loss: 4.068839073181152
training step: 27151, total_loss: 4.967720031738281
training step: 27152, total_loss: 5.092563152313232
training step: 27153, total_loss: 5.156046390533447
training step: 27154, total_loss: 4.866879463195801
training step: 27155, total_loss: 5.343469142913818
training step: 27156, total_loss: 5.687488555908203
training step: 27157, total_loss: 5.580770492553711
training step: 27158, total_loss: 6.115894317626953
training step: 27159, total_loss: 4.767129898071289
training step: 27160, total_loss: 3.5059468746185303
training step: 27161, total_loss: 5.5542449951171875
training step: 27162, total_loss: 3.4873604774475098
training step: 27163, total_loss: 4.876521587371826
training step: 27164, total_loss: 3.8233141899108887
training step: 27165, total_loss: 3.8774428367614746
training step: 27166, total_loss: 3.9847657680511475
training step: 27167, total_loss: 3.8207364082336426
training step: 27168, total_loss: 3.9710958003997803
training step: 27169, total_loss: 2.5093135833740234
training step: 27170, total_loss: 5.236194610595703
training step: 27171, total_loss: 5.024351119995117
training step: 27172, total_loss: 2.871030569076538
training step: 27173, total_loss: 4.846384048461914
training step: 27174, total_loss: 0.8907275199890137
training step: 27175, total_loss: 5.5189666748046875
training step: 27176, total_loss: 3.7298550605773926
training step: 27177, total_loss: 6.1543073654174805
training step: 27178, total_loss: 5.515722274780273
training step: 27179, total_loss: 4.83903694152832
training step: 27180, total_loss: 4.15113639831543
training step: 27181, total_loss: 3.135322093963623
training step: 27182, total_loss: 4.618882179260254
training step: 27183, total_loss: 4.636754035949707
training step: 27184, total_loss: 4.416356563568115
training step: 27185, total_loss: 0.7096872329711914
training step: 27186, total_loss: 3.7732582092285156
training step: 27187, total_loss: 4.097193717956543
training step: 27188, total_loss: 3.572174549102783
training step: 27189, total_loss: 2.9773190021514893
training step: 27190, total_loss: 4.318636417388916
training step: 27191, total_loss: 4.994549751281738
training step: 27192, total_loss: 5.8678483963012695
training step: 27193, total_loss: 3.8579912185668945
training step: 27194, total_loss: 5.80833625793457
training step: 27195, total_loss: 3.975184917449951
training step: 27196, total_loss: 3.9775257110595703
training step: 27197, total_loss: 5.57257080078125
training step: 27198, total_loss: 5.542034149169922
training step: 27199, total_loss: 3.410123348236084
training step: 27200, total_loss: 4.626102447509766
training step: 27201, total_loss: 4.751749038696289
training step: 27202, total_loss: 4.086847305297852
training step: 27203, total_loss: 3.5094709396362305
training step: 27204, total_loss: 4.9666924476623535
training step: 27205, total_loss: 4.011290073394775
training step: 27206, total_loss: 2.55684494972229
training step: 27207, total_loss: 3.6774816513061523
training step: 27208, total_loss: 4.043134689331055
training step: 27209, total_loss: 3.1408183574676514
training step: 27210, total_loss: 5.1179070472717285
training step: 27211, total_loss: 2.35520076751709
training step: 27212, total_loss: 0.7829279899597168
training step: 27213, total_loss: 5.038136959075928
training step: 27214, total_loss: 5.808407306671143
training step: 27215, total_loss: 4.509016990661621
training step: 27216, total_loss: 3.9439384937286377
training step: 27217, total_loss: 3.696415424346924
training step: 27218, total_loss: 5.12064266204834
training step: 27219, total_loss: 4.670027256011963
training step: 27220, total_loss: 4.393335819244385
training step: 27221, total_loss: 3.404040813446045
training step: 27222, total_loss: 4.766369819641113
training step: 27223, total_loss: 5.8369622230529785
training step: 27224, total_loss: 3.1954503059387207
training step: 27225, total_loss: 5.008396148681641
training step: 27226, total_loss: 4.415432453155518
training step: 27227, total_loss: 4.294689178466797
training step: 27228, total_loss: 6.205770969390869
training step: 27229, total_loss: 5.9570512771606445
training step: 27230, total_loss: 4.588830947875977
training step: 27231, total_loss: 4.776140213012695
training step: 27232, total_loss: 4.616359233856201
training step: 27233, total_loss: 4.6266770362854
training step: 27234, total_loss: 5.404618263244629
training step: 27235, total_loss: 5.27599573135376
training step: 27236, total_loss: 3.690969944000244
training step: 27237, total_loss: 4.988182544708252
training step: 27238, total_loss: 5.762938499450684
training step: 27239, total_loss: 4.740827560424805
training step: 27240, total_loss: 5.194160461425781
training step: 27241, total_loss: 5.671921730041504
training step: 27242, total_loss: 3.0948543548583984
training step: 27243, total_loss: 4.633326530456543
training step: 27244, total_loss: 4.396239280700684
training step: 27245, total_loss: 3.037865161895752
training step: 27246, total_loss: 5.097042083740234
training step: 27247, total_loss: 4.0813984870910645
training step: 27248, total_loss: 5.358640670776367
training step: 27249, total_loss: 3.0390124320983887
training step: 27250, total_loss: 3.9352924823760986
training step: 27251, total_loss: 5.289241790771484
training step: 27252, total_loss: 5.1636505126953125
training step: 27253, total_loss: 5.652316093444824
training step: 27254, total_loss: 4.396575927734375
training step: 27255, total_loss: 5.456244468688965
training step: 27256, total_loss: 4.849069118499756
training step: 27257, total_loss: 2.8238701820373535
training step: 27258, total_loss: 2.5821375846862793
training step: 27259, total_loss: 1.088571310043335
training step: 27260, total_loss: 4.495351314544678
training step: 27261, total_loss: 3.3740158081054688
training step: 27262, total_loss: 3.9693870544433594
training step: 27263, total_loss: 0.9716871976852417
training step: 27264, total_loss: 4.930649757385254
training step: 27265, total_loss: 4.9292192459106445
training step: 27266, total_loss: 3.7544937133789062
training step: 27267, total_loss: 5.3944091796875
training step: 27268, total_loss: 0.8141931295394897
training step: 27269, total_loss: 2.6529245376586914
training step: 27270, total_loss: 3.5409321784973145
training step: 27271, total_loss: 2.7347047328948975
training step: 27272, total_loss: 4.326711177825928
training step: 27273, total_loss: 3.758026123046875
training step: 27274, total_loss: 1.196067452430725
training step: 27275, total_loss: 4.424433708190918
training step: 27276, total_loss: 4.107661724090576
training step: 27277, total_loss: 5.130190849304199
training step: 27278, total_loss: 6.118440628051758
training step: 27279, total_loss: 4.785233497619629
training step: 27280, total_loss: 4.668504238128662
training step: 27281, total_loss: 5.698378562927246
training step: 27282, total_loss: 5.328590393066406
training step: 27283, total_loss: 5.109883785247803
training step: 27284, total_loss: 3.3092269897460938
training step: 27285, total_loss: 3.820798397064209
training step: 27286, total_loss: 3.6952710151672363
training step: 27287, total_loss: 3.3684334754943848
training step: 27288, total_loss: 4.706075191497803
training step: 27289, total_loss: 4.347246170043945
training step: 27290, total_loss: 6.5353217124938965
training step: 27291, total_loss: 6.698533535003662
training step: 27292, total_loss: 4.47584342956543
training step: 27293, total_loss: 5.560450077056885
training step: 27294, total_loss: 4.703761577606201
training step: 27295, total_loss: 5.332571983337402
training step: 27296, total_loss: 4.2996087074279785
training step: 27297, total_loss: 5.688963413238525
training step: 27298, total_loss: 5.377547264099121
training step: 27299, total_loss: 6.211030006408691
training step: 27300, total_loss: 5.39232063293457
training step: 27301, total_loss: 4.204980850219727
training step: 27302, total_loss: 3.3803558349609375
training step: 27303, total_loss: 4.569698810577393
training step: 27304, total_loss: 5.02840518951416
training step: 27305, total_loss: 5.0343780517578125
training step: 27306, total_loss: 5.322121620178223
training step: 27307, total_loss: 1.6718522310256958
training step: 27308, total_loss: 4.358896255493164
training step: 27309, total_loss: 4.944557189941406
training step: 27310, total_loss: 3.8525633811950684
training step: 27311, total_loss: 4.744200229644775
training step: 27312, total_loss: 4.527986526489258
training step: 27313, total_loss: 5.257141590118408
training step: 27314, total_loss: 5.939423561096191
training step: 27315, total_loss: 5.298221588134766
training step: 27316, total_loss: 4.075421333312988
training step: 27317, total_loss: 3.8123815059661865
training step: 27318, total_loss: 3.7710342407226562
training step: 27319, total_loss: 2.948263168334961
training step: 27320, total_loss: 5.21726655960083
training step: 27321, total_loss: 1.2992379665374756
training step: 27322, total_loss: 4.17829704284668
training step: 27323, total_loss: 4.8101348876953125
training step: 27324, total_loss: 4.01485013961792
training step: 27325, total_loss: 5.3769731521606445
training step: 27326, total_loss: 5.180856704711914
training step: 27327, total_loss: 4.76682186126709
training step: 27328, total_loss: 4.481550693511963
training step: 27329, total_loss: 4.147210597991943
training step: 27330, total_loss: 4.597532272338867
training step: 27331, total_loss: 5.060344696044922
training step: 27332, total_loss: 2.936126708984375
training step: 27333, total_loss: 4.190670967102051
training step: 27334, total_loss: 4.439576148986816
training step: 27335, total_loss: 4.895905494689941
training step: 27336, total_loss: 4.173186302185059
training step: 27337, total_loss: 4.813385009765625
training step: 27338, total_loss: 2.5175247192382812
training step: 27339, total_loss: 1.5098295211791992
training step: 27340, total_loss: 3.7760419845581055
training step: 27341, total_loss: 4.680794715881348
training step: 27342, total_loss: 5.380456924438477
training step: 27343, total_loss: 4.829268455505371
training step: 27344, total_loss: 4.5764570236206055
training step: 27345, total_loss: 4.633530139923096
training step: 27346, total_loss: 4.731904029846191
training step: 27347, total_loss: 3.7374420166015625
training step: 27348, total_loss: 4.3550190925598145
training step: 27349, total_loss: 4.560085773468018
training step: 27350, total_loss: 4.786098957061768
training step: 27351, total_loss: 4.224000453948975
training step: 27352, total_loss: 4.5952324867248535
training step: 27353, total_loss: 4.1811113357543945
training step: 27354, total_loss: 4.018818378448486
training step: 27355, total_loss: 4.369477272033691
training step: 27356, total_loss: 4.522147178649902
training step: 27357, total_loss: 4.284918785095215
training step: 27358, total_loss: 5.164778232574463
training step: 27359, total_loss: 4.1199798583984375
training step: 27360, total_loss: 3.944577693939209
training step: 27361, total_loss: 4.371316909790039
training step: 27362, total_loss: 4.101595878601074
training step: 27363, total_loss: 5.5953688621521
training step: 27364, total_loss: 5.058462619781494
training step: 27365, total_loss: 2.6397528648376465
training step: 27366, total_loss: 3.1477019786834717
training step: 27367, total_loss: 4.938172340393066
training step: 27368, total_loss: 3.6693577766418457
training step: 27369, total_loss: 4.376615047454834
training step: 27370, total_loss: 3.6034798622131348
training step: 27371, total_loss: 4.872809410095215
training step: 27372, total_loss: 3.4850337505340576
training step: 27373, total_loss: 5.9942169189453125
training step: 27374, total_loss: 3.433523654937744
training step: 27375, total_loss: 5.001284599304199
training step: 27376, total_loss: 3.120544195175171
training step: 27377, total_loss: 3.772067070007324
training step: 27378, total_loss: 2.991455078125
training step: 27379, total_loss: 3.934985399246216
training step: 27380, total_loss: 5.8120012283325195
training step: 27381, total_loss: 3.7630162239074707
training step: 27382, total_loss: 4.646464824676514
training step: 27383, total_loss: 4.983832359313965
training step: 27384, total_loss: 4.36113166809082
training step: 27385, total_loss: 6.597657203674316
training step: 27386, total_loss: 5.3106689453125
training step: 27387, total_loss: 2.845733165740967
training step: 27388, total_loss: 4.663875579833984
training step: 27389, total_loss: 3.9561643600463867
training step: 27390, total_loss: 3.0615713596343994
training step: 27391, total_loss: 5.016334533691406
training step: 27392, total_loss: 1.2453492879867554
training step: 27393, total_loss: 5.616543292999268
training step: 27394, total_loss: 4.917903900146484
training step: 27395, total_loss: 3.8751800060272217
training step: 27396, total_loss: 1.3915865421295166
training step: 27397, total_loss: 3.4976768493652344
training step: 27398, total_loss: 5.3838348388671875
training step: 27399, total_loss: 3.3004746437072754
training step: 27400, total_loss: 4.475149631500244
training step: 27401, total_loss: 4.54823112487793
training step: 27402, total_loss: 5.468723297119141
training step: 27403, total_loss: 5.81327486038208
training step: 27404, total_loss: 4.256335735321045
training step: 27405, total_loss: 4.866907119750977
training step: 27406, total_loss: 4.625273704528809
training step: 27407, total_loss: 3.905580520629883
training step: 27408, total_loss: 4.294036865234375
training step: 27409, total_loss: 5.382937431335449
training step: 27410, total_loss: 6.224527359008789
training step: 27411, total_loss: 4.391743183135986
training step: 27412, total_loss: 5.352969169616699
training step: 27413, total_loss: 4.370477199554443
training step: 27414, total_loss: 4.681940078735352
training step: 27415, total_loss: 3.824918270111084
training step: 27416, total_loss: 4.7971367835998535
training step: 27417, total_loss: 3.9959826469421387
training step: 27418, total_loss: 4.099515914916992
training step: 27419, total_loss: 4.538578033447266
training step: 27420, total_loss: 3.3997480869293213
training step: 27421, total_loss: 3.9332447052001953
training step: 27422, total_loss: 3.9069290161132812
training step: 27423, total_loss: 6.072473526000977
training step: 27424, total_loss: 5.12233304977417
training step: 27425, total_loss: 4.451671600341797
training step: 27426, total_loss: 2.7527854442596436
training step: 27427, total_loss: 4.673425674438477
training step: 27428, total_loss: 4.9739179611206055
training step: 27429, total_loss: 5.250701904296875
training step: 27430, total_loss: 3.3221683502197266
training step: 27431, total_loss: 4.867580890655518
training step: 27432, total_loss: 7.039511680603027
training step: 27433, total_loss: 4.372298240661621
training step: 27434, total_loss: 4.769713878631592
training step: 27435, total_loss: 3.5238592624664307
training step: 27436, total_loss: 2.5462379455566406
training step: 27437, total_loss: 5.658204078674316
training step: 27438, total_loss: 3.9169633388519287
training step: 27439, total_loss: 5.020437240600586
training step: 27440, total_loss: 4.347352981567383
training step: 27441, total_loss: 3.9256129264831543
training step: 27442, total_loss: 3.5558407306671143
training step: 27443, total_loss: 4.2600555419921875
training step: 27444, total_loss: 2.5419580936431885
training step: 27445, total_loss: 2.6384010314941406
training step: 27446, total_loss: 5.088356971740723
training step: 27447, total_loss: 3.722395896911621
training step: 27448, total_loss: 5.352860450744629
training step: 27449, total_loss: 4.701112270355225
training step: 27450, total_loss: 4.685565948486328
training step: 27451, total_loss: 4.558748245239258
training step: 27452, total_loss: 3.196316719055176
training step: 27453, total_loss: 4.2252960205078125
training step: 27454, total_loss: 4.236217498779297
training step: 27455, total_loss: 3.880053758621216
training step: 27456, total_loss: 3.0992441177368164
training step: 27457, total_loss: 3.656120777130127
training step: 27458, total_loss: 1.6486080884933472
training step: 27459, total_loss: 3.248154401779175
training step: 27460, total_loss: 3.2710070610046387
training step: 27461, total_loss: 5.145267963409424
training step: 27462, total_loss: 3.3467857837677
training step: 27463, total_loss: 4.544231414794922
training step: 27464, total_loss: 3.7090744972229004
training step: 27465, total_loss: 4.72743558883667
training step: 27466, total_loss: 4.7378997802734375
training step: 27467, total_loss: 4.071488380432129
training step: 27468, total_loss: 4.07334566116333
training step: 27469, total_loss: 4.612642288208008
training step: 27470, total_loss: 5.141607284545898
training step: 27471, total_loss: 4.120732307434082
training step: 27472, total_loss: 3.9790380001068115
training step: 27473, total_loss: 6.896596908569336
training step: 27474, total_loss: 5.235601425170898
training step: 27475, total_loss: 5.630023002624512
training step: 27476, total_loss: 5.616480827331543
training step: 27477, total_loss: 5.172741889953613
training step: 27478, total_loss: 4.446876525878906
training step: 27479, total_loss: 5.448202133178711
training step: 27480, total_loss: 5.379568099975586
training step: 27481, total_loss: 4.100167274475098
training step: 27482, total_loss: 4.953896522521973
training step: 27483, total_loss: 4.688429832458496
training step: 27484, total_loss: 4.146432399749756
training step: 27485, total_loss: 4.211426734924316
training step: 27486, total_loss: 3.7553296089172363
training step: 27487, total_loss: 4.500882148742676
training step: 27488, total_loss: 3.528470516204834
training step: 27489, total_loss: 3.486118793487549
training step: 27490, total_loss: 3.606419801712036
training step: 27491, total_loss: 4.8661956787109375
training step: 27492, total_loss: 3.476335048675537
training step: 27493, total_loss: 2.796416759490967
training step: 27494, total_loss: 3.888430118560791
training step: 27495, total_loss: 5.712774276733398
training step: 27496, total_loss: 4.70619010925293
training step: 27497, total_loss: 3.7760868072509766
training step: 27498, total_loss: 4.7689313888549805
training step: 27499, total_loss: 5.018931865692139
training step: 27500, total_loss: 4.833492279052734
training step: 27501, total_loss: 2.8963940143585205
training step: 27502, total_loss: 3.812488317489624
training step: 27503, total_loss: 1.1621601581573486
training step: 27504, total_loss: 5.442652225494385
training step: 27505, total_loss: 2.664909839630127
training step: 27506, total_loss: 6.040495872497559
training step: 27507, total_loss: 4.761774063110352
training step: 27508, total_loss: 5.158867835998535
training step: 27509, total_loss: 4.840501308441162
training step: 27510, total_loss: 4.160652160644531
training step: 27511, total_loss: 2.109578847885132
training step: 27512, total_loss: 4.425966262817383
training step: 27513, total_loss: 4.223066806793213
training step: 27514, total_loss: 4.832004547119141
training step: 27515, total_loss: 3.091951847076416
training step: 27516, total_loss: 5.422878265380859
training step: 27517, total_loss: 4.855247497558594
training step: 27518, total_loss: 4.605161190032959
training step: 27519, total_loss: 5.091094970703125
training step: 27520, total_loss: 5.881255149841309
training step: 27521, total_loss: 5.079831123352051
training step: 27522, total_loss: 5.208303451538086
training step: 27523, total_loss: 6.073117256164551
training step: 27524, total_loss: 5.595398902893066
training step: 27525, total_loss: 4.3087592124938965
training step: 27526, total_loss: 5.052616596221924
training step: 27527, total_loss: 4.79614782333374
training step: 27528, total_loss: 3.7812767028808594
training step: 27529, total_loss: 3.4615957736968994
training step: 27530, total_loss: 4.886621952056885
training step: 27531, total_loss: 3.362299919128418
training step: 27532, total_loss: 3.54087233543396
training step: 27533, total_loss: 4.071916580200195
training step: 27534, total_loss: 4.85870361328125
training step: 27535, total_loss: 2.894965171813965
training step: 27536, total_loss: 4.830958366394043
training step: 27537, total_loss: 1.3704808950424194
training step: 27538, total_loss: 4.0912275314331055
training step: 27539, total_loss: 4.732611179351807
training step: 27540, total_loss: 4.5390849113464355
training step: 27541, total_loss: 6.142853736877441
training step: 27542, total_loss: 3.7712597846984863
training step: 27543, total_loss: 5.321552753448486
training step: 27544, total_loss: 4.435606002807617
training step: 27545, total_loss: 5.0786895751953125
training step: 27546, total_loss: 3.7448606491088867
training step: 27547, total_loss: 4.5803422927856445
training step: 27548, total_loss: 5.197408676147461
training step: 27549, total_loss: 4.419262886047363
training step: 27550, total_loss: 4.0923075675964355
training step: 27551, total_loss: 4.275858402252197
training step: 27552, total_loss: 6.2488112449646
training step: 27553, total_loss: 3.439249277114868
training step: 27554, total_loss: 2.553208589553833
training step: 27555, total_loss: 3.9120852947235107
training step: 27556, total_loss: 6.831953048706055
training step: 27557, total_loss: 4.662406921386719
training step: 27558, total_loss: 4.451169490814209
training step: 27559, total_loss: 4.210351943969727
training step: 27560, total_loss: 3.749056816101074
training step: 27561, total_loss: 4.241238594055176
training step: 27562, total_loss: 5.332283973693848
training step: 27563, total_loss: 5.159104347229004
training step: 27564, total_loss: 3.7034645080566406
training step: 27565, total_loss: 4.452277660369873
training step: 27566, total_loss: 5.109318733215332
training step: 27567, total_loss: 4.553264617919922
training step: 27568, total_loss: 4.46885871887207
training step: 27569, total_loss: 3.403890609741211
training step: 27570, total_loss: 2.357114315032959
training step: 27571, total_loss: 7.162273406982422
training step: 27572, total_loss: 5.369415283203125
training step: 27573, total_loss: 4.238375186920166
training step: 27574, total_loss: 3.648638963699341
training step: 27575, total_loss: 4.502241134643555
training step: 27576, total_loss: 5.997664451599121
training step: 27577, total_loss: 6.487148761749268
training step: 27578, total_loss: 4.900415420532227
training step: 27579, total_loss: 3.516993999481201
training step: 27580, total_loss: 5.306507110595703
training step: 27581, total_loss: 5.203039169311523
training step: 27582, total_loss: 4.824753761291504
training step: 27583, total_loss: 2.4058501720428467
training step: 27584, total_loss: 4.427123069763184
training step: 27585, total_loss: 1.1158807277679443
training step: 27586, total_loss: 4.865662574768066
training step: 27587, total_loss: 4.733193397521973
training step: 27588, total_loss: 5.453897953033447
training step: 27589, total_loss: 3.8240790367126465
training step: 27590, total_loss: 3.147444725036621
training step: 27591, total_loss: 3.4528586864471436
training step: 27592, total_loss: 4.463447093963623
training step: 27593, total_loss: 4.810199737548828
training step: 27594, total_loss: 5.8447465896606445
training step: 27595, total_loss: 4.1072540283203125
training step: 27596, total_loss: 3.768794059753418
training step: 27597, total_loss: 5.300100326538086
training step: 27598, total_loss: 2.7528076171875
training step: 27599, total_loss: 1.1881786584854126
training step: 27600, total_loss: 4.600170612335205
training step: 27601, total_loss: 3.089902400970459
training step: 27602, total_loss: 4.449479103088379
training step: 27603, total_loss: 5.331890106201172
training step: 27604, total_loss: 2.8131048679351807
training step: 27605, total_loss: 5.081620216369629
training step: 27606, total_loss: 1.0129344463348389
training step: 27607, total_loss: 4.83465576171875
training step: 27608, total_loss: 3.5618984699249268
training step: 27609, total_loss: 3.6189794540405273
training step: 27610, total_loss: 5.759163856506348
training step: 27611, total_loss: 3.855313301086426
training step: 27612, total_loss: 3.896547317504883
training step: 27613, total_loss: 2.890225887298584
training step: 27614, total_loss: 3.3416926860809326
training step: 27615, total_loss: 4.9059977531433105
training step: 27616, total_loss: 4.718634605407715
training step: 27617, total_loss: 0.9369537234306335
training step: 27618, total_loss: 4.481671333312988
training step: 27619, total_loss: 3.862285852432251
training step: 27620, total_loss: 4.975872039794922
training step: 27621, total_loss: 4.4793701171875
training step: 27622, total_loss: 3.655214309692383
training step: 27623, total_loss: 4.24921989440918
training step: 27624, total_loss: 4.663476467132568
training step: 27625, total_loss: 5.0238142013549805
training step: 27626, total_loss: 6.181848526000977
training step: 27627, total_loss: 4.822004318237305
training step: 27628, total_loss: 5.034027099609375
training step: 27629, total_loss: 5.602877616882324
training step: 27630, total_loss: 3.9119224548339844
training step: 27631, total_loss: 0.9019386768341064
training step: 27632, total_loss: 4.508480548858643
training step: 27633, total_loss: 0.7845667004585266
training step: 27634, total_loss: 6.0593719482421875
training step: 27635, total_loss: 3.9108777046203613
training step: 27636, total_loss: 2.68540096282959
training step: 27637, total_loss: 0.690926194190979
training step: 27638, total_loss: 4.679118633270264
training step: 27639, total_loss: 4.799417495727539
training step: 27640, total_loss: 4.811847686767578
training step: 27641, total_loss: 4.629847526550293
training step: 27642, total_loss: 6.794374465942383
training step: 27643, total_loss: 5.793542861938477
training step: 27644, total_loss: 6.181800842285156
training step: 27645, total_loss: 2.779606342315674
training step: 27646, total_loss: 4.008414268493652
training step: 27647, total_loss: 7.390366554260254
training step: 27648, total_loss: 5.71920108795166
training step: 27649, total_loss: 4.83194637298584
training step: 27650, total_loss: 4.878942489624023
training step: 27651, total_loss: 3.2283482551574707
training step: 27652, total_loss: 1.4728829860687256
training step: 27653, total_loss: 5.5972065925598145
training step: 27654, total_loss: 5.917489051818848
training step: 27655, total_loss: 3.1782002449035645
training step: 27656, total_loss: 5.444245338439941
training step: 27657, total_loss: 4.958492279052734
training step: 27658, total_loss: 4.533463954925537
training step: 27659, total_loss: 5.669816493988037
training step: 27660, total_loss: 4.993844509124756
training step: 27661, total_loss: 4.791338920593262
training step: 27662, total_loss: 3.9753353595733643
training step: 27663, total_loss: 5.732274055480957
training step: 27664, total_loss: 4.953248023986816
training step: 27665, total_loss: 4.832448959350586
training step: 27666, total_loss: 5.168917655944824
training step: 27667, total_loss: 4.09879732131958
training step: 27668, total_loss: 3.8011691570281982
training step: 27669, total_loss: 4.834103584289551
training step: 27670, total_loss: 5.1462225914001465
training step: 27671, total_loss: 5.124512195587158
training step: 27672, total_loss: 5.236289978027344
training step: 27673, total_loss: 4.743587970733643
training step: 27674, total_loss: 4.637585639953613
training step: 27675, total_loss: 3.941782236099243
training step: 27676, total_loss: 3.538736343383789
training step: 27677, total_loss: 2.161432981491089
training step: 27678, total_loss: 4.026825904846191
training step: 27679, total_loss: 4.359927177429199
training step: 27680, total_loss: 3.413562297821045
training step: 27681, total_loss: 5.932683944702148
training step: 27682, total_loss: 4.5425286293029785
training step: 27683, total_loss: 3.5747311115264893
training step: 27684, total_loss: 5.317731857299805
training step: 27685, total_loss: 7.162353992462158
training step: 27686, total_loss: 6.452445030212402
training step: 27687, total_loss: 4.611315727233887
training step: 27688, total_loss: 4.360068321228027
training step: 27689, total_loss: 4.11518669128418
training step: 27690, total_loss: 4.324304580688477
training step: 27691, total_loss: 1.572798490524292
training step: 27692, total_loss: 4.527544021606445
training step: 27693, total_loss: 5.345153331756592
training step: 27694, total_loss: 1.096798062324524
training step: 27695, total_loss: 4.32745361328125
training step: 27696, total_loss: 2.2177796363830566
training step: 27697, total_loss: 1.5032349824905396
training step: 27698, total_loss: 2.807094097137451
training step: 27699, total_loss: 4.431107997894287
training step: 27700, total_loss: 5.848008632659912
training step: 27701, total_loss: 4.269130229949951
training step: 27702, total_loss: 1.1042016744613647
training step: 27703, total_loss: 5.456580638885498
training step: 27704, total_loss: 3.4701614379882812
training step: 27705, total_loss: 6.185559272766113
training step: 27706, total_loss: 5.063970565795898
training step: 27707, total_loss: 4.325317859649658
training step: 27708, total_loss: 5.14229679107666
training step: 27709, total_loss: 2.406040906906128
training step: 27710, total_loss: 4.60802698135376
training step: 27711, total_loss: 6.408371925354004
training step: 27712, total_loss: 5.227203369140625
training step: 27713, total_loss: 4.457620620727539
training step: 27714, total_loss: 4.549041271209717
training step: 27715, total_loss: 3.481656789779663
training step: 27716, total_loss: 6.209031581878662
training step: 27717, total_loss: 4.737958908081055
training step: 27718, total_loss: 4.36868953704834
training step: 27719, total_loss: 5.839743614196777
training step: 27720, total_loss: 4.010898590087891
training step: 27721, total_loss: 5.409501552581787
training step: 27722, total_loss: 3.662381887435913
training step: 27723, total_loss: 4.559330463409424
training step: 27724, total_loss: 7.211524963378906
training step: 27725, total_loss: 4.914366722106934
training step: 27726, total_loss: 4.814065933227539
training step: 27727, total_loss: 4.589672088623047
training step: 27728, total_loss: 4.056179523468018
training step: 27729, total_loss: 5.359681606292725
training step: 27730, total_loss: 3.398247241973877
training step: 27731, total_loss: 4.758236885070801
training step: 27732, total_loss: 5.727049350738525
training step: 27733, total_loss: 4.888113975524902
training step: 27734, total_loss: 1.2283885478973389
training step: 27735, total_loss: 4.378494739532471
training step: 27736, total_loss: 3.250123977661133
training step: 27737, total_loss: 4.345598220825195
training step: 27738, total_loss: 3.8182947635650635
training step: 27739, total_loss: 3.9334869384765625
training step: 27740, total_loss: 5.1315531730651855
training step: 27741, total_loss: 5.381503105163574
training step: 27742, total_loss: 6.437644958496094
training step: 27743, total_loss: 3.5752384662628174
training step: 27744, total_loss: 4.642765998840332
training step: 27745, total_loss: 4.626750469207764
training step: 27746, total_loss: 4.895082473754883
training step: 27747, total_loss: 3.300858497619629
training step: 27748, total_loss: 5.57469367980957
training step: 27749, total_loss: 3.519533634185791
training step: 27750, total_loss: 4.078651428222656
training step: 27751, total_loss: 5.612723350524902
training step: 27752, total_loss: 3.7924909591674805
training step: 27753, total_loss: 4.699676990509033
training step: 27754, total_loss: 4.949257850646973
training step: 27755, total_loss: 5.003730297088623
training step: 27756, total_loss: 4.588858604431152
training step: 27757, total_loss: 5.749112129211426
training step: 27758, total_loss: 3.524820327758789
training step: 27759, total_loss: 5.197417736053467
training step: 27760, total_loss: 4.304437637329102
training step: 27761, total_loss: 4.486214637756348
training step: 27762, total_loss: 4.4533772468566895
training step: 27763, total_loss: 4.254735946655273
training step: 27764, total_loss: 4.194511413574219
training step: 27765, total_loss: 3.7043700218200684
training step: 27766, total_loss: 5.263979434967041
training step: 27767, total_loss: 4.839914798736572
training step: 27768, total_loss: 4.802647590637207
training step: 27769, total_loss: 3.2046375274658203
training step: 27770, total_loss: 4.67800235748291
training step: 27771, total_loss: 2.568099021911621
training step: 27772, total_loss: 3.485293388366699
training step: 27773, total_loss: 5.215743064880371
training step: 27774, total_loss: 4.239954471588135
training step: 27775, total_loss: 5.071691989898682
training step: 27776, total_loss: 2.9662351608276367
training step: 27777, total_loss: 5.4744086265563965
training step: 27778, total_loss: 5.161848068237305
training step: 27779, total_loss: 3.981489658355713
training step: 27780, total_loss: 0.9738782644271851
training step: 27781, total_loss: 5.686516761779785
training step: 27782, total_loss: 3.846555471420288
training step: 27783, total_loss: 5.154214859008789
training step: 27784, total_loss: 6.724420547485352
training step: 27785, total_loss: 3.5915701389312744
training step: 27786, total_loss: 4.817455291748047
training step: 27787, total_loss: 4.683452606201172
training step: 27788, total_loss: 5.213288307189941
training step: 27789, total_loss: 4.7687482833862305
training step: 27790, total_loss: 4.516495227813721
training step: 27791, total_loss: 4.516402721405029
training step: 27792, total_loss: 2.18865704536438
training step: 27793, total_loss: 3.4086101055145264
training step: 27794, total_loss: 4.25273323059082
training step: 27795, total_loss: 6.094009876251221
training step: 27796, total_loss: 4.814821243286133
training step: 27797, total_loss: 4.4081010818481445
training step: 27798, total_loss: 4.056393623352051
training step: 27799, total_loss: 5.11009407043457
training step: 27800, total_loss: 5.332524299621582
training step: 27801, total_loss: 4.835402488708496
training step: 27802, total_loss: 5.678213596343994
training step: 27803, total_loss: 2.753509521484375
training step: 27804, total_loss: 4.537989616394043
training step: 27805, total_loss: 5.514753818511963
training step: 27806, total_loss: 4.673953056335449
training step: 27807, total_loss: 4.065207481384277
training step: 27808, total_loss: 5.406377792358398
training step: 27809, total_loss: 5.065254211425781
training step: 27810, total_loss: 2.439289093017578
training step: 27811, total_loss: 4.753035545349121
training step: 27812, total_loss: 4.579506874084473
training step: 27813, total_loss: 4.156749725341797
training step: 27814, total_loss: 5.053769111633301
training step: 27815, total_loss: 4.492980480194092
training step: 27816, total_loss: 4.564714431762695
training step: 27817, total_loss: 5.299690246582031
training step: 27818, total_loss: 5.344959735870361
training step: 27819, total_loss: 4.502532958984375
training step: 27820, total_loss: 3.677950859069824
training step: 27821, total_loss: 4.411672592163086
training step: 27822, total_loss: 3.0285274982452393
training step: 27823, total_loss: 3.7142715454101562
training step: 27824, total_loss: 2.575425624847412
training step: 27825, total_loss: 4.346765518188477
training step: 27826, total_loss: 6.589724540710449
training step: 27827, total_loss: 3.6585195064544678
training step: 27828, total_loss: 4.257034778594971
training step: 27829, total_loss: 4.044867515563965
training step: 27830, total_loss: 4.410199165344238
training step: 27831, total_loss: 4.157193660736084
training step: 27832, total_loss: 3.7859203815460205
training step: 27833, total_loss: 4.840278148651123
training step: 27834, total_loss: 4.445911407470703
training step: 27835, total_loss: 3.993457794189453
training step: 27836, total_loss: 4.44126558303833
training step: 27837, total_loss: 5.567196369171143
training step: 27838, total_loss: 3.9609012603759766
training step: 27839, total_loss: 3.636005401611328
training step: 27840, total_loss: 4.907932281494141
training step: 27841, total_loss: 4.998678684234619
training step: 27842, total_loss: 3.591036081314087
training step: 27843, total_loss: 4.445060729980469
training step: 27844, total_loss: 4.414074420928955
training step: 27845, total_loss: 2.744429588317871
training step: 27846, total_loss: 4.072052478790283
training step: 27847, total_loss: 5.62045955657959
training step: 27848, total_loss: 4.774179458618164
training step: 27849, total_loss: 4.927378177642822
training step: 27850, total_loss: 3.5376734733581543
training step: 27851, total_loss: 4.10398006439209
training step: 27852, total_loss: 4.8127522468566895
training step: 27853, total_loss: 4.578291416168213
training step: 27854, total_loss: 5.156780242919922
training step: 27855, total_loss: 3.069998264312744
training step: 27856, total_loss: 2.8991522789001465
training step: 27857, total_loss: 4.201833724975586
training step: 27858, total_loss: 3.7512190341949463
training step: 27859, total_loss: 4.7459611892700195
training step: 27860, total_loss: 1.4274052381515503
training step: 27861, total_loss: 3.61710262298584
training step: 27862, total_loss: 3.9698846340179443
training step: 27863, total_loss: 4.583413124084473
training step: 27864, total_loss: 3.8227505683898926
training step: 27865, total_loss: 3.838860034942627
training step: 27866, total_loss: 5.8205060958862305
training step: 27867, total_loss: 2.7568325996398926
training step: 27868, total_loss: 3.1409552097320557
training step: 27869, total_loss: 4.785765647888184
training step: 27870, total_loss: 6.769637107849121
training step: 27871, total_loss: 4.466136932373047
training step: 27872, total_loss: 4.797821998596191
training step: 27873, total_loss: 3.7621850967407227
training step: 27874, total_loss: 4.460750579833984
training step: 27875, total_loss: 4.086147308349609
training step: 27876, total_loss: 3.2619528770446777
training step: 27877, total_loss: 4.926227569580078
training step: 27878, total_loss: 4.641073226928711
training step: 27879, total_loss: 4.455752372741699
training step: 27880, total_loss: 4.818349838256836
training step: 27881, total_loss: 4.479583263397217
training step: 27882, total_loss: 4.098301887512207
training step: 27883, total_loss: 5.351579666137695
training step: 27884, total_loss: 5.259889602661133
training step: 27885, total_loss: 6.303810119628906
training step: 27886, total_loss: 4.003779411315918
training step: 27887, total_loss: 5.661387920379639
training step: 27888, total_loss: 3.628599166870117
training step: 27889, total_loss: 4.216850280761719
training step: 27890, total_loss: 3.9820621013641357
training step: 27891, total_loss: 4.217533111572266
training step: 27892, total_loss: 4.441397666931152
training step: 27893, total_loss: 3.3906936645507812
training step: 27894, total_loss: 3.0550241470336914
training step: 27895, total_loss: 5.05643892288208
training step: 27896, total_loss: 5.972437858581543
training step: 27897, total_loss: 4.674078941345215
training step: 27898, total_loss: 5.173182010650635
training step: 27899, total_loss: 5.803692817687988
training step: 27900, total_loss: 4.248579025268555
training step: 27901, total_loss: 4.339885234832764
training step: 27902, total_loss: 3.2031567096710205
training step: 27903, total_loss: 3.54434871673584
training step: 27904, total_loss: 3.776376724243164
training step: 27905, total_loss: 5.1207966804504395
training step: 27906, total_loss: 5.8449602127075195
training step: 27907, total_loss: 4.2635979652404785
training step: 27908, total_loss: 4.969202995300293
training step: 27909, total_loss: 4.336507797241211
training step: 27910, total_loss: 6.639834880828857
training step: 27911, total_loss: 4.712160110473633
training step: 27912, total_loss: 5.00515604019165
training step: 27913, total_loss: 6.843524932861328
training step: 27914, total_loss: 5.103243827819824
training step: 27915, total_loss: 4.432522773742676
training step: 27916, total_loss: 3.9761643409729004
training step: 27917, total_loss: 5.2132439613342285
training step: 27918, total_loss: 4.8974761962890625
training step: 27919, total_loss: 5.10390567779541
training step: 27920, total_loss: 4.981492042541504
training step: 27921, total_loss: 3.862362861633301
training step: 27922, total_loss: 3.5346367359161377
training step: 27923, total_loss: 4.801214218139648
training step: 27924, total_loss: 4.812877655029297
training step: 27925, total_loss: 4.3507184982299805
training step: 27926, total_loss: 3.0679407119750977
training step: 27927, total_loss: 3.7997384071350098
training step: 27928, total_loss: 5.284970760345459
training step: 27929, total_loss: 4.243254661560059
training step: 27930, total_loss: 5.740962028503418
training step: 27931, total_loss: 1.1700372695922852
training step: 27932, total_loss: 4.2070536613464355
training step: 27933, total_loss: 4.402500152587891
training step: 27934, total_loss: 4.154260635375977
training step: 27935, total_loss: 4.261906623840332
training step: 27936, total_loss: 5.010528564453125
training step: 27937, total_loss: 5.3214521408081055
training step: 27938, total_loss: 5.366319179534912
training step: 27939, total_loss: 2.7418293952941895
training step: 27940, total_loss: 4.375969409942627
training step: 27941, total_loss: 3.518611431121826
training step: 27942, total_loss: 5.837185382843018
training step: 27943, total_loss: 6.751386642456055
training step: 27944, total_loss: 5.347373962402344
training step: 27945, total_loss: 5.20499324798584
training step: 27946, total_loss: 5.651946067810059
training step: 27947, total_loss: 4.391176223754883
training step: 27948, total_loss: 3.1870055198669434
training step: 27949, total_loss: 4.687470436096191
training step: 27950, total_loss: 3.445321559906006
training step: 27951, total_loss: 4.2868757247924805
training step: 27952, total_loss: 3.9108047485351562
training step: 27953, total_loss: 4.4168806076049805
training step: 27954, total_loss: 4.9396514892578125
training step: 27955, total_loss: 4.675760269165039
training step: 27956, total_loss: 4.295792579650879
training step: 27957, total_loss: 4.701775550842285
training step: 27958, total_loss: 3.8135688304901123
training step: 27959, total_loss: 4.976330757141113
training step: 27960, total_loss: 4.493216037750244
training step: 27961, total_loss: 4.108777046203613
training step: 27962, total_loss: 3.3999581336975098
training step: 27963, total_loss: 5.9734206199646
training step: 27964, total_loss: 4.865468978881836
training step: 27965, total_loss: 3.7035908699035645
training step: 27966, total_loss: 4.410181999206543
training step: 27967, total_loss: 5.495501518249512
training step: 27968, total_loss: 4.1203155517578125
training step: 27969, total_loss: 5.672245502471924
training step: 27970, total_loss: 5.446906089782715
training step: 27971, total_loss: 3.4401867389678955
training step: 27972, total_loss: 4.932480812072754
training step: 27973, total_loss: 4.835037708282471
training step: 27974, total_loss: 5.3168864250183105
training step: 27975, total_loss: 4.662405014038086
training step: 27976, total_loss: 2.4071602821350098
training step: 27977, total_loss: 4.483887672424316
training step: 27978, total_loss: 3.356567621231079
training step: 27979, total_loss: 5.570672035217285
training step: 27980, total_loss: 3.649723529815674
training step: 27981, total_loss: 5.523372650146484
training step: 27982, total_loss: 5.139430046081543
training step: 27983, total_loss: 2.186356782913208
training step: 27984, total_loss: 3.7116315364837646
training step: 27985, total_loss: 5.483425140380859
training step: 27986, total_loss: 3.8521320819854736
training step: 27987, total_loss: 3.8019585609436035
training step: 27988, total_loss: 4.488119125366211
training step: 27989, total_loss: 4.614720344543457
training step: 27990, total_loss: 4.804411888122559
training step: 27991, total_loss: 2.488064765930176
training step: 27992, total_loss: 3.3335397243499756
training step: 27993, total_loss: 2.9212965965270996
training step: 27994, total_loss: 3.6837611198425293
training step: 27995, total_loss: 4.32399845123291
training step: 27996, total_loss: 4.972996234893799
training step: 27997, total_loss: 5.091079235076904
training step: 27998, total_loss: 4.304181098937988
training step: 27999, total_loss: 4.850362777709961
training step: 28000, total_loss: 5.331434726715088
training step: 28001, total_loss: 0.8531019687652588
training step: 28002, total_loss: 5.986452579498291
training step: 28003, total_loss: 4.272231578826904
training step: 28004, total_loss: 5.467871189117432
training step: 28005, total_loss: 5.4771504402160645
training step: 28006, total_loss: 3.4877676963806152
training step: 28007, total_loss: 4.424869537353516
training step: 28008, total_loss: 5.134576797485352
training step: 28009, total_loss: 5.3345136642456055
training step: 28010, total_loss: 4.602411270141602
training step: 28011, total_loss: 0.9587877988815308
training step: 28012, total_loss: 5.360189437866211
training step: 28013, total_loss: 4.433962821960449
training step: 28014, total_loss: 4.959537029266357
training step: 28015, total_loss: 3.4497060775756836
training step: 28016, total_loss: 5.811802864074707
training step: 28017, total_loss: 4.255836486816406
training step: 28018, total_loss: 0.936996579170227
training step: 28019, total_loss: 3.8433804512023926
training step: 28020, total_loss: 4.57957649230957
training step: 28021, total_loss: 4.476955890655518
training step: 28022, total_loss: 3.7683444023132324
training step: 28023, total_loss: 4.09975004196167
training step: 28024, total_loss: 5.739283084869385
training step: 28025, total_loss: 3.2561874389648438
training step: 28026, total_loss: 5.089295387268066
training step: 28027, total_loss: 4.960371971130371
training step: 28028, total_loss: 4.218989372253418
training step: 28029, total_loss: 4.445488929748535
training step: 28030, total_loss: 4.046069145202637
training step: 28031, total_loss: 5.16820764541626
training step: 28032, total_loss: 4.525984287261963
training step: 28033, total_loss: 4.210498332977295
training step: 28034, total_loss: 4.683249473571777
training step: 28035, total_loss: 2.948657989501953
training step: 28036, total_loss: 4.200366973876953
training step: 28037, total_loss: 4.468743324279785
training step: 28038, total_loss: 6.115082740783691
training step: 28039, total_loss: 4.839186668395996
training step: 28040, total_loss: 4.245449066162109
training step: 28041, total_loss: 4.23431921005249
training step: 28042, total_loss: 4.167617321014404
training step: 28043, total_loss: 5.099920272827148
training step: 28044, total_loss: 3.750309467315674
training step: 28045, total_loss: 4.497303485870361
training step: 28046, total_loss: 6.726166725158691
training step: 28047, total_loss: 5.432334899902344
training step: 28048, total_loss: 5.134097099304199
training step: 28049, total_loss: 5.716645240783691
training step: 28050, total_loss: 4.699477195739746
training step: 28051, total_loss: 5.079598426818848
training step: 28052, total_loss: 5.268368721008301
training step: 28053, total_loss: 4.916831970214844
training step: 28054, total_loss: 3.362227201461792
training step: 28055, total_loss: 4.061440944671631
training step: 28056, total_loss: 3.9310996532440186
training step: 28057, total_loss: 4.708403587341309
training step: 28058, total_loss: 3.879055976867676
training step: 28059, total_loss: 3.885462522506714
training step: 28060, total_loss: 3.891119956970215
training step: 28061, total_loss: 4.53416633605957
training step: 28062, total_loss: 4.523056983947754
training step: 28063, total_loss: 3.225128650665283
training step: 28064, total_loss: 4.838334083557129
training step: 28065, total_loss: 4.766260147094727
training step: 28066, total_loss: 5.011861801147461
training step: 28067, total_loss: 3.6934759616851807
training step: 28068, total_loss: 3.372035026550293
training step: 28069, total_loss: 4.13525915145874
training step: 28070, total_loss: 3.735024929046631
training step: 28071, total_loss: 4.929011344909668
training step: 28072, total_loss: 5.0677995681762695
training step: 28073, total_loss: 4.067208290100098
training step: 28074, total_loss: 4.057938575744629
training step: 28075, total_loss: 3.9429078102111816
training step: 28076, total_loss: 5.214792251586914
training step: 28077, total_loss: 5.068873405456543
training step: 28078, total_loss: 4.51035213470459
training step: 28079, total_loss: 5.018614768981934
training step: 28080, total_loss: 1.1580452919006348
training step: 28081, total_loss: 4.934690475463867
training step: 28082, total_loss: 5.945878982543945
training step: 28083, total_loss: 4.187650680541992
training step: 28084, total_loss: 4.877093315124512
training step: 28085, total_loss: 7.368941307067871
training step: 28086, total_loss: 5.013467788696289
training step: 28087, total_loss: 4.943221092224121
training step: 28088, total_loss: 3.5251359939575195
training step: 28089, total_loss: 4.1335978507995605
training step: 28090, total_loss: 5.714003562927246
training step: 28091, total_loss: 6.414882183074951
training step: 28092, total_loss: 4.282526969909668
training step: 28093, total_loss: 3.600687026977539
training step: 28094, total_loss: 4.907190322875977
training step: 28095, total_loss: 5.528655052185059
training step: 28096, total_loss: 4.997547149658203
training step: 28097, total_loss: 3.6994054317474365
training step: 28098, total_loss: 4.365991115570068
training step: 28099, total_loss: 4.633135795593262
training step: 28100, total_loss: 4.809125900268555
training step: 28101, total_loss: 4.806766510009766
training step: 28102, total_loss: 4.164696216583252
training step: 28103, total_loss: 4.981972694396973
training step: 28104, total_loss: 4.562023162841797
training step: 28105, total_loss: 5.001059532165527
training step: 28106, total_loss: 5.374217510223389
training step: 28107, total_loss: 5.139890193939209
training step: 28108, total_loss: 5.393583297729492
training step: 28109, total_loss: 6.1213178634643555
training step: 28110, total_loss: 3.768892288208008
training step: 28111, total_loss: 5.289133071899414
training step: 28112, total_loss: 5.78468132019043
training step: 28113, total_loss: 3.2030763626098633
training step: 28114, total_loss: 4.727643013000488
training step: 28115, total_loss: 5.15940523147583
training step: 28116, total_loss: 4.8500075340271
training step: 28117, total_loss: 3.8897109031677246
training step: 28118, total_loss: 4.577206611633301
training step: 28119, total_loss: 2.7175540924072266
training step: 28120, total_loss: 4.382991313934326
training step: 28121, total_loss: 3.79895281791687
training step: 28122, total_loss: 3.737623691558838
training step: 28123, total_loss: 4.024399757385254
training step: 28124, total_loss: 3.58964204788208
training step: 28125, total_loss: 4.540273189544678
training step: 28126, total_loss: 4.292790412902832
training step: 28127, total_loss: 4.450288772583008
training step: 28128, total_loss: 4.438986778259277
training step: 28129, total_loss: 4.589014530181885
training step: 28130, total_loss: 4.23848819732666
training step: 28131, total_loss: 3.776512622833252
training step: 28132, total_loss: 5.723278045654297
training step: 28133, total_loss: 5.084890842437744
training step: 28134, total_loss: 5.2547831535339355
training step: 28135, total_loss: 5.993939399719238
training step: 28136, total_loss: 5.490032196044922
training step: 28137, total_loss: 4.67393159866333
training step: 28138, total_loss: 4.416763782501221
training step: 28139, total_loss: 4.438730716705322
training step: 28140, total_loss: 4.423494815826416
training step: 28141, total_loss: 5.089055061340332
training step: 28142, total_loss: 3.8002772331237793
training step: 28143, total_loss: 4.907599449157715
training step: 28144, total_loss: 4.2380170822143555
training step: 28145, total_loss: 6.176545143127441
training step: 28146, total_loss: 5.744797229766846
training step: 28147, total_loss: 5.079230308532715
training step: 28148, total_loss: 5.64858341217041
training step: 28149, total_loss: 4.0821146965026855
training step: 28150, total_loss: 4.682777404785156
training step: 28151, total_loss: 7.259736061096191
training step: 28152, total_loss: 4.6886677742004395
training step: 28153, total_loss: 4.033373832702637
training step: 28154, total_loss: 5.7359538078308105
training step: 28155, total_loss: 4.353185176849365
training step: 28156, total_loss: 4.491389751434326
training step: 28157, total_loss: 6.378638744354248
training step: 28158, total_loss: 3.500039577484131
training step: 28159, total_loss: 4.487454414367676
training step: 28160, total_loss: 4.121715545654297
training step: 28161, total_loss: 4.389707565307617
training step: 28162, total_loss: 5.173040390014648
training step: 28163, total_loss: 2.91094970703125
training step: 28164, total_loss: 5.168547630310059
training step: 28165, total_loss: 3.688453197479248
training step: 28166, total_loss: 4.053987979888916
training step: 28167, total_loss: 4.291299343109131
training step: 28168, total_loss: 5.3772687911987305
training step: 28169, total_loss: 2.8271496295928955
training step: 28170, total_loss: 3.6113333702087402
training step: 28171, total_loss: 5.452117443084717
training step: 28172, total_loss: 4.534467697143555
training step: 28173, total_loss: 4.896002769470215
training step: 28174, total_loss: 4.312397003173828
training step: 28175, total_loss: 3.860792636871338
training step: 28176, total_loss: 3.6547675132751465
training step: 28177, total_loss: 5.442892074584961
training step: 28178, total_loss: 5.642911911010742
training step: 28179, total_loss: 4.749194622039795
training step: 28180, total_loss: 1.3008294105529785
training step: 28181, total_loss: 5.514322280883789
training step: 28182, total_loss: 4.9455156326293945
training step: 28183, total_loss: 4.137568473815918
training step: 28184, total_loss: 4.785497665405273
training step: 28185, total_loss: 5.437756538391113
training step: 28186, total_loss: 5.220331192016602
training step: 28187, total_loss: 4.584921836853027
training step: 28188, total_loss: 4.5138630867004395
training step: 28189, total_loss: 4.576435089111328
training step: 28190, total_loss: 3.9560487270355225
training step: 28191, total_loss: 4.810469627380371
training step: 28192, total_loss: 4.790475845336914
training step: 28193, total_loss: 4.709541320800781
training step: 28194, total_loss: 4.851275444030762
training step: 28195, total_loss: 3.596682071685791
training step: 28196, total_loss: 6.017405033111572
training step: 28197, total_loss: 4.339738845825195
training step: 28198, total_loss: 4.8180012702941895
training step: 28199, total_loss: 4.877519130706787
training step: 28200, total_loss: 4.340813159942627
training step: 28201, total_loss: 4.365597248077393
training step: 28202, total_loss: 4.575568199157715
training step: 28203, total_loss: 3.8072597980499268
training step: 28204, total_loss: 5.963444709777832
training step: 28205, total_loss: 3.864670753479004
training step: 28206, total_loss: 4.423088073730469
training step: 28207, total_loss: 4.451748847961426
training step: 28208, total_loss: 4.628115177154541
training step: 28209, total_loss: 5.048851013183594
training step: 28210, total_loss: 4.662507057189941
training step: 28211, total_loss: 5.842386245727539
training step: 28212, total_loss: 4.924694061279297
training step: 28213, total_loss: 4.034807205200195
training step: 28214, total_loss: 3.9150352478027344
training step: 28215, total_loss: 4.488614082336426
training step: 28216, total_loss: 4.150602340698242
training step: 28217, total_loss: 1.8804402351379395
training step: 28218, total_loss: 4.115261554718018
training step: 28219, total_loss: 4.8781843185424805
training step: 28220, total_loss: 4.3284010887146
training step: 28221, total_loss: 4.738299369812012
training step: 28222, total_loss: 2.899872064590454
training step: 28223, total_loss: 4.8616719245910645
training step: 28224, total_loss: 4.509688854217529
training step: 28225, total_loss: 4.554415702819824
training step: 28226, total_loss: 4.270719528198242
training step: 28227, total_loss: 3.362173080444336
training step: 28228, total_loss: 4.216985702514648
training step: 28229, total_loss: 3.348538637161255
training step: 28230, total_loss: 5.936672210693359
training step: 28231, total_loss: 4.175673484802246
training step: 28232, total_loss: 1.2059996128082275
training step: 28233, total_loss: 3.6395645141601562
training step: 28234, total_loss: 3.015623092651367
training step: 28235, total_loss: 5.0213727951049805
training step: 28236, total_loss: 1.018641710281372
training step: 28237, total_loss: 2.969372272491455
training step: 28238, total_loss: 3.4118781089782715
training step: 28239, total_loss: 4.6312665939331055
training step: 28240, total_loss: 2.6477346420288086
training step: 28241, total_loss: 4.605223655700684
training step: 28242, total_loss: 3.150235176086426
training step: 28243, total_loss: 3.827198028564453
training step: 28244, total_loss: 4.64261531829834
training step: 28245, total_loss: 2.6181130409240723
training step: 28246, total_loss: 4.4014129638671875
training step: 28247, total_loss: 4.042634010314941
training step: 28248, total_loss: 3.976623058319092
training step: 28249, total_loss: 4.198413848876953
training step: 28250, total_loss: 4.473910331726074
training step: 28251, total_loss: 3.419116973876953
training step: 28252, total_loss: 3.7397756576538086
training step: 28253, total_loss: 6.683472633361816
training step: 28254, total_loss: 4.837382793426514
training step: 28255, total_loss: 3.9052271842956543
training step: 28256, total_loss: 4.890836238861084
training step: 28257, total_loss: 5.52678918838501
training step: 28258, total_loss: 5.808006286621094
training step: 28259, total_loss: 3.8819003105163574
training step: 28260, total_loss: 4.574134349822998
training step: 28261, total_loss: 1.9079194068908691
training step: 28262, total_loss: 3.8978211879730225
training step: 28263, total_loss: 5.255084991455078
training step: 28264, total_loss: 6.758256435394287
training step: 28265, total_loss: 5.660566806793213
training step: 28266, total_loss: 5.480763912200928
training step: 28267, total_loss: 5.138311386108398
training step: 28268, total_loss: 5.179627418518066
training step: 28269, total_loss: 4.36018180847168
training step: 28270, total_loss: 2.5436415672302246
training step: 28271, total_loss: 3.34641170501709
training step: 28272, total_loss: 4.969418525695801
training step: 28273, total_loss: 4.684077262878418
training step: 28274, total_loss: 4.4554314613342285
training step: 28275, total_loss: 5.606626033782959
training step: 28276, total_loss: 1.8797115087509155
training step: 28277, total_loss: 5.209251880645752
training step: 28278, total_loss: 2.6011953353881836
training step: 28279, total_loss: 3.767857074737549
training step: 28280, total_loss: 5.030783176422119
training step: 28281, total_loss: 5.205654144287109
training step: 28282, total_loss: 4.997561454772949
training step: 28283, total_loss: 4.16126012802124
training step: 28284, total_loss: 3.3443565368652344
training step: 28285, total_loss: 5.363858222961426
training step: 28286, total_loss: 4.003436088562012
training step: 28287, total_loss: 2.881741523742676
training step: 28288, total_loss: 4.904311656951904
training step: 28289, total_loss: 5.547574043273926
training step: 28290, total_loss: 2.955843925476074
training step: 28291, total_loss: 4.469241619110107
training step: 28292, total_loss: 4.682987689971924
training step: 28293, total_loss: 4.468903064727783
training step: 28294, total_loss: 5.6410908699035645
training step: 28295, total_loss: 5.7337541580200195
training step: 28296, total_loss: 5.861940860748291
training step: 28297, total_loss: 5.134788990020752
training step: 28298, total_loss: 4.627046585083008
training step: 28299, total_loss: 3.714181661605835
training step: 28300, total_loss: 5.945666313171387
training step: 28301, total_loss: 4.617588520050049
training step: 28302, total_loss: 4.416031837463379
training step: 28303, total_loss: 4.4684906005859375
training step: 28304, total_loss: 4.858242034912109
training step: 28305, total_loss: 1.9281554222106934
training step: 28306, total_loss: 3.9459266662597656
training step: 28307, total_loss: 4.371486663818359
training step: 28308, total_loss: 4.3077545166015625
training step: 28309, total_loss: 4.4342451095581055
training step: 28310, total_loss: 3.2016830444335938
training step: 28311, total_loss: 3.814215898513794
training step: 28312, total_loss: 2.94309139251709
training step: 28313, total_loss: 4.007277965545654
training step: 28314, total_loss: 3.05400013923645
training step: 28315, total_loss: 4.531411170959473
training step: 28316, total_loss: 4.497023582458496
training step: 28317, total_loss: 5.74384880065918
training step: 28318, total_loss: 4.730105400085449
training step: 28319, total_loss: 5.228126049041748
training step: 28320, total_loss: 3.8697562217712402
training step: 28321, total_loss: 5.264575481414795
training step: 28322, total_loss: 3.6323540210723877
training step: 28323, total_loss: 4.334494590759277
training step: 28324, total_loss: 5.734896659851074
training step: 28325, total_loss: 4.019622802734375
training step: 28326, total_loss: 4.422590255737305
training step: 28327, total_loss: 4.514594078063965
training step: 28328, total_loss: 6.589778900146484
training step: 28329, total_loss: 4.041000843048096
training step: 28330, total_loss: 3.934948444366455
training step: 28331, total_loss: 5.926731109619141
training step: 28332, total_loss: 5.530453681945801
training step: 28333, total_loss: 5.914012908935547
training step: 28334, total_loss: 4.732954025268555
training step: 28335, total_loss: 3.707040309906006
training step: 28336, total_loss: 5.1881818771362305
training step: 28337, total_loss: 5.015999794006348
training step: 28338, total_loss: 2.5037682056427
training step: 28339, total_loss: 3.7766590118408203
training step: 28340, total_loss: 6.70442533493042
training step: 28341, total_loss: 4.816240310668945
training step: 28342, total_loss: 4.743733882904053
training step: 28343, total_loss: 4.6568193435668945
training step: 28344, total_loss: 5.061680793762207
training step: 28345, total_loss: 5.0268096923828125
training step: 28346, total_loss: 4.153848648071289
training step: 28347, total_loss: 3.8323404788970947
training step: 28348, total_loss: 4.890776634216309
training step: 28349, total_loss: 4.973095893859863
training step: 28350, total_loss: 4.045836925506592
training step: 28351, total_loss: 4.577721118927002
training step: 28352, total_loss: 4.737044334411621
training step: 28353, total_loss: 5.28756046295166
training step: 28354, total_loss: 4.801714897155762
training step: 28355, total_loss: 3.3087680339813232
training step: 28356, total_loss: 3.4945034980773926
training step: 28357, total_loss: 4.974079132080078
training step: 28358, total_loss: 6.619349002838135
training step: 28359, total_loss: 5.3519816398620605
training step: 28360, total_loss: 4.215936660766602
training step: 28361, total_loss: 4.375132083892822
training step: 28362, total_loss: 4.672249794006348
training step: 28363, total_loss: 3.409778594970703
training step: 28364, total_loss: 4.540359973907471
training step: 28365, total_loss: 5.526968002319336
training step: 28366, total_loss: 2.9903407096862793
training step: 28367, total_loss: 4.205018997192383
training step: 28368, total_loss: 3.242145538330078
training step: 28369, total_loss: 4.957795143127441
training step: 28370, total_loss: 3.5920701026916504
training step: 28371, total_loss: 2.882673740386963
training step: 28372, total_loss: 4.204287528991699
training step: 28373, total_loss: 4.140854835510254
training step: 28374, total_loss: 3.750063419342041
training step: 28375, total_loss: 3.5370917320251465
training step: 28376, total_loss: 5.007452964782715
training step: 28377, total_loss: 4.697967529296875
training step: 28378, total_loss: 5.020066261291504
training step: 28379, total_loss: 5.602972984313965
training step: 28380, total_loss: 5.121410846710205
training step: 28381, total_loss: 4.042293071746826
training step: 28382, total_loss: 3.646096706390381
training step: 28383, total_loss: 4.407238483428955
training step: 28384, total_loss: 5.545468330383301
training step: 28385, total_loss: 4.386682510375977
training step: 28386, total_loss: 5.539742946624756
training step: 28387, total_loss: 3.399996757507324
training step: 28388, total_loss: 5.146790504455566
training step: 28389, total_loss: 4.113958835601807
training step: 28390, total_loss: 6.0809760093688965
training step: 28391, total_loss: 4.653822898864746
training step: 28392, total_loss: 5.26203727722168
training step: 28393, total_loss: 3.5573174953460693
training step: 28394, total_loss: 5.738224029541016
training step: 28395, total_loss: 4.023829936981201
training step: 28396, total_loss: 4.749798774719238
training step: 28397, total_loss: 4.601815700531006
training step: 28398, total_loss: 5.26882266998291
training step: 28399, total_loss: 5.2283935546875
training step: 28400, total_loss: 4.9191999435424805
training step: 28401, total_loss: 6.497310638427734
training step: 28402, total_loss: 5.208357334136963
training step: 28403, total_loss: 5.101127624511719
training step: 28404, total_loss: 5.536501884460449
training step: 28405, total_loss: 4.392606735229492
training step: 28406, total_loss: 1.5883643627166748
training step: 28407, total_loss: 5.3020243644714355
training step: 28408, total_loss: 5.2552900314331055
training step: 28409, total_loss: 4.768272399902344
training step: 28410, total_loss: 3.8813529014587402
training step: 28411, total_loss: 5.3663129806518555
training step: 28412, total_loss: 4.169659614562988
training step: 28413, total_loss: 4.6471662521362305
training step: 28414, total_loss: 3.623414993286133
training step: 28415, total_loss: 4.059767723083496
training step: 28416, total_loss: 4.366308689117432
training step: 28417, total_loss: 5.857050895690918
training step: 28418, total_loss: 4.324532985687256
training step: 28419, total_loss: 5.275938987731934
training step: 28420, total_loss: 3.3000905513763428
training step: 28421, total_loss: 4.84942626953125
training step: 28422, total_loss: 4.5702033042907715
training step: 28423, total_loss: 5.786714553833008
training step: 28424, total_loss: 5.152167797088623
training step: 28425, total_loss: 4.247868537902832
training step: 28426, total_loss: 3.1619791984558105
training step: 28427, total_loss: 3.1386070251464844
training step: 28428, total_loss: 1.1663463115692139
training step: 28429, total_loss: 3.868420362472534
training step: 28430, total_loss: 4.245163917541504
training step: 28431, total_loss: 3.158451557159424
training step: 28432, total_loss: 3.4537196159362793
training step: 28433, total_loss: 5.457422733306885
training step: 28434, total_loss: 5.087693214416504
training step: 28435, total_loss: 4.6082329750061035
training step: 28436, total_loss: 1.4566919803619385
training step: 28437, total_loss: 4.889620780944824
training step: 28438, total_loss: 4.085492134094238
training step: 28439, total_loss: 3.7645885944366455
training step: 28440, total_loss: 4.854994773864746
training step: 28441, total_loss: 4.980885982513428
training step: 28442, total_loss: 4.113046169281006
training step: 28443, total_loss: 4.338499069213867
training step: 28444, total_loss: 2.3161001205444336
training step: 28445, total_loss: 5.6900715827941895
training step: 28446, total_loss: 4.2285332679748535
training step: 28447, total_loss: 5.180632591247559
training step: 28448, total_loss: 5.137487411499023
training step: 28449, total_loss: 4.401411533355713
training step: 28450, total_loss: 2.956503391265869
training step: 28451, total_loss: 4.985692977905273
training step: 28452, total_loss: 4.098607063293457
training step: 28453, total_loss: 5.703805923461914
training step: 28454, total_loss: 4.094367980957031
training step: 28455, total_loss: 4.4311842918396
training step: 28456, total_loss: 5.2987823486328125
training step: 28457, total_loss: 3.8085198402404785
training step: 28458, total_loss: 3.7876100540161133
training step: 28459, total_loss: 4.542192459106445
training step: 28460, total_loss: 4.211786270141602
training step: 28461, total_loss: 1.158286690711975
training step: 28462, total_loss: 5.283618927001953
training step: 28463, total_loss: 4.914884090423584
training step: 28464, total_loss: 4.649441719055176
training step: 28465, total_loss: 0.9947410821914673
training step: 28466, total_loss: 5.858107566833496
training step: 28467, total_loss: 2.8923330307006836
training step: 28468, total_loss: 5.112582206726074
training step: 28469, total_loss: 3.1771345138549805
training step: 28470, total_loss: 3.912184000015259
training step: 28471, total_loss: 4.276163101196289
training step: 28472, total_loss: 4.661357402801514
training step: 28473, total_loss: 4.34626579284668
training step: 28474, total_loss: 4.463050842285156
training step: 28475, total_loss: 3.8486037254333496
training step: 28476, total_loss: 4.102616310119629
training step: 28477, total_loss: 4.36796760559082
training step: 28478, total_loss: 2.9509401321411133
training step: 28479, total_loss: 4.005430221557617
training step: 28480, total_loss: 4.7508344650268555
training step: 28481, total_loss: 4.6019511222839355
training step: 28482, total_loss: 4.355628967285156
training step: 28483, total_loss: 1.020461082458496
training step: 28484, total_loss: 4.365815162658691
training step: 28485, total_loss: 4.974480628967285
training step: 28486, total_loss: 3.774674654006958
training step: 28487, total_loss: 1.0768722295761108
training step: 28488, total_loss: 4.923381805419922
training step: 28489, total_loss: 6.273949146270752
training step: 28490, total_loss: 2.7517664432525635
training step: 28491, total_loss: 3.5205798149108887
training step: 28492, total_loss: 4.4318132400512695
training step: 28493, total_loss: 3.902647018432617
training step: 28494, total_loss: 4.16428279876709
training step: 28495, total_loss: 4.972294807434082
training step: 28496, total_loss: 5.035490036010742
training step: 28497, total_loss: 4.146162986755371
training step: 28498, total_loss: 4.5123372077941895
training step: 28499, total_loss: 5.584590911865234
training step: 28500, total_loss: 5.512560844421387
training step: 28501, total_loss: 5.106020927429199
training step: 28502, total_loss: 3.4424872398376465
training step: 28503, total_loss: 3.2038440704345703
training step: 28504, total_loss: 3.601705551147461
training step: 28505, total_loss: 5.405544281005859
training step: 28506, total_loss: 5.943868637084961
training step: 28507, total_loss: 3.971388101577759
training step: 28508, total_loss: 4.959419250488281
training step: 28509, total_loss: 5.161365509033203
training step: 28510, total_loss: 5.219311714172363
training step: 28511, total_loss: 4.820107936859131
training step: 28512, total_loss: 6.092576026916504
training step: 28513, total_loss: 4.60283899307251
training step: 28514, total_loss: 4.3258562088012695
training step: 28515, total_loss: 4.25533390045166
training step: 28516, total_loss: 4.350505828857422
training step: 28517, total_loss: 5.590015411376953
training step: 28518, total_loss: 6.119390487670898
training step: 28519, total_loss: 3.3734261989593506
training step: 28520, total_loss: 3.8582425117492676
training step: 28521, total_loss: 3.63798189163208
training step: 28522, total_loss: 3.6859169006347656
training step: 28523, total_loss: 2.988521099090576
training step: 28524, total_loss: 4.564687728881836
training step: 28525, total_loss: 4.551373481750488
training step: 28526, total_loss: 4.546534061431885
training step: 28527, total_loss: 4.682265758514404
training step: 28528, total_loss: 3.4226486682891846
training step: 28529, total_loss: 5.812372207641602
training step: 28530, total_loss: 4.8903584480285645
training step: 28531, total_loss: 4.156009674072266
training step: 28532, total_loss: 4.144223213195801
training step: 28533, total_loss: 4.743996620178223
training step: 28534, total_loss: 5.306334495544434
training step: 28535, total_loss: 4.734738826751709
training step: 28536, total_loss: 4.846015930175781
training step: 28537, total_loss: 4.8705034255981445
training step: 28538, total_loss: 3.717090129852295
training step: 28539, total_loss: 4.14200496673584
training step: 28540, total_loss: 5.3437604904174805
training step: 28541, total_loss: 5.386214733123779
training step: 28542, total_loss: 6.251977920532227
training step: 28543, total_loss: 4.853302001953125
training step: 28544, total_loss: 5.247372627258301
training step: 28545, total_loss: 4.8693952560424805
training step: 28546, total_loss: 4.9978485107421875
training step: 28547, total_loss: 3.9885635375976562
training step: 28548, total_loss: 4.447519779205322
training step: 28549, total_loss: 4.135829925537109
training step: 28550, total_loss: 4.291794300079346
training step: 28551, total_loss: 4.675368309020996
training step: 28552, total_loss: 3.926638603210449
training step: 28553, total_loss: 4.874878883361816
training step: 28554, total_loss: 4.164926052093506
training step: 28555, total_loss: 6.21038818359375
training step: 28556, total_loss: 4.7846550941467285
training step: 28557, total_loss: 4.312228679656982
training step: 28558, total_loss: 3.4581336975097656
training step: 28559, total_loss: 4.648123741149902
training step: 28560, total_loss: 3.7232460975646973
training step: 28561, total_loss: 4.5474677085876465
training step: 28562, total_loss: 5.181164741516113
training step: 28563, total_loss: 4.705726623535156
training step: 28564, total_loss: 5.231321334838867
training step: 28565, total_loss: 6.30089807510376
training step: 28566, total_loss: 5.385181427001953
training step: 28567, total_loss: 4.204649925231934
training step: 28568, total_loss: 4.338222026824951
training step: 28569, total_loss: 5.2935357093811035
training step: 28570, total_loss: 4.588718414306641
training step: 28571, total_loss: 3.8259119987487793
training step: 28572, total_loss: 3.3356237411499023
training step: 28573, total_loss: 4.226050853729248
training step: 28574, total_loss: 4.09193229675293
training step: 28575, total_loss: 4.963703155517578
training step: 28576, total_loss: 3.2782201766967773
training step: 28577, total_loss: 4.509538650512695
training step: 28578, total_loss: 1.7811660766601562
training step: 28579, total_loss: 3.34433913230896
training step: 28580, total_loss: 5.289316177368164
training step: 28581, total_loss: 3.8788204193115234
training step: 28582, total_loss: 4.642176151275635
training step: 28583, total_loss: 4.222687244415283
training step: 28584, total_loss: 4.000730991363525
training step: 28585, total_loss: 4.31843900680542
training step: 28586, total_loss: 6.132076263427734
training step: 28587, total_loss: 4.635124683380127
training step: 28588, total_loss: 4.89749002456665
training step: 28589, total_loss: 3.91688871383667
training step: 28590, total_loss: 4.006678581237793
training step: 28591, total_loss: 4.430031776428223
training step: 28592, total_loss: 4.636880874633789
training step: 28593, total_loss: 3.9231433868408203
training step: 28594, total_loss: 3.750295400619507
training step: 28595, total_loss: 4.033341407775879
training step: 28596, total_loss: 5.943971633911133
training step: 28597, total_loss: 7.271703720092773
training step: 28598, total_loss: 6.6382575035095215
training step: 28599, total_loss: 3.881404399871826
training step: 28600, total_loss: 6.263642311096191
training step: 28601, total_loss: 3.92734956741333
training step: 28602, total_loss: 3.7509732246398926
training step: 28603, total_loss: 4.987436771392822
training step: 28604, total_loss: 3.524393320083618
training step: 28605, total_loss: 2.4887681007385254
training step: 28606, total_loss: 6.497145652770996
training step: 28607, total_loss: 4.418498516082764
training step: 28608, total_loss: 6.379334449768066
training step: 28609, total_loss: 4.958920478820801
training step: 28610, total_loss: 4.3231611251831055
training step: 28611, total_loss: 4.272297382354736
training step: 28612, total_loss: 3.519012451171875
training step: 28613, total_loss: 5.008574485778809
training step: 28614, total_loss: 3.3972673416137695
training step: 28615, total_loss: 4.646082878112793
training step: 28616, total_loss: 3.36405086517334
training step: 28617, total_loss: 4.550694465637207
training step: 28618, total_loss: 4.352952480316162
training step: 28619, total_loss: 3.13881254196167
training step: 28620, total_loss: 4.470747947692871
training step: 28621, total_loss: 4.521139621734619
training step: 28622, total_loss: 4.605165481567383
training step: 28623, total_loss: 4.503129959106445
training step: 28624, total_loss: 5.667294502258301
training step: 28625, total_loss: 5.336769104003906
training step: 28626, total_loss: 3.8812079429626465
training step: 28627, total_loss: 3.529081344604492
training step: 28628, total_loss: 4.2187299728393555
training step: 28629, total_loss: 3.372189998626709
training step: 28630, total_loss: 4.123353958129883
training step: 28631, total_loss: 3.4187772274017334
training step: 28632, total_loss: 6.300749778747559
training step: 28633, total_loss: 4.391895771026611
training step: 28634, total_loss: 4.482986927032471
training step: 28635, total_loss: 4.786348342895508
training step: 28636, total_loss: 4.986852645874023
training step: 28637, total_loss: 4.091343879699707
training step: 28638, total_loss: 4.228847503662109
training step: 28639, total_loss: 3.269439458847046
training step: 28640, total_loss: 4.069613933563232
training step: 28641, total_loss: 3.9198122024536133
training step: 28642, total_loss: 5.607028007507324
training step: 28643, total_loss: 3.2638611793518066
training step: 28644, total_loss: 5.332526206970215
training step: 28645, total_loss: 3.1923928260803223
training step: 28646, total_loss: 4.578605651855469
training step: 28647, total_loss: 2.2441253662109375
training step: 28648, total_loss: 5.555734634399414
training step: 28649, total_loss: 6.754490852355957
training step: 28650, total_loss: 5.3616790771484375
training step: 28651, total_loss: 2.67872953414917
training step: 28652, total_loss: 4.346347332000732
training step: 28653, total_loss: 4.740024566650391
training step: 28654, total_loss: 5.802572727203369
training step: 28655, total_loss: 4.2666850090026855
training step: 28656, total_loss: 5.090872764587402
training step: 28657, total_loss: 3.893846035003662
training step: 28658, total_loss: 5.607059478759766
training step: 28659, total_loss: 3.945540428161621
training step: 28660, total_loss: 5.963680267333984
training step: 28661, total_loss: 4.079608917236328
training step: 28662, total_loss: 4.152402877807617
training step: 28663, total_loss: 5.694216728210449
training step: 28664, total_loss: 3.895258903503418
training step: 28665, total_loss: 4.283367156982422
training step: 28666, total_loss: 5.0072150230407715
training step: 28667, total_loss: 4.8407487869262695
training step: 28668, total_loss: 1.433760166168213
training step: 28669, total_loss: 5.323419570922852
training step: 28670, total_loss: 4.62617301940918
training step: 28671, total_loss: 4.724971771240234
training step: 28672, total_loss: 4.2417097091674805
training step: 28673, total_loss: 4.198333263397217
training step: 28674, total_loss: 5.767634391784668
training step: 28675, total_loss: 5.582400321960449
training step: 28676, total_loss: 4.903268814086914
training step: 28677, total_loss: 3.36220645904541
training step: 28678, total_loss: 4.08513069152832
training step: 28679, total_loss: 3.3982324600219727
training step: 28680, total_loss: 4.712410926818848
training step: 28681, total_loss: 1.2958879470825195
training step: 28682, total_loss: 4.179272651672363
training step: 28683, total_loss: 2.226343870162964
training step: 28684, total_loss: 4.921126842498779
training step: 28685, total_loss: 5.385983943939209
training step: 28686, total_loss: 4.506564140319824
training step: 28687, total_loss: 3.7005014419555664
training step: 28688, total_loss: 3.8282363414764404
training step: 28689, total_loss: 4.769293308258057
training step: 28690, total_loss: 2.917388916015625
training step: 28691, total_loss: 3.335272789001465
training step: 28692, total_loss: 5.905845642089844
training step: 28693, total_loss: 5.4105329513549805
training step: 28694, total_loss: 4.774374008178711
training step: 28695, total_loss: 3.641134738922119
training step: 28696, total_loss: 3.911895990371704
training step: 28697, total_loss: 5.134522914886475
training step: 28698, total_loss: 4.83804178237915
training step: 28699, total_loss: 4.325934410095215
training step: 28700, total_loss: 3.977006196975708
training step: 28701, total_loss: 6.295846939086914
training step: 28702, total_loss: 2.797976016998291
training step: 28703, total_loss: 3.988239288330078
training step: 28704, total_loss: 3.745656728744507
training step: 28705, total_loss: 4.235650539398193
training step: 28706, total_loss: 4.657732009887695
training step: 28707, total_loss: 3.7047367095947266
training step: 28708, total_loss: 4.444260120391846
training step: 28709, total_loss: 4.844610214233398
training step: 28710, total_loss: 3.9647631645202637
training step: 28711, total_loss: 4.6694183349609375
training step: 28712, total_loss: 5.204768657684326
training step: 28713, total_loss: 3.3119304180145264
training step: 28714, total_loss: 5.1101765632629395
training step: 28715, total_loss: 5.885499000549316
training step: 28716, total_loss: 4.874690532684326
training step: 28717, total_loss: 3.576211452484131
training step: 28718, total_loss: 4.8384222984313965
training step: 28719, total_loss: 5.686627388000488
training step: 28720, total_loss: 4.763667106628418
training step: 28721, total_loss: 4.412683486938477
training step: 28722, total_loss: 4.005445957183838
training step: 28723, total_loss: 3.6440658569335938
training step: 28724, total_loss: 3.26267147064209
training step: 28725, total_loss: 4.994305610656738
training step: 28726, total_loss: 4.556066989898682
training step: 28727, total_loss: 4.283541679382324
training step: 28728, total_loss: 4.1805500984191895
training step: 28729, total_loss: 4.549793720245361
training step: 28730, total_loss: 4.061967849731445
training step: 28731, total_loss: 4.3287353515625
training step: 28732, total_loss: 5.431509017944336
training step: 28733, total_loss: 3.6125967502593994
training step: 28734, total_loss: 4.878393173217773
training step: 28735, total_loss: 4.427028656005859
training step: 28736, total_loss: 2.9696335792541504
training step: 28737, total_loss: 3.9076178073883057
training step: 28738, total_loss: 4.136698246002197
training step: 28739, total_loss: 4.805753707885742
training step: 28740, total_loss: 4.223761558532715
training step: 28741, total_loss: 4.650805473327637
training step: 28742, total_loss: 3.7753639221191406
training step: 28743, total_loss: 5.549019813537598
training step: 28744, total_loss: 4.993131637573242
training step: 28745, total_loss: 5.371332168579102
training step: 28746, total_loss: 4.696734428405762
training step: 28747, total_loss: 1.1172780990600586
training step: 28748, total_loss: 4.248536586761475
training step: 28749, total_loss: 4.545687198638916
training step: 28750, total_loss: 4.401786804199219
training step: 28751, total_loss: 3.773336887359619
training step: 28752, total_loss: 4.169630527496338
training step: 28753, total_loss: 3.5825071334838867
training step: 28754, total_loss: 4.757624626159668
training step: 28755, total_loss: 6.736438751220703
training step: 28756, total_loss: 6.071864604949951
training step: 28757, total_loss: 4.655296802520752
training step: 28758, total_loss: 4.316622257232666
training step: 28759, total_loss: 5.432467460632324
training step: 28760, total_loss: 3.2522616386413574
training step: 28761, total_loss: 4.497684001922607
training step: 28762, total_loss: 5.821674346923828
training step: 28763, total_loss: 4.412105560302734
training step: 28764, total_loss: 4.234870433807373
training step: 28765, total_loss: 4.943536758422852
training step: 28766, total_loss: 5.513095855712891
training step: 28767, total_loss: 4.812469005584717
training step: 28768, total_loss: 5.345952033996582
training step: 28769, total_loss: 4.353538990020752
training step: 28770, total_loss: 5.120632648468018
training step: 28771, total_loss: 5.36173152923584
training step: 28772, total_loss: 4.529121398925781
training step: 28773, total_loss: 3.905627489089966
training step: 28774, total_loss: 4.687726020812988
training step: 28775, total_loss: 4.4962663650512695
training step: 28776, total_loss: 5.141724109649658
training step: 28777, total_loss: 3.75311279296875
training step: 28778, total_loss: 5.127750873565674
training step: 28779, total_loss: 4.336816787719727
training step: 28780, total_loss: 4.739800453186035
training step: 28781, total_loss: 4.5745415687561035
training step: 28782, total_loss: 2.6292428970336914
training step: 28783, total_loss: 1.6685374975204468
training step: 28784, total_loss: 4.408477783203125
training step: 28785, total_loss: 5.579699993133545
training step: 28786, total_loss: 3.3329966068267822
training step: 28787, total_loss: 4.9752726554870605
training step: 28788, total_loss: 5.075273513793945
training step: 28789, total_loss: 4.441718578338623
training step: 28790, total_loss: 5.246756553649902
training step: 28791, total_loss: 4.2571306228637695
training step: 28792, total_loss: 3.947662830352783
training step: 28793, total_loss: 5.796846866607666
training step: 28794, total_loss: 4.383495330810547
training step: 28795, total_loss: 5.219038963317871
training step: 28796, total_loss: 2.806976079940796
training step: 28797, total_loss: 4.0166401863098145
training step: 28798, total_loss: 5.69490385055542
training step: 28799, total_loss: 4.434515953063965
training step: 28800, total_loss: 4.6245646476745605
training step: 28801, total_loss: 4.920339107513428
training step: 28802, total_loss: 4.765347003936768
training step: 28803, total_loss: 4.094009876251221
training step: 28804, total_loss: 4.316455364227295
training step: 28805, total_loss: 4.596863746643066
training step: 28806, total_loss: 5.88922119140625
training step: 28807, total_loss: 5.610953330993652
training step: 28808, total_loss: 4.384081840515137
training step: 28809, total_loss: 5.300009250640869
training step: 28810, total_loss: 4.058539867401123
training step: 28811, total_loss: 4.823177337646484
training step: 28812, total_loss: 1.0307528972625732
training step: 28813, total_loss: 4.357840538024902
training step: 28814, total_loss: 5.637369632720947
training step: 28815, total_loss: 3.4226346015930176
training step: 28816, total_loss: 4.089272499084473
training step: 28817, total_loss: 3.813314437866211
training step: 28818, total_loss: 5.391111373901367
training step: 28819, total_loss: 3.152620792388916
training step: 28820, total_loss: 5.863485336303711
training step: 28821, total_loss: 4.830366134643555
training step: 28822, total_loss: 4.818778038024902
training step: 28823, total_loss: 3.3397202491760254
training step: 28824, total_loss: 4.955831527709961
training step: 28825, total_loss: 3.829569101333618
training step: 28826, total_loss: 4.585877418518066
training step: 28827, total_loss: 5.309528350830078
training step: 28828, total_loss: 5.821616172790527
training step: 28829, total_loss: 4.465498447418213
training step: 28830, total_loss: 3.241241455078125
training step: 28831, total_loss: 5.064383029937744
training step: 28832, total_loss: 4.953237533569336
training step: 28833, total_loss: 5.583203315734863
training step: 28834, total_loss: 4.272985935211182
training step: 28835, total_loss: 4.892978668212891
training step: 28836, total_loss: 4.4257707595825195
training step: 28837, total_loss: 4.668949604034424
training step: 28838, total_loss: 4.259256362915039
training step: 28839, total_loss: 4.305429935455322
training step: 28840, total_loss: 5.176210880279541
training step: 28841, total_loss: 1.1323535442352295
training step: 28842, total_loss: 4.614618301391602
training step: 28843, total_loss: 2.6692142486572266
training step: 28844, total_loss: 5.1920576095581055
training step: 28845, total_loss: 5.512009143829346
training step: 28846, total_loss: 1.360825777053833
training step: 28847, total_loss: 3.9213860034942627
training step: 28848, total_loss: 3.2266547679901123
training step: 28849, total_loss: 4.526719570159912
training step: 28850, total_loss: 3.713764190673828
training step: 28851, total_loss: 5.405828475952148
training step: 28852, total_loss: 5.851798057556152
training step: 28853, total_loss: 4.68122673034668
training step: 28854, total_loss: 5.653240203857422
training step: 28855, total_loss: 2.6125454902648926
training step: 28856, total_loss: 4.3192644119262695
training step: 28857, total_loss: 3.997171640396118
training step: 28858, total_loss: 4.073807239532471
training step: 28859, total_loss: 4.982661724090576
training step: 28860, total_loss: 6.913045406341553
training step: 28861, total_loss: 4.447999000549316
training step: 28862, total_loss: 4.788500785827637
training step: 28863, total_loss: 4.672999382019043
training step: 28864, total_loss: 3.5063395500183105
training step: 28865, total_loss: 4.734928131103516
training step: 28866, total_loss: 3.7653863430023193
training step: 28867, total_loss: 4.040607452392578
training step: 28868, total_loss: 4.901415824890137
training step: 28869, total_loss: 5.6160969734191895
training step: 28870, total_loss: 4.260393142700195
training step: 28871, total_loss: 3.5951662063598633
training step: 28872, total_loss: 6.3079915046691895
training step: 28873, total_loss: 3.894941568374634
training step: 28874, total_loss: 4.843092918395996
training step: 28875, total_loss: 5.515041351318359
training step: 28876, total_loss: 3.023925304412842
training step: 28877, total_loss: 5.192287445068359
training step: 28878, total_loss: 3.8380062580108643
training step: 28879, total_loss: 5.6462554931640625
training step: 28880, total_loss: 5.081718444824219
training step: 28881, total_loss: 2.95365047454834
training step: 28882, total_loss: 4.366703987121582
training step: 28883, total_loss: 6.915759563446045
training step: 28884, total_loss: 5.272556304931641
training step: 28885, total_loss: 3.962414264678955
training step: 28886, total_loss: 5.896605014801025
training step: 28887, total_loss: 0.7664335370063782
training step: 28888, total_loss: 4.491519927978516
training step: 28889, total_loss: 4.187173843383789
training step: 28890, total_loss: 5.093441963195801
training step: 28891, total_loss: 4.4245524406433105
training step: 28892, total_loss: 4.010305404663086
training step: 28893, total_loss: 5.606119155883789
training step: 28894, total_loss: 2.900388717651367
training step: 28895, total_loss: 4.196969509124756
training step: 28896, total_loss: 5.12030029296875
training step: 28897, total_loss: 4.501874923706055
training step: 28898, total_loss: 4.70433235168457
training step: 28899, total_loss: 5.337961196899414
training step: 28900, total_loss: 6.120942115783691
training step: 28901, total_loss: 4.379332542419434
training step: 28902, total_loss: 4.3023295402526855
training step: 28903, total_loss: 4.302107810974121
training step: 28904, total_loss: 6.827066421508789
training step: 28905, total_loss: 4.769830703735352
training step: 28906, total_loss: 5.3983564376831055
training step: 28907, total_loss: 5.8983845710754395
training step: 28908, total_loss: 4.102700233459473
training step: 28909, total_loss: 4.214004993438721
training step: 28910, total_loss: 3.917238712310791
training step: 28911, total_loss: 3.6351170539855957
training step: 28912, total_loss: 0.985673189163208
training step: 28913, total_loss: 4.706051349639893
training step: 28914, total_loss: 4.60292911529541
training step: 28915, total_loss: 5.36229133605957
training step: 28916, total_loss: 4.396238803863525
training step: 28917, total_loss: 4.321967601776123
training step: 28918, total_loss: 4.914373397827148
training step: 28919, total_loss: 5.129183769226074
training step: 28920, total_loss: 6.159811019897461
training step: 28921, total_loss: 5.2235612869262695
training step: 28922, total_loss: 4.583422660827637
training step: 28923, total_loss: 5.133166313171387
training step: 28924, total_loss: 4.430970191955566
training step: 28925, total_loss: 4.724362373352051
training step: 28926, total_loss: 5.8891143798828125
training step: 28927, total_loss: 4.130986213684082
training step: 28928, total_loss: 4.769215106964111
training step: 28929, total_loss: 4.531145095825195
training step: 28930, total_loss: 6.163212776184082
training step: 28931, total_loss: 3.5808939933776855
training step: 28932, total_loss: 4.334074974060059
training step: 28933, total_loss: 4.316974639892578
training step: 28934, total_loss: 2.556781530380249
training step: 28935, total_loss: 3.94160795211792
training step: 28936, total_loss: 5.211823463439941
training step: 28937, total_loss: 5.507582187652588
training step: 28938, total_loss: 5.123220443725586
training step: 28939, total_loss: 4.0659332275390625
training step: 28940, total_loss: 4.49532413482666
training step: 28941, total_loss: 4.741064548492432
training step: 28942, total_loss: 3.9587583541870117
training step: 28943, total_loss: 5.804281711578369
training step: 28944, total_loss: 4.565647125244141
training step: 28945, total_loss: 1.0905282497406006
training step: 28946, total_loss: 7.762421131134033
training step: 28947, total_loss: 3.8348257541656494
training step: 28948, total_loss: 4.116132736206055
training step: 28949, total_loss: 4.237816333770752
training step: 28950, total_loss: 5.197299957275391
training step: 28951, total_loss: 5.619773864746094
training step: 28952, total_loss: 4.070868968963623
training step: 28953, total_loss: 3.296945571899414
training step: 28954, total_loss: 3.9792895317077637
training step: 28955, total_loss: 4.037294387817383
training step: 28956, total_loss: 5.453058242797852
training step: 28957, total_loss: 4.188784122467041
training step: 28958, total_loss: 5.9374213218688965
training step: 28959, total_loss: 5.372878551483154
training step: 28960, total_loss: 3.7141780853271484
training step: 28961, total_loss: 4.217914581298828
training step: 28962, total_loss: 4.458595275878906
training step: 28963, total_loss: 4.255114555358887
training step: 28964, total_loss: 4.609304904937744
training step: 28965, total_loss: 5.045927047729492
training step: 28966, total_loss: 4.678732872009277
training step: 28967, total_loss: 4.045600891113281
training step: 28968, total_loss: 4.252355575561523
training step: 28969, total_loss: 4.656461715698242
training step: 28970, total_loss: 4.30435848236084
training step: 28971, total_loss: 4.294790744781494
training step: 28972, total_loss: 3.487452507019043
training step: 28973, total_loss: 4.352186679840088
training step: 28974, total_loss: 4.227567195892334
training step: 28975, total_loss: 4.747253894805908
training step: 28976, total_loss: 3.4771246910095215
training step: 28977, total_loss: 5.893135070800781
training step: 28978, total_loss: 4.823526382446289
training step: 28979, total_loss: 4.248042106628418
training step: 28980, total_loss: 4.277809143066406
training step: 28981, total_loss: 4.008277893066406
training step: 28982, total_loss: 5.36728572845459
training step: 28983, total_loss: 4.251062393188477
training step: 28984, total_loss: 3.76658296585083
training step: 28985, total_loss: 5.64637565612793
training step: 28986, total_loss: 4.466200351715088
training step: 28987, total_loss: 4.51472806930542
training step: 28988, total_loss: 5.229877471923828
training step: 28989, total_loss: 4.542025566101074
training step: 28990, total_loss: 3.5398125648498535
training step: 28991, total_loss: 2.4735307693481445
training step: 28992, total_loss: 4.836117744445801
training step: 28993, total_loss: 4.109657287597656
training step: 28994, total_loss: 1.9418513774871826
training step: 28995, total_loss: 1.0618369579315186
training step: 28996, total_loss: 4.550175666809082
training step: 28997, total_loss: 6.187008857727051
training step: 28998, total_loss: 7.696236610412598
training step: 28999, total_loss: 3.3160908222198486
training step: 29000, total_loss: 3.6100986003875732
training step: 29001, total_loss: 5.5460309982299805
training step: 29002, total_loss: 3.711820125579834
training step: 29003, total_loss: 3.9389500617980957
training step: 29004, total_loss: 5.048559665679932
training step: 29005, total_loss: 4.354333877563477
training step: 29006, total_loss: 4.495375633239746
training step: 29007, total_loss: 6.063307762145996
training step: 29008, total_loss: 3.5803065299987793
training step: 29009, total_loss: 5.130565166473389
training step: 29010, total_loss: 4.416353225708008
training step: 29011, total_loss: 3.887916088104248
training step: 29012, total_loss: 5.050327777862549
training step: 29013, total_loss: 4.877804279327393
training step: 29014, total_loss: 4.651288032531738
training step: 29015, total_loss: 4.932641983032227
training step: 29016, total_loss: 5.2662129402160645
training step: 29017, total_loss: 4.383408546447754
training step: 29018, total_loss: 4.9476518630981445
training step: 29019, total_loss: 2.586297035217285
training step: 29020, total_loss: 4.704617500305176
training step: 29021, total_loss: 3.8386037349700928
training step: 29022, total_loss: 4.189308166503906
training step: 29023, total_loss: 4.14861536026001
training step: 29024, total_loss: 3.008164405822754
training step: 29025, total_loss: 3.384121894836426
training step: 29026, total_loss: 4.517163276672363
training step: 29027, total_loss: 5.674365520477295
training step: 29028, total_loss: 2.6355175971984863
training step: 29029, total_loss: 5.3072967529296875
training step: 29030, total_loss: 4.985512733459473
training step: 29031, total_loss: 4.384097576141357
training step: 29032, total_loss: 4.643100738525391
training step: 29033, total_loss: 2.642702579498291
training step: 29034, total_loss: 3.4118504524230957
training step: 29035, total_loss: 5.304011344909668
training step: 29036, total_loss: 4.485972881317139
training step: 29037, total_loss: 5.101933002471924
training step: 29038, total_loss: 4.464241981506348
training step: 29039, total_loss: 4.276872634887695
training step: 29040, total_loss: 3.489290237426758
training step: 29041, total_loss: 4.699654579162598
training step: 29042, total_loss: 4.515743255615234
training step: 29043, total_loss: 5.2704620361328125
training step: 29044, total_loss: 5.526458263397217
training step: 29045, total_loss: 3.295942783355713
training step: 29046, total_loss: 5.923162460327148
training step: 29047, total_loss: 5.041684627532959
training step: 29048, total_loss: 7.835755825042725
training step: 29049, total_loss: 4.4382781982421875
training step: 29050, total_loss: 5.366894721984863
training step: 29051, total_loss: 4.629171371459961
training step: 29052, total_loss: 3.7847390174865723
training step: 29053, total_loss: 3.916501522064209
training step: 29054, total_loss: 4.292209148406982
training step: 29055, total_loss: 4.226527214050293
training step: 29056, total_loss: 4.869316101074219
training step: 29057, total_loss: 3.7740509510040283
training step: 29058, total_loss: 6.516913414001465
training step: 29059, total_loss: 4.38730525970459
training step: 29060, total_loss: 3.9070568084716797
training step: 29061, total_loss: 4.226550102233887
training step: 29062, total_loss: 4.652829170227051
training step: 29063, total_loss: 4.317996978759766
training step: 29064, total_loss: 3.6791603565216064
training step: 29065, total_loss: 4.4520263671875
training step: 29066, total_loss: 4.49945068359375
training step: 29067, total_loss: 2.8522682189941406
training step: 29068, total_loss: 4.008467674255371
training step: 29069, total_loss: 4.16621208190918
training step: 29070, total_loss: 4.382128715515137
training step: 29071, total_loss: 4.347867965698242
training step: 29072, total_loss: 5.891749382019043
training step: 29073, total_loss: 5.489194393157959
training step: 29074, total_loss: 3.5495259761810303
training step: 29075, total_loss: 5.271343231201172
training step: 29076, total_loss: 1.7041884660720825
training step: 29077, total_loss: 6.546197891235352
training step: 29078, total_loss: 4.0319390296936035
training step: 29079, total_loss: 2.8253209590911865
training step: 29080, total_loss: 4.334714889526367
training step: 29081, total_loss: 4.568948268890381
training step: 29082, total_loss: 4.525248050689697
training step: 29083, total_loss: 4.947626113891602
training step: 29084, total_loss: 3.995758056640625
training step: 29085, total_loss: 6.050431251525879
training step: 29086, total_loss: 5.809352874755859
training step: 29087, total_loss: 5.312776565551758
training step: 29088, total_loss: 3.950124979019165
training step: 29089, total_loss: 3.116344928741455
training step: 29090, total_loss: 1.2124512195587158
training step: 29091, total_loss: 5.807574272155762
training step: 29092, total_loss: 4.177438735961914
training step: 29093, total_loss: 3.2111172676086426
training step: 29094, total_loss: 5.620332717895508
training step: 29095, total_loss: 4.897143363952637
training step: 29096, total_loss: 5.399704933166504
training step: 29097, total_loss: 2.8857920169830322
training step: 29098, total_loss: 4.729893684387207
training step: 29099, total_loss: 3.828169345855713
training step: 29100, total_loss: 1.2219252586364746
training step: 29101, total_loss: 4.407961845397949
training step: 29102, total_loss: 5.514518737792969
training step: 29103, total_loss: 4.054852485656738
training step: 29104, total_loss: 3.5067875385284424
training step: 29105, total_loss: 4.163188457489014
training step: 29106, total_loss: 4.344236373901367
training step: 29107, total_loss: 3.6519651412963867
training step: 29108, total_loss: 2.954267978668213
training step: 29109, total_loss: 3.3170828819274902
training step: 29110, total_loss: 5.1048431396484375
training step: 29111, total_loss: 4.030218601226807
training step: 29112, total_loss: 4.084018707275391
training step: 29113, total_loss: 2.988186836242676
training step: 29114, total_loss: 3.0403389930725098
training step: 29115, total_loss: 5.550335884094238
training step: 29116, total_loss: 4.945023536682129
training step: 29117, total_loss: 3.4601974487304688
training step: 29118, total_loss: 4.915241241455078
training step: 29119, total_loss: 0.9569165706634521
training step: 29120, total_loss: 4.872865200042725
training step: 29121, total_loss: 2.8659467697143555
training step: 29122, total_loss: 6.102472305297852
training step: 29123, total_loss: 5.4059367179870605
training step: 29124, total_loss: 4.264418601989746
training step: 29125, total_loss: 6.244849681854248
training step: 29126, total_loss: 2.810807943344116
training step: 29127, total_loss: 4.11432409286499
training step: 29128, total_loss: 4.416032791137695
training step: 29129, total_loss: 3.5218286514282227
training step: 29130, total_loss: 3.9704644680023193
training step: 29131, total_loss: 4.5361738204956055
training step: 29132, total_loss: 3.8700270652770996
training step: 29133, total_loss: 4.046180248260498
training step: 29134, total_loss: 4.184370040893555
training step: 29135, total_loss: 5.475344657897949
training step: 29136, total_loss: 4.392743110656738
training step: 29137, total_loss: 0.6366903781890869
training step: 29138, total_loss: 4.692075729370117
training step: 29139, total_loss: 0.7162680625915527
training step: 29140, total_loss: 2.746623992919922
training step: 29141, total_loss: 5.967716693878174
training step: 29142, total_loss: 6.134309768676758
training step: 29143, total_loss: 4.248399257659912
training step: 29144, total_loss: 4.931099891662598
training step: 29145, total_loss: 3.5338973999023438
training step: 29146, total_loss: 5.0950608253479
training step: 29147, total_loss: 5.776792049407959
training step: 29148, total_loss: 5.227538108825684
training step: 29149, total_loss: 0.9236958622932434
training step: 29150, total_loss: 3.710085391998291
training step: 29151, total_loss: 4.649827480316162
training step: 29152, total_loss: 3.3177900314331055
training step: 29153, total_loss: 4.874544143676758
training step: 29154, total_loss: 4.500673294067383
training step: 29155, total_loss: 5.927120685577393
training step: 29156, total_loss: 4.645005226135254
training step: 29157, total_loss: 5.466370582580566
training step: 29158, total_loss: 3.541292667388916
training step: 29159, total_loss: 5.8975138664245605
training step: 29160, total_loss: 4.606281757354736
training step: 29161, total_loss: 4.160705089569092
training step: 29162, total_loss: 4.085339546203613
training step: 29163, total_loss: 4.1720452308654785
training step: 29164, total_loss: 4.458472728729248
training step: 29165, total_loss: 4.185512065887451
training step: 29166, total_loss: 4.4584479331970215
training step: 29167, total_loss: 4.402741432189941
training step: 29168, total_loss: 5.080692291259766
training step: 29169, total_loss: 2.562748432159424
training step: 29170, total_loss: 4.05246639251709
training step: 29171, total_loss: 4.979099750518799
training step: 29172, total_loss: 4.634390830993652
training step: 29173, total_loss: 5.417372703552246
training step: 29174, total_loss: 4.17752742767334
training step: 29175, total_loss: 4.110047817230225
training step: 29176, total_loss: 5.261971473693848
training step: 29177, total_loss: 4.634690284729004
training step: 29178, total_loss: 5.37806510925293
training step: 29179, total_loss: 4.69968318939209
training step: 29180, total_loss: 4.486664772033691
training step: 29181, total_loss: 3.395564079284668
training step: 29182, total_loss: 4.1790032386779785
training step: 29183, total_loss: 5.8943562507629395
training step: 29184, total_loss: 4.698367118835449
training step: 29185, total_loss: 4.889675140380859
training step: 29186, total_loss: 3.4207916259765625
training step: 29187, total_loss: 3.7510550022125244
training step: 29188, total_loss: 4.636648178100586
training step: 29189, total_loss: 5.099502086639404
training step: 29190, total_loss: 4.9258856773376465
training step: 29191, total_loss: 5.0032548904418945
training step: 29192, total_loss: 4.294557094573975
training step: 29193, total_loss: 3.3847572803497314
training step: 29194, total_loss: 5.6763916015625
training step: 29195, total_loss: 4.222128868103027
training step: 29196, total_loss: 4.626000881195068
training step: 29197, total_loss: 4.520672798156738
training step: 29198, total_loss: 4.864645957946777
training step: 29199, total_loss: 3.7785487174987793
training step: 29200, total_loss: 4.024528503417969
training step: 29201, total_loss: 4.831547260284424
training step: 29202, total_loss: 2.9349212646484375
training step: 29203, total_loss: 3.9386065006256104
training step: 29204, total_loss: 3.601732015609741
training step: 29205, total_loss: 5.97086238861084
training step: 29206, total_loss: 4.609742164611816
training step: 29207, total_loss: 4.200693130493164
training step: 29208, total_loss: 4.537980079650879
training step: 29209, total_loss: 4.566486358642578
training step: 29210, total_loss: 5.600330352783203
training step: 29211, total_loss: 5.502922534942627
training step: 29212, total_loss: 3.2258124351501465
training step: 29213, total_loss: 4.700932025909424
training step: 29214, total_loss: 3.1393346786499023
training step: 29215, total_loss: 4.332884311676025
training step: 29216, total_loss: 6.183925628662109
training step: 29217, total_loss: 4.847929954528809
training step: 29218, total_loss: 5.283379554748535
training step: 29219, total_loss: 4.536574363708496
training step: 29220, total_loss: 5.950844764709473
training step: 29221, total_loss: 4.5457682609558105
training step: 29222, total_loss: 2.649338722229004
training step: 29223, total_loss: 4.04594612121582
training step: 29224, total_loss: 4.686207294464111
training step: 29225, total_loss: 3.678560256958008
training step: 29226, total_loss: 3.517159938812256
training step: 29227, total_loss: 4.280756950378418
training step: 29228, total_loss: 4.467779159545898
training step: 29229, total_loss: 3.097064971923828
training step: 29230, total_loss: 4.417591571807861
training step: 29231, total_loss: 4.4659881591796875
training step: 29232, total_loss: 5.4712371826171875
training step: 29233, total_loss: 4.770893096923828
training step: 29234, total_loss: 3.5925841331481934
training step: 29235, total_loss: 5.947187423706055
training step: 29236, total_loss: 2.7587220668792725
training step: 29237, total_loss: 5.931194305419922
training step: 29238, total_loss: 3.4393110275268555
training step: 29239, total_loss: 5.254426002502441
training step: 29240, total_loss: 5.567844390869141
training step: 29241, total_loss: 5.939794540405273
training step: 29242, total_loss: 5.086705207824707
training step: 29243, total_loss: 4.129310131072998
training step: 29244, total_loss: 3.6568541526794434
training step: 29245, total_loss: 4.634726524353027
training step: 29246, total_loss: 4.115039825439453
training step: 29247, total_loss: 5.002144813537598
training step: 29248, total_loss: 5.867347717285156
training step: 29249, total_loss: 4.324831962585449
training step: 29250, total_loss: 4.4808831214904785
training step: 29251, total_loss: 3.397490978240967
training step: 29252, total_loss: 4.81710147857666
training step: 29253, total_loss: 4.228911876678467
training step: 29254, total_loss: 6.090453147888184
training step: 29255, total_loss: 5.017276763916016
training step: 29256, total_loss: 6.852764129638672
training step: 29257, total_loss: 3.7295889854431152
training step: 29258, total_loss: 4.936880111694336
training step: 29259, total_loss: 4.39846134185791
training step: 29260, total_loss: 5.206707954406738
training step: 29261, total_loss: 3.0499188899993896
training step: 29262, total_loss: 4.548868179321289
training step: 29263, total_loss: 2.9515416622161865
training step: 29264, total_loss: 5.345891952514648
training step: 29265, total_loss: 4.117857933044434
training step: 29266, total_loss: 5.994635105133057
training step: 29267, total_loss: 5.853091239929199
training step: 29268, total_loss: 4.838266372680664
training step: 29269, total_loss: 2.948087215423584
training step: 29270, total_loss: 3.4797139167785645
training step: 29271, total_loss: 5.644840717315674
training step: 29272, total_loss: 4.287717819213867
training step: 29273, total_loss: 3.684527635574341
training step: 29274, total_loss: 2.6964588165283203
training step: 29275, total_loss: 4.385153770446777
training step: 29276, total_loss: 4.741549015045166
training step: 29277, total_loss: 4.263102054595947
training step: 29278, total_loss: 5.781712055206299
training step: 29279, total_loss: 4.8439435958862305
training step: 29280, total_loss: 3.367849826812744
training step: 29281, total_loss: 4.024341583251953
training step: 29282, total_loss: 4.646050453186035
training step: 29283, total_loss: 4.056821823120117
training step: 29284, total_loss: 5.558368682861328
training step: 29285, total_loss: 4.208348274230957
training step: 29286, total_loss: 3.62290620803833
training step: 29287, total_loss: 6.467160224914551
training step: 29288, total_loss: 4.379305839538574
training step: 29289, total_loss: 2.837686061859131
training step: 29290, total_loss: 4.368062973022461
training step: 29291, total_loss: 4.4990363121032715
training step: 29292, total_loss: 3.2805233001708984
training step: 29293, total_loss: 4.152491092681885
training step: 29294, total_loss: 4.753836631774902
training step: 29295, total_loss: 4.689356803894043
training step: 29296, total_loss: 3.6698555946350098
training step: 29297, total_loss: 5.793073654174805
training step: 29298, total_loss: 4.811993598937988
training step: 29299, total_loss: 5.795795440673828
training step: 29300, total_loss: 4.663822174072266
training step: 29301, total_loss: 5.49644136428833
training step: 29302, total_loss: 4.102138996124268
training step: 29303, total_loss: 4.563747406005859
training step: 29304, total_loss: 4.421659469604492
training step: 29305, total_loss: 4.731049537658691
training step: 29306, total_loss: 4.889253616333008
training step: 29307, total_loss: 4.427720546722412
training step: 29308, total_loss: 4.927980422973633
training step: 29309, total_loss: 4.455491542816162
training step: 29310, total_loss: 4.345938682556152
training step: 29311, total_loss: 5.0026631355285645
training step: 29312, total_loss: 3.671354055404663
training step: 29313, total_loss: 4.0961809158325195
training step: 29314, total_loss: 5.501470565795898
training step: 29315, total_loss: 3.3866777420043945
training step: 29316, total_loss: 3.982907295227051
training step: 29317, total_loss: 5.46434211730957
training step: 29318, total_loss: 4.942256450653076
training step: 29319, total_loss: 3.973907470703125
training step: 29320, total_loss: 4.013965606689453
training step: 29321, total_loss: 5.1602067947387695
training step: 29322, total_loss: 2.1889967918395996
training step: 29323, total_loss: 4.376529216766357
training step: 29324, total_loss: 5.852822780609131
training step: 29325, total_loss: 5.40665864944458
training step: 29326, total_loss: 4.095800876617432
training step: 29327, total_loss: 4.101891994476318
training step: 29328, total_loss: 5.176587104797363
training step: 29329, total_loss: 4.672121047973633
training step: 29330, total_loss: 5.827978134155273
training step: 29331, total_loss: 1.2048609256744385
training step: 29332, total_loss: 4.46497106552124
training step: 29333, total_loss: 3.3878631591796875
training step: 29334, total_loss: 5.163368225097656
training step: 29335, total_loss: 4.920815467834473
training step: 29336, total_loss: 3.874242067337036
training step: 29337, total_loss: 4.960936546325684
training step: 29338, total_loss: 5.188851356506348
training step: 29339, total_loss: 4.474095821380615
training step: 29340, total_loss: 2.8648948669433594
training step: 29341, total_loss: 4.958106994628906
training step: 29342, total_loss: 5.88914680480957
training step: 29343, total_loss: 5.890883922576904
training step: 29344, total_loss: 5.829518795013428
training step: 29345, total_loss: 4.76691198348999
training step: 29346, total_loss: 4.100841999053955
training step: 29347, total_loss: 4.438800811767578
training step: 29348, total_loss: 4.435796737670898
training step: 29349, total_loss: 4.4297919273376465
training step: 29350, total_loss: 4.544991970062256
training step: 29351, total_loss: 4.647648811340332
training step: 29352, total_loss: 5.467741012573242
training step: 29353, total_loss: 4.526703834533691
training step: 29354, total_loss: 4.31649923324585
training step: 29355, total_loss: 2.7515668869018555
training step: 29356, total_loss: 6.554257392883301
training step: 29357, total_loss: 5.040828704833984
training step: 29358, total_loss: 4.2656941413879395
training step: 29359, total_loss: 4.548348426818848
training step: 29360, total_loss: 3.2066872119903564
training step: 29361, total_loss: 6.595144271850586
training step: 29362, total_loss: 4.55966854095459
training step: 29363, total_loss: 5.431865692138672
training step: 29364, total_loss: 4.871827125549316
training step: 29365, total_loss: 4.4821672439575195
training step: 29366, total_loss: 4.595242500305176
training step: 29367, total_loss: 5.927964210510254
training step: 29368, total_loss: 5.144610404968262
training step: 29369, total_loss: 2.8338382244110107
training step: 29370, total_loss: 2.2177672386169434
training step: 29371, total_loss: 3.613506555557251
training step: 29372, total_loss: 3.1697378158569336
training step: 29373, total_loss: 3.6191582679748535
training step: 29374, total_loss: 3.808228015899658
training step: 29375, total_loss: 5.146505355834961
training step: 29376, total_loss: 4.415060997009277
training step: 29377, total_loss: 2.5503997802734375
training step: 29378, total_loss: 3.7266409397125244
training step: 29379, total_loss: 4.217553615570068
training step: 29380, total_loss: 1.5166409015655518
training step: 29381, total_loss: 4.388912200927734
training step: 29382, total_loss: 4.22432279586792
training step: 29383, total_loss: 4.042092323303223
training step: 29384, total_loss: 7.278320789337158
training step: 29385, total_loss: 4.43947172164917
training step: 29386, total_loss: 5.17927360534668
training step: 29387, total_loss: 5.472267150878906
training step: 29388, total_loss: 4.94924259185791
training step: 29389, total_loss: 4.706834316253662
training step: 29390, total_loss: 3.408869743347168
training step: 29391, total_loss: 5.485490322113037
training step: 29392, total_loss: 4.454904556274414
training step: 29393, total_loss: 5.129337787628174
training step: 29394, total_loss: 4.631339073181152
training step: 29395, total_loss: 4.500362396240234
training step: 29396, total_loss: 4.909000396728516
training step: 29397, total_loss: 4.311560153961182
training step: 29398, total_loss: 4.215552806854248
training step: 29399, total_loss: 3.7255260944366455
training step: 29400, total_loss: 4.817794322967529
training step: 29401, total_loss: 3.708223581314087
training step: 29402, total_loss: 4.796777725219727
training step: 29403, total_loss: 4.851783752441406
training step: 29404, total_loss: 3.2547051906585693
training step: 29405, total_loss: 4.991660118103027
training step: 29406, total_loss: 3.7081048488616943
training step: 29407, total_loss: 4.2986063957214355
training step: 29408, total_loss: 5.323742389678955
training step: 29409, total_loss: 5.422515392303467
training step: 29410, total_loss: 4.840054512023926
training step: 29411, total_loss: 2.9226222038269043
training step: 29412, total_loss: 3.897618532180786
training step: 29413, total_loss: 5.76210880279541
training step: 29414, total_loss: 2.6242008209228516
training step: 29415, total_loss: 4.3569207191467285
training step: 29416, total_loss: 3.5227084159851074
training step: 29417, total_loss: 5.218505859375
training step: 29418, total_loss: 3.4890053272247314
training step: 29419, total_loss: 4.66047477722168
training step: 29420, total_loss: 7.5717363357543945
training step: 29421, total_loss: 3.8883721828460693
training step: 29422, total_loss: 3.981818914413452
training step: 29423, total_loss: 4.1442670822143555
training step: 29424, total_loss: 5.251429557800293
training step: 29425, total_loss: 4.36713981628418
training step: 29426, total_loss: 4.402240753173828
training step: 29427, total_loss: 4.877636909484863
training step: 29428, total_loss: 3.8407840728759766
training step: 29429, total_loss: 3.5572683811187744
training step: 29430, total_loss: 3.8879175186157227
training step: 29431, total_loss: 4.035433292388916
training step: 29432, total_loss: 4.226666450500488
training step: 29433, total_loss: 4.193658351898193
training step: 29434, total_loss: 3.010192632675171
training step: 29435, total_loss: 6.0449042320251465
training step: 29436, total_loss: 4.761837482452393
training step: 29437, total_loss: 3.943239688873291
training step: 29438, total_loss: 5.071704864501953
training step: 29439, total_loss: 3.8004462718963623
training step: 29440, total_loss: 2.523928642272949
training step: 29441, total_loss: 3.315765380859375
training step: 29442, total_loss: 3.8884475231170654
training step: 29443, total_loss: 4.3663225173950195
training step: 29444, total_loss: 4.374999046325684
training step: 29445, total_loss: 6.12709903717041
training step: 29446, total_loss: 3.777336835861206
training step: 29447, total_loss: 4.383590221405029
training step: 29448, total_loss: 4.248106956481934
training step: 29449, total_loss: 1.2906149625778198
training step: 29450, total_loss: 5.4302659034729
training step: 29451, total_loss: 2.4146580696105957
training step: 29452, total_loss: 5.2357354164123535
training step: 29453, total_loss: 5.488038063049316
training step: 29454, total_loss: 4.026363372802734
training step: 29455, total_loss: 6.410308837890625
training step: 29456, total_loss: 3.472142219543457
training step: 29457, total_loss: 4.231855392456055
training step: 29458, total_loss: 2.179516077041626
training step: 29459, total_loss: 4.740048885345459
training step: 29460, total_loss: 4.257228851318359
training step: 29461, total_loss: 6.97055721282959
training step: 29462, total_loss: 6.639368534088135
training step: 29463, total_loss: 3.9024007320404053
training step: 29464, total_loss: 3.6826629638671875
training step: 29465, total_loss: 3.420586585998535
training step: 29466, total_loss: 5.178321361541748
training step: 29467, total_loss: 3.819094181060791
training step: 29468, total_loss: 5.691632270812988
training step: 29469, total_loss: 4.780381679534912
training step: 29470, total_loss: 5.470878601074219
training step: 29471, total_loss: 5.200052261352539
training step: 29472, total_loss: 4.999332427978516
training step: 29473, total_loss: 3.5353245735168457
training step: 29474, total_loss: 4.810701847076416
training step: 29475, total_loss: 4.500824928283691
training step: 29476, total_loss: 4.1566972732543945
training step: 29477, total_loss: 3.617382049560547
training step: 29478, total_loss: 4.685515403747559
training step: 29479, total_loss: 4.463761329650879
training step: 29480, total_loss: 5.25757360458374
training step: 29481, total_loss: 2.872525691986084
training step: 29482, total_loss: 4.862330436706543
training step: 29483, total_loss: 5.06683349609375
training step: 29484, total_loss: 3.8979575634002686
training step: 29485, total_loss: 4.8932037353515625
training step: 29486, total_loss: 5.037271976470947
training step: 29487, total_loss: 4.0106964111328125
training step: 29488, total_loss: 4.171809196472168
training step: 29489, total_loss: 5.487621307373047
training step: 29490, total_loss: 3.9786834716796875
training step: 29491, total_loss: 4.631589889526367
training step: 29492, total_loss: 4.894892692565918
training step: 29493, total_loss: 4.2735915184021
training step: 29494, total_loss: 4.360834121704102
training step: 29495, total_loss: 5.96580171585083
training step: 29496, total_loss: 4.9615607261657715
training step: 29497, total_loss: 4.29433536529541
training step: 29498, total_loss: 4.528884410858154
training step: 29499, total_loss: 2.911330461502075
training step: 29500, total_loss: 5.4508161544799805
training step: 29501, total_loss: 5.244868278503418
training step: 29502, total_loss: 5.5972900390625
training step: 29503, total_loss: 3.562150478363037
training step: 29504, total_loss: 3.720561981201172
training step: 29505, total_loss: 3.3673486709594727
training step: 29506, total_loss: 2.4862780570983887
training step: 29507, total_loss: 4.29299783706665
training step: 29508, total_loss: 5.376438140869141
training step: 29509, total_loss: 4.538217544555664
training step: 29510, total_loss: 3.320570945739746
training step: 29511, total_loss: 4.419681549072266
training step: 29512, total_loss: 4.968946933746338
training step: 29513, total_loss: 5.415796279907227
training step: 29514, total_loss: 3.167569398880005
training step: 29515, total_loss: 4.614471912384033
training step: 29516, total_loss: 5.185668468475342
training step: 29517, total_loss: 4.552282333374023
training step: 29518, total_loss: 5.388763427734375
training step: 29519, total_loss: 3.761589527130127
training step: 29520, total_loss: 4.393258094787598
training step: 29521, total_loss: 4.669637680053711
training step: 29522, total_loss: 5.73403263092041
training step: 29523, total_loss: 3.9963207244873047
training step: 29524, total_loss: 3.855034351348877
training step: 29525, total_loss: 5.273032188415527
training step: 29526, total_loss: 4.592679023742676
training step: 29527, total_loss: 1.3790841102600098
training step: 29528, total_loss: 6.185729026794434
training step: 29529, total_loss: 4.026078701019287
training step: 29530, total_loss: 4.701300621032715
training step: 29531, total_loss: 3.5329604148864746
training step: 29532, total_loss: 4.247566223144531
training step: 29533, total_loss: 3.7621889114379883
training step: 29534, total_loss: 4.537604331970215
training step: 29535, total_loss: 4.085289001464844
training step: 29536, total_loss: 5.736271858215332
training step: 29537, total_loss: 1.1191425323486328
training step: 29538, total_loss: 6.731299877166748
training step: 29539, total_loss: 4.511664867401123
training step: 29540, total_loss: 4.343925476074219
training step: 29541, total_loss: 6.29478120803833
training step: 29542, total_loss: 4.602587699890137
training step: 29543, total_loss: 5.506744861602783
training step: 29544, total_loss: 3.948033332824707
training step: 29545, total_loss: 2.8843653202056885
training step: 29546, total_loss: 4.065001964569092
training step: 29547, total_loss: 4.9225053787231445
training step: 29548, total_loss: 4.502329349517822
training step: 29549, total_loss: 4.864114284515381
training step: 29550, total_loss: 3.8795065879821777
training step: 29551, total_loss: 5.188545227050781
training step: 29552, total_loss: 4.511466026306152
training step: 29553, total_loss: 4.223959445953369
training step: 29554, total_loss: 4.368156909942627
training step: 29555, total_loss: 3.829115867614746
training step: 29556, total_loss: 4.6169023513793945
training step: 29557, total_loss: 4.2968244552612305
training step: 29558, total_loss: 3.757767677307129
training step: 29559, total_loss: 4.225465774536133
training step: 29560, total_loss: 3.088392734527588
training step: 29561, total_loss: 5.823615074157715
training step: 29562, total_loss: 6.037186622619629
training step: 29563, total_loss: 4.401341438293457
training step: 29564, total_loss: 5.054547309875488
training step: 29565, total_loss: 3.929504871368408
training step: 29566, total_loss: 4.6468634605407715
training step: 29567, total_loss: 4.482259750366211
training step: 29568, total_loss: 4.468164920806885
training step: 29569, total_loss: 3.069260835647583
training step: 29570, total_loss: 4.766388893127441
training step: 29571, total_loss: 2.815328598022461
training step: 29572, total_loss: 4.343415260314941
training step: 29573, total_loss: 5.1038970947265625
training step: 29574, total_loss: 4.590606212615967
training step: 29575, total_loss: 5.8345489501953125
training step: 29576, total_loss: 4.800382614135742
training step: 29577, total_loss: 4.644039154052734
training step: 29578, total_loss: 5.004316806793213
training step: 29579, total_loss: 3.895970344543457
training step: 29580, total_loss: 3.568793296813965
training step: 29581, total_loss: 2.665771007537842
training step: 29582, total_loss: 5.244356155395508
training step: 29583, total_loss: 4.220715045928955
training step: 29584, total_loss: 5.08158016204834
training step: 29585, total_loss: 4.192943572998047
training step: 29586, total_loss: 5.348123550415039
training step: 29587, total_loss: 3.9950876235961914
training step: 29588, total_loss: 4.048896789550781
training step: 29589, total_loss: 4.185677528381348
training step: 29590, total_loss: 3.285148859024048
training step: 29591, total_loss: 5.36796760559082
training step: 29592, total_loss: 5.802737236022949
training step: 29593, total_loss: 2.801102638244629
training step: 29594, total_loss: 4.915117263793945
training step: 29595, total_loss: 3.491054058074951
training step: 29596, total_loss: 4.29210901260376
training step: 29597, total_loss: 4.450544834136963
training step: 29598, total_loss: 4.863968849182129
training step: 29599, total_loss: 5.07576847076416
training step: 29600, total_loss: 5.755327224731445
training step: 29601, total_loss: 3.274493455886841
training step: 29602, total_loss: 6.368078708648682
training step: 29603, total_loss: 7.499020576477051
training step: 29604, total_loss: 4.2984395027160645
training step: 29605, total_loss: 4.087193012237549
training step: 29606, total_loss: 3.987271547317505
training step: 29607, total_loss: 5.004676818847656
training step: 29608, total_loss: 3.8247909545898438
training step: 29609, total_loss: 5.3578643798828125
training step: 29610, total_loss: 3.809638023376465
training step: 29611, total_loss: 3.9756369590759277
training step: 29612, total_loss: 4.322104454040527
training step: 29613, total_loss: 3.889770746231079
training step: 29614, total_loss: 5.0039472579956055
training step: 29615, total_loss: 4.599810600280762
training step: 29616, total_loss: 5.444157600402832
training step: 29617, total_loss: 4.38663387298584
training step: 29618, total_loss: 3.997239828109741
training step: 29619, total_loss: 3.2297592163085938
training step: 29620, total_loss: 4.433584213256836
training step: 29621, total_loss: 4.537716388702393
training step: 29622, total_loss: 5.305811405181885
training step: 29623, total_loss: 1.4820184707641602
training step: 29624, total_loss: 4.567028045654297
training step: 29625, total_loss: 4.413247108459473
training step: 29626, total_loss: 4.075066566467285
training step: 29627, total_loss: 6.002491474151611
training step: 29628, total_loss: 1.6038339138031006
training step: 29629, total_loss: 2.6176345348358154
training step: 29630, total_loss: 3.8048768043518066
training step: 29631, total_loss: 3.5856759548187256
training step: 29632, total_loss: 4.811990737915039
training step: 29633, total_loss: 4.527252197265625
training step: 29634, total_loss: 4.202557563781738
training step: 29635, total_loss: 4.26927375793457
training step: 29636, total_loss: 4.006983757019043
training step: 29637, total_loss: 4.75921630859375
training step: 29638, total_loss: 3.8071703910827637
training step: 29639, total_loss: 4.294752597808838
training step: 29640, total_loss: 5.011608123779297
training step: 29641, total_loss: 4.208799839019775
training step: 29642, total_loss: 5.3990020751953125
training step: 29643, total_loss: 4.4685163497924805
training step: 29644, total_loss: 5.709758281707764
training step: 29645, total_loss: 7.3199944496154785
training step: 29646, total_loss: 5.263833999633789
training step: 29647, total_loss: 5.554487705230713
training step: 29648, total_loss: 5.3009233474731445
training step: 29649, total_loss: 3.2512431144714355
training step: 29650, total_loss: 4.493603229522705
training step: 29651, total_loss: 5.935290813446045
training step: 29652, total_loss: 5.9785261154174805
training step: 29653, total_loss: 4.414038181304932
training step: 29654, total_loss: 5.280811309814453
training step: 29655, total_loss: 5.074860572814941
training step: 29656, total_loss: 5.102203845977783
training step: 29657, total_loss: 4.783638954162598
training step: 29658, total_loss: 3.3931288719177246
training step: 29659, total_loss: 5.218975067138672
training step: 29660, total_loss: 2.986403465270996
training step: 29661, total_loss: 3.95052170753479
training step: 29662, total_loss: 5.126218795776367
training step: 29663, total_loss: 3.7718029022216797
training step: 29664, total_loss: 4.965440273284912
training step: 29665, total_loss: 3.4264631271362305
training step: 29666, total_loss: 3.425541400909424
training step: 29667, total_loss: 4.647909164428711
training step: 29668, total_loss: 4.881352424621582
training step: 29669, total_loss: 4.580270767211914
training step: 29670, total_loss: 4.9629316329956055
training step: 29671, total_loss: 7.320154190063477
training step: 29672, total_loss: 3.456936836242676
training step: 29673, total_loss: 5.716235637664795
training step: 29674, total_loss: 4.440291404724121
training step: 29675, total_loss: 1.4159433841705322
training step: 29676, total_loss: 4.949995040893555
training step: 29677, total_loss: 4.455964088439941
training step: 29678, total_loss: 4.115208625793457
training step: 29679, total_loss: 1.0636703968048096
training step: 29680, total_loss: 4.101742267608643
training step: 29681, total_loss: 4.774539947509766
training step: 29682, total_loss: 2.8298022747039795
training step: 29683, total_loss: 6.990262985229492
training step: 29684, total_loss: 1.0275843143463135
training step: 29685, total_loss: 3.427785873413086
training step: 29686, total_loss: 3.8222904205322266
training step: 29687, total_loss: 4.318593978881836
training step: 29688, total_loss: 3.0934693813323975
training step: 29689, total_loss: 5.175371170043945
training step: 29690, total_loss: 4.567668914794922
training step: 29691, total_loss: 4.651792526245117
training step: 29692, total_loss: 3.7357354164123535
training step: 29693, total_loss: 4.943670272827148
training step: 29694, total_loss: 4.142351150512695
training step: 29695, total_loss: 4.890582084655762
training step: 29696, total_loss: 6.999136924743652
training step: 29697, total_loss: 4.180171012878418
training step: 29698, total_loss: 5.551820755004883
training step: 29699, total_loss: 0.7760896682739258
training step: 29700, total_loss: 4.428981781005859
training step: 29701, total_loss: 4.6441497802734375
training step: 29702, total_loss: 5.236645698547363
training step: 29703, total_loss: 3.4476118087768555
training step: 29704, total_loss: 4.738326072692871
training step: 29705, total_loss: 4.213408946990967
training step: 29706, total_loss: 6.9854512214660645
training step: 29707, total_loss: 3.9695568084716797
training step: 29708, total_loss: 4.176515579223633
training step: 29709, total_loss: 4.730447769165039
training step: 29710, total_loss: 4.472194194793701
training step: 29711, total_loss: 4.156977653503418
training step: 29712, total_loss: 5.622776031494141
training step: 29713, total_loss: 5.518271446228027
training step: 29714, total_loss: 4.7873992919921875
training step: 29715, total_loss: 4.123798847198486
training step: 29716, total_loss: 3.0043399333953857
training step: 29717, total_loss: 4.290529727935791
training step: 29718, total_loss: 5.183047294616699
training step: 29719, total_loss: 2.2671420574188232
training step: 29720, total_loss: 4.237895965576172
training step: 29721, total_loss: 3.946965217590332
training step: 29722, total_loss: 4.178288459777832
training step: 29723, total_loss: 3.511125087738037
training step: 29724, total_loss: 4.466390132904053
training step: 29725, total_loss: 4.450682640075684
training step: 29726, total_loss: 4.32839822769165
training step: 29727, total_loss: 4.180591583251953
training step: 29728, total_loss: 3.8736424446105957
training step: 29729, total_loss: 4.527833938598633
training step: 29730, total_loss: 2.698150157928467
training step: 29731, total_loss: 1.1899218559265137
training step: 29732, total_loss: 6.444884300231934
training step: 29733, total_loss: 6.0601654052734375
training step: 29734, total_loss: 4.260977745056152
training step: 29735, total_loss: 3.4430129528045654
training step: 29736, total_loss: 5.7840423583984375
training step: 29737, total_loss: 4.134772300720215
training step: 29738, total_loss: 4.020590782165527
training step: 29739, total_loss: 3.8937807083129883
training step: 29740, total_loss: 5.796690464019775
training step: 29741, total_loss: 5.65666389465332
training step: 29742, total_loss: 5.491951942443848
training step: 29743, total_loss: 4.282094478607178
training step: 29744, total_loss: 5.231508731842041
training step: 29745, total_loss: 4.547170162200928
training step: 29746, total_loss: 4.618884086608887
training step: 29747, total_loss: 4.755101680755615
training step: 29748, total_loss: 2.6205005645751953
training step: 29749, total_loss: 5.167674541473389
training step: 29750, total_loss: 4.249544143676758
training step: 29751, total_loss: 4.904531002044678
training step: 29752, total_loss: 5.578090667724609
training step: 29753, total_loss: 6.027501106262207
training step: 29754, total_loss: 5.314708709716797
training step: 29755, total_loss: 4.479633331298828
training step: 29756, total_loss: 3.7442173957824707
training step: 29757, total_loss: 4.8054656982421875
training step: 29758, total_loss: 4.318423271179199
training step: 29759, total_loss: 5.066067695617676
training step: 29760, total_loss: 4.602326393127441
training step: 29761, total_loss: 5.198248863220215
training step: 29762, total_loss: 4.692652225494385
training step: 29763, total_loss: 4.431033134460449
training step: 29764, total_loss: 4.983352184295654
training step: 29765, total_loss: 3.4204256534576416
training step: 29766, total_loss: 4.210606575012207
training step: 29767, total_loss: 4.524866580963135
training step: 29768, total_loss: 4.407149791717529
training step: 29769, total_loss: 5.754513263702393
training step: 29770, total_loss: 5.033243656158447
training step: 29771, total_loss: 3.529151678085327
training step: 29772, total_loss: 3.985649585723877
training step: 29773, total_loss: 5.220934867858887
training step: 29774, total_loss: 4.214456558227539
training step: 29775, total_loss: 5.567596435546875
training step: 29776, total_loss: 1.1746604442596436
training step: 29777, total_loss: 4.390631198883057
training step: 29778, total_loss: 4.906863212585449
training step: 29779, total_loss: 4.701910495758057
training step: 29780, total_loss: 4.207551956176758
training step: 29781, total_loss: 4.5540008544921875
training step: 29782, total_loss: 3.2408599853515625
training step: 29783, total_loss: 4.965900421142578
training step: 29784, total_loss: 3.0733234882354736
training step: 29785, total_loss: 5.381069183349609
training step: 29786, total_loss: 4.734736442565918
training step: 29787, total_loss: 5.965253829956055
training step: 29788, total_loss: 5.051848411560059
training step: 29789, total_loss: 3.2140896320343018
training step: 29790, total_loss: 4.501097679138184
training step: 29791, total_loss: 4.376689910888672
training step: 29792, total_loss: 4.524967193603516
training step: 29793, total_loss: 3.1403989791870117
training step: 29794, total_loss: 4.108382225036621
training step: 29795, total_loss: 5.751619338989258
training step: 29796, total_loss: 2.9338483810424805
training step: 29797, total_loss: 5.955995559692383
training step: 29798, total_loss: 4.287295341491699
training step: 29799, total_loss: 6.692058563232422
training step: 29800, total_loss: 4.187656879425049
training step: 29801, total_loss: 3.526865005493164
training step: 29802, total_loss: 5.456185817718506
training step: 29803, total_loss: 4.172096252441406
training step: 29804, total_loss: 4.113608360290527
training step: 29805, total_loss: 4.533562660217285
training step: 29806, total_loss: 4.944700241088867
training step: 29807, total_loss: 5.251571178436279
training step: 29808, total_loss: 6.507307052612305
training step: 29809, total_loss: 5.355774402618408
training step: 29810, total_loss: 5.223433494567871
training step: 29811, total_loss: 5.1710205078125
training step: 29812, total_loss: 3.7785801887512207
training step: 29813, total_loss: 4.90001106262207
training step: 29814, total_loss: 5.366111755371094
training step: 29815, total_loss: 4.382486343383789
training step: 29816, total_loss: 3.1807687282562256
training step: 29817, total_loss: 5.856672286987305
training step: 29818, total_loss: 5.024506568908691
training step: 29819, total_loss: 3.3066582679748535
training step: 29820, total_loss: 3.5943045616149902
training step: 29821, total_loss: 5.624799728393555
training step: 29822, total_loss: 4.92519474029541
training step: 29823, total_loss: 4.308650016784668
training step: 29824, total_loss: 3.695418357849121
training step: 29825, total_loss: 3.5686516761779785
training step: 29826, total_loss: 5.061967849731445
training step: 29827, total_loss: 4.438319683074951
training step: 29828, total_loss: 3.5401997566223145
training step: 29829, total_loss: 5.113316535949707
training step: 29830, total_loss: 4.273528575897217
training step: 29831, total_loss: 2.828974723815918
training step: 29832, total_loss: 5.723474502563477
training step: 29833, total_loss: 1.2353975772857666
training step: 29834, total_loss: 4.345073699951172
training step: 29835, total_loss: 5.944652557373047
training step: 29836, total_loss: 4.214032173156738
training step: 29837, total_loss: 4.362373352050781
training step: 29838, total_loss: 4.703383922576904
training step: 29839, total_loss: 4.095252990722656
training step: 29840, total_loss: 4.262932300567627
training step: 29841, total_loss: 5.111089706420898
training step: 29842, total_loss: 3.288926601409912
training step: 29843, total_loss: 4.682574272155762
training step: 29844, total_loss: 4.649853229522705
training step: 29845, total_loss: 3.6104941368103027
training step: 29846, total_loss: 3.8300020694732666
training step: 29847, total_loss: 3.3927881717681885
training step: 29848, total_loss: 4.866769790649414
training step: 29849, total_loss: 4.724531173706055
training step: 29850, total_loss: 3.796116828918457
training step: 29851, total_loss: 4.15700101852417
training step: 29852, total_loss: 3.669215679168701
training step: 29853, total_loss: 4.3353190422058105
training step: 29854, total_loss: 4.119260787963867
training step: 29855, total_loss: 4.308598518371582
training step: 29856, total_loss: 4.931713581085205
training step: 29857, total_loss: 3.4282946586608887
training step: 29858, total_loss: 6.195811748504639
training step: 29859, total_loss: 3.8358078002929688
training step: 29860, total_loss: 3.5463333129882812
training step: 29861, total_loss: 4.284997463226318
training step: 29862, total_loss: 4.423321723937988
training step: 29863, total_loss: 2.707855701446533
training step: 29864, total_loss: 4.246556282043457
training step: 29865, total_loss: 4.977636814117432
training step: 29866, total_loss: 1.2847323417663574
training step: 29867, total_loss: 4.854467868804932
training step: 29868, total_loss: 3.635866165161133
training step: 29869, total_loss: 5.271623134613037
training step: 29870, total_loss: 5.03773307800293
training step: 29871, total_loss: 3.3709211349487305
training step: 29872, total_loss: 4.746415138244629
training step: 29873, total_loss: 1.1702654361724854
training step: 29874, total_loss: 4.157752990722656
training step: 29875, total_loss: 4.321651935577393
training step: 29876, total_loss: 4.6490678787231445
training step: 29877, total_loss: 3.904648780822754
training step: 29878, total_loss: 6.612615585327148
training step: 29879, total_loss: 4.67570686340332
training step: 29880, total_loss: 6.962743759155273
training step: 29881, total_loss: 3.4643664360046387
training step: 29882, total_loss: 4.151454925537109
training step: 29883, total_loss: 2.34749174118042
training step: 29884, total_loss: 2.742422580718994
training step: 29885, total_loss: 4.219583988189697
training step: 29886, total_loss: 3.9140563011169434
training step: 29887, total_loss: 2.8034133911132812
training step: 29888, total_loss: 2.8361082077026367
training step: 29889, total_loss: 3.599226951599121
training step: 29890, total_loss: 4.742512226104736
training step: 29891, total_loss: 3.8332643508911133
training step: 29892, total_loss: 5.576234817504883
training step: 29893, total_loss: 6.687108993530273
training step: 29894, total_loss: 3.328500270843506
training step: 29895, total_loss: 4.986486911773682
training step: 29896, total_loss: 6.088313102722168
training step: 29897, total_loss: 4.009746074676514
training step: 29898, total_loss: 5.838955402374268
training step: 29899, total_loss: 4.210390567779541
training step: 29900, total_loss: 4.2955451011657715
training step: 29901, total_loss: 5.2348952293396
training step: 29902, total_loss: 4.702550888061523
training step: 29903, total_loss: 5.523445129394531
training step: 29904, total_loss: 5.348517417907715
training step: 29905, total_loss: 3.9363534450531006
training step: 29906, total_loss: 3.0073018074035645
training step: 29907, total_loss: 4.339408874511719
training step: 29908, total_loss: 4.180459976196289
training step: 29909, total_loss: 3.4888253211975098
training step: 29910, total_loss: 3.6983513832092285
training step: 29911, total_loss: 4.190927505493164
training step: 29912, total_loss: 4.661005020141602
training step: 29913, total_loss: 3.0688629150390625
training step: 29914, total_loss: 5.258660316467285
training step: 29915, total_loss: 2.3172550201416016
training step: 29916, total_loss: 3.55196213722229
training step: 29917, total_loss: 3.4733939170837402
training step: 29918, total_loss: 0.9170762300491333
training step: 29919, total_loss: 5.13109827041626
training step: 29920, total_loss: 5.678560256958008
training step: 29921, total_loss: 2.712833881378174
training step: 29922, total_loss: 4.983816623687744
training step: 29923, total_loss: 1.9159798622131348
training step: 29924, total_loss: 4.249197959899902
training step: 29925, total_loss: 3.7123446464538574
training step: 29926, total_loss: 4.1075897216796875
training step: 29927, total_loss: 2.6039953231811523
training step: 29928, total_loss: 5.026174545288086
training step: 29929, total_loss: 4.074962615966797
training step: 29930, total_loss: 4.005435943603516
training step: 29931, total_loss: 4.14685583114624
training step: 29932, total_loss: 3.0655622482299805
training step: 29933, total_loss: 3.608328342437744
training step: 29934, total_loss: 6.895315170288086
training step: 29935, total_loss: 2.7077555656433105
training step: 29936, total_loss: 5.542875289916992
training step: 29937, total_loss: 3.6971945762634277
training step: 29938, total_loss: 4.3863444328308105
training step: 29939, total_loss: 5.673895835876465
training step: 29940, total_loss: 4.355484962463379
training step: 29941, total_loss: 5.854973793029785
training step: 29942, total_loss: 4.352945327758789
training step: 29943, total_loss: 4.629093170166016
training step: 29944, total_loss: 5.216245651245117
training step: 29945, total_loss: 2.8876938819885254
training step: 29946, total_loss: 4.376625061035156
training step: 29947, total_loss: 4.034915447235107
training step: 29948, total_loss: 5.126490592956543
training step: 29949, total_loss: 4.238736152648926
training step: 29950, total_loss: 4.3006086349487305
training step: 29951, total_loss: 4.325229644775391
training step: 29952, total_loss: 5.135505676269531
training step: 29953, total_loss: 3.9647891521453857
training step: 29954, total_loss: 3.8866934776306152
training step: 29955, total_loss: 6.192112445831299
training step: 29956, total_loss: 4.499340057373047
training step: 29957, total_loss: 4.976375579833984
training step: 29958, total_loss: 4.392235279083252
training step: 29959, total_loss: 5.388091087341309
training step: 29960, total_loss: 4.445125579833984
training step: 29961, total_loss: 5.823639869689941
training step: 29962, total_loss: 4.165751934051514
training step: 29963, total_loss: 4.044431686401367
training step: 29964, total_loss: 5.833181381225586
training step: 29965, total_loss: 4.358380317687988
training step: 29966, total_loss: 2.9156558513641357
training step: 29967, total_loss: 2.8518590927124023
training step: 29968, total_loss: 3.4629263877868652
training step: 29969, total_loss: 5.709006309509277
training step: 29970, total_loss: 5.078948974609375
training step: 29971, total_loss: 6.1339521408081055
training step: 29972, total_loss: 4.6217122077941895
training step: 29973, total_loss: 5.1818413734436035
training step: 29974, total_loss: 6.009578704833984
training step: 29975, total_loss: 4.511163711547852
training step: 29976, total_loss: 1.1598868370056152
training step: 29977, total_loss: 5.135222434997559
training step: 29978, total_loss: 3.436920642852783
training step: 29979, total_loss: 5.229453086853027
training step: 29980, total_loss: 4.914332389831543
training step: 29981, total_loss: 3.9354231357574463
training step: 29982, total_loss: 4.184762001037598
training step: 29983, total_loss: 2.683811664581299
training step: 29984, total_loss: 4.070158004760742
training step: 29985, total_loss: 4.114066123962402
training step: 29986, total_loss: 5.307002544403076
training step: 29987, total_loss: 4.7530012130737305
training step: 29988, total_loss: 4.562632083892822
training step: 29989, total_loss: 4.898580551147461
training step: 29990, total_loss: 5.334635257720947
training step: 29991, total_loss: 5.283931732177734
training step: 29992, total_loss: 5.413090229034424
training step: 29993, total_loss: 4.028944969177246
training step: 29994, total_loss: 4.227519989013672
training step: 29995, total_loss: 4.670660495758057
training step: 29996, total_loss: 5.338812828063965
training step: 29997, total_loss: 4.060605049133301
training step: 29998, total_loss: 4.886718273162842
training step: 29999, total_loss: 5.063023567199707
training step: 30000, total_loss: 4.297964096069336
training step: 30001, total_loss: 4.772282600402832
training step: 30002, total_loss: 1.1097218990325928
training step: 30003, total_loss: 4.738119125366211
training step: 30004, total_loss: 3.041874408721924
training step: 30005, total_loss: 4.115568161010742
training step: 30006, total_loss: 6.540983200073242
training step: 30007, total_loss: 2.830672264099121
training step: 30008, total_loss: 2.96925950050354
training step: 30009, total_loss: 4.509937286376953
training step: 30010, total_loss: 2.7433438301086426
training step: 30011, total_loss: 3.2952282428741455
training step: 30012, total_loss: 5.167868137359619
training step: 30013, total_loss: 4.404153823852539
training step: 30014, total_loss: 3.7963881492614746
training step: 30015, total_loss: 5.102643013000488
training step: 30016, total_loss: 4.30289363861084
training step: 30017, total_loss: 5.721518516540527
training step: 30018, total_loss: 3.9040050506591797
training step: 30019, total_loss: 5.685727119445801
training step: 30020, total_loss: 5.292872428894043
training step: 30021, total_loss: 3.2552833557128906
training step: 30022, total_loss: 4.264992713928223
training step: 30023, total_loss: 5.345349311828613
training step: 30024, total_loss: 4.57585334777832
training step: 30025, total_loss: 4.5728654861450195
training step: 30026, total_loss: 4.657751083374023
training step: 30027, total_loss: 4.996323585510254
training step: 30028, total_loss: 4.6916961669921875
training step: 30029, total_loss: 3.9233179092407227
training step: 30030, total_loss: 3.183429002761841
training step: 30031, total_loss: 4.226899147033691
training step: 30032, total_loss: 5.6425018310546875
training step: 30033, total_loss: 5.384059906005859
training step: 30034, total_loss: 3.28448486328125
training step: 30035, total_loss: 4.754685401916504
training step: 30036, total_loss: 4.400527477264404
training step: 30037, total_loss: 4.1844658851623535
training step: 30038, total_loss: 4.5996174812316895
training step: 30039, total_loss: 6.09029483795166
training step: 30040, total_loss: 3.3214526176452637
training step: 30041, total_loss: 3.335240364074707
training step: 30042, total_loss: 6.564598560333252
training step: 30043, total_loss: 4.332981109619141
training step: 30044, total_loss: 5.1033430099487305
training step: 30045, total_loss: 3.745424747467041
training step: 30046, total_loss: 5.373227119445801
training step: 30047, total_loss: 3.9101099967956543
training step: 30048, total_loss: 3.5659894943237305
training step: 30049, total_loss: 4.954448223114014
training step: 30050, total_loss: 4.956263065338135
training step: 30051, total_loss: 4.257409572601318
training step: 30052, total_loss: 4.974909782409668
training step: 30053, total_loss: 4.305727005004883
training step: 30054, total_loss: 4.150538444519043
training step: 30055, total_loss: 5.253053665161133
training step: 30056, total_loss: 4.496405601501465
training step: 30057, total_loss: 4.381744384765625
training step: 30058, total_loss: 5.482004165649414
training step: 30059, total_loss: 5.378631114959717
training step: 30060, total_loss: 1.397476077079773
training step: 30061, total_loss: 1.49147629737854
training step: 30062, total_loss: 3.7614216804504395
training step: 30063, total_loss: 4.638337135314941
training step: 30064, total_loss: 4.322972297668457
training step: 30065, total_loss: 2.9570937156677246
training step: 30066, total_loss: 3.203420639038086
training step: 30067, total_loss: 4.478679656982422
training step: 30068, total_loss: 2.748939037322998
training step: 30069, total_loss: 7.047942161560059
training step: 30070, total_loss: 5.0431437492370605
training step: 30071, total_loss: 4.712182998657227
training step: 30072, total_loss: 4.77386474609375
training step: 30073, total_loss: 4.695903301239014
training step: 30074, total_loss: 4.806938648223877
training step: 30075, total_loss: 4.487310409545898
training step: 30076, total_loss: 4.725271224975586
training step: 30077, total_loss: 5.422735214233398
training step: 30078, total_loss: 3.641713857650757
training step: 30079, total_loss: 4.857329368591309
training step: 30080, total_loss: 5.092373371124268
training step: 30081, total_loss: 5.293639183044434
training step: 30082, total_loss: 3.776960611343384
training step: 30083, total_loss: 5.022295951843262
training step: 30084, total_loss: 4.470284461975098
training step: 30085, total_loss: 5.111276149749756
training step: 30086, total_loss: 4.365616798400879
training step: 30087, total_loss: 4.749916076660156
training step: 30088, total_loss: 4.855893611907959
training step: 30089, total_loss: 4.4766035079956055
training step: 30090, total_loss: 4.959011554718018
training step: 30091, total_loss: 6.8104777336120605
training step: 30092, total_loss: 6.628210544586182
training step: 30093, total_loss: 6.118374824523926
training step: 30094, total_loss: 6.179775238037109
training step: 30095, total_loss: 3.4914236068725586
training step: 30096, total_loss: 2.545717716217041
training step: 30097, total_loss: 4.681291580200195
training step: 30098, total_loss: 4.3594770431518555
training step: 30099, total_loss: 5.157010078430176
training step: 30100, total_loss: 4.003559112548828
training step: 30101, total_loss: 3.4909439086914062
training step: 30102, total_loss: 4.228903293609619
training step: 30103, total_loss: 4.480042457580566
training step: 30104, total_loss: 5.8786420822143555
training step: 30105, total_loss: 6.142946243286133
training step: 30106, total_loss: 4.130612850189209
training step: 30107, total_loss: 5.329355239868164
training step: 30108, total_loss: 4.768231391906738
training step: 30109, total_loss: 5.058961391448975
training step: 30110, total_loss: 2.332303762435913
training step: 30111, total_loss: 4.47952938079834
training step: 30112, total_loss: 5.1918840408325195
training step: 30113, total_loss: 3.8260650634765625
training step: 30114, total_loss: 5.108211517333984
training step: 30115, total_loss: 4.5453877449035645
training step: 30116, total_loss: 4.273666858673096
training step: 30117, total_loss: 4.301792621612549
training step: 30118, total_loss: 1.4213025569915771
training step: 30119, total_loss: 2.975877523422241
training step: 30120, total_loss: 5.829087257385254
training step: 30121, total_loss: 4.588281631469727
training step: 30122, total_loss: 3.4454948902130127
training step: 30123, total_loss: 3.9082884788513184
training step: 30124, total_loss: 4.149563789367676
training step: 30125, total_loss: 3.9423367977142334
training step: 30126, total_loss: 5.343994617462158
training step: 30127, total_loss: 3.8691439628601074
training step: 30128, total_loss: 4.748660087585449
training step: 30129, total_loss: 4.160876274108887
training step: 30130, total_loss: 4.187687397003174
training step: 30131, total_loss: 3.2988693714141846
training step: 30132, total_loss: 4.573297500610352
training step: 30133, total_loss: 4.587060451507568
training step: 30134, total_loss: 4.546968936920166
training step: 30135, total_loss: 5.662601470947266
training step: 30136, total_loss: 4.728122234344482
training step: 30137, total_loss: 5.7817792892456055
training step: 30138, total_loss: 3.238771677017212
training step: 30139, total_loss: 4.750938415527344
training step: 30140, total_loss: 4.30015754699707
training step: 30141, total_loss: 3.6660163402557373
training step: 30142, total_loss: 5.174901962280273
training step: 30143, total_loss: 4.74729061126709
training step: 30144, total_loss: 2.658623695373535
training step: 30145, total_loss: 5.670260429382324
training step: 30146, total_loss: 4.681309223175049
training step: 30147, total_loss: 3.930666446685791
training step: 30148, total_loss: 3.622781753540039
training step: 30149, total_loss: 4.923472881317139
training step: 30150, total_loss: 4.855165004730225
training step: 30151, total_loss: 5.0638041496276855
training step: 30152, total_loss: 4.1034417152404785
training step: 30153, total_loss: 4.048889636993408
training step: 30154, total_loss: 4.314499855041504
training step: 30155, total_loss: 4.705329418182373
training step: 30156, total_loss: 4.25923490524292
training step: 30157, total_loss: 5.394503593444824
training step: 30158, total_loss: 4.122903347015381
training step: 30159, total_loss: 4.887475490570068
training step: 30160, total_loss: 3.9865689277648926
training step: 30161, total_loss: 4.77992582321167
training step: 30162, total_loss: 4.701651096343994
training step: 30163, total_loss: 4.897139549255371
training step: 30164, total_loss: 4.638666152954102
training step: 30165, total_loss: 2.278964042663574
training step: 30166, total_loss: 6.313481330871582
training step: 30167, total_loss: 3.925290584564209
training step: 30168, total_loss: 3.44325852394104
training step: 30169, total_loss: 3.740936756134033
training step: 30170, total_loss: 2.7994070053100586
training step: 30171, total_loss: 3.2320642471313477
training step: 30172, total_loss: 5.262467384338379
training step: 30173, total_loss: 4.596979141235352
training step: 30174, total_loss: 2.257094383239746
training step: 30175, total_loss: 3.8618335723876953
training step: 30176, total_loss: 4.079582214355469
training step: 30177, total_loss: 5.702090740203857
training step: 30178, total_loss: 5.1376423835754395
training step: 30179, total_loss: 4.169840335845947
training step: 30180, total_loss: 3.8437399864196777
training step: 30181, total_loss: 3.134672164916992
training step: 30182, total_loss: 3.6920809745788574
training step: 30183, total_loss: 3.5151662826538086
training step: 30184, total_loss: 4.315009117126465
training step: 30185, total_loss: 4.943996429443359
training step: 30186, total_loss: 2.4230706691741943
training step: 30187, total_loss: 4.4416117668151855
training step: 30188, total_loss: 4.026886463165283
training step: 30189, total_loss: 2.9945125579833984
training step: 30190, total_loss: 4.489372730255127
training step: 30191, total_loss: 3.6330554485321045
training step: 30192, total_loss: 4.2704973220825195
training step: 30193, total_loss: 4.796619415283203
training step: 30194, total_loss: 5.322066783905029
training step: 30195, total_loss: 5.376250743865967
training step: 30196, total_loss: 3.6609456539154053
training step: 30197, total_loss: 4.790143966674805
training step: 30198, total_loss: 3.8757877349853516
training step: 30199, total_loss: 4.286392688751221
training step: 30200, total_loss: 5.233621120452881
training step: 30201, total_loss: 4.075339317321777
training step: 30202, total_loss: 2.5323524475097656
training step: 30203, total_loss: 4.971436500549316
training step: 30204, total_loss: 6.480456352233887
training step: 30205, total_loss: 4.5180230140686035
training step: 30206, total_loss: 4.597764015197754
training step: 30207, total_loss: 5.67875862121582
training step: 30208, total_loss: 4.153167247772217
training step: 30209, total_loss: 3.594186782836914
training step: 30210, total_loss: 4.468402862548828
training step: 30211, total_loss: 5.09642219543457
training step: 30212, total_loss: 5.657483100891113
training step: 30213, total_loss: 4.242547035217285
training step: 30214, total_loss: 4.328364372253418
training step: 30215, total_loss: 3.0623011589050293
training step: 30216, total_loss: 3.816282272338867
training step: 30217, total_loss: 5.657883644104004
training step: 30218, total_loss: 2.3613760471343994
training step: 30219, total_loss: 3.987630844116211
training step: 30220, total_loss: 3.489744186401367
training step: 30221, total_loss: 5.047934055328369
training step: 30222, total_loss: 4.718775749206543
training step: 30223, total_loss: 3.5341458320617676
training step: 30224, total_loss: 4.2160162925720215
training step: 30225, total_loss: 3.9964652061462402
training step: 30226, total_loss: 3.9277124404907227
training step: 30227, total_loss: 4.304821968078613
training step: 30228, total_loss: 4.708322525024414
training step: 30229, total_loss: 4.507264614105225
training step: 30230, total_loss: 4.356242656707764
training step: 30231, total_loss: 3.771196126937866
training step: 30232, total_loss: 5.181708335876465
training step: 30233, total_loss: 4.516452789306641
training step: 30234, total_loss: 4.531210899353027
training step: 30235, total_loss: 4.42055606842041
training step: 30236, total_loss: 3.476175308227539
training step: 30237, total_loss: 4.455316543579102
training step: 30238, total_loss: 4.704119682312012
training step: 30239, total_loss: 4.790244102478027
training step: 30240, total_loss: 4.583835601806641
training step: 30241, total_loss: 4.7590436935424805
training step: 30242, total_loss: 4.727782726287842
training step: 30243, total_loss: 4.103999137878418
training step: 30244, total_loss: 5.337782859802246
training step: 30245, total_loss: 2.6734108924865723
training step: 30246, total_loss: 4.839380264282227
training step: 30247, total_loss: 5.392757892608643
training step: 30248, total_loss: 4.741664409637451
training step: 30249, total_loss: 5.421876907348633
training step: 30250, total_loss: 4.882189750671387
training step: 30251, total_loss: 4.990317344665527
training step: 30252, total_loss: 5.588461875915527
training step: 30253, total_loss: 4.079734802246094
training step: 30254, total_loss: 3.9767353534698486
training step: 30255, total_loss: 4.954286575317383
training step: 30256, total_loss: 3.9115216732025146
training step: 30257, total_loss: 5.069060325622559
training step: 30258, total_loss: 4.142142295837402
training step: 30259, total_loss: 3.1725287437438965
training step: 30260, total_loss: 6.129720687866211
training step: 30261, total_loss: 2.9987030029296875
training step: 30262, total_loss: 4.246249198913574
training step: 30263, total_loss: 5.045967102050781
training step: 30264, total_loss: 4.510897159576416
training step: 30265, total_loss: 1.4983241558074951
training step: 30266, total_loss: 3.409311294555664
training step: 30267, total_loss: 4.342530250549316
training step: 30268, total_loss: 4.837390899658203
training step: 30269, total_loss: 4.275732040405273
training step: 30270, total_loss: 5.438229084014893
training step: 30271, total_loss: 4.073796272277832
training step: 30272, total_loss: 5.74169397354126
training step: 30273, total_loss: 3.8427257537841797
training step: 30274, total_loss: 4.324641227722168
training step: 30275, total_loss: 2.7069251537323
training step: 30276, total_loss: 6.053711891174316
training step: 30277, total_loss: 5.22578763961792
training step: 30278, total_loss: 3.3308842182159424
training step: 30279, total_loss: 4.0480852127075195
training step: 30280, total_loss: 5.814260959625244
training step: 30281, total_loss: 5.784745216369629
training step: 30282, total_loss: 5.183314323425293
training step: 30283, total_loss: 5.404430389404297
training step: 30284, total_loss: 5.012035369873047
training step: 30285, total_loss: 4.990496635437012
training step: 30286, total_loss: 4.5556840896606445
training step: 30287, total_loss: 3.925633668899536
training step: 30288, total_loss: 2.5457558631896973
training step: 30289, total_loss: 4.971136569976807
training step: 30290, total_loss: 4.319401741027832
training step: 30291, total_loss: 4.483259201049805
training step: 30292, total_loss: 3.8067612648010254
training step: 30293, total_loss: 4.571450233459473
training step: 30294, total_loss: 4.876702785491943
training step: 30295, total_loss: 5.09217643737793
training step: 30296, total_loss: 5.5484490394592285
training step: 30297, total_loss: 4.887356281280518
training step: 30298, total_loss: 6.596878528594971
training step: 30299, total_loss: 4.703681945800781
training step: 30300, total_loss: 4.4160943031311035
training step: 30301, total_loss: 4.464715957641602
training step: 30302, total_loss: 3.629270076751709
training step: 30303, total_loss: 5.717252731323242
training step: 30304, total_loss: 5.60360050201416
training step: 30305, total_loss: 4.079814434051514
training step: 30306, total_loss: 4.509489059448242
training step: 30307, total_loss: 2.517542839050293
training step: 30308, total_loss: 2.7275519371032715
training step: 30309, total_loss: 4.057365894317627
training step: 30310, total_loss: 4.620748996734619
training step: 30311, total_loss: 4.563928604125977
training step: 30312, total_loss: 5.1119184494018555
training step: 30313, total_loss: 5.362907409667969
training step: 30314, total_loss: 4.9028167724609375
training step: 30315, total_loss: 3.722956657409668
training step: 30316, total_loss: 5.366387844085693
training step: 30317, total_loss: 4.8640923500061035
training step: 30318, total_loss: 4.875522136688232
training step: 30319, total_loss: 5.095382213592529
training step: 30320, total_loss: 4.505704879760742
training step: 30321, total_loss: 6.445415496826172
training step: 30322, total_loss: 4.220874786376953
training step: 30323, total_loss: 4.168929100036621
training step: 30324, total_loss: 2.619332790374756
training step: 30325, total_loss: 5.107118129730225
training step: 30326, total_loss: 4.407436370849609
training step: 30327, total_loss: 4.214330196380615
training step: 30328, total_loss: 4.884524345397949
training step: 30329, total_loss: 4.124515056610107
training step: 30330, total_loss: 4.14935302734375
training step: 30331, total_loss: 4.147726058959961
training step: 30332, total_loss: 4.310091972351074
training step: 30333, total_loss: 4.0186448097229
training step: 30334, total_loss: 4.812601089477539
training step: 30335, total_loss: 1.5569801330566406
training step: 30336, total_loss: 6.45911979675293
training step: 30337, total_loss: 5.052030086517334
training step: 30338, total_loss: 4.468419075012207
training step: 30339, total_loss: 4.624812602996826
training step: 30340, total_loss: 1.316462755203247
training step: 30341, total_loss: 4.164417266845703
training step: 30342, total_loss: 2.6561388969421387
training step: 30343, total_loss: 4.633815765380859
training step: 30344, total_loss: 4.431933879852295
training step: 30345, total_loss: 3.819474220275879
training step: 30346, total_loss: 5.735500812530518
training step: 30347, total_loss: 2.710206985473633
training step: 30348, total_loss: 3.6540422439575195
training step: 30349, total_loss: 3.5104074478149414
training step: 30350, total_loss: 1.0325919389724731
training step: 30351, total_loss: 4.2100629806518555
training step: 30352, total_loss: 4.194250583648682
training step: 30353, total_loss: 4.863631248474121
training step: 30354, total_loss: 4.15025520324707
training step: 30355, total_loss: 3.9811489582061768
training step: 30356, total_loss: 4.725754737854004
training step: 30357, total_loss: 5.678810119628906
training step: 30358, total_loss: 4.957736968994141
training step: 30359, total_loss: 2.746389865875244
training step: 30360, total_loss: 4.4998908042907715
training step: 30361, total_loss: 2.7882490158081055
training step: 30362, total_loss: 4.67861795425415
training step: 30363, total_loss: 1.2595784664154053
training step: 30364, total_loss: 4.620363235473633
training step: 30365, total_loss: 5.415387153625488
training step: 30366, total_loss: 3.301959991455078
training step: 30367, total_loss: 3.2768242359161377
training step: 30368, total_loss: 2.7998366355895996
training step: 30369, total_loss: 4.527122497558594
training step: 30370, total_loss: 4.996969699859619
training step: 30371, total_loss: 4.762398719787598
training step: 30372, total_loss: 4.255948543548584
training step: 30373, total_loss: 3.553048610687256
training step: 30374, total_loss: 2.3895068168640137
training step: 30375, total_loss: 4.372866153717041
training step: 30376, total_loss: 4.906349182128906
training step: 30377, total_loss: 4.868722438812256
training step: 30378, total_loss: 4.956833839416504
training step: 30379, total_loss: 3.6365318298339844
training step: 30380, total_loss: 5.283289909362793
training step: 30381, total_loss: 2.770338535308838
training step: 30382, total_loss: 2.664062023162842
training step: 30383, total_loss: 4.040460586547852
training step: 30384, total_loss: 4.247537612915039
training step: 30385, total_loss: 3.032892942428589
training step: 30386, total_loss: 4.645370006561279
training step: 30387, total_loss: 5.841326713562012
training step: 30388, total_loss: 4.416892051696777
training step: 30389, total_loss: 4.650073528289795
training step: 30390, total_loss: 3.8608145713806152
training step: 30391, total_loss: 3.950505495071411
training step: 30392, total_loss: 4.620434284210205
training step: 30393, total_loss: 5.592324256896973
training step: 30394, total_loss: 4.715207099914551
training step: 30395, total_loss: 3.9879202842712402
training step: 30396, total_loss: 5.178913116455078
training step: 30397, total_loss: 3.4293622970581055
training step: 30398, total_loss: 5.465461730957031
training step: 30399, total_loss: 4.289619445800781
training step: 30400, total_loss: 5.194236755371094
training step: 30401, total_loss: 4.466038703918457
training step: 30402, total_loss: 4.199118137359619
training step: 30403, total_loss: 3.6042838096618652
training step: 30404, total_loss: 3.6260604858398438
training step: 30405, total_loss: 4.503200531005859
training step: 30406, total_loss: 4.477347373962402
training step: 30407, total_loss: 4.559200286865234
training step: 30408, total_loss: 5.905811309814453
training step: 30409, total_loss: 5.312795639038086
training step: 30410, total_loss: 4.045959949493408
training step: 30411, total_loss: 4.797999382019043
training step: 30412, total_loss: 4.963009357452393
training step: 30413, total_loss: 4.093371868133545
training step: 30414, total_loss: 3.562304973602295
training step: 30415, total_loss: 3.527670383453369
training step: 30416, total_loss: 4.2035369873046875
training step: 30417, total_loss: 4.942430019378662
training step: 30418, total_loss: 5.765157222747803
training step: 30419, total_loss: 4.724257946014404
training step: 30420, total_loss: 3.615471363067627
training step: 30421, total_loss: 4.941346645355225
training step: 30422, total_loss: 5.06622314453125
training step: 30423, total_loss: 5.3336591720581055
training step: 30424, total_loss: 3.923855781555176
training step: 30425, total_loss: 4.701899528503418
training step: 30426, total_loss: 3.9740405082702637
training step: 30427, total_loss: 4.543158531188965
training step: 30428, total_loss: 3.0586133003234863
training step: 30429, total_loss: 6.686908721923828
training step: 30430, total_loss: 4.606142520904541
training step: 30431, total_loss: 3.815760850906372
training step: 30432, total_loss: 5.876786231994629
training step: 30433, total_loss: 5.082141399383545
training step: 30434, total_loss: 3.5793724060058594
training step: 30435, total_loss: 5.061761856079102
training step: 30436, total_loss: 4.800775051116943
training step: 30437, total_loss: 1.429746389389038
training step: 30438, total_loss: 4.541585922241211
training step: 30439, total_loss: 2.2776925563812256
training step: 30440, total_loss: 5.273039817810059
training step: 30441, total_loss: 4.586511611938477
training step: 30442, total_loss: 4.36388635635376
training step: 30443, total_loss: 1.3179423809051514
training step: 30444, total_loss: 4.056853294372559
training step: 30445, total_loss: 4.828516006469727
training step: 30446, total_loss: 4.286921501159668
training step: 30447, total_loss: 5.369948387145996
training step: 30448, total_loss: 4.895586967468262
training step: 30449, total_loss: 3.505195140838623
training step: 30450, total_loss: 4.445418834686279
training step: 30451, total_loss: 5.7409772872924805
training step: 30452, total_loss: 3.119178295135498
training step: 30453, total_loss: 4.732522010803223
training step: 30454, total_loss: 3.7860002517700195
training step: 30455, total_loss: 5.135067939758301
training step: 30456, total_loss: 3.996176242828369
training step: 30457, total_loss: 4.5908403396606445
training step: 30458, total_loss: 4.80155086517334
training step: 30459, total_loss: 4.164449691772461
training step: 30460, total_loss: 4.66362190246582
training step: 30461, total_loss: 4.559915542602539
training step: 30462, total_loss: 5.865728378295898
training step: 30463, total_loss: 4.984789848327637
training step: 30464, total_loss: 6.759298324584961
training step: 30465, total_loss: 3.65203857421875
training step: 30466, total_loss: 5.307694435119629
training step: 30467, total_loss: 5.390681743621826
training step: 30468, total_loss: 4.905311584472656
training step: 30469, total_loss: 5.6275129318237305
training step: 30470, total_loss: 4.527131080627441
training step: 30471, total_loss: 5.066083908081055
training step: 30472, total_loss: 2.6858386993408203
training step: 30473, total_loss: 3.654918909072876
training step: 30474, total_loss: 5.341073989868164
training step: 30475, total_loss: 5.692046165466309
training step: 30476, total_loss: 3.9415581226348877
training step: 30477, total_loss: 4.917456150054932
training step: 30478, total_loss: 3.0280556678771973
training step: 30479, total_loss: 4.9589948654174805
training step: 30480, total_loss: 4.5362982749938965
training step: 30481, total_loss: 4.082644462585449
training step: 30482, total_loss: 4.071434020996094
training step: 30483, total_loss: 4.63429594039917
training step: 30484, total_loss: 7.52934455871582
training step: 30485, total_loss: 3.5794687271118164
training step: 30486, total_loss: 4.486588001251221
training step: 30487, total_loss: 2.778409481048584
training step: 30488, total_loss: 3.902862548828125
training step: 30489, total_loss: 3.8357646465301514
training step: 30490, total_loss: 5.72739315032959
training step: 30491, total_loss: 4.001412868499756
training step: 30492, total_loss: 4.649039268493652
training step: 30493, total_loss: 4.621076583862305
training step: 30494, total_loss: 4.636297702789307
training step: 30495, total_loss: 5.541728496551514
training step: 30496, total_loss: 4.346174716949463
training step: 30497, total_loss: 3.0032410621643066
training step: 30498, total_loss: 4.592141151428223
training step: 30499, total_loss: 4.073728561401367
training step: 30500, total_loss: 5.462314605712891
training step: 30501, total_loss: 4.417397499084473
training step: 30502, total_loss: 4.496139049530029
training step: 30503, total_loss: 4.941132545471191
training step: 30504, total_loss: 4.489842414855957
training step: 30505, total_loss: 5.138955116271973
training step: 30506, total_loss: 4.425638198852539
training step: 30507, total_loss: 4.1166887283325195
training step: 30508, total_loss: 7.352344036102295
training step: 30509, total_loss: 5.3578619956970215
training step: 30510, total_loss: 4.88476037979126
training step: 30511, total_loss: 4.33612060546875
training step: 30512, total_loss: 4.99932861328125
training step: 30513, total_loss: 4.021858215332031
training step: 30514, total_loss: 4.6922783851623535
training step: 30515, total_loss: 4.278775691986084
training step: 30516, total_loss: 6.492101669311523
training step: 30517, total_loss: 4.14384651184082
training step: 30518, total_loss: 1.4052276611328125
training step: 30519, total_loss: 1.412471055984497
training step: 30520, total_loss: 5.2246904373168945
training step: 30521, total_loss: 4.0822954177856445
training step: 30522, total_loss: 4.457018852233887
training step: 30523, total_loss: 5.241065979003906
training step: 30524, total_loss: 1.5565223693847656
training step: 30525, total_loss: 5.467802047729492
training step: 30526, total_loss: 6.19615364074707
training step: 30527, total_loss: 3.1001901626586914
training step: 30528, total_loss: 5.486682891845703
training step: 30529, total_loss: 4.637105464935303
training step: 30530, total_loss: 4.108187675476074
training step: 30531, total_loss: 4.094200611114502
training step: 30532, total_loss: 4.681186199188232
training step: 30533, total_loss: 3.8950676918029785
training step: 30534, total_loss: 3.766143560409546
training step: 30535, total_loss: 4.43062162399292
training step: 30536, total_loss: 4.526242733001709
training step: 30537, total_loss: 2.1706151962280273
training step: 30538, total_loss: 5.465858459472656
training step: 30539, total_loss: 5.074487686157227
training step: 30540, total_loss: 3.4070301055908203
training step: 30541, total_loss: 4.276080131530762
training step: 30542, total_loss: 5.498763084411621
training step: 30543, total_loss: 3.768693447113037
training step: 30544, total_loss: 4.864910125732422
training step: 30545, total_loss: 5.265168190002441
training step: 30546, total_loss: 4.996908664703369
training step: 30547, total_loss: 4.682385444641113
training step: 30548, total_loss: 5.6101531982421875
training step: 30549, total_loss: 5.508358001708984
training step: 30550, total_loss: 4.862791061401367
training step: 30551, total_loss: 4.357983589172363
training step: 30552, total_loss: 4.008512496948242
training step: 30553, total_loss: 2.0847043991088867
training step: 30554, total_loss: 4.501335144042969
training step: 30555, total_loss: 5.236241340637207
training step: 30556, total_loss: 4.318007946014404
training step: 30557, total_loss: 4.627425193786621
training step: 30558, total_loss: 1.2895143032073975
training step: 30559, total_loss: 4.555025100708008
training step: 30560, total_loss: 5.278115272521973
training step: 30561, total_loss: 3.7206637859344482
training step: 30562, total_loss: 4.673480987548828
training step: 30563, total_loss: 5.388002395629883
training step: 30564, total_loss: 4.5029072761535645
training step: 30565, total_loss: 5.235052108764648
training step: 30566, total_loss: 4.94394588470459
training step: 30567, total_loss: 3.654949903488159
training step: 30568, total_loss: 5.112147331237793
training step: 30569, total_loss: 3.7083816528320312
training step: 30570, total_loss: 4.141009330749512
training step: 30571, total_loss: 4.825566291809082
training step: 30572, total_loss: 4.84246826171875
training step: 30573, total_loss: 5.848247528076172
training step: 30574, total_loss: 1.0500465631484985
training step: 30575, total_loss: 3.6212387084960938
training step: 30576, total_loss: 4.780719757080078
training step: 30577, total_loss: 4.422390460968018
training step: 30578, total_loss: 3.722586154937744
training step: 30579, total_loss: 5.000179290771484
training step: 30580, total_loss: 3.878795623779297
training step: 30581, total_loss: 1.6820507049560547
training step: 30582, total_loss: 3.9797160625457764
training step: 30583, total_loss: 4.760741233825684
training step: 30584, total_loss: 4.778414726257324
training step: 30585, total_loss: 4.729151725769043
training step: 30586, total_loss: 5.898003101348877
training step: 30587, total_loss: 5.477023124694824
training step: 30588, total_loss: 5.198934555053711
training step: 30589, total_loss: 5.298257827758789
training step: 30590, total_loss: 4.186189651489258
training step: 30591, total_loss: 3.3850178718566895
training step: 30592, total_loss: 4.515713214874268
training step: 30593, total_loss: 4.176730155944824
training step: 30594, total_loss: 3.370738983154297
training step: 30595, total_loss: 5.960565567016602
training step: 30596, total_loss: 3.017639398574829
training step: 30597, total_loss: 4.213295936584473
training step: 30598, total_loss: 4.151549339294434
training step: 30599, total_loss: 1.015910267829895
training step: 30600, total_loss: 5.877617835998535
training step: 30601, total_loss: 3.6298747062683105
training step: 30602, total_loss: 3.361783027648926
training step: 30603, total_loss: 4.102153301239014
training step: 30604, total_loss: 4.966680526733398
training step: 30605, total_loss: 3.388946533203125
training step: 30606, total_loss: 3.6780219078063965
training step: 30607, total_loss: 4.676513671875
training step: 30608, total_loss: 4.8178558349609375
training step: 30609, total_loss: 4.676756858825684
training step: 30610, total_loss: 5.475536346435547
training step: 30611, total_loss: 4.279417991638184
training step: 30612, total_loss: 5.029054641723633
training step: 30613, total_loss: 6.194079399108887
training step: 30614, total_loss: 5.402021408081055
training step: 30615, total_loss: 3.7366232872009277
training step: 30616, total_loss: 3.700489044189453
training step: 30617, total_loss: 5.055657386779785
training step: 30618, total_loss: 4.997248649597168
training step: 30619, total_loss: 4.500572204589844
training step: 30620, total_loss: 7.974627494812012
training step: 30621, total_loss: 2.483262538909912
training step: 30622, total_loss: 4.671910285949707
training step: 30623, total_loss: 3.1334598064422607
training step: 30624, total_loss: 6.694107532501221
training step: 30625, total_loss: 2.569441080093384
training step: 30626, total_loss: 4.377463340759277
training step: 30627, total_loss: 4.760578155517578
training step: 30628, total_loss: 3.7812376022338867
training step: 30629, total_loss: 3.9985604286193848
training step: 30630, total_loss: 3.2825098037719727
training step: 30631, total_loss: 4.995814323425293
training step: 30632, total_loss: 5.154447555541992
training step: 30633, total_loss: 3.9827141761779785
training step: 30634, total_loss: 4.204885482788086
training step: 30635, total_loss: 3.234009265899658
training step: 30636, total_loss: 3.180504322052002
training step: 30637, total_loss: 4.332310676574707
training step: 30638, total_loss: 4.555747985839844
training step: 30639, total_loss: 4.325996398925781
training step: 30640, total_loss: 3.980607032775879
training step: 30641, total_loss: 3.906109571456909
training step: 30642, total_loss: 4.665561676025391
training step: 30643, total_loss: 3.341029644012451
training step: 30644, total_loss: 4.554632663726807
training step: 30645, total_loss: 4.991082668304443
training step: 30646, total_loss: 3.8680977821350098
training step: 30647, total_loss: 3.543193817138672
training step: 30648, total_loss: 4.3325018882751465
training step: 30649, total_loss: 4.149178504943848
training step: 30650, total_loss: 4.511885643005371
training step: 30651, total_loss: 5.504362106323242
training step: 30652, total_loss: 5.405723571777344
training step: 30653, total_loss: 4.1006364822387695
training step: 30654, total_loss: 3.6418793201446533
training step: 30655, total_loss: 4.3447723388671875
training step: 30656, total_loss: 4.393065452575684
training step: 30657, total_loss: 5.351047515869141
training step: 30658, total_loss: 5.67917537689209
training step: 30659, total_loss: 3.568540334701538
training step: 30660, total_loss: 4.01460075378418
training step: 30661, total_loss: 1.6874406337738037
training step: 30662, total_loss: 3.568098306655884
training step: 30663, total_loss: 5.977066516876221
training step: 30664, total_loss: 3.630527973175049
training step: 30665, total_loss: 5.646114826202393
training step: 30666, total_loss: 4.357335090637207
training step: 30667, total_loss: 4.873530864715576
training step: 30668, total_loss: 5.392737865447998
training step: 30669, total_loss: 4.449270248413086
training step: 30670, total_loss: 4.030614376068115
training step: 30671, total_loss: 4.7335710525512695
training step: 30672, total_loss: 4.692807674407959
training step: 30673, total_loss: 4.201503753662109
training step: 30674, total_loss: 4.537091255187988
training step: 30675, total_loss: 2.9128003120422363
training step: 30676, total_loss: 4.026310920715332
training step: 30677, total_loss: 5.776638031005859
training step: 30678, total_loss: 4.59727668762207
training step: 30679, total_loss: 3.5996274948120117
training step: 30680, total_loss: 4.027226448059082
training step: 30681, total_loss: 4.16502571105957
training step: 30682, total_loss: 5.883545875549316
training step: 30683, total_loss: 5.306056022644043
training step: 30684, total_loss: 4.176148891448975
training step: 30685, total_loss: 3.51216721534729
training step: 30686, total_loss: 2.3023953437805176
training step: 30687, total_loss: 4.961496353149414
training step: 30688, total_loss: 4.4824371337890625
training step: 30689, total_loss: 5.701790809631348
training step: 30690, total_loss: 5.217386245727539
training step: 30691, total_loss: 2.970740795135498
training step: 30692, total_loss: 3.2068839073181152
training step: 30693, total_loss: 3.7443008422851562
training step: 30694, total_loss: 1.957453727722168
training step: 30695, total_loss: 4.729245662689209
training step: 30696, total_loss: 4.116608619689941
training step: 30697, total_loss: 3.264998435974121
training step: 30698, total_loss: 3.426680564880371
training step: 30699, total_loss: 3.558448314666748
training step: 30700, total_loss: 4.847664833068848
training step: 30701, total_loss: 4.535287857055664
training step: 30702, total_loss: 5.174988746643066
training step: 30703, total_loss: 4.887840270996094
training step: 30704, total_loss: 5.691521644592285
training step: 30705, total_loss: 7.291245937347412
training step: 30706, total_loss: 2.4598257541656494
training step: 30707, total_loss: 4.224783897399902
training step: 30708, total_loss: 3.9762039184570312
training step: 30709, total_loss: 3.8467187881469727
training step: 30710, total_loss: 7.111598014831543
training step: 30711, total_loss: 3.8041818141937256
training step: 30712, total_loss: 5.038652420043945
training step: 30713, total_loss: 4.75556755065918
training step: 30714, total_loss: 5.942246913909912
training step: 30715, total_loss: 4.664421081542969
training step: 30716, total_loss: 4.778404235839844
training step: 30717, total_loss: 3.3722105026245117
training step: 30718, total_loss: 5.301438331604004
training step: 30719, total_loss: 3.6948227882385254
training step: 30720, total_loss: 4.1488800048828125
training step: 30721, total_loss: 1.4617468118667603
training step: 30722, total_loss: 3.5571250915527344
training step: 30723, total_loss: 5.123841285705566
training step: 30724, total_loss: 4.324405670166016
training step: 30725, total_loss: 5.325488567352295
training step: 30726, total_loss: 4.418553352355957
training step: 30727, total_loss: 3.7895402908325195
training step: 30728, total_loss: 4.257239818572998
training step: 30729, total_loss: 3.8415465354919434
training step: 30730, total_loss: 4.690393447875977
training step: 30731, total_loss: 6.196969509124756
training step: 30732, total_loss: 5.14975643157959
training step: 30733, total_loss: 3.1191463470458984
training step: 30734, total_loss: 4.798852920532227
training step: 30735, total_loss: 4.276515960693359
training step: 30736, total_loss: 3.7317698001861572
training step: 30737, total_loss: 5.931807518005371
training step: 30738, total_loss: 5.224686145782471
training step: 30739, total_loss: 5.1765546798706055
training step: 30740, total_loss: 3.7161569595336914
training step: 30741, total_loss: 4.066494464874268
training step: 30742, total_loss: 4.219183921813965
training step: 30743, total_loss: 4.513260364532471
training step: 30744, total_loss: 3.9688258171081543
training step: 30745, total_loss: 4.2440080642700195
training step: 30746, total_loss: 5.403112888336182
training step: 30747, total_loss: 4.518017768859863
training step: 30748, total_loss: 4.944571495056152
training step: 30749, total_loss: 3.7437939643859863
training step: 30750, total_loss: 4.572167873382568
training step: 30751, total_loss: 4.766086578369141
training step: 30752, total_loss: 3.172774076461792
training step: 30753, total_loss: 4.382460117340088
training step: 30754, total_loss: 4.340476989746094
training step: 30755, total_loss: 4.980589866638184
training step: 30756, total_loss: 4.096954822540283
training step: 30757, total_loss: 4.902045249938965
training step: 30758, total_loss: 5.1313066482543945
training step: 30759, total_loss: 4.371417045593262
training step: 30760, total_loss: 5.65793514251709
training step: 30761, total_loss: 3.473605155944824
training step: 30762, total_loss: 2.791257381439209
training step: 30763, total_loss: 4.5834503173828125
training step: 30764, total_loss: 3.7829341888427734
training step: 30765, total_loss: 4.053778171539307
training step: 30766, total_loss: 4.730591773986816
training step: 30767, total_loss: 5.157906532287598
training step: 30768, total_loss: 5.122528076171875
training step: 30769, total_loss: 4.678551197052002
training step: 30770, total_loss: 3.2051732540130615
training step: 30771, total_loss: 4.988935947418213
training step: 30772, total_loss: 5.324464797973633
training step: 30773, total_loss: 5.308380126953125
training step: 30774, total_loss: 4.099664211273193
training step: 30775, total_loss: 6.070627212524414
training step: 30776, total_loss: 4.264908313751221
training step: 30777, total_loss: 4.879522800445557
training step: 30778, total_loss: 4.8246378898620605
training step: 30779, total_loss: 5.197330474853516
training step: 30780, total_loss: 5.003390312194824
training step: 30781, total_loss: 4.98915958404541
training step: 30782, total_loss: 5.107792854309082
training step: 30783, total_loss: 2.5795109272003174
training step: 30784, total_loss: 3.5354561805725098
training step: 30785, total_loss: 4.5173563957214355
training step: 30786, total_loss: 4.717809677124023
training step: 30787, total_loss: 4.222671031951904
training step: 30788, total_loss: 4.995229721069336
training step: 30789, total_loss: 5.6764092445373535
training step: 30790, total_loss: 5.738339424133301
training step: 30791, total_loss: 4.339898109436035
training step: 30792, total_loss: 5.3731231689453125
training step: 30793, total_loss: 3.7742209434509277
training step: 30794, total_loss: 3.8911490440368652
training step: 30795, total_loss: 4.149586200714111
training step: 30796, total_loss: 4.346526622772217
training step: 30797, total_loss: 3.7036356925964355
training step: 30798, total_loss: 4.323740482330322
training step: 30799, total_loss: 4.593073844909668
training step: 30800, total_loss: 5.292096138000488
training step: 30801, total_loss: 5.255258560180664
training step: 30802, total_loss: 4.314704895019531
training step: 30803, total_loss: 3.43515944480896
training step: 30804, total_loss: 4.6703104972839355
training step: 30805, total_loss: 4.645216464996338
training step: 30806, total_loss: 4.079280853271484
training step: 30807, total_loss: 5.898601531982422
training step: 30808, total_loss: 3.3746659755706787
training step: 30809, total_loss: 4.0904083251953125
training step: 30810, total_loss: 4.809279918670654
training step: 30811, total_loss: 4.315954208374023
training step: 30812, total_loss: 4.327610015869141
training step: 30813, total_loss: 5.859686851501465
training step: 30814, total_loss: 2.58164119720459
training step: 30815, total_loss: 4.069642066955566
training step: 30816, total_loss: 5.156759738922119
training step: 30817, total_loss: 3.822284698486328
training step: 30818, total_loss: 4.784017562866211
training step: 30819, total_loss: 4.95965576171875
training step: 30820, total_loss: 4.041788101196289
training step: 30821, total_loss: 4.590250015258789
training step: 30822, total_loss: 5.125666618347168
training step: 30823, total_loss: 4.497005462646484
training step: 30824, total_loss: 3.7434773445129395
training step: 30825, total_loss: 3.9533238410949707
training step: 30826, total_loss: 4.555391311645508
training step: 30827, total_loss: 5.048942565917969
training step: 30828, total_loss: 5.9778852462768555
training step: 30829, total_loss: 4.2824320793151855
training step: 30830, total_loss: 4.552180767059326
training step: 30831, total_loss: 4.405693531036377
training step: 30832, total_loss: 5.168535232543945
training step: 30833, total_loss: 2.5592947006225586
training step: 30834, total_loss: 4.889482021331787
training step: 30835, total_loss: 4.990018844604492
training step: 30836, total_loss: 2.957286834716797
training step: 30837, total_loss: 4.446802139282227
training step: 30838, total_loss: 2.874457836151123
training step: 30839, total_loss: 7.885272026062012
training step: 30840, total_loss: 3.8136520385742188
training step: 30841, total_loss: 5.46547269821167
training step: 30842, total_loss: 4.7206807136535645
training step: 30843, total_loss: 5.232452869415283
training step: 30844, total_loss: 5.427642822265625
training step: 30845, total_loss: 5.1099772453308105
training step: 30846, total_loss: 5.251913070678711
training step: 30847, total_loss: 5.939411163330078
training step: 30848, total_loss: 4.660093784332275
training step: 30849, total_loss: 3.3738956451416016
training step: 30850, total_loss: 4.843494415283203
training step: 30851, total_loss: 5.0501604080200195
training step: 30852, total_loss: 5.392566680908203
training step: 30853, total_loss: 3.4261765480041504
training step: 30854, total_loss: 3.77772855758667
training step: 30855, total_loss: 3.685668468475342
training step: 30856, total_loss: 4.737080097198486
training step: 30857, total_loss: 2.6025888919830322
training step: 30858, total_loss: 4.37811279296875
training step: 30859, total_loss: 3.7008614540100098
training step: 30860, total_loss: 2.278264045715332
training step: 30861, total_loss: 4.640941619873047
training step: 30862, total_loss: 4.1205949783325195
training step: 30863, total_loss: 4.316932201385498
training step: 30864, total_loss: 4.717038631439209
training step: 30865, total_loss: 3.804563283920288
training step: 30866, total_loss: 3.747659206390381
training step: 30867, total_loss: 6.022362232208252
training step: 30868, total_loss: 3.1469807624816895
training step: 30869, total_loss: 5.348565578460693
training step: 30870, total_loss: 4.290543079376221
training step: 30871, total_loss: 3.84779691696167
training step: 30872, total_loss: 5.167867183685303
training step: 30873, total_loss: 1.1725304126739502
training step: 30874, total_loss: 4.855121612548828
training step: 30875, total_loss: 3.667374610900879
training step: 30876, total_loss: 5.000919342041016
training step: 30877, total_loss: 4.296976089477539
training step: 30878, total_loss: 5.67303466796875
training step: 30879, total_loss: 4.193974494934082
training step: 30880, total_loss: 3.4230422973632812
training step: 30881, total_loss: 2.4839162826538086
training step: 30882, total_loss: 1.0433802604675293
training step: 30883, total_loss: 5.074373245239258
training step: 30884, total_loss: 4.65537166595459
training step: 30885, total_loss: 5.034595489501953
training step: 30886, total_loss: 6.680405616760254
training step: 30887, total_loss: 3.7740654945373535
training step: 30888, total_loss: 4.935521602630615
training step: 30889, total_loss: 5.094789505004883
training step: 30890, total_loss: 4.102881908416748
training step: 30891, total_loss: 5.083861351013184
training step: 30892, total_loss: 6.398329734802246
training step: 30893, total_loss: 4.0826287269592285
training step: 30894, total_loss: 5.003551483154297
training step: 30895, total_loss: 4.352331161499023
training step: 30896, total_loss: 4.426158905029297
training step: 30897, total_loss: 3.9185845851898193
training step: 30898, total_loss: 5.137917995452881
training step: 30899, total_loss: 6.429136276245117
training step: 30900, total_loss: 4.657737731933594
training step: 30901, total_loss: 4.058714866638184
training step: 30902, total_loss: 5.100050926208496
training step: 30903, total_loss: 4.735672473907471
training step: 30904, total_loss: 0.83523029088974
training step: 30905, total_loss: 5.89459228515625
training step: 30906, total_loss: 4.620922088623047
training step: 30907, total_loss: 4.259518146514893
training step: 30908, total_loss: 5.352919578552246
training step: 30909, total_loss: 6.068911075592041
training step: 30910, total_loss: 5.258812427520752
training step: 30911, total_loss: 4.258591651916504
training step: 30912, total_loss: 2.754329204559326
training step: 30913, total_loss: 3.9332022666931152
training step: 30914, total_loss: 4.857544898986816
training step: 30915, total_loss: 5.236230850219727
training step: 30916, total_loss: 6.422250747680664
training step: 30917, total_loss: 4.977604389190674
training step: 30918, total_loss: 4.538392066955566
training step: 30919, total_loss: 3.042147636413574
training step: 30920, total_loss: 4.654715538024902
training step: 30921, total_loss: 4.780576229095459
training step: 30922, total_loss: 5.222218990325928
training step: 30923, total_loss: 3.867976665496826
training step: 30924, total_loss: 5.27416467666626
training step: 30925, total_loss: 5.0968017578125
training step: 30926, total_loss: 4.390349388122559
training step: 30927, total_loss: 4.396508693695068
training step: 30928, total_loss: 3.6291372776031494
training step: 30929, total_loss: 4.7889204025268555
training step: 30930, total_loss: 3.866403102874756
training step: 30931, total_loss: 4.956254959106445
training step: 30932, total_loss: 4.576689720153809
training step: 30933, total_loss: 4.175324440002441
training step: 30934, total_loss: 6.360416412353516
training step: 30935, total_loss: 2.4471073150634766
training step: 30936, total_loss: 4.0404815673828125
training step: 30937, total_loss: 3.6689834594726562
training step: 30938, total_loss: 4.992578506469727
training step: 30939, total_loss: 4.065217971801758
training step: 30940, total_loss: 4.322094917297363
training step: 30941, total_loss: 3.2299046516418457
training step: 30942, total_loss: 4.9293107986450195
training step: 30943, total_loss: 4.584831237792969
training step: 30944, total_loss: 4.412107467651367
training step: 30945, total_loss: 3.7833478450775146
training step: 30946, total_loss: 5.554536819458008
training step: 30947, total_loss: 2.7131872177124023
training step: 30948, total_loss: 4.582353591918945
training step: 30949, total_loss: 3.6090617179870605
training step: 30950, total_loss: 2.6572887897491455
training step: 30951, total_loss: 4.386481285095215
training step: 30952, total_loss: 4.885695457458496
training step: 30953, total_loss: 3.802842140197754
training step: 30954, total_loss: 4.562139987945557
training step: 30955, total_loss: 4.795179843902588
training step: 30956, total_loss: 5.650022029876709
training step: 30957, total_loss: 4.341265678405762
training step: 30958, total_loss: 4.480720520019531
training step: 30959, total_loss: 3.8296103477478027
training step: 30960, total_loss: 4.513032913208008
training step: 30961, total_loss: 3.9085047245025635
training step: 30962, total_loss: 5.04517936706543
training step: 30963, total_loss: 4.6774821281433105
training step: 30964, total_loss: 3.798625946044922
training step: 30965, total_loss: 3.36556339263916
training step: 30966, total_loss: 5.230035781860352
training step: 30967, total_loss: 5.001032829284668
training step: 30968, total_loss: 5.837712287902832
training step: 30969, total_loss: 6.183533191680908
training step: 30970, total_loss: 4.041954040527344
training step: 30971, total_loss: 5.133279800415039
training step: 30972, total_loss: 4.025106430053711
training step: 30973, total_loss: 4.6838908195495605
training step: 30974, total_loss: 3.9344828128814697
training step: 30975, total_loss: 6.803194999694824
training step: 30976, total_loss: 5.21904182434082
training step: 30977, total_loss: 5.444971084594727
training step: 30978, total_loss: 4.00597620010376
training step: 30979, total_loss: 5.063060760498047
training step: 30980, total_loss: 2.0735952854156494
training step: 30981, total_loss: 5.101202487945557
training step: 30982, total_loss: 4.031130790710449
training step: 30983, total_loss: 5.097023963928223
training step: 30984, total_loss: 5.719131946563721
training step: 30985, total_loss: 5.042795181274414
training step: 30986, total_loss: 3.948967456817627
training step: 30987, total_loss: 3.4575610160827637
training step: 30988, total_loss: 3.3780083656311035
training step: 30989, total_loss: 3.3109359741210938
training step: 30990, total_loss: 3.8550949096679688
training step: 30991, total_loss: 3.7855730056762695
training step: 30992, total_loss: 4.494716644287109
training step: 30993, total_loss: 4.700172424316406
training step: 30994, total_loss: 3.053565502166748
training step: 30995, total_loss: 4.869582176208496
training step: 30996, total_loss: 3.039278507232666
training step: 30997, total_loss: 0.929497480392456
training step: 30998, total_loss: 4.418595790863037
training step: 30999, total_loss: 3.341001510620117
training step: 31000, total_loss: 5.164028167724609
training step: 31001, total_loss: 3.6372671127319336
training step: 31002, total_loss: 7.256061553955078
training step: 31003, total_loss: 5.075887203216553
training step: 31004, total_loss: 3.5228805541992188
training step: 31005, total_loss: 5.513548851013184
training step: 31006, total_loss: 4.095541000366211
training step: 31007, total_loss: 5.880216598510742
training step: 31008, total_loss: 4.583925247192383
training step: 31009, total_loss: 3.6951613426208496
training step: 31010, total_loss: 3.935138702392578
training step: 31011, total_loss: 4.305814743041992
training step: 31012, total_loss: 5.120546340942383
training step: 31013, total_loss: 4.990105152130127
training step: 31014, total_loss: 3.1689090728759766
training step: 31015, total_loss: 4.617910861968994
training step: 31016, total_loss: 5.260095596313477
training step: 31017, total_loss: 5.416616439819336
training step: 31018, total_loss: 2.9976117610931396
training step: 31019, total_loss: 4.560756683349609
training step: 31020, total_loss: 5.3713154792785645
training step: 31021, total_loss: 4.848888874053955
training step: 31022, total_loss: 4.3723835945129395
training step: 31023, total_loss: 4.499137878417969
training step: 31024, total_loss: 2.0816447734832764
training step: 31025, total_loss: 5.67171049118042
training step: 31026, total_loss: 2.410309314727783
training step: 31027, total_loss: 3.1325764656066895
training step: 31028, total_loss: 4.17490291595459
training step: 31029, total_loss: 4.427743434906006
training step: 31030, total_loss: 4.305133819580078
training step: 31031, total_loss: 2.1484978199005127
training step: 31032, total_loss: 4.872054576873779
training step: 31033, total_loss: 5.124029159545898
training step: 31034, total_loss: 4.043369293212891
training step: 31035, total_loss: 5.130396842956543
training step: 31036, total_loss: 3.773408889770508
training step: 31037, total_loss: 4.834865570068359
training step: 31038, total_loss: 4.776453018188477
training step: 31039, total_loss: 4.2861833572387695
training step: 31040, total_loss: 5.0300517082214355
training step: 31041, total_loss: 5.166311264038086
training step: 31042, total_loss: 4.185057640075684
training step: 31043, total_loss: 5.353689193725586
training step: 31044, total_loss: 3.9921059608459473
training step: 31045, total_loss: 2.5031347274780273
training step: 31046, total_loss: 5.0365400314331055
training step: 31047, total_loss: 5.166716575622559
training step: 31048, total_loss: 4.673342704772949
training step: 31049, total_loss: 4.495988368988037
training step: 31050, total_loss: 5.166674613952637
training step: 31051, total_loss: 4.365704536437988
training step: 31052, total_loss: 4.5469818115234375
training step: 31053, total_loss: 4.91330099105835
training step: 31054, total_loss: 4.3653459548950195
training step: 31055, total_loss: 4.9147186279296875
training step: 31056, total_loss: 3.9040122032165527
training step: 31057, total_loss: 4.575080871582031
training step: 31058, total_loss: 6.545003414154053
training step: 31059, total_loss: 4.071654796600342
training step: 31060, total_loss: 5.036445140838623
training step: 31061, total_loss: 4.606300354003906
training step: 31062, total_loss: 4.278541088104248
training step: 31063, total_loss: 3.882974147796631
training step: 31064, total_loss: 6.196951389312744
training step: 31065, total_loss: 4.1243743896484375
training step: 31066, total_loss: 1.9597270488739014
training step: 31067, total_loss: 6.094215393066406
training step: 31068, total_loss: 7.847096920013428
training step: 31069, total_loss: 3.6720130443573
training step: 31070, total_loss: 4.532229423522949
training step: 31071, total_loss: 5.424654960632324
training step: 31072, total_loss: 4.7958269119262695
training step: 31073, total_loss: 3.6630520820617676
training step: 31074, total_loss: 5.520101547241211
training step: 31075, total_loss: 3.9691882133483887
training step: 31076, total_loss: 4.947317123413086
training step: 31077, total_loss: 4.849704742431641
training step: 31078, total_loss: 4.2979278564453125
training step: 31079, total_loss: 3.379054546356201
training step: 31080, total_loss: 3.9143834114074707
training step: 31081, total_loss: 4.3697004318237305
training step: 31082, total_loss: 4.448647975921631
training step: 31083, total_loss: 5.187769412994385
training step: 31084, total_loss: 5.104963302612305
training step: 31085, total_loss: 3.427664279937744
training step: 31086, total_loss: 5.504071235656738
training step: 31087, total_loss: 5.368942737579346
training step: 31088, total_loss: 0.8328741788864136
training step: 31089, total_loss: 3.467738628387451
training step: 31090, total_loss: 4.02022647857666
training step: 31091, total_loss: 6.310937881469727
training step: 31092, total_loss: 5.619174003601074
training step: 31093, total_loss: 4.774692535400391
training step: 31094, total_loss: 6.5572919845581055
training step: 31095, total_loss: 4.080480098724365
training step: 31096, total_loss: 4.875040054321289
training step: 31097, total_loss: 3.7627954483032227
training step: 31098, total_loss: 2.8373608589172363
training step: 31099, total_loss: 3.9368786811828613
training step: 31100, total_loss: 6.070096015930176
training step: 31101, total_loss: 6.0087995529174805
training step: 31102, total_loss: 3.403524875640869
training step: 31103, total_loss: 4.401318073272705
training step: 31104, total_loss: 4.615041732788086
training step: 31105, total_loss: 4.2967939376831055
training step: 31106, total_loss: 5.989131927490234
training step: 31107, total_loss: 4.888354778289795
training step: 31108, total_loss: 5.113914489746094
training step: 31109, total_loss: 3.5728135108947754
training step: 31110, total_loss: 4.680522918701172
training step: 31111, total_loss: 5.5948004722595215
training step: 31112, total_loss: 5.713064193725586
training step: 31113, total_loss: 2.835235118865967
training step: 31114, total_loss: 5.177746772766113
training step: 31115, total_loss: 4.507256984710693
training step: 31116, total_loss: 5.129128456115723
training step: 31117, total_loss: 4.516890525817871
training step: 31118, total_loss: 4.3751726150512695
training step: 31119, total_loss: 4.444331169128418
training step: 31120, total_loss: 4.167036056518555
training step: 31121, total_loss: 4.604866027832031
training step: 31122, total_loss: 5.375692844390869
training step: 31123, total_loss: 4.364925384521484
training step: 31124, total_loss: 4.153051376342773
training step: 31125, total_loss: 3.1667280197143555
training step: 31126, total_loss: 3.2887144088745117
training step: 31127, total_loss: 4.28147029876709
training step: 31128, total_loss: 4.469536781311035
training step: 31129, total_loss: 4.004384994506836
training step: 31130, total_loss: 4.3556671142578125
training step: 31131, total_loss: 3.70651912689209
training step: 31132, total_loss: 4.668869495391846
training step: 31133, total_loss: 4.087954044342041
training step: 31134, total_loss: 5.440491199493408
training step: 31135, total_loss: 3.948040008544922
training step: 31136, total_loss: 5.131026268005371
training step: 31137, total_loss: 3.983382225036621
training step: 31138, total_loss: 4.562183380126953
training step: 31139, total_loss: 4.629574298858643
training step: 31140, total_loss: 4.644287109375
training step: 31141, total_loss: 4.610055923461914
training step: 31142, total_loss: 4.8472161293029785
training step: 31143, total_loss: 6.146686553955078
training step: 31144, total_loss: 4.8832879066467285
training step: 31145, total_loss: 5.7574310302734375
training step: 31146, total_loss: 4.4945197105407715
training step: 31147, total_loss: 2.372649908065796
training step: 31148, total_loss: 4.811999320983887
training step: 31149, total_loss: 4.448177337646484
training step: 31150, total_loss: 5.0340070724487305
training step: 31151, total_loss: 4.9767165184021
training step: 31152, total_loss: 2.974660873413086
training step: 31153, total_loss: 5.75227165222168
training step: 31154, total_loss: 5.319089412689209
training step: 31155, total_loss: 4.556645393371582
training step: 31156, total_loss: 5.192700386047363
training step: 31157, total_loss: 4.499917030334473
training step: 31158, total_loss: 4.268813133239746
training step: 31159, total_loss: 4.594204902648926
training step: 31160, total_loss: 3.65659761428833
training step: 31161, total_loss: 2.6434075832366943
training step: 31162, total_loss: 5.0616774559021
training step: 31163, total_loss: 4.4260149002075195
training step: 31164, total_loss: 4.0523600578308105
training step: 31165, total_loss: 3.8508758544921875
training step: 31166, total_loss: 5.682002067565918
training step: 31167, total_loss: 5.178922653198242
training step: 31168, total_loss: 4.72962760925293
training step: 31169, total_loss: 4.981145858764648
training step: 31170, total_loss: 5.44218635559082
training step: 31171, total_loss: 3.6936192512512207
training step: 31172, total_loss: 3.931062698364258
training step: 31173, total_loss: 1.288804054260254
training step: 31174, total_loss: 4.7788310050964355
training step: 31175, total_loss: 4.662788391113281
training step: 31176, total_loss: 5.952079772949219
training step: 31177, total_loss: 4.894124507904053
training step: 31178, total_loss: 3.6998631954193115
training step: 31179, total_loss: 3.9354052543640137
training step: 31180, total_loss: 2.7123942375183105
training step: 31181, total_loss: 4.316565990447998
training step: 31182, total_loss: 2.9425721168518066
training step: 31183, total_loss: 6.504115104675293
training step: 31184, total_loss: 3.4177958965301514
training step: 31185, total_loss: 4.775067329406738
training step: 31186, total_loss: 5.251689910888672
training step: 31187, total_loss: 3.2584962844848633
training step: 31188, total_loss: 2.9964661598205566
training step: 31189, total_loss: 3.4298458099365234
training step: 31190, total_loss: 4.12087345123291
training step: 31191, total_loss: 1.1850138902664185
training step: 31192, total_loss: 5.323610782623291
training step: 31193, total_loss: 6.164587020874023
training step: 31194, total_loss: 3.329202651977539
training step: 31195, total_loss: 4.98928165435791
training step: 31196, total_loss: 5.589788436889648
training step: 31197, total_loss: 1.3476718664169312
training step: 31198, total_loss: 3.7075695991516113
training step: 31199, total_loss: 5.418295383453369
training step: 31200, total_loss: 5.444106101989746
training step: 31201, total_loss: 5.177555084228516
training step: 31202, total_loss: 3.801236629486084
training step: 31203, total_loss: 2.9171721935272217
training step: 31204, total_loss: 4.638546943664551
training step: 31205, total_loss: 1.0807034969329834
training step: 31206, total_loss: 5.468091011047363
training step: 31207, total_loss: 6.426424026489258
training step: 31208, total_loss: 5.139259338378906
training step: 31209, total_loss: 4.199603080749512
training step: 31210, total_loss: 6.060117244720459
training step: 31211, total_loss: 4.179642677307129
training step: 31212, total_loss: 4.121844291687012
training step: 31213, total_loss: 5.824322700500488
training step: 31214, total_loss: 5.5108184814453125
training step: 31215, total_loss: 4.893332481384277
training step: 31216, total_loss: 6.438536643981934
training step: 31217, total_loss: 5.151845932006836
training step: 31218, total_loss: 5.126290798187256
training step: 31219, total_loss: 5.37755012512207
training step: 31220, total_loss: 4.547608375549316
training step: 31221, total_loss: 2.7524800300598145
training step: 31222, total_loss: 3.2856831550598145
training step: 31223, total_loss: 3.72989559173584
training step: 31224, total_loss: 3.6784729957580566
training step: 31225, total_loss: 4.330968856811523
training step: 31226, total_loss: 3.082566261291504
training step: 31227, total_loss: 5.00842809677124
training step: 31228, total_loss: 4.294736385345459
training step: 31229, total_loss: 4.7911057472229
training step: 31230, total_loss: 4.063390731811523
training step: 31231, total_loss: 5.304981231689453
training step: 31232, total_loss: 5.099299430847168
training step: 31233, total_loss: 3.8289482593536377
training step: 31234, total_loss: 6.114561080932617
training step: 31235, total_loss: 3.7145590782165527
training step: 31236, total_loss: 4.766559600830078
training step: 31237, total_loss: 4.579716205596924
training step: 31238, total_loss: 4.294243812561035
training step: 31239, total_loss: 4.197750568389893
training step: 31240, total_loss: 4.351653575897217
training step: 31241, total_loss: 0.9469955563545227
training step: 31242, total_loss: 4.284789562225342
training step: 31243, total_loss: 4.4487810134887695
training step: 31244, total_loss: 5.304628372192383
training step: 31245, total_loss: 3.3359341621398926
training step: 31246, total_loss: 3.503739833831787
training step: 31247, total_loss: 5.0327606201171875
training step: 31248, total_loss: 3.293203830718994
training step: 31249, total_loss: 3.9396700859069824
training step: 31250, total_loss: 2.8125784397125244
training step: 31251, total_loss: 5.214104652404785
training step: 31252, total_loss: 1.0340008735656738
training step: 31253, total_loss: 5.1561384201049805
training step: 31254, total_loss: 5.314146041870117
training step: 31255, total_loss: 2.9697060585021973
training step: 31256, total_loss: 5.756548881530762
training step: 31257, total_loss: 5.178966522216797
training step: 31258, total_loss: 4.48445463180542
training step: 31259, total_loss: 5.003810882568359
training step: 31260, total_loss: 5.278341293334961
training step: 31261, total_loss: 3.557870388031006
training step: 31262, total_loss: 4.351286888122559
training step: 31263, total_loss: 4.050091743469238
training step: 31264, total_loss: 3.2039146423339844
training step: 31265, total_loss: 5.2392683029174805
training step: 31266, total_loss: 5.3077921867370605
training step: 31267, total_loss: 5.277477264404297
training step: 31268, total_loss: 2.5571579933166504
training step: 31269, total_loss: 3.8960394859313965
training step: 31270, total_loss: 4.317071437835693
training step: 31271, total_loss: 4.213655948638916
training step: 31272, total_loss: 5.1634368896484375
training step: 31273, total_loss: 3.2927703857421875
training step: 31274, total_loss: 2.507516384124756
training step: 31275, total_loss: 4.626721382141113
training step: 31276, total_loss: 4.232404708862305
training step: 31277, total_loss: 2.985002279281616
training step: 31278, total_loss: 4.747316360473633
training step: 31279, total_loss: 4.592665672302246
training step: 31280, total_loss: 3.9165430068969727
training step: 31281, total_loss: 5.993969440460205
training step: 31282, total_loss: 4.892107963562012
training step: 31283, total_loss: 2.557034969329834
training step: 31284, total_loss: 5.818876266479492
training step: 31285, total_loss: 4.083864212036133
training step: 31286, total_loss: 5.386839866638184
training step: 31287, total_loss: 4.763578414916992
training step: 31288, total_loss: 2.707720994949341
training step: 31289, total_loss: 5.735309600830078
training step: 31290, total_loss: 6.250110626220703
training step: 31291, total_loss: 3.1617794036865234
training step: 31292, total_loss: 4.732419013977051
training step: 31293, total_loss: 3.596169948577881
training step: 31294, total_loss: 5.323670387268066
training step: 31295, total_loss: 3.08805251121521
training step: 31296, total_loss: 0.9832624793052673
training step: 31297, total_loss: 4.151839256286621
training step: 31298, total_loss: 3.7265491485595703
training step: 31299, total_loss: 4.621573448181152
training step: 31300, total_loss: 4.880218505859375
training step: 31301, total_loss: 6.179633140563965
training step: 31302, total_loss: 3.630039691925049
training step: 31303, total_loss: 6.957980155944824
training step: 31304, total_loss: 3.136693000793457
training step: 31305, total_loss: 5.236480712890625
training step: 31306, total_loss: 4.627175331115723
training step: 31307, total_loss: 4.227875232696533
training step: 31308, total_loss: 4.2095947265625
training step: 31309, total_loss: 5.859170913696289
training step: 31310, total_loss: 3.6839675903320312
training step: 31311, total_loss: 1.4466584920883179
training step: 31312, total_loss: 5.256081581115723
training step: 31313, total_loss: 4.390449523925781
training step: 31314, total_loss: 4.886323928833008
training step: 31315, total_loss: 3.765775203704834
training step: 31316, total_loss: 6.131364822387695
training step: 31317, total_loss: 4.4174041748046875
training step: 31318, total_loss: 4.376553058624268
training step: 31319, total_loss: 5.078530311584473
training step: 31320, total_loss: 4.64960241317749
training step: 31321, total_loss: 3.8525099754333496
training step: 31322, total_loss: 4.972798824310303
training step: 31323, total_loss: 3.9872541427612305
training step: 31324, total_loss: 4.985108852386475
training step: 31325, total_loss: 4.763986587524414
training step: 31326, total_loss: 5.09941291809082
training step: 31327, total_loss: 3.0732030868530273
training step: 31328, total_loss: 4.316824913024902
training step: 31329, total_loss: 4.172456741333008
training step: 31330, total_loss: 4.129968643188477
training step: 31331, total_loss: 3.1317310333251953
training step: 31332, total_loss: 4.330898284912109
training step: 31333, total_loss: 4.145742893218994
training step: 31334, total_loss: 3.6649980545043945
training step: 31335, total_loss: 3.650167465209961
training step: 31336, total_loss: 4.869370937347412
training step: 31337, total_loss: 4.304540634155273
training step: 31338, total_loss: 4.29011344909668
training step: 31339, total_loss: 4.482813358306885
training step: 31340, total_loss: 5.47508430480957
training step: 31341, total_loss: 4.7188544273376465
training step: 31342, total_loss: 3.2762045860290527
training step: 31343, total_loss: 4.761929512023926
training step: 31344, total_loss: 4.503534317016602
training step: 31345, total_loss: 4.922273635864258
training step: 31346, total_loss: 4.790506362915039
training step: 31347, total_loss: 5.696588039398193
training step: 31348, total_loss: 5.871673583984375
training step: 31349, total_loss: 5.923192977905273
training step: 31350, total_loss: 3.084063768386841
training step: 31351, total_loss: 3.6662986278533936
training step: 31352, total_loss: 6.020592212677002
training step: 31353, total_loss: 6.414121627807617
training step: 31354, total_loss: 3.8699264526367188
training step: 31355, total_loss: 1.138108730316162
training step: 31356, total_loss: 2.5358519554138184
training step: 31357, total_loss: 3.8241355419158936
training step: 31358, total_loss: 4.655778408050537
training step: 31359, total_loss: 5.093252182006836
training step: 31360, total_loss: 4.783167839050293
training step: 31361, total_loss: 4.706026077270508
training step: 31362, total_loss: 4.520951747894287
training step: 31363, total_loss: 5.540886402130127
training step: 31364, total_loss: 3.5384058952331543
training step: 31365, total_loss: 4.863628387451172
training step: 31366, total_loss: 4.335038661956787
training step: 31367, total_loss: 5.569530010223389
training step: 31368, total_loss: 5.104753017425537
training step: 31369, total_loss: 5.532321929931641
training step: 31370, total_loss: 6.795688629150391
training step: 31371, total_loss: 2.8906383514404297
training step: 31372, total_loss: 4.700170516967773
training step: 31373, total_loss: 1.2716500759124756
training step: 31374, total_loss: 5.363885879516602
training step: 31375, total_loss: 2.8698487281799316
training step: 31376, total_loss: 3.838834762573242
training step: 31377, total_loss: 4.580278396606445
training step: 31378, total_loss: 4.359414577484131
training step: 31379, total_loss: 4.887284755706787
training step: 31380, total_loss: 1.0703191757202148
training step: 31381, total_loss: 4.725095748901367
training step: 31382, total_loss: 5.5645599365234375
training step: 31383, total_loss: 4.722499370574951
training step: 31384, total_loss: 6.3224992752075195
training step: 31385, total_loss: 4.643718719482422
training step: 31386, total_loss: 4.316744804382324
training step: 31387, total_loss: 3.7700881958007812
training step: 31388, total_loss: 3.6293420791625977
training step: 31389, total_loss: 5.0874924659729
training step: 31390, total_loss: 5.182101249694824
training step: 31391, total_loss: 4.144281387329102
training step: 31392, total_loss: 4.029318809509277
training step: 31393, total_loss: 3.7766807079315186
training step: 31394, total_loss: 5.904374122619629
training step: 31395, total_loss: 0.9246546030044556
training step: 31396, total_loss: 7.229312419891357
training step: 31397, total_loss: 3.7583870887756348
training step: 31398, total_loss: 5.712141990661621
training step: 31399, total_loss: 4.6869683265686035
training step: 31400, total_loss: 4.181514739990234
training step: 31401, total_loss: 2.846571445465088
training step: 31402, total_loss: 3.892404556274414
training step: 31403, total_loss: 2.3914806842803955
training step: 31404, total_loss: 3.8403160572052
training step: 31405, total_loss: 5.60177755355835
training step: 31406, total_loss: 4.458442211151123
training step: 31407, total_loss: 4.827754020690918
training step: 31408, total_loss: 3.7410101890563965
training step: 31409, total_loss: 2.3955111503601074
training step: 31410, total_loss: 5.368353843688965
training step: 31411, total_loss: 4.6684489250183105
training step: 31412, total_loss: 3.7387290000915527
training step: 31413, total_loss: 4.744743347167969
training step: 31414, total_loss: 4.063292503356934
training step: 31415, total_loss: 3.983551025390625
training step: 31416, total_loss: 4.125105381011963
training step: 31417, total_loss: 1.821035623550415
training step: 31418, total_loss: 5.042427062988281
training step: 31419, total_loss: 3.436971664428711
training step: 31420, total_loss: 3.165379524230957
training step: 31421, total_loss: 5.475429534912109
training step: 31422, total_loss: 3.9308695793151855
training step: 31423, total_loss: 4.339700698852539
training step: 31424, total_loss: 4.876598358154297
training step: 31425, total_loss: 3.8237786293029785
training step: 31426, total_loss: 5.450079917907715
training step: 31427, total_loss: 5.527238845825195
training step: 31428, total_loss: 4.223295211791992
training step: 31429, total_loss: 5.142688274383545
training step: 31430, total_loss: 3.7045555114746094
training step: 31431, total_loss: 3.7811498641967773
training step: 31432, total_loss: 2.5577545166015625
training step: 31433, total_loss: 2.2726621627807617
training step: 31434, total_loss: 0.69149249792099
training step: 31435, total_loss: 5.1095991134643555
training step: 31436, total_loss: 4.2925872802734375
training step: 31437, total_loss: 4.260424613952637
training step: 31438, total_loss: 4.812169075012207
training step: 31439, total_loss: 5.943622589111328
training step: 31440, total_loss: 4.4785847663879395
training step: 31441, total_loss: 2.0098819732666016
training step: 31442, total_loss: 4.270701885223389
training step: 31443, total_loss: 4.539822578430176
training step: 31444, total_loss: 4.8861894607543945
training step: 31445, total_loss: 5.09296989440918
training step: 31446, total_loss: 3.7230029106140137
training step: 31447, total_loss: 4.206087589263916
training step: 31448, total_loss: 6.197892189025879
training step: 31449, total_loss: 3.7376160621643066
training step: 31450, total_loss: 4.27644157409668
training step: 31451, total_loss: 4.728421688079834
training step: 31452, total_loss: 2.845677614212036
training step: 31453, total_loss: 4.7435302734375
training step: 31454, total_loss: 4.721982955932617
training step: 31455, total_loss: 4.646967887878418
training step: 31456, total_loss: 5.27467155456543
training step: 31457, total_loss: 3.4641377925872803
training step: 31458, total_loss: 4.435060977935791
training step: 31459, total_loss: 3.5866127014160156
training step: 31460, total_loss: 5.473027229309082
training step: 31461, total_loss: 5.000617980957031
training step: 31462, total_loss: 7.9323530197143555
training step: 31463, total_loss: 4.214299201965332
training step: 31464, total_loss: 4.874320030212402
training step: 31465, total_loss: 5.092062473297119
training step: 31466, total_loss: 5.406052112579346
training step: 31467, total_loss: 4.996682167053223
training step: 31468, total_loss: 4.138833045959473
training step: 31469, total_loss: 4.452136993408203
training step: 31470, total_loss: 4.746276378631592
training step: 31471, total_loss: 2.668199300765991
training step: 31472, total_loss: 4.471339225769043
training step: 31473, total_loss: 3.2853846549987793
training step: 31474, total_loss: 4.546243667602539
training step: 31475, total_loss: 3.9444446563720703
training step: 31476, total_loss: 4.458660125732422
training step: 31477, total_loss: 4.798691749572754
training step: 31478, total_loss: 5.146845817565918
training step: 31479, total_loss: 3.7121293544769287
training step: 31480, total_loss: 4.423064231872559
training step: 31481, total_loss: 4.627470016479492
training step: 31482, total_loss: 3.2447800636291504
training step: 31483, total_loss: 5.034850120544434
training step: 31484, total_loss: 3.1207058429718018
training step: 31485, total_loss: 4.859471321105957
training step: 31486, total_loss: 4.763994216918945
training step: 31487, total_loss: 3.5297493934631348
training step: 31488, total_loss: 2.5721945762634277
training step: 31489, total_loss: 4.724124431610107
training step: 31490, total_loss: 4.54522705078125
training step: 31491, total_loss: 4.753245830535889
training step: 31492, total_loss: 4.162410736083984
training step: 31493, total_loss: 3.849156141281128
training step: 31494, total_loss: 5.0542802810668945
training step: 31495, total_loss: 4.969033718109131
training step: 31496, total_loss: 4.684559345245361
training step: 31497, total_loss: 5.165742874145508
training step: 31498, total_loss: 3.7863807678222656
training step: 31499, total_loss: 5.253820419311523
training step: 31500, total_loss: 4.689323902130127
training step: 31501, total_loss: 5.239713191986084
training step: 31502, total_loss: 4.397007465362549
training step: 31503, total_loss: 3.7888224124908447
training step: 31504, total_loss: 4.043004512786865
training step: 31505, total_loss: 4.439554214477539
training step: 31506, total_loss: 3.3749122619628906
training step: 31507, total_loss: 5.734682559967041
training step: 31508, total_loss: 3.6366119384765625
training step: 31509, total_loss: 3.782424211502075
training step: 31510, total_loss: 4.992618560791016
training step: 31511, total_loss: 4.9168572425842285
training step: 31512, total_loss: 5.458040237426758
training step: 31513, total_loss: 5.511440277099609
training step: 31514, total_loss: 3.2443056106567383
training step: 31515, total_loss: 4.228902339935303
training step: 31516, total_loss: 2.836075782775879
training step: 31517, total_loss: 4.135425567626953
training step: 31518, total_loss: 4.908902645111084
training step: 31519, total_loss: 5.42076301574707
training step: 31520, total_loss: 4.660032749176025
training step: 31521, total_loss: 3.86222505569458
training step: 31522, total_loss: 3.470571517944336
training step: 31523, total_loss: 4.60078763961792
training step: 31524, total_loss: 5.847455024719238
training step: 31525, total_loss: 4.8360395431518555
training step: 31526, total_loss: 5.161730766296387
training step: 31527, total_loss: 3.4220283031463623
training step: 31528, total_loss: 5.418755531311035
training step: 31529, total_loss: 3.725188970565796
training step: 31530, total_loss: 4.27508544921875
training step: 31531, total_loss: 2.3961594104766846
training step: 31532, total_loss: 4.387339115142822
training step: 31533, total_loss: 5.748385906219482
training step: 31534, total_loss: 4.108679294586182
training step: 31535, total_loss: 6.097418308258057
training step: 31536, total_loss: 3.031352996826172
training step: 31537, total_loss: 4.1435866355896
training step: 31538, total_loss: 5.658396244049072
training step: 31539, total_loss: 4.1269917488098145
training step: 31540, total_loss: 3.162031650543213
training step: 31541, total_loss: 5.225827693939209
training step: 31542, total_loss: 4.489673614501953
training step: 31543, total_loss: 4.91891622543335
training step: 31544, total_loss: 4.050377368927002
training step: 31545, total_loss: 4.920078277587891
training step: 31546, total_loss: 5.589028835296631
training step: 31547, total_loss: 4.2420268058776855
training step: 31548, total_loss: 4.751716613769531
training step: 31549, total_loss: 4.126719951629639
training step: 31550, total_loss: 4.301754474639893
training step: 31551, total_loss: 3.9637622833251953
training step: 31552, total_loss: 5.227876663208008
training step: 31553, total_loss: 3.7148852348327637
training step: 31554, total_loss: 4.244671821594238
training step: 31555, total_loss: 3.5160341262817383
training step: 31556, total_loss: 5.268229961395264
training step: 31557, total_loss: 5.06262731552124
training step: 31558, total_loss: 4.610618591308594
training step: 31559, total_loss: 3.8236584663391113
training step: 31560, total_loss: 0.9666275978088379
training step: 31561, total_loss: 3.2831742763519287
training step: 31562, total_loss: 4.184848785400391
training step: 31563, total_loss: 4.209078311920166
training step: 31564, total_loss: 2.6018803119659424
training step: 31565, total_loss: 3.794785499572754
training step: 31566, total_loss: 6.1291961669921875
training step: 31567, total_loss: 5.297189712524414
training step: 31568, total_loss: 4.107370853424072
training step: 31569, total_loss: 4.130606651306152
training step: 31570, total_loss: 1.6232059001922607
training step: 31571, total_loss: 4.648096084594727
training step: 31572, total_loss: 5.227639198303223
training step: 31573, total_loss: 2.8361992835998535
training step: 31574, total_loss: 4.133002281188965
training step: 31575, total_loss: 2.1829452514648438
training step: 31576, total_loss: 4.113015174865723
training step: 31577, total_loss: 3.9096479415893555
training step: 31578, total_loss: 4.649688720703125
training step: 31579, total_loss: 3.7225983142852783
training step: 31580, total_loss: 3.7476630210876465
training step: 31581, total_loss: 5.402578353881836
training step: 31582, total_loss: 5.412630081176758
training step: 31583, total_loss: 4.008106231689453
training step: 31584, total_loss: 5.140534400939941
training step: 31585, total_loss: 4.870293617248535
training step: 31586, total_loss: 4.624235153198242
training step: 31587, total_loss: 1.3406269550323486
training step: 31588, total_loss: 4.4974541664123535
training step: 31589, total_loss: 4.607559680938721
training step: 31590, total_loss: 6.169074058532715
training step: 31591, total_loss: 4.939451217651367
training step: 31592, total_loss: 2.8489603996276855
training step: 31593, total_loss: 3.712221145629883
training step: 31594, total_loss: 2.6490445137023926
training step: 31595, total_loss: 4.456674575805664
training step: 31596, total_loss: 4.697493553161621
training step: 31597, total_loss: 3.0474982261657715
training step: 31598, total_loss: 3.7781777381896973
training step: 31599, total_loss: 4.5399580001831055
training step: 31600, total_loss: 3.882575273513794
training step: 31601, total_loss: 4.819356918334961
training step: 31602, total_loss: 6.348769187927246
training step: 31603, total_loss: 4.359816551208496
training step: 31604, total_loss: 4.629456996917725
training step: 31605, total_loss: 3.81046199798584
training step: 31606, total_loss: 4.958785057067871
training step: 31607, total_loss: 5.70524787902832
training step: 31608, total_loss: 3.395425319671631
training step: 31609, total_loss: 5.332766532897949
training step: 31610, total_loss: 6.651446342468262
training step: 31611, total_loss: 6.0185980796813965
training step: 31612, total_loss: 5.029345989227295
training step: 31613, total_loss: 3.8723068237304688
training step: 31614, total_loss: 5.362398147583008
training step: 31615, total_loss: 5.162222385406494
training step: 31616, total_loss: 4.3465962409973145
training step: 31617, total_loss: 4.662622928619385
training step: 31618, total_loss: 2.6419456005096436
training step: 31619, total_loss: 3.4657649993896484
training step: 31620, total_loss: 5.109123706817627
training step: 31621, total_loss: 4.871329307556152
training step: 31622, total_loss: 5.384593963623047
training step: 31623, total_loss: 2.9015676975250244
training step: 31624, total_loss: 3.539552688598633
training step: 31625, total_loss: 4.759666919708252
training step: 31626, total_loss: 3.9097845554351807
training step: 31627, total_loss: 4.955286979675293
training step: 31628, total_loss: 4.219351768493652
training step: 31629, total_loss: 4.700361728668213
training step: 31630, total_loss: 5.142084121704102
training step: 31631, total_loss: 5.197697639465332
training step: 31632, total_loss: 4.314154624938965
training step: 31633, total_loss: 4.550831317901611
training step: 31634, total_loss: 3.854414463043213
training step: 31635, total_loss: 4.280003547668457
training step: 31636, total_loss: 4.824422836303711
training step: 31637, total_loss: 5.5173187255859375
training step: 31638, total_loss: 4.7098307609558105
training step: 31639, total_loss: 3.75067138671875
training step: 31640, total_loss: 5.213559150695801
training step: 31641, total_loss: 4.667035102844238
training step: 31642, total_loss: 4.070672035217285
training step: 31643, total_loss: 5.039443016052246
training step: 31644, total_loss: 3.91361141204834
training step: 31645, total_loss: 3.9638779163360596
training step: 31646, total_loss: 4.246079921722412
training step: 31647, total_loss: 5.802271366119385
training step: 31648, total_loss: 3.776642322540283
training step: 31649, total_loss: 3.816680908203125
training step: 31650, total_loss: 5.113590240478516
training step: 31651, total_loss: 3.988773822784424
training step: 31652, total_loss: 4.194584846496582
training step: 31653, total_loss: 4.7355570793151855
training step: 31654, total_loss: 5.652157306671143
training step: 31655, total_loss: 3.216252326965332
training step: 31656, total_loss: 4.1303606033325195
training step: 31657, total_loss: 4.3272528648376465
training step: 31658, total_loss: 4.767406940460205
training step: 31659, total_loss: 3.0301098823547363
training step: 31660, total_loss: 5.984494686126709
training step: 31661, total_loss: 3.661938190460205
training step: 31662, total_loss: 4.176942825317383
training step: 31663, total_loss: 3.616543769836426
training step: 31664, total_loss: 3.41825008392334
training step: 31665, total_loss: 3.4067587852478027
training step: 31666, total_loss: 5.182343482971191
training step: 31667, total_loss: 4.578341960906982
training step: 31668, total_loss: 5.179039001464844
training step: 31669, total_loss: 4.63881254196167
training step: 31670, total_loss: 5.676840305328369
training step: 31671, total_loss: 4.966856956481934
training step: 31672, total_loss: 4.547682285308838
training step: 31673, total_loss: 2.6398375034332275
training step: 31674, total_loss: 3.4962403774261475
training step: 31675, total_loss: 2.925996780395508
training step: 31676, total_loss: 5.335326194763184
training step: 31677, total_loss: 6.234967231750488
training step: 31678, total_loss: 4.496652126312256
training step: 31679, total_loss: 4.868002891540527
training step: 31680, total_loss: 3.444016933441162
training step: 31681, total_loss: 3.6676392555236816
training step: 31682, total_loss: 4.753043174743652
training step: 31683, total_loss: 4.108184337615967
training step: 31684, total_loss: 3.880826473236084
training step: 31685, total_loss: 1.2531707286834717
training step: 31686, total_loss: 5.5335845947265625
training step: 31687, total_loss: 4.1276960372924805
training step: 31688, total_loss: 3.993281841278076
training step: 31689, total_loss: 3.5448522567749023
training step: 31690, total_loss: 4.192349910736084
training step: 31691, total_loss: 5.694178581237793
training step: 31692, total_loss: 4.12187385559082
training step: 31693, total_loss: 4.742438316345215
training step: 31694, total_loss: 3.912362813949585
training step: 31695, total_loss: 4.814023494720459
training step: 31696, total_loss: 6.555655002593994
training step: 31697, total_loss: 3.70758056640625
training step: 31698, total_loss: 1.9723994731903076
training step: 31699, total_loss: 2.5981016159057617
training step: 31700, total_loss: 2.7150464057922363
training step: 31701, total_loss: 4.340203285217285
training step: 31702, total_loss: 6.310676574707031
training step: 31703, total_loss: 4.67636775970459
training step: 31704, total_loss: 5.635734558105469
training step: 31705, total_loss: 3.3340792655944824
training step: 31706, total_loss: 4.412248611450195
training step: 31707, total_loss: 4.442885398864746
training step: 31708, total_loss: 4.847397804260254
training step: 31709, total_loss: 4.228399276733398
training step: 31710, total_loss: 2.679027557373047
training step: 31711, total_loss: 3.376950263977051
training step: 31712, total_loss: 3.702336549758911
training step: 31713, total_loss: 5.385708808898926
training step: 31714, total_loss: 3.4226903915405273
training step: 31715, total_loss: 4.0810441970825195
training step: 31716, total_loss: 5.658617973327637
training step: 31717, total_loss: 4.692983627319336
training step: 31718, total_loss: 1.9596762657165527
training step: 31719, total_loss: 5.75750732421875
training step: 31720, total_loss: 0.7615126371383667
training step: 31721, total_loss: 5.302604675292969
training step: 31722, total_loss: 4.512509822845459
training step: 31723, total_loss: 4.512267589569092
training step: 31724, total_loss: 4.031538486480713
training step: 31725, total_loss: 4.139810562133789
training step: 31726, total_loss: 4.863747596740723
training step: 31727, total_loss: 4.921404838562012
training step: 31728, total_loss: 2.9462175369262695
training step: 31729, total_loss: 4.490628242492676
training step: 31730, total_loss: 4.988398551940918
training step: 31731, total_loss: 2.732239007949829
training step: 31732, total_loss: 4.5363850593566895
training step: 31733, total_loss: 4.462002754211426
training step: 31734, total_loss: 4.727250099182129
training step: 31735, total_loss: 5.183474540710449
training step: 31736, total_loss: 4.105293273925781
training step: 31737, total_loss: 4.2771711349487305
training step: 31738, total_loss: 4.666538238525391
training step: 31739, total_loss: 5.218410968780518
training step: 31740, total_loss: 4.369083404541016
training step: 31741, total_loss: 4.195626735687256
training step: 31742, total_loss: 3.995697021484375
training step: 31743, total_loss: 6.8010993003845215
training step: 31744, total_loss: 4.793034076690674
training step: 31745, total_loss: 4.064113616943359
training step: 31746, total_loss: 4.867847442626953
training step: 31747, total_loss: 5.855344772338867
training step: 31748, total_loss: 3.1441547870635986
training step: 31749, total_loss: 5.771197319030762
training step: 31750, total_loss: 3.395639419555664
training step: 31751, total_loss: 4.993961811065674
training step: 31752, total_loss: 5.566677570343018
training step: 31753, total_loss: 4.514011383056641
training step: 31754, total_loss: 4.834203720092773
training step: 31755, total_loss: 5.489160060882568
training step: 31756, total_loss: 5.366670608520508
training step: 31757, total_loss: 4.876277923583984
training step: 31758, total_loss: 4.9008026123046875
training step: 31759, total_loss: 2.0165932178497314
training step: 31760, total_loss: 7.362218856811523
training step: 31761, total_loss: 3.8031322956085205
training step: 31762, total_loss: 4.359633445739746
training step: 31763, total_loss: 5.464921951293945
training step: 31764, total_loss: 3.668452501296997
training step: 31765, total_loss: 4.71659517288208
training step: 31766, total_loss: 4.890507698059082
training step: 31767, total_loss: 4.079561710357666
training step: 31768, total_loss: 4.168612480163574
training step: 31769, total_loss: 4.830266952514648
training step: 31770, total_loss: 3.775512456893921
training step: 31771, total_loss: 5.702765941619873
training step: 31772, total_loss: 5.318878650665283
training step: 31773, total_loss: 3.647752046585083
training step: 31774, total_loss: 6.438970565795898
training step: 31775, total_loss: 6.142191410064697
training step: 31776, total_loss: 3.4114859104156494
training step: 31777, total_loss: 7.199433326721191
training step: 31778, total_loss: 5.567190647125244
training step: 31779, total_loss: 4.361079216003418
training step: 31780, total_loss: 6.542656898498535
training step: 31781, total_loss: 5.791131019592285
training step: 31782, total_loss: 4.208808898925781
training step: 31783, total_loss: 3.4260435104370117
training step: 31784, total_loss: 4.935714244842529
training step: 31785, total_loss: 5.169735908508301
training step: 31786, total_loss: 3.992814779281616
training step: 31787, total_loss: 4.649692058563232
training step: 31788, total_loss: 6.171377182006836
training step: 31789, total_loss: 5.380647659301758
training step: 31790, total_loss: 6.666591167449951
training step: 31791, total_loss: 3.6216306686401367
training step: 31792, total_loss: 3.7994420528411865
training step: 31793, total_loss: 4.114109992980957
training step: 31794, total_loss: 4.731577396392822
training step: 31795, total_loss: 3.101809024810791
training step: 31796, total_loss: 4.415794372558594
training step: 31797, total_loss: 1.523470163345337
training step: 31798, total_loss: 5.33050012588501
training step: 31799, total_loss: 2.191328525543213
training step: 31800, total_loss: 5.137203216552734
training step: 31801, total_loss: 3.5264883041381836
training step: 31802, total_loss: 4.354516983032227
training step: 31803, total_loss: 5.119424343109131
training step: 31804, total_loss: 2.8510689735412598
training step: 31805, total_loss: 6.414870262145996
training step: 31806, total_loss: 5.441836357116699
training step: 31807, total_loss: 3.9714860916137695
training step: 31808, total_loss: 5.5642571449279785
training step: 31809, total_loss: 3.8342747688293457
training step: 31810, total_loss: 4.8764238357543945
training step: 31811, total_loss: 3.8643298149108887
training step: 31812, total_loss: 4.900641441345215
training step: 31813, total_loss: 4.709435939788818
training step: 31814, total_loss: 6.609597206115723
training step: 31815, total_loss: 3.7892305850982666
training step: 31816, total_loss: 4.577414035797119
training step: 31817, total_loss: 4.50479793548584
training step: 31818, total_loss: 4.114436626434326
training step: 31819, total_loss: 5.115087032318115
training step: 31820, total_loss: 5.226828098297119
training step: 31821, total_loss: 2.4539804458618164
training step: 31822, total_loss: 5.135445594787598
training step: 31823, total_loss: 4.7802205085754395
training step: 31824, total_loss: 3.9774069786071777
training step: 31825, total_loss: 4.552011489868164
training step: 31826, total_loss: 4.541197776794434
training step: 31827, total_loss: 4.738818645477295
training step: 31828, total_loss: 4.958958148956299
training step: 31829, total_loss: 3.5727829933166504
training step: 31830, total_loss: 5.024388313293457
training step: 31831, total_loss: 4.255058288574219
training step: 31832, total_loss: 4.561468124389648
training step: 31833, total_loss: 5.024700164794922
training step: 31834, total_loss: 6.014886856079102
training step: 31835, total_loss: 4.15576171875
training step: 31836, total_loss: 2.8447952270507812
training step: 31837, total_loss: 3.848963499069214
training step: 31838, total_loss: 4.916001319885254
training step: 31839, total_loss: 3.8160321712493896
training step: 31840, total_loss: 3.2890994548797607
training step: 31841, total_loss: 3.5476672649383545
training step: 31842, total_loss: 3.2249836921691895
training step: 31843, total_loss: 4.714120864868164
training step: 31844, total_loss: 3.5974912643432617
training step: 31845, total_loss: 4.764845848083496
training step: 31846, total_loss: 3.8897058963775635
training step: 31847, total_loss: 5.126090049743652
training step: 31848, total_loss: 4.895951747894287
training step: 31849, total_loss: 4.459335803985596
training step: 31850, total_loss: 4.535446643829346
training step: 31851, total_loss: 4.1967363357543945
training step: 31852, total_loss: 4.651723384857178
training step: 31853, total_loss: 5.409945487976074
training step: 31854, total_loss: 5.24625825881958
training step: 31855, total_loss: 4.61848783493042
training step: 31856, total_loss: 3.1494102478027344
training step: 31857, total_loss: 3.833871841430664
training step: 31858, total_loss: 3.529005765914917
training step: 31859, total_loss: 6.1161417961120605
training step: 31860, total_loss: 4.780147552490234
training step: 31861, total_loss: 4.979368209838867
training step: 31862, total_loss: 3.5141797065734863
training step: 31863, total_loss: 5.45073938369751
training step: 31864, total_loss: 1.5249550342559814
training step: 31865, total_loss: 6.229718208312988
training step: 31866, total_loss: 3.8889384269714355
training step: 31867, total_loss: 5.500237464904785
training step: 31868, total_loss: 4.5568952560424805
training step: 31869, total_loss: 3.757640838623047
training step: 31870, total_loss: 3.8055901527404785
training step: 31871, total_loss: 4.430347442626953
training step: 31872, total_loss: 5.133639335632324
training step: 31873, total_loss: 5.912732124328613
training step: 31874, total_loss: 4.506938934326172
training step: 31875, total_loss: 4.510476112365723
training step: 31876, total_loss: 5.373195648193359
training step: 31877, total_loss: 5.058859825134277
training step: 31878, total_loss: 4.582680702209473
training step: 31879, total_loss: 3.7370285987854004
training step: 31880, total_loss: 3.6524219512939453
training step: 31881, total_loss: 4.155670166015625
training step: 31882, total_loss: 5.218169689178467
training step: 31883, total_loss: 5.311111927032471
training step: 31884, total_loss: 4.632758140563965
training step: 31885, total_loss: 3.2538650035858154
training step: 31886, total_loss: 4.919981002807617
training step: 31887, total_loss: 4.907547473907471
training step: 31888, total_loss: 4.056488513946533
training step: 31889, total_loss: 5.446062088012695
training step: 31890, total_loss: 5.640399932861328
training step: 31891, total_loss: 4.359073162078857
training step: 31892, total_loss: 5.339346408843994
training step: 31893, total_loss: 4.358532905578613
training step: 31894, total_loss: 6.572061538696289
training step: 31895, total_loss: 4.504220962524414
training step: 31896, total_loss: 5.69170618057251
training step: 31897, total_loss: 4.166532516479492
training step: 31898, total_loss: 4.553199291229248
training step: 31899, total_loss: 4.342222213745117
training step: 31900, total_loss: 4.956312656402588
training step: 31901, total_loss: 3.6472489833831787
training step: 31902, total_loss: 5.342222690582275
training step: 31903, total_loss: 4.584847450256348
training step: 31904, total_loss: 2.513350486755371
training step: 31905, total_loss: 5.522030353546143
training step: 31906, total_loss: 5.6405415534973145
training step: 31907, total_loss: 4.3929643630981445
training step: 31908, total_loss: 4.907772541046143
training step: 31909, total_loss: 5.278990745544434
training step: 31910, total_loss: 5.00535774230957
training step: 31911, total_loss: 2.9277920722961426
training step: 31912, total_loss: 4.502565383911133
training step: 31913, total_loss: 4.486557960510254
training step: 31914, total_loss: 4.821062088012695
training step: 31915, total_loss: 5.358787536621094
training step: 31916, total_loss: 4.696759223937988
training step: 31917, total_loss: 4.913984298706055
training step: 31918, total_loss: 3.673133373260498
training step: 31919, total_loss: 4.402341842651367
training step: 31920, total_loss: 4.365715503692627
training step: 31921, total_loss: 3.4204163551330566
training step: 31922, total_loss: 3.5167465209960938
training step: 31923, total_loss: 4.479097366333008
training step: 31924, total_loss: 2.37882924079895
training step: 31925, total_loss: 2.480797290802002
training step: 31926, total_loss: 4.101656913757324
training step: 31927, total_loss: 3.825843095779419
training step: 31928, total_loss: 3.0891647338867188
training step: 31929, total_loss: 4.831487655639648
training step: 31930, total_loss: 3.8827567100524902
training step: 31931, total_loss: 4.862509250640869
training step: 31932, total_loss: 5.4359846115112305
training step: 31933, total_loss: 4.707975387573242
training step: 31934, total_loss: 3.9799392223358154
training step: 31935, total_loss: 4.090387344360352
training step: 31936, total_loss: 4.979917049407959
training step: 31937, total_loss: 3.5873050689697266
training step: 31938, total_loss: 5.4925312995910645
training step: 31939, total_loss: 3.058960199356079
training step: 31940, total_loss: 5.321160793304443
training step: 31941, total_loss: 3.808058023452759
training step: 31942, total_loss: 5.544677257537842
training step: 31943, total_loss: 5.343479633331299
training step: 31944, total_loss: 3.782482624053955
training step: 31945, total_loss: 5.532370567321777
training step: 31946, total_loss: 5.205523490905762
training step: 31947, total_loss: 2.4298994541168213
training step: 31948, total_loss: 5.418255805969238
training step: 31949, total_loss: 4.410223007202148
training step: 31950, total_loss: 5.011112213134766
training step: 31951, total_loss: 7.041225910186768
training step: 31952, total_loss: 4.57806921005249
training step: 31953, total_loss: 3.9735307693481445
training step: 31954, total_loss: 5.16391658782959
training step: 31955, total_loss: 5.23998498916626
training step: 31956, total_loss: 3.7024717330932617
training step: 31957, total_loss: 4.7564239501953125
training step: 31958, total_loss: 4.864652633666992
training step: 31959, total_loss: 5.478597164154053
training step: 31960, total_loss: 5.072388648986816
training step: 31961, total_loss: 3.697827100753784
training step: 31962, total_loss: 3.726353883743286
training step: 31963, total_loss: 3.757981300354004
training step: 31964, total_loss: 4.592326641082764
training step: 31965, total_loss: 4.178552627563477
training step: 31966, total_loss: 4.718702793121338
training step: 31967, total_loss: 3.6457695960998535
training step: 31968, total_loss: 3.5788755416870117
training step: 31969, total_loss: 1.2579550743103027
training step: 31970, total_loss: 4.668000221252441
training step: 31971, total_loss: 4.388160705566406
training step: 31972, total_loss: 4.276440620422363
training step: 31973, total_loss: 3.9657793045043945
training step: 31974, total_loss: 3.6956465244293213
training step: 31975, total_loss: 4.330081939697266
training step: 31976, total_loss: 4.33207368850708
training step: 31977, total_loss: 5.082157611846924
training step: 31978, total_loss: 4.139179706573486
training step: 31979, total_loss: 3.209965705871582
training step: 31980, total_loss: 4.404941558837891
training step: 31981, total_loss: 3.88118314743042
training step: 31982, total_loss: 3.18660306930542
training step: 31983, total_loss: 4.332000732421875
training step: 31984, total_loss: 3.42598819732666
training step: 31985, total_loss: 4.700834274291992
training step: 31986, total_loss: 5.897736549377441
training step: 31987, total_loss: 4.336247444152832
training step: 31988, total_loss: 4.4369659423828125
training step: 31989, total_loss: 2.6021223068237305
training step: 31990, total_loss: 3.3722262382507324
training step: 31991, total_loss: 4.406935691833496
training step: 31992, total_loss: 4.781553745269775
training step: 31993, total_loss: 4.112404823303223
training step: 31994, total_loss: 5.632165431976318
training step: 31995, total_loss: 5.456108093261719
training step: 31996, total_loss: 3.6220414638519287
training step: 31997, total_loss: 4.684688568115234
training step: 31998, total_loss: 4.432328701019287
training step: 31999, total_loss: 5.336452960968018
training step: 32000, total_loss: 3.8941597938537598
training step: 32001, total_loss: 3.434009075164795
training step: 32002, total_loss: 3.841259717941284
training step: 32003, total_loss: 4.850363731384277
training step: 32004, total_loss: 4.346597671508789
training step: 32005, total_loss: 4.150820255279541
training step: 32006, total_loss: 3.624926805496216
training step: 32007, total_loss: 5.067608833312988
training step: 32008, total_loss: 4.431260108947754
training step: 32009, total_loss: 3.6714420318603516
training step: 32010, total_loss: 4.275582313537598
training step: 32011, total_loss: 3.739656925201416
training step: 32012, total_loss: 4.7057366371154785
training step: 32013, total_loss: 4.326657295227051
training step: 32014, total_loss: 4.428898811340332
training step: 32015, total_loss: 5.179242134094238
training step: 32016, total_loss: 4.440120697021484
training step: 32017, total_loss: 5.149487495422363
training step: 32018, total_loss: 4.929590702056885
training step: 32019, total_loss: 1.2890079021453857
training step: 32020, total_loss: 5.588929653167725
training step: 32021, total_loss: 4.947325706481934
training step: 32022, total_loss: 5.387462139129639
training step: 32023, total_loss: 4.5103888511657715
training step: 32024, total_loss: 6.730162620544434
training step: 32025, total_loss: 3.90224027633667
training step: 32026, total_loss: 3.2599411010742188
training step: 32027, total_loss: 2.6067733764648438
training step: 32028, total_loss: 3.781558036804199
training step: 32029, total_loss: 4.281759738922119
training step: 32030, total_loss: 7.230955123901367
training step: 32031, total_loss: 4.689794063568115
training step: 32032, total_loss: 5.398491859436035
training step: 32033, total_loss: 4.325030326843262
training step: 32034, total_loss: 4.296566963195801
training step: 32035, total_loss: 4.581051826477051
training step: 32036, total_loss: 4.979100227355957
training step: 32037, total_loss: 5.367153167724609
training step: 32038, total_loss: 4.83870792388916
training step: 32039, total_loss: 6.019137382507324
training step: 32040, total_loss: 5.524973392486572
training step: 32041, total_loss: 4.1841254234313965
training step: 32042, total_loss: 3.034912109375
training step: 32043, total_loss: 3.941932201385498
training step: 32044, total_loss: 3.3846802711486816
training step: 32045, total_loss: 4.906152725219727
training step: 32046, total_loss: 3.5815958976745605
training step: 32047, total_loss: 2.9187369346618652
training step: 32048, total_loss: 5.055188179016113
training step: 32049, total_loss: 2.9333877563476562
training step: 32050, total_loss: 4.777626991271973
training step: 32051, total_loss: 4.8846588134765625
training step: 32052, total_loss: 1.2309234142303467
training step: 32053, total_loss: 5.06062650680542
training step: 32054, total_loss: 4.848984718322754
training step: 32055, total_loss: 3.8096728324890137
training step: 32056, total_loss: 6.55543327331543
training step: 32057, total_loss: 1.4996967315673828
training step: 32058, total_loss: 4.489984512329102
training step: 32059, total_loss: 4.154067039489746
training step: 32060, total_loss: 4.836825370788574
training step: 32061, total_loss: 4.977483749389648
training step: 32062, total_loss: 4.537593841552734
training step: 32063, total_loss: 3.8738484382629395
training step: 32064, total_loss: 4.703435897827148
training step: 32065, total_loss: 3.8569092750549316
training step: 32066, total_loss: 5.56374979019165
training step: 32067, total_loss: 5.2855329513549805
training step: 32068, total_loss: 5.382627964019775
training step: 32069, total_loss: 4.944733619689941
training step: 32070, total_loss: 4.4143853187561035
training step: 32071, total_loss: 4.164848804473877
training step: 32072, total_loss: 5.086093902587891
training step: 32073, total_loss: 3.93522310256958
training step: 32074, total_loss: 6.708804130554199
training step: 32075, total_loss: 4.50999641418457
training step: 32076, total_loss: 4.2010955810546875
training step: 32077, total_loss: 4.199448108673096
training step: 32078, total_loss: 5.183267116546631
training step: 32079, total_loss: 4.894742965698242
training step: 32080, total_loss: 2.323789596557617
training step: 32081, total_loss: 4.654825210571289
training step: 32082, total_loss: 4.148614883422852
training step: 32083, total_loss: 4.059391975402832
training step: 32084, total_loss: 5.226971626281738
training step: 32085, total_loss: 3.3105831146240234
training step: 32086, total_loss: 2.00223970413208
training step: 32087, total_loss: 4.910316467285156
training step: 32088, total_loss: 4.323066234588623
training step: 32089, total_loss: 4.04249382019043
training step: 32090, total_loss: 3.184854030609131
training step: 32091, total_loss: 3.747554302215576
training step: 32092, total_loss: 5.651226997375488
training step: 32093, total_loss: 4.029365062713623
training step: 32094, total_loss: 2.7794272899627686
training step: 32095, total_loss: 4.418630599975586
training step: 32096, total_loss: 3.6450352668762207
training step: 32097, total_loss: 5.230362892150879
training step: 32098, total_loss: 4.41659688949585
training step: 32099, total_loss: 3.451159715652466
training step: 32100, total_loss: 4.151309967041016
training step: 32101, total_loss: 5.1384358406066895
training step: 32102, total_loss: 4.535572528839111
training step: 32103, total_loss: 3.719907522201538
training step: 32104, total_loss: 5.053638935089111
training step: 32105, total_loss: 3.773155689239502
training step: 32106, total_loss: 4.7374982833862305
training step: 32107, total_loss: 3.6868896484375
training step: 32108, total_loss: 3.6424360275268555
training step: 32109, total_loss: 4.5701165199279785
training step: 32110, total_loss: 5.091225624084473
training step: 32111, total_loss: 4.799421310424805
training step: 32112, total_loss: 4.75432014465332
training step: 32113, total_loss: 5.4103102684021
training step: 32114, total_loss: 4.682890892028809
training step: 32115, total_loss: 3.7771620750427246
training step: 32116, total_loss: 4.635658264160156
training step: 32117, total_loss: 3.6111299991607666
training step: 32118, total_loss: 4.995309352874756
training step: 32119, total_loss: 4.537234306335449
training step: 32120, total_loss: 3.887176990509033
training step: 32121, total_loss: 5.695618629455566
training step: 32122, total_loss: 4.272902011871338
training step: 32123, total_loss: 3.69814133644104
training step: 32124, total_loss: 4.974246978759766
training step: 32125, total_loss: 4.548993110656738
training step: 32126, total_loss: 4.688741683959961
training step: 32127, total_loss: 3.0980358123779297
training step: 32128, total_loss: 4.584737777709961
training step: 32129, total_loss: 4.066973686218262
training step: 32130, total_loss: 3.221074104309082
training step: 32131, total_loss: 4.935701370239258
training step: 32132, total_loss: 5.719127655029297
training step: 32133, total_loss: 4.3853912353515625
training step: 32134, total_loss: 5.5007219314575195
training step: 32135, total_loss: 2.7976579666137695
training step: 32136, total_loss: 3.8928048610687256
training step: 32137, total_loss: 4.485902786254883
training step: 32138, total_loss: 2.705862522125244
training step: 32139, total_loss: 4.736733436584473
training step: 32140, total_loss: 1.0749859809875488
training step: 32141, total_loss: 4.706668376922607
training step: 32142, total_loss: 1.4306217432022095
training step: 32143, total_loss: 4.258265495300293
training step: 32144, total_loss: 4.78171968460083
training step: 32145, total_loss: 2.9270360469818115
training step: 32146, total_loss: 3.772636651992798
training step: 32147, total_loss: 4.649801254272461
training step: 32148, total_loss: 4.063873767852783
training step: 32149, total_loss: 1.210132360458374
training step: 32150, total_loss: 4.840368270874023
training step: 32151, total_loss: 4.476338863372803
training step: 32152, total_loss: 4.500620365142822
training step: 32153, total_loss: 5.175782203674316
training step: 32154, total_loss: 5.414758682250977
training step: 32155, total_loss: 5.554333686828613
training step: 32156, total_loss: 6.9586334228515625
training step: 32157, total_loss: 4.962086200714111
training step: 32158, total_loss: 5.415746688842773
training step: 32159, total_loss: 3.570187568664551
training step: 32160, total_loss: 5.04239559173584
training step: 32161, total_loss: 4.391321182250977
training step: 32162, total_loss: 4.402661323547363
training step: 32163, total_loss: 4.1935577392578125
training step: 32164, total_loss: 0.8242596387863159
training step: 32165, total_loss: 3.903886318206787
training step: 32166, total_loss: 5.016084671020508
training step: 32167, total_loss: 2.3507442474365234
training step: 32168, total_loss: 3.2918691635131836
training step: 32169, total_loss: 4.415997505187988
training step: 32170, total_loss: 4.863516330718994
training step: 32171, total_loss: 4.59636926651001
training step: 32172, total_loss: 5.752721309661865
training step: 32173, total_loss: 4.541707992553711
training step: 32174, total_loss: 5.667430877685547
training step: 32175, total_loss: 4.166020393371582
training step: 32176, total_loss: 4.325429439544678
training step: 32177, total_loss: 6.081523895263672
training step: 32178, total_loss: 4.524077415466309
training step: 32179, total_loss: 5.183523178100586
training step: 32180, total_loss: 4.289165019989014
training step: 32181, total_loss: 5.053496360778809
training step: 32182, total_loss: 0.721467137336731
training step: 32183, total_loss: 4.261919975280762
training step: 32184, total_loss: 3.062689781188965
training step: 32185, total_loss: 4.477393627166748
training step: 32186, total_loss: 3.10825252532959
training step: 32187, total_loss: 5.875532150268555
training step: 32188, total_loss: 4.980003833770752
training step: 32189, total_loss: 4.128120422363281
training step: 32190, total_loss: 5.30414342880249
training step: 32191, total_loss: 2.361764669418335
training step: 32192, total_loss: 5.57336950302124
training step: 32193, total_loss: 4.939334869384766
training step: 32194, total_loss: 4.810072898864746
training step: 32195, total_loss: 4.376348495483398
training step: 32196, total_loss: 5.513432025909424
training step: 32197, total_loss: 4.312440395355225
training step: 32198, total_loss: 5.335474967956543
training step: 32199, total_loss: 4.68411922454834
training step: 32200, total_loss: 4.710763454437256
training step: 32201, total_loss: 4.72656774520874
training step: 32202, total_loss: 6.29766845703125
training step: 32203, total_loss: 3.1964027881622314
training step: 32204, total_loss: 2.9313604831695557
training step: 32205, total_loss: 2.97806715965271
training step: 32206, total_loss: 5.9169416427612305
training step: 32207, total_loss: 4.48183536529541
training step: 32208, total_loss: 4.384950637817383
training step: 32209, total_loss: 4.44282341003418
training step: 32210, total_loss: 3.775238037109375
training step: 32211, total_loss: 4.131535530090332
training step: 32212, total_loss: 4.1237287521362305
training step: 32213, total_loss: 4.2176690101623535
training step: 32214, total_loss: 4.3546905517578125
training step: 32215, total_loss: 4.643162250518799
training step: 32216, total_loss: 4.316764831542969
training step: 32217, total_loss: 3.9019861221313477
training step: 32218, total_loss: 5.269895076751709
training step: 32219, total_loss: 5.0826826095581055
training step: 32220, total_loss: 4.26959753036499
training step: 32221, total_loss: 5.648877143859863
training step: 32222, total_loss: 3.872119426727295
training step: 32223, total_loss: 4.7310075759887695
training step: 32224, total_loss: 4.67079496383667
training step: 32225, total_loss: 4.757293701171875
training step: 32226, total_loss: 5.336163520812988
training step: 32227, total_loss: 4.688831329345703
training step: 32228, total_loss: 4.776914119720459
training step: 32229, total_loss: 4.046443939208984
training step: 32230, total_loss: 5.266714096069336
training step: 32231, total_loss: 6.907451629638672
training step: 32232, total_loss: 4.193065643310547
training step: 32233, total_loss: 4.122377395629883
training step: 32234, total_loss: 4.625982284545898
training step: 32235, total_loss: 4.802182674407959
training step: 32236, total_loss: 5.194271087646484
training step: 32237, total_loss: 5.112075328826904
training step: 32238, total_loss: 4.817654609680176
training step: 32239, total_loss: 5.02846097946167
training step: 32240, total_loss: 1.6852085590362549
training step: 32241, total_loss: 4.7819719314575195
training step: 32242, total_loss: 5.591879844665527
training step: 32243, total_loss: 4.051841735839844
training step: 32244, total_loss: 6.08724308013916
training step: 32245, total_loss: 5.6867780685424805
training step: 32246, total_loss: 5.020956993103027
training step: 32247, total_loss: 5.08696174621582
training step: 32248, total_loss: 4.492115497589111
training step: 32249, total_loss: 4.663239002227783
training step: 32250, total_loss: 2.2789692878723145
training step: 32251, total_loss: 5.616615295410156
training step: 32252, total_loss: 4.696524620056152
training step: 32253, total_loss: 4.501612663269043
training step: 32254, total_loss: 4.877272605895996
training step: 32255, total_loss: 3.287051200866699
training step: 32256, total_loss: 4.754711627960205
training step: 32257, total_loss: 4.418333053588867
training step: 32258, total_loss: 7.335078239440918
training step: 32259, total_loss: 3.4386229515075684
training step: 32260, total_loss: 4.363238334655762
training step: 32261, total_loss: 4.950371742248535
training step: 32262, total_loss: 4.629103660583496
training step: 32263, total_loss: 4.277237415313721
training step: 32264, total_loss: 5.366022109985352
training step: 32265, total_loss: 4.883998394012451
training step: 32266, total_loss: 4.570148468017578
training step: 32267, total_loss: 4.257510185241699
training step: 32268, total_loss: 4.210131645202637
training step: 32269, total_loss: 4.950916290283203
training step: 32270, total_loss: 4.512097358703613
training step: 32271, total_loss: 4.64135217666626
training step: 32272, total_loss: 4.706532001495361
training step: 32273, total_loss: 3.6300740242004395
training step: 32274, total_loss: 4.810375213623047
training step: 32275, total_loss: 5.047070026397705
training step: 32276, total_loss: 5.987771987915039
training step: 32277, total_loss: 3.792370319366455
training step: 32278, total_loss: 3.954988956451416
training step: 32279, total_loss: 4.306797504425049
training step: 32280, total_loss: 6.065657615661621
training step: 32281, total_loss: 5.593653678894043
training step: 32282, total_loss: 3.989750623703003
training step: 32283, total_loss: 4.255385398864746
training step: 32284, total_loss: 4.815688133239746
training step: 32285, total_loss: 3.118032932281494
training step: 32286, total_loss: 4.0671067237854
training step: 32287, total_loss: 3.997980833053589
training step: 32288, total_loss: 4.604010581970215
training step: 32289, total_loss: 3.4956655502319336
training step: 32290, total_loss: 5.783145904541016
training step: 32291, total_loss: 4.920148849487305
training step: 32292, total_loss: 4.520017623901367
training step: 32293, total_loss: 3.9333274364471436
training step: 32294, total_loss: 3.4091432094573975
training step: 32295, total_loss: 6.571376800537109
training step: 32296, total_loss: 4.099333763122559
training step: 32297, total_loss: 4.663330554962158
training step: 32298, total_loss: 4.907453536987305
training step: 32299, total_loss: 6.094200611114502
training step: 32300, total_loss: 4.5049638748168945
training step: 32301, total_loss: 6.6690263748168945
training step: 32302, total_loss: 5.257596969604492
training step: 32303, total_loss: 4.574766159057617
training step: 32304, total_loss: 4.426318645477295
training step: 32305, total_loss: 4.929808616638184
training step: 32306, total_loss: 4.407591819763184
training step: 32307, total_loss: 4.1308698654174805
training step: 32308, total_loss: 4.906423091888428
training step: 32309, total_loss: 4.179435729980469
training step: 32310, total_loss: 4.753610610961914
training step: 32311, total_loss: 5.13533878326416
training step: 32312, total_loss: 4.257777690887451
training step: 32313, total_loss: 6.648749351501465
training step: 32314, total_loss: 1.3579437732696533
training step: 32315, total_loss: 5.053229808807373
training step: 32316, total_loss: 6.409396171569824
training step: 32317, total_loss: 3.9998350143432617
training step: 32318, total_loss: 3.291651487350464
training step: 32319, total_loss: 3.8349952697753906
training step: 32320, total_loss: 4.8534064292907715
training step: 32321, total_loss: 4.933680057525635
training step: 32322, total_loss: 2.5967917442321777
training step: 32323, total_loss: 4.9743571281433105
training step: 32324, total_loss: 5.173551559448242
training step: 32325, total_loss: 3.402797222137451
training step: 32326, total_loss: 4.701984405517578
training step: 32327, total_loss: 5.017638683319092
training step: 32328, total_loss: 4.537174224853516
training step: 32329, total_loss: 4.094161510467529
training step: 32330, total_loss: 4.255568981170654
training step: 32331, total_loss: 3.3364384174346924
training step: 32332, total_loss: 4.601868152618408
training step: 32333, total_loss: 5.357241153717041
training step: 32334, total_loss: 3.267326831817627
training step: 32335, total_loss: 2.9654533863067627
training step: 32336, total_loss: 5.2104949951171875
training step: 32337, total_loss: 4.9173383712768555
training step: 32338, total_loss: 4.012892246246338
training step: 32339, total_loss: 4.8520307540893555
training step: 32340, total_loss: 4.458525657653809
training step: 32341, total_loss: 5.107705116271973
training step: 32342, total_loss: 4.344046115875244
training step: 32343, total_loss: 4.697049617767334
training step: 32344, total_loss: 4.059370517730713
training step: 32345, total_loss: 5.349808692932129
training step: 32346, total_loss: 3.005882740020752
training step: 32347, total_loss: 3.395798683166504
training step: 32348, total_loss: 4.773423194885254
training step: 32349, total_loss: 5.86570930480957
training step: 32350, total_loss: 3.6908812522888184
training step: 32351, total_loss: 5.254949569702148
training step: 32352, total_loss: 6.508984565734863
training step: 32353, total_loss: 6.288038730621338
training step: 32354, total_loss: 1.2815892696380615
training step: 32355, total_loss: 4.857106685638428
training step: 32356, total_loss: 2.44480562210083
training step: 32357, total_loss: 4.506857872009277
training step: 32358, total_loss: 4.1784586906433105
training step: 32359, total_loss: 6.221524238586426
training step: 32360, total_loss: 4.805902481079102
training step: 32361, total_loss: 4.545512676239014
training step: 32362, total_loss: 4.344945907592773
training step: 32363, total_loss: 4.344189167022705
training step: 32364, total_loss: 4.5033464431762695
training step: 32365, total_loss: 3.206282138824463
training step: 32366, total_loss: 4.051840782165527
training step: 32367, total_loss: 4.052918910980225
training step: 32368, total_loss: 5.822205543518066
training step: 32369, total_loss: 4.703995704650879
training step: 32370, total_loss: 4.316303253173828
training step: 32371, total_loss: 3.409173011779785
training step: 32372, total_loss: 4.9435505867004395
training step: 32373, total_loss: 4.417257308959961
training step: 32374, total_loss: 3.9521281719207764
training step: 32375, total_loss: 5.430586814880371
training step: 32376, total_loss: 5.851893424987793
training step: 32377, total_loss: 4.2545857429504395
training step: 32378, total_loss: 5.582452297210693
training step: 32379, total_loss: 6.050469398498535
training step: 32380, total_loss: 3.964552402496338
training step: 32381, total_loss: 4.23345947265625
training step: 32382, total_loss: 4.021452903747559
training step: 32383, total_loss: 4.780046463012695
training step: 32384, total_loss: 4.81364631652832
training step: 32385, total_loss: 3.7008321285247803
training step: 32386, total_loss: 3.8231096267700195
training step: 32387, total_loss: 2.2221922874450684
training step: 32388, total_loss: 4.70851993560791
training step: 32389, total_loss: 5.556056976318359
training step: 32390, total_loss: 5.103915214538574
training step: 32391, total_loss: 4.714288234710693
training step: 32392, total_loss: 4.03761100769043
training step: 32393, total_loss: 3.7507879734039307
training step: 32394, total_loss: 2.904677391052246
training step: 32395, total_loss: 3.35516357421875
training step: 32396, total_loss: 5.3608174324035645
training step: 32397, total_loss: 5.042695045471191
training step: 32398, total_loss: 5.653097629547119
training step: 32399, total_loss: 4.336162090301514
training step: 32400, total_loss: 5.629848480224609
training step: 32401, total_loss: 6.02508020401001
training step: 32402, total_loss: 3.9383931159973145
training step: 32403, total_loss: 5.28402042388916
training step: 32404, total_loss: 4.244184970855713
training step: 32405, total_loss: 5.080507278442383
training step: 32406, total_loss: 5.002885341644287
training step: 32407, total_loss: 3.9295620918273926
training step: 32408, total_loss: 4.583708763122559
training step: 32409, total_loss: 4.097840309143066
training step: 32410, total_loss: 5.4928107261657715
training step: 32411, total_loss: 4.043630123138428
training step: 32412, total_loss: 4.5955657958984375
training step: 32413, total_loss: 4.7580156326293945
training step: 32414, total_loss: 4.525677680969238
training step: 32415, total_loss: 4.018245697021484
training step: 32416, total_loss: 3.320608139038086
training step: 32417, total_loss: 4.011449337005615
training step: 32418, total_loss: 5.083490371704102
training step: 32419, total_loss: 4.506697177886963
training step: 32420, total_loss: 4.497659683227539
training step: 32421, total_loss: 1.6806493997573853
training step: 32422, total_loss: 3.9060895442962646
training step: 32423, total_loss: 5.174466133117676
training step: 32424, total_loss: 3.5994529724121094
training step: 32425, total_loss: 4.224502086639404
training step: 32426, total_loss: 4.515900611877441
training step: 32427, total_loss: 4.289117813110352
training step: 32428, total_loss: 4.679355144500732
training step: 32429, total_loss: 3.934835910797119
training step: 32430, total_loss: 4.97440242767334
training step: 32431, total_loss: 4.621493339538574
training step: 32432, total_loss: 4.603363990783691
training step: 32433, total_loss: 4.768326759338379
training step: 32434, total_loss: 3.973281145095825
training step: 32435, total_loss: 3.8667752742767334
training step: 32436, total_loss: 4.772446632385254
training step: 32437, total_loss: 5.0860114097595215
training step: 32438, total_loss: 3.7858376502990723
training step: 32439, total_loss: 4.021478652954102
training step: 32440, total_loss: 1.7766880989074707
training step: 32441, total_loss: 5.503085613250732
training step: 32442, total_loss: 4.118133544921875
training step: 32443, total_loss: 1.3703306913375854
training step: 32444, total_loss: 4.10616397857666
training step: 32445, total_loss: 6.053597450256348
training step: 32446, total_loss: 3.8755271434783936
training step: 32447, total_loss: 4.098546028137207
training step: 32448, total_loss: 4.537546157836914
training step: 32449, total_loss: 3.142670154571533
training step: 32450, total_loss: 5.008864402770996
training step: 32451, total_loss: 5.485595703125
training step: 32452, total_loss: 4.818243026733398
training step: 32453, total_loss: 3.1560277938842773
training step: 32454, total_loss: 4.955156326293945
training step: 32455, total_loss: 5.563324451446533
training step: 32456, total_loss: 4.5349531173706055
training step: 32457, total_loss: 5.594163417816162
training step: 32458, total_loss: 5.2008161544799805
training step: 32459, total_loss: 4.091931343078613
training step: 32460, total_loss: 3.831831455230713
training step: 32461, total_loss: 3.202989101409912
training step: 32462, total_loss: 4.484291076660156
training step: 32463, total_loss: 4.379998207092285
training step: 32464, total_loss: 3.356948137283325
training step: 32465, total_loss: 4.699897289276123
training step: 32466, total_loss: 4.442322731018066
training step: 32467, total_loss: 4.933711051940918
training step: 32468, total_loss: 6.240067481994629
training step: 32469, total_loss: 5.018403053283691
training step: 32470, total_loss: 5.870115280151367
training step: 32471, total_loss: 4.513521671295166
training step: 32472, total_loss: 5.446681022644043
training step: 32473, total_loss: 3.0559022426605225
training step: 32474, total_loss: 3.5218546390533447
training step: 32475, total_loss: 4.05940055847168
training step: 32476, total_loss: 5.692359924316406
training step: 32477, total_loss: 2.193209171295166
training step: 32478, total_loss: 1.616104006767273
training step: 32479, total_loss: 5.139740943908691
training step: 32480, total_loss: 5.444795608520508
training step: 32481, total_loss: 4.822836875915527
training step: 32482, total_loss: 5.067831993103027
training step: 32483, total_loss: 3.489866256713867
training step: 32484, total_loss: 4.234221935272217
training step: 32485, total_loss: 3.784883975982666
training step: 32486, total_loss: 3.762854814529419
training step: 32487, total_loss: 4.004159927368164
training step: 32488, total_loss: 4.363927364349365
training step: 32489, total_loss: 4.784825325012207
training step: 32490, total_loss: 4.435553550720215
training step: 32491, total_loss: 2.4809911251068115
training step: 32492, total_loss: 5.295404434204102
training step: 32493, total_loss: 5.207707405090332
training step: 32494, total_loss: 3.8433022499084473
training step: 32495, total_loss: 4.0837202072143555
training step: 32496, total_loss: 5.062291145324707
training step: 32497, total_loss: 4.087913513183594
training step: 32498, total_loss: 4.771726608276367
training step: 32499, total_loss: 4.81072998046875
training step: 32500, total_loss: 3.073793411254883
training step: 32501, total_loss: 3.9758145809173584
training step: 32502, total_loss: 1.4781166315078735
training step: 32503, total_loss: 4.378408432006836
training step: 32504, total_loss: 4.231016635894775
training step: 32505, total_loss: 5.238282680511475
training step: 32506, total_loss: 2.6372427940368652
training step: 32507, total_loss: 2.475884437561035
training step: 32508, total_loss: 4.142730712890625
training step: 32509, total_loss: 2.9332046508789062
training step: 32510, total_loss: 4.446286201477051
training step: 32511, total_loss: 4.866994857788086
training step: 32512, total_loss: 4.589818000793457
training step: 32513, total_loss: 3.9120397567749023
training step: 32514, total_loss: 5.759477138519287
training step: 32515, total_loss: 3.947343111038208
training step: 32516, total_loss: 4.173739433288574
training step: 32517, total_loss: 4.795649528503418
training step: 32518, total_loss: 5.436629295349121
training step: 32519, total_loss: 4.169978618621826
training step: 32520, total_loss: 0.8297320008277893
training step: 32521, total_loss: 3.2042431831359863
training step: 32522, total_loss: 6.832714080810547
training step: 32523, total_loss: 2.932546854019165
training step: 32524, total_loss: 2.7979602813720703
training step: 32525, total_loss: 4.049881458282471
training step: 32526, total_loss: 3.1376397609710693
training step: 32527, total_loss: 5.662167549133301
training step: 32528, total_loss: 5.177240371704102
training step: 32529, total_loss: 4.291255950927734
training step: 32530, total_loss: 4.553012371063232
training step: 32531, total_loss: 4.431785583496094
training step: 32532, total_loss: 5.424398422241211
training step: 32533, total_loss: 4.361078262329102
training step: 32534, total_loss: 4.165745735168457
training step: 32535, total_loss: 3.912412643432617
training step: 32536, total_loss: 5.383080959320068
training step: 32537, total_loss: 3.417311906814575
training step: 32538, total_loss: 3.9866600036621094
training step: 32539, total_loss: 4.31273078918457
training step: 32540, total_loss: 4.274819374084473
training step: 32541, total_loss: 4.573237419128418
training step: 32542, total_loss: 3.296173572540283
training step: 32543, total_loss: 4.1531982421875
training step: 32544, total_loss: 2.937001943588257
training step: 32545, total_loss: 2.358304262161255
training step: 32546, total_loss: 4.301576137542725
training step: 32547, total_loss: 0.9781146049499512
training step: 32548, total_loss: 4.281412601470947
training step: 32549, total_loss: 3.704416513442993
training step: 32550, total_loss: 5.141634941101074
training step: 32551, total_loss: 4.888612747192383
training step: 32552, total_loss: 5.017152786254883
training step: 32553, total_loss: 3.1864688396453857
training step: 32554, total_loss: 4.982386589050293
training step: 32555, total_loss: 5.536208152770996
training step: 32556, total_loss: 6.6163434982299805
training step: 32557, total_loss: 0.9793970584869385
training step: 32558, total_loss: 3.8955917358398438
training step: 32559, total_loss: 4.187187671661377
training step: 32560, total_loss: 4.9875288009643555
training step: 32561, total_loss: 4.9341559410095215
training step: 32562, total_loss: 5.176197052001953
training step: 32563, total_loss: 4.466729640960693
training step: 32564, total_loss: 2.479931354522705
training step: 32565, total_loss: 2.5200321674346924
training step: 32566, total_loss: 5.12031364440918
training step: 32567, total_loss: 4.273670196533203
training step: 32568, total_loss: 5.914017677307129
training step: 32569, total_loss: 3.277104377746582
training step: 32570, total_loss: 4.7659912109375
training step: 32571, total_loss: 2.2730555534362793
training step: 32572, total_loss: 4.026673316955566
training step: 32573, total_loss: 3.791090488433838
training step: 32574, total_loss: 6.24696683883667
training step: 32575, total_loss: 4.523603439331055
training step: 32576, total_loss: 3.306636333465576
training step: 32577, total_loss: 5.1095170974731445
training step: 32578, total_loss: 5.115206718444824
training step: 32579, total_loss: 3.384288787841797
training step: 32580, total_loss: 5.066069602966309
training step: 32581, total_loss: 4.111288070678711
training step: 32582, total_loss: 3.7952828407287598
training step: 32583, total_loss: 4.871626853942871
training step: 32584, total_loss: 2.5742664337158203
training step: 32585, total_loss: 5.1586594581604
training step: 32586, total_loss: 4.1299147605896
training step: 32587, total_loss: 2.460061550140381
training step: 32588, total_loss: 6.690152645111084
training step: 32589, total_loss: 4.564833164215088
training step: 32590, total_loss: 3.9009177684783936
training step: 32591, total_loss: 0.9352887272834778
training step: 32592, total_loss: 3.269989013671875
training step: 32593, total_loss: 3.240886688232422
training step: 32594, total_loss: 2.642094135284424
training step: 32595, total_loss: 6.3528337478637695
training step: 32596, total_loss: 5.67310905456543
training step: 32597, total_loss: 4.0121355056762695
training step: 32598, total_loss: 4.302334308624268
training step: 32599, total_loss: 4.17979621887207
training step: 32600, total_loss: 3.7105650901794434
training step: 32601, total_loss: 4.865370750427246
training step: 32602, total_loss: 4.3562798500061035
training step: 32603, total_loss: 2.6100335121154785
training step: 32604, total_loss: 4.677117347717285
training step: 32605, total_loss: 2.816453456878662
training step: 32606, total_loss: 5.8842973709106445
training step: 32607, total_loss: 1.515865683555603
training step: 32608, total_loss: 4.9031219482421875
training step: 32609, total_loss: 3.5934276580810547
training step: 32610, total_loss: 2.50137996673584
training step: 32611, total_loss: 5.393983364105225
training step: 32612, total_loss: 2.974334239959717
training step: 32613, total_loss: 3.984265089035034
training step: 32614, total_loss: 2.0975887775421143
training step: 32615, total_loss: 3.2377138137817383
training step: 32616, total_loss: 5.611198902130127
training step: 32617, total_loss: 4.044482231140137
training step: 32618, total_loss: 4.754402160644531
training step: 32619, total_loss: 6.637902736663818
training step: 32620, total_loss: 4.3852691650390625
training step: 32621, total_loss: 8.484704971313477
training step: 32622, total_loss: 5.684227466583252
training step: 32623, total_loss: 2.984300136566162
training step: 32624, total_loss: 3.6791579723358154
training step: 32625, total_loss: 3.455502510070801
training step: 32626, total_loss: 4.580026626586914
training step: 32627, total_loss: 3.8939366340637207
training step: 32628, total_loss: 3.784238815307617
training step: 32629, total_loss: 4.260228157043457
training step: 32630, total_loss: 5.064745903015137
training step: 32631, total_loss: 4.84005069732666
training step: 32632, total_loss: 4.838089466094971
training step: 32633, total_loss: 4.314460754394531
training step: 32634, total_loss: 4.370431423187256
training step: 32635, total_loss: 1.9492255449295044
training step: 32636, total_loss: 5.082373142242432
training step: 32637, total_loss: 5.205979347229004
training step: 32638, total_loss: 5.473212718963623
training step: 32639, total_loss: 4.858760356903076
training step: 32640, total_loss: 4.128101348876953
training step: 32641, total_loss: 2.5277276039123535
training step: 32642, total_loss: 4.93077278137207
training step: 32643, total_loss: 4.569262504577637
training step: 32644, total_loss: 8.167881965637207
training step: 32645, total_loss: 4.767950534820557
training step: 32646, total_loss: 5.426669120788574
training step: 32647, total_loss: 4.930569171905518
training step: 32648, total_loss: 3.9384765625
training step: 32649, total_loss: 5.838353157043457
training step: 32650, total_loss: 6.330303192138672
training step: 32651, total_loss: 3.501495361328125
training step: 32652, total_loss: 3.0954065322875977
training step: 32653, total_loss: 6.0548505783081055
training step: 32654, total_loss: 4.906464576721191
training step: 32655, total_loss: 4.875065803527832
training step: 32656, total_loss: 5.13129186630249
training step: 32657, total_loss: 4.307949066162109
training step: 32658, total_loss: 4.926142692565918
training step: 32659, total_loss: 4.86467981338501
training step: 32660, total_loss: 6.292510032653809
training step: 32661, total_loss: 4.524351119995117
training step: 32662, total_loss: 3.194118022918701
training step: 32663, total_loss: 3.9226369857788086
training step: 32664, total_loss: 6.014383316040039
training step: 32665, total_loss: 4.458759784698486
training step: 32666, total_loss: 4.675049781799316
training step: 32667, total_loss: 3.3189268112182617
training step: 32668, total_loss: 5.070431232452393
training step: 32669, total_loss: 2.3402163982391357
training step: 32670, total_loss: 2.5613656044006348
training step: 32671, total_loss: 5.0749921798706055
training step: 32672, total_loss: 4.569711208343506
training step: 32673, total_loss: 3.1247615814208984
training step: 32674, total_loss: 4.026796340942383
training step: 32675, total_loss: 2.957845687866211
training step: 32676, total_loss: 4.276789665222168
training step: 32677, total_loss: 4.241633415222168
training step: 32678, total_loss: 1.0709947347640991
training step: 32679, total_loss: 1.1729564666748047
training step: 32680, total_loss: 4.6606292724609375
training step: 32681, total_loss: 4.881124973297119
training step: 32682, total_loss: 4.959809303283691
training step: 32683, total_loss: 3.841874122619629
training step: 32684, total_loss: 5.821057319641113
training step: 32685, total_loss: 4.653614044189453
training step: 32686, total_loss: 5.649272918701172
training step: 32687, total_loss: 4.577304363250732
training step: 32688, total_loss: 4.448647975921631
training step: 32689, total_loss: 4.32692813873291
training step: 32690, total_loss: 4.8556389808654785
training step: 32691, total_loss: 3.1329433917999268
training step: 32692, total_loss: 4.324054718017578
training step: 32693, total_loss: 4.230485439300537
training step: 32694, total_loss: 5.225101947784424
training step: 32695, total_loss: 4.639453887939453
training step: 32696, total_loss: 2.51836895942688
training step: 32697, total_loss: 5.637298583984375
training step: 32698, total_loss: 4.521401405334473
training step: 32699, total_loss: 4.2865400314331055
training step: 32700, total_loss: 5.628751754760742
training step: 32701, total_loss: 4.765679359436035
training step: 32702, total_loss: 5.016427040100098
training step: 32703, total_loss: 5.1645894050598145
training step: 32704, total_loss: 3.9555182456970215
training step: 32705, total_loss: 6.481249809265137
training step: 32706, total_loss: 4.798609733581543
training step: 32707, total_loss: 4.105411052703857
training step: 32708, total_loss: 3.40777850151062
training step: 32709, total_loss: 3.441056728363037
training step: 32710, total_loss: 7.001474380493164
training step: 32711, total_loss: 3.3720481395721436
training step: 32712, total_loss: 4.473499298095703
training step: 32713, total_loss: 3.6714553833007812
training step: 32714, total_loss: 2.7491350173950195
training step: 32715, total_loss: 4.075304985046387
training step: 32716, total_loss: 4.884757041931152
training step: 32717, total_loss: 4.085054397583008
training step: 32718, total_loss: 4.7572736740112305
training step: 32719, total_loss: 2.8617379665374756
training step: 32720, total_loss: 3.8471522331237793
training step: 32721, total_loss: 2.395061492919922
training step: 32722, total_loss: 4.99265718460083
training step: 32723, total_loss: 5.166688919067383
training step: 32724, total_loss: 6.532040596008301
training step: 32725, total_loss: 4.229138374328613
training step: 32726, total_loss: 3.146986961364746
training step: 32727, total_loss: 5.629556179046631
training step: 32728, total_loss: 2.693209648132324
training step: 32729, total_loss: 4.498167991638184
training step: 32730, total_loss: 5.285319805145264
training step: 32731, total_loss: 3.339837074279785
training step: 32732, total_loss: 3.786820411682129
training step: 32733, total_loss: 3.108412742614746
training step: 32734, total_loss: 4.111605644226074
training step: 32735, total_loss: 4.337625503540039
training step: 32736, total_loss: 3.8708724975585938
training step: 32737, total_loss: 3.9459891319274902
training step: 32738, total_loss: 4.167315483093262
training step: 32739, total_loss: 5.405157566070557
training step: 32740, total_loss: 2.2879605293273926
training step: 32741, total_loss: 3.0595622062683105
training step: 32742, total_loss: 4.161984443664551
training step: 32743, total_loss: 1.0886003971099854
training step: 32744, total_loss: 4.9652910232543945
training step: 32745, total_loss: 4.982154846191406
training step: 32746, total_loss: 4.894124984741211
training step: 32747, total_loss: 4.76470947265625
training step: 32748, total_loss: 4.195694923400879
training step: 32749, total_loss: 6.052114486694336
training step: 32750, total_loss: 3.0386061668395996
training step: 32751, total_loss: 1.8064641952514648
training step: 32752, total_loss: 3.972083568572998
training step: 32753, total_loss: 5.513229846954346
training step: 32754, total_loss: 4.4415788650512695
training step: 32755, total_loss: 2.4989123344421387
training step: 32756, total_loss: 3.3123114109039307
training step: 32757, total_loss: 4.701440334320068
training step: 32758, total_loss: 4.013670444488525
training step: 32759, total_loss: 3.7827632427215576
training step: 32760, total_loss: 3.7758851051330566
training step: 32761, total_loss: 6.248848915100098
training step: 32762, total_loss: 5.1157121658325195
training step: 32763, total_loss: 3.8202292919158936
training step: 32764, total_loss: 4.473095417022705
training step: 32765, total_loss: 5.97698974609375
training step: 32766, total_loss: 4.656021595001221
training step: 32767, total_loss: 4.002985954284668
training step: 32768, total_loss: 2.8954577445983887
training step: 32769, total_loss: 4.169427871704102
training step: 32770, total_loss: 5.983046531677246
training step: 32771, total_loss: 5.531655311584473
training step: 32772, total_loss: 5.541626930236816
training step: 32773, total_loss: 4.099713325500488
training step: 32774, total_loss: 3.2287869453430176
training step: 32775, total_loss: 3.6122915744781494
training step: 32776, total_loss: 3.7685611248016357
training step: 32777, total_loss: 2.8415732383728027
training step: 32778, total_loss: 3.897892951965332
training step: 32779, total_loss: 4.586694717407227
training step: 32780, total_loss: 6.07224178314209
training step: 32781, total_loss: 4.295883655548096
training step: 32782, total_loss: 5.905187129974365
training step: 32783, total_loss: 4.055192947387695
training step: 32784, total_loss: 4.311668872833252
training step: 32785, total_loss: 5.5464043617248535
training step: 32786, total_loss: 5.528783798217773
training step: 32787, total_loss: 4.159183502197266
training step: 32788, total_loss: 5.860628128051758
training step: 32789, total_loss: 5.1762237548828125
training step: 32790, total_loss: 5.638619422912598
training step: 32791, total_loss: 3.5510520935058594
training step: 32792, total_loss: 3.4869489669799805
training step: 32793, total_loss: 5.204653739929199
training step: 32794, total_loss: 4.33665657043457
training step: 32795, total_loss: 4.208410263061523
training step: 32796, total_loss: 5.582545280456543
training step: 32797, total_loss: 3.636155128479004
training step: 32798, total_loss: 3.5475077629089355
training step: 32799, total_loss: 3.685668468475342
training step: 32800, total_loss: 4.151899337768555
training step: 32801, total_loss: 3.9985342025756836
training step: 32802, total_loss: 2.790896415710449
training step: 32803, total_loss: 4.404349327087402
training step: 32804, total_loss: 2.9563417434692383
training step: 32805, total_loss: 2.8770971298217773
training step: 32806, total_loss: 4.454862594604492
training step: 32807, total_loss: 4.70269250869751
training step: 32808, total_loss: 1.7348953485488892
training step: 32809, total_loss: 2.9339070320129395
training step: 32810, total_loss: 5.120540142059326
training step: 32811, total_loss: 3.630880355834961
training step: 32812, total_loss: 4.099514007568359
training step: 32813, total_loss: 4.432778358459473
training step: 32814, total_loss: 4.539494514465332
training step: 32815, total_loss: 4.53758430480957
training step: 32816, total_loss: 4.9735918045043945
training step: 32817, total_loss: 5.50428581237793
training step: 32818, total_loss: 5.488030433654785
training step: 32819, total_loss: 4.714794635772705
training step: 32820, total_loss: 3.5242857933044434
training step: 32821, total_loss: 5.062087535858154
training step: 32822, total_loss: 4.580169677734375
training step: 32823, total_loss: 5.3275370597839355
training step: 32824, total_loss: 5.695929527282715
training step: 32825, total_loss: 4.3233137130737305
training step: 32826, total_loss: 4.6942243576049805
training step: 32827, total_loss: 6.762515544891357
training step: 32828, total_loss: 4.496495723724365
training step: 32829, total_loss: 3.902629852294922
training step: 32830, total_loss: 5.544312000274658
training step: 32831, total_loss: 4.099443435668945
training step: 32832, total_loss: 3.8946828842163086
training step: 32833, total_loss: 2.7997570037841797
training step: 32834, total_loss: 4.5787811279296875
training step: 32835, total_loss: 4.801319122314453
training step: 32836, total_loss: 1.3623144626617432
training step: 32837, total_loss: 4.053733825683594
training step: 32838, total_loss: 5.509690284729004
training step: 32839, total_loss: 4.881010055541992
training step: 32840, total_loss: 5.065220355987549
training step: 32841, total_loss: 4.695157051086426
training step: 32842, total_loss: 2.7126669883728027
training step: 32843, total_loss: 3.8472657203674316
training step: 32844, total_loss: 3.4572110176086426
training step: 32845, total_loss: 3.8418684005737305
training step: 32846, total_loss: 4.680238723754883
training step: 32847, total_loss: 5.193058967590332
training step: 32848, total_loss: 5.111858367919922
training step: 32849, total_loss: 3.856903076171875
training step: 32850, total_loss: 3.5455727577209473
training step: 32851, total_loss: 3.7411608695983887
training step: 32852, total_loss: 5.399140357971191
training step: 32853, total_loss: 5.328183174133301
training step: 32854, total_loss: 3.564534902572632
training step: 32855, total_loss: 4.87276029586792
training step: 32856, total_loss: 5.075135231018066
training step: 32857, total_loss: 3.761723041534424
training step: 32858, total_loss: 4.009818077087402
training step: 32859, total_loss: 6.5902605056762695
training step: 32860, total_loss: 4.7678914070129395
training step: 32861, total_loss: 2.84962797164917
training step: 32862, total_loss: 5.328484535217285
training step: 32863, total_loss: 4.9359612464904785
training step: 32864, total_loss: 5.114367485046387
training step: 32865, total_loss: 4.120522499084473
training step: 32866, total_loss: 5.519484519958496
training step: 32867, total_loss: 4.196528911590576
training step: 32868, total_loss: 4.56376314163208
training step: 32869, total_loss: 5.660897254943848
training step: 32870, total_loss: 5.209057807922363
training step: 32871, total_loss: 4.969607830047607
training step: 32872, total_loss: 3.734644889831543
training step: 32873, total_loss: 5.020014762878418
training step: 32874, total_loss: 3.730250358581543
training step: 32875, total_loss: 5.421910285949707
training step: 32876, total_loss: 4.625134468078613
training step: 32877, total_loss: 3.597804069519043
training step: 32878, total_loss: 2.761906623840332
training step: 32879, total_loss: 5.241253852844238
training step: 32880, total_loss: 5.78053617477417
training step: 32881, total_loss: 4.983848571777344
training step: 32882, total_loss: 4.7117509841918945
training step: 32883, total_loss: 5.019775867462158
training step: 32884, total_loss: 5.342877388000488
training step: 32885, total_loss: 5.738137245178223
training step: 32886, total_loss: 5.055410385131836
training step: 32887, total_loss: 3.210078716278076
training step: 32888, total_loss: 3.9208765029907227
training step: 32889, total_loss: 3.2870306968688965
training step: 32890, total_loss: 4.506609916687012
training step: 32891, total_loss: 4.8712921142578125
training step: 32892, total_loss: 4.771350860595703
training step: 32893, total_loss: 5.614076137542725
training step: 32894, total_loss: 6.072072505950928
training step: 32895, total_loss: 4.988828182220459
training step: 32896, total_loss: 3.750189781188965
training step: 32897, total_loss: 4.565473556518555
training step: 32898, total_loss: 5.973617076873779
training step: 32899, total_loss: 6.226010322570801
training step: 32900, total_loss: 4.925225257873535
training step: 32901, total_loss: 4.521210193634033
training step: 32902, total_loss: 3.157796859741211
training step: 32903, total_loss: 4.957852840423584
training step: 32904, total_loss: 4.247180938720703
training step: 32905, total_loss: 2.1807479858398438
training step: 32906, total_loss: 4.088769912719727
training step: 32907, total_loss: 5.492000102996826
training step: 32908, total_loss: 3.947244882583618
training step: 32909, total_loss: 5.554157257080078
training step: 32910, total_loss: 1.289764642715454
training step: 32911, total_loss: 1.0075880289077759
training step: 32912, total_loss: 2.5263586044311523
training step: 32913, total_loss: 3.9304487705230713
training step: 32914, total_loss: 3.2738044261932373
training step: 32915, total_loss: 4.934494495391846
training step: 32916, total_loss: 3.683587074279785
training step: 32917, total_loss: 4.480460166931152
training step: 32918, total_loss: 3.6092369556427
training step: 32919, total_loss: 5.529648303985596
training step: 32920, total_loss: 4.793994426727295
training step: 32921, total_loss: 4.073368072509766
training step: 32922, total_loss: 2.533719539642334
training step: 32923, total_loss: 0.9697965383529663
training step: 32924, total_loss: 7.252407073974609
training step: 32925, total_loss: 4.110501766204834
training step: 32926, total_loss: 4.534926414489746
training step: 32927, total_loss: 3.232943058013916
training step: 32928, total_loss: 4.507877349853516
training step: 32929, total_loss: 4.072170734405518
training step: 32930, total_loss: 4.000776290893555
training step: 32931, total_loss: 3.2548828125
training step: 32932, total_loss: 4.516258239746094
training step: 32933, total_loss: 5.072561740875244
training step: 32934, total_loss: 3.834592819213867
training step: 32935, total_loss: 5.220091342926025
training step: 32936, total_loss: 4.097482204437256
training step: 32937, total_loss: 3.486375331878662
training step: 32938, total_loss: 4.672127723693848
training step: 32939, total_loss: 4.256218433380127
training step: 32940, total_loss: 5.229480266571045
training step: 32941, total_loss: 3.0107064247131348
training step: 32942, total_loss: 5.092284202575684
training step: 32943, total_loss: 3.305001735687256
training step: 32944, total_loss: 4.044279098510742
training step: 32945, total_loss: 4.314648628234863
training step: 32946, total_loss: 4.941633701324463
training step: 32947, total_loss: 4.742955207824707
training step: 32948, total_loss: 5.075064659118652
training step: 32949, total_loss: 5.572597026824951
training step: 32950, total_loss: 4.271739959716797
training step: 32951, total_loss: 4.919397354125977
training step: 32952, total_loss: 4.408838748931885
training step: 32953, total_loss: 3.878638982772827
training step: 32954, total_loss: 4.518759250640869
training step: 32955, total_loss: 4.310704231262207
training step: 32956, total_loss: 4.83279275894165
training step: 32957, total_loss: 5.2527570724487305
training step: 32958, total_loss: 4.409049034118652
training step: 32959, total_loss: 4.90096378326416
training step: 32960, total_loss: 1.7066954374313354
training step: 32961, total_loss: 4.26694393157959
training step: 32962, total_loss: 3.478055477142334
training step: 32963, total_loss: 5.028724670410156
training step: 32964, total_loss: 4.805975914001465
training step: 32965, total_loss: 4.8651933670043945
training step: 32966, total_loss: 3.63883638381958
training step: 32967, total_loss: 3.2851815223693848
training step: 32968, total_loss: 5.479640007019043
training step: 32969, total_loss: 4.610904216766357
training step: 32970, total_loss: 5.388632774353027
training step: 32971, total_loss: 4.913034915924072
training step: 32972, total_loss: 5.048750877380371
training step: 32973, total_loss: 5.35129451751709
training step: 32974, total_loss: 4.461967468261719
training step: 32975, total_loss: 5.660684585571289
training step: 32976, total_loss: 3.95487117767334
training step: 32977, total_loss: 2.473829746246338
training step: 32978, total_loss: 2.562814474105835
training step: 32979, total_loss: 4.689043045043945
training step: 32980, total_loss: 5.161821365356445
training step: 32981, total_loss: 4.404814720153809
training step: 32982, total_loss: 5.439281463623047
training step: 32983, total_loss: 4.653843879699707
training step: 32984, total_loss: 4.953474044799805
training step: 32985, total_loss: 0.948112964630127
training step: 32986, total_loss: 4.558147430419922
training step: 32987, total_loss: 2.6890759468078613
training step: 32988, total_loss: 3.569742202758789
training step: 32989, total_loss: 4.396239757537842
training step: 32990, total_loss: 5.159065246582031
training step: 32991, total_loss: 2.1852970123291016
training step: 32992, total_loss: 2.94984769821167
training step: 32993, total_loss: 5.23830509185791
training step: 32994, total_loss: 4.50834321975708
training step: 32995, total_loss: 3.971332550048828
training step: 32996, total_loss: 4.429549217224121
training step: 32997, total_loss: 4.443820953369141
training step: 32998, total_loss: 4.352941036224365
training step: 32999, total_loss: 5.824250221252441
training step: 33000, total_loss: 6.232333183288574
training step: 33001, total_loss: 2.791961193084717
training step: 33002, total_loss: 3.885596752166748
training step: 33003, total_loss: 5.033500671386719
training step: 33004, total_loss: 5.887503623962402
training step: 33005, total_loss: 5.575109004974365
training step: 33006, total_loss: 4.049678325653076
training step: 33007, total_loss: 2.951770782470703
training step: 33008, total_loss: 3.5154061317443848
training step: 33009, total_loss: 2.420140504837036
training step: 33010, total_loss: 3.496471881866455
training step: 33011, total_loss: 5.122981071472168
training step: 33012, total_loss: 2.4265553951263428
training step: 33013, total_loss: 4.294729232788086
training step: 33014, total_loss: 4.02120304107666
training step: 33015, total_loss: 5.099114418029785
training step: 33016, total_loss: 5.755741119384766
training step: 33017, total_loss: 5.544000625610352
training step: 33018, total_loss: 4.177330493927002
training step: 33019, total_loss: 4.751047134399414
training step: 33020, total_loss: 4.069436073303223
training step: 33021, total_loss: 2.322937488555908
training step: 33022, total_loss: 4.265463829040527
training step: 33023, total_loss: 4.7471771240234375
training step: 33024, total_loss: 4.112793922424316
training step: 33025, total_loss: 4.302051544189453
training step: 33026, total_loss: 6.520264625549316
training step: 33027, total_loss: 3.85476016998291
training step: 33028, total_loss: 4.327846527099609
training step: 33029, total_loss: 5.063681602478027
training step: 33030, total_loss: 2.6804354190826416
training step: 33031, total_loss: 4.157858848571777
training step: 33032, total_loss: 4.373057842254639
training step: 33033, total_loss: 4.795401096343994
training step: 33034, total_loss: 4.401082992553711
training step: 33035, total_loss: 3.619584321975708
training step: 33036, total_loss: 3.579773426055908
training step: 33037, total_loss: 4.594109535217285
training step: 33038, total_loss: 5.431330680847168
training step: 33039, total_loss: 4.937559604644775
training step: 33040, total_loss: 4.622187614440918
training step: 33041, total_loss: 5.120019912719727
training step: 33042, total_loss: 4.132649898529053
training step: 33043, total_loss: 5.137030601501465
training step: 33044, total_loss: 6.017605304718018
training step: 33045, total_loss: 5.051202297210693
training step: 33046, total_loss: 3.0341687202453613
training step: 33047, total_loss: 4.902909278869629
training step: 33048, total_loss: 4.73428201675415
training step: 33049, total_loss: 5.734376430511475
training step: 33050, total_loss: 4.833121299743652
training step: 33051, total_loss: 4.695888042449951
training step: 33052, total_loss: 5.063033103942871
training step: 33053, total_loss: 5.103565692901611
training step: 33054, total_loss: 3.1130402088165283
training step: 33055, total_loss: 4.4048309326171875
training step: 33056, total_loss: 4.216363906860352
training step: 33057, total_loss: 4.17324161529541
training step: 33058, total_loss: 4.957392692565918
training step: 33059, total_loss: 4.708620071411133
training step: 33060, total_loss: 4.8354363441467285
training step: 33061, total_loss: 3.244835138320923
training step: 33062, total_loss: 3.6506452560424805
training step: 33063, total_loss: 4.922647476196289
training step: 33064, total_loss: 5.174917221069336
training step: 33065, total_loss: 4.982819557189941
training step: 33066, total_loss: 4.7324090003967285
training step: 33067, total_loss: 6.0521464347839355
training step: 33068, total_loss: 4.843436241149902
training step: 33069, total_loss: 2.5884594917297363
training step: 33070, total_loss: 3.8360493183135986
training step: 33071, total_loss: 4.107561111450195
training step: 33072, total_loss: 3.3391430377960205
training step: 33073, total_loss: 5.356350421905518
training step: 33074, total_loss: 5.331483840942383
training step: 33075, total_loss: 4.851144790649414
training step: 33076, total_loss: 3.781470775604248
training step: 33077, total_loss: 4.287984848022461
training step: 33078, total_loss: 5.2114410400390625
training step: 33079, total_loss: 2.753477096557617
training step: 33080, total_loss: 5.684525489807129
training step: 33081, total_loss: 3.8195974826812744
training step: 33082, total_loss: 5.911185264587402
training step: 33083, total_loss: 3.9423294067382812
training step: 33084, total_loss: 4.442277908325195
training step: 33085, total_loss: 4.092548370361328
training step: 33086, total_loss: 4.223058700561523
training step: 33087, total_loss: 5.26143217086792
training step: 33088, total_loss: 4.619770050048828
training step: 33089, total_loss: 4.790224552154541
training step: 33090, total_loss: 4.182499408721924
training step: 33091, total_loss: 5.112320899963379
training step: 33092, total_loss: 4.864441871643066
training step: 33093, total_loss: 4.37437629699707
training step: 33094, total_loss: 3.0330891609191895
training step: 33095, total_loss: 4.020449638366699
training step: 33096, total_loss: 2.791147232055664
training step: 33097, total_loss: 5.343602180480957
training step: 33098, total_loss: 4.585864067077637
training step: 33099, total_loss: 4.621811866760254
training step: 33100, total_loss: 5.1735429763793945
training step: 33101, total_loss: 5.056059837341309
training step: 33102, total_loss: 5.934526443481445
training step: 33103, total_loss: 5.33099889755249
training step: 33104, total_loss: 3.815319776535034
training step: 33105, total_loss: 4.465273857116699
training step: 33106, total_loss: 4.024358749389648
training step: 33107, total_loss: 3.491081953048706
training step: 33108, total_loss: 4.613302230834961
training step: 33109, total_loss: 4.08269739151001
training step: 33110, total_loss: 2.9950621128082275
training step: 33111, total_loss: 1.069157600402832
training step: 33112, total_loss: 4.563694953918457
training step: 33113, total_loss: 4.367216110229492
training step: 33114, total_loss: 4.543396949768066
training step: 33115, total_loss: 3.8845601081848145
training step: 33116, total_loss: 2.9235610961914062
training step: 33117, total_loss: 3.304849863052368
training step: 33118, total_loss: 2.964627981185913
training step: 33119, total_loss: 3.647331714630127
training step: 33120, total_loss: 4.219780445098877
training step: 33121, total_loss: 5.312648773193359
training step: 33122, total_loss: 3.5431301593780518
training step: 33123, total_loss: 6.468842506408691
training step: 33124, total_loss: 3.9005696773529053
training step: 33125, total_loss: 3.4828996658325195
training step: 33126, total_loss: 4.601832389831543
training step: 33127, total_loss: 5.245333671569824
training step: 33128, total_loss: 4.882408142089844
training step: 33129, total_loss: 3.421276569366455
training step: 33130, total_loss: 4.810763835906982
training step: 33131, total_loss: 4.50985050201416
training step: 33132, total_loss: 4.455559253692627
training step: 33133, total_loss: 5.996747016906738
training step: 33134, total_loss: 4.429903030395508
training step: 33135, total_loss: 4.658117294311523
training step: 33136, total_loss: 6.036290168762207
training step: 33137, total_loss: 5.333042144775391
training step: 33138, total_loss: 5.147656440734863
training step: 33139, total_loss: 4.064785480499268
training step: 33140, total_loss: 3.9051332473754883
training step: 33141, total_loss: 5.466015815734863
training step: 33142, total_loss: 4.062115669250488
training step: 33143, total_loss: 4.989811420440674
training step: 33144, total_loss: 4.135456085205078
training step: 33145, total_loss: 4.391602516174316
training step: 33146, total_loss: 4.294806003570557
training step: 33147, total_loss: 2.451986074447632
training step: 33148, total_loss: 5.178045272827148
training step: 33149, total_loss: 5.258992671966553
training step: 33150, total_loss: 2.241413116455078
training step: 33151, total_loss: 4.245203495025635
training step: 33152, total_loss: 4.596637725830078
training step: 33153, total_loss: 4.712064743041992
training step: 33154, total_loss: 4.767555236816406
training step: 33155, total_loss: 5.085988998413086
training step: 33156, total_loss: 5.295053482055664
training step: 33157, total_loss: 4.565593242645264
training step: 33158, total_loss: 5.168050289154053
training step: 33159, total_loss: 3.9874162673950195
training step: 33160, total_loss: 4.776200294494629
training step: 33161, total_loss: 5.76102352142334
training step: 33162, total_loss: 3.4341721534729004
training step: 33163, total_loss: 5.234374046325684
training step: 33164, total_loss: 5.290685176849365
training step: 33165, total_loss: 0.8743757605552673
training step: 33166, total_loss: 3.8387997150421143
training step: 33167, total_loss: 4.299012660980225
training step: 33168, total_loss: 5.456307888031006
training step: 33169, total_loss: 4.102156162261963
training step: 33170, total_loss: 1.8378195762634277
training step: 33171, total_loss: 4.548545837402344
training step: 33172, total_loss: 4.026394367218018
training step: 33173, total_loss: 5.045018196105957
training step: 33174, total_loss: 3.947575092315674
training step: 33175, total_loss: 3.8282089233398438
training step: 33176, total_loss: 5.178261756896973
training step: 33177, total_loss: 3.30198073387146
training step: 33178, total_loss: 5.121870994567871
training step: 33179, total_loss: 4.339582443237305
training step: 33180, total_loss: 2.4809300899505615
training step: 33181, total_loss: 4.228480339050293
training step: 33182, total_loss: 1.266364574432373
training step: 33183, total_loss: 3.43023419380188
training step: 33184, total_loss: 4.086155891418457
training step: 33185, total_loss: 5.105897903442383
training step: 33186, total_loss: 3.642360210418701
training step: 33187, total_loss: 4.212886810302734
training step: 33188, total_loss: 3.932513952255249
training step: 33189, total_loss: 2.69956111907959
training step: 33190, total_loss: 3.098583221435547
training step: 33191, total_loss: 3.381500244140625
training step: 33192, total_loss: 4.714627265930176
training step: 33193, total_loss: 4.688353538513184
training step: 33194, total_loss: 3.7284955978393555
training step: 33195, total_loss: 5.449097156524658
training step: 33196, total_loss: 4.5491180419921875
training step: 33197, total_loss: 5.374639987945557
training step: 33198, total_loss: 3.7024435997009277
training step: 33199, total_loss: 4.93630313873291
training step: 33200, total_loss: 4.0067548751831055
training step: 33201, total_loss: 5.179020404815674
training step: 33202, total_loss: 6.409126281738281
training step: 33203, total_loss: 5.013338088989258
training step: 33204, total_loss: 5.080558776855469
training step: 33205, total_loss: 4.365388870239258
training step: 33206, total_loss: 7.019292831420898
training step: 33207, total_loss: 4.800365447998047
training step: 33208, total_loss: 3.590034008026123
training step: 33209, total_loss: 4.322636127471924
training step: 33210, total_loss: 4.785799026489258
training step: 33211, total_loss: 3.411869525909424
training step: 33212, total_loss: 4.429439067840576
training step: 33213, total_loss: 4.55481481552124
training step: 33214, total_loss: 3.36653470993042
training step: 33215, total_loss: 4.679991245269775
training step: 33216, total_loss: 5.55291223526001
training step: 33217, total_loss: 4.208519458770752
training step: 33218, total_loss: 3.1125125885009766
training step: 33219, total_loss: 4.22191047668457
training step: 33220, total_loss: 5.587789535522461
training step: 33221, total_loss: 4.500690460205078
training step: 33222, total_loss: 5.0362091064453125
training step: 33223, total_loss: 4.102086067199707
training step: 33224, total_loss: 4.780843734741211
training step: 33225, total_loss: 4.175856113433838
training step: 33226, total_loss: 4.419645309448242
training step: 33227, total_loss: 4.507012367248535
training step: 33228, total_loss: 4.288246154785156
training step: 33229, total_loss: 4.049427032470703
training step: 33230, total_loss: 2.9287545680999756
training step: 33231, total_loss: 4.6034746170043945
training step: 33232, total_loss: 4.710402488708496
training step: 33233, total_loss: 5.139702796936035
training step: 33234, total_loss: 4.470719337463379
training step: 33235, total_loss: 5.247974872589111
training step: 33236, total_loss: 3.7126145362854004
training step: 33237, total_loss: 4.580196380615234
training step: 33238, total_loss: 6.705966472625732
training step: 33239, total_loss: 6.25661039352417
training step: 33240, total_loss: 5.305238246917725
training step: 33241, total_loss: 2.6406452655792236
training step: 33242, total_loss: 1.8720817565917969
training step: 33243, total_loss: 6.841279029846191
training step: 33244, total_loss: 4.432745456695557
training step: 33245, total_loss: 3.7569732666015625
training step: 33246, total_loss: 4.6236982345581055
training step: 33247, total_loss: 5.815757751464844
training step: 33248, total_loss: 5.044849395751953
training step: 33249, total_loss: 5.334938049316406
training step: 33250, total_loss: 4.194128513336182
training step: 33251, total_loss: 4.117677688598633
training step: 33252, total_loss: 3.883784770965576
training step: 33253, total_loss: 3.110780715942383
training step: 33254, total_loss: 4.472702980041504
training step: 33255, total_loss: 4.466001510620117
training step: 33256, total_loss: 5.2458815574646
training step: 33257, total_loss: 4.7323808670043945
training step: 33258, total_loss: 7.223544597625732
training step: 33259, total_loss: 2.5513224601745605
training step: 33260, total_loss: 2.716245412826538
training step: 33261, total_loss: 3.5998873710632324
training step: 33262, total_loss: 2.43572735786438
training step: 33263, total_loss: 6.130711555480957
training step: 33264, total_loss: 4.8164262771606445
training step: 33265, total_loss: 4.433127403259277
training step: 33266, total_loss: 3.9942941665649414
training step: 33267, total_loss: 4.953672885894775
training step: 33268, total_loss: 3.61043381690979
training step: 33269, total_loss: 4.667330741882324
training step: 33270, total_loss: 3.4472177028656006
training step: 33271, total_loss: 4.065487861633301
training step: 33272, total_loss: 3.612973690032959
training step: 33273, total_loss: 3.9471983909606934
training step: 33274, total_loss: 4.515349388122559
training step: 33275, total_loss: 6.102972030639648
training step: 33276, total_loss: 3.6361827850341797
training step: 33277, total_loss: 7.168184757232666
training step: 33278, total_loss: 4.08453369140625
training step: 33279, total_loss: 7.205603122711182
training step: 33280, total_loss: 4.116894721984863
training step: 33281, total_loss: 4.855574607849121
training step: 33282, total_loss: 4.566922664642334
training step: 33283, total_loss: 4.811744213104248
training step: 33284, total_loss: 4.78441047668457
training step: 33285, total_loss: 3.6660990715026855
training step: 33286, total_loss: 3.2004213333129883
training step: 33287, total_loss: 4.6640400886535645
training step: 33288, total_loss: 5.698474407196045
training step: 33289, total_loss: 2.865020751953125
training step: 33290, total_loss: 1.429875135421753
training step: 33291, total_loss: 4.7160258293151855
training step: 33292, total_loss: 3.885842800140381
training step: 33293, total_loss: 4.54808235168457
training step: 33294, total_loss: 4.772521018981934
training step: 33295, total_loss: 1.976381540298462
training step: 33296, total_loss: 4.512692451477051
training step: 33297, total_loss: 3.5010793209075928
training step: 33298, total_loss: 5.303245544433594
training step: 33299, total_loss: 4.53126859664917
training step: 33300, total_loss: 5.30739164352417
training step: 33301, total_loss: 3.879732608795166
training step: 33302, total_loss: 5.332015037536621
training step: 33303, total_loss: 3.7379069328308105
training step: 33304, total_loss: 5.024980545043945
training step: 33305, total_loss: 5.99839973449707
training step: 33306, total_loss: 3.6251814365386963
training step: 33307, total_loss: 6.255603313446045
training step: 33308, total_loss: 2.7174153327941895
training step: 33309, total_loss: 5.3582258224487305
training step: 33310, total_loss: 5.285869121551514
training step: 33311, total_loss: 1.1369116306304932
training step: 33312, total_loss: 3.4057860374450684
training step: 33313, total_loss: 3.0486292839050293
training step: 33314, total_loss: 5.140860557556152
training step: 33315, total_loss: 4.483639717102051
training step: 33316, total_loss: 5.678891181945801
training step: 33317, total_loss: 4.821712493896484
training step: 33318, total_loss: 4.013473033905029
training step: 33319, total_loss: 5.215494632720947
training step: 33320, total_loss: 4.2554826736450195
training step: 33321, total_loss: 2.585340738296509
training step: 33322, total_loss: 5.321747779846191
training step: 33323, total_loss: 5.358282089233398
training step: 33324, total_loss: 4.13327693939209
training step: 33325, total_loss: 3.5278396606445312
training step: 33326, total_loss: 5.146822452545166
training step: 33327, total_loss: 4.9929351806640625
training step: 33328, total_loss: 3.898130416870117
training step: 33329, total_loss: 4.473905563354492
training step: 33330, total_loss: 4.667535781860352
training step: 33331, total_loss: 5.611185550689697
training step: 33332, total_loss: 5.959780693054199
training step: 33333, total_loss: 6.3488688468933105
training step: 33334, total_loss: 2.953277111053467
training step: 33335, total_loss: 3.5591089725494385
training step: 33336, total_loss: 4.148402214050293
training step: 33337, total_loss: 4.188417434692383
training step: 33338, total_loss: 3.3189148902893066
training step: 33339, total_loss: 4.358990669250488
training step: 33340, total_loss: 2.887193202972412
training step: 33341, total_loss: 3.8018858432769775
training step: 33342, total_loss: 5.295835018157959
training step: 33343, total_loss: 4.491827011108398
training step: 33344, total_loss: 4.38008451461792
training step: 33345, total_loss: 4.71366024017334
training step: 33346, total_loss: 4.701805591583252
training step: 33347, total_loss: 2.8358712196350098
training step: 33348, total_loss: 5.824667930603027
training step: 33349, total_loss: 4.836846828460693
training step: 33350, total_loss: 4.094451904296875
training step: 33351, total_loss: 4.8123297691345215
training step: 33352, total_loss: 5.134615898132324
training step: 33353, total_loss: 5.272170066833496
training step: 33354, total_loss: 3.004398822784424
training step: 33355, total_loss: 1.1208593845367432
training step: 33356, total_loss: 3.7419357299804688
training step: 33357, total_loss: 6.269925117492676
training step: 33358, total_loss: 2.711686134338379
training step: 33359, total_loss: 3.3267669677734375
training step: 33360, total_loss: 3.6529409885406494
training step: 33361, total_loss: 4.23494291305542
training step: 33362, total_loss: 4.822004318237305
training step: 33363, total_loss: 4.103544235229492
training step: 33364, total_loss: 4.949905872344971
training step: 33365, total_loss: 4.5203752517700195
training step: 33366, total_loss: 4.764294624328613
training step: 33367, total_loss: 5.590104103088379
training step: 33368, total_loss: 4.5114030838012695
training step: 33369, total_loss: 3.614375352859497
training step: 33370, total_loss: 5.1585588455200195
training step: 33371, total_loss: 3.3489603996276855
training step: 33372, total_loss: 4.134602069854736
training step: 33373, total_loss: 4.8316779136657715
training step: 33374, total_loss: 5.65126895904541
training step: 33375, total_loss: 4.256734848022461
training step: 33376, total_loss: 6.700824737548828
training step: 33377, total_loss: 5.0746965408325195
training step: 33378, total_loss: 4.0144734382629395
training step: 33379, total_loss: 5.614106178283691
training step: 33380, total_loss: 5.406999111175537
training step: 33381, total_loss: 5.094182014465332
training step: 33382, total_loss: 6.114134311676025
training step: 33383, total_loss: 5.841276168823242
training step: 33384, total_loss: 4.957479000091553
training step: 33385, total_loss: 5.305656909942627
training step: 33386, total_loss: 4.6741042137146
training step: 33387, total_loss: 3.911160469055176
training step: 33388, total_loss: 4.821810722351074
training step: 33389, total_loss: 3.8458542823791504
training step: 33390, total_loss: 4.739919662475586
training step: 33391, total_loss: 4.109052658081055
training step: 33392, total_loss: 3.8411307334899902
training step: 33393, total_loss: 2.8991317749023438
training step: 33394, total_loss: 4.616057395935059
training step: 33395, total_loss: 5.8090314865112305
training step: 33396, total_loss: 5.223637104034424
training step: 33397, total_loss: 4.03169584274292
training step: 33398, total_loss: 5.0745415687561035
training step: 33399, total_loss: 4.409637451171875
training step: 33400, total_loss: 5.459089279174805
training step: 33401, total_loss: 4.9172186851501465
training step: 33402, total_loss: 3.112910032272339
training step: 33403, total_loss: 4.6569061279296875
training step: 33404, total_loss: 4.329497814178467
training step: 33405, total_loss: 3.643507242202759
training step: 33406, total_loss: 3.960991859436035
training step: 33407, total_loss: 4.323907852172852
training step: 33408, total_loss: 3.5284676551818848
training step: 33409, total_loss: 4.151647567749023
training step: 33410, total_loss: 4.367849826812744
training step: 33411, total_loss: 3.8530685901641846
training step: 33412, total_loss: 4.125449180603027
training step: 33413, total_loss: 5.934738636016846
training step: 33414, total_loss: 4.7166571617126465
training step: 33415, total_loss: 4.419429779052734
training step: 33416, total_loss: 3.639390468597412
training step: 33417, total_loss: 4.993971824645996
training step: 33418, total_loss: 3.532197952270508
training step: 33419, total_loss: 4.822257041931152
training step: 33420, total_loss: 4.9644775390625
training step: 33421, total_loss: 4.356142044067383
training step: 33422, total_loss: 4.820040225982666
training step: 33423, total_loss: 3.361839771270752
training step: 33424, total_loss: 5.254673957824707
training step: 33425, total_loss: 3.1782469749450684
training step: 33426, total_loss: 5.72004508972168
training step: 33427, total_loss: 5.482646942138672
training step: 33428, total_loss: 3.158367395401001
training step: 33429, total_loss: 4.567439079284668
training step: 33430, total_loss: 3.1432688236236572
training step: 33431, total_loss: 7.52199649810791
training step: 33432, total_loss: 3.45957350730896
training step: 33433, total_loss: 6.127144813537598
training step: 33434, total_loss: 5.2599310874938965
training step: 33435, total_loss: 4.490784645080566
training step: 33436, total_loss: 5.178244590759277
training step: 33437, total_loss: 4.0962724685668945
training step: 33438, total_loss: 5.0175628662109375
training step: 33439, total_loss: 5.652976036071777
training step: 33440, total_loss: 4.704864025115967
training step: 33441, total_loss: 4.584799289703369
training step: 33442, total_loss: 4.407037258148193
training step: 33443, total_loss: 4.688526153564453
training step: 33444, total_loss: 4.6341142654418945
training step: 33445, total_loss: 3.6578893661499023
training step: 33446, total_loss: 4.59694766998291
training step: 33447, total_loss: 4.800318717956543
training step: 33448, total_loss: 4.1708903312683105
training step: 33449, total_loss: 5.829957008361816
training step: 33450, total_loss: 4.098935127258301
training step: 33451, total_loss: 3.401623249053955
training step: 33452, total_loss: 5.905686378479004
training step: 33453, total_loss: 5.405613422393799
training step: 33454, total_loss: 4.47217321395874
training step: 33455, total_loss: 3.5963149070739746
training step: 33456, total_loss: 3.3682961463928223
training step: 33457, total_loss: 5.648962020874023
training step: 33458, total_loss: 4.405335426330566
training step: 33459, total_loss: 5.357644081115723
training step: 33460, total_loss: 4.149101734161377
training step: 33461, total_loss: 2.7355380058288574
training step: 33462, total_loss: 5.115904808044434
training step: 33463, total_loss: 4.977992534637451
training step: 33464, total_loss: 4.271064758300781
training step: 33465, total_loss: 3.64766788482666
training step: 33466, total_loss: 4.664525985717773
training step: 33467, total_loss: 4.70928955078125
training step: 33468, total_loss: 4.683521270751953
training step: 33469, total_loss: 3.1972970962524414
training step: 33470, total_loss: 5.537467956542969
training step: 33471, total_loss: 3.6908187866210938
training step: 33472, total_loss: 4.945254325866699
training step: 33473, total_loss: 4.71867561340332
training step: 33474, total_loss: 4.536023139953613
training step: 33475, total_loss: 4.7383575439453125
training step: 33476, total_loss: 3.8770179748535156
training step: 33477, total_loss: 2.6699981689453125
training step: 33478, total_loss: 5.176036834716797
training step: 33479, total_loss: 4.228428840637207
training step: 33480, total_loss: 4.650304794311523
training step: 33481, total_loss: 3.1992697715759277
training step: 33482, total_loss: 4.278110504150391
training step: 33483, total_loss: 3.2507686614990234
training step: 33484, total_loss: 5.3145270347595215
training step: 33485, total_loss: 4.421133041381836
training step: 33486, total_loss: 4.40770149230957
training step: 33487, total_loss: 3.3669497966766357
training step: 33488, total_loss: 5.078104019165039
training step: 33489, total_loss: 3.1241698265075684
training step: 33490, total_loss: 4.650595664978027
training step: 33491, total_loss: 3.530802011489868
training step: 33492, total_loss: 4.763361930847168
training step: 33493, total_loss: 4.541872024536133
training step: 33494, total_loss: 5.250554084777832
training step: 33495, total_loss: 5.285764694213867
training step: 33496, total_loss: 4.571122169494629
training step: 33497, total_loss: 3.8838114738464355
training step: 33498, total_loss: 6.955395698547363
training step: 33499, total_loss: 5.336269855499268
training step: 33500, total_loss: 5.726409912109375
training step: 33501, total_loss: 3.7811410427093506
training step: 33502, total_loss: 6.189926624298096
training step: 33503, total_loss: 3.0762176513671875
training step: 33504, total_loss: 4.556950569152832
training step: 33505, total_loss: 4.375404357910156
training step: 33506, total_loss: 4.686319351196289
training step: 33507, total_loss: 3.8447394371032715
training step: 33508, total_loss: 4.654256820678711
training step: 33509, total_loss: 4.2990922927856445
training step: 33510, total_loss: 4.731654644012451
training step: 33511, total_loss: 5.588994026184082
training step: 33512, total_loss: 6.177793979644775
training step: 33513, total_loss: 3.743621349334717
training step: 33514, total_loss: 1.2978007793426514
training step: 33515, total_loss: 4.10791015625
training step: 33516, total_loss: 3.1063783168792725
training step: 33517, total_loss: 4.20412015914917
training step: 33518, total_loss: 3.34356427192688
training step: 33519, total_loss: 4.624634742736816
training step: 33520, total_loss: 3.9258527755737305
training step: 33521, total_loss: 3.9135549068450928
training step: 33522, total_loss: 4.643773078918457
training step: 33523, total_loss: 4.202463626861572
training step: 33524, total_loss: 4.639825820922852
training step: 33525, total_loss: 3.897796154022217
training step: 33526, total_loss: 3.5688319206237793
training step: 33527, total_loss: 4.159789085388184
training step: 33528, total_loss: 3.764460325241089
training step: 33529, total_loss: 3.8501758575439453
training step: 33530, total_loss: 2.6883139610290527
training step: 33531, total_loss: 6.329472541809082
training step: 33532, total_loss: 3.296802043914795
training step: 33533, total_loss: 3.376760482788086
training step: 33534, total_loss: 4.18179988861084
training step: 33535, total_loss: 5.695556640625
training step: 33536, total_loss: 7.454597473144531
training step: 33537, total_loss: 4.585615158081055
training step: 33538, total_loss: 3.6728904247283936
training step: 33539, total_loss: 5.682453155517578
training step: 33540, total_loss: 4.307443618774414
training step: 33541, total_loss: 3.959848403930664
training step: 33542, total_loss: 3.109877824783325
training step: 33543, total_loss: 3.112095832824707
training step: 33544, total_loss: 3.91385555267334
training step: 33545, total_loss: 6.092318534851074
training step: 33546, total_loss: 2.6942944526672363
training step: 33547, total_loss: 5.820385932922363
training step: 33548, total_loss: 3.6097331047058105
training step: 33549, total_loss: 4.582758903503418
training step: 33550, total_loss: 4.33810567855835
training step: 33551, total_loss: 2.038239002227783
training step: 33552, total_loss: 4.723496437072754
training step: 33553, total_loss: 3.4006667137145996
training step: 33554, total_loss: 3.950547933578491
training step: 33555, total_loss: 3.7670974731445312
training step: 33556, total_loss: 3.9744749069213867
training step: 33557, total_loss: 4.156132221221924
training step: 33558, total_loss: 4.367478370666504
training step: 33559, total_loss: 3.206897735595703
training step: 33560, total_loss: 1.8863288164138794
training step: 33561, total_loss: 3.2237942218780518
training step: 33562, total_loss: 5.043109893798828
training step: 33563, total_loss: 4.109249591827393
training step: 33564, total_loss: 4.2873945236206055
training step: 33565, total_loss: 4.9246721267700195
training step: 33566, total_loss: 5.220285415649414
training step: 33567, total_loss: 5.9316301345825195
training step: 33568, total_loss: 4.073007583618164
training step: 33569, total_loss: 5.331165313720703
training step: 33570, total_loss: 4.86167049407959
training step: 33571, total_loss: 4.056862831115723
training step: 33572, total_loss: 3.756251811981201
training step: 33573, total_loss: 5.4842071533203125
training step: 33574, total_loss: 5.774082183837891
training step: 33575, total_loss: 5.358084201812744
training step: 33576, total_loss: 4.416020393371582
training step: 33577, total_loss: 5.723761558532715
training step: 33578, total_loss: 4.745349884033203
training step: 33579, total_loss: 4.958019256591797
training step: 33580, total_loss: 3.1868152618408203
training step: 33581, total_loss: 2.5843358039855957
training step: 33582, total_loss: 5.112531661987305
training step: 33583, total_loss: 5.5233073234558105
training step: 33584, total_loss: 4.03972053527832
training step: 33585, total_loss: 5.906980991363525
training step: 33586, total_loss: 4.369405746459961
training step: 33587, total_loss: 5.751257419586182
training step: 33588, total_loss: 6.5102972984313965
training step: 33589, total_loss: 5.0618672370910645
training step: 33590, total_loss: 5.858551025390625
training step: 33591, total_loss: 5.343016147613525
training step: 33592, total_loss: 3.952148914337158
training step: 33593, total_loss: 4.745755195617676
training step: 33594, total_loss: 4.48307466506958
training step: 33595, total_loss: 4.338681697845459
training step: 33596, total_loss: 5.791847229003906
training step: 33597, total_loss: 5.217999458312988
training step: 33598, total_loss: 6.930143356323242
training step: 33599, total_loss: 5.710042953491211
training step: 33600, total_loss: 6.925836563110352
training step: 33601, total_loss: 4.349545478820801
training step: 33602, total_loss: 2.2765095233917236
training step: 33603, total_loss: 4.84613561630249
training step: 33604, total_loss: 3.8346571922302246
training step: 33605, total_loss: 3.452247142791748
training step: 33606, total_loss: 4.005032062530518
training step: 33607, total_loss: 4.500095844268799
training step: 33608, total_loss: 4.788870811462402
training step: 33609, total_loss: 4.194529056549072
training step: 33610, total_loss: 4.1115851402282715
training step: 33611, total_loss: 4.594545364379883
training step: 33612, total_loss: 4.023314476013184
training step: 33613, total_loss: 4.512074947357178
training step: 33614, total_loss: 3.4649391174316406
training step: 33615, total_loss: 5.374837875366211
training step: 33616, total_loss: 5.131272792816162
training step: 33617, total_loss: 6.133392333984375
training step: 33618, total_loss: 5.065422534942627
training step: 33619, total_loss: 3.1813249588012695
training step: 33620, total_loss: 5.381903648376465
training step: 33621, total_loss: 4.885417461395264
training step: 33622, total_loss: 5.336092948913574
training step: 33623, total_loss: 4.074912071228027
training step: 33624, total_loss: 4.994028091430664
training step: 33625, total_loss: 5.140455722808838
training step: 33626, total_loss: 4.74882698059082
training step: 33627, total_loss: 5.065192699432373
training step: 33628, total_loss: 4.340364933013916
training step: 33629, total_loss: 5.646942615509033
training step: 33630, total_loss: 4.997862815856934
training step: 33631, total_loss: 6.387774467468262
training step: 33632, total_loss: 3.919358015060425
training step: 33633, total_loss: 5.659721374511719
training step: 33634, total_loss: 3.7101988792419434
training step: 33635, total_loss: 1.3442081212997437
training step: 33636, total_loss: 4.0391316413879395
training step: 33637, total_loss: 4.298830986022949
training step: 33638, total_loss: 6.3146162033081055
training step: 33639, total_loss: 4.1615400314331055
training step: 33640, total_loss: 3.840703010559082
training step: 33641, total_loss: 3.377347469329834
training step: 33642, total_loss: 4.670743942260742
training step: 33643, total_loss: 3.9042978286743164
training step: 33644, total_loss: 2.994295597076416
training step: 33645, total_loss: 4.727895259857178
training step: 33646, total_loss: 4.2768235206604
training step: 33647, total_loss: 4.160520553588867
training step: 33648, total_loss: 6.272591590881348
training step: 33649, total_loss: 4.052489757537842
training step: 33650, total_loss: 5.045526504516602
training step: 33651, total_loss: 2.6317901611328125
training step: 33652, total_loss: 5.698589324951172
training step: 33653, total_loss: 1.9564282894134521
training step: 33654, total_loss: 6.119020462036133
training step: 33655, total_loss: 4.8626251220703125
training step: 33656, total_loss: 5.592771530151367
training step: 33657, total_loss: 3.4833898544311523
training step: 33658, total_loss: 5.291156768798828
training step: 33659, total_loss: 4.373339653015137
training step: 33660, total_loss: 4.494413375854492
training step: 33661, total_loss: 4.372770309448242
training step: 33662, total_loss: 5.246079444885254
training step: 33663, total_loss: 3.3171277046203613
training step: 33664, total_loss: 4.129279613494873
training step: 33665, total_loss: 4.081540584564209
training step: 33666, total_loss: 5.409412384033203
training step: 33667, total_loss: 4.711132049560547
training step: 33668, total_loss: 4.845249176025391
training step: 33669, total_loss: 4.229187965393066
training step: 33670, total_loss: 5.119907379150391
training step: 33671, total_loss: 5.367192268371582
training step: 33672, total_loss: 4.623466968536377
training step: 33673, total_loss: 4.997366905212402
training step: 33674, total_loss: 5.313877105712891
training step: 33675, total_loss: 3.391002655029297
training step: 33676, total_loss: 3.825373888015747
training step: 33677, total_loss: 4.887471675872803
training step: 33678, total_loss: 3.5859262943267822
training step: 33679, total_loss: 5.401981830596924
training step: 33680, total_loss: 6.302449703216553
training step: 33681, total_loss: 3.756300449371338
training step: 33682, total_loss: 3.9614877700805664
training step: 33683, total_loss: 5.48056697845459
training step: 33684, total_loss: 4.301833152770996
training step: 33685, total_loss: 3.7829365730285645
training step: 33686, total_loss: 3.2505764961242676
training step: 33687, total_loss: 4.025698184967041
training step: 33688, total_loss: 3.9774065017700195
training step: 33689, total_loss: 3.9924936294555664
training step: 33690, total_loss: 3.650012969970703
training step: 33691, total_loss: 4.3519206047058105
training step: 33692, total_loss: 4.690495014190674
training step: 33693, total_loss: 5.050135135650635
training step: 33694, total_loss: 4.657588005065918
training step: 33695, total_loss: 4.918605804443359
training step: 33696, total_loss: 4.342818260192871
training step: 33697, total_loss: 5.4822869300842285
training step: 33698, total_loss: 4.938467025756836
training step: 33699, total_loss: 7.1373138427734375
training step: 33700, total_loss: 4.824862480163574
training step: 33701, total_loss: 4.360142707824707
training step: 33702, total_loss: 3.5362062454223633
training step: 33703, total_loss: 4.050249099731445
training step: 33704, total_loss: 3.823427677154541
training step: 33705, total_loss: 5.080861568450928
training step: 33706, total_loss: 5.265252113342285
training step: 33707, total_loss: 4.520823001861572
training step: 33708, total_loss: 4.167672634124756
training step: 33709, total_loss: 6.083747386932373
training step: 33710, total_loss: 4.53893518447876
training step: 33711, total_loss: 3.888570785522461
training step: 33712, total_loss: 5.10504150390625
training step: 33713, total_loss: 4.305998802185059
training step: 33714, total_loss: 5.079517364501953
training step: 33715, total_loss: 4.297634601593018
training step: 33716, total_loss: 4.898489475250244
training step: 33717, total_loss: 4.43073844909668
training step: 33718, total_loss: 5.579135894775391
training step: 33719, total_loss: 4.298699378967285
training step: 33720, total_loss: 4.071587562561035
training step: 33721, total_loss: 4.2347092628479
training step: 33722, total_loss: 3.6673688888549805
training step: 33723, total_loss: 4.6854352951049805
training step: 33724, total_loss: 4.295583724975586
training step: 33725, total_loss: 3.109666347503662
training step: 33726, total_loss: 4.297811508178711
training step: 33727, total_loss: 3.776033878326416
training step: 33728, total_loss: 4.491225719451904
training step: 33729, total_loss: 3.3345961570739746
training step: 33730, total_loss: 5.905508995056152
training step: 33731, total_loss: 3.261340618133545
training step: 33732, total_loss: 6.64549446105957
training step: 33733, total_loss: 3.4572246074676514
training step: 33734, total_loss: 3.043304920196533
training step: 33735, total_loss: 4.3762946128845215
training step: 33736, total_loss: 7.021056175231934
training step: 33737, total_loss: 4.750331401824951
training step: 33738, total_loss: 4.688680648803711
training step: 33739, total_loss: 6.683385848999023
training step: 33740, total_loss: 4.474057197570801
training step: 33741, total_loss: 5.258172512054443
training step: 33742, total_loss: 6.459891319274902
training step: 33743, total_loss: 4.631173133850098
training step: 33744, total_loss: 7.026222229003906
training step: 33745, total_loss: 1.748476505279541
training step: 33746, total_loss: 3.467360019683838
training step: 33747, total_loss: 5.2197065353393555
training step: 33748, total_loss: 4.5254058837890625
training step: 33749, total_loss: 4.485188961029053
training step: 33750, total_loss: 3.9750781059265137
training step: 33751, total_loss: 4.993227958679199
training step: 33752, total_loss: 7.753393173217773
training step: 33753, total_loss: 5.262996673583984
training step: 33754, total_loss: 4.579269886016846
training step: 33755, total_loss: 4.897974014282227
training step: 33756, total_loss: 5.55949592590332
training step: 33757, total_loss: 6.159795761108398
training step: 33758, total_loss: 5.749523162841797
training step: 33759, total_loss: 4.217045307159424
training step: 33760, total_loss: 3.2784671783447266
training step: 33761, total_loss: 4.224059104919434
training step: 33762, total_loss: 4.8730010986328125
training step: 33763, total_loss: 4.5310468673706055
training step: 33764, total_loss: 5.239867687225342
training step: 33765, total_loss: 5.150554180145264
training step: 33766, total_loss: 4.68050479888916
training step: 33767, total_loss: 3.064403533935547
training step: 33768, total_loss: 4.99612283706665
training step: 33769, total_loss: 5.137134075164795
training step: 33770, total_loss: 4.168448448181152
training step: 33771, total_loss: 3.421947956085205
training step: 33772, total_loss: 5.652398586273193
training step: 33773, total_loss: 4.913294792175293
training step: 33774, total_loss: 4.012103080749512
training step: 33775, total_loss: 3.845072031021118
training step: 33776, total_loss: 2.3838391304016113
training step: 33777, total_loss: 4.839771270751953
training step: 33778, total_loss: 4.3070831298828125
training step: 33779, total_loss: 3.7745625972747803
training step: 33780, total_loss: 4.382415771484375
training step: 33781, total_loss: 5.962786674499512
training step: 33782, total_loss: 3.565304756164551
training step: 33783, total_loss: 3.418426275253296
training step: 33784, total_loss: 4.729255676269531
training step: 33785, total_loss: 4.399527549743652
training step: 33786, total_loss: 4.165829658508301
training step: 33787, total_loss: 4.223518371582031
training step: 33788, total_loss: 3.1379685401916504
training step: 33789, total_loss: 5.11672306060791
training step: 33790, total_loss: 4.362044811248779
training step: 33791, total_loss: 3.858051300048828
training step: 33792, total_loss: 4.6554460525512695
training step: 33793, total_loss: 5.563234329223633
training step: 33794, total_loss: 5.876132011413574
training step: 33795, total_loss: 3.9776320457458496
training step: 33796, total_loss: 4.608941078186035
training step: 33797, total_loss: 3.2951347827911377
training step: 33798, total_loss: 5.526268482208252
training step: 33799, total_loss: 6.793284893035889
training step: 33800, total_loss: 3.2361855506896973
training step: 33801, total_loss: 3.3879261016845703
training step: 33802, total_loss: 4.6449761390686035
training step: 33803, total_loss: 3.0979981422424316
training step: 33804, total_loss: 5.1363630294799805
training step: 33805, total_loss: 4.694676399230957
training step: 33806, total_loss: 5.299424648284912
training step: 33807, total_loss: 3.442046642303467
training step: 33808, total_loss: 5.966305732727051
training step: 33809, total_loss: 4.161818504333496
training step: 33810, total_loss: 5.2540998458862305
training step: 33811, total_loss: 5.98549747467041
training step: 33812, total_loss: 4.6718645095825195
training step: 33813, total_loss: 3.809333324432373
training step: 33814, total_loss: 4.03537654876709
training step: 33815, total_loss: 5.299464225769043
training step: 33816, total_loss: 2.7545433044433594
training step: 33817, total_loss: 4.770709037780762
training step: 33818, total_loss: 5.5115065574646
training step: 33819, total_loss: 3.4604601860046387
training step: 33820, total_loss: 5.232036590576172
training step: 33821, total_loss: 4.983190059661865
training step: 33822, total_loss: 4.758977890014648
training step: 33823, total_loss: 3.610020637512207
training step: 33824, total_loss: 5.002090930938721
training step: 33825, total_loss: 4.202645778656006
training step: 33826, total_loss: 4.730950355529785
training step: 33827, total_loss: 4.437808990478516
training step: 33828, total_loss: 4.387497901916504
training step: 33829, total_loss: 5.371343612670898
training step: 33830, total_loss: 4.70598030090332
training step: 33831, total_loss: 4.823410511016846
training step: 33832, total_loss: 4.302563190460205
training step: 33833, total_loss: 3.2899422645568848
training step: 33834, total_loss: 5.655362129211426
training step: 33835, total_loss: 5.126734733581543
training step: 33836, total_loss: 4.523927688598633
training step: 33837, total_loss: 4.821061134338379
training step: 33838, total_loss: 3.2745399475097656
training step: 33839, total_loss: 2.8266072273254395
training step: 33840, total_loss: 4.410797119140625
training step: 33841, total_loss: 5.704771518707275
training step: 33842, total_loss: 3.721029043197632
training step: 33843, total_loss: 3.1404337882995605
training step: 33844, total_loss: 5.864504814147949
training step: 33845, total_loss: 3.814077377319336
training step: 33846, total_loss: 5.354401588439941
training step: 33847, total_loss: 3.1677896976470947
training step: 33848, total_loss: 6.976954460144043
training step: 33849, total_loss: 4.59819221496582
training step: 33850, total_loss: 3.3351383209228516
training step: 33851, total_loss: 4.424715042114258
training step: 33852, total_loss: 4.461883544921875
training step: 33853, total_loss: 4.6712517738342285
training step: 33854, total_loss: 4.998077869415283
training step: 33855, total_loss: 3.975128650665283
training step: 33856, total_loss: 6.4127068519592285
training step: 33857, total_loss: 4.072253704071045
training step: 33858, total_loss: 3.9618637561798096
training step: 33859, total_loss: 4.1633453369140625
training step: 33860, total_loss: 5.77040433883667
training step: 33861, total_loss: 3.026700019836426
training step: 33862, total_loss: 5.508979797363281
training step: 33863, total_loss: 5.005341529846191
training step: 33864, total_loss: 4.75792932510376
training step: 33865, total_loss: 4.410394191741943
training step: 33866, total_loss: 5.551775932312012
training step: 33867, total_loss: 4.008028030395508
training step: 33868, total_loss: 1.2040255069732666
training step: 33869, total_loss: 5.17305850982666
training step: 33870, total_loss: 3.2451279163360596
training step: 33871, total_loss: 5.062023162841797
training step: 33872, total_loss: 4.035863876342773
training step: 33873, total_loss: 4.386937141418457
training step: 33874, total_loss: 4.642326354980469
training step: 33875, total_loss: 4.104247093200684
training step: 33876, total_loss: 4.300667762756348
training step: 33877, total_loss: 3.4687228202819824
training step: 33878, total_loss: 3.346273422241211
training step: 33879, total_loss: 4.1653618812561035
training step: 33880, total_loss: 5.1840972900390625
training step: 33881, total_loss: 4.866247653961182
training step: 33882, total_loss: 3.4115233421325684
training step: 33883, total_loss: 5.859809875488281
training step: 33884, total_loss: 5.013728618621826
training step: 33885, total_loss: 2.65211820602417
training step: 33886, total_loss: 3.201819896697998
training step: 33887, total_loss: 1.2837843894958496
training step: 33888, total_loss: 4.243170738220215
training step: 33889, total_loss: 4.493392467498779
training step: 33890, total_loss: 4.3762993812561035
training step: 33891, total_loss: 2.771118640899658
training step: 33892, total_loss: 5.677879810333252
training step: 33893, total_loss: 4.095144271850586
training step: 33894, total_loss: 4.652194023132324
training step: 33895, total_loss: 4.7775959968566895
training step: 33896, total_loss: 5.194859504699707
training step: 33897, total_loss: 3.344663143157959
training step: 33898, total_loss: 4.683114051818848
training step: 33899, total_loss: 5.544910907745361
training step: 33900, total_loss: 3.8293797969818115
training step: 33901, total_loss: 3.434326171875
training step: 33902, total_loss: 4.069614410400391
training step: 33903, total_loss: 4.63078498840332
training step: 33904, total_loss: 2.459833860397339
training step: 33905, total_loss: 3.9859695434570312
training step: 33906, total_loss: 4.269498348236084
training step: 33907, total_loss: 4.383873462677002
training step: 33908, total_loss: 4.308189868927002
training step: 33909, total_loss: 4.765725135803223
training step: 33910, total_loss: 3.9676640033721924
training step: 33911, total_loss: 3.5106358528137207
training step: 33912, total_loss: 5.937751770019531
training step: 33913, total_loss: 4.22900390625
training step: 33914, total_loss: 2.897843360900879
training step: 33915, total_loss: 5.105973243713379
training step: 33916, total_loss: 4.8366217613220215
training step: 33917, total_loss: 4.581998348236084
training step: 33918, total_loss: 3.8535141944885254
training step: 33919, total_loss: 6.7148051261901855
training step: 33920, total_loss: 6.416550636291504
training step: 33921, total_loss: 4.962818622589111
training step: 33922, total_loss: 5.721864700317383
training step: 33923, total_loss: 5.332978248596191
training step: 33924, total_loss: 5.701788902282715
training step: 33925, total_loss: 4.152790069580078
training step: 33926, total_loss: 3.8304312229156494
training step: 33927, total_loss: 6.454322814941406
training step: 33928, total_loss: 4.455294609069824
training step: 33929, total_loss: 5.154213905334473
training step: 33930, total_loss: 5.409282207489014
training step: 33931, total_loss: 4.375450134277344
training step: 33932, total_loss: 4.339145660400391
training step: 33933, total_loss: 3.50272536277771
training step: 33934, total_loss: 4.949676513671875
training step: 33935, total_loss: 4.066741943359375
training step: 33936, total_loss: 5.723043441772461
training step: 33937, total_loss: 3.6207685470581055
training step: 33938, total_loss: 5.311564922332764
training step: 33939, total_loss: 3.756679058074951
training step: 33940, total_loss: 5.1576337814331055
training step: 33941, total_loss: 3.7721309661865234
training step: 33942, total_loss: 4.916489601135254
training step: 33943, total_loss: 5.022559642791748
training step: 33944, total_loss: 5.781715393066406
training step: 33945, total_loss: 5.590539932250977
training step: 33946, total_loss: 3.7029099464416504
training step: 33947, total_loss: 4.38697624206543
training step: 33948, total_loss: 3.077202081680298
training step: 33949, total_loss: 2.9570798873901367
training step: 33950, total_loss: 4.880975723266602
training step: 33951, total_loss: 4.317275047302246
training step: 33952, total_loss: 3.7766799926757812
training step: 33953, total_loss: 1.337263822555542
training step: 33954, total_loss: 4.518154621124268
training step: 33955, total_loss: 5.403815746307373
training step: 33956, total_loss: 2.9562864303588867
training step: 33957, total_loss: 4.072113037109375
training step: 33958, total_loss: 4.35435676574707
training step: 33959, total_loss: 4.337896823883057
training step: 33960, total_loss: 4.78044319152832
training step: 33961, total_loss: 3.0785303115844727
training step: 33962, total_loss: 4.581641674041748
training step: 33963, total_loss: 3.7538599967956543
training step: 33964, total_loss: 5.935521602630615
training step: 33965, total_loss: 3.5725860595703125
training step: 33966, total_loss: 4.418290138244629
training step: 33967, total_loss: 3.2877233028411865
training step: 33968, total_loss: 2.7704732418060303
training step: 33969, total_loss: 4.989518165588379
training step: 33970, total_loss: 5.391701698303223
training step: 33971, total_loss: 3.6155173778533936
training step: 33972, total_loss: 5.121335983276367
training step: 33973, total_loss: 4.676570415496826
training step: 33974, total_loss: 4.390286445617676
training step: 33975, total_loss: 5.40035343170166
training step: 33976, total_loss: 2.9409828186035156
training step: 33977, total_loss: 4.509363651275635
training step: 33978, total_loss: 3.938058853149414
training step: 33979, total_loss: 4.244185447692871
training step: 33980, total_loss: 2.865692615509033
training step: 33981, total_loss: 4.028472423553467
training step: 33982, total_loss: 4.651537895202637
training step: 33983, total_loss: 4.78839111328125
training step: 33984, total_loss: 3.758340358734131
training step: 33985, total_loss: 4.225536346435547
training step: 33986, total_loss: 3.4766788482666016
training step: 33987, total_loss: 3.656550884246826
training step: 33988, total_loss: 4.82568359375
training step: 33989, total_loss: 4.634854316711426
training step: 33990, total_loss: 1.2436705827713013
training step: 33991, total_loss: 5.171874046325684
training step: 33992, total_loss: 4.243592739105225
training step: 33993, total_loss: 4.115504741668701
training step: 33994, total_loss: 3.820169448852539
training step: 33995, total_loss: 6.315232276916504
training step: 33996, total_loss: 5.363375186920166
training step: 33997, total_loss: 3.8626770973205566
training step: 33998, total_loss: 5.763862609863281
training step: 33999, total_loss: 4.347684860229492
training step: 34000, total_loss: 5.3458452224731445
training step: 34001, total_loss: 4.829868793487549
training step: 34002, total_loss: 4.5755109786987305
training step: 34003, total_loss: 5.242621421813965
training step: 34004, total_loss: 3.881566286087036
training step: 34005, total_loss: 3.9943947792053223
training step: 34006, total_loss: 4.751162528991699
training step: 34007, total_loss: 5.1572747230529785
training step: 34008, total_loss: 5.309222221374512
training step: 34009, total_loss: 2.0055553913116455
training step: 34010, total_loss: 4.705295562744141
training step: 34011, total_loss: 3.770462989807129
training step: 34012, total_loss: 2.376060962677002
training step: 34013, total_loss: 3.7016704082489014
training step: 34014, total_loss: 5.454628944396973
training step: 34015, total_loss: 4.99381160736084
training step: 34016, total_loss: 2.3510184288024902
training step: 34017, total_loss: 4.41768741607666
training step: 34018, total_loss: 3.565833806991577
training step: 34019, total_loss: 3.195322036743164
training step: 34020, total_loss: 4.143313407897949
training step: 34021, total_loss: 6.6073503494262695
training step: 34022, total_loss: 4.035053730010986
training step: 34023, total_loss: 4.616157531738281
training step: 34024, total_loss: 5.6391425132751465
training step: 34025, total_loss: 4.44730281829834
training step: 34026, total_loss: 2.5425426959991455
training step: 34027, total_loss: 5.624716758728027
training step: 34028, total_loss: 4.592383861541748
training step: 34029, total_loss: 3.716387987136841
training step: 34030, total_loss: 4.114629745483398
training step: 34031, total_loss: 3.714034080505371
training step: 34032, total_loss: 4.905353546142578
training step: 34033, total_loss: 3.0251071453094482
training step: 34034, total_loss: 4.165720462799072
training step: 34035, total_loss: 3.4659759998321533
training step: 34036, total_loss: 2.517516613006592
training step: 34037, total_loss: 3.4030239582061768
training step: 34038, total_loss: 3.9271047115325928
training step: 34039, total_loss: 4.183355808258057
training step: 34040, total_loss: 3.7711544036865234
training step: 34041, total_loss: 4.091080188751221
training step: 34042, total_loss: 3.921481132507324
training step: 34043, total_loss: 3.2662601470947266
training step: 34044, total_loss: 4.314369201660156
training step: 34045, total_loss: 4.555047988891602
training step: 34046, total_loss: 3.8763322830200195
training step: 34047, total_loss: 3.3581106662750244
training step: 34048, total_loss: 5.0949249267578125
training step: 34049, total_loss: 4.900539398193359
training step: 34050, total_loss: 4.475887298583984
training step: 34051, total_loss: 5.286966800689697
training step: 34052, total_loss: 3.2142343521118164
training step: 34053, total_loss: 6.011396408081055
training step: 34054, total_loss: 5.814478874206543
training step: 34055, total_loss: 5.173327445983887
training step: 34056, total_loss: 4.330026626586914
training step: 34057, total_loss: 5.0999531745910645
training step: 34058, total_loss: 2.72204852104187
training step: 34059, total_loss: 3.6663336753845215
training step: 34060, total_loss: 3.7082173824310303
training step: 34061, total_loss: 3.8172590732574463
training step: 34062, total_loss: 5.28092098236084
training step: 34063, total_loss: 4.670740127563477
training step: 34064, total_loss: 4.340920448303223
training step: 34065, total_loss: 3.320436954498291
training step: 34066, total_loss: 5.053103446960449
training step: 34067, total_loss: 7.138868808746338
training step: 34068, total_loss: 4.702908515930176
training step: 34069, total_loss: 4.675361633300781
training step: 34070, total_loss: 4.307375907897949
training step: 34071, total_loss: 4.989167213439941
training step: 34072, total_loss: 3.9250640869140625
training step: 34073, total_loss: 2.7261996269226074
training step: 34074, total_loss: 2.7613894939422607
training step: 34075, total_loss: 6.862395763397217
training step: 34076, total_loss: 5.901828765869141
training step: 34077, total_loss: 5.547782897949219
training step: 34078, total_loss: 5.546212673187256
training step: 34079, total_loss: 3.435666084289551
training step: 34080, total_loss: 5.039534568786621
training step: 34081, total_loss: 4.867208480834961
training step: 34082, total_loss: 2.794112205505371
training step: 34083, total_loss: 4.808788299560547
training step: 34084, total_loss: 4.80480432510376
training step: 34085, total_loss: 4.807520866394043
training step: 34086, total_loss: 5.691802024841309
training step: 34087, total_loss: 4.677014350891113
training step: 34088, total_loss: 4.870243072509766
training step: 34089, total_loss: 3.8401832580566406
training step: 34090, total_loss: 3.2793591022491455
training step: 34091, total_loss: 4.780484676361084
training step: 34092, total_loss: 4.412006855010986
training step: 34093, total_loss: 3.887953281402588
training step: 34094, total_loss: 4.9716877937316895
training step: 34095, total_loss: 5.84946346282959
training step: 34096, total_loss: 3.5704593658447266
training step: 34097, total_loss: 3.6036267280578613
training step: 34098, total_loss: 4.7444562911987305
training step: 34099, total_loss: 4.271202564239502
training step: 34100, total_loss: 4.967321395874023
training step: 34101, total_loss: 2.721010208129883
training step: 34102, total_loss: 4.224042892456055
training step: 34103, total_loss: 4.450193405151367
training step: 34104, total_loss: 3.2594308853149414
training step: 34105, total_loss: 6.0305585861206055
training step: 34106, total_loss: 4.732895851135254
training step: 34107, total_loss: 4.031332015991211
training step: 34108, total_loss: 4.906572341918945
training step: 34109, total_loss: 3.1401662826538086
training step: 34110, total_loss: 5.681441307067871
training step: 34111, total_loss: 4.350860118865967
training step: 34112, total_loss: 5.644290924072266
training step: 34113, total_loss: 3.3297715187072754
training step: 34114, total_loss: 3.1347713470458984
training step: 34115, total_loss: 4.601465225219727
training step: 34116, total_loss: 5.364269256591797
training step: 34117, total_loss: 4.411538124084473
training step: 34118, total_loss: 2.9483349323272705
training step: 34119, total_loss: 4.506962299346924
training step: 34120, total_loss: 3.9289674758911133
training step: 34121, total_loss: 4.253994941711426
training step: 34122, total_loss: 5.096397399902344
training step: 34123, total_loss: 1.1453756093978882
training step: 34124, total_loss: 5.698293209075928
training step: 34125, total_loss: 4.301043510437012
training step: 34126, total_loss: 4.27454948425293
training step: 34127, total_loss: 4.888576507568359
training step: 34128, total_loss: 3.809318780899048
training step: 34129, total_loss: 4.709758758544922
training step: 34130, total_loss: 5.097729206085205
training step: 34131, total_loss: 3.2571659088134766
training step: 34132, total_loss: 3.407741069793701
training step: 34133, total_loss: 3.248265504837036
training step: 34134, total_loss: 4.205060958862305
training step: 34135, total_loss: 5.128857612609863
training step: 34136, total_loss: 5.338165283203125
training step: 34137, total_loss: 4.406916618347168
training step: 34138, total_loss: 3.832425117492676
training step: 34139, total_loss: 3.6898226737976074
training step: 34140, total_loss: 5.0327043533325195
training step: 34141, total_loss: 7.199612617492676
training step: 34142, total_loss: 2.283573627471924
training step: 34143, total_loss: 4.277273178100586
training step: 34144, total_loss: 1.1039059162139893
training step: 34145, total_loss: 4.173527717590332
training step: 34146, total_loss: 3.8903543949127197
training step: 34147, total_loss: 4.858098030090332
training step: 34148, total_loss: 4.692203044891357
training step: 34149, total_loss: 6.69234561920166
training step: 34150, total_loss: 5.289705276489258
training step: 34151, total_loss: 3.9494051933288574
training step: 34152, total_loss: 0.9146713614463806
training step: 34153, total_loss: 4.412937641143799
training step: 34154, total_loss: 4.664029121398926
training step: 34155, total_loss: 4.857476234436035
training step: 34156, total_loss: 4.819611549377441
training step: 34157, total_loss: 3.9364702701568604
training step: 34158, total_loss: 2.8203420639038086
training step: 34159, total_loss: 4.263912677764893
training step: 34160, total_loss: 5.203360080718994
training step: 34161, total_loss: 3.8653578758239746
training step: 34162, total_loss: 5.3624725341796875
training step: 34163, total_loss: 4.319324493408203
training step: 34164, total_loss: 4.272936820983887
training step: 34165, total_loss: 2.5175037384033203
training step: 34166, total_loss: 4.676843166351318
training step: 34167, total_loss: 4.003673553466797
training step: 34168, total_loss: 3.8899247646331787
training step: 34169, total_loss: 4.827661514282227
training step: 34170, total_loss: 3.584441661834717
training step: 34171, total_loss: 3.884838104248047
training step: 34172, total_loss: 4.903663635253906
training step: 34173, total_loss: 3.682755947113037
training step: 34174, total_loss: 2.7961337566375732
training step: 34175, total_loss: 4.594799041748047
training step: 34176, total_loss: 4.059043884277344
training step: 34177, total_loss: 2.5502564907073975
training step: 34178, total_loss: 4.695182800292969
training step: 34179, total_loss: 5.980339527130127
training step: 34180, total_loss: 4.0593037605285645
training step: 34181, total_loss: 4.383251190185547
training step: 34182, total_loss: 4.222345352172852
training step: 34183, total_loss: 3.731332540512085
training step: 34184, total_loss: 5.9837775230407715
training step: 34185, total_loss: 4.65971040725708
training step: 34186, total_loss: 5.908801078796387
training step: 34187, total_loss: 5.782649517059326
training step: 34188, total_loss: 3.252122402191162
training step: 34189, total_loss: 2.557827949523926
training step: 34190, total_loss: 3.3271865844726562
training step: 34191, total_loss: 4.998317241668701
training step: 34192, total_loss: 4.585016250610352
training step: 34193, total_loss: 3.6732640266418457
training step: 34194, total_loss: 5.456907272338867
training step: 34195, total_loss: 3.5407581329345703
training step: 34196, total_loss: 4.809276103973389
training step: 34197, total_loss: 4.796639442443848
training step: 34198, total_loss: 4.246434211730957
training step: 34199, total_loss: 4.0127854347229
training step: 34200, total_loss: 4.005365371704102
training step: 34201, total_loss: 3.8499910831451416
training step: 34202, total_loss: 5.565481185913086
training step: 34203, total_loss: 5.444178104400635
training step: 34204, total_loss: 5.947916507720947
training step: 34205, total_loss: 5.298191070556641
training step: 34206, total_loss: 3.0167760848999023
training step: 34207, total_loss: 2.6340222358703613
training step: 34208, total_loss: 3.3299591541290283
training step: 34209, total_loss: 4.037139892578125
training step: 34210, total_loss: 6.678889274597168
training step: 34211, total_loss: 3.1412322521209717
training step: 34212, total_loss: 3.673401355743408
training step: 34213, total_loss: 3.362018585205078
training step: 34214, total_loss: 4.692868709564209
training step: 34215, total_loss: 3.759566307067871
training step: 34216, total_loss: 5.210356712341309
training step: 34217, total_loss: 4.76588249206543
training step: 34218, total_loss: 4.204509735107422
training step: 34219, total_loss: 4.272263050079346
training step: 34220, total_loss: 2.9247305393218994
training step: 34221, total_loss: 4.596570014953613
training step: 34222, total_loss: 4.273652076721191
training step: 34223, total_loss: 4.603328227996826
training step: 34224, total_loss: 4.688212871551514
training step: 34225, total_loss: 3.433256149291992
training step: 34226, total_loss: 5.631175518035889
training step: 34227, total_loss: 5.277941703796387
training step: 34228, total_loss: 5.567744255065918
training step: 34229, total_loss: 4.224770545959473
training step: 34230, total_loss: 3.0046799182891846
training step: 34231, total_loss: 5.183022499084473
training step: 34232, total_loss: 5.218621253967285
training step: 34233, total_loss: 4.996366024017334
training step: 34234, total_loss: 4.583577632904053
training step: 34235, total_loss: 2.530775547027588
training step: 34236, total_loss: 4.254691123962402
training step: 34237, total_loss: 4.457894802093506
training step: 34238, total_loss: 4.4984235763549805
training step: 34239, total_loss: 4.518307209014893
training step: 34240, total_loss: 4.392430305480957
training step: 34241, total_loss: 5.057408332824707
training step: 34242, total_loss: 3.7541708946228027
training step: 34243, total_loss: 2.5679266452789307
training step: 34244, total_loss: 3.8173983097076416
training step: 34245, total_loss: 3.980593681335449
training step: 34246, total_loss: 3.6565380096435547
training step: 34247, total_loss: 2.666583776473999
training step: 34248, total_loss: 4.252598285675049
training step: 34249, total_loss: 4.256324768066406
training step: 34250, total_loss: 4.27972412109375
training step: 34251, total_loss: 4.141462326049805
training step: 34252, total_loss: 4.406256198883057
training step: 34253, total_loss: 2.37467360496521
training step: 34254, total_loss: 4.804808616638184
training step: 34255, total_loss: 4.497019290924072
training step: 34256, total_loss: 5.548313617706299
training step: 34257, total_loss: 3.1691927909851074
training step: 34258, total_loss: 4.581880569458008
training step: 34259, total_loss: 4.13304328918457
training step: 34260, total_loss: 4.158461570739746
training step: 34261, total_loss: 4.265486717224121
training step: 34262, total_loss: 1.1863669157028198
training step: 34263, total_loss: 4.046302795410156
training step: 34264, total_loss: 5.740437984466553
training step: 34265, total_loss: 1.20708167552948
training step: 34266, total_loss: 2.5351204872131348
training step: 34267, total_loss: 3.1177268028259277
training step: 34268, total_loss: 5.505414009094238
training step: 34269, total_loss: 2.3348805904388428
training step: 34270, total_loss: 5.375116348266602
training step: 34271, total_loss: 5.442408084869385
training step: 34272, total_loss: 0.8649789094924927
training step: 34273, total_loss: 4.857203006744385
training step: 34274, total_loss: 2.9145212173461914
training step: 34275, total_loss: 5.000445365905762
training step: 34276, total_loss: 4.650747776031494
training step: 34277, total_loss: 2.7002854347229004
training step: 34278, total_loss: 3.552757501602173
training step: 34279, total_loss: 5.878986358642578
training step: 34280, total_loss: 3.7327518463134766
training step: 34281, total_loss: 4.1112165451049805
training step: 34282, total_loss: 1.8135733604431152
training step: 34283, total_loss: 4.044074058532715
training step: 34284, total_loss: 5.018302917480469
training step: 34285, total_loss: 3.288120985031128
training step: 34286, total_loss: 5.077154636383057
training step: 34287, total_loss: 4.581336498260498
training step: 34288, total_loss: 4.7500810623168945
training step: 34289, total_loss: 4.204607963562012
training step: 34290, total_loss: 4.869318962097168
training step: 34291, total_loss: 4.407066345214844
training step: 34292, total_loss: 4.099515914916992
training step: 34293, total_loss: 4.563043594360352
training step: 34294, total_loss: 0.7724184989929199
training step: 34295, total_loss: 5.730644226074219
training step: 34296, total_loss: 5.453710079193115
training step: 34297, total_loss: 4.593095779418945
training step: 34298, total_loss: 1.9945831298828125
training step: 34299, total_loss: 4.667513370513916
training step: 34300, total_loss: 2.0409786701202393
training step: 34301, total_loss: 2.8909013271331787
training step: 34302, total_loss: 5.497247695922852
training step: 34303, total_loss: 5.170490264892578
training step: 34304, total_loss: 8.315106391906738
training step: 34305, total_loss: 4.845378875732422
training step: 34306, total_loss: 3.494600772857666
training step: 34307, total_loss: 2.6556661128997803
training step: 34308, total_loss: 5.5038371086120605
training step: 34309, total_loss: 4.568141937255859
training step: 34310, total_loss: 4.51922607421875
training step: 34311, total_loss: 0.6809467077255249
training step: 34312, total_loss: 0.6797484159469604
training step: 34313, total_loss: 3.3289759159088135
training step: 34314, total_loss: 5.224583625793457
training step: 34315, total_loss: 4.332225799560547
training step: 34316, total_loss: 5.064359188079834
training step: 34317, total_loss: 5.458268165588379
training step: 34318, total_loss: 5.74870491027832
training step: 34319, total_loss: 3.4925618171691895
training step: 34320, total_loss: 3.601919174194336
training step: 34321, total_loss: 4.98093318939209
training step: 34322, total_loss: 3.8797574043273926
training step: 34323, total_loss: 4.768421173095703
training step: 34324, total_loss: 4.005766868591309
training step: 34325, total_loss: 5.316946983337402
training step: 34326, total_loss: 5.747777462005615
training step: 34327, total_loss: 5.515862464904785
training step: 34328, total_loss: 3.6585521697998047
training step: 34329, total_loss: 4.762766361236572
training step: 34330, total_loss: 5.127004623413086
training step: 34331, total_loss: 3.372358798980713
training step: 34332, total_loss: 4.71792459487915
training step: 34333, total_loss: 4.129081726074219
training step: 34334, total_loss: 4.36592960357666
training step: 34335, total_loss: 1.8759623765945435
training step: 34336, total_loss: 0.7390750050544739
training step: 34337, total_loss: 5.515773296356201
training step: 34338, total_loss: 4.335958003997803
training step: 34339, total_loss: 5.627740859985352
training step: 34340, total_loss: 4.5401458740234375
training step: 34341, total_loss: 3.933408737182617
training step: 34342, total_loss: 4.567919731140137
training step: 34343, total_loss: 4.834339141845703
training step: 34344, total_loss: 5.158687114715576
training step: 34345, total_loss: 3.9435060024261475
training step: 34346, total_loss: 4.22813081741333
training step: 34347, total_loss: 5.281948089599609
training step: 34348, total_loss: 5.466344356536865
training step: 34349, total_loss: 4.380712509155273
training step: 34350, total_loss: 4.049007892608643
training step: 34351, total_loss: 4.758393287658691
training step: 34352, total_loss: 1.2846977710723877
training step: 34353, total_loss: 5.549163341522217
training step: 34354, total_loss: 3.934865951538086
training step: 34355, total_loss: 4.1855363845825195
training step: 34356, total_loss: 1.97772216796875
training step: 34357, total_loss: 5.001010894775391
training step: 34358, total_loss: 5.23399543762207
training step: 34359, total_loss: 4.239865303039551
training step: 34360, total_loss: 6.172402381896973
training step: 34361, total_loss: 1.0990486145019531
training step: 34362, total_loss: 3.839326858520508
training step: 34363, total_loss: 7.230799674987793
training step: 34364, total_loss: 5.266122817993164
training step: 34365, total_loss: 6.029984474182129
training step: 34366, total_loss: 3.143681049346924
training step: 34367, total_loss: 3.952526569366455
training step: 34368, total_loss: 3.964561700820923
training step: 34369, total_loss: 6.321464538574219
training step: 34370, total_loss: 4.521566390991211
training step: 34371, total_loss: 3.1481614112854004
training step: 34372, total_loss: 3.6109282970428467
training step: 34373, total_loss: 5.158073425292969
training step: 34374, total_loss: 4.741029262542725
training step: 34375, total_loss: 4.1200127601623535
training step: 34376, total_loss: 3.091373920440674
training step: 34377, total_loss: 4.8582000732421875
training step: 34378, total_loss: 2.8120248317718506
training step: 34379, total_loss: 4.998392105102539
training step: 34380, total_loss: 4.25708532333374
training step: 34381, total_loss: 5.407026290893555
training step: 34382, total_loss: 2.651705741882324
training step: 34383, total_loss: 4.402483940124512
training step: 34384, total_loss: 4.48415470123291
training step: 34385, total_loss: 4.34014892578125
training step: 34386, total_loss: 4.053491115570068
training step: 34387, total_loss: 3.9471211433410645
training step: 34388, total_loss: 4.662583827972412
training step: 34389, total_loss: 4.231818199157715
training step: 34390, total_loss: 3.952904462814331
training step: 34391, total_loss: 2.4294421672821045
training step: 34392, total_loss: 4.034025192260742
training step: 34393, total_loss: 2.11643648147583
training step: 34394, total_loss: 3.44653058052063
training step: 34395, total_loss: 3.9578213691711426
training step: 34396, total_loss: 5.333902835845947
training step: 34397, total_loss: 3.5120773315429688
training step: 34398, total_loss: 4.481420993804932
training step: 34399, total_loss: 4.5987701416015625
training step: 34400, total_loss: 5.001646041870117
training step: 34401, total_loss: 3.817843437194824
training step: 34402, total_loss: 4.342364311218262
training step: 34403, total_loss: 4.769512176513672
training step: 34404, total_loss: 3.964634895324707
training step: 34405, total_loss: 4.725054740905762
training step: 34406, total_loss: 4.00603723526001
training step: 34407, total_loss: 3.559000015258789
training step: 34408, total_loss: 3.5652477741241455
training step: 34409, total_loss: 4.27728271484375
training step: 34410, total_loss: 4.073855876922607
training step: 34411, total_loss: 5.855169773101807
training step: 34412, total_loss: 5.372539043426514
training step: 34413, total_loss: 5.385852813720703
training step: 34414, total_loss: 2.010932683944702
training step: 34415, total_loss: 3.9429211616516113
training step: 34416, total_loss: 3.3635950088500977
training step: 34417, total_loss: 3.6088132858276367
training step: 34418, total_loss: 4.856939315795898
training step: 34419, total_loss: 4.8741302490234375
training step: 34420, total_loss: 4.273459434509277
training step: 34421, total_loss: 3.19393253326416
training step: 34422, total_loss: 5.774389266967773
training step: 34423, total_loss: 5.065727233886719
training step: 34424, total_loss: 4.921902656555176
training step: 34425, total_loss: 5.52866792678833
training step: 34426, total_loss: 4.612295150756836
training step: 34427, total_loss: 5.246518135070801
training step: 34428, total_loss: 6.688338279724121
training step: 34429, total_loss: 5.532269477844238
training step: 34430, total_loss: 4.758882999420166
training step: 34431, total_loss: 3.741095542907715
training step: 34432, total_loss: 2.84562349319458
training step: 34433, total_loss: 6.205286502838135
training step: 34434, total_loss: 4.686018943786621
training step: 34435, total_loss: 4.415655136108398
training step: 34436, total_loss: 4.537691116333008
training step: 34437, total_loss: 4.527575492858887
training step: 34438, total_loss: 1.0217746496200562
training step: 34439, total_loss: 1.7007859945297241
training step: 34440, total_loss: 4.017487525939941
training step: 34441, total_loss: 4.709331035614014
training step: 34442, total_loss: 3.8719911575317383
training step: 34443, total_loss: 4.927532196044922
training step: 34444, total_loss: 5.429063320159912
training step: 34445, total_loss: 6.436697959899902
training step: 34446, total_loss: 4.791787624359131
training step: 34447, total_loss: 4.512807369232178
training step: 34448, total_loss: 4.36776876449585
training step: 34449, total_loss: 4.047427654266357
training step: 34450, total_loss: 5.212889671325684
training step: 34451, total_loss: 3.0491714477539062
training step: 34452, total_loss: 3.692033052444458
training step: 34453, total_loss: 4.365780353546143
training step: 34454, total_loss: 3.6536402702331543
training step: 34455, total_loss: 4.780691146850586
training step: 34456, total_loss: 4.3533782958984375
training step: 34457, total_loss: 1.0365781784057617
training step: 34458, total_loss: 1.0013622045516968
training step: 34459, total_loss: 4.393670082092285
training step: 34460, total_loss: 3.4148685932159424
training step: 34461, total_loss: 4.613271236419678
training step: 34462, total_loss: 4.913906097412109
training step: 34463, total_loss: 3.788543224334717
training step: 34464, total_loss: 2.725769519805908
training step: 34465, total_loss: 4.513813495635986
training step: 34466, total_loss: 4.771090507507324
training step: 34467, total_loss: 4.26071310043335
training step: 34468, total_loss: 5.485962867736816
training step: 34469, total_loss: 2.8694701194763184
training step: 34470, total_loss: 4.6701459884643555
training step: 34471, total_loss: 3.692894697189331
training step: 34472, total_loss: 4.2935404777526855
training step: 34473, total_loss: 4.4392852783203125
training step: 34474, total_loss: 3.660219669342041
training step: 34475, total_loss: 5.135713577270508
training step: 34476, total_loss: 5.541355133056641
training step: 34477, total_loss: 4.7760114669799805
training step: 34478, total_loss: 3.8834478855133057
training step: 34479, total_loss: 5.735803127288818
training step: 34480, total_loss: 2.753955125808716
training step: 34481, total_loss: 3.5648839473724365
training step: 34482, total_loss: 4.205878257751465
training step: 34483, total_loss: 5.071442604064941
training step: 34484, total_loss: 2.871394634246826
training step: 34485, total_loss: 4.484122276306152
training step: 34486, total_loss: 4.104407787322998
training step: 34487, total_loss: 4.189223766326904
training step: 34488, total_loss: 4.494950771331787
training step: 34489, total_loss: 3.422477960586548
training step: 34490, total_loss: 5.346729755401611
training step: 34491, total_loss: 4.239202499389648
training step: 34492, total_loss: 6.257966995239258
training step: 34493, total_loss: 5.476027488708496
training step: 34494, total_loss: 3.4981937408447266
training step: 34495, total_loss: 4.636959075927734
training step: 34496, total_loss: 5.804716110229492
training step: 34497, total_loss: 4.0254058837890625
training step: 34498, total_loss: 4.3853373527526855
training step: 34499, total_loss: 3.0773279666900635
training step: 34500, total_loss: 1.0390782356262207
training step: 34501, total_loss: 4.768490791320801
training step: 34502, total_loss: 4.620427131652832
training step: 34503, total_loss: 4.3744096755981445
training step: 34504, total_loss: 4.593018531799316
training step: 34505, total_loss: 5.474134922027588
training step: 34506, total_loss: 4.231804847717285
training step: 34507, total_loss: 4.562722682952881
training step: 34508, total_loss: 5.601249694824219
training step: 34509, total_loss: 4.771634101867676
training step: 34510, total_loss: 4.7368316650390625
training step: 34511, total_loss: 5.379626274108887
training step: 34512, total_loss: 4.2286529541015625
training step: 34513, total_loss: 4.955630779266357
training step: 34514, total_loss: 3.1590523719787598
training step: 34515, total_loss: 4.513739585876465
training step: 34516, total_loss: 3.6588377952575684
training step: 34517, total_loss: 2.640383005142212
training step: 34518, total_loss: 2.8895788192749023
training step: 34519, total_loss: 5.546314239501953
training step: 34520, total_loss: 2.215040683746338
training step: 34521, total_loss: 4.050693035125732
training step: 34522, total_loss: 4.417150497436523
training step: 34523, total_loss: 5.573233604431152
training step: 34524, total_loss: 3.415816068649292
training step: 34525, total_loss: 3.6388211250305176
training step: 34526, total_loss: 2.107698440551758
training step: 34527, total_loss: 4.867732048034668
training step: 34528, total_loss: 5.389034271240234
training step: 34529, total_loss: 3.6606948375701904
training step: 34530, total_loss: 6.4639177322387695
training step: 34531, total_loss: 4.842026233673096
training step: 34532, total_loss: 5.162463665008545
training step: 34533, total_loss: 3.2808678150177
training step: 34534, total_loss: 3.975724220275879
training step: 34535, total_loss: 4.442448616027832
training step: 34536, total_loss: 5.46879768371582
training step: 34537, total_loss: 5.337378025054932
training step: 34538, total_loss: 3.079537868499756
training step: 34539, total_loss: 4.152035236358643
training step: 34540, total_loss: 4.300769805908203
training step: 34541, total_loss: 3.899975299835205
training step: 34542, total_loss: 2.9503040313720703
training step: 34543, total_loss: 5.794634819030762
training step: 34544, total_loss: 4.320980548858643
training step: 34545, total_loss: 2.4225878715515137
training step: 34546, total_loss: 5.297263145446777
training step: 34547, total_loss: 5.008467197418213
training step: 34548, total_loss: 5.190780162811279
training step: 34549, total_loss: 4.6407999992370605
training step: 34550, total_loss: 4.5417890548706055
training step: 34551, total_loss: 4.193296432495117
training step: 34552, total_loss: 4.410746097564697
training step: 34553, total_loss: 4.921041965484619
training step: 34554, total_loss: 3.402012825012207
training step: 34555, total_loss: 4.703368663787842
training step: 34556, total_loss: 3.9682505130767822
training step: 34557, total_loss: 4.532459259033203
training step: 34558, total_loss: 4.38981819152832
training step: 34559, total_loss: 5.8896989822387695
training step: 34560, total_loss: 3.842130422592163
training step: 34561, total_loss: 4.672294616699219
training step: 34562, total_loss: 4.797055244445801
training step: 34563, total_loss: 4.7671661376953125
training step: 34564, total_loss: 4.742154121398926
training step: 34565, total_loss: 2.68194317817688
training step: 34566, total_loss: 3.1662497520446777
training step: 34567, total_loss: 6.229475975036621
training step: 34568, total_loss: 5.57515287399292
training step: 34569, total_loss: 5.637982368469238
training step: 34570, total_loss: 5.363872528076172
training step: 34571, total_loss: 6.395525932312012
training step: 34572, total_loss: 4.301179885864258
training step: 34573, total_loss: 4.176962852478027
training step: 34574, total_loss: 5.122438430786133
training step: 34575, total_loss: 3.0993876457214355
training step: 34576, total_loss: 4.2040205001831055
training step: 34577, total_loss: 6.181678771972656
training step: 34578, total_loss: 3.9732422828674316
training step: 34579, total_loss: 2.3194262981414795
training step: 34580, total_loss: 8.221250534057617
training step: 34581, total_loss: 4.399505138397217
training step: 34582, total_loss: 4.1981024742126465
training step: 34583, total_loss: 4.390986442565918
training step: 34584, total_loss: 2.931756019592285
training step: 34585, total_loss: 4.295000076293945
training step: 34586, total_loss: 3.8414227962493896
training step: 34587, total_loss: 3.3021998405456543
training step: 34588, total_loss: 5.4696455001831055
training step: 34589, total_loss: 2.5209312438964844
training step: 34590, total_loss: 2.499328136444092
training step: 34591, total_loss: 7.109133243560791
training step: 34592, total_loss: 4.176984786987305
training step: 34593, total_loss: 3.7317705154418945
training step: 34594, total_loss: 4.1876373291015625
training step: 34595, total_loss: 4.648238658905029
training step: 34596, total_loss: 4.092404365539551
training step: 34597, total_loss: 4.44035530090332
training step: 34598, total_loss: 3.802845001220703
training step: 34599, total_loss: 5.561305999755859
training step: 34600, total_loss: 3.5876028537750244
training step: 34601, total_loss: 5.256898880004883
training step: 34602, total_loss: 4.486936569213867
training step: 34603, total_loss: 5.631080627441406
training step: 34604, total_loss: 4.57594633102417
training step: 34605, total_loss: 5.5796403884887695
training step: 34606, total_loss: 5.525504112243652
training step: 34607, total_loss: 3.259828567504883
training step: 34608, total_loss: 3.543243408203125
training step: 34609, total_loss: 2.269098997116089
training step: 34610, total_loss: 5.135191440582275
training step: 34611, total_loss: 4.843824863433838
training step: 34612, total_loss: 1.616929054260254
training step: 34613, total_loss: 5.171195030212402
training step: 34614, total_loss: 4.989090919494629
training step: 34615, total_loss: 4.416681289672852
training step: 34616, total_loss: 4.21934175491333
training step: 34617, total_loss: 3.4006118774414062
training step: 34618, total_loss: 4.2994279861450195
training step: 34619, total_loss: 4.62224006652832
training step: 34620, total_loss: 4.857024669647217
training step: 34621, total_loss: 3.055628776550293
training step: 34622, total_loss: 5.001011848449707
training step: 34623, total_loss: 5.275740623474121
training step: 34624, total_loss: 4.869009971618652
training step: 34625, total_loss: 1.474172592163086
training step: 34626, total_loss: 3.85471248626709
training step: 34627, total_loss: 3.951172351837158
training step: 34628, total_loss: 3.053880214691162
training step: 34629, total_loss: 2.324794292449951
training step: 34630, total_loss: 3.5198802947998047
training step: 34631, total_loss: 5.306186676025391
training step: 34632, total_loss: 4.533792972564697
training step: 34633, total_loss: 3.5517845153808594
training step: 34634, total_loss: 3.4547119140625
training step: 34635, total_loss: 2.0597691535949707
training step: 34636, total_loss: 4.605278968811035
training step: 34637, total_loss: 5.808414459228516
training step: 34638, total_loss: 4.179556369781494
training step: 34639, total_loss: 4.965695381164551
training step: 34640, total_loss: 3.1148500442504883
training step: 34641, total_loss: 2.6408772468566895
training step: 34642, total_loss: 4.8150634765625
training step: 34643, total_loss: 4.58110237121582
training step: 34644, total_loss: 4.573073387145996
training step: 34645, total_loss: 5.491034507751465
training step: 34646, total_loss: 4.991915702819824
training step: 34647, total_loss: 3.9343786239624023
training step: 34648, total_loss: 5.149116516113281
training step: 34649, total_loss: 4.3785552978515625
training step: 34650, total_loss: 4.661397457122803
training step: 34651, total_loss: 2.59566068649292
training step: 34652, total_loss: 3.6753828525543213
training step: 34653, total_loss: 3.060507297515869
training step: 34654, total_loss: 4.672163963317871
training step: 34655, total_loss: 3.5396971702575684
training step: 34656, total_loss: 5.514503479003906
training step: 34657, total_loss: 5.72768497467041
training step: 34658, total_loss: 5.002596855163574
training step: 34659, total_loss: 3.4816946983337402
training step: 34660, total_loss: 4.615253448486328
training step: 34661, total_loss: 2.319438934326172
training step: 34662, total_loss: 5.245426177978516
training step: 34663, total_loss: 6.500378608703613
training step: 34664, total_loss: 2.7403833866119385
training step: 34665, total_loss: 5.486975193023682
training step: 34666, total_loss: 6.381272315979004
training step: 34667, total_loss: 3.8561882972717285
training step: 34668, total_loss: 3.0733113288879395
training step: 34669, total_loss: 4.843570709228516
training step: 34670, total_loss: 4.834354400634766
training step: 34671, total_loss: 5.617527484893799
training step: 34672, total_loss: 5.11959981918335
training step: 34673, total_loss: 4.140563011169434
training step: 34674, total_loss: 4.040942192077637
training step: 34675, total_loss: 2.4711461067199707
training step: 34676, total_loss: 2.8636884689331055
training step: 34677, total_loss: 3.487011432647705
training step: 34678, total_loss: 5.395025253295898
training step: 34679, total_loss: 5.1329731941223145
training step: 34680, total_loss: 4.154835224151611
training step: 34681, total_loss: 4.159420013427734
training step: 34682, total_loss: 5.387514114379883
training step: 34683, total_loss: 1.032968521118164
training step: 34684, total_loss: 2.1046435832977295
training step: 34685, total_loss: 4.464372634887695
training step: 34686, total_loss: 6.750713348388672
training step: 34687, total_loss: 3.8215420246124268
training step: 34688, total_loss: 3.4122655391693115
training step: 34689, total_loss: 3.1328580379486084
training step: 34690, total_loss: 5.057570457458496
training step: 34691, total_loss: 3.704228639602661
training step: 34692, total_loss: 5.18873405456543
training step: 34693, total_loss: 3.977586269378662
training step: 34694, total_loss: 5.174537658691406
training step: 34695, total_loss: 3.478471517562866
training step: 34696, total_loss: 4.791788101196289
training step: 34697, total_loss: 5.091325283050537
training step: 34698, total_loss: 4.3195295333862305
training step: 34699, total_loss: 3.41361665725708
training step: 34700, total_loss: 5.799144268035889
training step: 34701, total_loss: 3.945124387741089
training step: 34702, total_loss: 4.703242301940918
training step: 34703, total_loss: 3.9030206203460693
training step: 34704, total_loss: 4.851785182952881
training step: 34705, total_loss: 3.6128592491149902
training step: 34706, total_loss: 5.09321403503418
training step: 34707, total_loss: 4.003033638000488
training step: 34708, total_loss: 4.912972450256348
training step: 34709, total_loss: 5.154597759246826
training step: 34710, total_loss: 4.175783634185791
training step: 34711, total_loss: 3.5342092514038086
training step: 34712, total_loss: 3.100809335708618
training step: 34713, total_loss: 4.34075927734375
training step: 34714, total_loss: 4.231293201446533
training step: 34715, total_loss: 5.192713737487793
training step: 34716, total_loss: 1.2629575729370117
training step: 34717, total_loss: 3.127930164337158
training step: 34718, total_loss: 3.9076173305511475
training step: 34719, total_loss: 4.633725643157959
training step: 34720, total_loss: 4.43535041809082
training step: 34721, total_loss: 4.179343223571777
training step: 34722, total_loss: 5.886615753173828
training step: 34723, total_loss: 3.8138279914855957
training step: 34724, total_loss: 3.5249271392822266
training step: 34725, total_loss: 4.564398288726807
training step: 34726, total_loss: 6.172192096710205
training step: 34727, total_loss: 4.1241912841796875
training step: 34728, total_loss: 4.482083797454834
training step: 34729, total_loss: 2.9392523765563965
training step: 34730, total_loss: 3.632688045501709
training step: 34731, total_loss: 3.405256748199463
training step: 34732, total_loss: 2.3459861278533936
training step: 34733, total_loss: 4.197392463684082
training step: 34734, total_loss: 3.796438217163086
training step: 34735, total_loss: 6.267618179321289
training step: 34736, total_loss: 4.878513336181641
training step: 34737, total_loss: 4.513879776000977
training step: 34738, total_loss: 5.937901496887207
training step: 34739, total_loss: 4.042909145355225
training step: 34740, total_loss: 5.214994430541992
training step: 34741, total_loss: 5.412154197692871
training step: 34742, total_loss: 4.498663902282715
training step: 34743, total_loss: 4.486867904663086
training step: 34744, total_loss: 4.273696422576904
training step: 34745, total_loss: 4.535274505615234
training step: 34746, total_loss: 5.263481140136719
training step: 34747, total_loss: 5.593608856201172
training step: 34748, total_loss: 4.600680828094482
training step: 34749, total_loss: 4.226853370666504
training step: 34750, total_loss: 4.442049026489258
training step: 34751, total_loss: 3.4886200428009033
training step: 34752, total_loss: 5.5407867431640625
training step: 34753, total_loss: 3.6609702110290527
training step: 34754, total_loss: 3.8791379928588867
training step: 34755, total_loss: 5.275396347045898
training step: 34756, total_loss: 3.8690614700317383
training step: 34757, total_loss: 4.91471004486084
training step: 34758, total_loss: 2.3935794830322266
training step: 34759, total_loss: 5.132730960845947
training step: 34760, total_loss: 5.066186904907227
training step: 34761, total_loss: 4.126216411590576
training step: 34762, total_loss: 5.101278305053711
training step: 34763, total_loss: 4.369617462158203
training step: 34764, total_loss: 5.64045524597168
training step: 34765, total_loss: 2.9360389709472656
training step: 34766, total_loss: 3.6572649478912354
training step: 34767, total_loss: 4.788596153259277
training step: 34768, total_loss: 4.894413948059082
training step: 34769, total_loss: 2.455775260925293
training step: 34770, total_loss: 3.414440631866455
training step: 34771, total_loss: 2.860872745513916
training step: 34772, total_loss: 5.744872093200684
training step: 34773, total_loss: 5.4797797203063965
training step: 34774, total_loss: 5.495693206787109
training step: 34775, total_loss: 5.057991981506348
training step: 34776, total_loss: 5.032259941101074
training step: 34777, total_loss: 3.251889705657959
training step: 34778, total_loss: 4.496288299560547
training step: 34779, total_loss: 5.988242149353027
training step: 34780, total_loss: 3.9753963947296143
training step: 34781, total_loss: 5.1661176681518555
training step: 34782, total_loss: 3.4263877868652344
training step: 34783, total_loss: 4.838320732116699
training step: 34784, total_loss: 3.2121379375457764
training step: 34785, total_loss: 4.879161834716797
training step: 34786, total_loss: 4.658797264099121
training step: 34787, total_loss: 4.2411603927612305
training step: 34788, total_loss: 4.786590576171875
training step: 34789, total_loss: 4.649483680725098
training step: 34790, total_loss: 4.482051849365234
training step: 34791, total_loss: 4.545753479003906
training step: 34792, total_loss: 4.381941318511963
training step: 34793, total_loss: 4.109386444091797
training step: 34794, total_loss: 2.741459608078003
training step: 34795, total_loss: 1.4490141868591309
training step: 34796, total_loss: 4.53734827041626
training step: 34797, total_loss: 4.329102039337158
training step: 34798, total_loss: 6.856080055236816
training step: 34799, total_loss: 3.3869411945343018
training step: 34800, total_loss: 6.488574981689453
training step: 34801, total_loss: 4.184409141540527
training step: 34802, total_loss: 5.027707099914551
training step: 34803, total_loss: 4.604918956756592
training step: 34804, total_loss: 4.9048261642456055
training step: 34805, total_loss: 4.476418495178223
training step: 34806, total_loss: 4.6420512199401855
training step: 34807, total_loss: 3.511580467224121
training step: 34808, total_loss: 4.553191661834717
training step: 34809, total_loss: 4.844265937805176
training step: 34810, total_loss: 3.8295416831970215
training step: 34811, total_loss: 5.548919200897217
training step: 34812, total_loss: 4.543516159057617
training step: 34813, total_loss: 5.044882774353027
training step: 34814, total_loss: 2.6565399169921875
training step: 34815, total_loss: 3.406057357788086
training step: 34816, total_loss: 4.418020725250244
training step: 34817, total_loss: 3.8243768215179443
training step: 34818, total_loss: 4.762670993804932
training step: 34819, total_loss: 4.022591590881348
training step: 34820, total_loss: 1.1663634777069092
training step: 34821, total_loss: 2.2438673973083496
training step: 34822, total_loss: 4.865670680999756
training step: 34823, total_loss: 4.547325134277344
training step: 34824, total_loss: 3.4435510635375977
training step: 34825, total_loss: 5.622878074645996
training step: 34826, total_loss: 3.122657299041748
training step: 34827, total_loss: 4.754759788513184
training step: 34828, total_loss: 5.126579284667969
training step: 34829, total_loss: 4.054019927978516
training step: 34830, total_loss: 4.817091941833496
training step: 34831, total_loss: 4.504086017608643
training step: 34832, total_loss: 6.024185657501221
training step: 34833, total_loss: 4.145417213439941
training step: 34834, total_loss: 5.056614875793457
training step: 34835, total_loss: 5.519992351531982
training step: 34836, total_loss: 3.8629794120788574
training step: 34837, total_loss: 2.2388510704040527
training step: 34838, total_loss: 4.312869548797607
training step: 34839, total_loss: 5.260306358337402
training step: 34840, total_loss: 2.4869349002838135
training step: 34841, total_loss: 4.962887287139893
training step: 34842, total_loss: 5.780734062194824
training step: 34843, total_loss: 4.385143756866455
training step: 34844, total_loss: 2.4122672080993652
training step: 34845, total_loss: 4.013974666595459
training step: 34846, total_loss: 3.9600625038146973
training step: 34847, total_loss: 6.137599468231201
training step: 34848, total_loss: 3.4004249572753906
training step: 34849, total_loss: 4.314957618713379
training step: 34850, total_loss: 3.884791135787964
training step: 34851, total_loss: 4.819491863250732
training step: 34852, total_loss: 4.957408905029297
training step: 34853, total_loss: 4.725327491760254
training step: 34854, total_loss: 4.109498023986816
training step: 34855, total_loss: 3.701075553894043
training step: 34856, total_loss: 2.5361456871032715
training step: 34857, total_loss: 3.2948856353759766
training step: 34858, total_loss: 3.6136960983276367
training step: 34859, total_loss: 2.958125114440918
training step: 34860, total_loss: 6.079224586486816
training step: 34861, total_loss: 5.593507766723633
training step: 34862, total_loss: 3.5431971549987793
training step: 34863, total_loss: 4.132682800292969
training step: 34864, total_loss: 1.1177138090133667
training step: 34865, total_loss: 2.7503437995910645
training step: 34866, total_loss: 4.790733337402344
training step: 34867, total_loss: 3.652071952819824
training step: 34868, total_loss: 4.4184370040893555
training step: 34869, total_loss: 4.545736312866211
training step: 34870, total_loss: 6.752318382263184
training step: 34871, total_loss: 2.666184425354004
training step: 34872, total_loss: 4.409059524536133
training step: 34873, total_loss: 3.6660075187683105
training step: 34874, total_loss: 3.4877212047576904
training step: 34875, total_loss: 4.149699687957764
training step: 34876, total_loss: 6.323424339294434
training step: 34877, total_loss: 3.305572032928467
training step: 34878, total_loss: 3.934675693511963
training step: 34879, total_loss: 3.6177430152893066
training step: 34880, total_loss: 4.490004539489746
training step: 34881, total_loss: 3.516552448272705
training step: 34882, total_loss: 4.174506187438965
training step: 34883, total_loss: 5.542055606842041
training step: 34884, total_loss: 4.772974967956543
training step: 34885, total_loss: 5.198200225830078
training step: 34886, total_loss: 4.408494472503662
training step: 34887, total_loss: 5.073364734649658
training step: 34888, total_loss: 3.93086576461792
training step: 34889, total_loss: 3.9400815963745117
training step: 34890, total_loss: 6.446125030517578
training step: 34891, total_loss: 3.658822536468506
training step: 34892, total_loss: 2.9879631996154785
training step: 34893, total_loss: 6.305733680725098
training step: 34894, total_loss: 3.5258049964904785
training step: 34895, total_loss: 5.917904376983643
training step: 34896, total_loss: 4.277230262756348
training step: 34897, total_loss: 5.214971542358398
training step: 34898, total_loss: 3.913705348968506
training step: 34899, total_loss: 5.390356540679932
training step: 34900, total_loss: 6.237337589263916
training step: 34901, total_loss: 5.090034484863281
training step: 34902, total_loss: 4.895677089691162
training step: 34903, total_loss: 3.530116081237793
training step: 34904, total_loss: 5.139917373657227
training step: 34905, total_loss: 4.719938278198242
training step: 34906, total_loss: 4.722750663757324
training step: 34907, total_loss: 3.4752960205078125
training step: 34908, total_loss: 4.266204833984375
training step: 34909, total_loss: 5.365785598754883
training step: 34910, total_loss: 4.955104827880859
training step: 34911, total_loss: 3.8284521102905273
training step: 34912, total_loss: 2.6609292030334473
training step: 34913, total_loss: 4.548285484313965
training step: 34914, total_loss: 5.414843559265137
training step: 34915, total_loss: 2.4212403297424316
training step: 34916, total_loss: 5.26312780380249
training step: 34917, total_loss: 3.160527229309082
training step: 34918, total_loss: 3.781548500061035
training step: 34919, total_loss: 3.0598807334899902
training step: 34920, total_loss: 3.4608383178710938
training step: 34921, total_loss: 4.435956001281738
training step: 34922, total_loss: 4.4709153175354
training step: 34923, total_loss: 5.451529502868652
training step: 34924, total_loss: 2.718250274658203
training step: 34925, total_loss: 4.045827865600586
training step: 34926, total_loss: 1.4296437501907349
training step: 34927, total_loss: 5.22592306137085
training step: 34928, total_loss: 2.8719143867492676
training step: 34929, total_loss: 3.0875511169433594
training step: 34930, total_loss: 3.9296140670776367
training step: 34931, total_loss: 5.235093116760254
training step: 34932, total_loss: 4.929508686065674
training step: 34933, total_loss: 2.922083616256714
training step: 34934, total_loss: 3.461965560913086
training step: 34935, total_loss: 4.5615339279174805
training step: 34936, total_loss: 2.77164626121521
training step: 34937, total_loss: 3.1967687606811523
training step: 34938, total_loss: 3.957279682159424
training step: 34939, total_loss: 4.5887603759765625
training step: 34940, total_loss: 5.086475372314453
training step: 34941, total_loss: 4.828142166137695
training step: 34942, total_loss: 4.411294460296631
training step: 34943, total_loss: 3.292989492416382
training step: 34944, total_loss: 4.464020729064941
training step: 34945, total_loss: 4.877285003662109
training step: 34946, total_loss: 4.3930840492248535
training step: 34947, total_loss: 3.604900360107422
training step: 34948, total_loss: 6.61305570602417
training step: 34949, total_loss: 3.0090317726135254
training step: 34950, total_loss: 4.924202919006348
training step: 34951, total_loss: 3.878887414932251
training step: 34952, total_loss: 4.2764692306518555
training step: 34953, total_loss: 4.506504058837891
training step: 34954, total_loss: 5.2983078956604
training step: 34955, total_loss: 3.2065186500549316
training step: 34956, total_loss: 2.3735058307647705
training step: 34957, total_loss: 2.939164161682129
training step: 34958, total_loss: 4.382570743560791
training step: 34959, total_loss: 5.507357597351074
training step: 34960, total_loss: 4.463902473449707
training step: 34961, total_loss: 0.700114905834198
training step: 34962, total_loss: 5.149571418762207
training step: 34963, total_loss: 5.6716156005859375
training step: 34964, total_loss: 3.957988977432251
training step: 34965, total_loss: 1.3052209615707397
training step: 34966, total_loss: 5.781251430511475
training step: 34967, total_loss: 5.549441337585449
training step: 34968, total_loss: 3.5100128650665283
training step: 34969, total_loss: 0.7252520322799683
training step: 34970, total_loss: 3.814180612564087
training step: 34971, total_loss: 3.8134913444519043
training step: 34972, total_loss: 3.625256061553955
training step: 34973, total_loss: 4.324288368225098
training step: 34974, total_loss: 4.3889265060424805
training step: 34975, total_loss: 4.751511573791504
training step: 34976, total_loss: 5.789125442504883
training step: 34977, total_loss: 5.098756790161133
training step: 34978, total_loss: 5.058221817016602
training step: 34979, total_loss: 2.909374713897705
training step: 34980, total_loss: 5.743151664733887
training step: 34981, total_loss: 5.623079299926758
training step: 34982, total_loss: 3.623112916946411
training step: 34983, total_loss: 5.1391401290893555
training step: 34984, total_loss: 5.187341690063477
training step: 34985, total_loss: 3.1462268829345703
training step: 34986, total_loss: 6.613072395324707
training step: 34987, total_loss: 0.7053913474082947
training step: 34988, total_loss: 5.25830078125
training step: 34989, total_loss: 4.797031879425049
training step: 34990, total_loss: 5.081467628479004
training step: 34991, total_loss: 6.283230781555176
training step: 34992, total_loss: 3.287869453430176
training step: 34993, total_loss: 3.6564371585845947
training step: 34994, total_loss: 6.021855354309082
training step: 34995, total_loss: 5.082315444946289
training step: 34996, total_loss: 3.8057329654693604
training step: 34997, total_loss: 3.939725637435913
training step: 34998, total_loss: 4.207033157348633
training step: 34999, total_loss: 4.507323741912842
training step: 35000, total_loss: 3.7401514053344727
training step: 35001, total_loss: 3.186922788619995
training step: 35002, total_loss: 3.1903045177459717
training step: 35003, total_loss: 3.4548964500427246
training step: 35004, total_loss: 5.927020072937012
training step: 35005, total_loss: 4.464285850524902
training step: 35006, total_loss: 3.8238186836242676
training step: 35007, total_loss: 3.859391450881958
training step: 35008, total_loss: 4.371654987335205
training step: 35009, total_loss: 4.538578033447266
training step: 35010, total_loss: 4.4761528968811035
training step: 35011, total_loss: 5.45380973815918
training step: 35012, total_loss: 6.589809894561768
training step: 35013, total_loss: 5.657218933105469
training step: 35014, total_loss: 5.474306583404541
training step: 35015, total_loss: 4.935136318206787
training step: 35016, total_loss: 5.995763301849365
training step: 35017, total_loss: 2.491511344909668
training step: 35018, total_loss: 4.17061710357666
training step: 35019, total_loss: 2.7959208488464355
training step: 35020, total_loss: 4.32688570022583
training step: 35021, total_loss: 5.183132171630859
training step: 35022, total_loss: 5.025783538818359
training step: 35023, total_loss: 3.599978446960449
training step: 35024, total_loss: 5.219459533691406
training step: 35025, total_loss: 5.646787643432617
training step: 35026, total_loss: 4.021783828735352
training step: 35027, total_loss: 5.668971061706543
training step: 35028, total_loss: 5.20053768157959
training step: 35029, total_loss: 5.656805038452148
training step: 35030, total_loss: 4.050897598266602
training step: 35031, total_loss: 4.628094673156738
training step: 35032, total_loss: 4.275217533111572
training step: 35033, total_loss: 3.6727123260498047
training step: 35034, total_loss: 5.467869758605957
training step: 35035, total_loss: 5.123029708862305
training step: 35036, total_loss: 3.758068561553955
training step: 35037, total_loss: 2.5195064544677734
training step: 35038, total_loss: 3.5355191230773926
training step: 35039, total_loss: 4.248490810394287
training step: 35040, total_loss: 4.806018829345703
training step: 35041, total_loss: 2.2893753051757812
training step: 35042, total_loss: 3.80116868019104
training step: 35043, total_loss: 6.501880168914795
training step: 35044, total_loss: 5.539406776428223
training step: 35045, total_loss: 4.061364650726318
training step: 35046, total_loss: 5.584620475769043
training step: 35047, total_loss: 6.102331638336182
training step: 35048, total_loss: 3.1604511737823486
training step: 35049, total_loss: 2.4919886589050293
training step: 35050, total_loss: 5.655482292175293
training step: 35051, total_loss: 2.9494926929473877
training step: 35052, total_loss: 5.5343098640441895
training step: 35053, total_loss: 4.026587009429932
training step: 35054, total_loss: 4.8764214515686035
training step: 35055, total_loss: 4.07473611831665
training step: 35056, total_loss: 4.56026554107666
training step: 35057, total_loss: 4.740529537200928
training step: 35058, total_loss: 3.1845216751098633
training step: 35059, total_loss: 4.252316474914551
training step: 35060, total_loss: 4.1723432540893555
training step: 35061, total_loss: 5.920978546142578
training step: 35062, total_loss: 0.8899001479148865
training step: 35063, total_loss: 5.716920375823975
training step: 35064, total_loss: 4.1655073165893555
training step: 35065, total_loss: 3.932140350341797
training step: 35066, total_loss: 1.3121027946472168
training step: 35067, total_loss: 2.7422287464141846
training step: 35068, total_loss: 3.354793071746826
training step: 35069, total_loss: 5.023188591003418
training step: 35070, total_loss: 2.610480785369873
training step: 35071, total_loss: 3.322873592376709
training step: 35072, total_loss: 4.875175476074219
training step: 35073, total_loss: 2.879836082458496
training step: 35074, total_loss: 5.4751505851745605
training step: 35075, total_loss: 5.655458450317383
training step: 35076, total_loss: 4.650296688079834
training step: 35077, total_loss: 4.076144218444824
training step: 35078, total_loss: 3.17897891998291
training step: 35079, total_loss: 4.677643775939941
training step: 35080, total_loss: 4.26584529876709
training step: 35081, total_loss: 5.448056221008301
training step: 35082, total_loss: 5.289170265197754
training step: 35083, total_loss: 5.210633277893066
training step: 35084, total_loss: 3.5968408584594727
training step: 35085, total_loss: 4.165991306304932
training step: 35086, total_loss: 2.8378968238830566
training step: 35087, total_loss: 4.230641841888428
training step: 35088, total_loss: 4.129143714904785
training step: 35089, total_loss: 4.344558238983154
training step: 35090, total_loss: 6.879366874694824
training step: 35091, total_loss: 2.4937901496887207
training step: 35092, total_loss: 5.481721878051758
training step: 35093, total_loss: 4.942346096038818
training step: 35094, total_loss: 3.5275707244873047
training step: 35095, total_loss: 1.2020459175109863
training step: 35096, total_loss: 5.6508307456970215
training step: 35097, total_loss: 4.442444801330566
training step: 35098, total_loss: 5.258504867553711
training step: 35099, total_loss: 5.350991249084473
training step: 35100, total_loss: 5.205531120300293
training step: 35101, total_loss: 4.388503074645996
training step: 35102, total_loss: 6.410001754760742
training step: 35103, total_loss: 4.824257850646973
training step: 35104, total_loss: 5.437129020690918
training step: 35105, total_loss: 2.1704659461975098
training step: 35106, total_loss: 5.129755973815918
training step: 35107, total_loss: 4.392054557800293
training step: 35108, total_loss: 4.80552864074707
training step: 35109, total_loss: 3.9768927097320557
training step: 35110, total_loss: 2.911057949066162
training step: 35111, total_loss: 5.298308372497559
training step: 35112, total_loss: 4.192786693572998
training step: 35113, total_loss: 5.043741703033447
training step: 35114, total_loss: 4.552818298339844
training step: 35115, total_loss: 5.571272850036621
training step: 35116, total_loss: 4.770641326904297
training step: 35117, total_loss: 5.3793253898620605
training step: 35118, total_loss: 3.4552290439605713
training step: 35119, total_loss: 3.4451732635498047
training step: 35120, total_loss: 1.9884926080703735
training step: 35121, total_loss: 2.753077983856201
training step: 35122, total_loss: 3.306138038635254
training step: 35123, total_loss: 4.601738929748535
training step: 35124, total_loss: 3.3115673065185547
training step: 35125, total_loss: 4.761051177978516
training step: 35126, total_loss: 3.804306983947754
training step: 35127, total_loss: 2.748368978500366
training step: 35128, total_loss: 4.03967809677124
training step: 35129, total_loss: 1.0877676010131836
training step: 35130, total_loss: 3.6784324645996094
training step: 35131, total_loss: 3.760004997253418
training step: 35132, total_loss: 3.200476884841919
training step: 35133, total_loss: 4.725409030914307
training step: 35134, total_loss: 3.8331451416015625
training step: 35135, total_loss: 5.05902624130249
training step: 35136, total_loss: 3.8738033771514893
training step: 35137, total_loss: 4.77461576461792
training step: 35138, total_loss: 3.99106502532959
training step: 35139, total_loss: 2.6630988121032715
training step: 35140, total_loss: 5.750557899475098
training step: 35141, total_loss: 5.692197799682617
training step: 35142, total_loss: 3.183201789855957
training step: 35143, total_loss: 5.7261176109313965
training step: 35144, total_loss: 0.7723561525344849
training step: 35145, total_loss: 4.769216060638428
training step: 35146, total_loss: 4.945947647094727
training step: 35147, total_loss: 6.03159236907959
training step: 35148, total_loss: 3.8552632331848145
training step: 35149, total_loss: 3.7188944816589355
training step: 35150, total_loss: 4.000197410583496
training step: 35151, total_loss: 3.696503162384033
training step: 35152, total_loss: 3.7763755321502686
training step: 35153, total_loss: 5.244763374328613
training step: 35154, total_loss: 3.8797218799591064
training step: 35155, total_loss: 2.949428081512451
training step: 35156, total_loss: 4.073853492736816
training step: 35157, total_loss: 4.510591983795166
training step: 35158, total_loss: 2.9490809440612793
training step: 35159, total_loss: 3.8607988357543945
training step: 35160, total_loss: 3.6555228233337402
training step: 35161, total_loss: 4.497951507568359
training step: 35162, total_loss: 4.967343330383301
training step: 35163, total_loss: 4.738865852355957
training step: 35164, total_loss: 5.212965965270996
training step: 35165, total_loss: 5.389568328857422
training step: 35166, total_loss: 2.6050400733947754
training step: 35167, total_loss: 5.519834518432617
training step: 35168, total_loss: 4.790689468383789
training step: 35169, total_loss: 4.115171432495117
training step: 35170, total_loss: 5.116814613342285
training step: 35171, total_loss: 3.870720863342285
training step: 35172, total_loss: 6.061949729919434
training step: 35173, total_loss: 5.272233009338379
training step: 35174, total_loss: 5.503513336181641
training step: 35175, total_loss: 5.67445707321167
training step: 35176, total_loss: 5.440267562866211
training step: 35177, total_loss: 3.6730260848999023
training step: 35178, total_loss: 3.9721741676330566
training step: 35179, total_loss: 3.975686550140381
training step: 35180, total_loss: 4.670133590698242
training step: 35181, total_loss: 4.624661445617676
training step: 35182, total_loss: 3.813727855682373
training step: 35183, total_loss: 5.950267314910889
training step: 35184, total_loss: 6.204891204833984
training step: 35185, total_loss: 3.3085412979125977
training step: 35186, total_loss: 4.558521270751953
training step: 35187, total_loss: 4.190995216369629
training step: 35188, total_loss: 3.154432773590088
training step: 35189, total_loss: 5.810185432434082
training step: 35190, total_loss: 4.980315208435059
training step: 35191, total_loss: 4.520444869995117
training step: 35192, total_loss: 5.037835121154785
training step: 35193, total_loss: 2.571237087249756
training step: 35194, total_loss: 5.4359588623046875
training step: 35195, total_loss: 2.09519624710083
training step: 35196, total_loss: 4.751681804656982
training step: 35197, total_loss: 5.282211780548096
training step: 35198, total_loss: 4.393564701080322
training step: 35199, total_loss: 2.374011278152466
training step: 35200, total_loss: 2.6659555435180664
training step: 35201, total_loss: 4.836847305297852
training step: 35202, total_loss: 3.688767194747925
training step: 35203, total_loss: 6.706340789794922
training step: 35204, total_loss: 4.598696231842041
training step: 35205, total_loss: 3.1575918197631836
training step: 35206, total_loss: 3.9943981170654297
training step: 35207, total_loss: 5.431963920593262
training step: 35208, total_loss: 4.390693664550781
training step: 35209, total_loss: 4.3259077072143555
training step: 35210, total_loss: 2.8104166984558105
training step: 35211, total_loss: 4.945091724395752
training step: 35212, total_loss: 4.666070461273193
training step: 35213, total_loss: 4.376359939575195
training step: 35214, total_loss: 4.577219009399414
training step: 35215, total_loss: 3.980466365814209
training step: 35216, total_loss: 2.9525794982910156
training step: 35217, total_loss: 3.013922929763794
training step: 35218, total_loss: 3.329138994216919
training step: 35219, total_loss: 4.7782464027404785
training step: 35220, total_loss: 4.6048383712768555
training step: 35221, total_loss: 4.237902641296387
training step: 35222, total_loss: 4.655844688415527
training step: 35223, total_loss: 4.049877166748047
training step: 35224, total_loss: 4.709547996520996
training step: 35225, total_loss: 5.572776794433594
training step: 35226, total_loss: 3.0213491916656494
training step: 35227, total_loss: 4.927690029144287
training step: 35228, total_loss: 4.908208847045898
training step: 35229, total_loss: 4.236812591552734
training step: 35230, total_loss: 4.81962776184082
training step: 35231, total_loss: 4.417592525482178
training step: 35232, total_loss: 4.856688022613525
training step: 35233, total_loss: 3.617076873779297
training step: 35234, total_loss: 4.465114116668701
training step: 35235, total_loss: 2.278041124343872
training step: 35236, total_loss: 4.613300323486328
training step: 35237, total_loss: 4.406017303466797
training step: 35238, total_loss: 4.220895290374756
training step: 35239, total_loss: 5.328850746154785
training step: 35240, total_loss: 5.282055854797363
training step: 35241, total_loss: 4.40146541595459
training step: 35242, total_loss: 2.8795480728149414
training step: 35243, total_loss: 4.932373046875
training step: 35244, total_loss: 5.236484527587891
training step: 35245, total_loss: 3.1455750465393066
training step: 35246, total_loss: 4.023279666900635
training step: 35247, total_loss: 4.4635796546936035
training step: 35248, total_loss: 3.397810935974121
training step: 35249, total_loss: 2.8007969856262207
training step: 35250, total_loss: 3.843369960784912
training step: 35251, total_loss: 3.455674648284912
training step: 35252, total_loss: 2.994363784790039
training step: 35253, total_loss: 1.1769620180130005
training step: 35254, total_loss: 4.920191287994385
training step: 35255, total_loss: 4.757724285125732
training step: 35256, total_loss: 5.195145606994629
training step: 35257, total_loss: 4.174180030822754
training step: 35258, total_loss: 4.449521541595459
training step: 35259, total_loss: 4.73124361038208
training step: 35260, total_loss: 5.20751953125
training step: 35261, total_loss: 3.9849166870117188
training step: 35262, total_loss: 4.165787220001221
training step: 35263, total_loss: 3.7486915588378906
training step: 35264, total_loss: 3.553555965423584
training step: 35265, total_loss: 5.98578405380249
training step: 35266, total_loss: 4.311407089233398
training step: 35267, total_loss: 4.9813690185546875
training step: 35268, total_loss: 4.698409080505371
training step: 35269, total_loss: 6.762454032897949
training step: 35270, total_loss: 5.549927234649658
training step: 35271, total_loss: 6.350287437438965
training step: 35272, total_loss: 4.320615291595459
training step: 35273, total_loss: 4.521020412445068
training step: 35274, total_loss: 2.308352470397949
training step: 35275, total_loss: 4.511953353881836
training step: 35276, total_loss: 4.8314208984375
training step: 35277, total_loss: 3.194721221923828
training step: 35278, total_loss: 5.525872230529785
training step: 35279, total_loss: 3.6152267456054688
training step: 35280, total_loss: 3.245199203491211
training step: 35281, total_loss: 4.887805938720703
training step: 35282, total_loss: 2.3236896991729736
training step: 35283, total_loss: 5.526297569274902
training step: 35284, total_loss: 3.50994873046875
training step: 35285, total_loss: 4.9261884689331055
training step: 35286, total_loss: 4.620999813079834
training step: 35287, total_loss: 5.16556978225708
training step: 35288, total_loss: 4.502654552459717
training step: 35289, total_loss: 3.669950008392334
training step: 35290, total_loss: 5.023341178894043
training step: 35291, total_loss: 4.0262227058410645
training step: 35292, total_loss: 2.527103900909424
training step: 35293, total_loss: 4.113733291625977
training step: 35294, total_loss: 4.024842739105225
training step: 35295, total_loss: 3.621588706970215
training step: 35296, total_loss: 4.505035400390625
training step: 35297, total_loss: 4.468535900115967
training step: 35298, total_loss: 5.365970611572266
training step: 35299, total_loss: 5.396644115447998
training step: 35300, total_loss: 4.303842067718506
training step: 35301, total_loss: 3.3460850715637207
training step: 35302, total_loss: 4.444007873535156
training step: 35303, total_loss: 3.614006519317627
training step: 35304, total_loss: 3.4799489974975586
training step: 35305, total_loss: 4.304945945739746
training step: 35306, total_loss: 4.529416084289551
training step: 35307, total_loss: 3.7362656593322754
training step: 35308, total_loss: 5.012202262878418
training step: 35309, total_loss: 0.9015651941299438
training step: 35310, total_loss: 6.427816390991211
training step: 35311, total_loss: 5.193068027496338
training step: 35312, total_loss: 3.6977853775024414
training step: 35313, total_loss: 4.639544486999512
training step: 35314, total_loss: 4.496893405914307
training step: 35315, total_loss: 6.024308204650879
training step: 35316, total_loss: 4.290188789367676
training step: 35317, total_loss: 2.771684169769287
training step: 35318, total_loss: 5.242703437805176
training step: 35319, total_loss: 2.806983470916748
training step: 35320, total_loss: 4.182807445526123
training step: 35321, total_loss: 5.950177192687988
training step: 35322, total_loss: 3.5367789268493652
training step: 35323, total_loss: 3.9374780654907227
training step: 35324, total_loss: 3.2589306831359863
training step: 35325, total_loss: 4.141828536987305
training step: 35326, total_loss: 5.437471866607666
training step: 35327, total_loss: 6.275777816772461
training step: 35328, total_loss: 5.98164176940918
training step: 35329, total_loss: 4.299363136291504
training step: 35330, total_loss: 5.292965412139893
training step: 35331, total_loss: 5.213831901550293
training step: 35332, total_loss: 3.551827907562256
training step: 35333, total_loss: 4.760721206665039
training step: 35334, total_loss: 4.652912616729736
training step: 35335, total_loss: 3.459712028503418
training step: 35336, total_loss: 4.869928359985352
training step: 35337, total_loss: 4.2872314453125
training step: 35338, total_loss: 3.994332790374756
training step: 35339, total_loss: 5.571935176849365
training step: 35340, total_loss: 3.097510576248169
training step: 35341, total_loss: 3.8657987117767334
training step: 35342, total_loss: 3.91579008102417
training step: 35343, total_loss: 3.361689567565918
training step: 35344, total_loss: 5.489438056945801
training step: 35345, total_loss: 6.2256879806518555
training step: 35346, total_loss: 5.518032550811768
training step: 35347, total_loss: 5.185277462005615
training step: 35348, total_loss: 5.069602966308594
training step: 35349, total_loss: 3.0965194702148438
training step: 35350, total_loss: 3.983952522277832
training step: 35351, total_loss: 4.073212623596191
training step: 35352, total_loss: 4.8090596199035645
training step: 35353, total_loss: 4.343330383300781
training step: 35354, total_loss: 4.524575710296631
training step: 35355, total_loss: 2.6010313034057617
training step: 35356, total_loss: 5.016218662261963
training step: 35357, total_loss: 4.772548675537109
training step: 35358, total_loss: 5.8058671951293945
training step: 35359, total_loss: 4.5766282081604
training step: 35360, total_loss: 4.311705589294434
training step: 35361, total_loss: 4.265073776245117
training step: 35362, total_loss: 3.4772121906280518
training step: 35363, total_loss: 4.408536434173584
training step: 35364, total_loss: 4.013125896453857
training step: 35365, total_loss: 3.9468579292297363
training step: 35366, total_loss: 3.38741135597229
training step: 35367, total_loss: 4.8131303787231445
training step: 35368, total_loss: 4.3018574714660645
training step: 35369, total_loss: 3.762584686279297
training step: 35370, total_loss: 3.9603285789489746
training step: 35371, total_loss: 5.161322593688965
training step: 35372, total_loss: 1.9785614013671875
training step: 35373, total_loss: 4.796295642852783
training step: 35374, total_loss: 5.30089807510376
training step: 35375, total_loss: 4.089174747467041
training step: 35376, total_loss: 4.484330177307129
training step: 35377, total_loss: 4.488167762756348
training step: 35378, total_loss: 5.359330654144287
training step: 35379, total_loss: 4.661586761474609
training step: 35380, total_loss: 4.130529880523682
training step: 35381, total_loss: 3.197748899459839
training step: 35382, total_loss: 3.968966007232666
training step: 35383, total_loss: 5.18519401550293
training step: 35384, total_loss: 4.891044616699219
training step: 35385, total_loss: 4.355289459228516
training step: 35386, total_loss: 3.4010632038116455
training step: 35387, total_loss: 4.415804862976074
training step: 35388, total_loss: 4.700104713439941
training step: 35389, total_loss: 2.834995746612549
training step: 35390, total_loss: 3.7222208976745605
training step: 35391, total_loss: 5.144827842712402
training step: 35392, total_loss: 6.238442897796631
training step: 35393, total_loss: 3.7175228595733643
training step: 35394, total_loss: 4.803553581237793
training step: 35395, total_loss: 3.285789966583252
training step: 35396, total_loss: 4.464962959289551
training step: 35397, total_loss: 3.4740703105926514
training step: 35398, total_loss: 3.3395729064941406
training step: 35399, total_loss: 3.5835909843444824
training step: 35400, total_loss: 4.253232955932617
training step: 35401, total_loss: 3.3163766860961914
training step: 35402, total_loss: 6.1320013999938965
training step: 35403, total_loss: 5.1243367195129395
training step: 35404, total_loss: 3.4742233753204346
training step: 35405, total_loss: 4.010637283325195
training step: 35406, total_loss: 2.7382030487060547
training step: 35407, total_loss: 4.912847518920898
training step: 35408, total_loss: 5.021883964538574
training step: 35409, total_loss: 3.6543824672698975
training step: 35410, total_loss: 5.675251007080078
training step: 35411, total_loss: 4.584438323974609
training step: 35412, total_loss: 3.7438716888427734
training step: 35413, total_loss: 4.798576354980469
training step: 35414, total_loss: 6.086287975311279
training step: 35415, total_loss: 5.326675891876221
training step: 35416, total_loss: 4.636482238769531
training step: 35417, total_loss: 5.562655448913574
training step: 35418, total_loss: 5.630806922912598
training step: 35419, total_loss: 4.150464057922363
training step: 35420, total_loss: 5.74224853515625
training step: 35421, total_loss: 3.0370020866394043
training step: 35422, total_loss: 5.185206890106201
training step: 35423, total_loss: 3.4531331062316895
training step: 35424, total_loss: 4.7302727699279785
training step: 35425, total_loss: 3.083428382873535
training step: 35426, total_loss: 3.972745418548584
training step: 35427, total_loss: 5.444872856140137
training step: 35428, total_loss: 4.820868968963623
training step: 35429, total_loss: 6.3705315589904785
training step: 35430, total_loss: 4.05690860748291
training step: 35431, total_loss: 5.281889915466309
training step: 35432, total_loss: 5.989695072174072
training step: 35433, total_loss: 6.282919406890869
training step: 35434, total_loss: 4.692280292510986
training step: 35435, total_loss: 4.036652088165283
training step: 35436, total_loss: 4.727163791656494
training step: 35437, total_loss: 5.005605220794678
training step: 35438, total_loss: 3.3010196685791016
training step: 35439, total_loss: 4.164953231811523
training step: 35440, total_loss: 3.230935573577881
training step: 35441, total_loss: 6.457125186920166
training step: 35442, total_loss: 4.38143253326416
training step: 35443, total_loss: 3.8839640617370605
training step: 35444, total_loss: 2.7162532806396484
training step: 35445, total_loss: 4.959909439086914
training step: 35446, total_loss: 4.950542449951172
training step: 35447, total_loss: 3.5415611267089844
training step: 35448, total_loss: 4.952279090881348
training step: 35449, total_loss: 3.04784893989563
training step: 35450, total_loss: 5.061161518096924
training step: 35451, total_loss: 4.154684066772461
training step: 35452, total_loss: 4.912899971008301
training step: 35453, total_loss: 4.905649662017822
training step: 35454, total_loss: 4.636244297027588
training step: 35455, total_loss: 4.611752510070801
training step: 35456, total_loss: 4.456630706787109
training step: 35457, total_loss: 4.676072597503662
training step: 35458, total_loss: 5.402554512023926
training step: 35459, total_loss: 4.820033073425293
training step: 35460, total_loss: 4.032169342041016
training step: 35461, total_loss: 5.4373579025268555
training step: 35462, total_loss: 5.174016952514648
training step: 35463, total_loss: 3.9993062019348145
training step: 35464, total_loss: 4.844128131866455
training step: 35465, total_loss: 4.470467567443848
training step: 35466, total_loss: 4.154254913330078
training step: 35467, total_loss: 4.286637783050537
training step: 35468, total_loss: 4.797767639160156
training step: 35469, total_loss: 5.15971565246582
training step: 35470, total_loss: 5.793248653411865
training step: 35471, total_loss: 4.342778205871582
training step: 35472, total_loss: 5.538857936859131
training step: 35473, total_loss: 5.0664262771606445
training step: 35474, total_loss: 4.677321910858154
training step: 35475, total_loss: 5.974993705749512
training step: 35476, total_loss: 4.60599422454834
training step: 35477, total_loss: 4.845312118530273
training step: 35478, total_loss: 5.942351818084717
training step: 35479, total_loss: 6.045797348022461
training step: 35480, total_loss: 4.110930442810059
training step: 35481, total_loss: 3.9993510246276855
training step: 35482, total_loss: 4.697005271911621
training step: 35483, total_loss: 5.224527359008789
training step: 35484, total_loss: 5.199621677398682
training step: 35485, total_loss: 4.5774078369140625
training step: 35486, total_loss: 4.474283218383789
training step: 35487, total_loss: 4.699007987976074
training step: 35488, total_loss: 4.160959720611572
training step: 35489, total_loss: 4.424873352050781
training step: 35490, total_loss: 3.852261543273926
training step: 35491, total_loss: 3.92580509185791
training step: 35492, total_loss: 3.725210189819336
training step: 35493, total_loss: 4.623244285583496
training step: 35494, total_loss: 5.92293119430542
training step: 35495, total_loss: 3.7712910175323486
training step: 35496, total_loss: 4.1882643699646
training step: 35497, total_loss: 3.812039375305176
training step: 35498, total_loss: 4.5981245040893555
training step: 35499, total_loss: 4.170670509338379
training step: 35500, total_loss: 4.065116882324219
training step: 35501, total_loss: 5.334962844848633
training step: 35502, total_loss: 4.919946670532227
training step: 35503, total_loss: 4.835844993591309
training step: 35504, total_loss: 4.207980155944824
training step: 35505, total_loss: 4.19654655456543
training step: 35506, total_loss: 5.1410603523254395
training step: 35507, total_loss: 3.1033267974853516
training step: 35508, total_loss: 5.33461856842041
training step: 35509, total_loss: 3.4713897705078125
training step: 35510, total_loss: 6.536168098449707
training step: 35511, total_loss: 4.904266834259033
training step: 35512, total_loss: 4.994011402130127
training step: 35513, total_loss: 4.845247268676758
training step: 35514, total_loss: 4.250934600830078
training step: 35515, total_loss: 4.250762939453125
training step: 35516, total_loss: 4.072929382324219
training step: 35517, total_loss: 4.7988409996032715
training step: 35518, total_loss: 4.51054048538208
training step: 35519, total_loss: 3.674189329147339
training step: 35520, total_loss: 5.422825813293457
training step: 35521, total_loss: 3.780055522918701
training step: 35522, total_loss: 5.217642784118652
training step: 35523, total_loss: 3.2839410305023193
training step: 35524, total_loss: 4.682150363922119
training step: 35525, total_loss: 3.538769245147705
training step: 35526, total_loss: 4.86785364151001
training step: 35527, total_loss: 5.629209518432617
training step: 35528, total_loss: 4.222466945648193
training step: 35529, total_loss: 4.725347518920898
training step: 35530, total_loss: 3.830449342727661
training step: 35531, total_loss: 3.927957534790039
training step: 35532, total_loss: 4.575291633605957
training step: 35533, total_loss: 4.569777011871338
training step: 35534, total_loss: 4.1350507736206055
training step: 35535, total_loss: 6.5090436935424805
training step: 35536, total_loss: 3.864363193511963
training step: 35537, total_loss: 4.600497245788574
training step: 35538, total_loss: 5.3716535568237305
training step: 35539, total_loss: 4.745115756988525
training step: 35540, total_loss: 5.304625511169434
training step: 35541, total_loss: 3.582040548324585
training step: 35542, total_loss: 4.453669548034668
training step: 35543, total_loss: 4.274141311645508
training step: 35544, total_loss: 3.5855979919433594
training step: 35545, total_loss: 4.493124008178711
training step: 35546, total_loss: 3.881143093109131
training step: 35547, total_loss: 4.131380081176758
training step: 35548, total_loss: 2.753791332244873
training step: 35549, total_loss: 4.867182731628418
training step: 35550, total_loss: 5.262730598449707
training step: 35551, total_loss: 4.120377540588379
training step: 35552, total_loss: 4.645496368408203
training step: 35553, total_loss: 3.691321849822998
training step: 35554, total_loss: 3.4708051681518555
training step: 35555, total_loss: 3.6386337280273438
training step: 35556, total_loss: 4.446267127990723
training step: 35557, total_loss: 6.29988431930542
training step: 35558, total_loss: 4.231895923614502
training step: 35559, total_loss: 4.714916706085205
training step: 35560, total_loss: 3.8283424377441406
training step: 35561, total_loss: 4.473823547363281
training step: 35562, total_loss: 4.563486099243164
training step: 35563, total_loss: 4.581979274749756
training step: 35564, total_loss: 5.1772332191467285
training step: 35565, total_loss: 4.605006217956543
training step: 35566, total_loss: 7.81610107421875
training step: 35567, total_loss: 3.247924327850342
training step: 35568, total_loss: 4.043667793273926
training step: 35569, total_loss: 6.335235595703125
training step: 35570, total_loss: 4.735325813293457
training step: 35571, total_loss: 4.69600248336792
training step: 35572, total_loss: 5.25103759765625
training step: 35573, total_loss: 3.461690902709961
training step: 35574, total_loss: 3.507707118988037
training step: 35575, total_loss: 4.921051025390625
training step: 35576, total_loss: 4.856969356536865
training step: 35577, total_loss: 5.1570329666137695
training step: 35578, total_loss: 4.715764999389648
training step: 35579, total_loss: 2.717318296432495
training step: 35580, total_loss: 5.324197769165039
training step: 35581, total_loss: 4.727897644042969
training step: 35582, total_loss: 3.9974780082702637
training step: 35583, total_loss: 4.548922538757324
training step: 35584, total_loss: 1.2310383319854736
training step: 35585, total_loss: 3.993443250656128
training step: 35586, total_loss: 4.721933841705322
training step: 35587, total_loss: 4.26560115814209
training step: 35588, total_loss: 5.502603530883789
training step: 35589, total_loss: 4.625579833984375
training step: 35590, total_loss: 4.671090126037598
training step: 35591, total_loss: 4.395185470581055
training step: 35592, total_loss: 5.299731254577637
training step: 35593, total_loss: 4.079549312591553
training step: 35594, total_loss: 4.223767280578613
training step: 35595, total_loss: 6.222586154937744
training step: 35596, total_loss: 4.300797462463379
training step: 35597, total_loss: 4.564515113830566
training step: 35598, total_loss: 4.926527976989746
training step: 35599, total_loss: 3.6594882011413574
training step: 35600, total_loss: 3.6464321613311768
training step: 35601, total_loss: 2.2797036170959473
training step: 35602, total_loss: 5.069921016693115
training step: 35603, total_loss: 6.142662048339844
training step: 35604, total_loss: 3.7088725566864014
training step: 35605, total_loss: 2.6442060470581055
training step: 35606, total_loss: 6.172152519226074
training step: 35607, total_loss: 4.178051471710205
training step: 35608, total_loss: 4.804553031921387
training step: 35609, total_loss: 4.541668891906738
training step: 35610, total_loss: 5.637115001678467
training step: 35611, total_loss: 5.629315376281738
training step: 35612, total_loss: 3.3707542419433594
training step: 35613, total_loss: 4.388339996337891
training step: 35614, total_loss: 4.258117198944092
training step: 35615, total_loss: 5.355570316314697
training step: 35616, total_loss: 4.93153715133667
training step: 35617, total_loss: 4.298361301422119
training step: 35618, total_loss: 4.246452331542969
training step: 35619, total_loss: 2.5047519207000732
training step: 35620, total_loss: 4.130716800689697
training step: 35621, total_loss: 4.88297176361084
training step: 35622, total_loss: 4.067874908447266
training step: 35623, total_loss: 5.4189453125
training step: 35624, total_loss: 4.003354072570801
training step: 35625, total_loss: 5.50255823135376
training step: 35626, total_loss: 6.016172409057617
training step: 35627, total_loss: 3.5047965049743652
training step: 35628, total_loss: 4.882555961608887
training step: 35629, total_loss: 3.7214150428771973
training step: 35630, total_loss: 4.71203088760376
training step: 35631, total_loss: 4.937724590301514
training step: 35632, total_loss: 4.108404636383057
training step: 35633, total_loss: 5.2316131591796875
training step: 35634, total_loss: 2.808303117752075
training step: 35635, total_loss: 6.2467474937438965
training step: 35636, total_loss: 4.449204444885254
training step: 35637, total_loss: 1.02744722366333
training step: 35638, total_loss: 3.307985544204712
training step: 35639, total_loss: 3.7555251121520996
training step: 35640, total_loss: 5.162503719329834
training step: 35641, total_loss: 4.9082536697387695
training step: 35642, total_loss: 4.694840908050537
training step: 35643, total_loss: 3.8504509925842285
training step: 35644, total_loss: 3.7191848754882812
training step: 35645, total_loss: 5.140410900115967
training step: 35646, total_loss: 6.263989448547363
training step: 35647, total_loss: 5.027848243713379
training step: 35648, total_loss: 3.1749825477600098
training step: 35649, total_loss: 6.154326438903809
training step: 35650, total_loss: 2.679802417755127
training step: 35651, total_loss: 3.7476277351379395
training step: 35652, total_loss: 6.989978790283203
training step: 35653, total_loss: 4.817255020141602
training step: 35654, total_loss: 4.646145820617676
training step: 35655, total_loss: 2.7562222480773926
training step: 35656, total_loss: 3.453782081604004
training step: 35657, total_loss: 3.613269329071045
training step: 35658, total_loss: 4.7586212158203125
training step: 35659, total_loss: 3.2040696144104004
training step: 35660, total_loss: 4.963014602661133
training step: 35661, total_loss: 3.747645616531372
training step: 35662, total_loss: 6.090390682220459
training step: 35663, total_loss: 5.371438980102539
training step: 35664, total_loss: 5.372539520263672
training step: 35665, total_loss: 4.869991302490234
training step: 35666, total_loss: 4.539096832275391
training step: 35667, total_loss: 6.421619415283203
training step: 35668, total_loss: 3.7681989669799805
training step: 35669, total_loss: 3.710642099380493
training step: 35670, total_loss: 4.804625511169434
training step: 35671, total_loss: 6.17927360534668
training step: 35672, total_loss: 3.9971399307250977
training step: 35673, total_loss: 3.7488951683044434
training step: 35674, total_loss: 5.760329246520996
training step: 35675, total_loss: 4.16815185546875
training step: 35676, total_loss: 4.258802890777588
training step: 35677, total_loss: 3.720210075378418
training step: 35678, total_loss: 3.4807024002075195
training step: 35679, total_loss: 2.955047845840454
training step: 35680, total_loss: 4.859247207641602
training step: 35681, total_loss: 4.920173645019531
training step: 35682, total_loss: 3.971862316131592
training step: 35683, total_loss: 5.339601516723633
training step: 35684, total_loss: 5.0650434494018555
training step: 35685, total_loss: 3.925367593765259
training step: 35686, total_loss: 4.148434638977051
training step: 35687, total_loss: 4.230439186096191
training step: 35688, total_loss: 6.3406829833984375
training step: 35689, total_loss: 1.1535906791687012
training step: 35690, total_loss: 4.281397819519043
training step: 35691, total_loss: 4.609994888305664
training step: 35692, total_loss: 4.643773078918457
training step: 35693, total_loss: 3.6571404933929443
training step: 35694, total_loss: 5.819301605224609
training step: 35695, total_loss: 4.494561195373535
training step: 35696, total_loss: 3.8991284370422363
training step: 35697, total_loss: 2.9278528690338135
training step: 35698, total_loss: 6.127717018127441
training step: 35699, total_loss: 4.776403427124023
training step: 35700, total_loss: 1.0843732357025146
training step: 35701, total_loss: 3.8151206970214844
training step: 35702, total_loss: 5.061312675476074
training step: 35703, total_loss: 5.036059379577637
training step: 35704, total_loss: 2.8767499923706055
training step: 35705, total_loss: 4.504575252532959
training step: 35706, total_loss: 6.434003829956055
training step: 35707, total_loss: 4.0255889892578125
training step: 35708, total_loss: 3.9838478565216064
training step: 35709, total_loss: 2.777796745300293
training step: 35710, total_loss: 3.202913761138916
training step: 35711, total_loss: 4.941986083984375
training step: 35712, total_loss: 4.786710739135742
training step: 35713, total_loss: 5.063363552093506
training step: 35714, total_loss: 5.134994029998779
training step: 35715, total_loss: 6.985459327697754
training step: 35716, total_loss: 4.198277473449707
training step: 35717, total_loss: 4.9268388748168945
training step: 35718, total_loss: 4.037371635437012
training step: 35719, total_loss: 5.20792293548584
training step: 35720, total_loss: 4.390037536621094
training step: 35721, total_loss: 4.544957160949707
training step: 35722, total_loss: 3.9238486289978027
training step: 35723, total_loss: 3.9722952842712402
training step: 35724, total_loss: 2.78167724609375
training step: 35725, total_loss: 2.94895601272583
training step: 35726, total_loss: 5.066478729248047
training step: 35727, total_loss: 4.5485520362854
training step: 35728, total_loss: 2.771165370941162
training step: 35729, total_loss: 5.131914138793945
training step: 35730, total_loss: 4.681087493896484
training step: 35731, total_loss: 4.14215612411499
training step: 35732, total_loss: 5.080438613891602
training step: 35733, total_loss: 5.877678394317627
training step: 35734, total_loss: 4.991788864135742
training step: 35735, total_loss: 4.293557167053223
training step: 35736, total_loss: 4.629669189453125
training step: 35737, total_loss: 5.867469787597656
training step: 35738, total_loss: 4.616817951202393
training step: 35739, total_loss: 4.12827205657959
training step: 35740, total_loss: 4.529636383056641
training step: 35741, total_loss: 5.267943382263184
training step: 35742, total_loss: 5.155740261077881
training step: 35743, total_loss: 4.74010705947876
training step: 35744, total_loss: 4.3664655685424805
training step: 35745, total_loss: 4.59088134765625
training step: 35746, total_loss: 2.7550907135009766
training step: 35747, total_loss: 2.782062292098999
training step: 35748, total_loss: 3.631382942199707
training step: 35749, total_loss: 3.380716323852539
training step: 35750, total_loss: 4.4155168533325195
training step: 35751, total_loss: 3.898374319076538
training step: 35752, total_loss: 4.160046577453613
training step: 35753, total_loss: 5.372524261474609
training step: 35754, total_loss: 5.094334602355957
training step: 35755, total_loss: 5.036299705505371
training step: 35756, total_loss: 4.706081390380859
training step: 35757, total_loss: 4.352082252502441
training step: 35758, total_loss: 5.792351722717285
training step: 35759, total_loss: 4.5516676902771
training step: 35760, total_loss: 3.7905242443084717
training step: 35761, total_loss: 5.349332809448242
training step: 35762, total_loss: 5.413976192474365
training step: 35763, total_loss: 5.018688678741455
training step: 35764, total_loss: 4.164612770080566
training step: 35765, total_loss: 5.119649410247803
training step: 35766, total_loss: 4.315423965454102
training step: 35767, total_loss: 4.275105953216553
training step: 35768, total_loss: 4.141371726989746
training step: 35769, total_loss: 4.765986442565918
training step: 35770, total_loss: 5.401830196380615
training step: 35771, total_loss: 5.661494731903076
training step: 35772, total_loss: 1.3326877355575562
training step: 35773, total_loss: 3.923809766769409
training step: 35774, total_loss: 4.884167671203613
training step: 35775, total_loss: 3.9828810691833496
training step: 35776, total_loss: 5.1709160804748535
training step: 35777, total_loss: 3.3073201179504395
training step: 35778, total_loss: 5.454787254333496
training step: 35779, total_loss: 3.2764623165130615
training step: 35780, total_loss: 4.942621231079102
training step: 35781, total_loss: 4.605201244354248
training step: 35782, total_loss: 3.443836212158203
training step: 35783, total_loss: 4.664765357971191
training step: 35784, total_loss: 4.535922527313232
training step: 35785, total_loss: 4.136662483215332
training step: 35786, total_loss: 3.5727128982543945
training step: 35787, total_loss: 3.436830520629883
training step: 35788, total_loss: 4.410733222961426
training step: 35789, total_loss: 4.704885959625244
training step: 35790, total_loss: 4.240871906280518
training step: 35791, total_loss: 3.624661445617676
training step: 35792, total_loss: 4.17897891998291
training step: 35793, total_loss: 4.071491718292236
training step: 35794, total_loss: 1.497558355331421
training step: 35795, total_loss: 4.801540374755859
training step: 35796, total_loss: 4.13681697845459
training step: 35797, total_loss: 2.934095621109009
training step: 35798, total_loss: 3.889019012451172
training step: 35799, total_loss: 4.660970211029053
training step: 35800, total_loss: 4.303594589233398
training step: 35801, total_loss: 3.283660411834717
training step: 35802, total_loss: 5.681362152099609
training step: 35803, total_loss: 4.144932746887207
training step: 35804, total_loss: 4.787580490112305
training step: 35805, total_loss: 4.133042335510254
training step: 35806, total_loss: 4.948596000671387
training step: 35807, total_loss: 5.48387336730957
training step: 35808, total_loss: 3.756772994995117
training step: 35809, total_loss: 3.46264386177063
training step: 35810, total_loss: 5.012971878051758
training step: 35811, total_loss: 4.619864463806152
training step: 35812, total_loss: 3.850541830062866
training step: 35813, total_loss: 3.603778600692749
training step: 35814, total_loss: 4.966771125793457
training step: 35815, total_loss: 5.119187831878662
training step: 35816, total_loss: 5.558669090270996
training step: 35817, total_loss: 3.4065566062927246
training step: 35818, total_loss: 4.802914619445801
training step: 35819, total_loss: 3.2199981212615967
training step: 35820, total_loss: 2.584190845489502
training step: 35821, total_loss: 6.988681316375732
training step: 35822, total_loss: 3.889625072479248
training step: 35823, total_loss: 6.370598793029785
training step: 35824, total_loss: 5.019611835479736
training step: 35825, total_loss: 5.218335151672363
training step: 35826, total_loss: 5.72463321685791
training step: 35827, total_loss: 3.296175956726074
training step: 35828, total_loss: 3.99920654296875
training step: 35829, total_loss: 4.401248931884766
training step: 35830, total_loss: 3.4532811641693115
training step: 35831, total_loss: 5.685509204864502
training step: 35832, total_loss: 5.995096206665039
training step: 35833, total_loss: 4.665045261383057
training step: 35834, total_loss: 2.2989501953125
training step: 35835, total_loss: 4.294848918914795
training step: 35836, total_loss: 4.578347682952881
training step: 35837, total_loss: 4.895485877990723
training step: 35838, total_loss: 4.41257381439209
training step: 35839, total_loss: 5.765104293823242
training step: 35840, total_loss: 3.272637128829956
training step: 35841, total_loss: 4.823579788208008
training step: 35842, total_loss: 5.338425636291504
training step: 35843, total_loss: 4.924201011657715
training step: 35844, total_loss: 6.262092590332031
training step: 35845, total_loss: 3.4800233840942383
training step: 35846, total_loss: 5.73278284072876
training step: 35847, total_loss: 2.936286211013794
training step: 35848, total_loss: 4.934659004211426
training step: 35849, total_loss: 4.076257705688477
training step: 35850, total_loss: 2.276142120361328
training step: 35851, total_loss: 4.109830856323242
training step: 35852, total_loss: 3.716543197631836
training step: 35853, total_loss: 4.252750396728516
training step: 35854, total_loss: 3.196333885192871
training step: 35855, total_loss: 4.914719581604004
training step: 35856, total_loss: 2.407257556915283
training step: 35857, total_loss: 5.4991607666015625
training step: 35858, total_loss: 4.565271377563477
training step: 35859, total_loss: 5.49306583404541
training step: 35860, total_loss: 4.451336860656738
training step: 35861, total_loss: 5.100305557250977
training step: 35862, total_loss: 3.6810202598571777
training step: 35863, total_loss: 3.137819290161133
training step: 35864, total_loss: 3.524380683898926
training step: 35865, total_loss: 5.0203537940979
training step: 35866, total_loss: 4.396387100219727
training step: 35867, total_loss: 4.095794677734375
training step: 35868, total_loss: 4.1092424392700195
training step: 35869, total_loss: 6.367117404937744
training step: 35870, total_loss: 4.308873653411865
training step: 35871, total_loss: 4.535384178161621
training step: 35872, total_loss: 5.290533542633057
training step: 35873, total_loss: 5.139787673950195
training step: 35874, total_loss: 4.916409015655518
training step: 35875, total_loss: 3.5782546997070312
training step: 35876, total_loss: 4.441844463348389
training step: 35877, total_loss: 4.409235000610352
training step: 35878, total_loss: 4.43271017074585
training step: 35879, total_loss: 3.2784857749938965
training step: 35880, total_loss: 3.9547762870788574
training step: 35881, total_loss: 2.8604350090026855
training step: 35882, total_loss: 4.494808673858643
training step: 35883, total_loss: 3.960989475250244
training step: 35884, total_loss: 3.8068952560424805
training step: 35885, total_loss: 3.35479736328125
training step: 35886, total_loss: 4.334736347198486
training step: 35887, total_loss: 4.0592145919799805
training step: 35888, total_loss: 6.196507930755615
training step: 35889, total_loss: 4.229907989501953
training step: 35890, total_loss: 4.9374775886535645
training step: 35891, total_loss: 4.221742630004883
training step: 35892, total_loss: 4.093675136566162
training step: 35893, total_loss: 4.872060775756836
training step: 35894, total_loss: 4.882064342498779
training step: 35895, total_loss: 3.1665217876434326
training step: 35896, total_loss: 3.5638513565063477
training step: 35897, total_loss: 4.496181011199951
training step: 35898, total_loss: 3.2745938301086426
training step: 35899, total_loss: 3.838222026824951
training step: 35900, total_loss: 4.947017669677734
training step: 35901, total_loss: 6.463710784912109
training step: 35902, total_loss: 4.234828948974609
training step: 35903, total_loss: 3.921142578125
training step: 35904, total_loss: 4.038923740386963
training step: 35905, total_loss: 5.773594856262207
training step: 35906, total_loss: 1.0792596340179443
training step: 35907, total_loss: 3.7548203468322754
training step: 35908, total_loss: 6.043838977813721
training step: 35909, total_loss: 4.3610053062438965
training step: 35910, total_loss: 2.8341450691223145
training step: 35911, total_loss: 5.892767429351807
training step: 35912, total_loss: 4.080071449279785
training step: 35913, total_loss: 4.316013336181641
training step: 35914, total_loss: 4.3747053146362305
training step: 35915, total_loss: 4.757391929626465
training step: 35916, total_loss: 3.6144907474517822
training step: 35917, total_loss: 4.524616241455078
training step: 35918, total_loss: 3.561094045639038
training step: 35919, total_loss: 5.069306373596191
training step: 35920, total_loss: 5.353060722351074
training step: 35921, total_loss: 3.22725772857666
training step: 35922, total_loss: 5.169875144958496
training step: 35923, total_loss: 1.5652127265930176
training step: 35924, total_loss: 4.431068420410156
training step: 35925, total_loss: 4.218894004821777
training step: 35926, total_loss: 3.5087757110595703
training step: 35927, total_loss: 4.14980411529541
training step: 35928, total_loss: 5.447997570037842
training step: 35929, total_loss: 4.960665702819824
training step: 35930, total_loss: 4.394676208496094
training step: 35931, total_loss: 4.481902599334717
training step: 35932, total_loss: 4.320211887359619
training step: 35933, total_loss: 4.645536422729492
training step: 35934, total_loss: 4.2887163162231445
training step: 35935, total_loss: 4.318466663360596
training step: 35936, total_loss: 2.8974883556365967
training step: 35937, total_loss: 2.778712749481201
training step: 35938, total_loss: 4.803593635559082
training step: 35939, total_loss: 2.586705446243286
training step: 35940, total_loss: 4.143119812011719
training step: 35941, total_loss: 4.2073516845703125
training step: 35942, total_loss: 4.2745819091796875
training step: 35943, total_loss: 5.389301300048828
training step: 35944, total_loss: 6.362545013427734
training step: 35945, total_loss: 3.443129062652588
training step: 35946, total_loss: 5.165976524353027
training step: 35947, total_loss: 6.595780849456787
training step: 35948, total_loss: 4.351510047912598
training step: 35949, total_loss: 4.055973052978516
training step: 35950, total_loss: 5.677586555480957
training step: 35951, total_loss: 6.086560249328613
training step: 35952, total_loss: 4.094094276428223
training step: 35953, total_loss: 3.601884603500366
training step: 35954, total_loss: 3.7721211910247803
training step: 35955, total_loss: 5.395536422729492
training step: 35956, total_loss: 4.945727348327637
training step: 35957, total_loss: 4.322113990783691
training step: 35958, total_loss: 3.987581253051758
training step: 35959, total_loss: 5.347060203552246
training step: 35960, total_loss: 1.0295705795288086
training step: 35961, total_loss: 3.8114964962005615
training step: 35962, total_loss: 3.577971935272217
training step: 35963, total_loss: 5.098816394805908
training step: 35964, total_loss: 4.352898597717285
training step: 35965, total_loss: 3.9031577110290527
training step: 35966, total_loss: 3.047348976135254
training step: 35967, total_loss: 2.6594605445861816
training step: 35968, total_loss: 4.506030082702637
training step: 35969, total_loss: 4.775856971740723
training step: 35970, total_loss: 4.223263263702393
training step: 35971, total_loss: 3.8232650756835938
training step: 35972, total_loss: 5.054476261138916
training step: 35973, total_loss: 4.255239009857178
training step: 35974, total_loss: 2.1831393241882324
training step: 35975, total_loss: 3.75956130027771
training step: 35976, total_loss: 4.133444786071777
training step: 35977, total_loss: 3.6961302757263184
training step: 35978, total_loss: 4.9085283279418945
training step: 35979, total_loss: 4.450353145599365
training step: 35980, total_loss: 5.2341108322143555
training step: 35981, total_loss: 3.7174723148345947
training step: 35982, total_loss: 5.300151824951172
training step: 35983, total_loss: 3.795297622680664
training step: 35984, total_loss: 4.316709995269775
training step: 35985, total_loss: 4.391051292419434
training step: 35986, total_loss: 5.548046112060547
training step: 35987, total_loss: 4.823587417602539
training step: 35988, total_loss: 3.758208990097046
training step: 35989, total_loss: 5.27551794052124
training step: 35990, total_loss: 4.285387992858887
training step: 35991, total_loss: 4.659247398376465
training step: 35992, total_loss: 4.714699745178223
training step: 35993, total_loss: 3.6189351081848145
training step: 35994, total_loss: 4.553034782409668
training step: 35995, total_loss: 4.289460182189941
training step: 35996, total_loss: 5.547309875488281
training step: 35997, total_loss: 4.258178234100342
training step: 35998, total_loss: 4.668808937072754
training step: 35999, total_loss: 5.893377780914307
training step: 36000, total_loss: 4.284791946411133
training step: 36001, total_loss: 5.262923240661621
training step: 36002, total_loss: 4.929232120513916
training step: 36003, total_loss: 4.526803970336914
training step: 36004, total_loss: 6.235898017883301
training step: 36005, total_loss: 3.440927505493164
training step: 36006, total_loss: 5.0853271484375
training step: 36007, total_loss: 4.459458351135254
training step: 36008, total_loss: 3.995919942855835
training step: 36009, total_loss: 4.52071475982666
training step: 36010, total_loss: 3.946218490600586
training step: 36011, total_loss: 5.202654838562012
training step: 36012, total_loss: 4.325494766235352
training step: 36013, total_loss: 3.936906576156616
training step: 36014, total_loss: 4.1862592697143555
training step: 36015, total_loss: 5.005622863769531
training step: 36016, total_loss: 3.6286540031433105
training step: 36017, total_loss: 5.352458477020264
training step: 36018, total_loss: 5.099884986877441
training step: 36019, total_loss: 3.561580181121826
training step: 36020, total_loss: 3.391397476196289
training step: 36021, total_loss: 5.9184250831604
training step: 36022, total_loss: 5.16076135635376
training step: 36023, total_loss: 3.931746006011963
training step: 36024, total_loss: 5.759362697601318
training step: 36025, total_loss: 4.958884239196777
training step: 36026, total_loss: 5.239707946777344
training step: 36027, total_loss: 3.776874303817749
training step: 36028, total_loss: 4.652612686157227
training step: 36029, total_loss: 4.841312408447266
training step: 36030, total_loss: 4.382150173187256
training step: 36031, total_loss: 3.154681444168091
training step: 36032, total_loss: 4.723661422729492
training step: 36033, total_loss: 4.369932651519775
training step: 36034, total_loss: 5.720402717590332
training step: 36035, total_loss: 3.436518669128418
training step: 36036, total_loss: 3.938025712966919
training step: 36037, total_loss: 4.514628887176514
training step: 36038, total_loss: 5.310244083404541
training step: 36039, total_loss: 4.189387321472168
training step: 36040, total_loss: 5.08321475982666
training step: 36041, total_loss: 5.686156272888184
training step: 36042, total_loss: 5.23390007019043
training step: 36043, total_loss: 4.5593366622924805
training step: 36044, total_loss: 2.8547263145446777
training step: 36045, total_loss: 5.824233055114746
training step: 36046, total_loss: 5.088596343994141
training step: 36047, total_loss: 4.046936511993408
training step: 36048, total_loss: 4.290184020996094
training step: 36049, total_loss: 3.7583959102630615
training step: 36050, total_loss: 6.6078386306762695
training step: 36051, total_loss: 2.9209673404693604
training step: 36052, total_loss: 4.277506351470947
training step: 36053, total_loss: 4.2557902336120605
training step: 36054, total_loss: 4.922863006591797
training step: 36055, total_loss: 3.8982291221618652
training step: 36056, total_loss: 5.748997688293457
training step: 36057, total_loss: 5.570082664489746
training step: 36058, total_loss: 4.768233299255371
training step: 36059, total_loss: 3.042470693588257
training step: 36060, total_loss: 4.675423622131348
training step: 36061, total_loss: 2.949829578399658
training step: 36062, total_loss: 4.623132705688477
training step: 36063, total_loss: 4.605734348297119
training step: 36064, total_loss: 2.836205005645752
training step: 36065, total_loss: 5.094038009643555
training step: 36066, total_loss: 3.452169179916382
training step: 36067, total_loss: 5.287537574768066
training step: 36068, total_loss: 3.6779232025146484
training step: 36069, total_loss: 4.66726016998291
training step: 36070, total_loss: 3.0131232738494873
training step: 36071, total_loss: 6.339110851287842
training step: 36072, total_loss: 4.925539970397949
training step: 36073, total_loss: 4.886670112609863
training step: 36074, total_loss: 5.272613525390625
training step: 36075, total_loss: 3.2921767234802246
training step: 36076, total_loss: 4.6080522537231445
training step: 36077, total_loss: 5.025016784667969
training step: 36078, total_loss: 4.723809242248535
training step: 36079, total_loss: 5.1734113693237305
training step: 36080, total_loss: 4.424057483673096
training step: 36081, total_loss: 4.860760688781738
training step: 36082, total_loss: 4.470798492431641
training step: 36083, total_loss: 4.595097541809082
training step: 36084, total_loss: 4.404027462005615
training step: 36085, total_loss: 3.7623214721679688
training step: 36086, total_loss: 2.589156150817871
training step: 36087, total_loss: 4.341734886169434
training step: 36088, total_loss: 3.688713788986206
training step: 36089, total_loss: 3.569430351257324
training step: 36090, total_loss: 4.575253486633301
training step: 36091, total_loss: 6.180520057678223
training step: 36092, total_loss: 4.795881271362305
training step: 36093, total_loss: 4.22991418838501
training step: 36094, total_loss: 5.362246513366699
training step: 36095, total_loss: 3.4944701194763184
training step: 36096, total_loss: 5.223791122436523
training step: 36097, total_loss: 5.449654579162598
training step: 36098, total_loss: 1.9673705101013184
training step: 36099, total_loss: 3.8318490982055664
training step: 36100, total_loss: 2.298384189605713
training step: 36101, total_loss: 4.330301284790039
training step: 36102, total_loss: 4.228826999664307
training step: 36103, total_loss: 4.282115936279297
training step: 36104, total_loss: 3.500927448272705
training step: 36105, total_loss: 5.173776149749756
training step: 36106, total_loss: 3.3737540245056152
training step: 36107, total_loss: 4.055384635925293
training step: 36108, total_loss: 4.837004661560059
training step: 36109, total_loss: 3.7242636680603027
training step: 36110, total_loss: 5.827197551727295
training step: 36111, total_loss: 4.429684638977051
training step: 36112, total_loss: 4.74356746673584
training step: 36113, total_loss: 4.965175628662109
training step: 36114, total_loss: 4.975863933563232
training step: 36115, total_loss: 5.704904556274414
training step: 36116, total_loss: 3.5663578510284424
training step: 36117, total_loss: 3.906980514526367
training step: 36118, total_loss: 4.833285331726074
training step: 36119, total_loss: 0.9527751207351685
training step: 36120, total_loss: 5.818025588989258
training step: 36121, total_loss: 4.575379371643066
training step: 36122, total_loss: 4.228917121887207
training step: 36123, total_loss: 3.7271857261657715
training step: 36124, total_loss: 4.54964542388916
training step: 36125, total_loss: 4.029658794403076
training step: 36126, total_loss: 2.5959808826446533
training step: 36127, total_loss: 4.1947126388549805
training step: 36128, total_loss: 4.914228439331055
training step: 36129, total_loss: 4.306653022766113
training step: 36130, total_loss: 5.003004550933838
training step: 36131, total_loss: 4.253643035888672
training step: 36132, total_loss: 4.816086769104004
training step: 36133, total_loss: 5.185122489929199
training step: 36134, total_loss: 4.954246997833252
training step: 36135, total_loss: 4.168104648590088
training step: 36136, total_loss: 2.512669086456299
training step: 36137, total_loss: 4.5142316818237305
training step: 36138, total_loss: 3.543745756149292
training step: 36139, total_loss: 3.4730072021484375
training step: 36140, total_loss: 3.8824872970581055
training step: 36141, total_loss: 3.869957447052002
training step: 36142, total_loss: 2.5782222747802734
training step: 36143, total_loss: 5.0557708740234375
training step: 36144, total_loss: 3.6785717010498047
training step: 36145, total_loss: 3.625277042388916
training step: 36146, total_loss: 5.042341232299805
training step: 36147, total_loss: 5.401968002319336
training step: 36148, total_loss: 6.224376678466797
training step: 36149, total_loss: 5.703428745269775
training step: 36150, total_loss: 5.226526260375977
training step: 36151, total_loss: 3.3897666931152344
training step: 36152, total_loss: 5.171013355255127
training step: 36153, total_loss: 3.0551400184631348
training step: 36154, total_loss: 4.150350570678711
training step: 36155, total_loss: 4.010542869567871
training step: 36156, total_loss: 4.508031845092773
training step: 36157, total_loss: 4.603799819946289
training step: 36158, total_loss: 4.5197577476501465
training step: 36159, total_loss: 4.693392753601074
training step: 36160, total_loss: 5.108342170715332
training step: 36161, total_loss: 3.79231595993042
training step: 36162, total_loss: 5.606772422790527
training step: 36163, total_loss: 2.7634506225585938
training step: 36164, total_loss: 3.7799859046936035
training step: 36165, total_loss: 4.831484317779541
training step: 36166, total_loss: 1.4972785711288452
training step: 36167, total_loss: 5.542827606201172
training step: 36168, total_loss: 3.6173019409179688
training step: 36169, total_loss: 5.312514305114746
training step: 36170, total_loss: 5.94835901260376
training step: 36171, total_loss: 7.157168865203857
training step: 36172, total_loss: 3.1478238105773926
training step: 36173, total_loss: 3.6224262714385986
training step: 36174, total_loss: 4.583240985870361
training step: 36175, total_loss: 4.4383134841918945
training step: 36176, total_loss: 5.422608375549316
training step: 36177, total_loss: 5.102083683013916
training step: 36178, total_loss: 4.5377912521362305
training step: 36179, total_loss: 4.335907936096191
training step: 36180, total_loss: 3.369828701019287
training step: 36181, total_loss: 6.0775322914123535
training step: 36182, total_loss: 4.005673408508301
training step: 36183, total_loss: 3.9639577865600586
training step: 36184, total_loss: 5.346096992492676
training step: 36185, total_loss: 4.733269691467285
training step: 36186, total_loss: 4.384862899780273
training step: 36187, total_loss: 7.273687362670898
training step: 36188, total_loss: 2.6545209884643555
training step: 36189, total_loss: 4.019080638885498
training step: 36190, total_loss: 4.496670722961426
training step: 36191, total_loss: 4.908034801483154
training step: 36192, total_loss: 5.216325283050537
training step: 36193, total_loss: 5.153889179229736
training step: 36194, total_loss: 4.254539966583252
training step: 36195, total_loss: 4.708416938781738
training step: 36196, total_loss: 4.409368515014648
training step: 36197, total_loss: 3.843428611755371
training step: 36198, total_loss: 4.331940650939941
training step: 36199, total_loss: 2.874622344970703
training step: 36200, total_loss: 3.717656135559082
training step: 36201, total_loss: 4.484334945678711
training step: 36202, total_loss: 4.598753929138184
training step: 36203, total_loss: 4.567722320556641
training step: 36204, total_loss: 4.649050712585449
training step: 36205, total_loss: 3.280578374862671
training step: 36206, total_loss: 5.362185955047607
training step: 36207, total_loss: 5.387503623962402
training step: 36208, total_loss: 5.020384788513184
training step: 36209, total_loss: 5.389662742614746
training step: 36210, total_loss: 5.5429792404174805
training step: 36211, total_loss: 3.2612648010253906
training step: 36212, total_loss: 3.590327739715576
training step: 36213, total_loss: 3.9085333347320557
training step: 36214, total_loss: 5.340614318847656
training step: 36215, total_loss: 4.75031852722168
training step: 36216, total_loss: 4.812752723693848
training step: 36217, total_loss: 4.134212493896484
training step: 36218, total_loss: 3.491837978363037
training step: 36219, total_loss: 4.65693998336792
training step: 36220, total_loss: 4.469231128692627
training step: 36221, total_loss: 4.149551868438721
training step: 36222, total_loss: 3.0144124031066895
training step: 36223, total_loss: 5.578371047973633
training step: 36224, total_loss: 5.259355068206787
training step: 36225, total_loss: 3.6896347999572754
training step: 36226, total_loss: 3.1758127212524414
training step: 36227, total_loss: 4.617442607879639
training step: 36228, total_loss: 4.628626346588135
training step: 36229, total_loss: 4.240823745727539
training step: 36230, total_loss: 4.335245609283447
training step: 36231, total_loss: 5.267207145690918
training step: 36232, total_loss: 4.953581809997559
training step: 36233, total_loss: 4.8863019943237305
training step: 36234, total_loss: 4.204824447631836
training step: 36235, total_loss: 4.687413215637207
training step: 36236, total_loss: 4.063074111938477
training step: 36237, total_loss: 4.786442756652832
training step: 36238, total_loss: 5.053342342376709
training step: 36239, total_loss: 4.251189708709717
training step: 36240, total_loss: 3.913954734802246
training step: 36241, total_loss: 4.825300216674805
training step: 36242, total_loss: 5.790792465209961
training step: 36243, total_loss: 4.6788506507873535
training step: 36244, total_loss: 5.944121837615967
training step: 36245, total_loss: 2.74185848236084
training step: 36246, total_loss: 3.700397253036499
training step: 36247, total_loss: 3.89044189453125
training step: 36248, total_loss: 4.3026227951049805
training step: 36249, total_loss: 3.832749605178833
training step: 36250, total_loss: 5.3402605056762695
training step: 36251, total_loss: 6.562865734100342
training step: 36252, total_loss: 5.179574012756348
training step: 36253, total_loss: 4.467387676239014
training step: 36254, total_loss: 4.971060752868652
training step: 36255, total_loss: 3.8212804794311523
training step: 36256, total_loss: 5.252902507781982
training step: 36257, total_loss: 4.461433410644531
training step: 36258, total_loss: 3.765749454498291
training step: 36259, total_loss: 4.383964538574219
training step: 36260, total_loss: 4.616167068481445
training step: 36261, total_loss: 4.095544815063477
training step: 36262, total_loss: 4.550950050354004
training step: 36263, total_loss: 3.5982213020324707
training step: 36264, total_loss: 5.452846527099609
training step: 36265, total_loss: 5.078106880187988
training step: 36266, total_loss: 4.613335609436035
training step: 36267, total_loss: 5.006769180297852
training step: 36268, total_loss: 4.224681854248047
training step: 36269, total_loss: 3.512160062789917
training step: 36270, total_loss: 4.69619083404541
training step: 36271, total_loss: 3.271756172180176
training step: 36272, total_loss: 4.88297700881958
training step: 36273, total_loss: 4.106281757354736
training step: 36274, total_loss: 5.695671558380127
training step: 36275, total_loss: 4.762365818023682
training step: 36276, total_loss: 4.21786642074585
training step: 36277, total_loss: 4.1512250900268555
training step: 36278, total_loss: 6.949580192565918
training step: 36279, total_loss: 3.961252212524414
training step: 36280, total_loss: 4.470186233520508
training step: 36281, total_loss: 3.271944046020508
training step: 36282, total_loss: 6.289701461791992
training step: 36283, total_loss: 4.91396951675415
training step: 36284, total_loss: 4.172393798828125
training step: 36285, total_loss: 2.755634069442749
training step: 36286, total_loss: 5.133366584777832
training step: 36287, total_loss: 3.0583791732788086
training step: 36288, total_loss: 4.447801113128662
training step: 36289, total_loss: 4.6454267501831055
training step: 36290, total_loss: 4.661245346069336
training step: 36291, total_loss: 4.046606540679932
training step: 36292, total_loss: 5.129537582397461
training step: 36293, total_loss: 3.567089557647705
training step: 36294, total_loss: 4.199617385864258
training step: 36295, total_loss: 4.043982028961182
training step: 36296, total_loss: 5.36224365234375
training step: 36297, total_loss: 3.914264440536499
training step: 36298, total_loss: 4.839900016784668
training step: 36299, total_loss: 3.781261920928955
training step: 36300, total_loss: 6.817861557006836
training step: 36301, total_loss: 4.196287631988525
training step: 36302, total_loss: 4.4291839599609375
training step: 36303, total_loss: 5.123553276062012
training step: 36304, total_loss: 1.1999019384384155
training step: 36305, total_loss: 4.193143844604492
training step: 36306, total_loss: 4.013801574707031
training step: 36307, total_loss: 4.720085144042969
training step: 36308, total_loss: 4.491306304931641
training step: 36309, total_loss: 4.690403938293457
training step: 36310, total_loss: 4.505032062530518
training step: 36311, total_loss: 4.937927722930908
training step: 36312, total_loss: 4.040700435638428
training step: 36313, total_loss: 3.9042716026306152
training step: 36314, total_loss: 4.290975570678711
training step: 36315, total_loss: 4.377891540527344
training step: 36316, total_loss: 3.6414737701416016
training step: 36317, total_loss: 4.524957656860352
training step: 36318, total_loss: 3.1308512687683105
training step: 36319, total_loss: 2.752957582473755
training step: 36320, total_loss: 4.842565536499023
training step: 36321, total_loss: 4.2161383628845215
training step: 36322, total_loss: 4.626413345336914
training step: 36323, total_loss: 4.347329139709473
training step: 36324, total_loss: 5.869462966918945
training step: 36325, total_loss: 4.815087795257568
training step: 36326, total_loss: 5.1650800704956055
training step: 36327, total_loss: 5.1668572425842285
training step: 36328, total_loss: 2.8811984062194824
training step: 36329, total_loss: 5.086726188659668
training step: 36330, total_loss: 4.000687599182129
training step: 36331, total_loss: 1.8131673336029053
training step: 36332, total_loss: 3.3499598503112793
training step: 36333, total_loss: 5.308370590209961
training step: 36334, total_loss: 4.051990509033203
training step: 36335, total_loss: 3.1129302978515625
training step: 36336, total_loss: 5.208372592926025
training step: 36337, total_loss: 4.412937641143799
training step: 36338, total_loss: 2.390913486480713
training step: 36339, total_loss: 3.252549171447754
training step: 36340, total_loss: 5.254342079162598
training step: 36341, total_loss: 5.367484092712402
training step: 36342, total_loss: 5.475553512573242
training step: 36343, total_loss: 6.442523956298828
training step: 36344, total_loss: 4.417878150939941
training step: 36345, total_loss: 4.285823822021484
training step: 36346, total_loss: 4.534977436065674
training step: 36347, total_loss: 2.8774991035461426
training step: 36348, total_loss: 4.8323493003845215
training step: 36349, total_loss: 4.31033992767334
training step: 36350, total_loss: 4.517453193664551
training step: 36351, total_loss: 4.001686096191406
training step: 36352, total_loss: 4.35459041595459
training step: 36353, total_loss: 4.175992965698242
training step: 36354, total_loss: 5.085813522338867
training step: 36355, total_loss: 4.868949890136719
training step: 36356, total_loss: 3.4960880279541016
training step: 36357, total_loss: 4.346189022064209
training step: 36358, total_loss: 3.3601443767547607
training step: 36359, total_loss: 4.738589286804199
training step: 36360, total_loss: 4.589093208312988
training step: 36361, total_loss: 5.095062255859375
training step: 36362, total_loss: 5.269805908203125
training step: 36363, total_loss: 1.8958263397216797
training step: 36364, total_loss: 5.309893608093262
training step: 36365, total_loss: 5.804257392883301
training step: 36366, total_loss: 3.310790538787842
training step: 36367, total_loss: 3.5396504402160645
training step: 36368, total_loss: 2.75931453704834
training step: 36369, total_loss: 6.131244659423828
training step: 36370, total_loss: 3.5906691551208496
training step: 36371, total_loss: 5.031774520874023
training step: 36372, total_loss: 3.2755589485168457
training step: 36373, total_loss: 4.77565336227417
training step: 36374, total_loss: 4.926462173461914
training step: 36375, total_loss: 4.658353805541992
training step: 36376, total_loss: 3.6694300174713135
training step: 36377, total_loss: 4.635973930358887
training step: 36378, total_loss: 5.066725254058838
training step: 36379, total_loss: 4.298508167266846
training step: 36380, total_loss: 4.962389945983887
training step: 36381, total_loss: 4.112920761108398
training step: 36382, total_loss: 3.895015001296997
training step: 36383, total_loss: 4.934576034545898
training step: 36384, total_loss: 4.099153518676758
training step: 36385, total_loss: 5.56973934173584
training step: 36386, total_loss: 4.091492176055908
training step: 36387, total_loss: 3.708850383758545
training step: 36388, total_loss: 5.6098527908325195
training step: 36389, total_loss: 5.122496128082275
training step: 36390, total_loss: 4.538940906524658
training step: 36391, total_loss: 2.8975882530212402
training step: 36392, total_loss: 8.329360961914062
training step: 36393, total_loss: 5.845855712890625
training step: 36394, total_loss: 4.9723052978515625
training step: 36395, total_loss: 4.144562721252441
training step: 36396, total_loss: 4.785970687866211
training step: 36397, total_loss: 5.350453853607178
training step: 36398, total_loss: 3.657034397125244
training step: 36399, total_loss: 1.6031848192214966
training step: 36400, total_loss: 2.1911981105804443
training step: 36401, total_loss: 5.977276802062988
training step: 36402, total_loss: 3.77253794670105
training step: 36403, total_loss: 3.539339542388916
training step: 36404, total_loss: 2.4144928455352783
training step: 36405, total_loss: 4.9878950119018555
training step: 36406, total_loss: 4.174261093139648
training step: 36407, total_loss: 6.154239654541016
training step: 36408, total_loss: 5.477930068969727
training step: 36409, total_loss: 4.200667858123779
training step: 36410, total_loss: 4.256401062011719
training step: 36411, total_loss: 5.049993515014648
training step: 36412, total_loss: 4.711471080780029
training step: 36413, total_loss: 4.402202129364014
training step: 36414, total_loss: 3.5050625801086426
training step: 36415, total_loss: 6.677192211151123
training step: 36416, total_loss: 4.8502092361450195
training step: 36417, total_loss: 4.701618194580078
training step: 36418, total_loss: 4.711822032928467
training step: 36419, total_loss: 3.2930164337158203
training step: 36420, total_loss: 5.910261154174805
training step: 36421, total_loss: 3.4313812255859375
training step: 36422, total_loss: 3.562812089920044
training step: 36423, total_loss: 4.192925930023193
training step: 36424, total_loss: 3.673401355743408
training step: 36425, total_loss: 4.430497169494629
training step: 36426, total_loss: 4.7531023025512695
training step: 36427, total_loss: 4.67519474029541
training step: 36428, total_loss: 4.493060111999512
training step: 36429, total_loss: 3.4136085510253906
training step: 36430, total_loss: 3.539008855819702
training step: 36431, total_loss: 5.12459659576416
training step: 36432, total_loss: 3.7849555015563965
training step: 36433, total_loss: 5.406396865844727
training step: 36434, total_loss: 1.7392666339874268
training step: 36435, total_loss: 4.168777942657471
training step: 36436, total_loss: 3.043471336364746
training step: 36437, total_loss: 4.482748031616211
training step: 36438, total_loss: 4.497350215911865
training step: 36439, total_loss: 3.919981002807617
training step: 36440, total_loss: 4.9926557540893555
training step: 36441, total_loss: 5.384462356567383
training step: 36442, total_loss: 4.953526020050049
training step: 36443, total_loss: 3.8897242546081543
training step: 36444, total_loss: 4.528143882751465
training step: 36445, total_loss: 4.131989479064941
training step: 36446, total_loss: 4.834952354431152
training step: 36447, total_loss: 3.1144728660583496
training step: 36448, total_loss: 3.1234781742095947
training step: 36449, total_loss: 4.908721923828125
training step: 36450, total_loss: 4.012994289398193
training step: 36451, total_loss: 3.8029608726501465
training step: 36452, total_loss: 6.80467414855957
training step: 36453, total_loss: 4.4586944580078125
training step: 36454, total_loss: 3.8447728157043457
training step: 36455, total_loss: 3.862478017807007
training step: 36456, total_loss: 4.887763023376465
training step: 36457, total_loss: 4.425846099853516
training step: 36458, total_loss: 4.888452053070068
training step: 36459, total_loss: 4.117156982421875
training step: 36460, total_loss: 4.141757965087891
training step: 36461, total_loss: 4.082832336425781
training step: 36462, total_loss: 4.682769775390625
training step: 36463, total_loss: 3.897336483001709
training step: 36464, total_loss: 4.119640827178955
training step: 36465, total_loss: 6.294096946716309
training step: 36466, total_loss: 6.4806365966796875
training step: 36467, total_loss: 2.8814852237701416
training step: 36468, total_loss: 5.308815002441406
training step: 36469, total_loss: 3.4882023334503174
training step: 36470, total_loss: 4.469121932983398
training step: 36471, total_loss: 5.3853254318237305
training step: 36472, total_loss: 3.707374095916748
training step: 36473, total_loss: 5.188563346862793
training step: 36474, total_loss: 5.320727348327637
training step: 36475, total_loss: 5.0240325927734375
training step: 36476, total_loss: 4.619096755981445
training step: 36477, total_loss: 3.1617839336395264
training step: 36478, total_loss: 8.108379364013672
training step: 36479, total_loss: 3.8487548828125
training step: 36480, total_loss: 1.2808012962341309
training step: 36481, total_loss: 5.372367858886719
training step: 36482, total_loss: 5.360347747802734
training step: 36483, total_loss: 5.090555191040039
training step: 36484, total_loss: 4.598432540893555
training step: 36485, total_loss: 4.234796524047852
training step: 36486, total_loss: 5.635552883148193
training step: 36487, total_loss: 3.269355297088623
training step: 36488, total_loss: 5.2705278396606445
training step: 36489, total_loss: 2.8033626079559326
training step: 36490, total_loss: 3.8170113563537598
training step: 36491, total_loss: 7.147353172302246
training step: 36492, total_loss: 5.352296829223633
training step: 36493, total_loss: 4.105107307434082
training step: 36494, total_loss: 4.3337860107421875
training step: 36495, total_loss: 5.042852401733398
training step: 36496, total_loss: 6.496595859527588
training step: 36497, total_loss: 5.4023895263671875
training step: 36498, total_loss: 3.931727170944214
training step: 36499, total_loss: 3.09297513961792
training step: 36500, total_loss: 2.8453540802001953
training step: 36501, total_loss: 7.306420803070068
training step: 36502, total_loss: 4.535787582397461
training step: 36503, total_loss: 5.274750709533691
training step: 36504, total_loss: 3.772541046142578
training step: 36505, total_loss: 5.56181526184082
training step: 36506, total_loss: 3.5968990325927734
training step: 36507, total_loss: 3.6402411460876465
training step: 36508, total_loss: 4.704180717468262
training step: 36509, total_loss: 5.709010124206543
training step: 36510, total_loss: 5.339926719665527
training step: 36511, total_loss: 4.2389702796936035
training step: 36512, total_loss: 4.263774394989014
training step: 36513, total_loss: 5.540521621704102
training step: 36514, total_loss: 6.020784378051758
training step: 36515, total_loss: 4.746628761291504
training step: 36516, total_loss: 3.787412166595459
training step: 36517, total_loss: 5.280880928039551
training step: 36518, total_loss: 4.135317802429199
training step: 36519, total_loss: 5.636272430419922
training step: 36520, total_loss: 2.8550944328308105
training step: 36521, total_loss: 4.839705467224121
training step: 36522, total_loss: 4.751865386962891
training step: 36523, total_loss: 3.1880455017089844
training step: 36524, total_loss: 5.4031572341918945
training step: 36525, total_loss: 5.159624099731445
training step: 36526, total_loss: 4.878533363342285
training step: 36527, total_loss: 5.499011993408203
training step: 36528, total_loss: 3.965481758117676
training step: 36529, total_loss: 6.120439052581787
training step: 36530, total_loss: 5.238363265991211
training step: 36531, total_loss: 4.182843208312988
training step: 36532, total_loss: 3.2030029296875
training step: 36533, total_loss: 3.7370548248291016
training step: 36534, total_loss: 3.2045435905456543
training step: 36535, total_loss: 4.854038715362549
training step: 36536, total_loss: 4.688230514526367
training step: 36537, total_loss: 3.9962286949157715
training step: 36538, total_loss: 2.1751179695129395
training step: 36539, total_loss: 5.055572509765625
training step: 36540, total_loss: 3.550713300704956
training step: 36541, total_loss: 4.233963489532471
training step: 36542, total_loss: 5.032956123352051
training step: 36543, total_loss: 3.9773800373077393
training step: 36544, total_loss: 6.732524394989014
training step: 36545, total_loss: 3.8935165405273438
training step: 36546, total_loss: 3.3448190689086914
training step: 36547, total_loss: 4.304001331329346
training step: 36548, total_loss: 2.988645076751709
training step: 36549, total_loss: 3.5855259895324707
training step: 36550, total_loss: 4.281778812408447
training step: 36551, total_loss: 4.320219993591309
training step: 36552, total_loss: 4.298432350158691
training step: 36553, total_loss: 5.649906158447266
training step: 36554, total_loss: 3.7933857440948486
training step: 36555, total_loss: 5.981493949890137
training step: 36556, total_loss: 5.52093505859375
training step: 36557, total_loss: 3.564206123352051
training step: 36558, total_loss: 3.3883485794067383
training step: 36559, total_loss: 3.3361411094665527
training step: 36560, total_loss: 3.8961753845214844
training step: 36561, total_loss: 3.8593673706054688
training step: 36562, total_loss: 4.683279991149902
training step: 36563, total_loss: 3.5047266483306885
training step: 36564, total_loss: 5.413440227508545
training step: 36565, total_loss: 4.981076240539551
training step: 36566, total_loss: 3.497021436691284
training step: 36567, total_loss: 3.50866961479187
training step: 36568, total_loss: 4.8388166427612305
training step: 36569, total_loss: 4.995537757873535
training step: 36570, total_loss: 2.6794567108154297
training step: 36571, total_loss: 5.862577438354492
training step: 36572, total_loss: 4.795302391052246
training step: 36573, total_loss: 3.702624797821045
training step: 36574, total_loss: 4.291409969329834
training step: 36575, total_loss: 4.571109294891357
training step: 36576, total_loss: 1.158877968788147
training step: 36577, total_loss: 3.9869298934936523
training step: 36578, total_loss: 4.583477020263672
training step: 36579, total_loss: 3.299917221069336
training step: 36580, total_loss: 5.934009075164795
training step: 36581, total_loss: 4.672127723693848
training step: 36582, total_loss: 4.803264617919922
training step: 36583, total_loss: 4.787147045135498
training step: 36584, total_loss: 4.539435386657715
training step: 36585, total_loss: 5.442728042602539
training step: 36586, total_loss: 5.073188781738281
training step: 36587, total_loss: 4.673801422119141
training step: 36588, total_loss: 4.799048900604248
training step: 36589, total_loss: 5.159594535827637
training step: 36590, total_loss: 4.86285400390625
training step: 36591, total_loss: 5.324777603149414
training step: 36592, total_loss: 3.322561740875244
training step: 36593, total_loss: 1.5905332565307617
training step: 36594, total_loss: 5.323006629943848
training step: 36595, total_loss: 4.030065536499023
training step: 36596, total_loss: 5.410736560821533
training step: 36597, total_loss: 4.978099822998047
training step: 36598, total_loss: 1.2927498817443848
training step: 36599, total_loss: 4.099769592285156
training step: 36600, total_loss: 3.758927822113037
training step: 36601, total_loss: 5.315706729888916
training step: 36602, total_loss: 3.8252854347229004
training step: 36603, total_loss: 3.9939351081848145
training step: 36604, total_loss: 3.9202303886413574
training step: 36605, total_loss: 4.8104658126831055
training step: 36606, total_loss: 3.695742130279541
training step: 36607, total_loss: 3.9879207611083984
training step: 36608, total_loss: 4.026526927947998
training step: 36609, total_loss: 4.462754726409912
training step: 36610, total_loss: 5.850346088409424
training step: 36611, total_loss: 3.6174628734588623
training step: 36612, total_loss: 4.134726047515869
training step: 36613, total_loss: 4.920722961425781
training step: 36614, total_loss: 4.175444602966309
training step: 36615, total_loss: 2.335273265838623
training step: 36616, total_loss: 3.752915620803833
training step: 36617, total_loss: 4.714231491088867
training step: 36618, total_loss: 3.6319713592529297
training step: 36619, total_loss: 4.443606853485107
training step: 36620, total_loss: 3.4564247131347656
training step: 36621, total_loss: 6.495908737182617
training step: 36622, total_loss: 2.5990686416625977
training step: 36623, total_loss: 5.783252716064453
training step: 36624, total_loss: 4.43460750579834
training step: 36625, total_loss: 3.408052921295166
training step: 36626, total_loss: 4.631833553314209
training step: 36627, total_loss: 4.425875186920166
training step: 36628, total_loss: 4.000265121459961
training step: 36629, total_loss: 5.270550727844238
training step: 36630, total_loss: 5.036364555358887
training step: 36631, total_loss: 5.743138313293457
training step: 36632, total_loss: 5.027312278747559
training step: 36633, total_loss: 3.2042999267578125
training step: 36634, total_loss: 3.044818878173828
training step: 36635, total_loss: 4.7248334884643555
training step: 36636, total_loss: 5.281111240386963
training step: 36637, total_loss: 4.873403549194336
training step: 36638, total_loss: 1.1653428077697754
training step: 36639, total_loss: 3.939310073852539
training step: 36640, total_loss: 0.9620385766029358
training step: 36641, total_loss: 4.710921287536621
training step: 36642, total_loss: 4.447808742523193
training step: 36643, total_loss: 4.570651054382324
training step: 36644, total_loss: 4.914186477661133
training step: 36645, total_loss: 4.821217060089111
training step: 36646, total_loss: 3.036372423171997
training step: 36647, total_loss: 3.308897018432617
training step: 36648, total_loss: 3.6171202659606934
training step: 36649, total_loss: 5.603982925415039
training step: 36650, total_loss: 4.405158996582031
training step: 36651, total_loss: 4.645895957946777
training step: 36652, total_loss: 5.221124649047852
training step: 36653, total_loss: 1.1603291034698486
training step: 36654, total_loss: 4.494287967681885
training step: 36655, total_loss: 4.8534440994262695
training step: 36656, total_loss: 0.8998969793319702
training step: 36657, total_loss: 4.853871822357178
training step: 36658, total_loss: 5.139660835266113
training step: 36659, total_loss: 4.578557014465332
training step: 36660, total_loss: 4.101748466491699
training step: 36661, total_loss: 4.433635711669922
training step: 36662, total_loss: 3.612089157104492
training step: 36663, total_loss: 7.039897918701172
training step: 36664, total_loss: 3.3074238300323486
training step: 36665, total_loss: 3.272209644317627
training step: 36666, total_loss: 3.2444581985473633
training step: 36667, total_loss: 5.229618072509766
training step: 36668, total_loss: 5.217716217041016
training step: 36669, total_loss: 5.307806015014648
training step: 36670, total_loss: 4.306946754455566
training step: 36671, total_loss: 3.146646499633789
training step: 36672, total_loss: 4.929815292358398
training step: 36673, total_loss: 4.239245414733887
training step: 36674, total_loss: 3.985297679901123
training step: 36675, total_loss: 0.9685324430465698
training step: 36676, total_loss: 1.029675841331482
training step: 36677, total_loss: 4.078855514526367
training step: 36678, total_loss: 4.921414375305176
training step: 36679, total_loss: 5.407529830932617
training step: 36680, total_loss: 4.669878005981445
training step: 36681, total_loss: 4.082187652587891
training step: 36682, total_loss: 5.709658622741699
training step: 36683, total_loss: 4.426599025726318
training step: 36684, total_loss: 2.052809238433838
training step: 36685, total_loss: 5.085042476654053
training step: 36686, total_loss: 4.799049377441406
training step: 36687, total_loss: 3.6976559162139893
training step: 36688, total_loss: 5.4197001457214355
training step: 36689, total_loss: 4.641851425170898
training step: 36690, total_loss: 5.790590763092041
training step: 36691, total_loss: 4.267780303955078
training step: 36692, total_loss: 3.528425693511963
training step: 36693, total_loss: 6.147652626037598
training step: 36694, total_loss: 5.2192182540893555
training step: 36695, total_loss: 4.155858039855957
training step: 36696, total_loss: 5.191890716552734
training step: 36697, total_loss: 3.1076698303222656
training step: 36698, total_loss: 5.136701583862305
training step: 36699, total_loss: 2.7515273094177246
training step: 36700, total_loss: 3.803974151611328
training step: 36701, total_loss: 5.468089580535889
training step: 36702, total_loss: 5.232425689697266
training step: 36703, total_loss: 5.143259525299072
training step: 36704, total_loss: 4.552588939666748
training step: 36705, total_loss: 5.094654560089111
training step: 36706, total_loss: 4.460371494293213
training step: 36707, total_loss: 5.849756717681885
training step: 36708, total_loss: 4.064217567443848
training step: 36709, total_loss: 4.946196556091309
training step: 36710, total_loss: 2.70499324798584
training step: 36711, total_loss: 5.680051803588867
training step: 36712, total_loss: 5.250870227813721
training step: 36713, total_loss: 5.691384315490723
training step: 36714, total_loss: 4.32497501373291
training step: 36715, total_loss: 3.2534379959106445
training step: 36716, total_loss: 4.59530782699585
training step: 36717, total_loss: 5.071334362030029
training step: 36718, total_loss: 4.091886043548584
training step: 36719, total_loss: 5.58161735534668
training step: 36720, total_loss: 4.345061779022217
training step: 36721, total_loss: 4.535811424255371
training step: 36722, total_loss: 3.6054201126098633
training step: 36723, total_loss: 5.478991508483887
training step: 36724, total_loss: 3.7629380226135254
training step: 36725, total_loss: 3.345170497894287
training step: 36726, total_loss: 3.917471408843994
training step: 36727, total_loss: 4.700536727905273
training step: 36728, total_loss: 4.926615238189697
training step: 36729, total_loss: 3.8686370849609375
training step: 36730, total_loss: 3.9369113445281982
training step: 36731, total_loss: 5.515819549560547
training step: 36732, total_loss: 5.055349826812744
training step: 36733, total_loss: 3.9478955268859863
training step: 36734, total_loss: 4.726994037628174
training step: 36735, total_loss: 5.335099220275879
training step: 36736, total_loss: 4.152441024780273
training step: 36737, total_loss: 4.513171672821045
training step: 36738, total_loss: 4.297140121459961
training step: 36739, total_loss: 3.8281407356262207
training step: 36740, total_loss: 4.687571048736572
training step: 36741, total_loss: 4.121189594268799
training step: 36742, total_loss: 5.788202285766602
training step: 36743, total_loss: 5.714827537536621
training step: 36744, total_loss: 5.088818073272705
training step: 36745, total_loss: 4.836031436920166
training step: 36746, total_loss: 4.160243988037109
training step: 36747, total_loss: 3.7944138050079346
training step: 36748, total_loss: 3.9254891872406006
training step: 36749, total_loss: 4.668105125427246
training step: 36750, total_loss: 3.5461983680725098
training step: 36751, total_loss: 5.1593427658081055
training step: 36752, total_loss: 5.309077739715576
training step: 36753, total_loss: 4.19879150390625
training step: 36754, total_loss: 3.5450406074523926
training step: 36755, total_loss: 1.2220087051391602
training step: 36756, total_loss: 3.9456522464752197
training step: 36757, total_loss: 4.49306058883667
training step: 36758, total_loss: 3.305178165435791
training step: 36759, total_loss: 4.262750625610352
training step: 36760, total_loss: 3.642300605773926
training step: 36761, total_loss: 4.714001655578613
training step: 36762, total_loss: 5.091416358947754
training step: 36763, total_loss: 1.2654352188110352
training step: 36764, total_loss: 5.242754936218262
training step: 36765, total_loss: 5.550246238708496
training step: 36766, total_loss: 5.19634485244751
training step: 36767, total_loss: 5.238762378692627
training step: 36768, total_loss: 4.059638023376465
training step: 36769, total_loss: 4.3123297691345215
training step: 36770, total_loss: 4.0176286697387695
training step: 36771, total_loss: 2.815556049346924
training step: 36772, total_loss: 5.2605485916137695
training step: 36773, total_loss: 5.071160316467285
training step: 36774, total_loss: 5.071865081787109
training step: 36775, total_loss: 4.19698429107666
training step: 36776, total_loss: 5.569227695465088
training step: 36777, total_loss: 5.515680313110352
training step: 36778, total_loss: 4.330410957336426
training step: 36779, total_loss: 4.138912677764893
training step: 36780, total_loss: 4.869068145751953
training step: 36781, total_loss: 3.9625048637390137
training step: 36782, total_loss: 4.517834186553955
training step: 36783, total_loss: 3.2287261486053467
training step: 36784, total_loss: 3.9609286785125732
training step: 36785, total_loss: 4.2745466232299805
training step: 36786, total_loss: 3.6961421966552734
training step: 36787, total_loss: 4.415805816650391
training step: 36788, total_loss: 4.042752265930176
training step: 36789, total_loss: 4.996564865112305
training step: 36790, total_loss: 4.656067848205566
training step: 36791, total_loss: 1.6981711387634277
training step: 36792, total_loss: 3.9772114753723145
training step: 36793, total_loss: 4.362558841705322
training step: 36794, total_loss: 4.988069534301758
training step: 36795, total_loss: 4.137990951538086
training step: 36796, total_loss: 3.920614004135132
training step: 36797, total_loss: 3.034771203994751
training step: 36798, total_loss: 2.86356782913208
training step: 36799, total_loss: 4.192927837371826
training step: 36800, total_loss: 4.53702449798584
training step: 36801, total_loss: 3.344906806945801
training step: 36802, total_loss: 2.5191285610198975
training step: 36803, total_loss: 4.6073784828186035
training step: 36804, total_loss: 4.51621150970459
training step: 36805, total_loss: 3.3866028785705566
training step: 36806, total_loss: 4.833839416503906
training step: 36807, total_loss: 4.080900192260742
training step: 36808, total_loss: 4.738077163696289
training step: 36809, total_loss: 4.136569499969482
training step: 36810, total_loss: 5.9280805587768555
training step: 36811, total_loss: 5.614377021789551
training step: 36812, total_loss: 3.867617607116699
training step: 36813, total_loss: 4.34073543548584
training step: 36814, total_loss: 5.988831996917725
training step: 36815, total_loss: 4.462348461151123
training step: 36816, total_loss: 4.783444404602051
training step: 36817, total_loss: 4.934556007385254
training step: 36818, total_loss: 4.293630599975586
training step: 36819, total_loss: 3.9466195106506348
training step: 36820, total_loss: 3.9640207290649414
training step: 36821, total_loss: 2.098468780517578
training step: 36822, total_loss: 3.146599769592285
training step: 36823, total_loss: 4.8202338218688965
training step: 36824, total_loss: 4.9230546951293945
training step: 36825, total_loss: 3.798351287841797
training step: 36826, total_loss: 5.662045955657959
training step: 36827, total_loss: 3.279560089111328
training step: 36828, total_loss: 4.552796840667725
training step: 36829, total_loss: 2.7392807006835938
training step: 36830, total_loss: 2.398676872253418
training step: 36831, total_loss: 4.186307907104492
training step: 36832, total_loss: 4.117016792297363
training step: 36833, total_loss: 3.93290376663208
training step: 36834, total_loss: 3.8912150859832764
training step: 36835, total_loss: 3.311659812927246
training step: 36836, total_loss: 4.292581081390381
training step: 36837, total_loss: 4.469182968139648
training step: 36838, total_loss: 5.1914381980896
training step: 36839, total_loss: 3.434645891189575
training step: 36840, total_loss: 4.731220722198486
training step: 36841, total_loss: 3.0319414138793945
training step: 36842, total_loss: 5.460986137390137
training step: 36843, total_loss: 3.959350347518921
training step: 36844, total_loss: 5.129209518432617
training step: 36845, total_loss: 4.715160846710205
training step: 36846, total_loss: 2.5995264053344727
training step: 36847, total_loss: 4.798311233520508
training step: 36848, total_loss: 5.703090190887451
training step: 36849, total_loss: 3.645475387573242
training step: 36850, total_loss: 3.172706127166748
training step: 36851, total_loss: 2.435224771499634
training step: 36852, total_loss: 3.140423536300659
training step: 36853, total_loss: 4.811609268188477
training step: 36854, total_loss: 3.712571144104004
training step: 36855, total_loss: 3.9369020462036133
training step: 36856, total_loss: 3.6795127391815186
training step: 36857, total_loss: 3.5601511001586914
training step: 36858, total_loss: 3.9572949409484863
training step: 36859, total_loss: 3.3426876068115234
training step: 36860, total_loss: 4.51076078414917
training step: 36861, total_loss: 5.8912763595581055
training step: 36862, total_loss: 3.0473990440368652
training step: 36863, total_loss: 3.710157871246338
training step: 36864, total_loss: 3.5460472106933594
training step: 36865, total_loss: 4.028086185455322
training step: 36866, total_loss: 4.268210411071777
training step: 36867, total_loss: 3.497288227081299
training step: 36868, total_loss: 1.0109069347381592
training step: 36869, total_loss: 5.614999771118164
training step: 36870, total_loss: 5.19834041595459
training step: 36871, total_loss: 5.00661563873291
training step: 36872, total_loss: 2.718156337738037
training step: 36873, total_loss: 2.105919122695923
training step: 36874, total_loss: 3.8900070190429688
training step: 36875, total_loss: 4.6337738037109375
training step: 36876, total_loss: 4.5619001388549805
training step: 36877, total_loss: 5.303582191467285
training step: 36878, total_loss: 1.1140271425247192
training step: 36879, total_loss: 2.682049036026001
training step: 36880, total_loss: 4.767214298248291
training step: 36881, total_loss: 5.244052410125732
training step: 36882, total_loss: 4.441993713378906
training step: 36883, total_loss: 5.936943054199219
training step: 36884, total_loss: 4.4697394371032715
training step: 36885, total_loss: 3.9216859340667725
training step: 36886, total_loss: 3.517728328704834
training step: 36887, total_loss: 3.9679951667785645
training step: 36888, total_loss: 5.913010597229004
training step: 36889, total_loss: 4.683194160461426
training step: 36890, total_loss: 4.477032661437988
training step: 36891, total_loss: 4.946849822998047
training step: 36892, total_loss: 4.522820472717285
training step: 36893, total_loss: 5.250177383422852
training step: 36894, total_loss: 5.8578386306762695
training step: 36895, total_loss: 5.214995384216309
training step: 36896, total_loss: 4.53409481048584
training step: 36897, total_loss: 5.808308124542236
training step: 36898, total_loss: 4.786391258239746
training step: 36899, total_loss: 5.567453384399414
training step: 36900, total_loss: 5.506476402282715
training step: 36901, total_loss: 4.631814956665039
training step: 36902, total_loss: 3.8525843620300293
training step: 36903, total_loss: 4.143662452697754
training step: 36904, total_loss: 4.768520355224609
training step: 36905, total_loss: 4.4790191650390625
training step: 36906, total_loss: 3.556312084197998
training step: 36907, total_loss: 4.129909038543701
training step: 36908, total_loss: 4.5737504959106445
training step: 36909, total_loss: 7.020031929016113
training step: 36910, total_loss: 5.05851936340332
training step: 36911, total_loss: 4.74983024597168
training step: 36912, total_loss: 5.150003910064697
training step: 36913, total_loss: 4.527177810668945
training step: 36914, total_loss: 4.667776584625244
training step: 36915, total_loss: 4.403120517730713
training step: 36916, total_loss: 4.406045913696289
training step: 36917, total_loss: 4.239060878753662
training step: 36918, total_loss: 4.308653831481934
training step: 36919, total_loss: 4.0277791023254395
training step: 36920, total_loss: 3.676210880279541
training step: 36921, total_loss: 2.4059717655181885
training step: 36922, total_loss: 4.764019966125488
training step: 36923, total_loss: 5.192869186401367
training step: 36924, total_loss: 5.0123114585876465
training step: 36925, total_loss: 4.848362922668457
training step: 36926, total_loss: 5.172504901885986
training step: 36927, total_loss: 5.125051498413086
training step: 36928, total_loss: 4.90614652633667
training step: 36929, total_loss: 4.708172798156738
training step: 36930, total_loss: 4.371377944946289
training step: 36931, total_loss: 3.135356903076172
training step: 36932, total_loss: 5.282135009765625
training step: 36933, total_loss: 1.0749101638793945
training step: 36934, total_loss: 4.227871417999268
training step: 36935, total_loss: 5.192238807678223
training step: 36936, total_loss: 3.5906219482421875
training step: 36937, total_loss: 4.800859451293945
training step: 36938, total_loss: 3.682677745819092
training step: 36939, total_loss: 3.6153159141540527
training step: 36940, total_loss: 5.90797233581543
training step: 36941, total_loss: 4.576253414154053
training step: 36942, total_loss: 4.884397029876709
training step: 36943, total_loss: 4.523950099945068
training step: 36944, total_loss: 3.788092613220215
training step: 36945, total_loss: 3.758474349975586
training step: 36946, total_loss: 4.9666829109191895
training step: 36947, total_loss: 3.7682418823242188
training step: 36948, total_loss: 4.879775047302246
training step: 36949, total_loss: 5.742244720458984
training step: 36950, total_loss: 4.1615753173828125
training step: 36951, total_loss: 5.490382194519043
training step: 36952, total_loss: 4.215177536010742
training step: 36953, total_loss: 2.229645013809204
training step: 36954, total_loss: 5.153384685516357
training step: 36955, total_loss: 4.457747459411621
training step: 36956, total_loss: 4.617780685424805
training step: 36957, total_loss: 5.53078556060791
training step: 36958, total_loss: 6.668489456176758
training step: 36959, total_loss: 5.295806884765625
training step: 36960, total_loss: 4.443902969360352
training step: 36961, total_loss: 1.056920051574707
training step: 36962, total_loss: 3.7146284580230713
training step: 36963, total_loss: 2.6490843296051025
training step: 36964, total_loss: 3.232974052429199
training step: 36965, total_loss: 5.265494346618652
training step: 36966, total_loss: 4.295966625213623
training step: 36967, total_loss: 5.190507411956787
training step: 36968, total_loss: 3.815063714981079
training step: 36969, total_loss: 3.886826276779175
training step: 36970, total_loss: 3.2781355381011963
training step: 36971, total_loss: 4.280277729034424
training step: 36972, total_loss: 4.0274553298950195
training step: 36973, total_loss: 5.95454216003418
training step: 36974, total_loss: 5.0923590660095215
training step: 36975, total_loss: 2.0285844802856445
training step: 36976, total_loss: 4.255627632141113
training step: 36977, total_loss: 3.961010456085205
training step: 36978, total_loss: 5.166604518890381
training step: 36979, total_loss: 0.8944958448410034
training step: 36980, total_loss: 3.8643202781677246
training step: 36981, total_loss: 3.9697861671447754
training step: 36982, total_loss: 6.288156986236572
training step: 36983, total_loss: 4.970518112182617
training step: 36984, total_loss: 4.910039901733398
training step: 36985, total_loss: 4.60023832321167
training step: 36986, total_loss: 4.862985610961914
training step: 36987, total_loss: 4.21900749206543
training step: 36988, total_loss: 4.084566116333008
training step: 36989, total_loss: 4.097987174987793
training step: 36990, total_loss: 5.01707649230957
training step: 36991, total_loss: 5.423907279968262
training step: 36992, total_loss: 4.481616020202637
training step: 36993, total_loss: 5.411279678344727
training step: 36994, total_loss: 3.7869162559509277
training step: 36995, total_loss: 5.125292778015137
training step: 36996, total_loss: 2.7566137313842773
training step: 36997, total_loss: 4.287642955780029
training step: 36998, total_loss: 4.832335472106934
training step: 36999, total_loss: 3.9030470848083496
training step: 37000, total_loss: 1.8021365404129028
training step: 37001, total_loss: 4.533832550048828
training step: 37002, total_loss: 5.596116065979004
training step: 37003, total_loss: 4.571540832519531
training step: 37004, total_loss: 4.384743690490723
training step: 37005, total_loss: 4.7856597900390625
training step: 37006, total_loss: 4.252318382263184
training step: 37007, total_loss: 5.21401309967041
training step: 37008, total_loss: 4.650605201721191
training step: 37009, total_loss: 4.331485748291016
training step: 37010, total_loss: 2.290699005126953
training step: 37011, total_loss: 4.035916328430176
training step: 37012, total_loss: 4.017023086547852
training step: 37013, total_loss: 5.05788516998291
training step: 37014, total_loss: 4.93174934387207
training step: 37015, total_loss: 4.815300941467285
training step: 37016, total_loss: 4.5952253341674805
training step: 37017, total_loss: 3.0196328163146973
training step: 37018, total_loss: 3.394596815109253
training step: 37019, total_loss: 4.766147136688232
training step: 37020, total_loss: 4.749683380126953
training step: 37021, total_loss: 3.64965558052063
training step: 37022, total_loss: 4.453813552856445
training step: 37023, total_loss: 5.507416725158691
training step: 37024, total_loss: 4.4365692138671875
training step: 37025, total_loss: 3.6474719047546387
training step: 37026, total_loss: 4.228748321533203
training step: 37027, total_loss: 3.0849430561065674
training step: 37028, total_loss: 4.991767883300781
training step: 37029, total_loss: 5.512252330780029
training step: 37030, total_loss: 4.531742572784424
training step: 37031, total_loss: 4.6023054122924805
training step: 37032, total_loss: 2.841684579849243
training step: 37033, total_loss: 4.265986442565918
training step: 37034, total_loss: 6.729315757751465
training step: 37035, total_loss: 4.548550605773926
training step: 37036, total_loss: 4.560964107513428
training step: 37037, total_loss: 5.298431873321533
training step: 37038, total_loss: 4.684573650360107
training step: 37039, total_loss: 3.8028955459594727
training step: 37040, total_loss: 5.847414970397949
training step: 37041, total_loss: 4.009768486022949
training step: 37042, total_loss: 3.9133100509643555
training step: 37043, total_loss: 3.7752456665039062
training step: 37044, total_loss: 2.325531005859375
training step: 37045, total_loss: 5.749239444732666
training step: 37046, total_loss: 1.5513588190078735
training step: 37047, total_loss: 5.476014137268066
training step: 37048, total_loss: 2.7090516090393066
training step: 37049, total_loss: 4.080660343170166
training step: 37050, total_loss: 5.327218532562256
training step: 37051, total_loss: 4.284972190856934
training step: 37052, total_loss: 1.1181267499923706
training step: 37053, total_loss: 3.507861614227295
training step: 37054, total_loss: 4.7949113845825195
training step: 37055, total_loss: 4.3846588134765625
training step: 37056, total_loss: 5.347164154052734
training step: 37057, total_loss: 6.337303161621094
training step: 37058, total_loss: 4.065691947937012
training step: 37059, total_loss: 2.3922901153564453
training step: 37060, total_loss: 4.515284538269043
training step: 37061, total_loss: 5.041330814361572
training step: 37062, total_loss: 4.913222312927246
training step: 37063, total_loss: 3.5608696937561035
training step: 37064, total_loss: 3.4430079460144043
training step: 37065, total_loss: 5.916887283325195
training step: 37066, total_loss: 3.6656177043914795
training step: 37067, total_loss: 4.749139308929443
training step: 37068, total_loss: 3.2664928436279297
training step: 37069, total_loss: 3.5537109375
training step: 37070, total_loss: 4.292085647583008
training step: 37071, total_loss: 5.612983226776123
training step: 37072, total_loss: 3.949601411819458
training step: 37073, total_loss: 4.830595970153809
training step: 37074, total_loss: 3.7383878231048584
training step: 37075, total_loss: 3.7140731811523438
training step: 37076, total_loss: 2.8785288333892822
training step: 37077, total_loss: 3.078157424926758
training step: 37078, total_loss: 2.8297877311706543
training step: 37079, total_loss: 3.1823718547821045
training step: 37080, total_loss: 4.199944019317627
training step: 37081, total_loss: 4.478882789611816
training step: 37082, total_loss: 7.280814170837402
training step: 37083, total_loss: 5.135904312133789
training step: 37084, total_loss: 4.855672836303711
training step: 37085, total_loss: 5.319664478302002
training step: 37086, total_loss: 5.442336082458496
training step: 37087, total_loss: 5.133752822875977
training step: 37088, total_loss: 4.623539924621582
training step: 37089, total_loss: 5.86967658996582
training step: 37090, total_loss: 4.869966506958008
training step: 37091, total_loss: 5.5446882247924805
training step: 37092, total_loss: 4.057143211364746
training step: 37093, total_loss: 4.590254783630371
training step: 37094, total_loss: 4.671692371368408
training step: 37095, total_loss: 4.200211524963379
training step: 37096, total_loss: 3.9910027980804443
training step: 37097, total_loss: 5.281959533691406
training step: 37098, total_loss: 3.274458408355713
training step: 37099, total_loss: 5.4325456619262695
training step: 37100, total_loss: 4.635049819946289
training step: 37101, total_loss: 2.255382537841797
training step: 37102, total_loss: 4.205414295196533
training step: 37103, total_loss: 3.2046985626220703
training step: 37104, total_loss: 4.930120468139648
training step: 37105, total_loss: 5.438547611236572
training step: 37106, total_loss: 4.605236053466797
training step: 37107, total_loss: 1.9551726579666138
training step: 37108, total_loss: 5.904691219329834
training step: 37109, total_loss: 5.04797887802124
training step: 37110, total_loss: 3.7879629135131836
training step: 37111, total_loss: 4.256640434265137
training step: 37112, total_loss: 4.189671516418457
training step: 37113, total_loss: 4.13318395614624
training step: 37114, total_loss: 2.718402862548828
training step: 37115, total_loss: 4.807443141937256
training step: 37116, total_loss: 3.6389122009277344
training step: 37117, total_loss: 4.175967216491699
training step: 37118, total_loss: 3.6342129707336426
training step: 37119, total_loss: 3.2946059703826904
training step: 37120, total_loss: 4.810194969177246
training step: 37121, total_loss: 4.826513767242432
training step: 37122, total_loss: 4.237909317016602
training step: 37123, total_loss: 6.285709381103516
training step: 37124, total_loss: 4.180426597595215
training step: 37125, total_loss: 3.5969252586364746
training step: 37126, total_loss: 4.517751216888428
training step: 37127, total_loss: 4.588551044464111
training step: 37128, total_loss: 5.977416038513184
training step: 37129, total_loss: 4.676873207092285
training step: 37130, total_loss: 4.338308334350586
training step: 37131, total_loss: 1.023076057434082
training step: 37132, total_loss: 7.2085418701171875
training step: 37133, total_loss: 3.8131580352783203
training step: 37134, total_loss: 4.0762739181518555
training step: 37135, total_loss: 3.8178811073303223
training step: 37136, total_loss: 4.532270431518555
training step: 37137, total_loss: 4.71232795715332
training step: 37138, total_loss: 4.159212589263916
training step: 37139, total_loss: 4.846493721008301
training step: 37140, total_loss: 5.299304008483887
training step: 37141, total_loss: 3.9046168327331543
training step: 37142, total_loss: 2.9300503730773926
training step: 37143, total_loss: 3.2443857192993164
training step: 37144, total_loss: 2.984673023223877
training step: 37145, total_loss: 4.1090850830078125
training step: 37146, total_loss: 3.3825244903564453
training step: 37147, total_loss: 2.8615503311157227
training step: 37148, total_loss: 4.265949249267578
training step: 37149, total_loss: 2.613682270050049
training step: 37150, total_loss: 5.277753829956055
training step: 37151, total_loss: 4.124205589294434
training step: 37152, total_loss: 4.934447288513184
training step: 37153, total_loss: 5.396537780761719
training step: 37154, total_loss: 5.1504716873168945
training step: 37155, total_loss: 4.507991790771484
training step: 37156, total_loss: 3.3608198165893555
training step: 37157, total_loss: 2.6678013801574707
training step: 37158, total_loss: 4.601781845092773
training step: 37159, total_loss: 4.6650543212890625
training step: 37160, total_loss: 4.535039901733398
training step: 37161, total_loss: 6.138872146606445
training step: 37162, total_loss: 3.3315176963806152
training step: 37163, total_loss: 4.319629669189453
training step: 37164, total_loss: 4.994190216064453
training step: 37165, total_loss: 5.599126815795898
training step: 37166, total_loss: 3.84765625
training step: 37167, total_loss: 4.851447105407715
training step: 37168, total_loss: 5.352017402648926
training step: 37169, total_loss: 4.839092254638672
training step: 37170, total_loss: 4.637211322784424
training step: 37171, total_loss: 5.1299662590026855
training step: 37172, total_loss: 4.848783493041992
training step: 37173, total_loss: 4.737636566162109
training step: 37174, total_loss: 4.268406867980957
training step: 37175, total_loss: 1.1250874996185303
training step: 37176, total_loss: 4.657045364379883
training step: 37177, total_loss: 4.7190260887146
training step: 37178, total_loss: 3.6281609535217285
training step: 37179, total_loss: 4.0272016525268555
training step: 37180, total_loss: 4.8510332107543945
training step: 37181, total_loss: 5.549220085144043
training step: 37182, total_loss: 5.342665195465088
training step: 37183, total_loss: 3.545208215713501
training step: 37184, total_loss: 5.3567352294921875
training step: 37185, total_loss: 1.1101222038269043
training step: 37186, total_loss: 4.32139778137207
training step: 37187, total_loss: 5.314514636993408
training step: 37188, total_loss: 4.786778926849365
training step: 37189, total_loss: 2.911820888519287
training step: 37190, total_loss: 3.738273859024048
training step: 37191, total_loss: 3.802680253982544
training step: 37192, total_loss: 5.056209564208984
training step: 37193, total_loss: 2.5251245498657227
training step: 37194, total_loss: 3.0497195720672607
training step: 37195, total_loss: 4.935066223144531
training step: 37196, total_loss: 6.246689319610596
training step: 37197, total_loss: 3.014636993408203
training step: 37198, total_loss: 4.152310371398926
training step: 37199, total_loss: 5.363161087036133
training step: 37200, total_loss: 4.988486289978027
training step: 37201, total_loss: 4.085019588470459
training step: 37202, total_loss: 2.4122722148895264
training step: 37203, total_loss: 6.948752403259277
training step: 37204, total_loss: 4.928854465484619
training step: 37205, total_loss: 4.7706217765808105
training step: 37206, total_loss: 4.085864067077637
training step: 37207, total_loss: 3.7538132667541504
training step: 37208, total_loss: 5.538293361663818
training step: 37209, total_loss: 4.863234519958496
training step: 37210, total_loss: 6.148019790649414
training step: 37211, total_loss: 2.444169521331787
training step: 37212, total_loss: 3.6347107887268066
training step: 37213, total_loss: 5.028412818908691
training step: 37214, total_loss: 4.82174015045166
training step: 37215, total_loss: 3.883455753326416
training step: 37216, total_loss: 4.366239547729492
training step: 37217, total_loss: 4.3985700607299805
training step: 37218, total_loss: 5.601146697998047
training step: 37219, total_loss: 4.7691144943237305
training step: 37220, total_loss: 4.467222213745117
training step: 37221, total_loss: 3.734659194946289
training step: 37222, total_loss: 2.9156932830810547
training step: 37223, total_loss: 4.541599750518799
training step: 37224, total_loss: 6.200402736663818
training step: 37225, total_loss: 0.8664865493774414
training step: 37226, total_loss: 6.253108024597168
training step: 37227, total_loss: 4.584199905395508
training step: 37228, total_loss: 3.704357624053955
training step: 37229, total_loss: 4.572305202484131
training step: 37230, total_loss: 3.5197813510894775
training step: 37231, total_loss: 4.791565418243408
training step: 37232, total_loss: 4.899489879608154
training step: 37233, total_loss: 4.131155490875244
training step: 37234, total_loss: 5.362577438354492
training step: 37235, total_loss: 4.282391548156738
training step: 37236, total_loss: 4.915135860443115
training step: 37237, total_loss: 4.142475605010986
training step: 37238, total_loss: 4.235868453979492
training step: 37239, total_loss: 4.236388683319092
training step: 37240, total_loss: 1.6175997257232666
training step: 37241, total_loss: 6.250343322753906
training step: 37242, total_loss: 4.1107683181762695
training step: 37243, total_loss: 3.2569174766540527
training step: 37244, total_loss: 4.4578447341918945
training step: 37245, total_loss: 2.9311962127685547
training step: 37246, total_loss: 3.7581517696380615
training step: 37247, total_loss: 3.8757851123809814
training step: 37248, total_loss: 4.001572608947754
training step: 37249, total_loss: 4.667333602905273
training step: 37250, total_loss: 5.342471122741699
training step: 37251, total_loss: 6.199128150939941
training step: 37252, total_loss: 4.252114295959473
training step: 37253, total_loss: 4.55954647064209
training step: 37254, total_loss: 4.543516159057617
training step: 37255, total_loss: 4.64592170715332
training step: 37256, total_loss: 4.687055587768555
training step: 37257, total_loss: 3.5498805046081543
training step: 37258, total_loss: 4.721441268920898
training step: 37259, total_loss: 4.706321716308594
training step: 37260, total_loss: 6.261674880981445
training step: 37261, total_loss: 4.151206016540527
training step: 37262, total_loss: 3.7474896907806396
training step: 37263, total_loss: 5.754053115844727
training step: 37264, total_loss: 5.304222106933594
training step: 37265, total_loss: 5.141651153564453
training step: 37266, total_loss: 5.003652572631836
training step: 37267, total_loss: 4.503148078918457
training step: 37268, total_loss: 4.322342872619629
training step: 37269, total_loss: 4.4439897537231445
training step: 37270, total_loss: 4.598137378692627
training step: 37271, total_loss: 1.6561334133148193
training step: 37272, total_loss: 4.149559497833252
training step: 37273, total_loss: 4.545526504516602
training step: 37274, total_loss: 5.201427459716797
training step: 37275, total_loss: 5.485461235046387
training step: 37276, total_loss: 3.291902542114258
training step: 37277, total_loss: 4.0300703048706055
training step: 37278, total_loss: 5.426105499267578
training step: 37279, total_loss: 4.225963592529297
training step: 37280, total_loss: 6.174657821655273
training step: 37281, total_loss: 4.581676483154297
training step: 37282, total_loss: 4.043928146362305
training step: 37283, total_loss: 1.37917160987854
training step: 37284, total_loss: 2.567624807357788
training step: 37285, total_loss: 4.728949069976807
training step: 37286, total_loss: 4.563667297363281
training step: 37287, total_loss: 4.795823574066162
training step: 37288, total_loss: 7.188967227935791
training step: 37289, total_loss: 5.3070969581604
training step: 37290, total_loss: 2.9045066833496094
training step: 37291, total_loss: 4.664219856262207
training step: 37292, total_loss: 5.024683952331543
training step: 37293, total_loss: 4.353353023529053
training step: 37294, total_loss: 4.141303539276123
training step: 37295, total_loss: 1.314686894416809
training step: 37296, total_loss: 5.951521873474121
training step: 37297, total_loss: 5.303738594055176
training step: 37298, total_loss: 4.605466842651367
training step: 37299, total_loss: 6.296643257141113
training step: 37300, total_loss: 4.9891357421875
training step: 37301, total_loss: 4.807212829589844
training step: 37302, total_loss: 4.285772323608398
training step: 37303, total_loss: 4.575115203857422
training step: 37304, total_loss: 4.380135536193848
training step: 37305, total_loss: 4.732609748840332
training step: 37306, total_loss: 4.234281539916992
training step: 37307, total_loss: 4.960515975952148
training step: 37308, total_loss: 6.321943283081055
training step: 37309, total_loss: 4.479663372039795
training step: 37310, total_loss: 4.581247329711914
training step: 37311, total_loss: 4.891467571258545
training step: 37312, total_loss: 4.931060791015625
training step: 37313, total_loss: 3.1499924659729004
training step: 37314, total_loss: 4.1198906898498535
training step: 37315, total_loss: 4.005461692810059
training step: 37316, total_loss: 4.877110481262207
training step: 37317, total_loss: 4.191731929779053
training step: 37318, total_loss: 5.57889461517334
training step: 37319, total_loss: 4.378640174865723
training step: 37320, total_loss: 4.403395175933838
training step: 37321, total_loss: 3.5408835411071777
training step: 37322, total_loss: 4.79124641418457
training step: 37323, total_loss: 4.561232566833496
training step: 37324, total_loss: 3.731266736984253
training step: 37325, total_loss: 5.516650676727295
training step: 37326, total_loss: 3.992949962615967
training step: 37327, total_loss: 3.197131395339966
training step: 37328, total_loss: 3.3708925247192383
training step: 37329, total_loss: 6.5984954833984375
training step: 37330, total_loss: 4.9275031089782715
training step: 37331, total_loss: 4.929481029510498
training step: 37332, total_loss: 3.531432628631592
training step: 37333, total_loss: 3.6979007720947266
training step: 37334, total_loss: 5.520477294921875
training step: 37335, total_loss: 5.565547943115234
training step: 37336, total_loss: 4.865607261657715
training step: 37337, total_loss: 5.123568058013916
training step: 37338, total_loss: 4.768982887268066
training step: 37339, total_loss: 3.3106818199157715
training step: 37340, total_loss: 4.67622184753418
training step: 37341, total_loss: 4.218990802764893
training step: 37342, total_loss: 3.5107879638671875
training step: 37343, total_loss: 4.983126163482666
training step: 37344, total_loss: 5.140952110290527
training step: 37345, total_loss: 5.0793328285217285
training step: 37346, total_loss: 3.9252285957336426
training step: 37347, total_loss: 4.574697494506836
training step: 37348, total_loss: 4.612867832183838
training step: 37349, total_loss: 3.154444694519043
training step: 37350, total_loss: 4.684378623962402
training step: 37351, total_loss: 4.728863716125488
training step: 37352, total_loss: 4.782617568969727
training step: 37353, total_loss: 4.1228179931640625
training step: 37354, total_loss: 5.495622158050537
training step: 37355, total_loss: 1.469499111175537
training step: 37356, total_loss: 3.898512363433838
training step: 37357, total_loss: 3.5576114654541016
training step: 37358, total_loss: 3.4631845951080322
training step: 37359, total_loss: 4.799201011657715
training step: 37360, total_loss: 5.873927116394043
training step: 37361, total_loss: 5.122962951660156
training step: 37362, total_loss: 3.4455575942993164
training step: 37363, total_loss: 5.34377384185791
training step: 37364, total_loss: 5.726951599121094
training step: 37365, total_loss: 5.036639213562012
training step: 37366, total_loss: 3.3773903846740723
training step: 37367, total_loss: 4.603794574737549
training step: 37368, total_loss: 3.448758602142334
training step: 37369, total_loss: 4.307318210601807
training step: 37370, total_loss: 4.462386131286621
training step: 37371, total_loss: 4.574100494384766
training step: 37372, total_loss: 4.235005855560303
training step: 37373, total_loss: 5.251180648803711
training step: 37374, total_loss: 4.567149639129639
training step: 37375, total_loss: 3.382050037384033
training step: 37376, total_loss: 5.400566101074219
training step: 37377, total_loss: 4.070169448852539
training step: 37378, total_loss: 4.150989532470703
training step: 37379, total_loss: 6.217016696929932
training step: 37380, total_loss: 5.827726364135742
training step: 37381, total_loss: 4.175198554992676
training step: 37382, total_loss: 4.420742988586426
training step: 37383, total_loss: 3.754997730255127
training step: 37384, total_loss: 4.673152923583984
training step: 37385, total_loss: 4.062863349914551
training step: 37386, total_loss: 5.131446838378906
training step: 37387, total_loss: 4.686095237731934
training step: 37388, total_loss: 3.820218563079834
training step: 37389, total_loss: 2.982863187789917
training step: 37390, total_loss: 3.437896728515625
training step: 37391, total_loss: 4.11209774017334
training step: 37392, total_loss: 5.991501808166504
training step: 37393, total_loss: 3.2956349849700928
training step: 37394, total_loss: 4.238959312438965
training step: 37395, total_loss: 4.854827880859375
training step: 37396, total_loss: 4.931034088134766
training step: 37397, total_loss: 3.982231616973877
training step: 37398, total_loss: 4.30858039855957
training step: 37399, total_loss: 4.991487979888916
training step: 37400, total_loss: 4.437644958496094
training step: 37401, total_loss: 3.647580146789551
training step: 37402, total_loss: 6.660312652587891
training step: 37403, total_loss: 4.714346408843994
training step: 37404, total_loss: 2.967693328857422
training step: 37405, total_loss: 3.2412073612213135
training step: 37406, total_loss: 4.46796178817749
training step: 37407, total_loss: 3.1119258403778076
training step: 37408, total_loss: 5.638357162475586
training step: 37409, total_loss: 4.3322062492370605
training step: 37410, total_loss: 5.011336803436279
training step: 37411, total_loss: 3.3927178382873535
training step: 37412, total_loss: 2.390230894088745
training step: 37413, total_loss: 4.721435070037842
training step: 37414, total_loss: 4.915289878845215
training step: 37415, total_loss: 5.256624221801758
training step: 37416, total_loss: 4.423489093780518
training step: 37417, total_loss: 4.381461143493652
training step: 37418, total_loss: 4.5270280838012695
training step: 37419, total_loss: 4.584743022918701
training step: 37420, total_loss: 6.06539249420166
training step: 37421, total_loss: 3.350554943084717
training step: 37422, total_loss: 4.084559917449951
training step: 37423, total_loss: 4.665310859680176
training step: 37424, total_loss: 5.504860877990723
training step: 37425, total_loss: 5.638152122497559
training step: 37426, total_loss: 5.091039657592773
training step: 37427, total_loss: 4.737674713134766
training step: 37428, total_loss: 1.4237985610961914
training step: 37429, total_loss: 4.216825008392334
training step: 37430, total_loss: 6.748414516448975
training step: 37431, total_loss: 4.198942184448242
training step: 37432, total_loss: 3.2829160690307617
training step: 37433, total_loss: 5.85850715637207
training step: 37434, total_loss: 4.964764595031738
training step: 37435, total_loss: 5.1543169021606445
training step: 37436, total_loss: 5.437451362609863
training step: 37437, total_loss: 4.557352066040039
training step: 37438, total_loss: 4.887845516204834
training step: 37439, total_loss: 4.986380577087402
training step: 37440, total_loss: 4.649591445922852
training step: 37441, total_loss: 4.5524187088012695
training step: 37442, total_loss: 4.976505756378174
training step: 37443, total_loss: 4.704857349395752
training step: 37444, total_loss: 4.435471534729004
training step: 37445, total_loss: 4.34744930267334
training step: 37446, total_loss: 4.312779426574707
training step: 37447, total_loss: 5.218396186828613
training step: 37448, total_loss: 4.7440409660339355
training step: 37449, total_loss: 3.7650339603424072
training step: 37450, total_loss: 4.2120795249938965
training step: 37451, total_loss: 3.3453001976013184
training step: 37452, total_loss: 3.834089517593384
training step: 37453, total_loss: 3.8072891235351562
training step: 37454, total_loss: 3.699172258377075
training step: 37455, total_loss: 4.455780982971191
training step: 37456, total_loss: 4.748174667358398
training step: 37457, total_loss: 4.411045551300049
training step: 37458, total_loss: 3.32220458984375
training step: 37459, total_loss: 3.123452663421631
training step: 37460, total_loss: 4.084291458129883
training step: 37461, total_loss: 4.332277774810791
training step: 37462, total_loss: 5.038276195526123
training step: 37463, total_loss: 4.366100311279297
training step: 37464, total_loss: 5.111588954925537
training step: 37465, total_loss: 4.625087261199951
training step: 37466, total_loss: 3.7130260467529297
training step: 37467, total_loss: 3.785398006439209
training step: 37468, total_loss: 6.1273579597473145
training step: 37469, total_loss: 4.813838005065918
training step: 37470, total_loss: 5.742858409881592
training step: 37471, total_loss: 4.6754865646362305
training step: 37472, total_loss: 3.61938738822937
training step: 37473, total_loss: 4.848254203796387
training step: 37474, total_loss: 4.836787223815918
training step: 37475, total_loss: 3.562124490737915
training step: 37476, total_loss: 4.556229114532471
training step: 37477, total_loss: 4.807908058166504
training step: 37478, total_loss: 4.150904655456543
training step: 37479, total_loss: 4.277589797973633
training step: 37480, total_loss: 4.1520538330078125
training step: 37481, total_loss: 4.964906692504883
training step: 37482, total_loss: 5.885424613952637
training step: 37483, total_loss: 4.59255313873291
training step: 37484, total_loss: 4.711386680603027
training step: 37485, total_loss: 4.95615291595459
training step: 37486, total_loss: 4.158726692199707
training step: 37487, total_loss: 5.596220970153809
training step: 37488, total_loss: 4.398669242858887
training step: 37489, total_loss: 4.565483570098877
training step: 37490, total_loss: 3.9781429767608643
training step: 37491, total_loss: 3.8635029792785645
training step: 37492, total_loss: 2.177381992340088
training step: 37493, total_loss: 3.8516201972961426
training step: 37494, total_loss: 4.449684143066406
training step: 37495, total_loss: 5.102602481842041
training step: 37496, total_loss: 4.5733747482299805
training step: 37497, total_loss: 4.020600318908691
training step: 37498, total_loss: 3.4806294441223145
training step: 37499, total_loss: 2.5125322341918945
training step: 37500, total_loss: 4.75137996673584
training step: 37501, total_loss: 3.456860065460205
training step: 37502, total_loss: 5.340690612792969
training step: 37503, total_loss: 6.933408260345459
training step: 37504, total_loss: 2.766763687133789
training step: 37505, total_loss: 4.068058967590332
training step: 37506, total_loss: 4.121271133422852
training step: 37507, total_loss: 4.547076225280762
training step: 37508, total_loss: 4.2590742111206055
training step: 37509, total_loss: 4.045661449432373
training step: 37510, total_loss: 5.580623626708984
training step: 37511, total_loss: 4.33266544342041
training step: 37512, total_loss: 4.694005966186523
training step: 37513, total_loss: 3.3642971515655518
training step: 37514, total_loss: 4.239947319030762
training step: 37515, total_loss: 4.502054214477539
training step: 37516, total_loss: 3.749824285507202
training step: 37517, total_loss: 5.765847682952881
training step: 37518, total_loss: 5.162543296813965
training step: 37519, total_loss: 5.093398571014404
training step: 37520, total_loss: 4.902933597564697
training step: 37521, total_loss: 4.659648895263672
training step: 37522, total_loss: 5.107879638671875
training step: 37523, total_loss: 3.5699949264526367
training step: 37524, total_loss: 3.8028459548950195
training step: 37525, total_loss: 2.9747254848480225
training step: 37526, total_loss: 4.46725606918335
training step: 37527, total_loss: 4.745366096496582
training step: 37528, total_loss: 3.9341564178466797
training step: 37529, total_loss: 3.4255027770996094
training step: 37530, total_loss: 3.300851345062256
training step: 37531, total_loss: 5.094145774841309
training step: 37532, total_loss: 3.444322109222412
training step: 37533, total_loss: 4.6999616622924805
training step: 37534, total_loss: 4.600112438201904
training step: 37535, total_loss: 5.099193572998047
training step: 37536, total_loss: 3.361964225769043
training step: 37537, total_loss: 3.5064094066619873
training step: 37538, total_loss: 4.411304473876953
training step: 37539, total_loss: 3.9492104053497314
training step: 37540, total_loss: 4.421053886413574
training step: 37541, total_loss: 5.015192985534668
training step: 37542, total_loss: 4.732830047607422
training step: 37543, total_loss: 4.834688663482666
training step: 37544, total_loss: 3.5265419483184814
training step: 37545, total_loss: 4.095765590667725
training step: 37546, total_loss: 4.381587028503418
training step: 37547, total_loss: 3.4496448040008545
training step: 37548, total_loss: 3.3877768516540527
training step: 37549, total_loss: 4.1722822189331055
training step: 37550, total_loss: 4.602476596832275
training step: 37551, total_loss: 4.440909385681152
training step: 37552, total_loss: 5.771428108215332
training step: 37553, total_loss: 4.516501426696777
training step: 37554, total_loss: 2.191490411758423
training step: 37555, total_loss: 5.228730201721191
training step: 37556, total_loss: 3.853834629058838
training step: 37557, total_loss: 6.891127109527588
training step: 37558, total_loss: 3.861586570739746
training step: 37559, total_loss: 4.528290748596191
training step: 37560, total_loss: 3.5336523056030273
training step: 37561, total_loss: 4.7865376472473145
training step: 37562, total_loss: 5.374845504760742
training step: 37563, total_loss: 5.376738548278809
training step: 37564, total_loss: 3.6847176551818848
training step: 37565, total_loss: 5.203999996185303
training step: 37566, total_loss: 4.503912925720215
training step: 37567, total_loss: 5.206243515014648
training step: 37568, total_loss: 3.1665515899658203
training step: 37569, total_loss: 4.391871452331543
training step: 37570, total_loss: 2.7460432052612305
training step: 37571, total_loss: 4.372248649597168
training step: 37572, total_loss: 4.483625411987305
training step: 37573, total_loss: 3.7340784072875977
training step: 37574, total_loss: 5.681883335113525
training step: 37575, total_loss: 3.296943187713623
training step: 37576, total_loss: 4.245786666870117
training step: 37577, total_loss: 5.813465595245361
training step: 37578, total_loss: 4.32530403137207
training step: 37579, total_loss: 3.814324140548706
training step: 37580, total_loss: 3.9031472206115723
training step: 37581, total_loss: 2.565495252609253
training step: 37582, total_loss: 4.316327095031738
training step: 37583, total_loss: 3.3219330310821533
training step: 37584, total_loss: 8.39494514465332
training step: 37585, total_loss: 3.258486270904541
training step: 37586, total_loss: 5.21941614151001
training step: 37587, total_loss: 4.055031776428223
training step: 37588, total_loss: 4.008279800415039
training step: 37589, total_loss: 4.629534721374512
training step: 37590, total_loss: 4.363277435302734
training step: 37591, total_loss: 5.970101356506348
training step: 37592, total_loss: 5.017488479614258
training step: 37593, total_loss: 4.014660358428955
training step: 37594, total_loss: 4.69877815246582
training step: 37595, total_loss: 4.15037202835083
training step: 37596, total_loss: 3.657148838043213
training step: 37597, total_loss: 6.083687782287598
training step: 37598, total_loss: 5.2376708984375
training step: 37599, total_loss: 4.229351997375488
training step: 37600, total_loss: 3.690345287322998
training step: 37601, total_loss: 5.392866134643555
training step: 37602, total_loss: 5.0568623542785645
training step: 37603, total_loss: 4.998010635375977
training step: 37604, total_loss: 4.64238166809082
training step: 37605, total_loss: 3.520547866821289
training step: 37606, total_loss: 3.9830007553100586
training step: 37607, total_loss: 3.525451421737671
training step: 37608, total_loss: 5.222466468811035
training step: 37609, total_loss: 4.7049760818481445
training step: 37610, total_loss: 5.256121635437012
training step: 37611, total_loss: 4.215263366699219
training step: 37612, total_loss: 3.1195931434631348
training step: 37613, total_loss: 5.624350547790527
training step: 37614, total_loss: 5.139169692993164
training step: 37615, total_loss: 4.680923938751221
training step: 37616, total_loss: 3.4836666584014893
training step: 37617, total_loss: 4.779701232910156
training step: 37618, total_loss: 4.760984420776367
training step: 37619, total_loss: 4.099051475524902
training step: 37620, total_loss: 3.8539109230041504
training step: 37621, total_loss: 3.8862857818603516
training step: 37622, total_loss: 4.263157844543457
training step: 37623, total_loss: 6.143129348754883
training step: 37624, total_loss: 4.184759140014648
training step: 37625, total_loss: 3.589160442352295
training step: 37626, total_loss: 4.131826400756836
training step: 37627, total_loss: 4.1372833251953125
training step: 37628, total_loss: 3.625561237335205
training step: 37629, total_loss: 5.130066394805908
training step: 37630, total_loss: 3.74371600151062
training step: 37631, total_loss: 3.3482799530029297
training step: 37632, total_loss: 5.489819526672363
training step: 37633, total_loss: 1.323853850364685
training step: 37634, total_loss: 3.6260194778442383
training step: 37635, total_loss: 3.9612843990325928
training step: 37636, total_loss: 3.4799842834472656
training step: 37637, total_loss: 3.9330391883850098
training step: 37638, total_loss: 4.519424915313721
training step: 37639, total_loss: 4.592655181884766
training step: 37640, total_loss: 5.85941743850708
training step: 37641, total_loss: 6.046670913696289
training step: 37642, total_loss: 4.239779472351074
training step: 37643, total_loss: 5.4684929847717285
training step: 37644, total_loss: 3.1883978843688965
training step: 37645, total_loss: 6.429845809936523
training step: 37646, total_loss: 5.088932514190674
training step: 37647, total_loss: 5.102140426635742
training step: 37648, total_loss: 6.443835258483887
training step: 37649, total_loss: 4.296483993530273
training step: 37650, total_loss: 4.767106533050537
training step: 37651, total_loss: 5.202698707580566
training step: 37652, total_loss: 5.256535530090332
training step: 37653, total_loss: 2.89204740524292
training step: 37654, total_loss: 5.163866996765137
training step: 37655, total_loss: 2.255399703979492
training step: 37656, total_loss: 3.9660284519195557
training step: 37657, total_loss: 3.9764113426208496
training step: 37658, total_loss: 4.243910789489746
training step: 37659, total_loss: 5.048433780670166
training step: 37660, total_loss: 6.1923418045043945
training step: 37661, total_loss: 3.458132743835449
training step: 37662, total_loss: 4.696653366088867
training step: 37663, total_loss: 3.9687561988830566
training step: 37664, total_loss: 5.940497398376465
training step: 37665, total_loss: 4.272810459136963
training step: 37666, total_loss: 4.907830238342285
training step: 37667, total_loss: 2.1894123554229736
training step: 37668, total_loss: 4.964600563049316
training step: 37669, total_loss: 6.101401329040527
training step: 37670, total_loss: 4.8861918449401855
training step: 37671, total_loss: 4.567439079284668
training step: 37672, total_loss: 3.9336183071136475
training step: 37673, total_loss: 4.010158538818359
training step: 37674, total_loss: 5.481884956359863
training step: 37675, total_loss: 4.313628196716309
training step: 37676, total_loss: 3.829293727874756
training step: 37677, total_loss: 5.572261333465576
training step: 37678, total_loss: 3.508928060531616
training step: 37679, total_loss: 3.8364198207855225
training step: 37680, total_loss: 4.986717700958252
training step: 37681, total_loss: 5.335664749145508
training step: 37682, total_loss: 5.77783203125
training step: 37683, total_loss: 3.1393487453460693
training step: 37684, total_loss: 5.495211601257324
training step: 37685, total_loss: 5.488299369812012
training step: 37686, total_loss: 3.88665509223938
training step: 37687, total_loss: 5.541494369506836
training step: 37688, total_loss: 7.089839458465576
training step: 37689, total_loss: 5.883988380432129
training step: 37690, total_loss: 5.328907012939453
training step: 37691, total_loss: 5.222718715667725
training step: 37692, total_loss: 4.500638484954834
training step: 37693, total_loss: 4.4282660484313965
training step: 37694, total_loss: 3.9758477210998535
training step: 37695, total_loss: 4.632012367248535
training step: 37696, total_loss: 5.309771537780762
training step: 37697, total_loss: 4.936426162719727
training step: 37698, total_loss: 3.733506202697754
training step: 37699, total_loss: 4.253377437591553
training step: 37700, total_loss: 4.820287704467773
training step: 37701, total_loss: 4.489148139953613
training step: 37702, total_loss: 3.4060921669006348
training step: 37703, total_loss: 3.8920187950134277
training step: 37704, total_loss: 3.981468915939331
training step: 37705, total_loss: 3.381389617919922
training step: 37706, total_loss: 3.3178977966308594
training step: 37707, total_loss: 5.307043552398682
training step: 37708, total_loss: 4.591229438781738
training step: 37709, total_loss: 4.557018280029297
training step: 37710, total_loss: 3.911034107208252
training step: 37711, total_loss: 3.845172882080078
training step: 37712, total_loss: 4.750209808349609
training step: 37713, total_loss: 5.822560787200928
training step: 37714, total_loss: 5.24994421005249
training step: 37715, total_loss: 3.983109951019287
training step: 37716, total_loss: 3.7849318981170654
training step: 37717, total_loss: 3.8129711151123047
training step: 37718, total_loss: 4.782486438751221
training step: 37719, total_loss: 4.24778938293457
training step: 37720, total_loss: 5.303327560424805
training step: 37721, total_loss: 4.03068733215332
training step: 37722, total_loss: 4.448692321777344
training step: 37723, total_loss: 4.8257293701171875
training step: 37724, total_loss: 5.619405269622803
training step: 37725, total_loss: 3.4190683364868164
training step: 37726, total_loss: 5.269631385803223
training step: 37727, total_loss: 4.727684020996094
training step: 37728, total_loss: 4.821420669555664
training step: 37729, total_loss: 4.269148826599121
training step: 37730, total_loss: 4.228446006774902
training step: 37731, total_loss: 3.184558391571045
training step: 37732, total_loss: 5.029289245605469
training step: 37733, total_loss: 3.511679172515869
training step: 37734, total_loss: 3.4618968963623047
training step: 37735, total_loss: 4.8690948486328125
training step: 37736, total_loss: 4.516839027404785
training step: 37737, total_loss: 4.516789436340332
training step: 37738, total_loss: 3.2658557891845703
training step: 37739, total_loss: 4.383625507354736
training step: 37740, total_loss: 4.394224166870117
training step: 37741, total_loss: 3.4929187297821045
training step: 37742, total_loss: 3.9285435676574707
training step: 37743, total_loss: 3.9391233921051025
training step: 37744, total_loss: 3.4841489791870117
training step: 37745, total_loss: 4.838676929473877
training step: 37746, total_loss: 4.448625087738037
training step: 37747, total_loss: 3.9611024856567383
training step: 37748, total_loss: 4.533609390258789
training step: 37749, total_loss: 2.765296697616577
training step: 37750, total_loss: 3.0488486289978027
training step: 37751, total_loss: 4.6665778160095215
training step: 37752, total_loss: 5.605703353881836
training step: 37753, total_loss: 3.8880791664123535
training step: 37754, total_loss: 4.399980068206787
training step: 37755, total_loss: 3.8849620819091797
training step: 37756, total_loss: 4.058383464813232
training step: 37757, total_loss: 1.0214993953704834
training step: 37758, total_loss: 3.8169684410095215
training step: 37759, total_loss: 4.04432487487793
training step: 37760, total_loss: 4.942956447601318
training step: 37761, total_loss: 4.024698734283447
training step: 37762, total_loss: 5.723208427429199
training step: 37763, total_loss: 4.1349568367004395
training step: 37764, total_loss: 1.630831003189087
training step: 37765, total_loss: 3.4581093788146973
training step: 37766, total_loss: 5.355956077575684
training step: 37767, total_loss: 4.1277666091918945
training step: 37768, total_loss: 5.191056251525879
training step: 37769, total_loss: 1.1842693090438843
training step: 37770, total_loss: 5.9150519371032715
training step: 37771, total_loss: 5.211911201477051
training step: 37772, total_loss: 7.882150650024414
training step: 37773, total_loss: 4.156728744506836
training step: 37774, total_loss: 3.686901807785034
training step: 37775, total_loss: 3.92777419090271
training step: 37776, total_loss: 3.752506732940674
training step: 37777, total_loss: 5.118816375732422
training step: 37778, total_loss: 1.2475740909576416
training step: 37779, total_loss: 4.737739562988281
training step: 37780, total_loss: 4.397860527038574
training step: 37781, total_loss: 4.375823974609375
training step: 37782, total_loss: 5.313792705535889
training step: 37783, total_loss: 4.238805770874023
training step: 37784, total_loss: 3.4820849895477295
training step: 37785, total_loss: 6.554621696472168
training step: 37786, total_loss: 6.404479026794434
training step: 37787, total_loss: 2.712902069091797
training step: 37788, total_loss: 4.5568013191223145
training step: 37789, total_loss: 3.9484801292419434
training step: 37790, total_loss: 4.060213088989258
training step: 37791, total_loss: 3.060668468475342
training step: 37792, total_loss: 3.542909860610962
training step: 37793, total_loss: 4.084046363830566
training step: 37794, total_loss: 4.566852569580078
training step: 37795, total_loss: 4.231127738952637
training step: 37796, total_loss: 4.794798851013184
training step: 37797, total_loss: 3.7288784980773926
training step: 37798, total_loss: 5.000982761383057
training step: 37799, total_loss: 1.3604354858398438
training step: 37800, total_loss: 4.3189191818237305
training step: 37801, total_loss: 5.1554388999938965
training step: 37802, total_loss: 4.925814628601074
training step: 37803, total_loss: 6.0738372802734375
training step: 37804, total_loss: 5.6264967918396
training step: 37805, total_loss: 3.757556915283203
training step: 37806, total_loss: 2.576981544494629
training step: 37807, total_loss: 5.959083557128906
training step: 37808, total_loss: 4.508944511413574
training step: 37809, total_loss: 2.80464506149292
training step: 37810, total_loss: 5.477835178375244
training step: 37811, total_loss: 3.390148162841797
training step: 37812, total_loss: 3.3588387966156006
training step: 37813, total_loss: 4.036771774291992
training step: 37814, total_loss: 4.086238861083984
training step: 37815, total_loss: 4.572620868682861
training step: 37816, total_loss: 2.1407432556152344
training step: 37817, total_loss: 4.497810363769531
training step: 37818, total_loss: 4.957887172698975
training step: 37819, total_loss: 2.2814934253692627
training step: 37820, total_loss: 5.092229843139648
training step: 37821, total_loss: 4.772936820983887
training step: 37822, total_loss: 4.946166038513184
training step: 37823, total_loss: 4.71772575378418
training step: 37824, total_loss: 4.290291786193848
training step: 37825, total_loss: 5.343165397644043
training step: 37826, total_loss: 3.876927375793457
training step: 37827, total_loss: 5.41141414642334
training step: 37828, total_loss: 5.852202415466309
training step: 37829, total_loss: 4.337878227233887
training step: 37830, total_loss: 4.652281761169434
training step: 37831, total_loss: 5.780391216278076
training step: 37832, total_loss: 4.580580234527588
training step: 37833, total_loss: 5.223534107208252
training step: 37834, total_loss: 4.238898754119873
training step: 37835, total_loss: 4.542972087860107
training step: 37836, total_loss: 2.681910991668701
training step: 37837, total_loss: 5.29221248626709
training step: 37838, total_loss: 4.649511337280273
training step: 37839, total_loss: 4.262477874755859
training step: 37840, total_loss: 4.304447174072266
training step: 37841, total_loss: 4.296480178833008
training step: 37842, total_loss: 2.461573362350464
training step: 37843, total_loss: 3.1100378036499023
training step: 37844, total_loss: 2.2259504795074463
training step: 37845, total_loss: 3.697042465209961
training step: 37846, total_loss: 3.959585428237915
training step: 37847, total_loss: 4.798392295837402
training step: 37848, total_loss: 4.8812103271484375
training step: 37849, total_loss: 4.662164688110352
training step: 37850, total_loss: 3.2523019313812256
training step: 37851, total_loss: 5.678481101989746
training step: 37852, total_loss: 3.9346823692321777
training step: 37853, total_loss: 5.077281951904297
training step: 37854, total_loss: 5.227161407470703
training step: 37855, total_loss: 3.8028829097747803
training step: 37856, total_loss: 5.802846908569336
training step: 37857, total_loss: 4.6385626792907715
training step: 37858, total_loss: 6.242349624633789
training step: 37859, total_loss: 5.782800674438477
training step: 37860, total_loss: 4.744714736938477
training step: 37861, total_loss: 5.746315956115723
training step: 37862, total_loss: 4.941773891448975
training step: 37863, total_loss: 4.213254928588867
training step: 37864, total_loss: 4.056977272033691
training step: 37865, total_loss: 4.690126895904541
training step: 37866, total_loss: 3.308906316757202
training step: 37867, total_loss: 4.496643543243408
training step: 37868, total_loss: 4.89096736907959
training step: 37869, total_loss: 3.1580910682678223
training step: 37870, total_loss: 4.177147388458252
training step: 37871, total_loss: 5.0093278884887695
training step: 37872, total_loss: 4.160207748413086
training step: 37873, total_loss: 3.738633632659912
training step: 37874, total_loss: 3.1314611434936523
training step: 37875, total_loss: 5.828604221343994
training step: 37876, total_loss: 3.953040838241577
training step: 37877, total_loss: 4.554618835449219
training step: 37878, total_loss: 4.297345161437988
training step: 37879, total_loss: 4.743247032165527
training step: 37880, total_loss: 4.579150676727295
training step: 37881, total_loss: 2.931356906890869
training step: 37882, total_loss: 5.15622091293335
training step: 37883, total_loss: 4.095003128051758
training step: 37884, total_loss: 4.447726249694824
training step: 37885, total_loss: 5.333348274230957
training step: 37886, total_loss: 5.149977684020996
training step: 37887, total_loss: 3.8021466732025146
training step: 37888, total_loss: 2.3421406745910645
training step: 37889, total_loss: 4.490821838378906
training step: 37890, total_loss: 6.132623195648193
training step: 37891, total_loss: 4.2827229499816895
training step: 37892, total_loss: 4.462706089019775
training step: 37893, total_loss: 5.0016021728515625
training step: 37894, total_loss: 3.2245869636535645
training step: 37895, total_loss: 3.45723295211792
training step: 37896, total_loss: 4.789456367492676
training step: 37897, total_loss: 3.1179358959198
training step: 37898, total_loss: 3.955002784729004
training step: 37899, total_loss: 3.725184440612793
training step: 37900, total_loss: 3.6843645572662354
training step: 37901, total_loss: 6.544888019561768
training step: 37902, total_loss: 5.723663330078125
training step: 37903, total_loss: 3.2625572681427
training step: 37904, total_loss: 5.6048688888549805
training step: 37905, total_loss: 4.5265655517578125
training step: 37906, total_loss: 4.5191240310668945
training step: 37907, total_loss: 4.415044784545898
training step: 37908, total_loss: 6.913430690765381
training step: 37909, total_loss: 5.576376914978027
training step: 37910, total_loss: 5.092175483703613
training step: 37911, total_loss: 4.565351963043213
training step: 37912, total_loss: 4.475661277770996
training step: 37913, total_loss: 4.256834030151367
training step: 37914, total_loss: 5.256353855133057
training step: 37915, total_loss: 4.430870532989502
training step: 37916, total_loss: 4.1238813400268555
training step: 37917, total_loss: 3.3060803413391113
training step: 37918, total_loss: 4.558811187744141
training step: 37919, total_loss: 4.448905944824219
training step: 37920, total_loss: 4.3450727462768555
training step: 37921, total_loss: 3.095775604248047
training step: 37922, total_loss: 4.606789588928223
training step: 37923, total_loss: 3.975695848464966
training step: 37924, total_loss: 4.232657432556152
training step: 37925, total_loss: 4.287397384643555
training step: 37926, total_loss: 4.3768768310546875
training step: 37927, total_loss: 5.468382835388184
training step: 37928, total_loss: 4.223642349243164
training step: 37929, total_loss: 5.202284812927246
training step: 37930, total_loss: 4.297605514526367
training step: 37931, total_loss: 5.717978477478027
training step: 37932, total_loss: 3.498581886291504
training step: 37933, total_loss: 4.292464256286621
training step: 37934, total_loss: 4.916003227233887
training step: 37935, total_loss: 4.761375904083252
training step: 37936, total_loss: 3.280567169189453
training step: 37937, total_loss: 1.109073519706726
training step: 37938, total_loss: 3.0824596881866455
training step: 37939, total_loss: 4.061739921569824
training step: 37940, total_loss: 4.905993461608887
training step: 37941, total_loss: 4.202366828918457
training step: 37942, total_loss: 2.53269100189209
training step: 37943, total_loss: 5.176623344421387
training step: 37944, total_loss: 3.7803707122802734
training step: 37945, total_loss: 3.450650453567505
training step: 37946, total_loss: 4.001474380493164
training step: 37947, total_loss: 3.8273868560791016
training step: 37948, total_loss: 4.377264022827148
training step: 37949, total_loss: 4.83526611328125
training step: 37950, total_loss: 4.872264385223389
training step: 37951, total_loss: 4.326347827911377
training step: 37952, total_loss: 2.886449098587036
training step: 37953, total_loss: 3.581653118133545
training step: 37954, total_loss: 3.724851608276367
training step: 37955, total_loss: 3.910658359527588
training step: 37956, total_loss: 4.1794939041137695
training step: 37957, total_loss: 6.114255905151367
training step: 37958, total_loss: 4.739713668823242
training step: 37959, total_loss: 4.668839454650879
training step: 37960, total_loss: 3.769127130508423
training step: 37961, total_loss: 5.749330520629883
training step: 37962, total_loss: 4.808412551879883
training step: 37963, total_loss: 5.791543006896973
training step: 37964, total_loss: 3.36639142036438
training step: 37965, total_loss: 4.420787811279297
training step: 37966, total_loss: 4.667734146118164
training step: 37967, total_loss: 3.493546485900879
training step: 37968, total_loss: 3.8052945137023926
training step: 37969, total_loss: 3.538576126098633
training step: 37970, total_loss: 5.3671722412109375
training step: 37971, total_loss: 3.2322516441345215
training step: 37972, total_loss: 4.525996685028076
training step: 37973, total_loss: 0.9474986791610718
training step: 37974, total_loss: 0.8644025325775146
training step: 37975, total_loss: 3.5490317344665527
training step: 37976, total_loss: 2.377645969390869
training step: 37977, total_loss: 0.8536714315414429
training step: 37978, total_loss: 3.581238269805908
training step: 37979, total_loss: 3.00760555267334
training step: 37980, total_loss: 6.056140899658203
training step: 37981, total_loss: 2.6035733222961426
training step: 37982, total_loss: 2.9355430603027344
training step: 37983, total_loss: 4.675825119018555
training step: 37984, total_loss: 2.3842263221740723
training step: 37985, total_loss: 5.603722095489502
training step: 37986, total_loss: 4.788708686828613
training step: 37987, total_loss: 3.9695236682891846
training step: 37988, total_loss: 2.1427085399627686
training step: 37989, total_loss: 3.137397527694702
training step: 37990, total_loss: 5.107235908508301
training step: 37991, total_loss: 4.686059951782227
training step: 37992, total_loss: 4.712163925170898
training step: 37993, total_loss: 6.422749996185303
training step: 37994, total_loss: 3.65897274017334
training step: 37995, total_loss: 3.713648796081543
training step: 37996, total_loss: 0.5109943151473999
training step: 37997, total_loss: 3.5554323196411133
training step: 37998, total_loss: 4.241257667541504
training step: 37999, total_loss: 5.558230400085449
training step: 38000, total_loss: 4.1960906982421875
training step: 38001, total_loss: 4.394674301147461
training step: 38002, total_loss: 2.868093490600586
training step: 38003, total_loss: 4.318063259124756
training step: 38004, total_loss: 2.4573020935058594
training step: 38005, total_loss: 5.216090202331543
training step: 38006, total_loss: 4.357809066772461
training step: 38007, total_loss: 5.524379730224609
training step: 38008, total_loss: 5.039768695831299
training step: 38009, total_loss: 5.515778541564941
training step: 38010, total_loss: 2.807461738586426
training step: 38011, total_loss: 5.044352054595947
training step: 38012, total_loss: 4.9005584716796875
training step: 38013, total_loss: 3.145693302154541
training step: 38014, total_loss: 4.549298286437988
training step: 38015, total_loss: 4.14906644821167
training step: 38016, total_loss: 4.403797149658203
training step: 38017, total_loss: 4.778563976287842
training step: 38018, total_loss: 4.210575580596924
training step: 38019, total_loss: 0.41491270065307617
training step: 38020, total_loss: 5.877319812774658
training step: 38021, total_loss: 5.240853309631348
training step: 38022, total_loss: 4.411036491394043
training step: 38023, total_loss: 3.910226345062256
training step: 38024, total_loss: 6.192749500274658
training step: 38025, total_loss: 4.767827987670898
training step: 38026, total_loss: 4.10287618637085
training step: 38027, total_loss: 4.467090606689453
training step: 38028, total_loss: 5.520199298858643
training step: 38029, total_loss: 5.53104829788208
training step: 38030, total_loss: 3.1340091228485107
training step: 38031, total_loss: 3.2825188636779785
training step: 38032, total_loss: 4.097350597381592
training step: 38033, total_loss: 4.051595687866211
training step: 38034, total_loss: 5.7089457511901855
training step: 38035, total_loss: 4.929686546325684
training step: 38036, total_loss: 3.452914237976074
training step: 38037, total_loss: 4.680078983306885
training step: 38038, total_loss: 6.105187892913818
training step: 38039, total_loss: 5.635235786437988
training step: 38040, total_loss: 5.267440319061279
training step: 38041, total_loss: 5.143521308898926
training step: 38042, total_loss: 2.8598546981811523
training step: 38043, total_loss: 5.189370155334473
training step: 38044, total_loss: 2.107921600341797
training step: 38045, total_loss: 4.194052696228027
training step: 38046, total_loss: 3.154080867767334
training step: 38047, total_loss: 5.1266584396362305
training step: 38048, total_loss: 5.166555404663086
training step: 38049, total_loss: 4.300778388977051
training step: 38050, total_loss: 4.918717384338379
training step: 38051, total_loss: 4.038557052612305
training step: 38052, total_loss: 4.696147918701172
training step: 38053, total_loss: 3.498335361480713
training step: 38054, total_loss: 2.9961044788360596
training step: 38055, total_loss: 3.4228811264038086
training step: 38056, total_loss: 5.14133358001709
training step: 38057, total_loss: 5.530481338500977
training step: 38058, total_loss: 6.276081085205078
training step: 38059, total_loss: 3.490640163421631
training step: 38060, total_loss: 4.208189010620117
training step: 38061, total_loss: 3.4140467643737793
training step: 38062, total_loss: 4.973223686218262
training step: 38063, total_loss: 5.39382266998291
training step: 38064, total_loss: 5.093339920043945
training step: 38065, total_loss: 5.49166202545166
training step: 38066, total_loss: 3.449275493621826
training step: 38067, total_loss: 5.086613655090332
training step: 38068, total_loss: 0.7505285739898682
training step: 38069, total_loss: 3.8317079544067383
training step: 38070, total_loss: 4.959258079528809
training step: 38071, total_loss: 2.120980739593506
training step: 38072, total_loss: 4.713382720947266
training step: 38073, total_loss: 5.849272727966309
training step: 38074, total_loss: 3.238619804382324
training step: 38075, total_loss: 4.6126532554626465
training step: 38076, total_loss: 4.509546279907227
training step: 38077, total_loss: 5.058624267578125
training step: 38078, total_loss: 4.079146385192871
training step: 38079, total_loss: 5.4689860343933105
training step: 38080, total_loss: 5.3924736976623535
training step: 38081, total_loss: 5.813351631164551
training step: 38082, total_loss: 5.141245365142822
training step: 38083, total_loss: 4.19057035446167
training step: 38084, total_loss: 4.326516151428223
training step: 38085, total_loss: 3.664637565612793
training step: 38086, total_loss: 3.772656202316284
training step: 38087, total_loss: 4.978447914123535
training step: 38088, total_loss: 4.826131820678711
training step: 38089, total_loss: 4.008327484130859
training step: 38090, total_loss: 4.248867988586426
training step: 38091, total_loss: 5.3414788246154785
training step: 38092, total_loss: 4.351315021514893
training step: 38093, total_loss: 5.8065595626831055
training step: 38094, total_loss: 3.8709888458251953
training step: 38095, total_loss: 4.0762038230896
training step: 38096, total_loss: 4.4825944900512695
training step: 38097, total_loss: 5.189621925354004
training step: 38098, total_loss: 2.446524143218994
training step: 38099, total_loss: 5.249896049499512
training step: 38100, total_loss: 4.576298713684082
training step: 38101, total_loss: 5.890068054199219
training step: 38102, total_loss: 4.746529579162598
training step: 38103, total_loss: 5.289626121520996
training step: 38104, total_loss: 6.375288486480713
training step: 38105, total_loss: 4.372196197509766
training step: 38106, total_loss: 5.247045993804932
training step: 38107, total_loss: 4.379190444946289
training step: 38108, total_loss: 6.1540985107421875
training step: 38109, total_loss: 5.959815979003906
training step: 38110, total_loss: 5.248510360717773
training step: 38111, total_loss: 4.5426716804504395
training step: 38112, total_loss: 6.20897102355957
training step: 38113, total_loss: 7.08875846862793
training step: 38114, total_loss: 2.8123655319213867
training step: 38115, total_loss: 3.916752815246582
training step: 38116, total_loss: 3.626962900161743
training step: 38117, total_loss: 4.240571975708008
training step: 38118, total_loss: 4.501822471618652
training step: 38119, total_loss: 1.0474226474761963
training step: 38120, total_loss: 4.123751640319824
training step: 38121, total_loss: 4.772197723388672
training step: 38122, total_loss: 5.007129669189453
training step: 38123, total_loss: 4.5630693435668945
training step: 38124, total_loss: 4.893461227416992
training step: 38125, total_loss: 5.3283281326293945
training step: 38126, total_loss: 2.9773383140563965
training step: 38127, total_loss: 3.9377799034118652
training step: 38128, total_loss: 2.852954387664795
training step: 38129, total_loss: 4.051783561706543
training step: 38130, total_loss: 5.364073753356934
training step: 38131, total_loss: 4.589988708496094
training step: 38132, total_loss: 4.813592910766602
training step: 38133, total_loss: 5.713216304779053
training step: 38134, total_loss: 3.4961915016174316
training step: 38135, total_loss: 5.396749496459961
training step: 38136, total_loss: 4.960842609405518
training step: 38137, total_loss: 5.635126113891602
training step: 38138, total_loss: 4.624466896057129
training step: 38139, total_loss: 4.39653205871582
training step: 38140, total_loss: 5.039457321166992
training step: 38141, total_loss: 1.7859281301498413
training step: 38142, total_loss: 4.767580509185791
training step: 38143, total_loss: 4.158880233764648
training step: 38144, total_loss: 5.490796089172363
training step: 38145, total_loss: 3.3198795318603516
training step: 38146, total_loss: 3.1411733627319336
training step: 38147, total_loss: 3.7114861011505127
training step: 38148, total_loss: 5.568368911743164
training step: 38149, total_loss: 3.8003530502319336
training step: 38150, total_loss: 4.004969596862793
training step: 38151, total_loss: 5.63430118560791
training step: 38152, total_loss: 4.642292022705078
training step: 38153, total_loss: 3.2141330242156982
training step: 38154, total_loss: 1.337733268737793
training step: 38155, total_loss: 4.702203750610352
training step: 38156, total_loss: 4.30111026763916
training step: 38157, total_loss: 4.0389790534973145
training step: 38158, total_loss: 4.647992134094238
training step: 38159, total_loss: 4.739436149597168
training step: 38160, total_loss: 5.109710693359375
training step: 38161, total_loss: 5.260666847229004
training step: 38162, total_loss: 5.3847880363464355
training step: 38163, total_loss: 4.695367813110352
training step: 38164, total_loss: 6.431676864624023
training step: 38165, total_loss: 5.046316146850586
training step: 38166, total_loss: 6.707423686981201
training step: 38167, total_loss: 3.865529775619507
training step: 38168, total_loss: 3.9292516708374023
training step: 38169, total_loss: 4.08686637878418
training step: 38170, total_loss: 2.2796261310577393
training step: 38171, total_loss: 4.928176403045654
training step: 38172, total_loss: 6.501965522766113
training step: 38173, total_loss: 2.7699036598205566
training step: 38174, total_loss: 5.016711235046387
training step: 38175, total_loss: 3.239976406097412
training step: 38176, total_loss: 4.47407341003418
training step: 38177, total_loss: 3.280149221420288
training step: 38178, total_loss: 5.152834415435791
training step: 38179, total_loss: 3.894303798675537
training step: 38180, total_loss: 2.855281352996826
training step: 38181, total_loss: 4.143512725830078
training step: 38182, total_loss: 5.205380439758301
training step: 38183, total_loss: 4.546361923217773
training step: 38184, total_loss: 4.950772285461426
training step: 38185, total_loss: 3.5286335945129395
training step: 38186, total_loss: 3.976672649383545
training step: 38187, total_loss: 3.83817195892334
training step: 38188, total_loss: 2.528773784637451
training step: 38189, total_loss: 4.303666114807129
training step: 38190, total_loss: 4.432240009307861
training step: 38191, total_loss: 4.307404041290283
training step: 38192, total_loss: 4.036533355712891
training step: 38193, total_loss: 5.74951171875
training step: 38194, total_loss: 5.582464218139648
training step: 38195, total_loss: 4.070248603820801
training step: 38196, total_loss: 1.6047590970993042
training step: 38197, total_loss: 4.857917785644531
training step: 38198, total_loss: 4.836800575256348
training step: 38199, total_loss: 4.7313923835754395
training step: 38200, total_loss: 3.863365650177002
training step: 38201, total_loss: 5.230391502380371
training step: 38202, total_loss: 4.286569595336914
training step: 38203, total_loss: 5.138355255126953
training step: 38204, total_loss: 4.824121475219727
training step: 38205, total_loss: 4.664766788482666
training step: 38206, total_loss: 4.499165058135986
training step: 38207, total_loss: 4.012207508087158
training step: 38208, total_loss: 3.4339871406555176
training step: 38209, total_loss: 5.573620796203613
training step: 38210, total_loss: 4.036129951477051
training step: 38211, total_loss: 4.631774425506592
training step: 38212, total_loss: 0.9793210029602051
training step: 38213, total_loss: 3.6722865104675293
training step: 38214, total_loss: 4.398120880126953
training step: 38215, total_loss: 4.416960716247559
training step: 38216, total_loss: 3.8636269569396973
training step: 38217, total_loss: 3.234015464782715
training step: 38218, total_loss: 4.20565938949585
training step: 38219, total_loss: 6.1161370277404785
training step: 38220, total_loss: 3.485823154449463
training step: 38221, total_loss: 2.6862707138061523
training step: 38222, total_loss: 4.888063430786133
training step: 38223, total_loss: 4.346584320068359
training step: 38224, total_loss: 6.162336349487305
training step: 38225, total_loss: 5.462763786315918
training step: 38226, total_loss: 2.8339571952819824
training step: 38227, total_loss: 3.4572887420654297
training step: 38228, total_loss: 5.251757621765137
training step: 38229, total_loss: 5.527848720550537
training step: 38230, total_loss: 4.209525108337402
training step: 38231, total_loss: 4.35716438293457
training step: 38232, total_loss: 4.923785209655762
training step: 38233, total_loss: 5.200634002685547
training step: 38234, total_loss: 3.8922834396362305
training step: 38235, total_loss: 4.367032527923584
training step: 38236, total_loss: 4.263437747955322
training step: 38237, total_loss: 4.274435043334961
training step: 38238, total_loss: 3.8222360610961914
training step: 38239, total_loss: 4.457681655883789
training step: 38240, total_loss: 5.9538445472717285
training step: 38241, total_loss: 4.399725914001465
training step: 38242, total_loss: 2.9451003074645996
training step: 38243, total_loss: 5.547503471374512
training step: 38244, total_loss: 4.578014373779297
training step: 38245, total_loss: 4.856836318969727
training step: 38246, total_loss: 1.5949628353118896
training step: 38247, total_loss: 4.62366247177124
training step: 38248, total_loss: 4.579773902893066
training step: 38249, total_loss: 2.2867517471313477
training step: 38250, total_loss: 5.055296421051025
training step: 38251, total_loss: 4.534175872802734
training step: 38252, total_loss: 4.578378677368164
training step: 38253, total_loss: 4.609860420227051
training step: 38254, total_loss: 4.877773284912109
training step: 38255, total_loss: 4.71258020401001
training step: 38256, total_loss: 5.4600019454956055
training step: 38257, total_loss: 5.007485866546631
training step: 38258, total_loss: 4.7924909591674805
training step: 38259, total_loss: 4.0562591552734375
training step: 38260, total_loss: 3.7797131538391113
training step: 38261, total_loss: 0.9917281270027161
training step: 38262, total_loss: 2.9759414196014404
training step: 38263, total_loss: 4.359813690185547
training step: 38264, total_loss: 0.994968056678772
training step: 38265, total_loss: 4.640676498413086
training step: 38266, total_loss: 4.9101881980896
training step: 38267, total_loss: 4.112137317657471
training step: 38268, total_loss: 4.42428731918335
training step: 38269, total_loss: 4.208915710449219
training step: 38270, total_loss: 4.325345039367676
training step: 38271, total_loss: 4.37285041809082
training step: 38272, total_loss: 4.032959938049316
training step: 38273, total_loss: 4.836080074310303
training step: 38274, total_loss: 4.427258014678955
training step: 38275, total_loss: 2.220494270324707
training step: 38276, total_loss: 4.385971546173096
training step: 38277, total_loss: 5.9252028465271
training step: 38278, total_loss: 3.2640624046325684
training step: 38279, total_loss: 3.3526206016540527
training step: 38280, total_loss: 3.9727256298065186
training step: 38281, total_loss: 4.214326858520508
training step: 38282, total_loss: 5.5965352058410645
training step: 38283, total_loss: 4.062812805175781
training step: 38284, total_loss: 4.657991409301758
training step: 38285, total_loss: 5.010117053985596
training step: 38286, total_loss: 3.5236001014709473
training step: 38287, total_loss: 2.320578098297119
training step: 38288, total_loss: 5.425195693969727
training step: 38289, total_loss: 4.576906681060791
training step: 38290, total_loss: 4.8117499351501465
training step: 38291, total_loss: 3.1881558895111084
training step: 38292, total_loss: 4.70562219619751
training step: 38293, total_loss: 4.86998987197876
training step: 38294, total_loss: 4.707386016845703
training step: 38295, total_loss: 2.3223319053649902
training step: 38296, total_loss: 5.3938398361206055
training step: 38297, total_loss: 5.464753150939941
training step: 38298, total_loss: 5.548752307891846
training step: 38299, total_loss: 4.596366882324219
training step: 38300, total_loss: 6.142526626586914
training step: 38301, total_loss: 4.901907920837402
training step: 38302, total_loss: 4.571518898010254
training step: 38303, total_loss: 3.638148069381714
training step: 38304, total_loss: 0.6603323817253113
training step: 38305, total_loss: 2.731517791748047
training step: 38306, total_loss: 4.326756954193115
training step: 38307, total_loss: 3.5886473655700684
training step: 38308, total_loss: 4.374083518981934
training step: 38309, total_loss: 4.850186347961426
training step: 38310, total_loss: 3.941908597946167
training step: 38311, total_loss: 4.547048568725586
training step: 38312, total_loss: 5.874542236328125
training step: 38313, total_loss: 2.3874099254608154
training step: 38314, total_loss: 4.791711807250977
training step: 38315, total_loss: 3.1617507934570312
training step: 38316, total_loss: 4.923076629638672
training step: 38317, total_loss: 3.5950708389282227
training step: 38318, total_loss: 4.996638774871826
training step: 38319, total_loss: 4.805370330810547
training step: 38320, total_loss: 5.157904624938965
training step: 38321, total_loss: 3.4193456172943115
training step: 38322, total_loss: 4.465660572052002
training step: 38323, total_loss: 3.9056332111358643
training step: 38324, total_loss: 4.978787422180176
training step: 38325, total_loss: 5.641634464263916
training step: 38326, total_loss: 7.025249481201172
training step: 38327, total_loss: 4.931997299194336
training step: 38328, total_loss: 4.823798179626465
training step: 38329, total_loss: 3.841031074523926
training step: 38330, total_loss: 4.683474063873291
training step: 38331, total_loss: 4.419346809387207
training step: 38332, total_loss: 1.1913275718688965
training step: 38333, total_loss: 4.857535362243652
training step: 38334, total_loss: 3.461705207824707
training step: 38335, total_loss: 5.402374267578125
training step: 38336, total_loss: 4.563570022583008
training step: 38337, total_loss: 4.279000282287598
training step: 38338, total_loss: 3.6718921661376953
training step: 38339, total_loss: 5.698590278625488
training step: 38340, total_loss: 1.7535014152526855
training step: 38341, total_loss: 5.498438835144043
training step: 38342, total_loss: 3.2959561347961426
training step: 38343, total_loss: 4.639266014099121
training step: 38344, total_loss: 5.258220672607422
training step: 38345, total_loss: 4.5773115158081055
training step: 38346, total_loss: 5.044933795928955
training step: 38347, total_loss: 4.529757499694824
training step: 38348, total_loss: 4.624698638916016
training step: 38349, total_loss: 4.600189685821533
training step: 38350, total_loss: 3.890414237976074
training step: 38351, total_loss: 4.112735748291016
training step: 38352, total_loss: 4.26717472076416
training step: 38353, total_loss: 5.976235389709473
training step: 38354, total_loss: 6.1421990394592285
training step: 38355, total_loss: 3.3403501510620117
training step: 38356, total_loss: 4.369439601898193
training step: 38357, total_loss: 3.1987180709838867
training step: 38358, total_loss: 4.448485851287842
training step: 38359, total_loss: 4.728696823120117
training step: 38360, total_loss: 4.767622947692871
training step: 38361, total_loss: 7.1482086181640625
training step: 38362, total_loss: 4.832779884338379
training step: 38363, total_loss: 3.6590704917907715
training step: 38364, total_loss: 3.5282492637634277
training step: 38365, total_loss: 3.7672152519226074
training step: 38366, total_loss: 4.008176326751709
training step: 38367, total_loss: 3.4524409770965576
training step: 38368, total_loss: 6.652996063232422
training step: 38369, total_loss: 6.92667293548584
training step: 38370, total_loss: 5.169816017150879
training step: 38371, total_loss: 5.513643264770508
training step: 38372, total_loss: 5.203396320343018
training step: 38373, total_loss: 4.576798439025879
training step: 38374, total_loss: 5.889049053192139
training step: 38375, total_loss: 3.8771300315856934
training step: 38376, total_loss: 4.087515830993652
training step: 38377, total_loss: 3.5325660705566406
training step: 38378, total_loss: 4.21444845199585
training step: 38379, total_loss: 5.044106483459473
training step: 38380, total_loss: 4.701537132263184
training step: 38381, total_loss: 5.08729362487793
training step: 38382, total_loss: 5.9128193855285645
training step: 38383, total_loss: 2.8473734855651855
training step: 38384, total_loss: 4.887995719909668
training step: 38385, total_loss: 4.448774337768555
training step: 38386, total_loss: 4.236269950866699
training step: 38387, total_loss: 5.0306172370910645
training step: 38388, total_loss: 5.068052768707275
training step: 38389, total_loss: 5.119570255279541
training step: 38390, total_loss: 3.9997451305389404
training step: 38391, total_loss: 3.381880044937134
training step: 38392, total_loss: 3.537740468978882
training step: 38393, total_loss: 3.9924612045288086
training step: 38394, total_loss: 4.554940700531006
training step: 38395, total_loss: 4.404694557189941
training step: 38396, total_loss: 4.792411804199219
training step: 38397, total_loss: 5.201822280883789
training step: 38398, total_loss: 4.083754539489746
training step: 38399, total_loss: 4.443218231201172
training step: 38400, total_loss: 5.077042102813721
training step: 38401, total_loss: 3.7106857299804688
training step: 38402, total_loss: 4.215561389923096
training step: 38403, total_loss: 1.190363883972168
training step: 38404, total_loss: 2.3497376441955566
training step: 38405, total_loss: 3.58742094039917
training step: 38406, total_loss: 6.093827247619629
training step: 38407, total_loss: 6.180300712585449
training step: 38408, total_loss: 3.1556737422943115
training step: 38409, total_loss: 4.822035789489746
training step: 38410, total_loss: 5.353372573852539
training step: 38411, total_loss: 4.294789791107178
training step: 38412, total_loss: 4.731323719024658
training step: 38413, total_loss: 5.500391483306885
training step: 38414, total_loss: 4.272724151611328
training step: 38415, total_loss: 3.119565486907959
training step: 38416, total_loss: 3.3220133781433105
training step: 38417, total_loss: 3.9985320568084717
training step: 38418, total_loss: 4.326991081237793
training step: 38419, total_loss: 5.222315788269043
training step: 38420, total_loss: 5.144143104553223
training step: 38421, total_loss: 4.116175651550293
training step: 38422, total_loss: 5.428348541259766
training step: 38423, total_loss: 4.084685325622559
training step: 38424, total_loss: 4.436619281768799
training step: 38425, total_loss: 4.0744476318359375
training step: 38426, total_loss: 4.120734214782715
training step: 38427, total_loss: 3.9555416107177734
training step: 38428, total_loss: 4.469705581665039
training step: 38429, total_loss: 2.7922821044921875
training step: 38430, total_loss: 3.4697070121765137
training step: 38431, total_loss: 4.94105863571167
training step: 38432, total_loss: 3.758059501647949
training step: 38433, total_loss: 5.281970977783203
training step: 38434, total_loss: 4.789907455444336
training step: 38435, total_loss: 4.848126411437988
training step: 38436, total_loss: 3.965094566345215
training step: 38437, total_loss: 4.1390485763549805
training step: 38438, total_loss: 7.51576042175293
training step: 38439, total_loss: 5.141590118408203
training step: 38440, total_loss: 3.9950971603393555
training step: 38441, total_loss: 4.524371147155762
training step: 38442, total_loss: 4.132388591766357
training step: 38443, total_loss: 4.223289966583252
training step: 38444, total_loss: 4.738253116607666
training step: 38445, total_loss: 4.366933345794678
training step: 38446, total_loss: 1.317280650138855
training step: 38447, total_loss: 3.8744988441467285
training step: 38448, total_loss: 3.8832950592041016
training step: 38449, total_loss: 3.993431568145752
training step: 38450, total_loss: 4.736586570739746
training step: 38451, total_loss: 4.973357200622559
training step: 38452, total_loss: 3.1919937133789062
training step: 38453, total_loss: 5.238969802856445
training step: 38454, total_loss: 3.589128017425537
training step: 38455, total_loss: 2.7330434322357178
training step: 38456, total_loss: 4.072330951690674
training step: 38457, total_loss: 4.076753616333008
training step: 38458, total_loss: 5.070306777954102
training step: 38459, total_loss: 4.535984992980957
training step: 38460, total_loss: 4.624103546142578
training step: 38461, total_loss: 4.149228096008301
training step: 38462, total_loss: 3.184220790863037
training step: 38463, total_loss: 4.362442493438721
training step: 38464, total_loss: 4.343534469604492
training step: 38465, total_loss: 1.2336175441741943
training step: 38466, total_loss: 4.384180068969727
training step: 38467, total_loss: 5.875827312469482
training step: 38468, total_loss: 1.1568740606307983
training step: 38469, total_loss: 4.9536051750183105
training step: 38470, total_loss: 5.395695686340332
training step: 38471, total_loss: 3.3377938270568848
training step: 38472, total_loss: 4.621384620666504
training step: 38473, total_loss: 3.5082926750183105
training step: 38474, total_loss: 3.3155019283294678
training step: 38475, total_loss: 4.35435152053833
training step: 38476, total_loss: 4.236452579498291
training step: 38477, total_loss: 4.112699508666992
training step: 38478, total_loss: 4.24637508392334
training step: 38479, total_loss: 4.920785903930664
training step: 38480, total_loss: 4.380722999572754
training step: 38481, total_loss: 5.310630798339844
training step: 38482, total_loss: 2.077256202697754
training step: 38483, total_loss: 6.114211082458496
training step: 38484, total_loss: 3.733642101287842
training step: 38485, total_loss: 4.0272674560546875
training step: 38486, total_loss: 2.3998727798461914
training step: 38487, total_loss: 3.297177791595459
training step: 38488, total_loss: 4.694619178771973
training step: 38489, total_loss: 5.424386024475098
training step: 38490, total_loss: 4.263152122497559
training step: 38491, total_loss: 3.803673505783081
training step: 38492, total_loss: 1.9808273315429688
training step: 38493, total_loss: 3.556169033050537
training step: 38494, total_loss: 5.493669509887695
training step: 38495, total_loss: 0.8395828008651733
training step: 38496, total_loss: 5.535009860992432
training step: 38497, total_loss: 5.556319236755371
training step: 38498, total_loss: 3.6982970237731934
training step: 38499, total_loss: 4.415309906005859
training step: 38500, total_loss: 3.7981839179992676
training step: 38501, total_loss: 4.721182823181152
training step: 38502, total_loss: 2.1413793563842773
training step: 38503, total_loss: 4.400918960571289
training step: 38504, total_loss: 4.555257320404053
training step: 38505, total_loss: 4.309579849243164
training step: 38506, total_loss: 3.6166810989379883
training step: 38507, total_loss: 2.987809181213379
training step: 38508, total_loss: 3.7894392013549805
training step: 38509, total_loss: 0.7395921349525452
training step: 38510, total_loss: 2.81411075592041
training step: 38511, total_loss: 2.7077479362487793
training step: 38512, total_loss: 5.038726806640625
training step: 38513, total_loss: 5.087919235229492
training step: 38514, total_loss: 5.209854602813721
training step: 38515, total_loss: 6.051522254943848
training step: 38516, total_loss: 2.2948436737060547
training step: 38517, total_loss: 5.46801233291626
training step: 38518, total_loss: 4.660785675048828
training step: 38519, total_loss: 3.759235382080078
training step: 38520, total_loss: 5.373510837554932
training step: 38521, total_loss: 3.9633331298828125
training step: 38522, total_loss: 4.966291427612305
training step: 38523, total_loss: 5.423797607421875
training step: 38524, total_loss: 3.614574909210205
training step: 38525, total_loss: 3.7231693267822266
training step: 38526, total_loss: 5.101970672607422
training step: 38527, total_loss: 5.251307487487793
training step: 38528, total_loss: 4.681878089904785
training step: 38529, total_loss: 3.340024948120117
training step: 38530, total_loss: 4.823142051696777
training step: 38531, total_loss: 4.953872203826904
training step: 38532, total_loss: 5.33940315246582
training step: 38533, total_loss: 7.864254951477051
training step: 38534, total_loss: 3.952320098876953
training step: 38535, total_loss: 5.43991756439209
training step: 38536, total_loss: 3.7624876499176025
training step: 38537, total_loss: 3.4649479389190674
training step: 38538, total_loss: 5.2910661697387695
training step: 38539, total_loss: 5.052392959594727
training step: 38540, total_loss: 2.7289035320281982
training step: 38541, total_loss: 3.7699954509735107
training step: 38542, total_loss: 4.830281734466553
training step: 38543, total_loss: 5.008480072021484
training step: 38544, total_loss: 4.600182056427002
training step: 38545, total_loss: 3.357260227203369
training step: 38546, total_loss: 4.171393394470215
training step: 38547, total_loss: 5.419239044189453
training step: 38548, total_loss: 5.777540683746338
training step: 38549, total_loss: 4.680079460144043
training step: 38550, total_loss: 2.0769004821777344
training step: 38551, total_loss: 4.202564716339111
training step: 38552, total_loss: 5.167636871337891
training step: 38553, total_loss: 5.500087261199951
training step: 38554, total_loss: 2.629268169403076
training step: 38555, total_loss: 3.7312068939208984
training step: 38556, total_loss: 3.535682201385498
training step: 38557, total_loss: 3.718844413757324
training step: 38558, total_loss: 4.854132652282715
training step: 38559, total_loss: 3.7221498489379883
training step: 38560, total_loss: 4.473870277404785
training step: 38561, total_loss: 3.66580867767334
training step: 38562, total_loss: 3.4690299034118652
training step: 38563, total_loss: 3.8994460105895996
training step: 38564, total_loss: 1.1577779054641724
training step: 38565, total_loss: 3.1963753700256348
training step: 38566, total_loss: 5.144683837890625
training step: 38567, total_loss: 4.031926155090332
training step: 38568, total_loss: 4.375462532043457
training step: 38569, total_loss: 4.713520050048828
training step: 38570, total_loss: 3.758028030395508
training step: 38571, total_loss: 3.8965108394622803
training step: 38572, total_loss: 1.1309622526168823
training step: 38573, total_loss: 3.971987724304199
training step: 38574, total_loss: 5.779731273651123
training step: 38575, total_loss: 6.160696983337402
training step: 38576, total_loss: 5.78504753112793
training step: 38577, total_loss: 5.008774757385254
training step: 38578, total_loss: 5.750155448913574
training step: 38579, total_loss: 4.168842792510986
training step: 38580, total_loss: 6.146720886230469
training step: 38581, total_loss: 0.9668015241622925
training step: 38582, total_loss: 4.1581525802612305
training step: 38583, total_loss: 4.918920993804932
training step: 38584, total_loss: 3.7327561378479004
training step: 38585, total_loss: 3.6482362747192383
training step: 38586, total_loss: 3.448184013366699
training step: 38587, total_loss: 4.175973892211914
training step: 38588, total_loss: 5.061990737915039
training step: 38589, total_loss: 4.168874740600586
training step: 38590, total_loss: 3.9426090717315674
training step: 38591, total_loss: 3.706848621368408
training step: 38592, total_loss: 4.257011890411377
training step: 38593, total_loss: 4.011432647705078
training step: 38594, total_loss: 4.441708564758301
training step: 38595, total_loss: 3.774850845336914
training step: 38596, total_loss: 4.041705131530762
training step: 38597, total_loss: 3.8833634853363037
training step: 38598, total_loss: 3.408986806869507
training step: 38599, total_loss: 4.385641098022461
training step: 38600, total_loss: 1.1393816471099854
training step: 38601, total_loss: 5.972033977508545
training step: 38602, total_loss: 5.736641883850098
training step: 38603, total_loss: 4.979238510131836
training step: 38604, total_loss: 4.481773376464844
training step: 38605, total_loss: 5.420182228088379
training step: 38606, total_loss: 4.770299911499023
training step: 38607, total_loss: 4.891806602478027
training step: 38608, total_loss: 3.634477376937866
training step: 38609, total_loss: 3.6715989112854004
training step: 38610, total_loss: 4.183496475219727
training step: 38611, total_loss: 5.279383659362793
training step: 38612, total_loss: 4.868683338165283
training step: 38613, total_loss: 1.1417386531829834
training step: 38614, total_loss: 4.189927101135254
training step: 38615, total_loss: 4.053818702697754
training step: 38616, total_loss: 4.8913373947143555
training step: 38617, total_loss: 3.1122164726257324
training step: 38618, total_loss: 3.749185800552368
training step: 38619, total_loss: 5.940427780151367
training step: 38620, total_loss: 3.547003746032715
training step: 38621, total_loss: 5.333810806274414
training step: 38622, total_loss: 5.4175567626953125
training step: 38623, total_loss: 5.828614234924316
training step: 38624, total_loss: 4.591998100280762
training step: 38625, total_loss: 2.864412307739258
training step: 38626, total_loss: 3.9901514053344727
training step: 38627, total_loss: 3.1654844284057617
training step: 38628, total_loss: 4.232590675354004
training step: 38629, total_loss: 5.740269660949707
training step: 38630, total_loss: 4.8800048828125
training step: 38631, total_loss: 2.7643847465515137
training step: 38632, total_loss: 6.955273151397705
training step: 38633, total_loss: 3.1113297939300537
training step: 38634, total_loss: 3.6433944702148438
training step: 38635, total_loss: 3.379291534423828
training step: 38636, total_loss: 4.5253753662109375
training step: 38637, total_loss: 5.596556663513184
training step: 38638, total_loss: 4.299342155456543
training step: 38639, total_loss: 3.7324094772338867
training step: 38640, total_loss: 6.280574798583984
training step: 38641, total_loss: 2.601012706756592
training step: 38642, total_loss: 2.923612117767334
training step: 38643, total_loss: 4.4176177978515625
training step: 38644, total_loss: 4.329771041870117
training step: 38645, total_loss: 3.464249610900879
training step: 38646, total_loss: 4.261310577392578
training step: 38647, total_loss: 1.89600670337677
training step: 38648, total_loss: 1.3268811702728271
training step: 38649, total_loss: 3.8463327884674072
training step: 38650, total_loss: 4.165694236755371
training step: 38651, total_loss: 4.58072566986084
training step: 38652, total_loss: 5.0725998878479
training step: 38653, total_loss: 3.9139938354492188
training step: 38654, total_loss: 4.708578586578369
training step: 38655, total_loss: 3.976977825164795
training step: 38656, total_loss: 5.951233863830566
training step: 38657, total_loss: 5.144075393676758
training step: 38658, total_loss: 4.7865495681762695
training step: 38659, total_loss: 4.800693035125732
training step: 38660, total_loss: 4.657111167907715
training step: 38661, total_loss: 5.358311176300049
training step: 38662, total_loss: 4.992534637451172
training step: 38663, total_loss: 3.8225619792938232
training step: 38664, total_loss: 5.475615501403809
training step: 38665, total_loss: 4.448179244995117
training step: 38666, total_loss: 6.488842010498047
training step: 38667, total_loss: 3.7373220920562744
training step: 38668, total_loss: 3.995349884033203
training step: 38669, total_loss: 5.287180423736572
training step: 38670, total_loss: 1.240010380744934
training step: 38671, total_loss: 3.7961690425872803
training step: 38672, total_loss: 4.379175186157227
training step: 38673, total_loss: 4.408616542816162
training step: 38674, total_loss: 4.081063747406006
training step: 38675, total_loss: 3.3256759643554688
training step: 38676, total_loss: 3.887683868408203
training step: 38677, total_loss: 4.767120361328125
training step: 38678, total_loss: 4.169751167297363
training step: 38679, total_loss: 5.655852794647217
training step: 38680, total_loss: 4.817451477050781
training step: 38681, total_loss: 5.052726745605469
training step: 38682, total_loss: 4.242053031921387
training step: 38683, total_loss: 4.218020439147949
training step: 38684, total_loss: 4.592016220092773
training step: 38685, total_loss: 3.346493721008301
training step: 38686, total_loss: 4.679753303527832
training step: 38687, total_loss: 4.724588394165039
training step: 38688, total_loss: 4.711676120758057
training step: 38689, total_loss: 3.395720958709717
training step: 38690, total_loss: 5.160951614379883
training step: 38691, total_loss: 1.056565523147583
training step: 38692, total_loss: 4.970420837402344
training step: 38693, total_loss: 4.458464622497559
training step: 38694, total_loss: 2.228710651397705
training step: 38695, total_loss: 3.2345056533813477
training step: 38696, total_loss: 4.089261054992676
training step: 38697, total_loss: 3.820148468017578
training step: 38698, total_loss: 4.9487104415893555
training step: 38699, total_loss: 4.020166397094727
training step: 38700, total_loss: 3.080392599105835
training step: 38701, total_loss: 4.206217288970947
training step: 38702, total_loss: 4.166990280151367
training step: 38703, total_loss: 3.221452474594116
training step: 38704, total_loss: 4.381494045257568
training step: 38705, total_loss: 4.917888641357422
training step: 38706, total_loss: 3.905857563018799
training step: 38707, total_loss: 4.010777473449707
training step: 38708, total_loss: 6.038028717041016
training step: 38709, total_loss: 5.249537467956543
training step: 38710, total_loss: 3.803709030151367
training step: 38711, total_loss: 2.7936882972717285
training step: 38712, total_loss: 5.949967861175537
training step: 38713, total_loss: 3.695847511291504
training step: 38714, total_loss: 5.560956954956055
training step: 38715, total_loss: 4.524845123291016
training step: 38716, total_loss: 3.298090934753418
training step: 38717, total_loss: 4.37786865234375
training step: 38718, total_loss: 4.710024356842041
training step: 38719, total_loss: 6.507823467254639
training step: 38720, total_loss: 4.8517374992370605
training step: 38721, total_loss: 2.7448346614837646
training step: 38722, total_loss: 4.609180450439453
training step: 38723, total_loss: 6.019933700561523
training step: 38724, total_loss: 4.552788734436035
training step: 38725, total_loss: 5.018646717071533
training step: 38726, total_loss: 5.94313907623291
training step: 38727, total_loss: 3.953263282775879
training step: 38728, total_loss: 4.754329204559326
training step: 38729, total_loss: 4.96750545501709
training step: 38730, total_loss: 2.6583175659179688
training step: 38731, total_loss: 4.663944244384766
training step: 38732, total_loss: 3.865225315093994
training step: 38733, total_loss: 3.7530934810638428
training step: 38734, total_loss: 4.34121036529541
training step: 38735, total_loss: 1.2144663333892822
training step: 38736, total_loss: 3.5382466316223145
training step: 38737, total_loss: 5.116787433624268
training step: 38738, total_loss: 2.861269950866699
training step: 38739, total_loss: 3.470445156097412
training step: 38740, total_loss: 5.38098669052124
training step: 38741, total_loss: 5.757580280303955
training step: 38742, total_loss: 4.452569007873535
training step: 38743, total_loss: 4.480910778045654
training step: 38744, total_loss: 3.8171305656433105
training step: 38745, total_loss: 3.671720027923584
training step: 38746, total_loss: 6.175092697143555
training step: 38747, total_loss: 5.966679096221924
training step: 38748, total_loss: 3.8460400104522705
training step: 38749, total_loss: 2.44236421585083
training step: 38750, total_loss: 4.004907131195068
training step: 38751, total_loss: 3.092855453491211
training step: 38752, total_loss: 4.845987319946289
training step: 38753, total_loss: 2.952972412109375
training step: 38754, total_loss: 2.9450244903564453
training step: 38755, total_loss: 2.4411158561706543
training step: 38756, total_loss: 3.4751691818237305
training step: 38757, total_loss: 5.921982765197754
training step: 38758, total_loss: 4.61231803894043
training step: 38759, total_loss: 4.954711437225342
training step: 38760, total_loss: 4.441196918487549
training step: 38761, total_loss: 4.908738613128662
training step: 38762, total_loss: 7.174422264099121
training step: 38763, total_loss: 5.2929582595825195
training step: 38764, total_loss: 4.709310054779053
training step: 38765, total_loss: 4.069020748138428
training step: 38766, total_loss: 4.704782962799072
training step: 38767, total_loss: 5.456996917724609
training step: 38768, total_loss: 5.1849470138549805
training step: 38769, total_loss: 6.332826137542725
training step: 38770, total_loss: 3.908306121826172
training step: 38771, total_loss: 4.515897750854492
training step: 38772, total_loss: 4.149679660797119
training step: 38773, total_loss: 4.988498687744141
training step: 38774, total_loss: 3.8919029235839844
training step: 38775, total_loss: 3.3090548515319824
training step: 38776, total_loss: 1.6565492153167725
training step: 38777, total_loss: 3.7988221645355225
training step: 38778, total_loss: 5.68688440322876
training step: 38779, total_loss: 4.676278114318848
training step: 38780, total_loss: 2.7169699668884277
training step: 38781, total_loss: 4.584299087524414
training step: 38782, total_loss: 4.2375288009643555
training step: 38783, total_loss: 3.6865429878234863
training step: 38784, total_loss: 4.450962543487549
training step: 38785, total_loss: 5.324328422546387
training step: 38786, total_loss: 5.126152038574219
training step: 38787, total_loss: 6.028635025024414
training step: 38788, total_loss: 6.00304651260376
training step: 38789, total_loss: 5.100942611694336
training step: 38790, total_loss: 4.324062347412109
training step: 38791, total_loss: 2.95261287689209
training step: 38792, total_loss: 6.1415228843688965
training step: 38793, total_loss: 2.5161595344543457
training step: 38794, total_loss: 4.8254804611206055
training step: 38795, total_loss: 2.6772172451019287
training step: 38796, total_loss: 1.384559988975525
training step: 38797, total_loss: 4.077755928039551
training step: 38798, total_loss: 5.0187835693359375
training step: 38799, total_loss: 5.407625675201416
training step: 38800, total_loss: 4.870946884155273
training step: 38801, total_loss: 3.374591588973999
training step: 38802, total_loss: 4.120251655578613
training step: 38803, total_loss: 5.353442192077637
training step: 38804, total_loss: 5.187529563903809
training step: 38805, total_loss: 3.761139392852783
training step: 38806, total_loss: 4.251802921295166
training step: 38807, total_loss: 4.327885627746582
training step: 38808, total_loss: 4.398069381713867
training step: 38809, total_loss: 4.609174728393555
training step: 38810, total_loss: 3.4177756309509277
training step: 38811, total_loss: 5.540805816650391
training step: 38812, total_loss: 3.694328546524048
training step: 38813, total_loss: 3.932396411895752
training step: 38814, total_loss: 3.71858286857605
training step: 38815, total_loss: 4.75676155090332
training step: 38816, total_loss: 3.134659767150879
training step: 38817, total_loss: 1.0498616695404053
training step: 38818, total_loss: 4.973605155944824
training step: 38819, total_loss: 4.619291305541992
training step: 38820, total_loss: 3.9708971977233887
training step: 38821, total_loss: 4.859528064727783
training step: 38822, total_loss: 5.043783187866211
training step: 38823, total_loss: 4.610322952270508
training step: 38824, total_loss: 5.353656768798828
training step: 38825, total_loss: 5.1023712158203125
training step: 38826, total_loss: 4.259406089782715
training step: 38827, total_loss: 6.074790954589844
training step: 38828, total_loss: 3.6538138389587402
training step: 38829, total_loss: 4.689593315124512
training step: 38830, total_loss: 1.3502378463745117
training step: 38831, total_loss: 2.738755702972412
training step: 38832, total_loss: 4.868539333343506
training step: 38833, total_loss: 5.5675950050354
training step: 38834, total_loss: 4.897697448730469
training step: 38835, total_loss: 3.139660358428955
training step: 38836, total_loss: 2.981290578842163
training step: 38837, total_loss: 0.8795163631439209
training step: 38838, total_loss: 4.878645420074463
training step: 38839, total_loss: 5.982903003692627
training step: 38840, total_loss: 4.836688041687012
training step: 38841, total_loss: 5.064548492431641
training step: 38842, total_loss: 3.969836711883545
training step: 38843, total_loss: 4.460848808288574
training step: 38844, total_loss: 5.67940616607666
training step: 38845, total_loss: 4.381839752197266
training step: 38846, total_loss: 5.7576003074646
training step: 38847, total_loss: 4.926948547363281
training step: 38848, total_loss: 4.216819763183594
training step: 38849, total_loss: 4.639299392700195
training step: 38850, total_loss: 4.216556072235107
training step: 38851, total_loss: 5.619335174560547
training step: 38852, total_loss: 3.509500026702881
training step: 38853, total_loss: 1.3148858547210693
training step: 38854, total_loss: 2.029127597808838
training step: 38855, total_loss: 4.29943323135376
training step: 38856, total_loss: 3.5525619983673096
training step: 38857, total_loss: 4.4149699211120605
training step: 38858, total_loss: 3.6319282054901123
training step: 38859, total_loss: 4.664917469024658
training step: 38860, total_loss: 3.581444501876831
training step: 38861, total_loss: 5.170425891876221
training step: 38862, total_loss: 4.463535308837891
training step: 38863, total_loss: 5.4152631759643555
training step: 38864, total_loss: 3.3769278526306152
training step: 38865, total_loss: 4.637107849121094
training step: 38866, total_loss: 0.7184205651283264
training step: 38867, total_loss: 5.00366735458374
training step: 38868, total_loss: 4.232214450836182
training step: 38869, total_loss: 4.412121772766113
training step: 38870, total_loss: 6.310852527618408
training step: 38871, total_loss: 5.110417366027832
training step: 38872, total_loss: 6.2655744552612305
training step: 38873, total_loss: 4.896843433380127
training step: 38874, total_loss: 4.653753757476807
training step: 38875, total_loss: 3.7895021438598633
training step: 38876, total_loss: 4.672865867614746
training step: 38877, total_loss: 4.865028381347656
training step: 38878, total_loss: 6.4346418380737305
training step: 38879, total_loss: 5.637575149536133
training step: 38880, total_loss: 4.529825210571289
training step: 38881, total_loss: 5.365772247314453
training step: 38882, total_loss: 5.364969253540039
training step: 38883, total_loss: 5.073403835296631
training step: 38884, total_loss: 3.4089040756225586
training step: 38885, total_loss: 4.936312198638916
training step: 38886, total_loss: 4.6638994216918945
training step: 38887, total_loss: 4.88346004486084
training step: 38888, total_loss: 3.2386655807495117
training step: 38889, total_loss: 4.597745895385742
training step: 38890, total_loss: 4.00400447845459
training step: 38891, total_loss: 4.002443313598633
training step: 38892, total_loss: 4.721221446990967
training step: 38893, total_loss: 4.162513732910156
training step: 38894, total_loss: 4.472548484802246
training step: 38895, total_loss: 3.805467128753662
training step: 38896, total_loss: 3.4636361598968506
training step: 38897, total_loss: 2.978088855743408
training step: 38898, total_loss: 4.842471122741699
training step: 38899, total_loss: 5.401126861572266
training step: 38900, total_loss: 5.51216983795166
training step: 38901, total_loss: 4.186452865600586
training step: 38902, total_loss: 5.62559175491333
training step: 38903, total_loss: 5.722601890563965
training step: 38904, total_loss: 4.770065784454346
training step: 38905, total_loss: 4.058680057525635
training step: 38906, total_loss: 4.51317834854126
training step: 38907, total_loss: 2.843489646911621
training step: 38908, total_loss: 6.412153244018555
training step: 38909, total_loss: 0.8600960373878479
training step: 38910, total_loss: 5.243411540985107
training step: 38911, total_loss: 3.9955272674560547
training step: 38912, total_loss: 3.963649034500122
training step: 38913, total_loss: 5.4897074699401855
training step: 38914, total_loss: 2.7766358852386475
training step: 38915, total_loss: 3.9778475761413574
training step: 38916, total_loss: 5.304548263549805
training step: 38917, total_loss: 5.039694786071777
training step: 38918, total_loss: 4.9571452140808105
training step: 38919, total_loss: 4.074001312255859
training step: 38920, total_loss: 3.8609321117401123
training step: 38921, total_loss: 4.273573875427246
training step: 38922, total_loss: 4.660322189331055
training step: 38923, total_loss: 5.460061073303223
training step: 38924, total_loss: 3.7843985557556152
training step: 38925, total_loss: 4.472347259521484
training step: 38926, total_loss: 3.2503199577331543
training step: 38927, total_loss: 3.6925911903381348
training step: 38928, total_loss: 2.5211713314056396
training step: 38929, total_loss: 0.745061993598938
training step: 38930, total_loss: 5.320145606994629
training step: 38931, total_loss: 4.190286636352539
training step: 38932, total_loss: 4.700309753417969
training step: 38933, total_loss: 6.877115249633789
training step: 38934, total_loss: 4.7432403564453125
training step: 38935, total_loss: 2.551516056060791
training step: 38936, total_loss: 4.374130725860596
training step: 38937, total_loss: 4.4705810546875
training step: 38938, total_loss: 3.088186264038086
training step: 38939, total_loss: 3.581289768218994
training step: 38940, total_loss: 3.7103447914123535
training step: 38941, total_loss: 5.387250900268555
training step: 38942, total_loss: 2.998383045196533
training step: 38943, total_loss: 4.252220630645752
training step: 38944, total_loss: 4.756583213806152
training step: 38945, total_loss: 2.9671945571899414
training step: 38946, total_loss: 5.132935523986816
training step: 38947, total_loss: 4.3127336502075195
training step: 38948, total_loss: 4.825388431549072
training step: 38949, total_loss: 5.413317680358887
training step: 38950, total_loss: 5.30504035949707
training step: 38951, total_loss: 4.513132572174072
training step: 38952, total_loss: 2.5832128524780273
training step: 38953, total_loss: 4.004243850708008
training step: 38954, total_loss: 5.190428733825684
training step: 38955, total_loss: 4.440077781677246
training step: 38956, total_loss: 3.7448959350585938
training step: 38957, total_loss: 4.132411956787109
training step: 38958, total_loss: 0.6091066598892212
training step: 38959, total_loss: 2.6385691165924072
training step: 38960, total_loss: 3.698801279067993
training step: 38961, total_loss: 4.723645210266113
training step: 38962, total_loss: 4.462198734283447
training step: 38963, total_loss: 3.40443754196167
training step: 38964, total_loss: 2.913095474243164
training step: 38965, total_loss: 5.407098770141602
training step: 38966, total_loss: 4.950214862823486
training step: 38967, total_loss: 4.95982551574707
training step: 38968, total_loss: 2.890967607498169
training step: 38969, total_loss: 3.8161191940307617
training step: 38970, total_loss: 4.988961219787598
training step: 38971, total_loss: 2.495811700820923
training step: 38972, total_loss: 4.6974778175354
training step: 38973, total_loss: 5.891040802001953
training step: 38974, total_loss: 5.079146385192871
training step: 38975, total_loss: 3.5509777069091797
training step: 38976, total_loss: 3.898441791534424
training step: 38977, total_loss: 4.884523391723633
training step: 38978, total_loss: 5.464869499206543
training step: 38979, total_loss: 4.627666473388672
training step: 38980, total_loss: 3.5598697662353516
training step: 38981, total_loss: 5.749927043914795
training step: 38982, total_loss: 4.150313377380371
training step: 38983, total_loss: 3.021489381790161
training step: 38984, total_loss: 4.709348201751709
training step: 38985, total_loss: 4.230616092681885
training step: 38986, total_loss: 3.2201101779937744
training step: 38987, total_loss: 5.069822311401367
training step: 38988, total_loss: 3.137769937515259
training step: 38989, total_loss: 0.8476028442382812
training step: 38990, total_loss: 3.1662275791168213
training step: 38991, total_loss: 4.583657264709473
training step: 38992, total_loss: 3.9166784286499023
training step: 38993, total_loss: 4.188502788543701
training step: 38994, total_loss: 4.324596881866455
training step: 38995, total_loss: 3.4814043045043945
training step: 38996, total_loss: 1.8770729303359985
training step: 38997, total_loss: 4.952245712280273
training step: 38998, total_loss: 4.147136211395264
training step: 38999, total_loss: 5.219918251037598
training step: 39000, total_loss: 5.030566215515137
training step: 39001, total_loss: 4.012740135192871
training step: 39002, total_loss: 3.7567098140716553
training step: 39003, total_loss: 3.585148811340332
training step: 39004, total_loss: 2.2696075439453125
training step: 39005, total_loss: 4.463783264160156
training step: 39006, total_loss: 4.1608734130859375
training step: 39007, total_loss: 3.5726046562194824
training step: 39008, total_loss: 4.862621307373047
training step: 39009, total_loss: 1.8862096071243286
training step: 39010, total_loss: 4.4140305519104
training step: 39011, total_loss: 4.057895183563232
training step: 39012, total_loss: 3.9749951362609863
training step: 39013, total_loss: 5.331746578216553
training step: 39014, total_loss: 3.7272067070007324
training step: 39015, total_loss: 5.565845489501953
training step: 39016, total_loss: 7.954827785491943
training step: 39017, total_loss: 4.008951187133789
training step: 39018, total_loss: 3.4787168502807617
training step: 39019, total_loss: 5.9893999099731445
training step: 39020, total_loss: 6.136962413787842
training step: 39021, total_loss: 4.412474632263184
training step: 39022, total_loss: 3.6012749671936035
training step: 39023, total_loss: 5.265051364898682
training step: 39024, total_loss: 4.793266296386719
training step: 39025, total_loss: 4.333566665649414
training step: 39026, total_loss: 3.523632049560547
training step: 39027, total_loss: 4.360762119293213
training step: 39028, total_loss: 6.192206382751465
training step: 39029, total_loss: 2.9942126274108887
training step: 39030, total_loss: 3.6837282180786133
training step: 39031, total_loss: 4.145765781402588
training step: 39032, total_loss: 2.892666816711426
training step: 39033, total_loss: 3.3436779975891113
training step: 39034, total_loss: 4.971890449523926
training step: 39035, total_loss: 4.824748516082764
training step: 39036, total_loss: 4.544131278991699
training step: 39037, total_loss: 2.5829150676727295
training step: 39038, total_loss: 4.039614200592041
training step: 39039, total_loss: 5.118332862854004
training step: 39040, total_loss: 5.255121231079102
training step: 39041, total_loss: 5.2412638664245605
training step: 39042, total_loss: 2.0898966789245605
training step: 39043, total_loss: 5.26142692565918
training step: 39044, total_loss: 4.122489929199219
training step: 39045, total_loss: 4.685564994812012
training step: 39046, total_loss: 4.1219482421875
training step: 39047, total_loss: 3.804511070251465
training step: 39048, total_loss: 3.3635313510894775
training step: 39049, total_loss: 3.5659854412078857
training step: 39050, total_loss: 5.844753742218018
training step: 39051, total_loss: 3.0274534225463867
training step: 39052, total_loss: 3.7467896938323975
training step: 39053, total_loss: 4.6860857009887695
training step: 39054, total_loss: 3.538952350616455
training step: 39055, total_loss: 4.173781394958496
training step: 39056, total_loss: 4.991355895996094
training step: 39057, total_loss: 3.9377615451812744
training step: 39058, total_loss: 3.4808313846588135
training step: 39059, total_loss: 3.3389711380004883
training step: 39060, total_loss: 5.8855204582214355
training step: 39061, total_loss: 4.942980766296387
training step: 39062, total_loss: 2.9341049194335938
training step: 39063, total_loss: 4.6858930587768555
training step: 39064, total_loss: 5.328483581542969
training step: 39065, total_loss: 5.582494258880615
training step: 39066, total_loss: 4.734859943389893
training step: 39067, total_loss: 5.060529708862305
training step: 39068, total_loss: 4.896903038024902
training step: 39069, total_loss: 6.079299449920654
training step: 39070, total_loss: 4.366701126098633
training step: 39071, total_loss: 7.204488754272461
training step: 39072, total_loss: 4.905791759490967
training step: 39073, total_loss: 4.636246204376221
training step: 39074, total_loss: 4.529778003692627
training step: 39075, total_loss: 3.1542935371398926
training step: 39076, total_loss: 5.171209812164307
training step: 39077, total_loss: 3.8998818397521973
training step: 39078, total_loss: 4.0562591552734375
training step: 39079, total_loss: 5.049923896789551
training step: 39080, total_loss: 4.935087203979492
training step: 39081, total_loss: 4.660774230957031
training step: 39082, total_loss: 4.815723896026611
training step: 39083, total_loss: 4.9458112716674805
training step: 39084, total_loss: 4.590456962585449
training step: 39085, total_loss: 4.748150825500488
training step: 39086, total_loss: 3.4774246215820312
training step: 39087, total_loss: 2.9156928062438965
training step: 39088, total_loss: 4.245054721832275
training step: 39089, total_loss: 4.55294132232666
training step: 39090, total_loss: 5.067931175231934
training step: 39091, total_loss: 3.326763153076172
training step: 39092, total_loss: 5.036975383758545
training step: 39093, total_loss: 5.999248504638672
training step: 39094, total_loss: 4.951683044433594
training step: 39095, total_loss: 3.616002082824707
training step: 39096, total_loss: 3.391357898712158
training step: 39097, total_loss: 0.8400434255599976
training step: 39098, total_loss: 4.564969539642334
training step: 39099, total_loss: 4.17619514465332
training step: 39100, total_loss: 3.6582727432250977
training step: 39101, total_loss: 4.34389591217041
training step: 39102, total_loss: 4.4934306144714355
training step: 39103, total_loss: 4.8520965576171875
training step: 39104, total_loss: 4.212276458740234
training step: 39105, total_loss: 4.086000442504883
training step: 39106, total_loss: 3.8447554111480713
training step: 39107, total_loss: 5.746808052062988
training step: 39108, total_loss: 3.1773524284362793
training step: 39109, total_loss: 2.691133499145508
training step: 39110, total_loss: 4.744609832763672
training step: 39111, total_loss: 2.8411478996276855
training step: 39112, total_loss: 2.735301971435547
training step: 39113, total_loss: 4.625250816345215
training step: 39114, total_loss: 6.638269424438477
training step: 39115, total_loss: 5.161980628967285
training step: 39116, total_loss: 5.8692731857299805
training step: 39117, total_loss: 4.656381607055664
training step: 39118, total_loss: 4.521234512329102
training step: 39119, total_loss: 4.502686023712158
training step: 39120, total_loss: 4.196556091308594
training step: 39121, total_loss: 3.2830724716186523
training step: 39122, total_loss: 4.131124973297119
training step: 39123, total_loss: 3.956432342529297
training step: 39124, total_loss: 4.680120468139648
training step: 39125, total_loss: 1.9358227252960205
training step: 39126, total_loss: 6.397658348083496
training step: 39127, total_loss: 4.260004997253418
training step: 39128, total_loss: 3.5611586570739746
training step: 39129, total_loss: 3.779937744140625
training step: 39130, total_loss: 2.877354145050049
training step: 39131, total_loss: 5.434743881225586
training step: 39132, total_loss: 5.786049842834473
training step: 39133, total_loss: 5.028200626373291
training step: 39134, total_loss: 5.3538665771484375
training step: 39135, total_loss: 5.61635684967041
training step: 39136, total_loss: 4.111303806304932
training step: 39137, total_loss: 3.637535572052002
training step: 39138, total_loss: 2.0219860076904297
training step: 39139, total_loss: 5.249664306640625
training step: 39140, total_loss: 4.614896297454834
training step: 39141, total_loss: 4.865688323974609
training step: 39142, total_loss: 4.386491298675537
training step: 39143, total_loss: 4.756999969482422
training step: 39144, total_loss: 4.136078834533691
training step: 39145, total_loss: 4.450512409210205
training step: 39146, total_loss: 3.9816806316375732
training step: 39147, total_loss: 3.550142288208008
training step: 39148, total_loss: 5.005505561828613
training step: 39149, total_loss: 4.661796569824219
training step: 39150, total_loss: 4.873394966125488
training step: 39151, total_loss: 3.5428690910339355
training step: 39152, total_loss: 1.3929901123046875
training step: 39153, total_loss: 4.395678520202637
training step: 39154, total_loss: 4.598116397857666
training step: 39155, total_loss: 3.822718858718872
training step: 39156, total_loss: 4.683121681213379
training step: 39157, total_loss: 3.947342872619629
training step: 39158, total_loss: 6.1347455978393555
training step: 39159, total_loss: 4.798526287078857
training step: 39160, total_loss: 5.790750980377197
training step: 39161, total_loss: 4.5603556632995605
training step: 39162, total_loss: 4.539734840393066
training step: 39163, total_loss: 4.4971113204956055
training step: 39164, total_loss: 4.490179061889648
training step: 39165, total_loss: 5.05713415145874
training step: 39166, total_loss: 4.647218704223633
training step: 39167, total_loss: 4.807349681854248
training step: 39168, total_loss: 1.1640368700027466
training step: 39169, total_loss: 3.228961944580078
training step: 39170, total_loss: 3.545717239379883
training step: 39171, total_loss: 5.446977615356445
training step: 39172, total_loss: 4.132469177246094
training step: 39173, total_loss: 4.709716796875
training step: 39174, total_loss: 5.402461051940918
training step: 39175, total_loss: 2.6907739639282227
training step: 39176, total_loss: 3.781938076019287
training step: 39177, total_loss: 4.047149658203125
training step: 39178, total_loss: 4.421529769897461
training step: 39179, total_loss: 4.911498069763184
training step: 39180, total_loss: 4.258528709411621
training step: 39181, total_loss: 4.602145195007324
training step: 39182, total_loss: 3.3504884243011475
training step: 39183, total_loss: 4.095832824707031
training step: 39184, total_loss: 4.4755964279174805
training step: 39185, total_loss: 5.490764141082764
training step: 39186, total_loss: 3.352321147918701
training step: 39187, total_loss: 5.046103477478027
training step: 39188, total_loss: 3.9159035682678223
training step: 39189, total_loss: 5.072443962097168
training step: 39190, total_loss: 5.0460429191589355
training step: 39191, total_loss: 5.289889335632324
training step: 39192, total_loss: 5.150612831115723
training step: 39193, total_loss: 5.4576592445373535
training step: 39194, total_loss: 4.965804100036621
training step: 39195, total_loss: 4.362389087677002
training step: 39196, total_loss: 0.9028447866439819
training step: 39197, total_loss: 4.975254058837891
training step: 39198, total_loss: 4.556940078735352
training step: 39199, total_loss: 3.6318936347961426
training step: 39200, total_loss: 4.657371520996094
training step: 39201, total_loss: 4.415187835693359
training step: 39202, total_loss: 4.003477096557617
training step: 39203, total_loss: 5.3396806716918945
training step: 39204, total_loss: 4.805493354797363
training step: 39205, total_loss: 5.627582550048828
training step: 39206, total_loss: 3.8989439010620117
training step: 39207, total_loss: 6.07981538772583
training step: 39208, total_loss: 3.218705654144287
training step: 39209, total_loss: 1.8587603569030762
training step: 39210, total_loss: 3.908494472503662
training step: 39211, total_loss: 4.386584281921387
training step: 39212, total_loss: 4.1687211990356445
training step: 39213, total_loss: 4.305026054382324
training step: 39214, total_loss: 3.113184690475464
training step: 39215, total_loss: 2.5887651443481445
training step: 39216, total_loss: 5.351792335510254
training step: 39217, total_loss: 4.684597015380859
training step: 39218, total_loss: 4.725149154663086
training step: 39219, total_loss: 3.928837299346924
training step: 39220, total_loss: 6.497179985046387
training step: 39221, total_loss: 5.113063812255859
training step: 39222, total_loss: 4.754294395446777
training step: 39223, total_loss: 4.532631874084473
training step: 39224, total_loss: 5.545840740203857
training step: 39225, total_loss: 4.529086112976074
training step: 39226, total_loss: 2.415344476699829
training step: 39227, total_loss: 4.132638454437256
training step: 39228, total_loss: 3.1536169052124023
training step: 39229, total_loss: 4.772330284118652
training step: 39230, total_loss: 1.18560791015625
training step: 39231, total_loss: 4.7584686279296875
training step: 39232, total_loss: 3.884772777557373
training step: 39233, total_loss: 2.0091700553894043
training step: 39234, total_loss: 4.825582027435303
training step: 39235, total_loss: 2.867286443710327
training step: 39236, total_loss: 4.966923713684082
training step: 39237, total_loss: 4.114961624145508
training step: 39238, total_loss: 1.4825299978256226
training step: 39239, total_loss: 6.424862861633301
training step: 39240, total_loss: 5.3217315673828125
training step: 39241, total_loss: 4.299684047698975
training step: 39242, total_loss: 2.8890132904052734
training step: 39243, total_loss: 2.400486469268799
training step: 39244, total_loss: 3.862010955810547
training step: 39245, total_loss: 5.768207550048828
training step: 39246, total_loss: 3.3816843032836914
training step: 39247, total_loss: 4.424831390380859
training step: 39248, total_loss: 3.8747589588165283
training step: 39249, total_loss: 5.507392883300781
training step: 39250, total_loss: 4.407740116119385
training step: 39251, total_loss: 3.9404497146606445
training step: 39252, total_loss: 4.355388641357422
training step: 39253, total_loss: 5.281203746795654
training step: 39254, total_loss: 4.183224678039551
training step: 39255, total_loss: 3.73190975189209
training step: 39256, total_loss: 4.913589954376221
training step: 39257, total_loss: 6.200275421142578
training step: 39258, total_loss: 5.266674041748047
training step: 39259, total_loss: 5.93248176574707
training step: 39260, total_loss: 2.865269899368286
training step: 39261, total_loss: 4.94134521484375
training step: 39262, total_loss: 6.191719055175781
training step: 39263, total_loss: 2.945613384246826
training step: 39264, total_loss: 4.325462341308594
training step: 39265, total_loss: 3.9159460067749023
training step: 39266, total_loss: 4.6029767990112305
training step: 39267, total_loss: 5.952862739562988
training step: 39268, total_loss: 4.977972030639648
training step: 39269, total_loss: 3.1675312519073486
training step: 39270, total_loss: 4.885547161102295
training step: 39271, total_loss: 5.577828407287598
training step: 39272, total_loss: 4.511458396911621
training step: 39273, total_loss: 5.3907470703125
training step: 39274, total_loss: 1.1471364498138428
training step: 39275, total_loss: 3.5577142238616943
training step: 39276, total_loss: 4.5899553298950195
training step: 39277, total_loss: 3.776885509490967
training step: 39278, total_loss: 4.294564247131348
training step: 39279, total_loss: 4.522177219390869
training step: 39280, total_loss: 4.621417999267578
training step: 39281, total_loss: 4.610621452331543
training step: 39282, total_loss: 3.7039737701416016
training step: 39283, total_loss: 3.563015937805176
training step: 39284, total_loss: 3.100984811782837
training step: 39285, total_loss: 3.403904676437378
training step: 39286, total_loss: 5.27139949798584
training step: 39287, total_loss: 5.397809028625488
training step: 39288, total_loss: 3.7876312732696533
training step: 39289, total_loss: 7.066812038421631
training step: 39290, total_loss: 4.590571403503418
training step: 39291, total_loss: 1.277719259262085
training step: 39292, total_loss: 5.460474014282227
training step: 39293, total_loss: 4.572110652923584
training step: 39294, total_loss: 4.937819480895996
training step: 39295, total_loss: 4.981529235839844
training step: 39296, total_loss: 6.491056442260742
training step: 39297, total_loss: 4.958572864532471
training step: 39298, total_loss: 3.462894916534424
training step: 39299, total_loss: 1.3751990795135498
training step: 39300, total_loss: 5.513329982757568
training step: 39301, total_loss: 4.530884742736816
training step: 39302, total_loss: 4.950016498565674
training step: 39303, total_loss: 5.743795394897461
training step: 39304, total_loss: 3.418508291244507
training step: 39305, total_loss: 4.5647783279418945
training step: 39306, total_loss: 3.966226577758789
training step: 39307, total_loss: 5.961469650268555
training step: 39308, total_loss: 4.3729939460754395
training step: 39309, total_loss: 4.285558700561523
training step: 39310, total_loss: 4.078065872192383
training step: 39311, total_loss: 2.5486791133880615
training step: 39312, total_loss: 3.7338931560516357
training step: 39313, total_loss: 6.755445957183838
training step: 39314, total_loss: 4.800549507141113
training step: 39315, total_loss: 2.847482681274414
training step: 39316, total_loss: 4.148406982421875
training step: 39317, total_loss: 5.333283424377441
training step: 39318, total_loss: 4.904081344604492
training step: 39319, total_loss: 3.9376587867736816
training step: 39320, total_loss: 4.52800178527832
training step: 39321, total_loss: 4.630758285522461
training step: 39322, total_loss: 5.013698577880859
training step: 39323, total_loss: 4.049078464508057
training step: 39324, total_loss: 5.099404335021973
training step: 39325, total_loss: 4.594245910644531
training step: 39326, total_loss: 6.1217546463012695
training step: 39327, total_loss: 4.4712677001953125
training step: 39328, total_loss: 4.486876487731934
training step: 39329, total_loss: 3.5748672485351562
training step: 39330, total_loss: 3.5815701484680176
training step: 39331, total_loss: 3.7059645652770996
training step: 39332, total_loss: 3.831927537918091
training step: 39333, total_loss: 4.734460830688477
training step: 39334, total_loss: 3.7837376594543457
training step: 39335, total_loss: 5.146491050720215
training step: 39336, total_loss: 3.4748501777648926
training step: 39337, total_loss: 4.393680572509766
training step: 39338, total_loss: 3.9029600620269775
training step: 39339, total_loss: 5.5362677574157715
training step: 39340, total_loss: 3.754136085510254
training step: 39341, total_loss: 5.113400459289551
training step: 39342, total_loss: 4.755992412567139
training step: 39343, total_loss: 6.094527244567871
training step: 39344, total_loss: 5.151675701141357
training step: 39345, total_loss: 3.569131851196289
training step: 39346, total_loss: 4.819395065307617
training step: 39347, total_loss: 3.9661824703216553
training step: 39348, total_loss: 3.7251577377319336
training step: 39349, total_loss: 3.8433914184570312
training step: 39350, total_loss: 2.7201013565063477
training step: 39351, total_loss: 4.690404415130615
training step: 39352, total_loss: 4.68037223815918
training step: 39353, total_loss: 3.596728801727295
training step: 39354, total_loss: 4.520815372467041
training step: 39355, total_loss: 5.056146144866943
training step: 39356, total_loss: 4.3336567878723145
training step: 39357, total_loss: 4.5715436935424805
training step: 39358, total_loss: 3.84151554107666
training step: 39359, total_loss: 5.973814010620117
training step: 39360, total_loss: 4.829659938812256
training step: 39361, total_loss: 5.08448600769043
training step: 39362, total_loss: 5.212824821472168
training step: 39363, total_loss: 5.252115726470947
training step: 39364, total_loss: 5.805542469024658
training step: 39365, total_loss: 3.4118118286132812
training step: 39366, total_loss: 4.658506870269775
training step: 39367, total_loss: 3.9259328842163086
training step: 39368, total_loss: 4.291113376617432
training step: 39369, total_loss: 5.276461601257324
training step: 39370, total_loss: 4.966794013977051
training step: 39371, total_loss: 4.022894859313965
training step: 39372, total_loss: 5.266571044921875
training step: 39373, total_loss: 3.269324779510498
training step: 39374, total_loss: 3.908031940460205
training step: 39375, total_loss: 3.5069589614868164
training step: 39376, total_loss: 4.6170334815979
training step: 39377, total_loss: 4.2726640701293945
training step: 39378, total_loss: 4.691841125488281
training step: 39379, total_loss: 4.295988082885742
training step: 39380, total_loss: 5.052691459655762
training step: 39381, total_loss: 2.0832605361938477
training step: 39382, total_loss: 4.64265775680542
training step: 39383, total_loss: 5.831639766693115
training step: 39384, total_loss: 3.1760404109954834
training step: 39385, total_loss: 2.9445736408233643
training step: 39386, total_loss: 6.792087554931641
training step: 39387, total_loss: 4.170025825500488
training step: 39388, total_loss: 3.8462111949920654
training step: 39389, total_loss: 3.6955630779266357
training step: 39390, total_loss: 4.423305034637451
training step: 39391, total_loss: 4.323085308074951
training step: 39392, total_loss: 2.8151776790618896
training step: 39393, total_loss: 3.5654730796813965
training step: 39394, total_loss: 4.601400375366211
training step: 39395, total_loss: 6.074883460998535
training step: 39396, total_loss: 4.894893646240234
training step: 39397, total_loss: 2.73915433883667
training step: 39398, total_loss: 3.470061779022217
training step: 39399, total_loss: 5.168306350708008
training step: 39400, total_loss: 5.201839447021484
training step: 39401, total_loss: 4.201486587524414
training step: 39402, total_loss: 5.308174133300781
training step: 39403, total_loss: 5.039341926574707
training step: 39404, total_loss: 5.221569061279297
training step: 39405, total_loss: 3.406651496887207
training step: 39406, total_loss: 5.71440315246582
training step: 39407, total_loss: 1.1175167560577393
training step: 39408, total_loss: 5.078251361846924
training step: 39409, total_loss: 6.702512741088867
training step: 39410, total_loss: 4.929779052734375
training step: 39411, total_loss: 3.1155307292938232
training step: 39412, total_loss: 5.33430290222168
training step: 39413, total_loss: 4.376939296722412
training step: 39414, total_loss: 3.6939101219177246
training step: 39415, total_loss: 5.053357124328613
training step: 39416, total_loss: 3.833219528198242
training step: 39417, total_loss: 3.8526148796081543
training step: 39418, total_loss: 4.785836219787598
training step: 39419, total_loss: 5.733059883117676
training step: 39420, total_loss: 2.705510139465332
training step: 39421, total_loss: 1.3949775695800781
training step: 39422, total_loss: 4.7103376388549805
training step: 39423, total_loss: 5.7519073486328125
training step: 39424, total_loss: 4.753215789794922
training step: 39425, total_loss: 3.5155296325683594
training step: 39426, total_loss: 3.3349075317382812
training step: 39427, total_loss: 5.952754974365234
training step: 39428, total_loss: 3.5019845962524414
training step: 39429, total_loss: 4.4410576820373535
training step: 39430, total_loss: 3.9308528900146484
training step: 39431, total_loss: 4.6275224685668945
training step: 39432, total_loss: 4.659549713134766
training step: 39433, total_loss: 4.735594749450684
training step: 39434, total_loss: 4.764469623565674
training step: 39435, total_loss: 4.291019439697266
training step: 39436, total_loss: 4.0308709144592285
training step: 39437, total_loss: 5.847938537597656
training step: 39438, total_loss: 4.890020370483398
training step: 39439, total_loss: 5.380428314208984
training step: 39440, total_loss: 4.403228759765625
training step: 39441, total_loss: 4.813408374786377
training step: 39442, total_loss: 4.343101501464844
training step: 39443, total_loss: 5.91959285736084
training step: 39444, total_loss: 5.471419334411621
training step: 39445, total_loss: 5.36018705368042
training step: 39446, total_loss: 3.9733598232269287
training step: 39447, total_loss: 4.185000419616699
training step: 39448, total_loss: 4.434291839599609
training step: 39449, total_loss: 2.7197718620300293
training step: 39450, total_loss: 1.3849859237670898
training step: 39451, total_loss: 4.0796284675598145
training step: 39452, total_loss: 3.61360502243042
training step: 39453, total_loss: 4.996450424194336
training step: 39454, total_loss: 5.106752395629883
training step: 39455, total_loss: 2.9240381717681885
training step: 39456, total_loss: 3.946290969848633
training step: 39457, total_loss: 3.1074392795562744
training step: 39458, total_loss: 2.7673449516296387
training step: 39459, total_loss: 3.9052159786224365
training step: 39460, total_loss: 4.9622650146484375
training step: 39461, total_loss: 4.712360382080078
training step: 39462, total_loss: 4.083054065704346
training step: 39463, total_loss: 4.1396026611328125
training step: 39464, total_loss: 4.874658107757568
training step: 39465, total_loss: 3.3709912300109863
training step: 39466, total_loss: 4.627309799194336
training step: 39467, total_loss: 3.6979079246520996
training step: 39468, total_loss: 6.22932243347168
training step: 39469, total_loss: 5.448373317718506
training step: 39470, total_loss: 5.600252151489258
training step: 39471, total_loss: 3.4095029830932617
training step: 39472, total_loss: 4.316227436065674
training step: 39473, total_loss: 4.596553802490234
training step: 39474, total_loss: 4.925717353820801
training step: 39475, total_loss: 5.169543743133545
training step: 39476, total_loss: 4.102553367614746
training step: 39477, total_loss: 3.642335891723633
training step: 39478, total_loss: 4.450181484222412
training step: 39479, total_loss: 3.9766178131103516
training step: 39480, total_loss: 5.818258762359619
training step: 39481, total_loss: 2.607806921005249
training step: 39482, total_loss: 5.084756851196289
training step: 39483, total_loss: 2.098181962966919
training step: 39484, total_loss: 3.380272388458252
training step: 39485, total_loss: 4.026728630065918
training step: 39486, total_loss: 5.476104736328125
training step: 39487, total_loss: 5.382091999053955
training step: 39488, total_loss: 5.6084303855896
training step: 39489, total_loss: 3.162466526031494
training step: 39490, total_loss: 5.3380584716796875
training step: 39491, total_loss: 3.9694416522979736
training step: 39492, total_loss: 4.313742637634277
training step: 39493, total_loss: 4.380993366241455
training step: 39494, total_loss: 5.04280424118042
training step: 39495, total_loss: 4.325172424316406
training step: 39496, total_loss: 4.1446614265441895
training step: 39497, total_loss: 0.8748397827148438
training step: 39498, total_loss: 3.460754871368408
training step: 39499, total_loss: 1.104600191116333
training step: 39500, total_loss: 6.825566291809082
training step: 39501, total_loss: 3.002041816711426
training step: 39502, total_loss: 4.13815975189209
training step: 39503, total_loss: 4.050209999084473
training step: 39504, total_loss: 4.494454383850098
training step: 39505, total_loss: 3.8038039207458496
training step: 39506, total_loss: 5.583953380584717
training step: 39507, total_loss: 4.11794376373291
training step: 39508, total_loss: 3.938352108001709
training step: 39509, total_loss: 6.577333927154541
training step: 39510, total_loss: 2.292402744293213
training step: 39511, total_loss: 6.652514457702637
training step: 39512, total_loss: 4.533234596252441
training step: 39513, total_loss: 3.7756080627441406
training step: 39514, total_loss: 2.39646577835083
training step: 39515, total_loss: 4.663867950439453
training step: 39516, total_loss: 4.945572853088379
training step: 39517, total_loss: 4.178956031799316
training step: 39518, total_loss: 4.389698028564453
training step: 39519, total_loss: 5.3562703132629395
training step: 39520, total_loss: 7.2403082847595215
training step: 39521, total_loss: 4.711779594421387
training step: 39522, total_loss: 2.3072290420532227
training step: 39523, total_loss: 3.526358127593994
training step: 39524, total_loss: 2.798872947692871
training step: 39525, total_loss: 2.3088011741638184
training step: 39526, total_loss: 3.8590126037597656
training step: 39527, total_loss: 3.028197765350342
training step: 39528, total_loss: 3.9268527030944824
training step: 39529, total_loss: 5.490505218505859
training step: 39530, total_loss: 5.7898101806640625
training step: 39531, total_loss: 5.523838996887207
training step: 39532, total_loss: 3.437138080596924
training step: 39533, total_loss: 3.9088525772094727
training step: 39534, total_loss: 5.109871864318848
training step: 39535, total_loss: 6.614177703857422
training step: 39536, total_loss: 4.1414995193481445
training step: 39537, total_loss: 4.766713619232178
training step: 39538, total_loss: 4.296082496643066
training step: 39539, total_loss: 4.160024642944336
training step: 39540, total_loss: 3.796555519104004
training step: 39541, total_loss: 5.14462947845459
training step: 39542, total_loss: 5.0468292236328125
training step: 39543, total_loss: 4.95332145690918
training step: 39544, total_loss: 2.8813254833221436
training step: 39545, total_loss: 4.495970249176025
training step: 39546, total_loss: 5.499887466430664
training step: 39547, total_loss: 4.038830757141113
training step: 39548, total_loss: 4.43732213973999
training step: 39549, total_loss: 4.3525004386901855
training step: 39550, total_loss: 3.9703450202941895
training step: 39551, total_loss: 5.16611909866333
training step: 39552, total_loss: 5.28446102142334
training step: 39553, total_loss: 5.61761474609375
training step: 39554, total_loss: 3.841992139816284
training step: 39555, total_loss: 3.8241868019104004
training step: 39556, total_loss: 4.5449066162109375
training step: 39557, total_loss: 4.115487098693848
training step: 39558, total_loss: 5.503605842590332
training step: 39559, total_loss: 5.047881126403809
training step: 39560, total_loss: 4.162667274475098
training step: 39561, total_loss: 4.546968460083008
training step: 39562, total_loss: 6.088501930236816
training step: 39563, total_loss: 6.896976470947266
training step: 39564, total_loss: 3.3360321521759033
training step: 39565, total_loss: 4.859104156494141
training step: 39566, total_loss: 6.431180477142334
training step: 39567, total_loss: 5.221262454986572
training step: 39568, total_loss: 6.717676162719727
training step: 39569, total_loss: 1.0265098810195923
training step: 39570, total_loss: 3.8182647228240967
training step: 39571, total_loss: 5.206881046295166
training step: 39572, total_loss: 0.9286471605300903
training step: 39573, total_loss: 5.444653511047363
training step: 39574, total_loss: 5.034252166748047
training step: 39575, total_loss: 4.351690292358398
training step: 39576, total_loss: 3.4140467643737793
training step: 39577, total_loss: 4.565387725830078
training step: 39578, total_loss: 4.13489294052124
training step: 39579, total_loss: 3.5171117782592773
training step: 39580, total_loss: 5.23897647857666
training step: 39581, total_loss: 3.262482166290283
training step: 39582, total_loss: 5.176949501037598
training step: 39583, total_loss: 4.750760555267334
training step: 39584, total_loss: 4.399200439453125
training step: 39585, total_loss: 4.2107157707214355
training step: 39586, total_loss: 3.0153915882110596
training step: 39587, total_loss: 4.902828216552734
training step: 39588, total_loss: 4.724328994750977
training step: 39589, total_loss: 5.585818290710449
training step: 39590, total_loss: 3.3706674575805664
training step: 39591, total_loss: 4.66854190826416
training step: 39592, total_loss: 5.419958114624023
training step: 39593, total_loss: 4.537012100219727
training step: 39594, total_loss: 6.726078987121582
training step: 39595, total_loss: 4.106414318084717
training step: 39596, total_loss: 4.572925090789795
training step: 39597, total_loss: 3.8627634048461914
training step: 39598, total_loss: 4.442734718322754
training step: 39599, total_loss: 5.089448928833008
training step: 39600, total_loss: 4.0613932609558105
training step: 39601, total_loss: 4.482600688934326
training step: 39602, total_loss: 4.965036392211914
training step: 39603, total_loss: 4.99467658996582
training step: 39604, total_loss: 3.9339959621429443
training step: 39605, total_loss: 2.5215401649475098
training step: 39606, total_loss: 4.62804651260376
training step: 39607, total_loss: 4.162062168121338
training step: 39608, total_loss: 4.817985534667969
training step: 39609, total_loss: 3.14540433883667
training step: 39610, total_loss: 4.298998832702637
training step: 39611, total_loss: 3.023127794265747
training step: 39612, total_loss: 4.868600368499756
training step: 39613, total_loss: 4.746805667877197
training step: 39614, total_loss: 2.4464879035949707
training step: 39615, total_loss: 4.704469680786133
training step: 39616, total_loss: 4.155621528625488
training step: 39617, total_loss: 4.202517509460449
training step: 39618, total_loss: 4.52924919128418
training step: 39619, total_loss: 3.1319103240966797
training step: 39620, total_loss: 2.5558769702911377
training step: 39621, total_loss: 4.92245626449585
training step: 39622, total_loss: 6.094010829925537
training step: 39623, total_loss: 6.076718330383301
training step: 39624, total_loss: 4.947831153869629
training step: 39625, total_loss: 2.73447322845459
training step: 39626, total_loss: 4.6898064613342285
training step: 39627, total_loss: 4.1559672355651855
training step: 39628, total_loss: 4.552628993988037
training step: 39629, total_loss: 4.263467311859131
training step: 39630, total_loss: 5.154600143432617
training step: 39631, total_loss: 3.3024535179138184
training step: 39632, total_loss: 5.697321891784668
training step: 39633, total_loss: 4.530384540557861
training step: 39634, total_loss: 3.6779611110687256
training step: 39635, total_loss: 4.9816508293151855
training step: 39636, total_loss: 4.325690269470215
training step: 39637, total_loss: 6.4351067543029785
training step: 39638, total_loss: 2.8829658031463623
training step: 39639, total_loss: 4.640028953552246
training step: 39640, total_loss: 4.310581684112549
training step: 39641, total_loss: 4.10469388961792
training step: 39642, total_loss: 5.359857559204102
training step: 39643, total_loss: 4.285787582397461
training step: 39644, total_loss: 5.983724594116211
training step: 39645, total_loss: 4.2510881423950195
training step: 39646, total_loss: 4.505386829376221
training step: 39647, total_loss: 4.5367279052734375
training step: 39648, total_loss: 2.7934651374816895
training step: 39649, total_loss: 4.173725128173828
training step: 39650, total_loss: 4.909851551055908
training step: 39651, total_loss: 3.199920177459717
training step: 39652, total_loss: 4.71823263168335
training step: 39653, total_loss: 4.620641708374023
training step: 39654, total_loss: 4.643824577331543
training step: 39655, total_loss: 3.9268667697906494
training step: 39656, total_loss: 3.8420193195343018
training step: 39657, total_loss: 4.4961957931518555
training step: 39658, total_loss: 4.9809722900390625
training step: 39659, total_loss: 4.3409857749938965
training step: 39660, total_loss: 4.611664772033691
training step: 39661, total_loss: 4.711504936218262
training step: 39662, total_loss: 5.240400791168213
training step: 39663, total_loss: 3.556042432785034
training step: 39664, total_loss: 6.067439079284668
training step: 39665, total_loss: 4.9605560302734375
training step: 39666, total_loss: 4.252188682556152
training step: 39667, total_loss: 4.544486045837402
training step: 39668, total_loss: 4.943531036376953
training step: 39669, total_loss: 3.0711445808410645
training step: 39670, total_loss: 5.439780235290527
training step: 39671, total_loss: 4.990317344665527
training step: 39672, total_loss: 4.013906478881836
training step: 39673, total_loss: 5.041086196899414
training step: 39674, total_loss: 4.315864562988281
training step: 39675, total_loss: 5.057628631591797
training step: 39676, total_loss: 5.112177848815918
training step: 39677, total_loss: 5.492432594299316
training step: 39678, total_loss: 4.388425827026367
training step: 39679, total_loss: 5.016914367675781
training step: 39680, total_loss: 4.068620681762695
training step: 39681, total_loss: 5.041875839233398
training step: 39682, total_loss: 4.667511940002441
training step: 39683, total_loss: 4.440387725830078
training step: 39684, total_loss: 5.297492027282715
training step: 39685, total_loss: 3.342268943786621
training step: 39686, total_loss: 4.873266696929932
training step: 39687, total_loss: 8.126487731933594
training step: 39688, total_loss: 5.027210712432861
training step: 39689, total_loss: 3.6431922912597656
training step: 39690, total_loss: 2.606912136077881
training step: 39691, total_loss: 4.755311965942383
training step: 39692, total_loss: 2.4498298168182373
training step: 39693, total_loss: 3.403546094894409
training step: 39694, total_loss: 4.683868885040283
training step: 39695, total_loss: 3.6979851722717285
training step: 39696, total_loss: 3.06868314743042
training step: 39697, total_loss: 4.737372398376465
training step: 39698, total_loss: 2.95676589012146
training step: 39699, total_loss: 4.726436138153076
training step: 39700, total_loss: 3.5897467136383057
training step: 39701, total_loss: 4.019134998321533
training step: 39702, total_loss: 4.534717082977295
training step: 39703, total_loss: 5.172919273376465
training step: 39704, total_loss: 4.739470958709717
training step: 39705, total_loss: 4.283994674682617
training step: 39706, total_loss: 3.927039384841919
training step: 39707, total_loss: 3.7260537147521973
training step: 39708, total_loss: 5.3764519691467285
training step: 39709, total_loss: 4.518023490905762
training step: 39710, total_loss: 3.508471965789795
training step: 39711, total_loss: 6.023215293884277
training step: 39712, total_loss: 3.5563530921936035
training step: 39713, total_loss: 4.6137800216674805
training step: 39714, total_loss: 3.297858476638794
training step: 39715, total_loss: 4.18154764175415
training step: 39716, total_loss: 4.956112384796143
training step: 39717, total_loss: 4.153613090515137
training step: 39718, total_loss: 2.762274742126465
training step: 39719, total_loss: 4.014248847961426
training step: 39720, total_loss: 3.5252976417541504
training step: 39721, total_loss: 4.422213077545166
training step: 39722, total_loss: 5.396595001220703
training step: 39723, total_loss: 3.504641532897949
training step: 39724, total_loss: 3.524915933609009
training step: 39725, total_loss: 3.1466991901397705
training step: 39726, total_loss: 3.1226935386657715
training step: 39727, total_loss: 4.591494083404541
training step: 39728, total_loss: 3.5981228351593018
training step: 39729, total_loss: 4.476904392242432
training step: 39730, total_loss: 4.398344993591309
training step: 39731, total_loss: 5.455232620239258
training step: 39732, total_loss: 4.25333833694458
training step: 39733, total_loss: 5.4251861572265625
training step: 39734, total_loss: 2.943326950073242
training step: 39735, total_loss: 3.7544965744018555
training step: 39736, total_loss: 5.867447853088379
training step: 39737, total_loss: 3.628556728363037
training step: 39738, total_loss: 3.694223403930664
training step: 39739, total_loss: 4.2040581703186035
training step: 39740, total_loss: 4.27443265914917
training step: 39741, total_loss: 2.504378080368042
training step: 39742, total_loss: 4.072802543640137
training step: 39743, total_loss: 7.121551036834717
training step: 39744, total_loss: 3.5914435386657715
training step: 39745, total_loss: 5.911284923553467
training step: 39746, total_loss: 4.782650947570801
training step: 39747, total_loss: 4.727215766906738
training step: 39748, total_loss: 1.263455867767334
training step: 39749, total_loss: 2.4537785053253174
training step: 39750, total_loss: 5.3102922439575195
training step: 39751, total_loss: 4.2768330574035645
training step: 39752, total_loss: 4.5014448165893555
training step: 39753, total_loss: 5.1941423416137695
training step: 39754, total_loss: 6.056510925292969
training step: 39755, total_loss: 5.9478864669799805
training step: 39756, total_loss: 2.3360581398010254
training step: 39757, total_loss: 5.378696441650391
training step: 39758, total_loss: 5.015411853790283
training step: 39759, total_loss: 3.507152795791626
training step: 39760, total_loss: 4.475343227386475
training step: 39761, total_loss: 3.732931137084961
training step: 39762, total_loss: 5.26447868347168
training step: 39763, total_loss: 4.685771942138672
training step: 39764, total_loss: 4.79746675491333
training step: 39765, total_loss: 3.5603740215301514
training step: 39766, total_loss: 4.430747032165527
training step: 39767, total_loss: 5.666826248168945
training step: 39768, total_loss: 2.989060401916504
training step: 39769, total_loss: 2.0742714405059814
training step: 39770, total_loss: 4.928381443023682
training step: 39771, total_loss: 4.785761833190918
training step: 39772, total_loss: 5.229723930358887
training step: 39773, total_loss: 3.0050230026245117
training step: 39774, total_loss: 7.5057220458984375
training step: 39775, total_loss: 5.899853706359863
training step: 39776, total_loss: 2.467639446258545
training step: 39777, total_loss: 4.667880535125732
training step: 39778, total_loss: 4.061740398406982
training step: 39779, total_loss: 3.9765677452087402
training step: 39780, total_loss: 2.6131293773651123
training step: 39781, total_loss: 3.231943368911743
training step: 39782, total_loss: 4.118135452270508
training step: 39783, total_loss: 5.022818565368652
training step: 39784, total_loss: 6.06274938583374
training step: 39785, total_loss: 4.024644374847412
training step: 39786, total_loss: 3.6388845443725586
training step: 39787, total_loss: 3.761268377304077
training step: 39788, total_loss: 3.4115805625915527
training step: 39789, total_loss: 4.534670829772949
training step: 39790, total_loss: 4.687017917633057
training step: 39791, total_loss: 3.0016117095947266
training step: 39792, total_loss: 4.587825775146484
training step: 39793, total_loss: 3.9958276748657227
training step: 39794, total_loss: 3.316997766494751
training step: 39795, total_loss: 0.8370130062103271
training step: 39796, total_loss: 0.9496703147888184
training step: 39797, total_loss: 4.452882289886475
training step: 39798, total_loss: 3.927165985107422
training step: 39799, total_loss: 4.883588790893555
training step: 39800, total_loss: 3.8562488555908203
training step: 39801, total_loss: 4.611867904663086
training step: 39802, total_loss: 4.486530303955078
training step: 39803, total_loss: 3.1221108436584473
training step: 39804, total_loss: 4.991565227508545
training step: 39805, total_loss: 4.834639072418213
training step: 39806, total_loss: 0.6646729111671448
training step: 39807, total_loss: 3.918548822402954
training step: 39808, total_loss: 5.3346710205078125
training step: 39809, total_loss: 3.008619785308838
training step: 39810, total_loss: 4.236729621887207
training step: 39811, total_loss: 6.413575649261475
training step: 39812, total_loss: 3.8904361724853516
training step: 39813, total_loss: 3.9404165744781494
training step: 39814, total_loss: 3.205732822418213
training step: 39815, total_loss: 5.525696754455566
training step: 39816, total_loss: 3.4077208042144775
training step: 39817, total_loss: 4.548067092895508
training step: 39818, total_loss: 2.7742128372192383
training step: 39819, total_loss: 3.336146831512451
training step: 39820, total_loss: 4.467649936676025
training step: 39821, total_loss: 4.4339985847473145
training step: 39822, total_loss: 4.8732099533081055
training step: 39823, total_loss: 5.225273132324219
training step: 39824, total_loss: 4.057518005371094
training step: 39825, total_loss: 2.773989677429199
training step: 39826, total_loss: 3.5210585594177246
training step: 39827, total_loss: 4.329510688781738
training step: 39828, total_loss: 5.555509567260742
training step: 39829, total_loss: 6.177980422973633
training step: 39830, total_loss: 5.055335998535156
training step: 39831, total_loss: 4.176633834838867
training step: 39832, total_loss: 4.2958269119262695
training step: 39833, total_loss: 1.8691763877868652
training step: 39834, total_loss: 4.172144889831543
training step: 39835, total_loss: 4.57630729675293
training step: 39836, total_loss: 4.6319732666015625
training step: 39837, total_loss: 5.554233551025391
training step: 39838, total_loss: 4.322106838226318
training step: 39839, total_loss: 6.515452861785889
training step: 39840, total_loss: 4.189244747161865
training step: 39841, total_loss: 3.4642841815948486
training step: 39842, total_loss: 0.6453987956047058
training step: 39843, total_loss: 4.2604169845581055
training step: 39844, total_loss: 2.716524124145508
training step: 39845, total_loss: 5.094215393066406
training step: 39846, total_loss: 0.6858522891998291
training step: 39847, total_loss: 4.435832977294922
training step: 39848, total_loss: 5.066375255584717
training step: 39849, total_loss: 4.476907730102539
training step: 39850, total_loss: 0.7357732057571411
training step: 39851, total_loss: 4.388783931732178
training step: 39852, total_loss: 4.775886535644531
training step: 39853, total_loss: 5.415561676025391
training step: 39854, total_loss: 3.557323694229126
training step: 39855, total_loss: 4.6065263748168945
training step: 39856, total_loss: 6.616183757781982
training step: 39857, total_loss: 5.003434181213379
training step: 39858, total_loss: 4.808826923370361
training step: 39859, total_loss: 7.538239479064941
training step: 39860, total_loss: 6.208510398864746
training step: 39861, total_loss: 3.6879446506500244
training step: 39862, total_loss: 5.074060440063477
training step: 39863, total_loss: 4.377434730529785
training step: 39864, total_loss: 5.463403701782227
training step: 39865, total_loss: 1.7582440376281738
training step: 39866, total_loss: 6.590498924255371
training step: 39867, total_loss: 4.3913726806640625
training step: 39868, total_loss: 3.577889919281006
training step: 39869, total_loss: 5.060158729553223
training step: 39870, total_loss: 5.954654693603516
training step: 39871, total_loss: 5.790408134460449
training step: 39872, total_loss: 3.4916205406188965
training step: 39873, total_loss: 3.598754405975342
training step: 39874, total_loss: 4.277353763580322
training step: 39875, total_loss: 3.990189552307129
training step: 39876, total_loss: 6.683249473571777
training step: 39877, total_loss: 3.7938199043273926
training step: 39878, total_loss: 4.67289924621582
training step: 39879, total_loss: 4.3625030517578125
training step: 39880, total_loss: 4.42783784866333
training step: 39881, total_loss: 4.2121686935424805
training step: 39882, total_loss: 4.469609260559082
training step: 39883, total_loss: 3.4363341331481934
training step: 39884, total_loss: 2.029585361480713
training step: 39885, total_loss: 5.008216857910156
training step: 39886, total_loss: 3.4879441261291504
training step: 39887, total_loss: 3.4282617568969727
training step: 39888, total_loss: 4.005457878112793
training step: 39889, total_loss: 6.116269111633301
training step: 39890, total_loss: 4.290896415710449
training step: 39891, total_loss: 3.183979034423828
training step: 39892, total_loss: 5.274641990661621
training step: 39893, total_loss: 4.8375959396362305
training step: 39894, total_loss: 5.850108623504639
training step: 39895, total_loss: 6.366211891174316
training step: 39896, total_loss: 5.427859306335449
training step: 39897, total_loss: 6.4666547775268555
training step: 39898, total_loss: 4.4129319190979
training step: 39899, total_loss: 4.964702129364014
training step: 39900, total_loss: 3.7524120807647705
training step: 39901, total_loss: 2.923813819885254
training step: 39902, total_loss: 4.404927730560303
training step: 39903, total_loss: 4.065342426300049
training step: 39904, total_loss: 5.019505500793457
training step: 39905, total_loss: 5.421627998352051
training step: 39906, total_loss: 4.860186576843262
training step: 39907, total_loss: 4.122716903686523
training step: 39908, total_loss: 4.575376987457275
training step: 39909, total_loss: 4.401721000671387
training step: 39910, total_loss: 2.5515074729919434
training step: 39911, total_loss: 4.465519428253174
training step: 39912, total_loss: 4.485166549682617
training step: 39913, total_loss: 3.323227643966675
training step: 39914, total_loss: 4.067503929138184
training step: 39915, total_loss: 4.892426490783691
training step: 39916, total_loss: 1.9117971658706665
training step: 39917, total_loss: 5.374600410461426
training step: 39918, total_loss: 4.958930015563965
training step: 39919, total_loss: 6.247621536254883
training step: 39920, total_loss: 4.963120937347412
training step: 39921, total_loss: 4.272378921508789
training step: 39922, total_loss: 6.6242475509643555
training step: 39923, total_loss: 4.319416046142578
training step: 39924, total_loss: 4.087976455688477
training step: 39925, total_loss: 3.8524675369262695
training step: 39926, total_loss: 2.6308858394622803
training step: 39927, total_loss: 5.20753812789917
training step: 39928, total_loss: 3.288130760192871
training step: 39929, total_loss: 3.9382431507110596
training step: 39930, total_loss: 4.38631010055542
training step: 39931, total_loss: 4.886566162109375
training step: 39932, total_loss: 3.7801125049591064
training step: 39933, total_loss: 5.874843597412109
training step: 39934, total_loss: 5.078532695770264
training step: 39935, total_loss: 4.1018242835998535
training step: 39936, total_loss: 4.378854751586914
training step: 39937, total_loss: 1.4372508525848389
training step: 39938, total_loss: 4.503635406494141
training step: 39939, total_loss: 3.1275384426116943
training step: 39940, total_loss: 4.78453254699707
training step: 39941, total_loss: 4.104290008544922
training step: 39942, total_loss: 4.197490215301514
training step: 39943, total_loss: 6.131659030914307
training step: 39944, total_loss: 5.196338653564453
training step: 39945, total_loss: 3.834683895111084
training step: 39946, total_loss: 4.982623100280762
training step: 39947, total_loss: 3.3229894638061523
training step: 39948, total_loss: 3.7876079082489014
training step: 39949, total_loss: 4.265810966491699
training step: 39950, total_loss: 4.356538772583008
training step: 39951, total_loss: 5.912041664123535
training step: 39952, total_loss: 3.7877025604248047
training step: 39953, total_loss: 5.459536552429199
training step: 39954, total_loss: 4.453486442565918
training step: 39955, total_loss: 4.399875640869141
training step: 39956, total_loss: 5.257671356201172
training step: 39957, total_loss: 4.085792064666748
training step: 39958, total_loss: 3.3648452758789062
training step: 39959, total_loss: 5.4121012687683105
training step: 39960, total_loss: 5.14849853515625
training step: 39961, total_loss: 5.413393974304199
training step: 39962, total_loss: 4.809634685516357
training step: 39963, total_loss: 3.06303071975708
training step: 39964, total_loss: 5.473649978637695
training step: 39965, total_loss: 5.041445732116699
training step: 39966, total_loss: 4.693986892700195
training step: 39967, total_loss: 4.189017295837402
training step: 39968, total_loss: 4.3812575340271
training step: 39969, total_loss: 5.686156272888184
training step: 39970, total_loss: 5.267821311950684
training step: 39971, total_loss: 4.0012335777282715
training step: 39972, total_loss: 2.927753448486328
training step: 39973, total_loss: 4.930079460144043
training step: 39974, total_loss: 4.3861894607543945
training step: 39975, total_loss: 4.350714683532715
training step: 39976, total_loss: 5.178051471710205
training step: 39977, total_loss: 2.9467177391052246
training step: 39978, total_loss: 5.724115371704102
training step: 39979, total_loss: 6.181138038635254
training step: 39980, total_loss: 5.413199424743652
training step: 39981, total_loss: 5.582586288452148
training step: 39982, total_loss: 5.661039352416992
training step: 39983, total_loss: 5.980469703674316
training step: 39984, total_loss: 5.900136947631836
training step: 39985, total_loss: 6.115598678588867
training step: 39986, total_loss: 4.444511413574219
training step: 39987, total_loss: 4.181456565856934
training step: 39988, total_loss: 4.275230407714844
training step: 39989, total_loss: 4.441917419433594
training step: 39990, total_loss: 4.232696056365967
training step: 39991, total_loss: 0.9290751218795776
training step: 39992, total_loss: 4.640326023101807
training step: 39993, total_loss: 3.251600980758667
training step: 39994, total_loss: 4.824448585510254
training step: 39995, total_loss: 4.168765068054199
training step: 39996, total_loss: 3.5527939796447754
training step: 39997, total_loss: 4.588170051574707
training step: 39998, total_loss: 4.350302219390869
training step: 39999, total_loss: 4.819431304931641
training step: 40000, total_loss: 5.623776435852051
training step: 40001, total_loss: 3.9654762744903564
training step: 40002, total_loss: 2.569493055343628
training step: 40003, total_loss: 3.937333583831787
training step: 40004, total_loss: 1.4184163808822632
training step: 40005, total_loss: 3.8916268348693848
training step: 40006, total_loss: 4.615720748901367
training step: 40007, total_loss: 5.555488586425781
training step: 40008, total_loss: 4.495987415313721
training step: 40009, total_loss: 3.4201130867004395
training step: 40010, total_loss: 4.914068698883057
training step: 40011, total_loss: 4.5380144119262695
training step: 40012, total_loss: 4.188418388366699
training step: 40013, total_loss: 5.777229309082031
training step: 40014, total_loss: 3.2829606533050537
training step: 40015, total_loss: 4.813077449798584
training step: 40016, total_loss: 4.295315265655518
training step: 40017, total_loss: 4.311087131500244
training step: 40018, total_loss: 4.84083366394043
training step: 40019, total_loss: 4.809238433837891
training step: 40020, total_loss: 5.187013626098633
training step: 40021, total_loss: 4.268842697143555
training step: 40022, total_loss: 5.635857582092285
training step: 40023, total_loss: 5.665019989013672
training step: 40024, total_loss: 5.505653381347656
training step: 40025, total_loss: 3.8100483417510986
training step: 40026, total_loss: 4.820749759674072
training step: 40027, total_loss: 3.7163195610046387
training step: 40028, total_loss: 5.109471321105957
training step: 40029, total_loss: 4.380924224853516
training step: 40030, total_loss: 5.508686542510986
training step: 40031, total_loss: 4.587307929992676
training step: 40032, total_loss: 4.67734956741333
training step: 40033, total_loss: 5.092215061187744
training step: 40034, total_loss: 2.3803482055664062
training step: 40035, total_loss: 5.201534271240234
training step: 40036, total_loss: 3.5726165771484375
training step: 40037, total_loss: 2.733553409576416
training step: 40038, total_loss: 4.622369289398193
training step: 40039, total_loss: 5.714963912963867
training step: 40040, total_loss: 4.854475975036621
training step: 40041, total_loss: 4.342710018157959
training step: 40042, total_loss: 4.042778968811035
training step: 40043, total_loss: 3.8780131340026855
training step: 40044, total_loss: 4.441910743713379
training step: 40045, total_loss: 4.1856889724731445
training step: 40046, total_loss: 6.4759931564331055
training step: 40047, total_loss: 3.423013210296631
training step: 40048, total_loss: 2.523678779602051
training step: 40049, total_loss: 4.045108795166016
training step: 40050, total_loss: 4.6292619705200195
training step: 40051, total_loss: 4.903755187988281
training step: 40052, total_loss: 4.495847702026367
training step: 40053, total_loss: 4.800689697265625
training step: 40054, total_loss: 6.659604072570801
training step: 40055, total_loss: 5.902926445007324
training step: 40056, total_loss: 6.634880542755127
training step: 40057, total_loss: 5.4818267822265625
training step: 40058, total_loss: 5.066433906555176
training step: 40059, total_loss: 4.478204727172852
training step: 40060, total_loss: 4.718597412109375
training step: 40061, total_loss: 4.1133131980896
training step: 40062, total_loss: 3.2725839614868164
training step: 40063, total_loss: 4.140694618225098
training step: 40064, total_loss: 5.569265365600586
training step: 40065, total_loss: 5.783911228179932
training step: 40066, total_loss: 3.8525102138519287
training step: 40067, total_loss: 5.16317081451416
training step: 40068, total_loss: 4.1377787590026855
training step: 40069, total_loss: 2.854625701904297
training step: 40070, total_loss: 5.029537200927734
training step: 40071, total_loss: 4.855464935302734
training step: 40072, total_loss: 4.74091911315918
training step: 40073, total_loss: 4.390510559082031
training step: 40074, total_loss: 5.037341117858887
training step: 40075, total_loss: 4.558185577392578
training step: 40076, total_loss: 4.1168622970581055
training step: 40077, total_loss: 3.9447689056396484
training step: 40078, total_loss: 2.742584228515625
training step: 40079, total_loss: 4.8992767333984375
training step: 40080, total_loss: 5.117377281188965
training step: 40081, total_loss: 3.7171473503112793
training step: 40082, total_loss: 5.2573137283325195
training step: 40083, total_loss: 4.906663417816162
training step: 40084, total_loss: 4.339511871337891
training step: 40085, total_loss: 5.760124206542969
training step: 40086, total_loss: 4.711421012878418
training step: 40087, total_loss: 4.3005499839782715
training step: 40088, total_loss: 4.257049560546875
training step: 40089, total_loss: 4.6371026039123535
training step: 40090, total_loss: 4.977487564086914
training step: 40091, total_loss: 4.932678699493408
training step: 40092, total_loss: 3.2057342529296875
training step: 40093, total_loss: 4.615732192993164
training step: 40094, total_loss: 4.811478614807129
training step: 40095, total_loss: 4.401462554931641
training step: 40096, total_loss: 5.741257667541504
training step: 40097, total_loss: 3.522209644317627
training step: 40098, total_loss: 1.4065468311309814
training step: 40099, total_loss: 4.917101860046387
training step: 40100, total_loss: 3.790196657180786
training step: 40101, total_loss: 1.1599292755126953
training step: 40102, total_loss: 5.127191543579102
training step: 40103, total_loss: 4.574207305908203
training step: 40104, total_loss: 1.0890520811080933
training step: 40105, total_loss: 4.587981224060059
training step: 40106, total_loss: 5.059177398681641
training step: 40107, total_loss: 3.8488125801086426
training step: 40108, total_loss: 2.4861693382263184
training step: 40109, total_loss: 2.3065176010131836
training step: 40110, total_loss: 3.7487993240356445
training step: 40111, total_loss: 4.898352146148682
training step: 40112, total_loss: 3.982921600341797
training step: 40113, total_loss: 4.58376932144165
training step: 40114, total_loss: 3.9850120544433594
training step: 40115, total_loss: 2.9385557174682617
training step: 40116, total_loss: 3.8254427909851074
training step: 40117, total_loss: 5.054047107696533
training step: 40118, total_loss: 4.54502534866333
training step: 40119, total_loss: 4.961708068847656
training step: 40120, total_loss: 4.653903007507324
training step: 40121, total_loss: 4.214527606964111
training step: 40122, total_loss: 1.1423003673553467
training step: 40123, total_loss: 4.023580551147461
training step: 40124, total_loss: 4.702216625213623
training step: 40125, total_loss: 2.799389600753784
training step: 40126, total_loss: 0.9113767147064209
training step: 40127, total_loss: 4.708664417266846
training step: 40128, total_loss: 5.027243137359619
training step: 40129, total_loss: 4.39223575592041
training step: 40130, total_loss: 4.696753025054932
training step: 40131, total_loss: 3.905975341796875
training step: 40132, total_loss: 2.850811004638672
training step: 40133, total_loss: 4.697121620178223
training step: 40134, total_loss: 4.7022833824157715
training step: 40135, total_loss: 3.609595775604248
training step: 40136, total_loss: 4.233205318450928
training step: 40137, total_loss: 4.573447227478027
training step: 40138, total_loss: 4.089437007904053
training step: 40139, total_loss: 3.713190793991089
training step: 40140, total_loss: 3.701707363128662
training step: 40141, total_loss: 1.6459203958511353
training step: 40142, total_loss: 5.0554986000061035
training step: 40143, total_loss: 4.245900630950928
training step: 40144, total_loss: 4.291329383850098
training step: 40145, total_loss: 4.523161888122559
training step: 40146, total_loss: 5.192910194396973
training step: 40147, total_loss: 2.528533935546875
training step: 40148, total_loss: 3.305424213409424
training step: 40149, total_loss: 2.7901992797851562
training step: 40150, total_loss: 6.835344314575195
training step: 40151, total_loss: 2.956193447113037
training step: 40152, total_loss: 0.9951756000518799
training step: 40153, total_loss: 3.5530238151550293
training step: 40154, total_loss: 3.987185001373291
training step: 40155, total_loss: 5.300257682800293
training step: 40156, total_loss: 2.661179780960083
training step: 40157, total_loss: 2.8366799354553223
training step: 40158, total_loss: 5.308208465576172
training step: 40159, total_loss: 4.338988304138184
training step: 40160, total_loss: 5.519600868225098
training step: 40161, total_loss: 0.7136631011962891
training step: 40162, total_loss: 4.439110279083252
training step: 40163, total_loss: 4.5254011154174805
training step: 40164, total_loss: 4.467942237854004
training step: 40165, total_loss: 4.429318904876709
training step: 40166, total_loss: 5.430288314819336
training step: 40167, total_loss: 5.327681541442871
training step: 40168, total_loss: 5.134423732757568
training step: 40169, total_loss: 4.547423362731934
training step: 40170, total_loss: 5.500865936279297
training step: 40171, total_loss: 4.994200229644775
training step: 40172, total_loss: 5.330190181732178
training step: 40173, total_loss: 4.189610481262207
training step: 40174, total_loss: 4.013099193572998
training step: 40175, total_loss: 6.23707389831543
training step: 40176, total_loss: 4.99658203125
training step: 40177, total_loss: 3.386996269226074
training step: 40178, total_loss: 3.8868179321289062
training step: 40179, total_loss: 5.747528076171875
training step: 40180, total_loss: 3.9966859817504883
training step: 40181, total_loss: 4.913431167602539
training step: 40182, total_loss: 3.6407504081726074
training step: 40183, total_loss: 4.506138324737549
training step: 40184, total_loss: 4.485033988952637
training step: 40185, total_loss: 3.093014717102051
training step: 40186, total_loss: 4.417904853820801
training step: 40187, total_loss: 4.007502555847168
training step: 40188, total_loss: 4.8675737380981445
training step: 40189, total_loss: 5.465715408325195
training step: 40190, total_loss: 5.239651203155518
training step: 40191, total_loss: 3.2911763191223145
training step: 40192, total_loss: 5.001007080078125
training step: 40193, total_loss: 3.3632731437683105
training step: 40194, total_loss: 4.47901725769043
training step: 40195, total_loss: 4.66969108581543
training step: 40196, total_loss: 6.530424118041992
training step: 40197, total_loss: 3.8643388748168945
training step: 40198, total_loss: 4.227194309234619
training step: 40199, total_loss: 2.8741507530212402
training step: 40200, total_loss: 5.189715385437012
training step: 40201, total_loss: 3.816500663757324
training step: 40202, total_loss: 4.37235164642334
training step: 40203, total_loss: 3.7184228897094727
training step: 40204, total_loss: 5.028214454650879
training step: 40205, total_loss: 3.0034239292144775
training step: 40206, total_loss: 4.439537048339844
training step: 40207, total_loss: 3.8292689323425293
training step: 40208, total_loss: 4.122188568115234
training step: 40209, total_loss: 4.292420387268066
training step: 40210, total_loss: 5.765230178833008
training step: 40211, total_loss: 4.23269510269165
training step: 40212, total_loss: 5.206243515014648
training step: 40213, total_loss: 4.080373287200928
training step: 40214, total_loss: 3.8941097259521484
training step: 40215, total_loss: 3.839240550994873
training step: 40216, total_loss: 3.983157157897949
training step: 40217, total_loss: 3.8675217628479004
training step: 40218, total_loss: 4.796226501464844
training step: 40219, total_loss: 5.274598121643066
training step: 40220, total_loss: 4.543036937713623
training step: 40221, total_loss: 5.086701393127441
training step: 40222, total_loss: 5.0831756591796875
training step: 40223, total_loss: 6.003476142883301
training step: 40224, total_loss: 4.74251651763916
training step: 40225, total_loss: 4.8665313720703125
training step: 40226, total_loss: 2.8637900352478027
training step: 40227, total_loss: 5.022989273071289
training step: 40228, total_loss: 5.210793495178223
training step: 40229, total_loss: 4.2688775062561035
training step: 40230, total_loss: 4.329090595245361
training step: 40231, total_loss: 5.971229553222656
training step: 40232, total_loss: 4.437767505645752
training step: 40233, total_loss: 4.001375198364258
training step: 40234, total_loss: 3.848896026611328
training step: 40235, total_loss: 3.302152633666992
training step: 40236, total_loss: 4.969119071960449
training step: 40237, total_loss: 3.6846604347229004
training step: 40238, total_loss: 4.366275310516357
training step: 40239, total_loss: 4.734674453735352
training step: 40240, total_loss: 1.8570477962493896
training step: 40241, total_loss: 3.681211471557617
training step: 40242, total_loss: 2.486356496810913
training step: 40243, total_loss: 4.553138256072998
training step: 40244, total_loss: 4.47133731842041
training step: 40245, total_loss: 4.289945602416992
training step: 40246, total_loss: 4.005171298980713
training step: 40247, total_loss: 3.7628159523010254
training step: 40248, total_loss: 3.0192975997924805
training step: 40249, total_loss: 4.487133979797363
training step: 40250, total_loss: 2.651366710662842
training step: 40251, total_loss: 4.781160354614258
training step: 40252, total_loss: 6.411096572875977
training step: 40253, total_loss: 1.00605309009552
training step: 40254, total_loss: 3.7912509441375732
training step: 40255, total_loss: 4.36265230178833
training step: 40256, total_loss: 4.395727157592773
training step: 40257, total_loss: 3.393460273742676
training step: 40258, total_loss: 4.754037857055664
training step: 40259, total_loss: 6.015961170196533
training step: 40260, total_loss: 4.739261627197266
training step: 40261, total_loss: 4.187976837158203
training step: 40262, total_loss: 5.437589645385742
training step: 40263, total_loss: 4.078723430633545
training step: 40264, total_loss: 2.9487085342407227
training step: 40265, total_loss: 3.3477895259857178
training step: 40266, total_loss: 3.9077577590942383
training step: 40267, total_loss: 3.904240369796753
training step: 40268, total_loss: 6.970457077026367
training step: 40269, total_loss: 4.900038242340088
training step: 40270, total_loss: 4.334488868713379
training step: 40271, total_loss: 4.2549543380737305
training step: 40272, total_loss: 4.934441566467285
training step: 40273, total_loss: 2.2148773670196533
training step: 40274, total_loss: 3.7509217262268066
training step: 40275, total_loss: 5.658403396606445
training step: 40276, total_loss: 3.7592549324035645
training step: 40277, total_loss: 3.8255157470703125
training step: 40278, total_loss: 3.6443381309509277
training step: 40279, total_loss: 3.8364973068237305
training step: 40280, total_loss: 1.6350934505462646
training step: 40281, total_loss: 5.366981506347656
training step: 40282, total_loss: 4.199276924133301
training step: 40283, total_loss: 3.765496015548706
training step: 40284, total_loss: 3.555047035217285
training step: 40285, total_loss: 3.504429340362549
training step: 40286, total_loss: 6.32480001449585
training step: 40287, total_loss: 6.365596771240234
training step: 40288, total_loss: 6.592514514923096
training step: 40289, total_loss: 4.195802688598633
training step: 40290, total_loss: 5.878162860870361
training step: 40291, total_loss: 4.874179363250732
training step: 40292, total_loss: 4.0430588722229
training step: 40293, total_loss: 2.767911911010742
training step: 40294, total_loss: 5.1429948806762695
training step: 40295, total_loss: 4.7729949951171875
training step: 40296, total_loss: 4.677197456359863
training step: 40297, total_loss: 4.892385482788086
training step: 40298, total_loss: 3.285060405731201
training step: 40299, total_loss: 4.586233139038086
training step: 40300, total_loss: 4.029705047607422
training step: 40301, total_loss: 3.849067449569702
training step: 40302, total_loss: 3.755169630050659
training step: 40303, total_loss: 4.311734199523926
training step: 40304, total_loss: 4.46668004989624
training step: 40305, total_loss: 2.835496664047241
training step: 40306, total_loss: 4.351971626281738
training step: 40307, total_loss: 1.5968714952468872
training step: 40308, total_loss: 5.4618024826049805
training step: 40309, total_loss: 4.537112712860107
training step: 40310, total_loss: 5.054232120513916
training step: 40311, total_loss: 3.3665361404418945
training step: 40312, total_loss: 3.3846089839935303
training step: 40313, total_loss: 2.7852704524993896
training step: 40314, total_loss: 4.9803266525268555
training step: 40315, total_loss: 4.255540370941162
training step: 40316, total_loss: 5.676837921142578
training step: 40317, total_loss: 5.771152019500732
training step: 40318, total_loss: 5.784765243530273
training step: 40319, total_loss: 3.9166781902313232
training step: 40320, total_loss: 5.787716865539551
training step: 40321, total_loss: 3.230553150177002
training step: 40322, total_loss: 3.992893695831299
training step: 40323, total_loss: 4.240060806274414
training step: 40324, total_loss: 4.578533172607422
training step: 40325, total_loss: 5.367581367492676
training step: 40326, total_loss: 4.689883232116699
training step: 40327, total_loss: 4.541636943817139
training step: 40328, total_loss: 5.70970344543457
training step: 40329, total_loss: 5.266434669494629
training step: 40330, total_loss: 4.1702189445495605
training step: 40331, total_loss: 3.9527273178100586
training step: 40332, total_loss: 2.6540417671203613
training step: 40333, total_loss: 5.762331008911133
training step: 40334, total_loss: 2.3704590797424316
training step: 40335, total_loss: 3.5988309383392334
training step: 40336, total_loss: 5.480546951293945
training step: 40337, total_loss: 4.1934003829956055
training step: 40338, total_loss: 4.889457702636719
training step: 40339, total_loss: 4.411418437957764
training step: 40340, total_loss: 4.320324897766113
training step: 40341, total_loss: 4.755331993103027
training step: 40342, total_loss: 5.679544448852539
training step: 40343, total_loss: 3.711866617202759
training step: 40344, total_loss: 5.847500324249268
training step: 40345, total_loss: 4.943571090698242
training step: 40346, total_loss: 5.383516788482666
training step: 40347, total_loss: 4.73253059387207
training step: 40348, total_loss: 5.0321736335754395
training step: 40349, total_loss: 5.104959011077881
training step: 40350, total_loss: 3.9340739250183105
training step: 40351, total_loss: 5.078972339630127
training step: 40352, total_loss: 5.355299949645996
training step: 40353, total_loss: 4.385502815246582
training step: 40354, total_loss: 4.823147773742676
training step: 40355, total_loss: 4.936645030975342
training step: 40356, total_loss: 4.083400249481201
training step: 40357, total_loss: 3.207211971282959
training step: 40358, total_loss: 4.531739234924316
training step: 40359, total_loss: 5.51431941986084
training step: 40360, total_loss: 4.9027252197265625
training step: 40361, total_loss: 4.866966247558594
training step: 40362, total_loss: 3.4875693321228027
training step: 40363, total_loss: 4.936425685882568
training step: 40364, total_loss: 4.078817844390869
training step: 40365, total_loss: 5.114352226257324
training step: 40366, total_loss: 4.67260217666626
training step: 40367, total_loss: 4.435230255126953
training step: 40368, total_loss: 4.744149208068848
training step: 40369, total_loss: 5.591123580932617
training step: 40370, total_loss: 4.181229591369629
training step: 40371, total_loss: 4.216377258300781
training step: 40372, total_loss: 3.661672592163086
training step: 40373, total_loss: 3.890714645385742
training step: 40374, total_loss: 4.486239433288574
training step: 40375, total_loss: 4.6353302001953125
training step: 40376, total_loss: 4.196513652801514
training step: 40377, total_loss: 3.5279812812805176
training step: 40378, total_loss: 5.029439449310303
training step: 40379, total_loss: 4.4620256423950195
training step: 40380, total_loss: 2.344020366668701
training step: 40381, total_loss: 3.711848735809326
training step: 40382, total_loss: 3.6293115615844727
training step: 40383, total_loss: 4.297640800476074
training step: 40384, total_loss: 6.3881683349609375
training step: 40385, total_loss: 4.494663238525391
training step: 40386, total_loss: 4.844995498657227
training step: 40387, total_loss: 4.570850372314453
training step: 40388, total_loss: 3.163834810256958
training step: 40389, total_loss: 4.209207534790039
training step: 40390, total_loss: 3.4513649940490723
training step: 40391, total_loss: 7.3382344245910645
training step: 40392, total_loss: 5.235297679901123
training step: 40393, total_loss: 4.023619651794434
training step: 40394, total_loss: 5.353643894195557
training step: 40395, total_loss: 4.06198263168335
training step: 40396, total_loss: 4.018270492553711
training step: 40397, total_loss: 5.9267072677612305
training step: 40398, total_loss: 4.943830490112305
training step: 40399, total_loss: 1.572596549987793
training step: 40400, total_loss: 5.3753862380981445
training step: 40401, total_loss: 4.1771063804626465
training step: 40402, total_loss: 4.811101913452148
training step: 40403, total_loss: 4.951751708984375
training step: 40404, total_loss: 3.2179226875305176
training step: 40405, total_loss: 4.845795631408691
training step: 40406, total_loss: 5.690560340881348
training step: 40407, total_loss: 4.867475509643555
training step: 40408, total_loss: 3.979630470275879
training step: 40409, total_loss: 2.197384834289551
training step: 40410, total_loss: 4.32436466217041
training step: 40411, total_loss: 2.816737651824951
training step: 40412, total_loss: 5.268795490264893
training step: 40413, total_loss: 5.397871017456055
training step: 40414, total_loss: 4.911966800689697
training step: 40415, total_loss: 4.211998462677002
training step: 40416, total_loss: 5.030366897583008
training step: 40417, total_loss: 3.8841605186462402
training step: 40418, total_loss: 4.374009609222412
training step: 40419, total_loss: 5.204647541046143
training step: 40420, total_loss: 4.535967826843262
training step: 40421, total_loss: 4.701168060302734
training step: 40422, total_loss: 3.75639009475708
training step: 40423, total_loss: 4.185896873474121
training step: 40424, total_loss: 4.32075834274292
training step: 40425, total_loss: 5.210759162902832
training step: 40426, total_loss: 4.034305572509766
training step: 40427, total_loss: 2.5264968872070312
training step: 40428, total_loss: 3.942819833755493
training step: 40429, total_loss: 5.476264476776123
training step: 40430, total_loss: 4.004744529724121
training step: 40431, total_loss: 4.404937744140625
training step: 40432, total_loss: 5.315572261810303
training step: 40433, total_loss: 4.398993015289307
training step: 40434, total_loss: 5.04618501663208
training step: 40435, total_loss: 4.576706886291504
training step: 40436, total_loss: 4.684562683105469
training step: 40437, total_loss: 5.60664701461792
training step: 40438, total_loss: 4.0996551513671875
training step: 40439, total_loss: 3.848145008087158
training step: 40440, total_loss: 4.790152072906494
training step: 40441, total_loss: 2.8025200366973877
training step: 40442, total_loss: 4.3921918869018555
training step: 40443, total_loss: 3.8700456619262695
training step: 40444, total_loss: 5.017189025878906
training step: 40445, total_loss: 4.083870887756348
training step: 40446, total_loss: 6.1364593505859375
training step: 40447, total_loss: 3.9233005046844482
training step: 40448, total_loss: 3.7093234062194824
training step: 40449, total_loss: 2.764582872390747
training step: 40450, total_loss: 3.966048240661621
training step: 40451, total_loss: 5.251359939575195
training step: 40452, total_loss: 4.6117143630981445
training step: 40453, total_loss: 3.4425580501556396
training step: 40454, total_loss: 4.637070178985596
training step: 40455, total_loss: 5.626514434814453
training step: 40456, total_loss: 5.3950910568237305
training step: 40457, total_loss: 3.1990599632263184
training step: 40458, total_loss: 4.172774314880371
training step: 40459, total_loss: 3.9573864936828613
training step: 40460, total_loss: 6.502498626708984
training step: 40461, total_loss: 4.15170955657959
training step: 40462, total_loss: 4.886630058288574
training step: 40463, total_loss: 4.509344100952148
training step: 40464, total_loss: 4.3160223960876465
training step: 40465, total_loss: 4.557727336883545
training step: 40466, total_loss: 3.773859977722168
training step: 40467, total_loss: 4.39818000793457
training step: 40468, total_loss: 4.942327499389648
training step: 40469, total_loss: 5.406085968017578
training step: 40470, total_loss: 4.715181827545166
training step: 40471, total_loss: 3.6203958988189697
training step: 40472, total_loss: 3.8281431198120117
training step: 40473, total_loss: 4.019739151000977
training step: 40474, total_loss: 4.541129112243652
training step: 40475, total_loss: 3.9145431518554688
training step: 40476, total_loss: 2.0725936889648438
training step: 40477, total_loss: 5.684060096740723
training step: 40478, total_loss: 3.875568389892578
training step: 40479, total_loss: 4.824925422668457
training step: 40480, total_loss: 2.913146734237671
training step: 40481, total_loss: 3.539130687713623
training step: 40482, total_loss: 3.8115925788879395
training step: 40483, total_loss: 5.160237789154053
training step: 40484, total_loss: 4.593667507171631
training step: 40485, total_loss: 3.9883999824523926
training step: 40486, total_loss: 3.9396133422851562
training step: 40487, total_loss: 3.6299595832824707
training step: 40488, total_loss: 4.9872846603393555
training step: 40489, total_loss: 5.416984558105469
training step: 40490, total_loss: 4.284078598022461
training step: 40491, total_loss: 4.340970039367676
training step: 40492, total_loss: 2.161695718765259
training step: 40493, total_loss: 4.405235290527344
training step: 40494, total_loss: 4.497645378112793
training step: 40495, total_loss: 5.895503044128418
training step: 40496, total_loss: 6.087430477142334
training step: 40497, total_loss: 2.6435794830322266
training step: 40498, total_loss: 4.487122058868408
training step: 40499, total_loss: 6.067915916442871
training step: 40500, total_loss: 4.883782863616943
training step: 40501, total_loss: 5.4087629318237305
training step: 40502, total_loss: 4.892850875854492
training step: 40503, total_loss: 4.107398509979248
training step: 40504, total_loss: 4.395552635192871
training step: 40505, total_loss: 5.3243207931518555
training step: 40506, total_loss: 4.404324054718018
training step: 40507, total_loss: 4.160390377044678
training step: 40508, total_loss: 5.096548557281494
training step: 40509, total_loss: 4.412067890167236
training step: 40510, total_loss: 5.616518974304199
training step: 40511, total_loss: 4.0700764656066895
training step: 40512, total_loss: 4.12500524520874
training step: 40513, total_loss: 4.446955680847168
training step: 40514, total_loss: 1.7864326238632202
training step: 40515, total_loss: 4.723679065704346
training step: 40516, total_loss: 6.378012657165527
training step: 40517, total_loss: 4.671451091766357
training step: 40518, total_loss: 4.124949932098389
training step: 40519, total_loss: 4.557672500610352
training step: 40520, total_loss: 3.9826791286468506
training step: 40521, total_loss: 7.07661771774292
training step: 40522, total_loss: 5.189172744750977
training step: 40523, total_loss: 4.236112594604492
training step: 40524, total_loss: 5.98397970199585
training step: 40525, total_loss: 5.252179145812988
training step: 40526, total_loss: 2.7214012145996094
training step: 40527, total_loss: 4.802668571472168
training step: 40528, total_loss: 3.495401382446289
training step: 40529, total_loss: 5.031310081481934
training step: 40530, total_loss: 4.219343185424805
training step: 40531, total_loss: 4.5990447998046875
training step: 40532, total_loss: 4.9305806159973145
training step: 40533, total_loss: 3.9270248413085938
training step: 40534, total_loss: 4.1306562423706055
training step: 40535, total_loss: 4.458064079284668
training step: 40536, total_loss: 3.8486390113830566
training step: 40537, total_loss: 3.750366687774658
training step: 40538, total_loss: 5.730071067810059
training step: 40539, total_loss: 4.847692966461182
training step: 40540, total_loss: 5.938398361206055
training step: 40541, total_loss: 3.455207347869873
training step: 40542, total_loss: 3.418955087661743
training step: 40543, total_loss: 3.6628541946411133
training step: 40544, total_loss: 3.2429685592651367
training step: 40545, total_loss: 2.7372171878814697
training step: 40546, total_loss: 4.991530418395996
training step: 40547, total_loss: 4.652249336242676
training step: 40548, total_loss: 4.192099571228027
training step: 40549, total_loss: 4.906946182250977
training step: 40550, total_loss: 4.197246074676514
training step: 40551, total_loss: 3.7142043113708496
training step: 40552, total_loss: 2.942836284637451
training step: 40553, total_loss: 4.706725597381592
training step: 40554, total_loss: 5.587502956390381
training step: 40555, total_loss: 3.7052407264709473
training step: 40556, total_loss: 3.453223705291748
training step: 40557, total_loss: 4.029870510101318
training step: 40558, total_loss: 3.7099502086639404
training step: 40559, total_loss: 3.5730226039886475
training step: 40560, total_loss: 3.8753700256347656
training step: 40561, total_loss: 4.698915004730225
training step: 40562, total_loss: 5.380639553070068
training step: 40563, total_loss: 3.9124839305877686
training step: 40564, total_loss: 3.138686180114746
training step: 40565, total_loss: 2.517916202545166
training step: 40566, total_loss: 3.698688507080078
training step: 40567, total_loss: 5.902750015258789
training step: 40568, total_loss: 4.696990013122559
training step: 40569, total_loss: 3.526872396469116
training step: 40570, total_loss: 5.680910110473633
training step: 40571, total_loss: 4.946832180023193
training step: 40572, total_loss: 2.757214307785034
training step: 40573, total_loss: 4.7039594650268555
training step: 40574, total_loss: 2.2556142807006836
training step: 40575, total_loss: 4.042500019073486
training step: 40576, total_loss: 4.9502458572387695
training step: 40577, total_loss: 2.2758355140686035
training step: 40578, total_loss: 4.894528865814209
training step: 40579, total_loss: 4.7471208572387695
training step: 40580, total_loss: 4.330883979797363
training step: 40581, total_loss: 3.729271173477173
training step: 40582, total_loss: 2.4765734672546387
training step: 40583, total_loss: 3.3286690711975098
training step: 40584, total_loss: 6.168888092041016
training step: 40585, total_loss: 4.364941596984863
training step: 40586, total_loss: 5.519871711730957
training step: 40587, total_loss: 3.3819077014923096
training step: 40588, total_loss: 4.341559886932373
training step: 40589, total_loss: 3.80730938911438
training step: 40590, total_loss: 3.635784149169922
training step: 40591, total_loss: 3.338078022003174
training step: 40592, total_loss: 4.438838958740234
training step: 40593, total_loss: 5.628225326538086
training step: 40594, total_loss: 4.013073921203613
training step: 40595, total_loss: 5.346546649932861
training step: 40596, total_loss: 3.9297375679016113
training step: 40597, total_loss: 5.151942729949951
training step: 40598, total_loss: 3.310955286026001
training step: 40599, total_loss: 4.109607696533203
training step: 40600, total_loss: 5.022787094116211
training step: 40601, total_loss: 1.467292070388794
training step: 40602, total_loss: 6.511258602142334
training step: 40603, total_loss: 4.527838706970215
training step: 40604, total_loss: 6.066171646118164
training step: 40605, total_loss: 3.94311785697937
training step: 40606, total_loss: 3.7442445755004883
training step: 40607, total_loss: 4.365469455718994
training step: 40608, total_loss: 3.986574411392212
training step: 40609, total_loss: 4.589256763458252
training step: 40610, total_loss: 4.959175109863281
training step: 40611, total_loss: 3.9594123363494873
training step: 40612, total_loss: 4.588711261749268
training step: 40613, total_loss: 4.789989948272705
training step: 40614, total_loss: 4.935478210449219
training step: 40615, total_loss: 4.605559825897217
training step: 40616, total_loss: 5.3209967613220215
training step: 40617, total_loss: 3.1568593978881836
training step: 40618, total_loss: 2.6149542331695557
training step: 40619, total_loss: 5.782193183898926
training step: 40620, total_loss: 3.3405404090881348
training step: 40621, total_loss: 4.381367206573486
training step: 40622, total_loss: 4.736106872558594
training step: 40623, total_loss: 3.2420425415039062
training step: 40624, total_loss: 4.164515495300293
training step: 40625, total_loss: 4.042352676391602
training step: 40626, total_loss: 3.4710705280303955
training step: 40627, total_loss: 4.623673915863037
training step: 40628, total_loss: 4.4443488121032715
training step: 40629, total_loss: 4.712481498718262
training step: 40630, total_loss: 4.046225070953369
training step: 40631, total_loss: 4.03471040725708
training step: 40632, total_loss: 5.896149158477783
training step: 40633, total_loss: 4.792715072631836
training step: 40634, total_loss: 2.4704644680023193
training step: 40635, total_loss: 5.8660783767700195
training step: 40636, total_loss: 4.264586448669434
training step: 40637, total_loss: 4.857062816619873
training step: 40638, total_loss: 4.102602005004883
training step: 40639, total_loss: 4.708944320678711
training step: 40640, total_loss: 3.7715883255004883
training step: 40641, total_loss: 4.956859588623047
training step: 40642, total_loss: 4.6773271560668945
training step: 40643, total_loss: 5.021232604980469
training step: 40644, total_loss: 4.623455047607422
training step: 40645, total_loss: 5.002912521362305
training step: 40646, total_loss: 5.197853088378906
training step: 40647, total_loss: 5.525480270385742
training step: 40648, total_loss: 3.8213977813720703
training step: 40649, total_loss: 3.7946906089782715
training step: 40650, total_loss: 3.9715499877929688
training step: 40651, total_loss: 3.8940341472625732
training step: 40652, total_loss: 6.433937072753906
training step: 40653, total_loss: 4.421016693115234
training step: 40654, total_loss: 4.050204277038574
training step: 40655, total_loss: 5.132453441619873
training step: 40656, total_loss: 5.500946998596191
training step: 40657, total_loss: 4.633397102355957
training step: 40658, total_loss: 6.476145267486572
training step: 40659, total_loss: 4.270328521728516
training step: 40660, total_loss: 4.140547752380371
training step: 40661, total_loss: 3.0802674293518066
training step: 40662, total_loss: 3.985947608947754
training step: 40663, total_loss: 5.661129951477051
training step: 40664, total_loss: 3.006580352783203
training step: 40665, total_loss: 4.762706756591797
training step: 40666, total_loss: 3.217299461364746
training step: 40667, total_loss: 4.827476978302002
training step: 40668, total_loss: 5.442480087280273
training step: 40669, total_loss: 4.677182197570801
training step: 40670, total_loss: 4.737423896789551
training step: 40671, total_loss: 5.503959655761719
training step: 40672, total_loss: 3.4234261512756348
training step: 40673, total_loss: 1.2829067707061768
training step: 40674, total_loss: 6.629591464996338
training step: 40675, total_loss: 2.936298131942749
training step: 40676, total_loss: 4.283442497253418
training step: 40677, total_loss: 5.369290351867676
training step: 40678, total_loss: 2.4544389247894287
training step: 40679, total_loss: 3.023409128189087
training step: 40680, total_loss: 4.577236175537109
training step: 40681, total_loss: 5.401827812194824
training step: 40682, total_loss: 5.105141639709473
training step: 40683, total_loss: 5.123897552490234
training step: 40684, total_loss: 2.452834129333496
training step: 40685, total_loss: 5.204798221588135
training step: 40686, total_loss: 4.260591506958008
training step: 40687, total_loss: 5.152339935302734
training step: 40688, total_loss: 4.869326591491699
training step: 40689, total_loss: 2.2242603302001953
training step: 40690, total_loss: 1.2703948020935059
training step: 40691, total_loss: 4.3225202560424805
training step: 40692, total_loss: 5.086678981781006
training step: 40693, total_loss: 4.070415019989014
training step: 40694, total_loss: 1.7457071542739868
training step: 40695, total_loss: 4.762803554534912
training step: 40696, total_loss: 3.669773578643799
training step: 40697, total_loss: 3.1817805767059326
training step: 40698, total_loss: 3.74810791015625
training step: 40699, total_loss: 4.780972480773926
training step: 40700, total_loss: 4.179110527038574
training step: 40701, total_loss: 5.101071357727051
training step: 40702, total_loss: 3.651749610900879
training step: 40703, total_loss: 4.6319580078125
training step: 40704, total_loss: 5.1412200927734375
training step: 40705, total_loss: 4.076366424560547
training step: 40706, total_loss: 2.758483409881592
training step: 40707, total_loss: 5.622961044311523
training step: 40708, total_loss: 3.970874309539795
training step: 40709, total_loss: 3.29996657371521
training step: 40710, total_loss: 3.410055637359619
training step: 40711, total_loss: 3.009288787841797
training step: 40712, total_loss: 4.580995559692383
training step: 40713, total_loss: 4.533263683319092
training step: 40714, total_loss: 6.224715709686279
training step: 40715, total_loss: 5.1682329177856445
training step: 40716, total_loss: 4.117916107177734
training step: 40717, total_loss: 5.2407050132751465
training step: 40718, total_loss: 5.791201591491699
training step: 40719, total_loss: 3.066519021987915
training step: 40720, total_loss: 4.0493927001953125
training step: 40721, total_loss: 4.422432899475098
training step: 40722, total_loss: 4.430392265319824
training step: 40723, total_loss: 4.001527786254883
training step: 40724, total_loss: 4.364105701446533
training step: 40725, total_loss: 5.110715866088867
training step: 40726, total_loss: 5.059871673583984
training step: 40727, total_loss: 4.571207046508789
training step: 40728, total_loss: 4.107849597930908
training step: 40729, total_loss: 5.154471397399902
training step: 40730, total_loss: 4.7607316970825195
training step: 40731, total_loss: 4.570528507232666
training step: 40732, total_loss: 5.558297634124756
training step: 40733, total_loss: 3.167752981185913
training step: 40734, total_loss: 4.530603408813477
training step: 40735, total_loss: 5.177356719970703
training step: 40736, total_loss: 0.7635962963104248
training step: 40737, total_loss: 3.953982353210449
training step: 40738, total_loss: 3.8418891429901123
training step: 40739, total_loss: 6.046912670135498
training step: 40740, total_loss: 2.9066665172576904
training step: 40741, total_loss: 3.9117822647094727
training step: 40742, total_loss: 2.6735782623291016
training step: 40743, total_loss: 5.601080894470215
training step: 40744, total_loss: 1.109595775604248
training step: 40745, total_loss: 3.9650630950927734
training step: 40746, total_loss: 4.649080276489258
training step: 40747, total_loss: 3.3081302642822266
training step: 40748, total_loss: 4.432435989379883
training step: 40749, total_loss: 5.545151710510254
training step: 40750, total_loss: 5.662613868713379
training step: 40751, total_loss: 3.470850944519043
training step: 40752, total_loss: 4.896523475646973
training step: 40753, total_loss: 4.635841369628906
training step: 40754, total_loss: 0.8119940757751465
training step: 40755, total_loss: 4.1672539710998535
training step: 40756, total_loss: 2.967597007751465
training step: 40757, total_loss: 5.036126136779785
training step: 40758, total_loss: 4.943595886230469
training step: 40759, total_loss: 5.722991466522217
training step: 40760, total_loss: 5.472578048706055
training step: 40761, total_loss: 5.737260818481445
training step: 40762, total_loss: 4.889108657836914
training step: 40763, total_loss: 4.533179759979248
training step: 40764, total_loss: 3.741959810256958
training step: 40765, total_loss: 4.634730815887451
training step: 40766, total_loss: 3.9822680950164795
training step: 40767, total_loss: 3.847872257232666
training step: 40768, total_loss: 2.911250114440918
training step: 40769, total_loss: 5.283477783203125
training step: 40770, total_loss: 3.837704658508301
training step: 40771, total_loss: 4.434026718139648
training step: 40772, total_loss: 3.9863390922546387
training step: 40773, total_loss: 4.982137680053711
training step: 40774, total_loss: 5.747267246246338
training step: 40775, total_loss: 4.4665045738220215
training step: 40776, total_loss: 5.777244567871094
training step: 40777, total_loss: 5.110809326171875
training step: 40778, total_loss: 3.595369815826416
training step: 40779, total_loss: 5.0912933349609375
training step: 40780, total_loss: 5.51578950881958
training step: 40781, total_loss: 4.580750465393066
training step: 40782, total_loss: 3.9897797107696533
training step: 40783, total_loss: 5.289713382720947
training step: 40784, total_loss: 5.928909778594971
training step: 40785, total_loss: 5.255209922790527
training step: 40786, total_loss: 4.677772521972656
training step: 40787, total_loss: 5.591492652893066
training step: 40788, total_loss: 5.465744972229004
training step: 40789, total_loss: 4.693061828613281
training step: 40790, total_loss: 2.606412410736084
training step: 40791, total_loss: 5.100028991699219
training step: 40792, total_loss: 5.889064788818359
training step: 40793, total_loss: 4.142945289611816
training step: 40794, total_loss: 6.440362453460693
training step: 40795, total_loss: 5.225921154022217
training step: 40796, total_loss: 2.877311944961548
training step: 40797, total_loss: 3.8550238609313965
training step: 40798, total_loss: 5.864011764526367
training step: 40799, total_loss: 4.18820858001709
training step: 40800, total_loss: 4.4339518547058105
training step: 40801, total_loss: 5.557851314544678
training step: 40802, total_loss: 4.104581356048584
training step: 40803, total_loss: 4.047268867492676
training step: 40804, total_loss: 4.591032028198242
training step: 40805, total_loss: 4.338679790496826
training step: 40806, total_loss: 4.108214378356934
training step: 40807, total_loss: 3.413280963897705
training step: 40808, total_loss: 3.3163137435913086
training step: 40809, total_loss: 2.699544906616211
training step: 40810, total_loss: 5.109376907348633
training step: 40811, total_loss: 3.158039093017578
training step: 40812, total_loss: 4.8642578125
training step: 40813, total_loss: 2.8955819606781006
training step: 40814, total_loss: 3.268106460571289
training step: 40815, total_loss: 4.4676642417907715
training step: 40816, total_loss: 5.2610039710998535
training step: 40817, total_loss: 4.215235710144043
training step: 40818, total_loss: 4.175783157348633
training step: 40819, total_loss: 3.2240161895751953
training step: 40820, total_loss: 0.7406513690948486
training step: 40821, total_loss: 3.489783763885498
training step: 40822, total_loss: 3.9978384971618652
training step: 40823, total_loss: 5.341585159301758
training step: 40824, total_loss: 3.6530728340148926
training step: 40825, total_loss: 4.895332336425781
training step: 40826, total_loss: 4.274636268615723
training step: 40827, total_loss: 4.697786331176758
training step: 40828, total_loss: 3.938664197921753
training step: 40829, total_loss: 4.591121673583984
training step: 40830, total_loss: 4.222909927368164
training step: 40831, total_loss: 4.798456192016602
training step: 40832, total_loss: 4.100561141967773
training step: 40833, total_loss: 4.6447954177856445
training step: 40834, total_loss: 4.322122097015381
training step: 40835, total_loss: 5.130706787109375
training step: 40836, total_loss: 4.058493137359619
training step: 40837, total_loss: 5.925658226013184
training step: 40838, total_loss: 5.014015197753906
training step: 40839, total_loss: 4.331259727478027
training step: 40840, total_loss: 4.9591240882873535
training step: 40841, total_loss: 3.987086772918701
training step: 40842, total_loss: 5.359908580780029
training step: 40843, total_loss: 4.259632587432861
training step: 40844, total_loss: 4.8567681312561035
training step: 40845, total_loss: 5.123108863830566
training step: 40846, total_loss: 4.654767036437988
training step: 40847, total_loss: 3.327540397644043
training step: 40848, total_loss: 4.885368347167969
training step: 40849, total_loss: 4.114757537841797
training step: 40850, total_loss: 5.929494857788086
training step: 40851, total_loss: 5.078392505645752
training step: 40852, total_loss: 4.893136024475098
training step: 40853, total_loss: 6.3858113288879395
training step: 40854, total_loss: 4.041320323944092
training step: 40855, total_loss: 3.4283993244171143
training step: 40856, total_loss: 4.466464042663574
training step: 40857, total_loss: 3.825676679611206
training step: 40858, total_loss: 4.798460960388184
training step: 40859, total_loss: 5.1275858879089355
training step: 40860, total_loss: 4.602769374847412
training step: 40861, total_loss: 1.171034574508667
training step: 40862, total_loss: 3.528470993041992
training step: 40863, total_loss: 1.9745646715164185
training step: 40864, total_loss: 4.287178039550781
training step: 40865, total_loss: 3.942856788635254
training step: 40866, total_loss: 3.5646238327026367
training step: 40867, total_loss: 4.7154364585876465
training step: 40868, total_loss: 3.8266444206237793
training step: 40869, total_loss: 3.914484739303589
training step: 40870, total_loss: 3.078237295150757
training step: 40871, total_loss: 5.600152969360352
training step: 40872, total_loss: 3.4442031383514404
training step: 40873, total_loss: 4.673116683959961
training step: 40874, total_loss: 4.206736087799072
training step: 40875, total_loss: 4.813020706176758
training step: 40876, total_loss: 4.0948286056518555
training step: 40877, total_loss: 3.8468422889709473
training step: 40878, total_loss: 4.526573181152344
training step: 40879, total_loss: 5.411199569702148
training step: 40880, total_loss: 5.191948890686035
training step: 40881, total_loss: 4.5453596115112305
training step: 40882, total_loss: 5.044582843780518
training step: 40883, total_loss: 3.0579230785369873
training step: 40884, total_loss: 5.191411972045898
training step: 40885, total_loss: 3.0453758239746094
training step: 40886, total_loss: 3.7364587783813477
training step: 40887, total_loss: 4.919971942901611
training step: 40888, total_loss: 5.3101983070373535
training step: 40889, total_loss: 5.67863655090332
training step: 40890, total_loss: 4.502049922943115
training step: 40891, total_loss: 4.0185465812683105
training step: 40892, total_loss: 5.713174819946289
training step: 40893, total_loss: 4.530464172363281
training step: 40894, total_loss: 2.393505811691284
training step: 40895, total_loss: 5.951343536376953
training step: 40896, total_loss: 6.396470069885254
training step: 40897, total_loss: 4.70869255065918
training step: 40898, total_loss: 4.914087295532227
training step: 40899, total_loss: 6.642452239990234
training step: 40900, total_loss: 5.881597518920898
training step: 40901, total_loss: 3.5308334827423096
training step: 40902, total_loss: 4.434292316436768
training step: 40903, total_loss: 4.586184501647949
training step: 40904, total_loss: 4.070970058441162
training step: 40905, total_loss: 3.707190752029419
training step: 40906, total_loss: 4.10235595703125
training step: 40907, total_loss: 3.965395927429199
training step: 40908, total_loss: 5.303211688995361
training step: 40909, total_loss: 4.635456085205078
training step: 40910, total_loss: 5.095355987548828
training step: 40911, total_loss: 3.922687530517578
training step: 40912, total_loss: 3.3169219493865967
training step: 40913, total_loss: 6.052675247192383
training step: 40914, total_loss: 4.386357307434082
training step: 40915, total_loss: 4.559399604797363
training step: 40916, total_loss: 6.829432010650635
training step: 40917, total_loss: 4.773440361022949
training step: 40918, total_loss: 5.347830772399902
training step: 40919, total_loss: 4.426806449890137
training step: 40920, total_loss: 3.74798321723938
training step: 40921, total_loss: 5.111106872558594
training step: 40922, total_loss: 4.61495304107666
training step: 40923, total_loss: 4.023736953735352
training step: 40924, total_loss: 3.0191802978515625
training step: 40925, total_loss: 4.511351108551025
training step: 40926, total_loss: 2.7879059314727783
training step: 40927, total_loss: 4.514059543609619
training step: 40928, total_loss: 4.331585884094238
training step: 40929, total_loss: 6.114373207092285
training step: 40930, total_loss: 4.613536357879639
training step: 40931, total_loss: 5.256092071533203
training step: 40932, total_loss: 6.458150863647461
training step: 40933, total_loss: 3.1703662872314453
training step: 40934, total_loss: 2.2980217933654785
training step: 40935, total_loss: 4.600025177001953
training step: 40936, total_loss: 4.890734672546387
training step: 40937, total_loss: 3.36147403717041
training step: 40938, total_loss: 3.773787498474121
training step: 40939, total_loss: 5.129267692565918
training step: 40940, total_loss: 6.088996887207031
training step: 40941, total_loss: 4.269742012023926
training step: 40942, total_loss: 5.367151260375977
training step: 40943, total_loss: 4.354385852813721
training step: 40944, total_loss: 4.164506912231445
training step: 40945, total_loss: 5.005082130432129
training step: 40946, total_loss: 3.9830713272094727
training step: 40947, total_loss: 3.914374828338623
training step: 40948, total_loss: 3.5991621017456055
training step: 40949, total_loss: 4.3868279457092285
training step: 40950, total_loss: 5.848762035369873
training step: 40951, total_loss: 3.830446720123291
training step: 40952, total_loss: 4.8033952713012695
training step: 40953, total_loss: 4.385114669799805
training step: 40954, total_loss: 4.163636207580566
training step: 40955, total_loss: 3.235440731048584
training step: 40956, total_loss: 4.655246734619141
training step: 40957, total_loss: 5.717718601226807
training step: 40958, total_loss: 4.535553455352783
training step: 40959, total_loss: 1.4863626956939697
training step: 40960, total_loss: 5.239819526672363
training step: 40961, total_loss: 2.6581850051879883
training step: 40962, total_loss: 3.753906011581421
training step: 40963, total_loss: 6.14831018447876
training step: 40964, total_loss: 5.625720977783203
training step: 40965, total_loss: 4.672762870788574
training step: 40966, total_loss: 3.9754798412323
training step: 40967, total_loss: 3.9419405460357666
training step: 40968, total_loss: 5.868497848510742
training step: 40969, total_loss: 5.330102920532227
training step: 40970, total_loss: 3.758942127227783
training step: 40971, total_loss: 3.9794387817382812
training step: 40972, total_loss: 3.2986555099487305
training step: 40973, total_loss: 4.873774528503418
training step: 40974, total_loss: 4.197257995605469
training step: 40975, total_loss: 3.3009276390075684
training step: 40976, total_loss: 4.943781852722168
training step: 40977, total_loss: 4.783888816833496
training step: 40978, total_loss: 5.305689811706543
training step: 40979, total_loss: 5.088192939758301
training step: 40980, total_loss: 4.368484020233154
training step: 40981, total_loss: 3.5322093963623047
training step: 40982, total_loss: 5.32253885269165
training step: 40983, total_loss: 5.753093719482422
training step: 40984, total_loss: 6.076581954956055
training step: 40985, total_loss: 5.23772668838501
training step: 40986, total_loss: 3.1212027072906494
training step: 40987, total_loss: 4.527882099151611
training step: 40988, total_loss: 3.821553945541382
training step: 40989, total_loss: 4.283786773681641
training step: 40990, total_loss: 3.5298712253570557
training step: 40991, total_loss: 4.9082794189453125
training step: 40992, total_loss: 4.407308578491211
training step: 40993, total_loss: 4.731750965118408
training step: 40994, total_loss: 5.225151538848877
training step: 40995, total_loss: 1.4055545330047607
training step: 40996, total_loss: 4.143303871154785
training step: 40997, total_loss: 4.508793830871582
training step: 40998, total_loss: 2.9970545768737793
training step: 40999, total_loss: 3.9685070514678955
training step: 41000, total_loss: 5.8752593994140625
training step: 41001, total_loss: 4.680227279663086
training step: 41002, total_loss: 6.2731781005859375
training step: 41003, total_loss: 4.423670768737793
training step: 41004, total_loss: 5.134809494018555
training step: 41005, total_loss: 4.124532699584961
training step: 41006, total_loss: 3.9433271884918213
training step: 41007, total_loss: 4.563753128051758
training step: 41008, total_loss: 3.4040980339050293
training step: 41009, total_loss: 4.119770050048828
training step: 41010, total_loss: 5.919888496398926
training step: 41011, total_loss: 3.847780227661133
training step: 41012, total_loss: 5.1941375732421875
training step: 41013, total_loss: 4.359588623046875
training step: 41014, total_loss: 4.75032377243042
training step: 41015, total_loss: 5.240013599395752
training step: 41016, total_loss: 5.087606430053711
training step: 41017, total_loss: 5.542265892028809
training step: 41018, total_loss: 4.519285678863525
training step: 41019, total_loss: 4.12128210067749
training step: 41020, total_loss: 4.273777484893799
training step: 41021, total_loss: 5.22973108291626
training step: 41022, total_loss: 3.0188815593719482
training step: 41023, total_loss: 4.842262268066406
training step: 41024, total_loss: 6.0542097091674805
training step: 41025, total_loss: 3.8826613426208496
training step: 41026, total_loss: 4.596560955047607
training step: 41027, total_loss: 3.0809335708618164
training step: 41028, total_loss: 5.0082502365112305
training step: 41029, total_loss: 4.8696980476379395
training step: 41030, total_loss: 3.80372953414917
training step: 41031, total_loss: 4.370822906494141
training step: 41032, total_loss: 4.483486175537109
training step: 41033, total_loss: 2.721219301223755
training step: 41034, total_loss: 4.143613338470459
training step: 41035, total_loss: 5.15473747253418
training step: 41036, total_loss: 3.9967141151428223
training step: 41037, total_loss: 5.003765106201172
training step: 41038, total_loss: 4.425814151763916
training step: 41039, total_loss: 4.7443461418151855
training step: 41040, total_loss: 4.125524044036865
training step: 41041, total_loss: 4.899901866912842
training step: 41042, total_loss: 5.319643020629883
training step: 41043, total_loss: 5.818619251251221
training step: 41044, total_loss: 4.906186103820801
training step: 41045, total_loss: 4.316424369812012
training step: 41046, total_loss: 4.625881671905518
training step: 41047, total_loss: 5.172633171081543
training step: 41048, total_loss: 5.345791339874268
training step: 41049, total_loss: 3.859419584274292
training step: 41050, total_loss: 4.966732025146484
training step: 41051, total_loss: 4.367043495178223
training step: 41052, total_loss: 4.756032943725586
training step: 41053, total_loss: 4.277411460876465
training step: 41054, total_loss: 4.025613307952881
training step: 41055, total_loss: 4.817136764526367
training step: 41056, total_loss: 3.2170896530151367
training step: 41057, total_loss: 4.402100086212158
training step: 41058, total_loss: 4.774582862854004
training step: 41059, total_loss: 4.1009602546691895
training step: 41060, total_loss: 4.804143905639648
training step: 41061, total_loss: 4.08819580078125
training step: 41062, total_loss: 3.686917543411255
training step: 41063, total_loss: 4.492572784423828
training step: 41064, total_loss: 4.71937370300293
training step: 41065, total_loss: 3.919682502746582
training step: 41066, total_loss: 4.8606061935424805
training step: 41067, total_loss: 3.5456607341766357
training step: 41068, total_loss: 5.696313858032227
training step: 41069, total_loss: 4.729430198669434
training step: 41070, total_loss: 3.9468398094177246
training step: 41071, total_loss: 3.5977025032043457
training step: 41072, total_loss: 4.498157501220703
training step: 41073, total_loss: 4.232088565826416
training step: 41074, total_loss: 1.2171094417572021
training step: 41075, total_loss: 4.825863361358643
training step: 41076, total_loss: 3.745755672454834
training step: 41077, total_loss: 5.375205039978027
training step: 41078, total_loss: 5.757234573364258
training step: 41079, total_loss: 3.5123324394226074
training step: 41080, total_loss: 5.26729154586792
training step: 41081, total_loss: 5.0530595779418945
training step: 41082, total_loss: 4.180240154266357
training step: 41083, total_loss: 3.713477373123169
training step: 41084, total_loss: 4.952964782714844
training step: 41085, total_loss: 5.1817402839660645
training step: 41086, total_loss: 3.098125457763672
training step: 41087, total_loss: 4.10727596282959
training step: 41088, total_loss: 2.5027503967285156
training step: 41089, total_loss: 4.890356063842773
training step: 41090, total_loss: 4.981328964233398
training step: 41091, total_loss: 4.451836109161377
training step: 41092, total_loss: 4.025397300720215
training step: 41093, total_loss: 5.589657783508301
training step: 41094, total_loss: 4.236250400543213
training step: 41095, total_loss: 3.8396382331848145
training step: 41096, total_loss: 4.568486213684082
training step: 41097, total_loss: 4.595427513122559
training step: 41098, total_loss: 5.039760589599609
training step: 41099, total_loss: 3.3265514373779297
training step: 41100, total_loss: 3.8781988620758057
training step: 41101, total_loss: 4.161003112792969
training step: 41102, total_loss: 4.123940467834473
training step: 41103, total_loss: 2.5973763465881348
training step: 41104, total_loss: 5.189938545227051
training step: 41105, total_loss: 4.0380072593688965
training step: 41106, total_loss: 5.574491500854492
training step: 41107, total_loss: 4.105913162231445
training step: 41108, total_loss: 5.212879180908203
training step: 41109, total_loss: 4.932200908660889
training step: 41110, total_loss: 3.966188907623291
training step: 41111, total_loss: 5.840245246887207
training step: 41112, total_loss: 4.833274841308594
training step: 41113, total_loss: 3.868992805480957
training step: 41114, total_loss: 3.0472733974456787
training step: 41115, total_loss: 5.002649784088135
training step: 41116, total_loss: 4.348343372344971
training step: 41117, total_loss: 6.257390975952148
training step: 41118, total_loss: 3.971574306488037
training step: 41119, total_loss: 3.2312440872192383
training step: 41120, total_loss: 6.069958686828613
training step: 41121, total_loss: 4.102709770202637
training step: 41122, total_loss: 4.91007137298584
training step: 41123, total_loss: 4.195957660675049
training step: 41124, total_loss: 3.381312131881714
training step: 41125, total_loss: 5.048238754272461
training step: 41126, total_loss: 4.696481227874756
training step: 41127, total_loss: 5.016766548156738
training step: 41128, total_loss: 4.357377052307129
training step: 41129, total_loss: 4.799566745758057
training step: 41130, total_loss: 4.302960395812988
training step: 41131, total_loss: 5.380216598510742
training step: 41132, total_loss: 3.311316967010498
training step: 41133, total_loss: 2.169037342071533
training step: 41134, total_loss: 6.394571781158447
training step: 41135, total_loss: 5.67568302154541
training step: 41136, total_loss: 2.6061713695526123
training step: 41137, total_loss: 3.240020751953125
training step: 41138, total_loss: 3.2020673751831055
training step: 41139, total_loss: 4.341464996337891
training step: 41140, total_loss: 4.431365489959717
training step: 41141, total_loss: 4.621488094329834
training step: 41142, total_loss: 6.021115303039551
training step: 41143, total_loss: 5.818075180053711
training step: 41144, total_loss: 4.6268510818481445
training step: 41145, total_loss: 5.708507537841797
training step: 41146, total_loss: 5.371883869171143
training step: 41147, total_loss: 5.27719783782959
training step: 41148, total_loss: 4.660333156585693
training step: 41149, total_loss: 5.451504707336426
training step: 41150, total_loss: 5.219232559204102
training step: 41151, total_loss: 2.738053321838379
training step: 41152, total_loss: 4.25460147857666
training step: 41153, total_loss: 4.383602619171143
training step: 41154, total_loss: 3.1412200927734375
training step: 41155, total_loss: 3.8114686012268066
training step: 41156, total_loss: 4.397827625274658
training step: 41157, total_loss: 5.691009521484375
training step: 41158, total_loss: 3.738770008087158
training step: 41159, total_loss: 3.3378257751464844
training step: 41160, total_loss: 4.433597564697266
training step: 41161, total_loss: 4.415422439575195
training step: 41162, total_loss: 4.749181747436523
training step: 41163, total_loss: 1.3114404678344727
training step: 41164, total_loss: 5.139529228210449
training step: 41165, total_loss: 4.27667760848999
training step: 41166, total_loss: 4.307635307312012
training step: 41167, total_loss: 4.313604831695557
training step: 41168, total_loss: 3.336764335632324
training step: 41169, total_loss: 4.073025703430176
training step: 41170, total_loss: 5.71223258972168
training step: 41171, total_loss: 4.774636268615723
training step: 41172, total_loss: 4.772445201873779
training step: 41173, total_loss: 3.697429656982422
training step: 41174, total_loss: 4.7779741287231445
training step: 41175, total_loss: 3.470089912414551
training step: 41176, total_loss: 4.497234344482422
training step: 41177, total_loss: 2.9052679538726807
training step: 41178, total_loss: 4.7091875076293945
training step: 41179, total_loss: 3.4092907905578613
training step: 41180, total_loss: 5.419295787811279
training step: 41181, total_loss: 3.566525459289551
training step: 41182, total_loss: 4.6175031661987305
training step: 41183, total_loss: 2.532026767730713
training step: 41184, total_loss: 5.42561149597168
training step: 41185, total_loss: 3.91959285736084
training step: 41186, total_loss: 5.644878387451172
training step: 41187, total_loss: 4.997352600097656
training step: 41188, total_loss: 2.7447590827941895
training step: 41189, total_loss: 4.435886383056641
training step: 41190, total_loss: 6.3507208824157715
training step: 41191, total_loss: 4.488407135009766
training step: 41192, total_loss: 3.889108419418335
training step: 41193, total_loss: 7.152390003204346
training step: 41194, total_loss: 4.091137886047363
training step: 41195, total_loss: 3.8151354789733887
training step: 41196, total_loss: 5.322885513305664
training step: 41197, total_loss: 6.779637813568115
training step: 41198, total_loss: 3.4269537925720215
training step: 41199, total_loss: 5.067713260650635
training step: 41200, total_loss: 3.807965040206909
training step: 41201, total_loss: 4.506300926208496
training step: 41202, total_loss: 3.6129324436187744
training step: 41203, total_loss: 4.568517684936523
training step: 41204, total_loss: 4.029414653778076
training step: 41205, total_loss: 3.403975009918213
training step: 41206, total_loss: 4.409261703491211
training step: 41207, total_loss: 4.247032165527344
training step: 41208, total_loss: 4.110039710998535
training step: 41209, total_loss: 4.677556037902832
training step: 41210, total_loss: 4.851420879364014
training step: 41211, total_loss: 1.5493152141571045
training step: 41212, total_loss: 3.716630220413208
training step: 41213, total_loss: 4.912164211273193
training step: 41214, total_loss: 4.246703147888184
training step: 41215, total_loss: 4.351982593536377
training step: 41216, total_loss: 3.7875142097473145
training step: 41217, total_loss: 3.4035468101501465
training step: 41218, total_loss: 4.312464237213135
training step: 41219, total_loss: 3.5942039489746094
training step: 41220, total_loss: 5.444488525390625
training step: 41221, total_loss: 3.871425151824951
training step: 41222, total_loss: 5.796597480773926
training step: 41223, total_loss: 4.461837291717529
training step: 41224, total_loss: 4.742064476013184
training step: 41225, total_loss: 3.734994888305664
training step: 41226, total_loss: 3.410841941833496
training step: 41227, total_loss: 3.580928087234497
training step: 41228, total_loss: 3.679708480834961
training step: 41229, total_loss: 5.047730445861816
training step: 41230, total_loss: 3.6437506675720215
training step: 41231, total_loss: 4.711518287658691
training step: 41232, total_loss: 2.0128846168518066
training step: 41233, total_loss: 2.8754520416259766
training step: 41234, total_loss: 4.698424339294434
training step: 41235, total_loss: 5.9583916664123535
training step: 41236, total_loss: 2.3486251831054688
training step: 41237, total_loss: 4.792606353759766
training step: 41238, total_loss: 4.852664947509766
training step: 41239, total_loss: 3.882601737976074
training step: 41240, total_loss: 2.609513282775879
training step: 41241, total_loss: 4.175499439239502
training step: 41242, total_loss: 0.8982070684432983
training step: 41243, total_loss: 3.208956241607666
training step: 41244, total_loss: 3.9748926162719727
training step: 41245, total_loss: 2.333409547805786
training step: 41246, total_loss: 5.151098251342773
training step: 41247, total_loss: 5.81793212890625
training step: 41248, total_loss: 4.957120895385742
training step: 41249, total_loss: 6.548638820648193
training step: 41250, total_loss: 5.238326072692871
training step: 41251, total_loss: 6.358078956604004
training step: 41252, total_loss: 3.561722993850708
training step: 41253, total_loss: 4.709390640258789
training step: 41254, total_loss: 3.9918928146362305
training step: 41255, total_loss: 4.1768951416015625
training step: 41256, total_loss: 2.7772512435913086
training step: 41257, total_loss: 3.9301090240478516
training step: 41258, total_loss: 4.434100151062012
training step: 41259, total_loss: 4.0315937995910645
training step: 41260, total_loss: 3.7164416313171387
training step: 41261, total_loss: 3.166841506958008
training step: 41262, total_loss: 4.95444917678833
training step: 41263, total_loss: 3.790435314178467
training step: 41264, total_loss: 3.315932035446167
training step: 41265, total_loss: 4.81803035736084
training step: 41266, total_loss: 3.1371498107910156
training step: 41267, total_loss: 2.4522080421447754
training step: 41268, total_loss: 6.561423301696777
training step: 41269, total_loss: 4.3059587478637695
training step: 41270, total_loss: 5.879443645477295
training step: 41271, total_loss: 5.057196140289307
training step: 41272, total_loss: 5.670838356018066
training step: 41273, total_loss: 3.2811152935028076
training step: 41274, total_loss: 4.339099884033203
training step: 41275, total_loss: 5.112038612365723
training step: 41276, total_loss: 4.921850681304932
training step: 41277, total_loss: 6.462000846862793
training step: 41278, total_loss: 3.0308613777160645
training step: 41279, total_loss: 3.9240169525146484
training step: 41280, total_loss: 4.710721969604492
training step: 41281, total_loss: 3.899937629699707
training step: 41282, total_loss: 5.341779708862305
training step: 41283, total_loss: 4.579346656799316
training step: 41284, total_loss: 4.183071136474609
training step: 41285, total_loss: 2.033860683441162
training step: 41286, total_loss: 6.023515701293945
training step: 41287, total_loss: 2.6869912147521973
training step: 41288, total_loss: 4.324108123779297
training step: 41289, total_loss: 3.1941428184509277
training step: 41290, total_loss: 5.458901405334473
training step: 41291, total_loss: 4.49760103225708
training step: 41292, total_loss: 4.884209156036377
training step: 41293, total_loss: 4.469533920288086
training step: 41294, total_loss: 6.255308151245117
training step: 41295, total_loss: 5.21083402633667
training step: 41296, total_loss: 3.2397665977478027
training step: 41297, total_loss: 4.641526699066162
training step: 41298, total_loss: 4.790234565734863
training step: 41299, total_loss: 4.937486171722412
training step: 41300, total_loss: 4.256075859069824
training step: 41301, total_loss: 6.092607021331787
training step: 41302, total_loss: 5.127158164978027
training step: 41303, total_loss: 5.3672685623168945
training step: 41304, total_loss: 4.54641056060791
training step: 41305, total_loss: 4.702769756317139
training step: 41306, total_loss: 3.8408355712890625
training step: 41307, total_loss: 4.858661651611328
training step: 41308, total_loss: 4.453522682189941
training step: 41309, total_loss: 4.577707290649414
training step: 41310, total_loss: 4.896772384643555
training step: 41311, total_loss: 4.671259880065918
training step: 41312, total_loss: 5.471277236938477
training step: 41313, total_loss: 4.5639848709106445
training step: 41314, total_loss: 4.527983665466309
training step: 41315, total_loss: 4.576555252075195
training step: 41316, total_loss: 4.353982925415039
training step: 41317, total_loss: 6.039395332336426
training step: 41318, total_loss: 4.739849090576172
training step: 41319, total_loss: 3.8834714889526367
training step: 41320, total_loss: 4.551978588104248
training step: 41321, total_loss: 5.769983291625977
training step: 41322, total_loss: 6.456537246704102
training step: 41323, total_loss: 5.602712631225586
training step: 41324, total_loss: 5.139274597167969
training step: 41325, total_loss: 4.977602005004883
training step: 41326, total_loss: 6.13510799407959
training step: 41327, total_loss: 4.617671966552734
training step: 41328, total_loss: 4.178739547729492
training step: 41329, total_loss: 4.48234748840332
training step: 41330, total_loss: 6.15411376953125
training step: 41331, total_loss: 2.9461076259613037
training step: 41332, total_loss: 5.180960655212402
training step: 41333, total_loss: 5.181447982788086
training step: 41334, total_loss: 3.1316380500793457
training step: 41335, total_loss: 3.298882007598877
training step: 41336, total_loss: 4.329708099365234
training step: 41337, total_loss: 3.1974005699157715
training step: 41338, total_loss: 4.537424087524414
training step: 41339, total_loss: 3.460378646850586
training step: 41340, total_loss: 3.647271156311035
training step: 41341, total_loss: 5.572290897369385
training step: 41342, total_loss: 4.0851216316223145
training step: 41343, total_loss: 3.687849283218384
training step: 41344, total_loss: 3.0472116470336914
training step: 41345, total_loss: 3.207797050476074
training step: 41346, total_loss: 3.3624143600463867
training step: 41347, total_loss: 2.235349655151367
training step: 41348, total_loss: 2.599740982055664
training step: 41349, total_loss: 4.959636688232422
training step: 41350, total_loss: 4.028470039367676
training step: 41351, total_loss: 5.601919651031494
training step: 41352, total_loss: 3.730051040649414
training step: 41353, total_loss: 3.7805681228637695
training step: 41354, total_loss: 4.946760177612305
training step: 41355, total_loss: 5.774625301361084
training step: 41356, total_loss: 5.5406813621521
training step: 41357, total_loss: 3.087998151779175
training step: 41358, total_loss: 3.44796085357666
training step: 41359, total_loss: 5.509275436401367
training step: 41360, total_loss: 4.543705463409424
training step: 41361, total_loss: 4.289187908172607
training step: 41362, total_loss: 4.1385040283203125
training step: 41363, total_loss: 5.236993789672852
training step: 41364, total_loss: 5.891544342041016
training step: 41365, total_loss: 2.784931182861328
training step: 41366, total_loss: 3.9608774185180664
training step: 41367, total_loss: 3.6548566818237305
training step: 41368, total_loss: 3.520918846130371
training step: 41369, total_loss: 3.7705512046813965
training step: 41370, total_loss: 4.420040607452393
training step: 41371, total_loss: 3.0954508781433105
training step: 41372, total_loss: 4.081637382507324
training step: 41373, total_loss: 2.4081623554229736
training step: 41374, total_loss: 2.5273549556732178
training step: 41375, total_loss: 3.9477181434631348
training step: 41376, total_loss: 5.501181602478027
training step: 41377, total_loss: 6.752835750579834
training step: 41378, total_loss: 4.307510852813721
training step: 41379, total_loss: 4.310014724731445
training step: 41380, total_loss: 3.610665798187256
training step: 41381, total_loss: 4.490828514099121
training step: 41382, total_loss: 5.330350399017334
training step: 41383, total_loss: 5.28994607925415
training step: 41384, total_loss: 4.9230217933654785
training step: 41385, total_loss: 3.6907505989074707
training step: 41386, total_loss: 4.621349334716797
training step: 41387, total_loss: 4.048490524291992
training step: 41388, total_loss: 4.376499176025391
training step: 41389, total_loss: 4.232734680175781
training step: 41390, total_loss: 3.792102098464966
training step: 41391, total_loss: 5.435009956359863
training step: 41392, total_loss: 4.369045257568359
training step: 41393, total_loss: 3.801772117614746
training step: 41394, total_loss: 6.500635147094727
training step: 41395, total_loss: 5.03372859954834
training step: 41396, total_loss: 5.043634414672852
training step: 41397, total_loss: 2.88746976852417
training step: 41398, total_loss: 5.008103370666504
training step: 41399, total_loss: 5.582884311676025
training step: 41400, total_loss: 5.928920745849609
training step: 41401, total_loss: 5.3989973068237305
training step: 41402, total_loss: 5.554256439208984
training step: 41403, total_loss: 6.775815486907959
training step: 41404, total_loss: 4.127392768859863
training step: 41405, total_loss: 3.5191779136657715
training step: 41406, total_loss: 4.373130798339844
training step: 41407, total_loss: 2.7044029235839844
training step: 41408, total_loss: 4.607235908508301
training step: 41409, total_loss: 6.0301833152771
training step: 41410, total_loss: 3.7150940895080566
training step: 41411, total_loss: 4.628853797912598
training step: 41412, total_loss: 5.254334449768066
training step: 41413, total_loss: 3.0312228202819824
training step: 41414, total_loss: 5.375964164733887
training step: 41415, total_loss: 3.149144411087036
training step: 41416, total_loss: 4.962462425231934
training step: 41417, total_loss: 5.296753883361816
training step: 41418, total_loss: 5.193402290344238
training step: 41419, total_loss: 3.676982879638672
training step: 41420, total_loss: 4.911199569702148
training step: 41421, total_loss: 4.947056770324707
training step: 41422, total_loss: 6.323786735534668
training step: 41423, total_loss: 4.853616714477539
training step: 41424, total_loss: 4.126912593841553
training step: 41425, total_loss: 2.493586540222168
training step: 41426, total_loss: 5.212285041809082
training step: 41427, total_loss: 4.366858959197998
training step: 41428, total_loss: 3.319096088409424
training step: 41429, total_loss: 4.7671356201171875
training step: 41430, total_loss: 5.263713359832764
training step: 41431, total_loss: 4.910121917724609
training step: 41432, total_loss: 2.957980155944824
training step: 41433, total_loss: 4.620700359344482
training step: 41434, total_loss: 3.8732218742370605
training step: 41435, total_loss: 5.337860584259033
training step: 41436, total_loss: 3.5936107635498047
training step: 41437, total_loss: 4.656845569610596
training step: 41438, total_loss: 4.588373184204102
training step: 41439, total_loss: 4.503543853759766
training step: 41440, total_loss: 3.9961585998535156
training step: 41441, total_loss: 3.9233827590942383
training step: 41442, total_loss: 4.015319347381592
training step: 41443, total_loss: 4.448338985443115
training step: 41444, total_loss: 3.302361011505127
training step: 41445, total_loss: 4.12808084487915
training step: 41446, total_loss: 5.23789119720459
training step: 41447, total_loss: 4.429238319396973
training step: 41448, total_loss: 4.830250263214111
training step: 41449, total_loss: 5.5622639656066895
training step: 41450, total_loss: 4.605648994445801
training step: 41451, total_loss: 4.951678276062012
training step: 41452, total_loss: 3.845139980316162
training step: 41453, total_loss: 3.9701156616210938
training step: 41454, total_loss: 4.641125679016113
training step: 41455, total_loss: 4.052942276000977
training step: 41456, total_loss: 4.480236053466797
training step: 41457, total_loss: 5.071474552154541
training step: 41458, total_loss: 4.603065490722656
training step: 41459, total_loss: 5.024763107299805
training step: 41460, total_loss: 4.135739803314209
training step: 41461, total_loss: 7.4102044105529785
training step: 41462, total_loss: 3.164187431335449
training step: 41463, total_loss: 4.667669773101807
training step: 41464, total_loss: 6.683684825897217
training step: 41465, total_loss: 4.813225269317627
training step: 41466, total_loss: 4.715424537658691
training step: 41467, total_loss: 4.420022487640381
training step: 41468, total_loss: 4.127903938293457
training step: 41469, total_loss: 3.3494601249694824
training step: 41470, total_loss: 3.7876009941101074
training step: 41471, total_loss: 5.486408233642578
training step: 41472, total_loss: 4.572994232177734
training step: 41473, total_loss: 3.9564669132232666
training step: 41474, total_loss: 4.990116596221924
training step: 41475, total_loss: 4.4315643310546875
training step: 41476, total_loss: 5.13707160949707
training step: 41477, total_loss: 5.089845657348633
training step: 41478, total_loss: 4.830284595489502
training step: 41479, total_loss: 4.537680625915527
training step: 41480, total_loss: 4.628583908081055
training step: 41481, total_loss: 4.087944984436035
training step: 41482, total_loss: 3.1715455055236816
training step: 41483, total_loss: 4.376827239990234
training step: 41484, total_loss: 6.05826997756958
training step: 41485, total_loss: 5.21116828918457
training step: 41486, total_loss: 5.87545108795166
training step: 41487, total_loss: 4.493727684020996
training step: 41488, total_loss: 4.201183319091797
training step: 41489, total_loss: 4.875249862670898
training step: 41490, total_loss: 4.381596565246582
training step: 41491, total_loss: 5.01352071762085
training step: 41492, total_loss: 3.5189099311828613
training step: 41493, total_loss: 4.687289714813232
training step: 41494, total_loss: 5.179103851318359
training step: 41495, total_loss: 1.4261656999588013
training step: 41496, total_loss: 5.471199989318848
training step: 41497, total_loss: 3.7907299995422363
training step: 41498, total_loss: 4.66116189956665
training step: 41499, total_loss: 5.1404924392700195
training step: 41500, total_loss: 2.6551191806793213
training step: 41501, total_loss: 3.9921419620513916
training step: 41502, total_loss: 4.896457672119141
training step: 41503, total_loss: 6.769561767578125
training step: 41504, total_loss: 5.774308681488037
training step: 41505, total_loss: 4.775482177734375
training step: 41506, total_loss: 5.658164978027344
training step: 41507, total_loss: 4.214481830596924
training step: 41508, total_loss: 5.104643821716309
training step: 41509, total_loss: 5.439537525177002
training step: 41510, total_loss: 4.471413612365723
training step: 41511, total_loss: 2.7836034297943115
training step: 41512, total_loss: 4.333438396453857
training step: 41513, total_loss: 4.153491497039795
training step: 41514, total_loss: 4.465151309967041
training step: 41515, total_loss: 4.162917613983154
training step: 41516, total_loss: 5.6118645668029785
training step: 41517, total_loss: 4.045135974884033
training step: 41518, total_loss: 4.7797160148620605
training step: 41519, total_loss: 3.8569860458374023
training step: 41520, total_loss: 3.290708541870117
training step: 41521, total_loss: 4.40408992767334
training step: 41522, total_loss: 5.76230525970459
training step: 41523, total_loss: 3.763026714324951
training step: 41524, total_loss: 3.8208165168762207
training step: 41525, total_loss: 4.257640361785889
training step: 41526, total_loss: 4.748395919799805
training step: 41527, total_loss: 4.260143756866455
training step: 41528, total_loss: 5.092742919921875
training step: 41529, total_loss: 3.4232754707336426
training step: 41530, total_loss: 4.978359699249268
training step: 41531, total_loss: 4.088555335998535
training step: 41532, total_loss: 3.6210222244262695
training step: 41533, total_loss: 3.4031906127929688
training step: 41534, total_loss: 5.044119834899902
training step: 41535, total_loss: 4.446892738342285
training step: 41536, total_loss: 2.510382652282715
training step: 41537, total_loss: 4.774877548217773
training step: 41538, total_loss: 5.137240886688232
training step: 41539, total_loss: 4.394497871398926
training step: 41540, total_loss: 3.4647581577301025
training step: 41541, total_loss: 4.819923400878906
training step: 41542, total_loss: 1.8224525451660156
training step: 41543, total_loss: 6.437032699584961
training step: 41544, total_loss: 1.461677074432373
training step: 41545, total_loss: 2.976487636566162
training step: 41546, total_loss: 4.0791730880737305
training step: 41547, total_loss: 4.5730414390563965
training step: 41548, total_loss: 4.662047386169434
training step: 41549, total_loss: 3.7123141288757324
training step: 41550, total_loss: 3.920891046524048
training step: 41551, total_loss: 3.2477216720581055
training step: 41552, total_loss: 3.301164150238037
training step: 41553, total_loss: 4.268916130065918
training step: 41554, total_loss: 4.543709754943848
training step: 41555, total_loss: 2.48335337638855
training step: 41556, total_loss: 3.191718578338623
training step: 41557, total_loss: 5.371572494506836
training step: 41558, total_loss: 5.129451751708984
training step: 41559, total_loss: 3.0966029167175293
training step: 41560, total_loss: 4.22096061706543
training step: 41561, total_loss: 3.0646719932556152
training step: 41562, total_loss: 4.831911087036133
training step: 41563, total_loss: 5.708417892456055
training step: 41564, total_loss: 4.220450401306152
training step: 41565, total_loss: 2.9847822189331055
training step: 41566, total_loss: 4.740758895874023
training step: 41567, total_loss: 1.5169192552566528
training step: 41568, total_loss: 4.966652870178223
training step: 41569, total_loss: 3.495030403137207
training step: 41570, total_loss: 4.124105453491211
training step: 41571, total_loss: 4.051954746246338
training step: 41572, total_loss: 4.253046989440918
training step: 41573, total_loss: 4.496315002441406
training step: 41574, total_loss: 6.032892227172852
training step: 41575, total_loss: 5.978386878967285
training step: 41576, total_loss: 4.994938373565674
training step: 41577, total_loss: 4.617781639099121
training step: 41578, total_loss: 4.615971565246582
training step: 41579, total_loss: 5.261621475219727
training step: 41580, total_loss: 3.8717660903930664
training step: 41581, total_loss: 3.812107563018799
training step: 41582, total_loss: 4.50919246673584
training step: 41583, total_loss: 3.3175048828125
training step: 41584, total_loss: 4.902338981628418
training step: 41585, total_loss: 4.883028030395508
training step: 41586, total_loss: 5.045814514160156
training step: 41587, total_loss: 4.947724342346191
training step: 41588, total_loss: 4.965380668640137
training step: 41589, total_loss: 3.680058240890503
training step: 41590, total_loss: 3.9792404174804688
training step: 41591, total_loss: 5.014802932739258
training step: 41592, total_loss: 4.75282096862793
training step: 41593, total_loss: 4.858395576477051
training step: 41594, total_loss: 4.631103992462158
training step: 41595, total_loss: 5.004833221435547
training step: 41596, total_loss: 5.5046844482421875
training step: 41597, total_loss: 3.2814910411834717
training step: 41598, total_loss: 5.434976577758789
training step: 41599, total_loss: 3.4164817333221436
training step: 41600, total_loss: 3.67215633392334
training step: 41601, total_loss: 7.308896064758301
training step: 41602, total_loss: 5.14970588684082
training step: 41603, total_loss: 4.231410026550293
training step: 41604, total_loss: 4.263653755187988
training step: 41605, total_loss: 3.678891181945801
training step: 41606, total_loss: 5.9976935386657715
training step: 41607, total_loss: 4.5865936279296875
training step: 41608, total_loss: 4.958205223083496
training step: 41609, total_loss: 4.461897373199463
training step: 41610, total_loss: 4.143222332000732
training step: 41611, total_loss: 3.2381467819213867
training step: 41612, total_loss: 4.216469764709473
training step: 41613, total_loss: 4.317351341247559
training step: 41614, total_loss: 4.98145866394043
training step: 41615, total_loss: 4.317883491516113
training step: 41616, total_loss: 3.8233656883239746
training step: 41617, total_loss: 4.7873735427856445
training step: 41618, total_loss: 5.113141059875488
training step: 41619, total_loss: 4.527482509613037
training step: 41620, total_loss: 4.153963565826416
training step: 41621, total_loss: 3.003779649734497
training step: 41622, total_loss: 3.4871773719787598
training step: 41623, total_loss: 4.509789943695068
training step: 41624, total_loss: 4.566278457641602
training step: 41625, total_loss: 4.627965927124023
training step: 41626, total_loss: 4.45784854888916
training step: 41627, total_loss: 4.810163974761963
training step: 41628, total_loss: 3.4021949768066406
training step: 41629, total_loss: 5.654871940612793
training step: 41630, total_loss: 4.934341907501221
training step: 41631, total_loss: 3.217029571533203
training step: 41632, total_loss: 6.305233001708984
training step: 41633, total_loss: 2.6082634925842285
training step: 41634, total_loss: 4.795305252075195
training step: 41635, total_loss: 4.578049659729004
training step: 41636, total_loss: 2.790508270263672
training step: 41637, total_loss: 2.9639010429382324
training step: 41638, total_loss: 5.536983013153076
training step: 41639, total_loss: 3.1237704753875732
training step: 41640, total_loss: 5.025187015533447
training step: 41641, total_loss: 3.0423901081085205
training step: 41642, total_loss: 2.6380386352539062
training step: 41643, total_loss: 4.438512802124023
training step: 41644, total_loss: 5.108457565307617
training step: 41645, total_loss: 4.322211265563965
training step: 41646, total_loss: 2.2799062728881836
training step: 41647, total_loss: 6.443979263305664
training step: 41648, total_loss: 3.864811420440674
training step: 41649, total_loss: 7.243756294250488
training step: 41650, total_loss: 4.338309288024902
training step: 41651, total_loss: 3.99250864982605
training step: 41652, total_loss: 4.062990188598633
training step: 41653, total_loss: 2.754929542541504
training step: 41654, total_loss: 5.090997695922852
training step: 41655, total_loss: 3.8902649879455566
training step: 41656, total_loss: 4.376654624938965
training step: 41657, total_loss: 3.0979301929473877
training step: 41658, total_loss: 4.774802207946777
training step: 41659, total_loss: 3.2770628929138184
training step: 41660, total_loss: 4.901882648468018
training step: 41661, total_loss: 5.8460588455200195
training step: 41662, total_loss: 3.954338550567627
training step: 41663, total_loss: 5.9240007400512695
training step: 41664, total_loss: 4.806221961975098
training step: 41665, total_loss: 4.613048553466797
training step: 41666, total_loss: 3.9842934608459473
training step: 41667, total_loss: 4.365196228027344
training step: 41668, total_loss: 4.74637508392334
training step: 41669, total_loss: 5.260092258453369
training step: 41670, total_loss: 3.0937581062316895
training step: 41671, total_loss: 3.7531344890594482
training step: 41672, total_loss: 1.3395501375198364
training step: 41673, total_loss: 5.260576248168945
training step: 41674, total_loss: 4.9448347091674805
training step: 41675, total_loss: 5.478574752807617
training step: 41676, total_loss: 4.658697128295898
training step: 41677, total_loss: 5.148193359375
training step: 41678, total_loss: 4.233477592468262
training step: 41679, total_loss: 4.409367561340332
training step: 41680, total_loss: 3.6227874755859375
training step: 41681, total_loss: 5.2489728927612305
training step: 41682, total_loss: 6.240870952606201
training step: 41683, total_loss: 4.738234996795654
training step: 41684, total_loss: 5.376283168792725
training step: 41685, total_loss: 3.446211338043213
training step: 41686, total_loss: 4.1494340896606445
training step: 41687, total_loss: 5.645017623901367
training step: 41688, total_loss: 4.1893415451049805
training step: 41689, total_loss: 3.7139456272125244
training step: 41690, total_loss: 3.1699044704437256
training step: 41691, total_loss: 3.9933273792266846
training step: 41692, total_loss: 5.753787994384766
training step: 41693, total_loss: 4.869548320770264
training step: 41694, total_loss: 3.939363479614258
training step: 41695, total_loss: 6.618790149688721
training step: 41696, total_loss: 3.705808639526367
training step: 41697, total_loss: 5.386293411254883
training step: 41698, total_loss: 3.2774863243103027
training step: 41699, total_loss: 4.772970676422119
training step: 41700, total_loss: 4.39478063583374
training step: 41701, total_loss: 3.911562919616699
training step: 41702, total_loss: 4.918369770050049
training step: 41703, total_loss: 4.032649993896484
training step: 41704, total_loss: 3.9731907844543457
training step: 41705, total_loss: 3.969209909439087
training step: 41706, total_loss: 5.948648452758789
training step: 41707, total_loss: 4.358687877655029
training step: 41708, total_loss: 5.445120334625244
training step: 41709, total_loss: 4.138638496398926
training step: 41710, total_loss: 6.371613025665283
training step: 41711, total_loss: 4.999039649963379
training step: 41712, total_loss: 4.089755058288574
training step: 41713, total_loss: 4.496115684509277
training step: 41714, total_loss: 5.105203628540039
training step: 41715, total_loss: 4.09326171875
training step: 41716, total_loss: 5.735261917114258
training step: 41717, total_loss: 5.022640228271484
training step: 41718, total_loss: 2.9709057807922363
training step: 41719, total_loss: 3.9074137210845947
training step: 41720, total_loss: 5.391618251800537
training step: 41721, total_loss: 4.897377014160156
training step: 41722, total_loss: 4.863897800445557
training step: 41723, total_loss: 3.2781643867492676
training step: 41724, total_loss: 3.7412824630737305
training step: 41725, total_loss: 6.9414167404174805
training step: 41726, total_loss: 4.738125801086426
training step: 41727, total_loss: 1.0740594863891602
training step: 41728, total_loss: 3.9722514152526855
training step: 41729, total_loss: 4.434541702270508
training step: 41730, total_loss: 6.231693267822266
training step: 41731, total_loss: 2.5407071113586426
training step: 41732, total_loss: 4.945801258087158
training step: 41733, total_loss: 4.688678741455078
training step: 41734, total_loss: 5.287317276000977
training step: 41735, total_loss: 5.174567699432373
training step: 41736, total_loss: 5.876785755157471
training step: 41737, total_loss: 5.265798568725586
training step: 41738, total_loss: 5.410516738891602
training step: 41739, total_loss: 2.725233793258667
training step: 41740, total_loss: 3.515256404876709
training step: 41741, total_loss: 3.763962984085083
training step: 41742, total_loss: 5.30569314956665
training step: 41743, total_loss: 5.093213081359863
training step: 41744, total_loss: 3.7375874519348145
training step: 41745, total_loss: 4.4357686042785645
training step: 41746, total_loss: 5.090569972991943
training step: 41747, total_loss: 4.662933349609375
training step: 41748, total_loss: 4.640012264251709
training step: 41749, total_loss: 3.328418493270874
training step: 41750, total_loss: 3.9454565048217773
training step: 41751, total_loss: 5.093775749206543
training step: 41752, total_loss: 3.9437718391418457
training step: 41753, total_loss: 3.3431882858276367
training step: 41754, total_loss: 2.749267816543579
training step: 41755, total_loss: 4.3555097579956055
training step: 41756, total_loss: 4.571690559387207
training step: 41757, total_loss: 3.9348387718200684
training step: 41758, total_loss: 4.078697681427002
training step: 41759, total_loss: 4.519392967224121
training step: 41760, total_loss: 2.6565263271331787
training step: 41761, total_loss: 4.217434883117676
training step: 41762, total_loss: 3.923776149749756
training step: 41763, total_loss: 4.0189080238342285
training step: 41764, total_loss: 1.4182847738265991
training step: 41765, total_loss: 5.013741970062256
training step: 41766, total_loss: 5.774970531463623
training step: 41767, total_loss: 5.591625213623047
training step: 41768, total_loss: 4.964336395263672
training step: 41769, total_loss: 4.071461200714111
training step: 41770, total_loss: 4.249301910400391
training step: 41771, total_loss: 3.542250156402588
training step: 41772, total_loss: 4.239692687988281
training step: 41773, total_loss: 5.239701747894287
training step: 41774, total_loss: 4.243943214416504
training step: 41775, total_loss: 4.770380020141602
training step: 41776, total_loss: 4.168220520019531
training step: 41777, total_loss: 4.336366176605225
training step: 41778, total_loss: 4.55318021774292
training step: 41779, total_loss: 3.749638080596924
training step: 41780, total_loss: 4.38754940032959
training step: 41781, total_loss: 3.995279312133789
training step: 41782, total_loss: 4.276056289672852
training step: 41783, total_loss: 4.456050872802734
training step: 41784, total_loss: 4.913247108459473
training step: 41785, total_loss: 4.343351364135742
training step: 41786, total_loss: 4.09312629699707
training step: 41787, total_loss: 4.400786876678467
training step: 41788, total_loss: 3.4334917068481445
training step: 41789, total_loss: 3.072474718093872
training step: 41790, total_loss: 4.144731521606445
training step: 41791, total_loss: 4.195752143859863
training step: 41792, total_loss: 5.256117343902588
training step: 41793, total_loss: 3.6162571907043457
training step: 41794, total_loss: 2.5237927436828613
training step: 41795, total_loss: 3.212327241897583
training step: 41796, total_loss: 4.675436019897461
training step: 41797, total_loss: 4.319330215454102
training step: 41798, total_loss: 3.7380735874176025
training step: 41799, total_loss: 3.848505973815918
training step: 41800, total_loss: 6.146297454833984
training step: 41801, total_loss: 4.239027500152588
training step: 41802, total_loss: 5.342524528503418
training step: 41803, total_loss: 3.2136428356170654
training step: 41804, total_loss: 4.769865989685059
training step: 41805, total_loss: 3.1572303771972656
training step: 41806, total_loss: 6.287149906158447
training step: 41807, total_loss: 5.117985725402832
training step: 41808, total_loss: 4.869865894317627
training step: 41809, total_loss: 5.286492347717285
training step: 41810, total_loss: 4.856057643890381
training step: 41811, total_loss: 4.6573309898376465
training step: 41812, total_loss: 3.140348434448242
training step: 41813, total_loss: 4.71821403503418
training step: 41814, total_loss: 4.379025459289551
training step: 41815, total_loss: 3.6926326751708984
training step: 41816, total_loss: 4.199165344238281
training step: 41817, total_loss: 4.6141815185546875
training step: 41818, total_loss: 3.099893569946289
training step: 41819, total_loss: 2.908456325531006
training step: 41820, total_loss: 4.981621265411377
training step: 41821, total_loss: 4.3882551193237305
training step: 41822, total_loss: 3.9014358520507812
training step: 41823, total_loss: 4.755195617675781
training step: 41824, total_loss: 5.0208892822265625
training step: 41825, total_loss: 5.969873428344727
training step: 41826, total_loss: 4.787013530731201
training step: 41827, total_loss: 5.420568466186523
training step: 41828, total_loss: 4.3349199295043945
training step: 41829, total_loss: 4.117671966552734
training step: 41830, total_loss: 5.587668418884277
training step: 41831, total_loss: 4.349563121795654
training step: 41832, total_loss: 3.751183032989502
training step: 41833, total_loss: 3.473522186279297
training step: 41834, total_loss: 3.710824489593506
training step: 41835, total_loss: 2.3064675331115723
training step: 41836, total_loss: 4.708154678344727
training step: 41837, total_loss: 4.088327407836914
training step: 41838, total_loss: 4.864651203155518
training step: 41839, total_loss: 5.073156356811523
training step: 41840, total_loss: 4.842197418212891
training step: 41841, total_loss: 4.257667541503906
training step: 41842, total_loss: 4.308017730712891
training step: 41843, total_loss: 4.917691707611084
training step: 41844, total_loss: 4.9683074951171875
training step: 41845, total_loss: 4.322932243347168
training step: 41846, total_loss: 4.1777729988098145
training step: 41847, total_loss: 4.704108238220215
training step: 41848, total_loss: 4.737460136413574
training step: 41849, total_loss: 2.6597256660461426
training step: 41850, total_loss: 4.0730061531066895
training step: 41851, total_loss: 3.1422510147094727
training step: 41852, total_loss: 5.016853332519531
training step: 41853, total_loss: 3.187462329864502
training step: 41854, total_loss: 4.468414306640625
training step: 41855, total_loss: 4.523061752319336
training step: 41856, total_loss: 3.531033515930176
training step: 41857, total_loss: 3.7097153663635254
training step: 41858, total_loss: 5.143230438232422
training step: 41859, total_loss: 4.463788986206055
training step: 41860, total_loss: 4.949351787567139
training step: 41861, total_loss: 4.991790771484375
training step: 41862, total_loss: 3.7210540771484375
training step: 41863, total_loss: 2.890488624572754
training step: 41864, total_loss: 5.126380443572998
training step: 41865, total_loss: 3.966118812561035
training step: 41866, total_loss: 4.255859851837158
training step: 41867, total_loss: 6.413320541381836
training step: 41868, total_loss: 4.150116443634033
training step: 41869, total_loss: 3.858748197555542
training step: 41870, total_loss: 4.744120121002197
training step: 41871, total_loss: 4.840031623840332
training step: 41872, total_loss: 3.4286534786224365
training step: 41873, total_loss: 3.9874818325042725
training step: 41874, total_loss: 4.7646989822387695
training step: 41875, total_loss: 5.798788547515869
training step: 41876, total_loss: 3.7396790981292725
training step: 41877, total_loss: 3.9496889114379883
training step: 41878, total_loss: 4.463807582855225
training step: 41879, total_loss: 4.696000099182129
training step: 41880, total_loss: 4.373340606689453
training step: 41881, total_loss: 1.1561942100524902
training step: 41882, total_loss: 4.896090507507324
training step: 41883, total_loss: 5.439993381500244
training step: 41884, total_loss: 4.105796813964844
training step: 41885, total_loss: 4.90608024597168
training step: 41886, total_loss: 2.635446548461914
training step: 41887, total_loss: 5.434131145477295
training step: 41888, total_loss: 4.801905632019043
training step: 41889, total_loss: 4.0999579429626465
training step: 41890, total_loss: 4.605583667755127
training step: 41891, total_loss: 3.936232566833496
training step: 41892, total_loss: 2.85030198097229
training step: 41893, total_loss: 4.574432373046875
training step: 41894, total_loss: 4.905318260192871
training step: 41895, total_loss: 4.61739444732666
training step: 41896, total_loss: 4.53450345993042
training step: 41897, total_loss: 6.534043312072754
training step: 41898, total_loss: 5.845551490783691
training step: 41899, total_loss: 5.01798677444458
training step: 41900, total_loss: 1.3639898300170898
training step: 41901, total_loss: 5.823931694030762
training step: 41902, total_loss: 3.4196009635925293
training step: 41903, total_loss: 4.750164985656738
training step: 41904, total_loss: 2.5964951515197754
training step: 41905, total_loss: 4.96108865737915
training step: 41906, total_loss: 3.16534161567688
training step: 41907, total_loss: 4.436738014221191
training step: 41908, total_loss: 5.1463847160339355
training step: 41909, total_loss: 3.5559935569763184
training step: 41910, total_loss: 6.071959018707275
training step: 41911, total_loss: 5.018243789672852
training step: 41912, total_loss: 4.786103248596191
training step: 41913, total_loss: 6.768647193908691
training step: 41914, total_loss: 3.364393711090088
training step: 41915, total_loss: 4.705963134765625
training step: 41916, total_loss: 3.1346983909606934
training step: 41917, total_loss: 5.428593158721924
training step: 41918, total_loss: 5.403450012207031
training step: 41919, total_loss: 4.405470371246338
training step: 41920, total_loss: 3.4022581577301025
training step: 41921, total_loss: 5.095771789550781
training step: 41922, total_loss: 4.5932464599609375
training step: 41923, total_loss: 3.9611926078796387
training step: 41924, total_loss: 3.11431884765625
training step: 41925, total_loss: 4.533661842346191
training step: 41926, total_loss: 1.1741807460784912
training step: 41927, total_loss: 5.857976913452148
training step: 41928, total_loss: 3.447267770767212
training step: 41929, total_loss: 3.7259469032287598
training step: 41930, total_loss: 4.480818748474121
training step: 41931, total_loss: 4.022332668304443
training step: 41932, total_loss: 4.220755577087402
training step: 41933, total_loss: 4.061001777648926
training step: 41934, total_loss: 4.158766746520996
training step: 41935, total_loss: 1.5224823951721191
training step: 41936, total_loss: 3.315263271331787
training step: 41937, total_loss: 4.30650520324707
training step: 41938, total_loss: 2.4072556495666504
training step: 41939, total_loss: 4.338277816772461
training step: 41940, total_loss: 3.7224066257476807
training step: 41941, total_loss: 4.567530632019043
training step: 41942, total_loss: 4.975092887878418
training step: 41943, total_loss: 5.316878318786621
training step: 41944, total_loss: 2.2983622550964355
training step: 41945, total_loss: 4.572396278381348
training step: 41946, total_loss: 4.498814582824707
training step: 41947, total_loss: 2.483081340789795
training step: 41948, total_loss: 5.711615562438965
training step: 41949, total_loss: 5.085007190704346
training step: 41950, total_loss: 4.922747611999512
training step: 41951, total_loss: 5.148351192474365
training step: 41952, total_loss: 5.324294090270996
training step: 41953, total_loss: 4.736766338348389
training step: 41954, total_loss: 5.709566116333008
training step: 41955, total_loss: 5.174230098724365
training step: 41956, total_loss: 2.638005495071411
training step: 41957, total_loss: 5.628541946411133
training step: 41958, total_loss: 3.9734272956848145
training step: 41959, total_loss: 4.058960437774658
training step: 41960, total_loss: 2.4445960521698
training step: 41961, total_loss: 4.259335041046143
training step: 41962, total_loss: 4.5404157638549805
training step: 41963, total_loss: 4.344487190246582
training step: 41964, total_loss: 3.045224666595459
training step: 41965, total_loss: 1.001115083694458
training step: 41966, total_loss: 0.9782247543334961
training step: 41967, total_loss: 3.6386377811431885
training step: 41968, total_loss: 1.0078858137130737
training step: 41969, total_loss: 5.3788676261901855
training step: 41970, total_loss: 5.170733451843262
training step: 41971, total_loss: 4.367807388305664
training step: 41972, total_loss: 3.59182071685791
training step: 41973, total_loss: 3.1456146240234375
training step: 41974, total_loss: 6.108116149902344
training step: 41975, total_loss: 3.951205015182495
training step: 41976, total_loss: 4.5942840576171875
training step: 41977, total_loss: 3.657695770263672
training step: 41978, total_loss: 5.388370037078857
training step: 41979, total_loss: 4.665073394775391
training step: 41980, total_loss: 4.335773468017578
training step: 41981, total_loss: 5.028668403625488
training step: 41982, total_loss: 3.4719338417053223
training step: 41983, total_loss: 6.212316989898682
training step: 41984, total_loss: 4.267970561981201
training step: 41985, total_loss: 4.816262245178223
training step: 41986, total_loss: 2.4494290351867676
training step: 41987, total_loss: 4.348667621612549
training step: 41988, total_loss: 5.228086471557617
training step: 41989, total_loss: 3.443085193634033
training step: 41990, total_loss: 3.776824951171875
training step: 41991, total_loss: 3.450878620147705
training step: 41992, total_loss: 6.422792911529541
training step: 41993, total_loss: 4.66401481628418
training step: 41994, total_loss: 4.068615913391113
training step: 41995, total_loss: 6.049332618713379
training step: 41996, total_loss: 3.163710594177246
training step: 41997, total_loss: 4.98979377746582
training step: 41998, total_loss: 3.656322956085205
training step: 41999, total_loss: 6.12116813659668
training step: 42000, total_loss: 5.1875200271606445
training step: 42001, total_loss: 3.1668620109558105
training step: 42002, total_loss: 6.2828168869018555
training step: 42003, total_loss: 4.000636577606201
training step: 42004, total_loss: 4.625978946685791
training step: 42005, total_loss: 4.765721797943115
training step: 42006, total_loss: 3.917818546295166
training step: 42007, total_loss: 3.7570791244506836
training step: 42008, total_loss: 5.06586217880249
training step: 42009, total_loss: 3.970217704772949
training step: 42010, total_loss: 4.244655132293701
training step: 42011, total_loss: 5.415459632873535
training step: 42012, total_loss: 5.0839738845825195
training step: 42013, total_loss: 6.382319927215576
training step: 42014, total_loss: 5.113461494445801
training step: 42015, total_loss: 2.4239864349365234
training step: 42016, total_loss: 4.886775970458984
training step: 42017, total_loss: 4.643301010131836
training step: 42018, total_loss: 4.959348201751709
training step: 42019, total_loss: 4.882366180419922
training step: 42020, total_loss: 5.636186599731445
training step: 42021, total_loss: 4.685707092285156
training step: 42022, total_loss: 4.793206691741943
training step: 42023, total_loss: 4.516247749328613
training step: 42024, total_loss: 4.159696102142334
training step: 42025, total_loss: 3.707636833190918
training step: 42026, total_loss: 5.3600616455078125
training step: 42027, total_loss: 5.3828840255737305
training step: 42028, total_loss: 4.446433067321777
training step: 42029, total_loss: 5.0891876220703125
training step: 42030, total_loss: 3.6525044441223145
training step: 42031, total_loss: 4.805107116699219
training step: 42032, total_loss: 4.490602016448975
training step: 42033, total_loss: 1.0774039030075073
training step: 42034, total_loss: 7.062701225280762
training step: 42035, total_loss: 4.240694999694824
training step: 42036, total_loss: 4.874053001403809
training step: 42037, total_loss: 5.56195592880249
training step: 42038, total_loss: 0.9920018911361694
training step: 42039, total_loss: 4.695256233215332
training step: 42040, total_loss: 4.146927833557129
training step: 42041, total_loss: 4.713939189910889
training step: 42042, total_loss: 6.5177435874938965
training step: 42043, total_loss: 4.859546184539795
training step: 42044, total_loss: 3.142604351043701
training step: 42045, total_loss: 3.176297187805176
training step: 42046, total_loss: 5.180286407470703
training step: 42047, total_loss: 4.288760185241699
training step: 42048, total_loss: 5.799923896789551
training step: 42049, total_loss: 3.551070213317871
training step: 42050, total_loss: 5.688026428222656
training step: 42051, total_loss: 3.5577151775360107
training step: 42052, total_loss: 5.950468063354492
training step: 42053, total_loss: 4.191747665405273
training step: 42054, total_loss: 3.2202200889587402
training step: 42055, total_loss: 5.786490440368652
training step: 42056, total_loss: 5.553230285644531
training step: 42057, total_loss: 4.8314666748046875
training step: 42058, total_loss: 1.1746468544006348
training step: 42059, total_loss: 4.5732831954956055
training step: 42060, total_loss: 3.984447956085205
training step: 42061, total_loss: 2.4774374961853027
training step: 42062, total_loss: 4.828936576843262
training step: 42063, total_loss: 2.570399761199951
training step: 42064, total_loss: 5.67945671081543
training step: 42065, total_loss: 3.9307737350463867
training step: 42066, total_loss: 4.710778713226318
training step: 42067, total_loss: 4.594520568847656
training step: 42068, total_loss: 4.113454818725586
training step: 42069, total_loss: 5.033294677734375
training step: 42070, total_loss: 5.293247699737549
training step: 42071, total_loss: 3.910897731781006
training step: 42072, total_loss: 4.406793594360352
training step: 42073, total_loss: 5.36964225769043
training step: 42074, total_loss: 4.181487083435059
training step: 42075, total_loss: 4.643582820892334
training step: 42076, total_loss: 0.926605224609375
training step: 42077, total_loss: 4.86712646484375
training step: 42078, total_loss: 4.064905166625977
training step: 42079, total_loss: 5.586997985839844
training step: 42080, total_loss: 4.851858139038086
training step: 42081, total_loss: 5.315279960632324
training step: 42082, total_loss: 4.728947639465332
training step: 42083, total_loss: 1.0055959224700928
training step: 42084, total_loss: 3.3038339614868164
training step: 42085, total_loss: 2.1790971755981445
training step: 42086, total_loss: 3.8019866943359375
training step: 42087, total_loss: 5.963912487030029
training step: 42088, total_loss: 5.100867748260498
training step: 42089, total_loss: 4.910974025726318
training step: 42090, total_loss: 4.969329357147217
training step: 42091, total_loss: 4.804281234741211
training step: 42092, total_loss: 1.3776243925094604
training step: 42093, total_loss: 5.66896390914917
training step: 42094, total_loss: 4.230645179748535
training step: 42095, total_loss: 5.475528717041016
training step: 42096, total_loss: 2.6666369438171387
training step: 42097, total_loss: 4.954355716705322
training step: 42098, total_loss: 4.667173862457275
training step: 42099, total_loss: 3.7317700386047363
training step: 42100, total_loss: 4.79233455657959
training step: 42101, total_loss: 4.235015869140625
training step: 42102, total_loss: 4.782207489013672
training step: 42103, total_loss: 4.252771377563477
training step: 42104, total_loss: 7.188746929168701
training step: 42105, total_loss: 4.17648458480835
training step: 42106, total_loss: 4.251218795776367
training step: 42107, total_loss: 3.905729293823242
training step: 42108, total_loss: 2.684243679046631
training step: 42109, total_loss: 4.382635593414307
training step: 42110, total_loss: 3.09672212600708
training step: 42111, total_loss: 3.744020938873291
training step: 42112, total_loss: 3.3120267391204834
training step: 42113, total_loss: 4.466361045837402
training step: 42114, total_loss: 5.0202436447143555
training step: 42115, total_loss: 4.912356376647949
training step: 42116, total_loss: 4.825776100158691
training step: 42117, total_loss: 3.912900686264038
training step: 42118, total_loss: 3.318453311920166
training step: 42119, total_loss: 3.8109512329101562
training step: 42120, total_loss: 4.552576541900635
training step: 42121, total_loss: 4.477746486663818
training step: 42122, total_loss: 2.8173508644104004
training step: 42123, total_loss: 3.6549830436706543
training step: 42124, total_loss: 4.520045280456543
training step: 42125, total_loss: 3.8110575675964355
training step: 42126, total_loss: 3.569373607635498
training step: 42127, total_loss: 3.5454652309417725
training step: 42128, total_loss: 2.7951412200927734
training step: 42129, total_loss: 4.4300336837768555
training step: 42130, total_loss: 2.852295160293579
training step: 42131, total_loss: 2.488431453704834
training step: 42132, total_loss: 3.9551472663879395
training step: 42133, total_loss: 0.9076418280601501
training step: 42134, total_loss: 4.502131462097168
training step: 42135, total_loss: 5.009748458862305
training step: 42136, total_loss: 2.474252700805664
training step: 42137, total_loss: 3.380521535873413
training step: 42138, total_loss: 3.844879150390625
training step: 42139, total_loss: 4.2256927490234375
training step: 42140, total_loss: 4.7291460037231445
training step: 42141, total_loss: 4.2504425048828125
training step: 42142, total_loss: 4.288124084472656
training step: 42143, total_loss: 4.100675582885742
training step: 42144, total_loss: 4.379744052886963
training step: 42145, total_loss: 3.6669368743896484
training step: 42146, total_loss: 6.822908401489258
training step: 42147, total_loss: 4.391663551330566
training step: 42148, total_loss: 5.518730163574219
training step: 42149, total_loss: 3.02994441986084
training step: 42150, total_loss: 4.677576541900635
training step: 42151, total_loss: 3.231294631958008
training step: 42152, total_loss: 4.81680965423584
training step: 42153, total_loss: 5.787969589233398
training step: 42154, total_loss: 3.7249486446380615
training step: 42155, total_loss: 3.6174569129943848
training step: 42156, total_loss: 3.7778091430664062
training step: 42157, total_loss: 4.762167930603027
training step: 42158, total_loss: 5.53603458404541
training step: 42159, total_loss: 4.645874977111816
training step: 42160, total_loss: 4.559143543243408
training step: 42161, total_loss: 4.026830196380615
training step: 42162, total_loss: 3.43339204788208
training step: 42163, total_loss: 4.695478439331055
training step: 42164, total_loss: 4.420604228973389
training step: 42165, total_loss: 4.1384429931640625
training step: 42166, total_loss: 2.6367571353912354
training step: 42167, total_loss: 4.835198402404785
training step: 42168, total_loss: 2.99418306350708
training step: 42169, total_loss: 2.8634886741638184
training step: 42170, total_loss: 4.350288391113281
training step: 42171, total_loss: 4.785953998565674
training step: 42172, total_loss: 3.26493501663208
training step: 42173, total_loss: 4.753724575042725
training step: 42174, total_loss: 4.146825790405273
training step: 42175, total_loss: 4.089131832122803
training step: 42176, total_loss: 5.003527641296387
training step: 42177, total_loss: 4.558682441711426
training step: 42178, total_loss: 3.8553881645202637
training step: 42179, total_loss: 4.34318733215332
training step: 42180, total_loss: 4.855248928070068
training step: 42181, total_loss: 3.719444990158081
training step: 42182, total_loss: 1.1250908374786377
training step: 42183, total_loss: 4.339293003082275
training step: 42184, total_loss: 3.5267181396484375
training step: 42185, total_loss: 4.637765407562256
training step: 42186, total_loss: 6.356165885925293
training step: 42187, total_loss: 3.9557833671569824
training step: 42188, total_loss: 2.5978078842163086
training step: 42189, total_loss: 2.5987417697906494
training step: 42190, total_loss: 3.975614547729492
training step: 42191, total_loss: 5.895586967468262
training step: 42192, total_loss: 4.441322326660156
training step: 42193, total_loss: 3.6044039726257324
training step: 42194, total_loss: 4.102700233459473
training step: 42195, total_loss: 4.274190425872803
training step: 42196, total_loss: 4.564727783203125
training step: 42197, total_loss: 4.50924015045166
training step: 42198, total_loss: 3.5023305416107178
training step: 42199, total_loss: 5.138026714324951
training step: 42200, total_loss: 4.789634704589844
training step: 42201, total_loss: 4.216757774353027
training step: 42202, total_loss: 6.060864448547363
training step: 42203, total_loss: 4.237942695617676
training step: 42204, total_loss: 2.386507034301758
training step: 42205, total_loss: 4.671710014343262
training step: 42206, total_loss: 3.8078088760375977
training step: 42207, total_loss: 2.774562358856201
training step: 42208, total_loss: 0.8778413534164429
training step: 42209, total_loss: 3.3233695030212402
training step: 42210, total_loss: 3.293036699295044
training step: 42211, total_loss: 4.821280479431152
training step: 42212, total_loss: 6.729202747344971
training step: 42213, total_loss: 2.297548294067383
training step: 42214, total_loss: 4.212392807006836
training step: 42215, total_loss: 6.213315010070801
training step: 42216, total_loss: 4.28745174407959
training step: 42217, total_loss: 6.436898231506348
training step: 42218, total_loss: 5.321025848388672
training step: 42219, total_loss: 2.910357713699341
training step: 42220, total_loss: 4.601408004760742
training step: 42221, total_loss: 3.567605972290039
training step: 42222, total_loss: 4.838103294372559
training step: 42223, total_loss: 4.131244659423828
training step: 42224, total_loss: 4.056192398071289
training step: 42225, total_loss: 3.628342628479004
training step: 42226, total_loss: 6.046610355377197
training step: 42227, total_loss: 1.7546783685684204
training step: 42228, total_loss: 3.539466142654419
training step: 42229, total_loss: 6.351253509521484
training step: 42230, total_loss: 5.97004508972168
training step: 42231, total_loss: 4.525747776031494
training step: 42232, total_loss: 3.6465210914611816
training step: 42233, total_loss: 2.9239864349365234
training step: 42234, total_loss: 6.460092544555664
training step: 42235, total_loss: 5.812823295593262
training step: 42236, total_loss: 3.969205379486084
training step: 42237, total_loss: 4.466183662414551
training step: 42238, total_loss: 2.9691410064697266
training step: 42239, total_loss: 3.6473681926727295
training step: 42240, total_loss: 3.770408868789673
training step: 42241, total_loss: 4.668443202972412
training step: 42242, total_loss: 4.436060905456543
training step: 42243, total_loss: 3.3308520317077637
training step: 42244, total_loss: 4.299863815307617
training step: 42245, total_loss: 5.000843048095703
training step: 42246, total_loss: 4.30794095993042
training step: 42247, total_loss: 4.61295747756958
training step: 42248, total_loss: 2.763573169708252
training step: 42249, total_loss: 4.52584171295166
training step: 42250, total_loss: 4.1309967041015625
training step: 42251, total_loss: 4.541818618774414
training step: 42252, total_loss: 5.351569175720215
training step: 42253, total_loss: 4.639050483703613
training step: 42254, total_loss: 5.022867202758789
training step: 42255, total_loss: 3.9005982875823975
training step: 42256, total_loss: 4.0277910232543945
training step: 42257, total_loss: 5.823180198669434
training step: 42258, total_loss: 5.294431209564209
training step: 42259, total_loss: 3.8943426609039307
training step: 42260, total_loss: 3.4682791233062744
training step: 42261, total_loss: 3.4500274658203125
training step: 42262, total_loss: 3.0727553367614746
training step: 42263, total_loss: 4.113602638244629
training step: 42264, total_loss: 3.2329721450805664
training step: 42265, total_loss: 1.2316627502441406
training step: 42266, total_loss: 1.0484634637832642
training step: 42267, total_loss: 3.2591464519500732
training step: 42268, total_loss: 3.804550886154175
training step: 42269, total_loss: 3.7460784912109375
training step: 42270, total_loss: 3.9462473392486572
training step: 42271, total_loss: 3.467728614807129
training step: 42272, total_loss: 4.452292442321777
training step: 42273, total_loss: 3.475733757019043
training step: 42274, total_loss: 3.6774275302886963
training step: 42275, total_loss: 5.500412940979004
training step: 42276, total_loss: 0.8576111793518066
training step: 42277, total_loss: 4.296507835388184
training step: 42278, total_loss: 5.467048645019531
training step: 42279, total_loss: 4.0373640060424805
training step: 42280, total_loss: 2.4056484699249268
training step: 42281, total_loss: 2.2714364528656006
training step: 42282, total_loss: 4.688111305236816
training step: 42283, total_loss: 4.264435768127441
training step: 42284, total_loss: 4.7422943115234375
training step: 42285, total_loss: 4.726208686828613
training step: 42286, total_loss: 6.637701511383057
training step: 42287, total_loss: 2.541463613510132
training step: 42288, total_loss: 4.003829479217529
training step: 42289, total_loss: 6.251519203186035
training step: 42290, total_loss: 2.001812696456909
training step: 42291, total_loss: 5.162469863891602
training step: 42292, total_loss: 4.8336076736450195
training step: 42293, total_loss: 7.17891788482666
training step: 42294, total_loss: 4.705916404724121
training step: 42295, total_loss: 4.637895107269287
training step: 42296, total_loss: 4.304973602294922
training step: 42297, total_loss: 4.132452011108398
training step: 42298, total_loss: 3.624976634979248
training step: 42299, total_loss: 3.298184394836426
training step: 42300, total_loss: 4.933903694152832
training step: 42301, total_loss: 3.816408634185791
training step: 42302, total_loss: 5.960201263427734
training step: 42303, total_loss: 3.84248685836792
training step: 42304, total_loss: 4.4608683586120605
training step: 42305, total_loss: 5.667631149291992
training step: 42306, total_loss: 4.30625581741333
training step: 42307, total_loss: 5.928094387054443
training step: 42308, total_loss: 5.416718482971191
training step: 42309, total_loss: 3.6172983646392822
training step: 42310, total_loss: 2.8793606758117676
training step: 42311, total_loss: 5.021365165710449
training step: 42312, total_loss: 3.497657299041748
training step: 42313, total_loss: 0.9667897820472717
training step: 42314, total_loss: 4.250718116760254
training step: 42315, total_loss: 2.471680164337158
training step: 42316, total_loss: 2.363170623779297
training step: 42317, total_loss: 5.881856918334961
training step: 42318, total_loss: 4.615958213806152
training step: 42319, total_loss: 2.6214258670806885
training step: 42320, total_loss: 4.444492816925049
training step: 42321, total_loss: 3.2739381790161133
training step: 42322, total_loss: 3.886824131011963
training step: 42323, total_loss: 3.301359176635742
training step: 42324, total_loss: 5.003366470336914
training step: 42325, total_loss: 5.5470123291015625
training step: 42326, total_loss: 3.738802671432495
training step: 42327, total_loss: 6.107599258422852
training step: 42328, total_loss: 4.025594711303711
training step: 42329, total_loss: 5.292230129241943
training step: 42330, total_loss: 5.318857192993164
training step: 42331, total_loss: 4.732163429260254
training step: 42332, total_loss: 3.9492087364196777
training step: 42333, total_loss: 3.153028964996338
training step: 42334, total_loss: 0.811568021774292
training step: 42335, total_loss: 5.033914566040039
training step: 42336, total_loss: 2.759230136871338
training step: 42337, total_loss: 4.604424476623535
training step: 42338, total_loss: 3.377070665359497
training step: 42339, total_loss: 4.939662933349609
training step: 42340, total_loss: 4.229240894317627
training step: 42341, total_loss: 3.6546120643615723
training step: 42342, total_loss: 5.873412132263184
training step: 42343, total_loss: 5.862812042236328
training step: 42344, total_loss: 4.309112071990967
training step: 42345, total_loss: 4.8271708488464355
training step: 42346, total_loss: 3.526521682739258
training step: 42347, total_loss: 4.4414286613464355
training step: 42348, total_loss: 6.108802795410156
training step: 42349, total_loss: 4.836613655090332
training step: 42350, total_loss: 4.654118061065674
training step: 42351, total_loss: 4.417736053466797
training step: 42352, total_loss: 4.583779811859131
training step: 42353, total_loss: 4.660305500030518
training step: 42354, total_loss: 5.273404598236084
training step: 42355, total_loss: 4.335338115692139
training step: 42356, total_loss: 5.060128211975098
training step: 42357, total_loss: 3.9972126483917236
training step: 42358, total_loss: 4.585017204284668
training step: 42359, total_loss: 3.060964345932007
training step: 42360, total_loss: 2.4369547367095947
training step: 42361, total_loss: 5.803462028503418
training step: 42362, total_loss: 5.037169933319092
training step: 42363, total_loss: 4.500965118408203
training step: 42364, total_loss: 5.467647552490234
training step: 42365, total_loss: 2.4739177227020264
training step: 42366, total_loss: 6.25220251083374
training step: 42367, total_loss: 3.9609227180480957
training step: 42368, total_loss: 2.7688467502593994
training step: 42369, total_loss: 6.501107215881348
training step: 42370, total_loss: 3.6734018325805664
training step: 42371, total_loss: 4.498744487762451
training step: 42372, total_loss: 3.163928985595703
training step: 42373, total_loss: 4.51784610748291
training step: 42374, total_loss: 4.852233409881592
training step: 42375, total_loss: 4.70515251159668
training step: 42376, total_loss: 4.598055839538574
training step: 42377, total_loss: 3.837562322616577
training step: 42378, total_loss: 4.690604209899902
training step: 42379, total_loss: 5.2065558433532715
training step: 42380, total_loss: 5.757193565368652
training step: 42381, total_loss: 1.5058846473693848
training step: 42382, total_loss: 0.6869696378707886
training step: 42383, total_loss: 3.456442356109619
training step: 42384, total_loss: 4.548983573913574
training step: 42385, total_loss: 2.9218480587005615
training step: 42386, total_loss: 4.608203887939453
training step: 42387, total_loss: 4.43836784362793
training step: 42388, total_loss: 4.8488688468933105
training step: 42389, total_loss: 2.5407345294952393
training step: 42390, total_loss: 5.487763404846191
training step: 42391, total_loss: 3.5840981006622314
training step: 42392, total_loss: 5.0250349044799805
training step: 42393, total_loss: 5.174458026885986
training step: 42394, total_loss: 4.794333457946777
training step: 42395, total_loss: 7.094278335571289
training step: 42396, total_loss: 4.215957164764404
training step: 42397, total_loss: 5.62759256362915
training step: 42398, total_loss: 3.780022382736206
training step: 42399, total_loss: 6.173215866088867
training step: 42400, total_loss: 5.647644996643066
training step: 42401, total_loss: 4.440885543823242
training step: 42402, total_loss: 4.272306442260742
training step: 42403, total_loss: 3.6310415267944336
training step: 42404, total_loss: 1.5000896453857422
training step: 42405, total_loss: 5.912026405334473
training step: 42406, total_loss: 4.9566144943237305
training step: 42407, total_loss: 3.122443675994873
training step: 42408, total_loss: 3.8021888732910156
training step: 42409, total_loss: 5.059220314025879
training step: 42410, total_loss: 3.8758046627044678
training step: 42411, total_loss: 5.383886814117432
training step: 42412, total_loss: 4.560042381286621
training step: 42413, total_loss: 4.527134895324707
training step: 42414, total_loss: 4.811826705932617
training step: 42415, total_loss: 5.024360179901123
training step: 42416, total_loss: 4.566551208496094
training step: 42417, total_loss: 3.4058070182800293
training step: 42418, total_loss: 6.588898658752441
training step: 42419, total_loss: 5.847527503967285
training step: 42420, total_loss: 3.863677740097046
training step: 42421, total_loss: 4.3820414543151855
training step: 42422, total_loss: 6.204440116882324
training step: 42423, total_loss: 4.873782157897949
training step: 42424, total_loss: 4.492813587188721
training step: 42425, total_loss: 4.3140411376953125
training step: 42426, total_loss: 4.838937282562256
training step: 42427, total_loss: 5.2325615882873535
training step: 42428, total_loss: 4.310764789581299
training step: 42429, total_loss: 5.1666717529296875
training step: 42430, total_loss: 4.574794769287109
training step: 42431, total_loss: 4.982343673706055
training step: 42432, total_loss: 4.67744779586792
training step: 42433, total_loss: 3.664429187774658
training step: 42434, total_loss: 4.943258285522461
training step: 42435, total_loss: 4.917034149169922
training step: 42436, total_loss: 1.0401548147201538
training step: 42437, total_loss: 4.558420181274414
training step: 42438, total_loss: 5.445420742034912
training step: 42439, total_loss: 4.181828498840332
training step: 42440, total_loss: 3.0315723419189453
training step: 42441, total_loss: 5.7321953773498535
training step: 42442, total_loss: 4.741658687591553
training step: 42443, total_loss: 4.859064102172852
training step: 42444, total_loss: 4.753391265869141
training step: 42445, total_loss: 4.097466945648193
training step: 42446, total_loss: 4.9003143310546875
training step: 42447, total_loss: 4.11268424987793
training step: 42448, total_loss: 6.347831726074219
training step: 42449, total_loss: 4.072093963623047
training step: 42450, total_loss: 3.734492301940918
training step: 42451, total_loss: 4.588006496429443
training step: 42452, total_loss: 5.101299285888672
training step: 42453, total_loss: 5.37625789642334
training step: 42454, total_loss: 4.96829891204834
training step: 42455, total_loss: 5.368957042694092
training step: 42456, total_loss: 4.050107955932617
training step: 42457, total_loss: 5.609784126281738
training step: 42458, total_loss: 3.613046169281006
training step: 42459, total_loss: 4.15085506439209
training step: 42460, total_loss: 4.889322280883789
training step: 42461, total_loss: 5.095115661621094
training step: 42462, total_loss: 3.8244645595550537
training step: 42463, total_loss: 3.881354808807373
training step: 42464, total_loss: 4.839159965515137
training step: 42465, total_loss: 4.9652934074401855
training step: 42466, total_loss: 2.971369743347168
training step: 42467, total_loss: 3.6714589595794678
training step: 42468, total_loss: 1.0626282691955566
training step: 42469, total_loss: 3.5368127822875977
training step: 42470, total_loss: 5.95839786529541
training step: 42471, total_loss: 4.074413299560547
training step: 42472, total_loss: 1.716865062713623
training step: 42473, total_loss: 3.1654539108276367
training step: 42474, total_loss: 2.878739833831787
training step: 42475, total_loss: 4.917023181915283
training step: 42476, total_loss: 2.9374032020568848
training step: 42477, total_loss: 5.144196033477783
training step: 42478, total_loss: 3.5822718143463135
training step: 42479, total_loss: 5.977867126464844
training step: 42480, total_loss: 3.1635491847991943
training step: 42481, total_loss: 5.20162296295166
training step: 42482, total_loss: 5.076059341430664
training step: 42483, total_loss: 6.10223913192749
training step: 42484, total_loss: 4.613684177398682
training step: 42485, total_loss: 4.7984619140625
training step: 42486, total_loss: 5.3100786209106445
training step: 42487, total_loss: 3.4799399375915527
training step: 42488, total_loss: 3.002302646636963
training step: 42489, total_loss: 4.033347129821777
training step: 42490, total_loss: 4.1034836769104
training step: 42491, total_loss: 2.4551162719726562
training step: 42492, total_loss: 3.923449993133545
training step: 42493, total_loss: 4.318381309509277
training step: 42494, total_loss: 3.9690048694610596
training step: 42495, total_loss: 4.762660026550293
training step: 42496, total_loss: 0.8803349733352661
training step: 42497, total_loss: 2.476043224334717
training step: 42498, total_loss: 5.097705841064453
training step: 42499, total_loss: 4.60711669921875
training step: 42500, total_loss: 5.084753513336182
training step: 42501, total_loss: 5.748834133148193
training step: 42502, total_loss: 6.051600456237793
training step: 42503, total_loss: 3.8143887519836426
training step: 42504, total_loss: 4.454535484313965
training step: 42505, total_loss: 5.345305919647217
training step: 42506, total_loss: 4.9156951904296875
training step: 42507, total_loss: 3.964073657989502
training step: 42508, total_loss: 5.369963645935059
training step: 42509, total_loss: 5.478137016296387
training step: 42510, total_loss: 5.23221492767334
training step: 42511, total_loss: 5.871139049530029
training step: 42512, total_loss: 4.000865936279297
training step: 42513, total_loss: 4.276583194732666
training step: 42514, total_loss: 2.350180149078369
training step: 42515, total_loss: 4.245182514190674
training step: 42516, total_loss: 5.153834342956543
training step: 42517, total_loss: 4.413239002227783
training step: 42518, total_loss: 1.1330583095550537
training step: 42519, total_loss: 4.432311058044434
training step: 42520, total_loss: 4.284580230712891
training step: 42521, total_loss: 4.933599948883057
training step: 42522, total_loss: 6.039824962615967
training step: 42523, total_loss: 4.613592147827148
training step: 42524, total_loss: 4.519627571105957
training step: 42525, total_loss: 3.064673900604248
training step: 42526, total_loss: 3.8956127166748047
training step: 42527, total_loss: 6.0635762214660645
training step: 42528, total_loss: 4.370137691497803
training step: 42529, total_loss: 4.109287738800049
training step: 42530, total_loss: 6.571098327636719
training step: 42531, total_loss: 4.451747894287109
training step: 42532, total_loss: 4.3602776527404785
training step: 42533, total_loss: 4.767106056213379
training step: 42534, total_loss: 4.237825870513916
training step: 42535, total_loss: 4.140679359436035
training step: 42536, total_loss: 5.046271324157715
training step: 42537, total_loss: 4.522814750671387
training step: 42538, total_loss: 5.668412685394287
training step: 42539, total_loss: 4.1825127601623535
training step: 42540, total_loss: 0.9450846910476685
training step: 42541, total_loss: 5.070971965789795
training step: 42542, total_loss: 4.222553253173828
training step: 42543, total_loss: 4.864884853363037
training step: 42544, total_loss: 2.5181121826171875
training step: 42545, total_loss: 3.6840732097625732
training step: 42546, total_loss: 3.2753806114196777
training step: 42547, total_loss: 4.37018346786499
training step: 42548, total_loss: 3.8487677574157715
training step: 42549, total_loss: 4.241380214691162
training step: 42550, total_loss: 3.6607067584991455
training step: 42551, total_loss: 5.395484924316406
training step: 42552, total_loss: 3.9218571186065674
training step: 42553, total_loss: 3.514657974243164
training step: 42554, total_loss: 5.278128147125244
training step: 42555, total_loss: 4.007209300994873
training step: 42556, total_loss: 6.7375688552856445
training step: 42557, total_loss: 5.629389762878418
training step: 42558, total_loss: 4.293572902679443
training step: 42559, total_loss: 3.7641990184783936
training step: 42560, total_loss: 5.554729461669922
training step: 42561, total_loss: 6.91611385345459
training step: 42562, total_loss: 4.604506969451904
training step: 42563, total_loss: 5.725574016571045
training step: 42564, total_loss: 0.8907730579376221
training step: 42565, total_loss: 4.776968002319336
training step: 42566, total_loss: 4.855616092681885
training step: 42567, total_loss: 4.7504167556762695
training step: 42568, total_loss: 4.805759429931641
training step: 42569, total_loss: 1.9110286235809326
training step: 42570, total_loss: 4.94023323059082
training step: 42571, total_loss: 5.407774448394775
training step: 42572, total_loss: 5.439182758331299
training step: 42573, total_loss: 5.227800369262695
training step: 42574, total_loss: 4.046165466308594
training step: 42575, total_loss: 4.6688456535339355
training step: 42576, total_loss: 3.430415153503418
training step: 42577, total_loss: 5.323795795440674
training step: 42578, total_loss: 1.1962063312530518
training step: 42579, total_loss: 3.4623703956604004
training step: 42580, total_loss: 3.6511406898498535
training step: 42581, total_loss: 3.5606117248535156
training step: 42582, total_loss: 4.577056884765625
training step: 42583, total_loss: 4.446722030639648
training step: 42584, total_loss: 6.085071563720703
training step: 42585, total_loss: 4.887956142425537
training step: 42586, total_loss: 5.891818046569824
training step: 42587, total_loss: 5.418096542358398
training step: 42588, total_loss: 4.304971694946289
training step: 42589, total_loss: 3.2927184104919434
training step: 42590, total_loss: 3.882302761077881
training step: 42591, total_loss: 5.486486911773682
training step: 42592, total_loss: 5.145220756530762
training step: 42593, total_loss: 5.483445644378662
training step: 42594, total_loss: 5.714498996734619
training step: 42595, total_loss: 4.334312438964844
training step: 42596, total_loss: 4.727347373962402
training step: 42597, total_loss: 4.599315643310547
training step: 42598, total_loss: 5.37264347076416
training step: 42599, total_loss: 5.1124348640441895
training step: 42600, total_loss: 4.545690059661865
training step: 42601, total_loss: 3.4378480911254883
training step: 42602, total_loss: 2.9093289375305176
training step: 42603, total_loss: 4.440292835235596
training step: 42604, total_loss: 4.251899719238281
training step: 42605, total_loss: 2.9640955924987793
training step: 42606, total_loss: 3.8293168544769287
training step: 42607, total_loss: 4.495849132537842
training step: 42608, total_loss: 4.0797905921936035
training step: 42609, total_loss: 4.476885795593262
training step: 42610, total_loss: 0.9416676759719849
training step: 42611, total_loss: 4.060111999511719
training step: 42612, total_loss: 4.321490287780762
training step: 42613, total_loss: 3.792297840118408
training step: 42614, total_loss: 3.1971631050109863
training step: 42615, total_loss: 5.12277889251709
training step: 42616, total_loss: 5.374502182006836
training step: 42617, total_loss: 3.421811819076538
training step: 42618, total_loss: 5.344080448150635
training step: 42619, total_loss: 4.456384181976318
training step: 42620, total_loss: 3.842576026916504
training step: 42621, total_loss: 3.242544412612915
training step: 42622, total_loss: 5.122537612915039
training step: 42623, total_loss: 4.4344401359558105
training step: 42624, total_loss: 6.248940467834473
training step: 42625, total_loss: 6.402465343475342
training step: 42626, total_loss: 4.5146989822387695
training step: 42627, total_loss: 3.8144569396972656
training step: 42628, total_loss: 3.9928412437438965
training step: 42629, total_loss: 1.2735289335250854
training step: 42630, total_loss: 3.0862841606140137
training step: 42631, total_loss: 4.703649520874023
training step: 42632, total_loss: 4.924655914306641
training step: 42633, total_loss: 4.49524450302124
training step: 42634, total_loss: 3.877134084701538
training step: 42635, total_loss: 4.980926990509033
training step: 42636, total_loss: 3.838642120361328
training step: 42637, total_loss: 3.9727981090545654
training step: 42638, total_loss: 4.5942277908325195
training step: 42639, total_loss: 4.624103546142578
training step: 42640, total_loss: 4.892769813537598
training step: 42641, total_loss: 3.776132106781006
training step: 42642, total_loss: 4.013092041015625
training step: 42643, total_loss: 3.37542986869812
training step: 42644, total_loss: 1.1394935846328735
training step: 42645, total_loss: 3.9705233573913574
training step: 42646, total_loss: 4.191544532775879
training step: 42647, total_loss: 4.380439758300781
training step: 42648, total_loss: 1.1018052101135254
training step: 42649, total_loss: 4.302165985107422
training step: 42650, total_loss: 3.8586783409118652
training step: 42651, total_loss: 4.97397518157959
training step: 42652, total_loss: 5.077681541442871
training step: 42653, total_loss: 5.232787132263184
training step: 42654, total_loss: 5.141010284423828
training step: 42655, total_loss: 5.766788005828857
training step: 42656, total_loss: 3.7479119300842285
training step: 42657, total_loss: 3.9287331104278564
training step: 42658, total_loss: 4.554967880249023
training step: 42659, total_loss: 4.576348304748535
training step: 42660, total_loss: 3.7823233604431152
training step: 42661, total_loss: 4.475412845611572
training step: 42662, total_loss: 3.6687395572662354
training step: 42663, total_loss: 5.141623497009277
training step: 42664, total_loss: 5.059582710266113
training step: 42665, total_loss: 4.580275535583496
training step: 42666, total_loss: 4.401320457458496
training step: 42667, total_loss: 4.361990928649902
training step: 42668, total_loss: 5.869799613952637
training step: 42669, total_loss: 4.2740278244018555
training step: 42670, total_loss: 1.8222155570983887
training step: 42671, total_loss: 5.104345798492432
training step: 42672, total_loss: 3.0587077140808105
training step: 42673, total_loss: 4.917223930358887
training step: 42674, total_loss: 4.339037895202637
training step: 42675, total_loss: 3.781606674194336
training step: 42676, total_loss: 4.446689605712891
training step: 42677, total_loss: 5.304355621337891
training step: 42678, total_loss: 2.6987528800964355
training step: 42679, total_loss: 5.4734954833984375
training step: 42680, total_loss: 4.804257869720459
training step: 42681, total_loss: 4.903306007385254
training step: 42682, total_loss: 6.295934677124023
training step: 42683, total_loss: 3.928563356399536
training step: 42684, total_loss: 1.7398093938827515
training step: 42685, total_loss: 4.563891887664795
training step: 42686, total_loss: 2.9691429138183594
training step: 42687, total_loss: 4.119990825653076
training step: 42688, total_loss: 6.387513637542725
training step: 42689, total_loss: 5.1023478507995605
training step: 42690, total_loss: 4.094181060791016
training step: 42691, total_loss: 4.586451053619385
training step: 42692, total_loss: 5.4147233963012695
training step: 42693, total_loss: 4.361273288726807
training step: 42694, total_loss: 4.0543742179870605
training step: 42695, total_loss: 6.2216339111328125
training step: 42696, total_loss: 5.207086086273193
training step: 42697, total_loss: 3.5111308097839355
training step: 42698, total_loss: 1.2043488025665283
training step: 42699, total_loss: 3.555269241333008
training step: 42700, total_loss: 3.791088581085205
training step: 42701, total_loss: 4.521658897399902
training step: 42702, total_loss: 4.341344833374023
training step: 42703, total_loss: 4.131335735321045
training step: 42704, total_loss: 4.181761264801025
training step: 42705, total_loss: 3.7181050777435303
training step: 42706, total_loss: 4.778897285461426
training step: 42707, total_loss: 4.912477970123291
training step: 42708, total_loss: 3.3019018173217773
training step: 42709, total_loss: 4.795931816101074
training step: 42710, total_loss: 4.656870365142822
training step: 42711, total_loss: 4.653040409088135
training step: 42712, total_loss: 5.215824604034424
training step: 42713, total_loss: 4.675820350646973
training step: 42714, total_loss: 4.788154125213623
training step: 42715, total_loss: 3.6094777584075928
training step: 42716, total_loss: 5.3933210372924805
training step: 42717, total_loss: 3.8384974002838135
training step: 42718, total_loss: 3.8976943492889404
training step: 42719, total_loss: 4.790439605712891
training step: 42720, total_loss: 3.7204556465148926
training step: 42721, total_loss: 3.310163974761963
training step: 42722, total_loss: 5.2334184646606445
training step: 42723, total_loss: 4.669593811035156
training step: 42724, total_loss: 5.780976295471191
training step: 42725, total_loss: 3.9164042472839355
training step: 42726, total_loss: 4.454218864440918
training step: 42727, total_loss: 2.3834714889526367
training step: 42728, total_loss: 5.488770484924316
training step: 42729, total_loss: 3.377335786819458
training step: 42730, total_loss: 4.119692802429199
training step: 42731, total_loss: 1.4673521518707275
training step: 42732, total_loss: 5.2542948722839355
training step: 42733, total_loss: 4.781778335571289
training step: 42734, total_loss: 4.531673431396484
training step: 42735, total_loss: 5.245235443115234
training step: 42736, total_loss: 5.629725456237793
training step: 42737, total_loss: 4.349089622497559
training step: 42738, total_loss: 2.993175745010376
training step: 42739, total_loss: 3.958162784576416
training step: 42740, total_loss: 5.2647528648376465
training step: 42741, total_loss: 4.5730180740356445
training step: 42742, total_loss: 4.439988136291504
training step: 42743, total_loss: 4.053807258605957
training step: 42744, total_loss: 4.879266262054443
training step: 42745, total_loss: 3.649885416030884
training step: 42746, total_loss: 4.116211414337158
training step: 42747, total_loss: 5.630702972412109
training step: 42748, total_loss: 4.651784896850586
training step: 42749, total_loss: 5.273774147033691
training step: 42750, total_loss: 3.419428825378418
training step: 42751, total_loss: 4.421578884124756
training step: 42752, total_loss: 5.098318099975586
training step: 42753, total_loss: 6.141395568847656
training step: 42754, total_loss: 5.462458610534668
training step: 42755, total_loss: 3.7866408824920654
training step: 42756, total_loss: 2.5130791664123535
training step: 42757, total_loss: 3.5597660541534424
training step: 42758, total_loss: 4.330114841461182
training step: 42759, total_loss: 4.837560653686523
training step: 42760, total_loss: 2.1487972736358643
training step: 42761, total_loss: 4.371191501617432
training step: 42762, total_loss: 4.22468900680542
training step: 42763, total_loss: 3.1992135047912598
training step: 42764, total_loss: 2.1401777267456055
training step: 42765, total_loss: 5.500551223754883
training step: 42766, total_loss: 5.278964519500732
training step: 42767, total_loss: 2.4261951446533203
training step: 42768, total_loss: 4.515366077423096
training step: 42769, total_loss: 1.0440797805786133
training step: 42770, total_loss: 4.627288341522217
training step: 42771, total_loss: 4.8183488845825195
training step: 42772, total_loss: 4.4929633140563965
training step: 42773, total_loss: 4.631186485290527
training step: 42774, total_loss: 3.906437873840332
training step: 42775, total_loss: 3.694101333618164
training step: 42776, total_loss: 4.768448829650879
training step: 42777, total_loss: 4.524777889251709
training step: 42778, total_loss: 4.839383602142334
training step: 42779, total_loss: 4.007347583770752
training step: 42780, total_loss: 5.570355415344238
training step: 42781, total_loss: 4.9500250816345215
training step: 42782, total_loss: 3.3230066299438477
training step: 42783, total_loss: 3.9880688190460205
training step: 42784, total_loss: 4.586380958557129
training step: 42785, total_loss: 4.777863502502441
training step: 42786, total_loss: 4.205324649810791
training step: 42787, total_loss: 4.946244239807129
training step: 42788, total_loss: 4.617055892944336
training step: 42789, total_loss: 4.935351848602295
training step: 42790, total_loss: 5.397289276123047
training step: 42791, total_loss: 4.805313587188721
training step: 42792, total_loss: 7.088187217712402
training step: 42793, total_loss: 3.6854891777038574
training step: 42794, total_loss: 4.592332363128662
training step: 42795, total_loss: 5.102873802185059
training step: 42796, total_loss: 4.702247619628906
training step: 42797, total_loss: 4.244657039642334
training step: 42798, total_loss: 1.1945592164993286
training step: 42799, total_loss: 4.451581001281738
training step: 42800, total_loss: 4.902910232543945
training step: 42801, total_loss: 6.085895538330078
training step: 42802, total_loss: 4.501309394836426
training step: 42803, total_loss: 5.222995758056641
training step: 42804, total_loss: 5.17652702331543
training step: 42805, total_loss: 4.250702857971191
training step: 42806, total_loss: 4.180570602416992
training step: 42807, total_loss: 1.304558277130127
training step: 42808, total_loss: 5.224921226501465
training step: 42809, total_loss: 5.066422462463379
training step: 42810, total_loss: 2.1502342224121094
training step: 42811, total_loss: 6.546870708465576
training step: 42812, total_loss: 3.210536241531372
training step: 42813, total_loss: 4.542719841003418
training step: 42814, total_loss: 5.2332444190979
training step: 42815, total_loss: 4.606492042541504
training step: 42816, total_loss: 5.236120223999023
training step: 42817, total_loss: 6.337066650390625
training step: 42818, total_loss: 3.9611048698425293
training step: 42819, total_loss: 3.746837615966797
training step: 42820, total_loss: 3.419036865234375
training step: 42821, total_loss: 3.8206253051757812
training step: 42822, total_loss: 2.7562355995178223
training step: 42823, total_loss: 5.67358922958374
training step: 42824, total_loss: 4.894919395446777
training step: 42825, total_loss: 3.0879385471343994
training step: 42826, total_loss: 4.272809028625488
training step: 42827, total_loss: 4.420753002166748
training step: 42828, total_loss: 2.9931492805480957
training step: 42829, total_loss: 5.210231781005859
training step: 42830, total_loss: 5.1512556076049805
training step: 42831, total_loss: 3.950150966644287
training step: 42832, total_loss: 4.135610580444336
training step: 42833, total_loss: 4.966696739196777
training step: 42834, total_loss: 4.6075544357299805
training step: 42835, total_loss: 3.2763826847076416
training step: 42836, total_loss: 4.437701225280762
training step: 42837, total_loss: 3.877656936645508
training step: 42838, total_loss: 3.9341747760772705
training step: 42839, total_loss: 3.3233413696289062
training step: 42840, total_loss: 5.597766876220703
training step: 42841, total_loss: 3.740560531616211
training step: 42842, total_loss: 2.3590760231018066
training step: 42843, total_loss: 3.3071670532226562
training step: 42844, total_loss: 4.503953456878662
training step: 42845, total_loss: 3.2789158821105957
training step: 42846, total_loss: 2.5089306831359863
training step: 42847, total_loss: 5.3669538497924805
training step: 42848, total_loss: 3.39821195602417
training step: 42849, total_loss: 4.120532035827637
training step: 42850, total_loss: 4.687334060668945
training step: 42851, total_loss: 4.238975524902344
training step: 42852, total_loss: 4.441424369812012
training step: 42853, total_loss: 4.354168891906738
training step: 42854, total_loss: 3.20355224609375
training step: 42855, total_loss: 3.975367546081543
training step: 42856, total_loss: 4.566774368286133
training step: 42857, total_loss: 4.648241996765137
training step: 42858, total_loss: 2.309196710586548
training step: 42859, total_loss: 4.137948989868164
training step: 42860, total_loss: 6.045297622680664
training step: 42861, total_loss: 4.274303913116455
training step: 42862, total_loss: 4.769766330718994
training step: 42863, total_loss: 3.7983243465423584
training step: 42864, total_loss: 3.7752346992492676
training step: 42865, total_loss: 5.4062981605529785
training step: 42866, total_loss: 4.862502574920654
training step: 42867, total_loss: 6.461579322814941
training step: 42868, total_loss: 4.612301826477051
training step: 42869, total_loss: 4.054633140563965
training step: 42870, total_loss: 4.114943504333496
training step: 42871, total_loss: 1.1858092546463013
training step: 42872, total_loss: 4.821746826171875
training step: 42873, total_loss: 3.0879383087158203
training step: 42874, total_loss: 3.7809033393859863
training step: 42875, total_loss: 4.095860958099365
training step: 42876, total_loss: 6.270240783691406
training step: 42877, total_loss: 3.7295851707458496
training step: 42878, total_loss: 4.238822937011719
training step: 42879, total_loss: 4.526578903198242
training step: 42880, total_loss: 4.970409393310547
training step: 42881, total_loss: 3.0907020568847656
training step: 42882, total_loss: 3.9421041011810303
training step: 42883, total_loss: 5.851117134094238
training step: 42884, total_loss: 1.08273184299469
training step: 42885, total_loss: 2.5294504165649414
training step: 42886, total_loss: 4.475242614746094
training step: 42887, total_loss: 2.0619471073150635
training step: 42888, total_loss: 4.817453861236572
training step: 42889, total_loss: 5.786972999572754
training step: 42890, total_loss: 4.948921203613281
training step: 42891, total_loss: 4.262180328369141
training step: 42892, total_loss: 6.014377593994141
training step: 42893, total_loss: 4.8588666915893555
training step: 42894, total_loss: 5.477410793304443
training step: 42895, total_loss: 4.978475093841553
training step: 42896, total_loss: 2.492262363433838
training step: 42897, total_loss: 5.086614608764648
training step: 42898, total_loss: 4.874523162841797
training step: 42899, total_loss: 5.937085151672363
training step: 42900, total_loss: 3.7451014518737793
training step: 42901, total_loss: 4.100457668304443
training step: 42902, total_loss: 1.0983688831329346
training step: 42903, total_loss: 5.867853164672852
training step: 42904, total_loss: 3.862840175628662
training step: 42905, total_loss: 4.145411491394043
training step: 42906, total_loss: 4.6070709228515625
training step: 42907, total_loss: 4.777502059936523
training step: 42908, total_loss: 4.331768989562988
training step: 42909, total_loss: 5.0436811447143555
training step: 42910, total_loss: 5.858173370361328
training step: 42911, total_loss: 4.214845657348633
training step: 42912, total_loss: 5.275870323181152
training step: 42913, total_loss: 3.1825313568115234
training step: 42914, total_loss: 3.8880882263183594
training step: 42915, total_loss: 4.632917404174805
training step: 42916, total_loss: 6.029656410217285
training step: 42917, total_loss: 3.7804598808288574
training step: 42918, total_loss: 4.883932590484619
training step: 42919, total_loss: 4.218415260314941
training step: 42920, total_loss: 5.118800163269043
training step: 42921, total_loss: 4.357369422912598
training step: 42922, total_loss: 6.015677452087402
training step: 42923, total_loss: 5.64012336730957
training step: 42924, total_loss: 4.131673336029053
training step: 42925, total_loss: 4.7618865966796875
training step: 42926, total_loss: 3.920100450515747
training step: 42927, total_loss: 4.014689922332764
training step: 42928, total_loss: 3.3709216117858887
training step: 42929, total_loss: 4.584157943725586
training step: 42930, total_loss: 4.194849014282227
training step: 42931, total_loss: 4.597121715545654
training step: 42932, total_loss: 2.277954578399658
training step: 42933, total_loss: 4.441764831542969
training step: 42934, total_loss: 3.3305726051330566
training step: 42935, total_loss: 3.7251787185668945
training step: 42936, total_loss: 4.307401657104492
training step: 42937, total_loss: 5.623420715332031
training step: 42938, total_loss: 3.3733794689178467
training step: 42939, total_loss: 4.59498929977417
training step: 42940, total_loss: 4.011316776275635
training step: 42941, total_loss: 3.782838821411133
training step: 42942, total_loss: 4.554967403411865
training step: 42943, total_loss: 5.114908695220947
training step: 42944, total_loss: 4.345246315002441
training step: 42945, total_loss: 4.559872627258301
training step: 42946, total_loss: 3.2912309169769287
training step: 42947, total_loss: 3.9697365760803223
training step: 42948, total_loss: 4.0436506271362305
training step: 42949, total_loss: 4.484424591064453
training step: 42950, total_loss: 4.856472969055176
training step: 42951, total_loss: 4.695453643798828
training step: 42952, total_loss: 4.628843784332275
training step: 42953, total_loss: 4.286842346191406
training step: 42954, total_loss: 4.179202079772949
training step: 42955, total_loss: 3.6237072944641113
training step: 42956, total_loss: 5.457119941711426
training step: 42957, total_loss: 4.323338031768799
training step: 42958, total_loss: 2.7947404384613037
training step: 42959, total_loss: 5.128776550292969
training step: 42960, total_loss: 4.268320083618164
training step: 42961, total_loss: 4.33797550201416
training step: 42962, total_loss: 4.047755241394043
training step: 42963, total_loss: 1.126246452331543
training step: 42964, total_loss: 3.9671404361724854
training step: 42965, total_loss: 4.558950901031494
training step: 42966, total_loss: 3.579472541809082
training step: 42967, total_loss: 3.942765235900879
training step: 42968, total_loss: 5.5459136962890625
training step: 42969, total_loss: 3.247103691101074
training step: 42970, total_loss: 3.0008602142333984
training step: 42971, total_loss: 5.552925109863281
training step: 42972, total_loss: 3.4211883544921875
training step: 42973, total_loss: 3.639805316925049
training step: 42974, total_loss: 6.478796482086182
training step: 42975, total_loss: 1.0374393463134766
training step: 42976, total_loss: 5.062224388122559
training step: 42977, total_loss: 6.5625104904174805
training step: 42978, total_loss: 5.6748247146606445
training step: 42979, total_loss: 4.400417327880859
training step: 42980, total_loss: 5.431723117828369
training step: 42981, total_loss: 5.047780990600586
training step: 42982, total_loss: 2.9352307319641113
training step: 42983, total_loss: 3.7293219566345215
training step: 42984, total_loss: 4.924487590789795
training step: 42985, total_loss: 3.6179747581481934
training step: 42986, total_loss: 4.7941083908081055
training step: 42987, total_loss: 2.8073415756225586
training step: 42988, total_loss: 4.782793045043945
training step: 42989, total_loss: 4.928829193115234
training step: 42990, total_loss: 4.906440734863281
training step: 42991, total_loss: 4.996945858001709
training step: 42992, total_loss: 4.6143646240234375
training step: 42993, total_loss: 5.954615592956543
training step: 42994, total_loss: 5.204270839691162
training step: 42995, total_loss: 3.8307547569274902
training step: 42996, total_loss: 4.086645603179932
training step: 42997, total_loss: 6.020331382751465
training step: 42998, total_loss: 5.03993034362793
training step: 42999, total_loss: 4.69682502746582
training step: 43000, total_loss: 3.6856093406677246
training step: 43001, total_loss: 5.232790946960449
training step: 43002, total_loss: 5.447766304016113
training step: 43003, total_loss: 5.277159690856934
training step: 43004, total_loss: 2.5703353881835938
training step: 43005, total_loss: 4.582066535949707
training step: 43006, total_loss: 2.3905303478240967
training step: 43007, total_loss: 4.801584720611572
training step: 43008, total_loss: 4.529304027557373
training step: 43009, total_loss: 3.9253830909729004
training step: 43010, total_loss: 3.9484829902648926
training step: 43011, total_loss: 4.132514953613281
training step: 43012, total_loss: 3.8925256729125977
training step: 43013, total_loss: 7.395198822021484
training step: 43014, total_loss: 4.417881011962891
training step: 43015, total_loss: 5.625540733337402
training step: 43016, total_loss: 3.973468065261841
training step: 43017, total_loss: 3.6037864685058594
training step: 43018, total_loss: 3.804574489593506
training step: 43019, total_loss: 4.891384124755859
training step: 43020, total_loss: 3.4579429626464844
training step: 43021, total_loss: 4.358103275299072
training step: 43022, total_loss: 6.483191967010498
training step: 43023, total_loss: 3.9561991691589355
training step: 43024, total_loss: 4.613035678863525
training step: 43025, total_loss: 4.461252689361572
training step: 43026, total_loss: 4.385096549987793
training step: 43027, total_loss: 3.8509182929992676
training step: 43028, total_loss: 4.6596808433532715
training step: 43029, total_loss: 4.084022521972656
training step: 43030, total_loss: 4.457235336303711
training step: 43031, total_loss: 2.4900026321411133
training step: 43032, total_loss: 4.024343967437744
training step: 43033, total_loss: 4.491394996643066
training step: 43034, total_loss: 2.5177454948425293
training step: 43035, total_loss: 4.357336521148682
training step: 43036, total_loss: 4.226797103881836
training step: 43037, total_loss: 4.048450469970703
training step: 43038, total_loss: 4.466517448425293
training step: 43039, total_loss: 4.259050369262695
training step: 43040, total_loss: 4.859569549560547
training step: 43041, total_loss: 4.34141731262207
training step: 43042, total_loss: 4.483739852905273
training step: 43043, total_loss: 4.30840539932251
training step: 43044, total_loss: 4.3093461990356445
training step: 43045, total_loss: 2.562566041946411
training step: 43046, total_loss: 4.742213249206543
training step: 43047, total_loss: 4.052729606628418
training step: 43048, total_loss: 5.954062461853027
training step: 43049, total_loss: 4.271004676818848
training step: 43050, total_loss: 4.6742939949035645
training step: 43051, total_loss: 5.058664321899414
training step: 43052, total_loss: 4.490515232086182
training step: 43053, total_loss: 4.698416709899902
training step: 43054, total_loss: 3.2650744915008545
training step: 43055, total_loss: 4.744076251983643
training step: 43056, total_loss: 6.378495693206787
training step: 43057, total_loss: 5.066378593444824
training step: 43058, total_loss: 3.833644151687622
training step: 43059, total_loss: 5.252293586730957
training step: 43060, total_loss: 4.306797027587891
training step: 43061, total_loss: 3.8617002964019775
training step: 43062, total_loss: 3.791470766067505
training step: 43063, total_loss: 4.3082170486450195
training step: 43064, total_loss: 4.276537895202637
training step: 43065, total_loss: 2.422445297241211
training step: 43066, total_loss: 4.546078681945801
training step: 43067, total_loss: 2.939800262451172
training step: 43068, total_loss: 3.484084129333496
training step: 43069, total_loss: 5.116153717041016
training step: 43070, total_loss: 6.043536186218262
training step: 43071, total_loss: 6.0590667724609375
training step: 43072, total_loss: 2.1371607780456543
training step: 43073, total_loss: 4.7475199699401855
training step: 43074, total_loss: 5.785181522369385
training step: 43075, total_loss: 5.093018531799316
training step: 43076, total_loss: 1.295166015625
training step: 43077, total_loss: 5.1285529136657715
training step: 43078, total_loss: 4.509535789489746
training step: 43079, total_loss: 4.186546802520752
training step: 43080, total_loss: 4.235700607299805
training step: 43081, total_loss: 6.353193283081055
training step: 43082, total_loss: 3.887920379638672
training step: 43083, total_loss: 5.383553504943848
training step: 43084, total_loss: 5.730445384979248
training step: 43085, total_loss: 4.572035789489746
training step: 43086, total_loss: 3.804171562194824
training step: 43087, total_loss: 4.845632553100586
training step: 43088, total_loss: 4.719546318054199
training step: 43089, total_loss: 3.6184065341949463
training step: 43090, total_loss: 3.360562324523926
training step: 43091, total_loss: 4.106450080871582
training step: 43092, total_loss: 5.538403511047363
training step: 43093, total_loss: 4.3885040283203125
training step: 43094, total_loss: 5.447091102600098
training step: 43095, total_loss: 4.618063926696777
training step: 43096, total_loss: 4.877235412597656
training step: 43097, total_loss: 4.5292816162109375
training step: 43098, total_loss: 6.041011810302734
training step: 43099, total_loss: 3.794200897216797
training step: 43100, total_loss: 5.936227798461914
training step: 43101, total_loss: 5.435856819152832
training step: 43102, total_loss: 6.170727729797363
training step: 43103, total_loss: 3.5574240684509277
training step: 43104, total_loss: 3.974480152130127
training step: 43105, total_loss: 4.813427448272705
training step: 43106, total_loss: 4.744858264923096
training step: 43107, total_loss: 3.278536558151245
training step: 43108, total_loss: 3.791947364807129
training step: 43109, total_loss: 4.746058464050293
training step: 43110, total_loss: 5.510374069213867
training step: 43111, total_loss: 4.47683048248291
training step: 43112, total_loss: 1.265920877456665
training step: 43113, total_loss: 5.220118522644043
training step: 43114, total_loss: 1.2128965854644775
training step: 43115, total_loss: 4.671314716339111
training step: 43116, total_loss: 3.6219520568847656
training step: 43117, total_loss: 3.7689895629882812
training step: 43118, total_loss: 3.9868249893188477
training step: 43119, total_loss: 5.013524055480957
training step: 43120, total_loss: 3.144744396209717
training step: 43121, total_loss: 5.939766883850098
training step: 43122, total_loss: 5.08290958404541
training step: 43123, total_loss: 4.049195289611816
training step: 43124, total_loss: 4.506866455078125
training step: 43125, total_loss: 4.3619794845581055
training step: 43126, total_loss: 4.294075965881348
training step: 43127, total_loss: 3.9989428520202637
training step: 43128, total_loss: 2.7050046920776367
training step: 43129, total_loss: 3.3684539794921875
training step: 43130, total_loss: 3.6116535663604736
training step: 43131, total_loss: 4.201248645782471
training step: 43132, total_loss: 2.738018035888672
training step: 43133, total_loss: 5.236566543579102
training step: 43134, total_loss: 4.437839508056641
training step: 43135, total_loss: 3.564432144165039
training step: 43136, total_loss: 4.992894172668457
training step: 43137, total_loss: 3.3222451210021973
training step: 43138, total_loss: 4.980945110321045
training step: 43139, total_loss: 5.152715682983398
training step: 43140, total_loss: 3.649019479751587
training step: 43141, total_loss: 4.23228120803833
training step: 43142, total_loss: 5.795161247253418
training step: 43143, total_loss: 2.832432746887207
training step: 43144, total_loss: 5.229679107666016
training step: 43145, total_loss: 1.7084012031555176
training step: 43146, total_loss: 3.66015362739563
training step: 43147, total_loss: 5.202420234680176
training step: 43148, total_loss: 4.83451509475708
training step: 43149, total_loss: 3.331836223602295
training step: 43150, total_loss: 2.830381393432617
training step: 43151, total_loss: 3.478466510772705
training step: 43152, total_loss: 4.271029949188232
training step: 43153, total_loss: 4.683712959289551
training step: 43154, total_loss: 5.347066879272461
training step: 43155, total_loss: 3.8563485145568848
training step: 43156, total_loss: 4.57102108001709
training step: 43157, total_loss: 3.979213237762451
training step: 43158, total_loss: 4.129513740539551
training step: 43159, total_loss: 5.391979217529297
training step: 43160, total_loss: 5.267518043518066
training step: 43161, total_loss: 4.4045820236206055
training step: 43162, total_loss: 5.1086039543151855
training step: 43163, total_loss: 4.699593544006348
training step: 43164, total_loss: 2.2913241386413574
training step: 43165, total_loss: 4.171849727630615
training step: 43166, total_loss: 5.480184555053711
training step: 43167, total_loss: 3.815584659576416
training step: 43168, total_loss: 4.6704630851745605
training step: 43169, total_loss: 5.5316925048828125
training step: 43170, total_loss: 3.8844661712646484
training step: 43171, total_loss: 3.078862190246582
training step: 43172, total_loss: 4.34874153137207
training step: 43173, total_loss: 5.125421524047852
training step: 43174, total_loss: 4.777320384979248
training step: 43175, total_loss: 5.358450889587402
training step: 43176, total_loss: 4.896571159362793
training step: 43177, total_loss: 5.591658115386963
training step: 43178, total_loss: 4.183363914489746
training step: 43179, total_loss: 5.458935260772705
training step: 43180, total_loss: 2.3748583793640137
training step: 43181, total_loss: 5.669475078582764
training step: 43182, total_loss: 4.635520935058594
training step: 43183, total_loss: 5.622127056121826
training step: 43184, total_loss: 4.660462379455566
training step: 43185, total_loss: 5.001682281494141
training step: 43186, total_loss: 5.063016891479492
training step: 43187, total_loss: 5.214367866516113
training step: 43188, total_loss: 3.698843002319336
training step: 43189, total_loss: 4.541111469268799
training step: 43190, total_loss: 4.716253280639648
training step: 43191, total_loss: 5.8795061111450195
training step: 43192, total_loss: 4.842285633087158
training step: 43193, total_loss: 3.731877326965332
training step: 43194, total_loss: 4.227940082550049
training step: 43195, total_loss: 2.8159728050231934
training step: 43196, total_loss: 4.276027679443359
training step: 43197, total_loss: 0.9640637040138245
training step: 43198, total_loss: 4.029700756072998
training step: 43199, total_loss: 3.483961343765259
training step: 43200, total_loss: 4.912087440490723
training step: 43201, total_loss: 4.809840202331543
training step: 43202, total_loss: 3.8671836853027344
training step: 43203, total_loss: 4.880222320556641
training step: 43204, total_loss: 4.6883931159973145
training step: 43205, total_loss: 4.300240516662598
training step: 43206, total_loss: 3.8441898822784424
training step: 43207, total_loss: 3.6219427585601807
training step: 43208, total_loss: 4.970170974731445
training step: 43209, total_loss: 3.3839259147644043
training step: 43210, total_loss: 4.649245262145996
training step: 43211, total_loss: 3.877375364303589
training step: 43212, total_loss: 6.10767126083374
training step: 43213, total_loss: 4.453883171081543
training step: 43214, total_loss: 1.0033481121063232
training step: 43215, total_loss: 2.7807259559631348
training step: 43216, total_loss: 6.835048675537109
training step: 43217, total_loss: 5.580864906311035
training step: 43218, total_loss: 5.545045852661133
training step: 43219, total_loss: 1.1199798583984375
training step: 43220, total_loss: 3.711742401123047
training step: 43221, total_loss: 2.969486713409424
training step: 43222, total_loss: 4.875646114349365
training step: 43223, total_loss: 3.3217244148254395
training step: 43224, total_loss: 4.992455959320068
training step: 43225, total_loss: 5.090786457061768
training step: 43226, total_loss: 4.7910003662109375
training step: 43227, total_loss: 0.9015475511550903
training step: 43228, total_loss: 3.277960777282715
training step: 43229, total_loss: 4.327642917633057
training step: 43230, total_loss: 4.4044084548950195
training step: 43231, total_loss: 5.6658854484558105
training step: 43232, total_loss: 4.383726596832275
training step: 43233, total_loss: 4.679540157318115
training step: 43234, total_loss: 3.0067968368530273
training step: 43235, total_loss: 3.9874696731567383
training step: 43236, total_loss: 4.27442741394043
training step: 43237, total_loss: 5.436905860900879
training step: 43238, total_loss: 5.448859214782715
training step: 43239, total_loss: 4.710497856140137
training step: 43240, total_loss: 4.423142433166504
training step: 43241, total_loss: 3.1315724849700928
training step: 43242, total_loss: 2.623110294342041
training step: 43243, total_loss: 3.9972612857818604
training step: 43244, total_loss: 4.849042892456055
training step: 43245, total_loss: 4.0190558433532715
training step: 43246, total_loss: 5.218236923217773
training step: 43247, total_loss: 5.546966075897217
training step: 43248, total_loss: 4.798094272613525
training step: 43249, total_loss: 6.2809343338012695
training step: 43250, total_loss: 3.5198802947998047
training step: 43251, total_loss: 3.5364136695861816
training step: 43252, total_loss: 2.375791549682617
training step: 43253, total_loss: 3.761326551437378
training step: 43254, total_loss: 0.9148434400558472
training step: 43255, total_loss: 4.361594200134277
training step: 43256, total_loss: 4.494266986846924
training step: 43257, total_loss: 3.2342214584350586
training step: 43258, total_loss: 2.995889902114868
training step: 43259, total_loss: 4.218625068664551
training step: 43260, total_loss: 5.5698394775390625
training step: 43261, total_loss: 4.012231826782227
training step: 43262, total_loss: 5.112180709838867
training step: 43263, total_loss: 4.379096031188965
training step: 43264, total_loss: 4.1214494705200195
training step: 43265, total_loss: 2.721363067626953
training step: 43266, total_loss: 5.2346510887146
training step: 43267, total_loss: 3.822012424468994
training step: 43268, total_loss: 4.932337760925293
training step: 43269, total_loss: 4.4508376121521
training step: 43270, total_loss: 2.6835684776306152
training step: 43271, total_loss: 3.487752914428711
training step: 43272, total_loss: 4.694038391113281
training step: 43273, total_loss: 3.3572254180908203
training step: 43274, total_loss: 3.6299242973327637
training step: 43275, total_loss: 2.0590531826019287
training step: 43276, total_loss: 5.7725830078125
training step: 43277, total_loss: 4.08797550201416
training step: 43278, total_loss: 5.241753578186035
training step: 43279, total_loss: 4.035203456878662
training step: 43280, total_loss: 4.448250770568848
training step: 43281, total_loss: 2.97426438331604
training step: 43282, total_loss: 5.309099197387695
training step: 43283, total_loss: 4.8755693435668945
training step: 43284, total_loss: 5.453319549560547
training step: 43285, total_loss: 4.6201982498168945
training step: 43286, total_loss: 3.888998508453369
training step: 43287, total_loss: 1.0920977592468262
training step: 43288, total_loss: 3.664168357849121
training step: 43289, total_loss: 4.763461112976074
training step: 43290, total_loss: 3.899047613143921
training step: 43291, total_loss: 5.921657085418701
training step: 43292, total_loss: 4.900310516357422
training step: 43293, total_loss: 5.533886432647705
training step: 43294, total_loss: 4.7702484130859375
training step: 43295, total_loss: 3.535708427429199
training step: 43296, total_loss: 3.9746382236480713
training step: 43297, total_loss: 4.136175155639648
training step: 43298, total_loss: 6.529458999633789
training step: 43299, total_loss: 3.70166015625
training step: 43300, total_loss: 5.127015113830566
training step: 43301, total_loss: 4.667858600616455
training step: 43302, total_loss: 5.133415222167969
training step: 43303, total_loss: 4.61794376373291
training step: 43304, total_loss: 4.1988372802734375
training step: 43305, total_loss: 3.432598114013672
training step: 43306, total_loss: 4.019758224487305
training step: 43307, total_loss: 3.0482125282287598
training step: 43308, total_loss: 5.499640464782715
training step: 43309, total_loss: 4.695306301116943
training step: 43310, total_loss: 5.414515495300293
training step: 43311, total_loss: 4.913788318634033
training step: 43312, total_loss: 3.2240591049194336
training step: 43313, total_loss: 4.32761287689209
training step: 43314, total_loss: 1.7218811511993408
training step: 43315, total_loss: 5.8405303955078125
training step: 43316, total_loss: 5.906519889831543
training step: 43317, total_loss: 4.666534900665283
training step: 43318, total_loss: 5.132302284240723
training step: 43319, total_loss: 5.8760528564453125
training step: 43320, total_loss: 6.373690605163574
training step: 43321, total_loss: 3.37534236907959
training step: 43322, total_loss: 4.866064548492432
training step: 43323, total_loss: 4.4014506340026855
training step: 43324, total_loss: 6.388958930969238
training step: 43325, total_loss: 3.479832649230957
training step: 43326, total_loss: 7.495538711547852
training step: 43327, total_loss: 0.9564681053161621
training step: 43328, total_loss: 3.6095664501190186
training step: 43329, total_loss: 5.087285041809082
training step: 43330, total_loss: 2.835531234741211
training step: 43331, total_loss: 5.790374279022217
training step: 43332, total_loss: 4.745176315307617
training step: 43333, total_loss: 3.7165491580963135
training step: 43334, total_loss: 3.361980438232422
training step: 43335, total_loss: 4.182753086090088
training step: 43336, total_loss: 4.216361999511719
training step: 43337, total_loss: 5.710099220275879
training step: 43338, total_loss: 4.789969444274902
training step: 43339, total_loss: 6.125914096832275
training step: 43340, total_loss: 5.9152631759643555
training step: 43341, total_loss: 4.3102264404296875
training step: 43342, total_loss: 4.009182929992676
training step: 43343, total_loss: 5.242114067077637
training step: 43344, total_loss: 3.8944358825683594
training step: 43345, total_loss: 4.5557942390441895
training step: 43346, total_loss: 2.8540101051330566
training step: 43347, total_loss: 5.08500862121582
training step: 43348, total_loss: 2.437574625015259
training step: 43349, total_loss: 3.379741907119751
training step: 43350, total_loss: 5.405896186828613
training step: 43351, total_loss: 4.223899841308594
training step: 43352, total_loss: 4.15273904800415
training step: 43353, total_loss: 4.772880554199219
training step: 43354, total_loss: 3.991818904876709
training step: 43355, total_loss: 2.50384521484375
training step: 43356, total_loss: 3.8941292762756348
training step: 43357, total_loss: 4.263617992401123
training step: 43358, total_loss: 4.452301979064941
training step: 43359, total_loss: 2.9958248138427734
training step: 43360, total_loss: 2.845025062561035
training step: 43361, total_loss: 6.087402820587158
training step: 43362, total_loss: 4.244300842285156
training step: 43363, total_loss: 4.173460960388184
training step: 43364, total_loss: 4.8242058753967285
training step: 43365, total_loss: 4.159431457519531
training step: 43366, total_loss: 4.256534576416016
training step: 43367, total_loss: 4.3281354904174805
training step: 43368, total_loss: 4.408435821533203
training step: 43369, total_loss: 0.7916151285171509
training step: 43370, total_loss: 4.138406753540039
training step: 43371, total_loss: 3.0162172317504883
training step: 43372, total_loss: 3.966493606567383
training step: 43373, total_loss: 1.4181731939315796
training step: 43374, total_loss: 2.7104549407958984
training step: 43375, total_loss: 1.174398422241211
training step: 43376, total_loss: 4.593811988830566
training step: 43377, total_loss: 4.017338752746582
training step: 43378, total_loss: 4.852666854858398
training step: 43379, total_loss: 5.3532514572143555
training step: 43380, total_loss: 4.5780029296875
training step: 43381, total_loss: 3.63106632232666
training step: 43382, total_loss: 4.442561149597168
training step: 43383, total_loss: 5.442680358886719
training step: 43384, total_loss: 5.8107805252075195
training step: 43385, total_loss: 3.6473512649536133
training step: 43386, total_loss: 3.343696355819702
training step: 43387, total_loss: 5.520252227783203
training step: 43388, total_loss: 4.261081695556641
training step: 43389, total_loss: 4.547066688537598
training step: 43390, total_loss: 4.918433666229248
training step: 43391, total_loss: 4.840984344482422
training step: 43392, total_loss: 3.5872981548309326
training step: 43393, total_loss: 6.415674209594727
training step: 43394, total_loss: 5.497494220733643
training step: 43395, total_loss: 5.27548360824585
training step: 43396, total_loss: 4.356739044189453
training step: 43397, total_loss: 5.616631507873535
training step: 43398, total_loss: 6.278196334838867
training step: 43399, total_loss: 0.8814345598220825
training step: 43400, total_loss: 3.8640716075897217
training step: 43401, total_loss: 3.6392598152160645
training step: 43402, total_loss: 3.9896044731140137
training step: 43403, total_loss: 5.869928359985352
training step: 43404, total_loss: 3.281212329864502
training step: 43405, total_loss: 4.809463024139404
training step: 43406, total_loss: 4.334225654602051
training step: 43407, total_loss: 4.983345985412598
training step: 43408, total_loss: 4.353798866271973
training step: 43409, total_loss: 4.345578193664551
training step: 43410, total_loss: 4.967443466186523
training step: 43411, total_loss: 5.996593475341797
training step: 43412, total_loss: 5.849790573120117
training step: 43413, total_loss: 4.553515434265137
training step: 43414, total_loss: 4.182579517364502
training step: 43415, total_loss: 4.7483744621276855
training step: 43416, total_loss: 5.226266860961914
training step: 43417, total_loss: 3.0135936737060547
training step: 43418, total_loss: 4.036928176879883
training step: 43419, total_loss: 4.578195571899414
training step: 43420, total_loss: 7.20428991317749
training step: 43421, total_loss: 3.2174339294433594
training step: 43422, total_loss: 4.873538970947266
training step: 43423, total_loss: 5.163087368011475
training step: 43424, total_loss: 4.506568431854248
training step: 43425, total_loss: 4.558873653411865
training step: 43426, total_loss: 0.8058868646621704
training step: 43427, total_loss: 3.3911092281341553
training step: 43428, total_loss: 4.840333461761475
training step: 43429, total_loss: 3.2431914806365967
training step: 43430, total_loss: 5.451770305633545
training step: 43431, total_loss: 3.584648609161377
training step: 43432, total_loss: 6.063192367553711
training step: 43433, total_loss: 6.832523822784424
training step: 43434, total_loss: 4.450995445251465
training step: 43435, total_loss: 4.694321632385254
training step: 43436, total_loss: 3.4955711364746094
training step: 43437, total_loss: 4.954898357391357
training step: 43438, total_loss: 3.7316157817840576
training step: 43439, total_loss: 5.320805549621582
training step: 43440, total_loss: 4.72955322265625
training step: 43441, total_loss: 4.109698295593262
training step: 43442, total_loss: 5.587389945983887
training step: 43443, total_loss: 3.6297731399536133
training step: 43444, total_loss: 4.788949012756348
training step: 43445, total_loss: 5.550497055053711
training step: 43446, total_loss: 2.9315185546875
training step: 43447, total_loss: 5.815788269042969
training step: 43448, total_loss: 4.098306655883789
training step: 43449, total_loss: 5.024325370788574
training step: 43450, total_loss: 6.522946357727051
training step: 43451, total_loss: 3.0977096557617188
training step: 43452, total_loss: 3.950852632522583
training step: 43453, total_loss: 5.09470796585083
training step: 43454, total_loss: 4.8885698318481445
training step: 43455, total_loss: 4.954057693481445
training step: 43456, total_loss: 3.6937084197998047
training step: 43457, total_loss: 3.7531890869140625
training step: 43458, total_loss: 4.411539077758789
training step: 43459, total_loss: 3.8946986198425293
training step: 43460, total_loss: 3.599994659423828
training step: 43461, total_loss: 4.939678192138672
training step: 43462, total_loss: 4.177820205688477
training step: 43463, total_loss: 3.427663803100586
training step: 43464, total_loss: 4.588108062744141
training step: 43465, total_loss: 4.565936088562012
training step: 43466, total_loss: 3.729642152786255
training step: 43467, total_loss: 3.1840906143188477
training step: 43468, total_loss: 5.931603908538818
training step: 43469, total_loss: 2.3817739486694336
training step: 43470, total_loss: 4.382753849029541
training step: 43471, total_loss: 6.351835250854492
training step: 43472, total_loss: 2.527486801147461
training step: 43473, total_loss: 4.061605453491211
training step: 43474, total_loss: 4.699788570404053
training step: 43475, total_loss: 4.0540971755981445
training step: 43476, total_loss: 3.3744378089904785
training step: 43477, total_loss: 5.285520553588867
training step: 43478, total_loss: 4.153393745422363
training step: 43479, total_loss: 5.064722061157227
training step: 43480, total_loss: 5.015463829040527
training step: 43481, total_loss: 5.441461563110352
training step: 43482, total_loss: 4.668704986572266
training step: 43483, total_loss: 4.595608711242676
training step: 43484, total_loss: 2.691368818283081
training step: 43485, total_loss: 3.824878692626953
training step: 43486, total_loss: 3.6887266635894775
training step: 43487, total_loss: 4.132248401641846
training step: 43488, total_loss: 2.6076724529266357
training step: 43489, total_loss: 3.36332368850708
training step: 43490, total_loss: 6.628047943115234
training step: 43491, total_loss: 6.39316463470459
training step: 43492, total_loss: 4.121968746185303
training step: 43493, total_loss: 5.680488109588623
training step: 43494, total_loss: 4.858331680297852
training step: 43495, total_loss: 0.9582415819168091
training step: 43496, total_loss: 3.7165307998657227
training step: 43497, total_loss: 4.352996826171875
training step: 43498, total_loss: 3.3214430809020996
training step: 43499, total_loss: 6.049004077911377
training step: 43500, total_loss: 5.568317413330078
training step: 43501, total_loss: 4.59480094909668
training step: 43502, total_loss: 6.127233505249023
training step: 43503, total_loss: 4.743595123291016
training step: 43504, total_loss: 4.799042701721191
training step: 43505, total_loss: 5.786456108093262
training step: 43506, total_loss: 3.020639419555664
training step: 43507, total_loss: 3.241067409515381
training step: 43508, total_loss: 4.062743663787842
training step: 43509, total_loss: 3.454582691192627
training step: 43510, total_loss: 3.7566330432891846
training step: 43511, total_loss: 4.492098808288574
training step: 43512, total_loss: 4.708038330078125
training step: 43513, total_loss: 2.425572633743286
training step: 43514, total_loss: 3.491669178009033
training step: 43515, total_loss: 4.324179649353027
training step: 43516, total_loss: 4.9420061111450195
training step: 43517, total_loss: 2.35858154296875
training step: 43518, total_loss: 4.7152557373046875
training step: 43519, total_loss: 4.647164344787598
training step: 43520, total_loss: 3.347625494003296
training step: 43521, total_loss: 4.702228546142578
training step: 43522, total_loss: 4.599442481994629
training step: 43523, total_loss: 4.511569023132324
training step: 43524, total_loss: 4.999945163726807
training step: 43525, total_loss: 4.712031841278076
training step: 43526, total_loss: 4.731755256652832
training step: 43527, total_loss: 4.820828437805176
training step: 43528, total_loss: 5.499395370483398
training step: 43529, total_loss: 4.286194801330566
training step: 43530, total_loss: 3.027949333190918
training step: 43531, total_loss: 4.676819801330566
training step: 43532, total_loss: 3.310098171234131
training step: 43533, total_loss: 5.37218713760376
training step: 43534, total_loss: 4.087089538574219
training step: 43535, total_loss: 3.9947962760925293
training step: 43536, total_loss: 1.4104658365249634
training step: 43537, total_loss: 4.3917059898376465
training step: 43538, total_loss: 4.530513763427734
training step: 43539, total_loss: 0.7215301990509033
training step: 43540, total_loss: 3.9727096557617188
training step: 43541, total_loss: 4.449069499969482
training step: 43542, total_loss: 4.049250602722168
training step: 43543, total_loss: 3.8494503498077393
training step: 43544, total_loss: 4.932762145996094
training step: 43545, total_loss: 5.167356014251709
training step: 43546, total_loss: 3.854454755783081
training step: 43547, total_loss: 4.178447246551514
training step: 43548, total_loss: 3.4243080615997314
training step: 43549, total_loss: 4.574104309082031
training step: 43550, total_loss: 5.216109275817871
training step: 43551, total_loss: 4.711361885070801
training step: 43552, total_loss: 4.909031391143799
training step: 43553, total_loss: 4.133428573608398
training step: 43554, total_loss: 4.966936111450195
training step: 43555, total_loss: 3.394465684890747
training step: 43556, total_loss: 4.944584369659424
training step: 43557, total_loss: 6.8780293464660645
training step: 43558, total_loss: 3.1232199668884277
training step: 43559, total_loss: 4.3285346031188965
training step: 43560, total_loss: 4.784112930297852
training step: 43561, total_loss: 4.137727737426758
training step: 43562, total_loss: 4.55119514465332
training step: 43563, total_loss: 5.464689254760742
training step: 43564, total_loss: 5.183605670928955
training step: 43565, total_loss: 5.204168319702148
training step: 43566, total_loss: 3.0003199577331543
training step: 43567, total_loss: 3.7085371017456055
training step: 43568, total_loss: 5.022433280944824
training step: 43569, total_loss: 4.4297051429748535
training step: 43570, total_loss: 2.6814327239990234
training step: 43571, total_loss: 3.486811876296997
training step: 43572, total_loss: 3.5097768306732178
training step: 43573, total_loss: 5.185328006744385
training step: 43574, total_loss: 4.3217058181762695
training step: 43575, total_loss: 3.188291549682617
training step: 43576, total_loss: 3.76617431640625
training step: 43577, total_loss: 4.580552101135254
training step: 43578, total_loss: 3.7497410774230957
training step: 43579, total_loss: 4.743906021118164
training step: 43580, total_loss: 4.681118011474609
training step: 43581, total_loss: 5.731997013092041
training step: 43582, total_loss: 2.7448463439941406
training step: 43583, total_loss: 3.64139986038208
training step: 43584, total_loss: 4.826226234436035
training step: 43585, total_loss: 4.903961181640625
training step: 43586, total_loss: 4.811548233032227
training step: 43587, total_loss: 4.479322910308838
training step: 43588, total_loss: 5.118659973144531
training step: 43589, total_loss: 4.501038074493408
training step: 43590, total_loss: 3.913627862930298
training step: 43591, total_loss: 3.745070695877075
training step: 43592, total_loss: 5.166417121887207
training step: 43593, total_loss: 3.002941131591797
training step: 43594, total_loss: 5.578566551208496
training step: 43595, total_loss: 4.925910949707031
training step: 43596, total_loss: 4.502147674560547
training step: 43597, total_loss: 5.10768985748291
training step: 43598, total_loss: 6.180108070373535
training step: 43599, total_loss: 5.11090087890625
training step: 43600, total_loss: 6.208911895751953
training step: 43601, total_loss: 3.9375548362731934
training step: 43602, total_loss: 3.215493679046631
training step: 43603, total_loss: 4.117773056030273
training step: 43604, total_loss: 4.827366828918457
training step: 43605, total_loss: 6.73909854888916
training step: 43606, total_loss: 4.738203048706055
training step: 43607, total_loss: 4.36732292175293
training step: 43608, total_loss: 3.537740707397461
training step: 43609, total_loss: 0.9245876669883728
training step: 43610, total_loss: 5.683478355407715
training step: 43611, total_loss: 3.7740108966827393
training step: 43612, total_loss: 3.7191662788391113
training step: 43613, total_loss: 5.439268112182617
training step: 43614, total_loss: 4.372722625732422
training step: 43615, total_loss: 4.9350996017456055
training step: 43616, total_loss: 5.174485206604004
training step: 43617, total_loss: 2.763062000274658
training step: 43618, total_loss: 5.013625621795654
training step: 43619, total_loss: 4.6774516105651855
training step: 43620, total_loss: 3.1780571937561035
training step: 43621, total_loss: 5.088809013366699
training step: 43622, total_loss: 4.045536994934082
training step: 43623, total_loss: 5.007335662841797
training step: 43624, total_loss: 4.489971160888672
training step: 43625, total_loss: 4.1195759773254395
training step: 43626, total_loss: 4.674163341522217
training step: 43627, total_loss: 4.535236358642578
training step: 43628, total_loss: 5.017517566680908
training step: 43629, total_loss: 3.9630560874938965
training step: 43630, total_loss: 2.5639424324035645
training step: 43631, total_loss: 4.771361351013184
training step: 43632, total_loss: 3.34602952003479
training step: 43633, total_loss: 5.2590789794921875
training step: 43634, total_loss: 4.093105316162109
training step: 43635, total_loss: 3.845369577407837
training step: 43636, total_loss: 5.133544921875
training step: 43637, total_loss: 3.776437520980835
training step: 43638, total_loss: 5.3350114822387695
training step: 43639, total_loss: 5.293491363525391
training step: 43640, total_loss: 3.9153847694396973
training step: 43641, total_loss: 4.30484676361084
training step: 43642, total_loss: 4.119356155395508
training step: 43643, total_loss: 2.3124380111694336
training step: 43644, total_loss: 3.9024558067321777
training step: 43645, total_loss: 3.26540470123291
training step: 43646, total_loss: 3.639169216156006
training step: 43647, total_loss: 4.832971572875977
training step: 43648, total_loss: 4.473082065582275
training step: 43649, total_loss: 4.9076409339904785
training step: 43650, total_loss: 2.22147536277771
training step: 43651, total_loss: 3.667569398880005
training step: 43652, total_loss: 4.248113632202148
training step: 43653, total_loss: 3.880880355834961
training step: 43654, total_loss: 5.681026458740234
training step: 43655, total_loss: 4.342473983764648
training step: 43656, total_loss: 4.33556604385376
training step: 43657, total_loss: 4.538529396057129
training step: 43658, total_loss: 5.074375152587891
training step: 43659, total_loss: 4.035605430603027
training step: 43660, total_loss: 3.981210708618164
training step: 43661, total_loss: 4.022004127502441
training step: 43662, total_loss: 2.401153087615967
training step: 43663, total_loss: 3.7670466899871826
training step: 43664, total_loss: 3.9099080562591553
training step: 43665, total_loss: 5.197961807250977
training step: 43666, total_loss: 1.4119969606399536
training step: 43667, total_loss: 6.1749114990234375
training step: 43668, total_loss: 3.485854148864746
training step: 43669, total_loss: 5.154973983764648
training step: 43670, total_loss: 3.862048625946045
training step: 43671, total_loss: 4.700891494750977
training step: 43672, total_loss: 0.9506127834320068
training step: 43673, total_loss: 4.364499092102051
training step: 43674, total_loss: 5.042177200317383
training step: 43675, total_loss: 4.7784881591796875
training step: 43676, total_loss: 5.58415412902832
training step: 43677, total_loss: 3.760890007019043
training step: 43678, total_loss: 2.3455886840820312
training step: 43679, total_loss: 3.757260322570801
training step: 43680, total_loss: 6.384863376617432
training step: 43681, total_loss: 3.725583076477051
training step: 43682, total_loss: 4.695415019989014
training step: 43683, total_loss: 4.621180534362793
training step: 43684, total_loss: 6.034972190856934
training step: 43685, total_loss: 5.338693141937256
training step: 43686, total_loss: 5.025465488433838
training step: 43687, total_loss: 4.507030487060547
training step: 43688, total_loss: 3.547952651977539
training step: 43689, total_loss: 4.686717987060547
training step: 43690, total_loss: 5.17611837387085
training step: 43691, total_loss: 5.6429443359375
training step: 43692, total_loss: 1.0420206785202026
training step: 43693, total_loss: 5.322853088378906
training step: 43694, total_loss: 3.1028671264648438
training step: 43695, total_loss: 5.235350608825684
training step: 43696, total_loss: 4.006960391998291
training step: 43697, total_loss: 4.232572555541992
training step: 43698, total_loss: 4.34403133392334
training step: 43699, total_loss: 5.359251976013184
training step: 43700, total_loss: 4.4550347328186035
training step: 43701, total_loss: 4.973729133605957
training step: 43702, total_loss: 4.568339824676514
training step: 43703, total_loss: 5.336005687713623
training step: 43704, total_loss: 4.213179588317871
training step: 43705, total_loss: 5.638522148132324
training step: 43706, total_loss: 0.8742192983627319
training step: 43707, total_loss: 5.230578422546387
training step: 43708, total_loss: 4.5872111320495605
training step: 43709, total_loss: 5.054243087768555
training step: 43710, total_loss: 5.56971549987793
training step: 43711, total_loss: 5.504016876220703
training step: 43712, total_loss: 3.4366469383239746
training step: 43713, total_loss: 3.9798121452331543
training step: 43714, total_loss: 3.9031941890716553
training step: 43715, total_loss: 6.803269386291504
training step: 43716, total_loss: 5.10938835144043
training step: 43717, total_loss: 4.370591640472412
training step: 43718, total_loss: 4.942120552062988
training step: 43719, total_loss: 5.188957214355469
training step: 43720, total_loss: 3.2915329933166504
training step: 43721, total_loss: 4.3678789138793945
training step: 43722, total_loss: 4.125387191772461
training step: 43723, total_loss: 6.016092300415039
training step: 43724, total_loss: 3.9245054721832275
training step: 43725, total_loss: 1.116779088973999
training step: 43726, total_loss: 5.207854747772217
training step: 43727, total_loss: 4.15440559387207
training step: 43728, total_loss: 3.856942892074585
training step: 43729, total_loss: 5.2531914710998535
training step: 43730, total_loss: 4.642170429229736
training step: 43731, total_loss: 4.330478668212891
training step: 43732, total_loss: 3.927415370941162
training step: 43733, total_loss: 4.319777965545654
training step: 43734, total_loss: 3.1584978103637695
training step: 43735, total_loss: 6.080661296844482
training step: 43736, total_loss: 4.296591758728027
training step: 43737, total_loss: 4.455719947814941
training step: 43738, total_loss: 4.631374359130859
training step: 43739, total_loss: 3.2056849002838135
training step: 43740, total_loss: 2.640580177307129
training step: 43741, total_loss: 2.8682196140289307
training step: 43742, total_loss: 3.30606746673584
training step: 43743, total_loss: 4.602922439575195
training step: 43744, total_loss: 4.877842903137207
training step: 43745, total_loss: 5.492137432098389
training step: 43746, total_loss: 3.951288938522339
training step: 43747, total_loss: 3.9754743576049805
training step: 43748, total_loss: 3.798304557800293
training step: 43749, total_loss: 4.076413631439209
training step: 43750, total_loss: 4.668370723724365
training step: 43751, total_loss: 7.080595016479492
training step: 43752, total_loss: 3.736778736114502
training step: 43753, total_loss: 3.86120867729187
training step: 43754, total_loss: 3.6438517570495605
training step: 43755, total_loss: 4.144824028015137
training step: 43756, total_loss: 4.219252586364746
training step: 43757, total_loss: 4.81733512878418
training step: 43758, total_loss: 4.099038124084473
training step: 43759, total_loss: 3.981673240661621
training step: 43760, total_loss: 2.7085790634155273
training step: 43761, total_loss: 4.572298049926758
training step: 43762, total_loss: 4.332788467407227
training step: 43763, total_loss: 4.719509124755859
training step: 43764, total_loss: 4.115218639373779
training step: 43765, total_loss: 4.772722244262695
training step: 43766, total_loss: 4.974808692932129
training step: 43767, total_loss: 4.1090264320373535
training step: 43768, total_loss: 3.431135654449463
training step: 43769, total_loss: 3.1008458137512207
training step: 43770, total_loss: 3.8464720249176025
training step: 43771, total_loss: 2.9134202003479004
training step: 43772, total_loss: 3.5960612297058105
training step: 43773, total_loss: 4.3667378425598145
training step: 43774, total_loss: 1.0339059829711914
training step: 43775, total_loss: 5.220205307006836
training step: 43776, total_loss: 4.855278968811035
training step: 43777, total_loss: 2.783173084259033
training step: 43778, total_loss: 5.374148368835449
training step: 43779, total_loss: 4.34109354019165
training step: 43780, total_loss: 4.33353328704834
training step: 43781, total_loss: 2.195671558380127
training step: 43782, total_loss: 4.618368625640869
training step: 43783, total_loss: 6.1200714111328125
training step: 43784, total_loss: 3.267479658126831
training step: 43785, total_loss: 4.790255546569824
training step: 43786, total_loss: 3.652465581893921
training step: 43787, total_loss: 6.233612537384033
training step: 43788, total_loss: 4.441591739654541
training step: 43789, total_loss: 5.107946872711182
training step: 43790, total_loss: 5.092840671539307
training step: 43791, total_loss: 3.55159854888916
training step: 43792, total_loss: 4.195870399475098
training step: 43793, total_loss: 5.771791458129883
training step: 43794, total_loss: 6.573161602020264
training step: 43795, total_loss: 5.099458694458008
training step: 43796, total_loss: 5.430633068084717
training step: 43797, total_loss: 4.545887470245361
training step: 43798, total_loss: 2.4962573051452637
training step: 43799, total_loss: 4.731084823608398
training step: 43800, total_loss: 5.5160675048828125
training step: 43801, total_loss: 3.254805564880371
training step: 43802, total_loss: 3.7791571617126465
training step: 43803, total_loss: 5.7497639656066895
training step: 43804, total_loss: 5.206424713134766
training step: 43805, total_loss: 4.91461181640625
training step: 43806, total_loss: 7.303553104400635
training step: 43807, total_loss: 5.528165340423584
training step: 43808, total_loss: 6.010846138000488
training step: 43809, total_loss: 2.442431926727295
training step: 43810, total_loss: 3.989485263824463
training step: 43811, total_loss: 5.946376323699951
training step: 43812, total_loss: 2.2122910022735596
training step: 43813, total_loss: 5.434055805206299
training step: 43814, total_loss: 3.546663761138916
training step: 43815, total_loss: 4.551469326019287
training step: 43816, total_loss: 4.614257335662842
training step: 43817, total_loss: 4.526455879211426
training step: 43818, total_loss: 6.450656414031982
training step: 43819, total_loss: 5.486223220825195
training step: 43820, total_loss: 4.295198917388916
training step: 43821, total_loss: 5.4550275802612305
training step: 43822, total_loss: 3.8982131481170654
training step: 43823, total_loss: 3.470829486846924
training step: 43824, total_loss: 4.562598705291748
training step: 43825, total_loss: 3.6880338191986084
training step: 43826, total_loss: 3.9451370239257812
training step: 43827, total_loss: 5.198545455932617
training step: 43828, total_loss: 4.9258198738098145
training step: 43829, total_loss: 3.530270576477051
training step: 43830, total_loss: 3.791802406311035
training step: 43831, total_loss: 4.038343906402588
training step: 43832, total_loss: 0.973061203956604
training step: 43833, total_loss: 0.9818671345710754
training step: 43834, total_loss: 3.339989185333252
training step: 43835, total_loss: 4.946349143981934
training step: 43836, total_loss: 3.948806047439575
training step: 43837, total_loss: 5.202425956726074
training step: 43838, total_loss: 3.247654914855957
training step: 43839, total_loss: 5.196593284606934
training step: 43840, total_loss: 3.092175006866455
training step: 43841, total_loss: 3.3578033447265625
training step: 43842, total_loss: 4.849175453186035
training step: 43843, total_loss: 5.329536437988281
training step: 43844, total_loss: 4.060430526733398
training step: 43845, total_loss: 4.789456844329834
training step: 43846, total_loss: 3.2664034366607666
training step: 43847, total_loss: 5.554422855377197
training step: 43848, total_loss: 5.650279998779297
training step: 43849, total_loss: 3.4616360664367676
training step: 43850, total_loss: 5.103201866149902
training step: 43851, total_loss: 5.67901086807251
training step: 43852, total_loss: 3.727118492126465
training step: 43853, total_loss: 4.318348407745361
training step: 43854, total_loss: 2.8375654220581055
training step: 43855, total_loss: 2.9053874015808105
training step: 43856, total_loss: 4.058131694793701
training step: 43857, total_loss: 1.0888773202896118
training step: 43858, total_loss: 5.603273868560791
training step: 43859, total_loss: 4.9924116134643555
training step: 43860, total_loss: 4.826385021209717
training step: 43861, total_loss: 5.068357467651367
training step: 43862, total_loss: 4.486496448516846
training step: 43863, total_loss: 5.36347770690918
training step: 43864, total_loss: 3.730175256729126
training step: 43865, total_loss: 4.9671854972839355
training step: 43866, total_loss: 4.406632423400879
training step: 43867, total_loss: 5.388874053955078
training step: 43868, total_loss: 3.4051513671875
training step: 43869, total_loss: 3.39229679107666
training step: 43870, total_loss: 6.307949066162109
training step: 43871, total_loss: 4.938479900360107
training step: 43872, total_loss: 3.5131728649139404
training step: 43873, total_loss: 2.6382129192352295
training step: 43874, total_loss: 4.006496429443359
training step: 43875, total_loss: 4.176975250244141
training step: 43876, total_loss: 6.110872268676758
training step: 43877, total_loss: 3.9782230854034424
training step: 43878, total_loss: 5.062922477722168
training step: 43879, total_loss: 3.9954476356506348
training step: 43880, total_loss: 5.0872907638549805
training step: 43881, total_loss: 2.3653764724731445
training step: 43882, total_loss: 6.3208770751953125
training step: 43883, total_loss: 5.611697196960449
training step: 43884, total_loss: 4.453117370605469
training step: 43885, total_loss: 5.193578720092773
training step: 43886, total_loss: 4.60872745513916
training step: 43887, total_loss: 5.051643371582031
training step: 43888, total_loss: 4.583217620849609
training step: 43889, total_loss: 3.7129759788513184
training step: 43890, total_loss: 4.3444414138793945
training step: 43891, total_loss: 5.410192489624023
training step: 43892, total_loss: 5.668575286865234
training step: 43893, total_loss: 3.397257089614868
training step: 43894, total_loss: 5.431107997894287
training step: 43895, total_loss: 4.477862358093262
training step: 43896, total_loss: 6.098669528961182
training step: 43897, total_loss: 3.6441469192504883
training step: 43898, total_loss: 4.308077812194824
training step: 43899, total_loss: 5.166896820068359
training step: 43900, total_loss: 3.684905529022217
training step: 43901, total_loss: 3.4317777156829834
training step: 43902, total_loss: 5.396877288818359
training step: 43903, total_loss: 3.914062976837158
training step: 43904, total_loss: 5.226071357727051
training step: 43905, total_loss: 4.869214057922363
training step: 43906, total_loss: 4.913153171539307
training step: 43907, total_loss: 1.03769052028656
training step: 43908, total_loss: 5.445562362670898
training step: 43909, total_loss: 4.25777530670166
training step: 43910, total_loss: 5.8576531410217285
training step: 43911, total_loss: 5.192154884338379
training step: 43912, total_loss: 4.33938455581665
training step: 43913, total_loss: 5.246822357177734
training step: 43914, total_loss: 3.4128623008728027
training step: 43915, total_loss: 2.6149749755859375
training step: 43916, total_loss: 5.399253845214844
training step: 43917, total_loss: 3.876756191253662
training step: 43918, total_loss: 4.188481330871582
training step: 43919, total_loss: 3.8376688957214355
training step: 43920, total_loss: 5.0414628982543945
training step: 43921, total_loss: 4.040494441986084
training step: 43922, total_loss: 4.420022964477539
training step: 43923, total_loss: 4.221330165863037
training step: 43924, total_loss: 5.212778091430664
training step: 43925, total_loss: 4.770211219787598
training step: 43926, total_loss: 5.240847587585449
training step: 43927, total_loss: 3.7535274028778076
training step: 43928, total_loss: 4.469461441040039
training step: 43929, total_loss: 5.160370826721191
training step: 43930, total_loss: 4.279780387878418
training step: 43931, total_loss: 3.1524829864501953
training step: 43932, total_loss: 2.277390480041504
training step: 43933, total_loss: 4.338127136230469
training step: 43934, total_loss: 4.663888454437256
training step: 43935, total_loss: 4.478121757507324
training step: 43936, total_loss: 3.288233757019043
training step: 43937, total_loss: 4.325473785400391
training step: 43938, total_loss: 3.4853663444519043
training step: 43939, total_loss: 5.488992691040039
training step: 43940, total_loss: 3.591383457183838
training step: 43941, total_loss: 5.575773239135742
training step: 43942, total_loss: 4.410031318664551
training step: 43943, total_loss: 5.563626766204834
training step: 43944, total_loss: 5.7083282470703125
training step: 43945, total_loss: 2.984597682952881
training step: 43946, total_loss: 4.827776908874512
training step: 43947, total_loss: 4.842894077301025
training step: 43948, total_loss: 5.368283271789551
training step: 43949, total_loss: 3.328557014465332
training step: 43950, total_loss: 6.414899826049805
training step: 43951, total_loss: 4.509504318237305
training step: 43952, total_loss: 3.942988872528076
training step: 43953, total_loss: 3.9477803707122803
training step: 43954, total_loss: 5.4242329597473145
training step: 43955, total_loss: 3.8142271041870117
training step: 43956, total_loss: 4.71150016784668
training step: 43957, total_loss: 4.591797351837158
training step: 43958, total_loss: 3.1513686180114746
training step: 43959, total_loss: 3.2233972549438477
training step: 43960, total_loss: 3.774068832397461
training step: 43961, total_loss: 4.797691345214844
training step: 43962, total_loss: 3.3932321071624756
training step: 43963, total_loss: 5.727753639221191
training step: 43964, total_loss: 4.245594501495361
training step: 43965, total_loss: 3.831946849822998
training step: 43966, total_loss: 4.839761734008789
training step: 43967, total_loss: 1.794687271118164
training step: 43968, total_loss: 3.7216482162475586
training step: 43969, total_loss: 4.188042163848877
training step: 43970, total_loss: 5.052402496337891
training step: 43971, total_loss: 1.0738552808761597
training step: 43972, total_loss: 5.105730056762695
training step: 43973, total_loss: 4.490904808044434
training step: 43974, total_loss: 1.1463555097579956
training step: 43975, total_loss: 5.252907752990723
training step: 43976, total_loss: 3.142592430114746
training step: 43977, total_loss: 3.706484794616699
training step: 43978, total_loss: 3.3628089427948
training step: 43979, total_loss: 3.4519429206848145
training step: 43980, total_loss: 5.213479995727539
training step: 43981, total_loss: 5.426348686218262
training step: 43982, total_loss: 5.486029624938965
training step: 43983, total_loss: 4.472515106201172
training step: 43984, total_loss: 3.3313143253326416
training step: 43985, total_loss: 5.272430896759033
training step: 43986, total_loss: 2.9359381198883057
training step: 43987, total_loss: 4.954184532165527
training step: 43988, total_loss: 3.5793519020080566
training step: 43989, total_loss: 4.797143936157227
training step: 43990, total_loss: 3.68646240234375
training step: 43991, total_loss: 4.005403995513916
training step: 43992, total_loss: 5.75324821472168
training step: 43993, total_loss: 5.806918144226074
training step: 43994, total_loss: 3.5348727703094482
training step: 43995, total_loss: 3.5073370933532715
training step: 43996, total_loss: 5.000552177429199
training step: 43997, total_loss: 4.6735429763793945
training step: 43998, total_loss: 4.894305229187012
training step: 43999, total_loss: 4.469228267669678
training step: 44000, total_loss: 1.0018298625946045
training step: 44001, total_loss: 5.051901817321777
training step: 44002, total_loss: 1.0763397216796875
training step: 44003, total_loss: 4.866809844970703
training step: 44004, total_loss: 3.2616095542907715
training step: 44005, total_loss: 3.855729103088379
training step: 44006, total_loss: 6.197119235992432
training step: 44007, total_loss: 5.0592498779296875
training step: 44008, total_loss: 4.181650161743164
training step: 44009, total_loss: 4.157755374908447
training step: 44010, total_loss: 4.836173057556152
training step: 44011, total_loss: 5.648542404174805
training step: 44012, total_loss: 4.207343578338623
training step: 44013, total_loss: 5.497709274291992
training step: 44014, total_loss: 2.758591651916504
training step: 44015, total_loss: 3.1451573371887207
training step: 44016, total_loss: 4.776979446411133
training step: 44017, total_loss: 4.092674255371094
training step: 44018, total_loss: 5.527081489562988
training step: 44019, total_loss: 6.029376983642578
training step: 44020, total_loss: 4.321442604064941
training step: 44021, total_loss: 3.9165239334106445
training step: 44022, total_loss: 6.0918684005737305
training step: 44023, total_loss: 1.0126471519470215
training step: 44024, total_loss: 4.750359058380127
training step: 44025, total_loss: 4.163535118103027
training step: 44026, total_loss: 4.510165214538574
training step: 44027, total_loss: 4.321135520935059
training step: 44028, total_loss: 4.365518093109131
training step: 44029, total_loss: 3.3631765842437744
training step: 44030, total_loss: 4.324642181396484
training step: 44031, total_loss: 4.977732181549072
training step: 44032, total_loss: 4.105534553527832
training step: 44033, total_loss: 4.937198638916016
training step: 44034, total_loss: 4.02861213684082
training step: 44035, total_loss: 4.639410495758057
training step: 44036, total_loss: 5.130465984344482
training step: 44037, total_loss: 4.768834114074707
training step: 44038, total_loss: 2.1908726692199707
training step: 44039, total_loss: 5.165683746337891
training step: 44040, total_loss: 5.349481582641602
training step: 44041, total_loss: 3.7329800128936768
training step: 44042, total_loss: 7.610834121704102
training step: 44043, total_loss: 5.426632881164551
training step: 44044, total_loss: 6.010439395904541
training step: 44045, total_loss: 5.6451416015625
training step: 44046, total_loss: 4.5232391357421875
training step: 44047, total_loss: 3.9229822158813477
training step: 44048, total_loss: 4.456014633178711
training step: 44049, total_loss: 5.468487739562988
training step: 44050, total_loss: 5.2368059158325195
training step: 44051, total_loss: 4.3403801918029785
training step: 44052, total_loss: 4.0629377365112305
training step: 44053, total_loss: 4.609035015106201
training step: 44054, total_loss: 3.2378053665161133
training step: 44055, total_loss: 4.570734977722168
training step: 44056, total_loss: 0.9984872341156006
training step: 44057, total_loss: 4.387343406677246
training step: 44058, total_loss: 5.12993860244751
training step: 44059, total_loss: 4.629499435424805
training step: 44060, total_loss: 4.621196746826172
training step: 44061, total_loss: 4.2849016189575195
training step: 44062, total_loss: 2.808652400970459
training step: 44063, total_loss: 5.4045915603637695
training step: 44064, total_loss: 4.644818305969238
training step: 44065, total_loss: 2.3654747009277344
training step: 44066, total_loss: 3.924600601196289
training step: 44067, total_loss: 5.165764331817627
training step: 44068, total_loss: 3.2595696449279785
training step: 44069, total_loss: 3.7602224349975586
training step: 44070, total_loss: 2.4829742908477783
training step: 44071, total_loss: 4.542112350463867
training step: 44072, total_loss: 7.341931343078613
training step: 44073, total_loss: 4.914739608764648
training step: 44074, total_loss: 3.8454091548919678
training step: 44075, total_loss: 4.0662126541137695
training step: 44076, total_loss: 4.779983997344971
training step: 44077, total_loss: 4.049490451812744
training step: 44078, total_loss: 5.043285369873047
training step: 44079, total_loss: 4.338672161102295
training step: 44080, total_loss: 3.236525058746338
training step: 44081, total_loss: 5.356347560882568
training step: 44082, total_loss: 3.4194836616516113
training step: 44083, total_loss: 2.2888031005859375
training step: 44084, total_loss: 3.2461087703704834
training step: 44085, total_loss: 3.9434781074523926
training step: 44086, total_loss: 3.6176462173461914
training step: 44087, total_loss: 5.600805282592773
training step: 44088, total_loss: 2.2299275398254395
training step: 44089, total_loss: 3.245081901550293
training step: 44090, total_loss: 4.640522480010986
training step: 44091, total_loss: 2.197484016418457
training step: 44092, total_loss: 5.882672309875488
training step: 44093, total_loss: 4.71303129196167
training step: 44094, total_loss: 5.677774906158447
training step: 44095, total_loss: 4.5018534660339355
training step: 44096, total_loss: 5.057183265686035
training step: 44097, total_loss: 5.5735907554626465
training step: 44098, total_loss: 5.177642345428467
training step: 44099, total_loss: 5.732850074768066
training step: 44100, total_loss: 5.0731611251831055
training step: 44101, total_loss: 3.782042980194092
training step: 44102, total_loss: 5.248016357421875
training step: 44103, total_loss: 6.124308109283447
training step: 44104, total_loss: 3.9189631938934326
training step: 44105, total_loss: 4.304853439331055
training step: 44106, total_loss: 4.513035774230957
training step: 44107, total_loss: 4.409721374511719
training step: 44108, total_loss: 4.333920955657959
training step: 44109, total_loss: 4.248202800750732
training step: 44110, total_loss: 4.143851280212402
training step: 44111, total_loss: 4.045740127563477
training step: 44112, total_loss: 4.8728485107421875
training step: 44113, total_loss: 4.85050106048584
training step: 44114, total_loss: 4.224922180175781
training step: 44115, total_loss: 4.92159366607666
training step: 44116, total_loss: 4.063990116119385
training step: 44117, total_loss: 3.1909523010253906
training step: 44118, total_loss: 4.3849077224731445
training step: 44119, total_loss: 3.1678531169891357
training step: 44120, total_loss: 3.9012980461120605
training step: 44121, total_loss: 6.725197792053223
training step: 44122, total_loss: 7.12131404876709
training step: 44123, total_loss: 4.039677619934082
training step: 44124, total_loss: 4.733051776885986
training step: 44125, total_loss: 4.026210784912109
training step: 44126, total_loss: 4.062543869018555
training step: 44127, total_loss: 4.2128682136535645
training step: 44128, total_loss: 4.48756742477417
training step: 44129, total_loss: 4.156782150268555
training step: 44130, total_loss: 4.46219539642334
training step: 44131, total_loss: 4.7257304191589355
training step: 44132, total_loss: 4.211038589477539
training step: 44133, total_loss: 6.248556137084961
training step: 44134, total_loss: 4.35224723815918
training step: 44135, total_loss: 3.8714277744293213
training step: 44136, total_loss: 2.662978172302246
training step: 44137, total_loss: 4.215783596038818
training step: 44138, total_loss: 4.647673606872559
training step: 44139, total_loss: 2.9928174018859863
training step: 44140, total_loss: 4.0202484130859375
training step: 44141, total_loss: 4.820651054382324
training step: 44142, total_loss: 3.5922484397888184
training step: 44143, total_loss: 5.281837463378906
training step: 44144, total_loss: 6.4309186935424805
training step: 44145, total_loss: 4.941675186157227
training step: 44146, total_loss: 5.042301654815674
training step: 44147, total_loss: 4.009487152099609
training step: 44148, total_loss: 4.974571704864502
training step: 44149, total_loss: 5.06036376953125
training step: 44150, total_loss: 3.908719539642334
training step: 44151, total_loss: 3.9651405811309814
training step: 44152, total_loss: 5.0547027587890625
training step: 44153, total_loss: 2.751730442047119
training step: 44154, total_loss: 4.462121963500977
training step: 44155, total_loss: 3.771576404571533
training step: 44156, total_loss: 3.383563995361328
training step: 44157, total_loss: 3.614438533782959
training step: 44158, total_loss: 3.9043498039245605
training step: 44159, total_loss: 3.286222219467163
training step: 44160, total_loss: 4.881058692932129
training step: 44161, total_loss: 3.616448402404785
training step: 44162, total_loss: 5.072452068328857
training step: 44163, total_loss: 3.790820598602295
training step: 44164, total_loss: 5.8839569091796875
training step: 44165, total_loss: 5.582887649536133
training step: 44166, total_loss: 4.602075576782227
training step: 44167, total_loss: 3.9150002002716064
training step: 44168, total_loss: 6.287141799926758
training step: 44169, total_loss: 4.637086868286133
training step: 44170, total_loss: 3.398225784301758
training step: 44171, total_loss: 5.317919731140137
training step: 44172, total_loss: 4.980676651000977
training step: 44173, total_loss: 2.5680670738220215
training step: 44174, total_loss: 3.663064479827881
training step: 44175, total_loss: 5.51845645904541
training step: 44176, total_loss: 4.56022310256958
training step: 44177, total_loss: 4.170334815979004
training step: 44178, total_loss: 4.053983688354492
training step: 44179, total_loss: 3.158432960510254
training step: 44180, total_loss: 6.088216781616211
training step: 44181, total_loss: 5.449728965759277
training step: 44182, total_loss: 4.824457168579102
training step: 44183, total_loss: 2.52984356880188
training step: 44184, total_loss: 4.375898361206055
training step: 44185, total_loss: 4.71978759765625
training step: 44186, total_loss: 3.8368148803710938
training step: 44187, total_loss: 3.5284876823425293
training step: 44188, total_loss: 4.772277355194092
training step: 44189, total_loss: 3.041530132293701
training step: 44190, total_loss: 5.533374786376953
training step: 44191, total_loss: 4.928321838378906
training step: 44192, total_loss: 6.681939125061035
training step: 44193, total_loss: 5.1446027755737305
training step: 44194, total_loss: 4.14620304107666
training step: 44195, total_loss: 6.010513782501221
training step: 44196, total_loss: 6.53804349899292
training step: 44197, total_loss: 4.957036018371582
training step: 44198, total_loss: 1.9722929000854492
training step: 44199, total_loss: 5.011539459228516
training step: 44200, total_loss: 1.2803170680999756
training step: 44201, total_loss: 4.696889400482178
training step: 44202, total_loss: 4.0358967781066895
training step: 44203, total_loss: 3.8094420433044434
training step: 44204, total_loss: 4.028880596160889
training step: 44205, total_loss: 3.3531479835510254
training step: 44206, total_loss: 5.093666076660156
training step: 44207, total_loss: 5.590490341186523
training step: 44208, total_loss: 4.2386322021484375
training step: 44209, total_loss: 4.278173446655273
training step: 44210, total_loss: 3.694798469543457
training step: 44211, total_loss: 4.892209529876709
training step: 44212, total_loss: 6.088727951049805
training step: 44213, total_loss: 1.0332735776901245
training step: 44214, total_loss: 5.375154972076416
training step: 44215, total_loss: 4.372447967529297
training step: 44216, total_loss: 5.497720718383789
training step: 44217, total_loss: 3.913753032684326
training step: 44218, total_loss: 3.6767892837524414
training step: 44219, total_loss: 1.0233509540557861
training step: 44220, total_loss: 4.027885913848877
training step: 44221, total_loss: 3.9878652095794678
training step: 44222, total_loss: 4.0425848960876465
training step: 44223, total_loss: 4.157657146453857
training step: 44224, total_loss: 5.501357078552246
training step: 44225, total_loss: 4.10823917388916
training step: 44226, total_loss: 4.241374969482422
training step: 44227, total_loss: 4.7864089012146
training step: 44228, total_loss: 3.6061110496520996
training step: 44229, total_loss: 5.54227352142334
training step: 44230, total_loss: 6.295774459838867
training step: 44231, total_loss: 3.7538533210754395
training step: 44232, total_loss: 4.423322677612305
training step: 44233, total_loss: 4.739111423492432
training step: 44234, total_loss: 2.8355889320373535
training step: 44235, total_loss: 3.6114139556884766
training step: 44236, total_loss: 5.7522664070129395
training step: 44237, total_loss: 4.461464881896973
training step: 44238, total_loss: 4.375091552734375
training step: 44239, total_loss: 4.074036121368408
training step: 44240, total_loss: 3.7368505001068115
training step: 44241, total_loss: 3.563673734664917
training step: 44242, total_loss: 2.5755057334899902
training step: 44243, total_loss: 3.76377534866333
training step: 44244, total_loss: 4.126521110534668
training step: 44245, total_loss: 3.8946313858032227
training step: 44246, total_loss: 3.9497735500335693
training step: 44247, total_loss: 4.629359722137451
training step: 44248, total_loss: 5.6199750900268555
training step: 44249, total_loss: 4.373234272003174
training step: 44250, total_loss: 4.77987003326416
training step: 44251, total_loss: 5.8336381912231445
training step: 44252, total_loss: 3.9591896533966064
training step: 44253, total_loss: 0.8974723815917969
training step: 44254, total_loss: 5.519183158874512
training step: 44255, total_loss: 4.173847198486328
training step: 44256, total_loss: 4.070587635040283
training step: 44257, total_loss: 3.1733791828155518
training step: 44258, total_loss: 4.493055820465088
training step: 44259, total_loss: 5.696401596069336
training step: 44260, total_loss: 4.210139274597168
training step: 44261, total_loss: 5.7382917404174805
training step: 44262, total_loss: 6.086554527282715
training step: 44263, total_loss: 0.8920906782150269
training step: 44264, total_loss: 2.736268997192383
training step: 44265, total_loss: 4.860001564025879
training step: 44266, total_loss: 4.307835578918457
training step: 44267, total_loss: 5.49482536315918
training step: 44268, total_loss: 4.294343948364258
training step: 44269, total_loss: 4.600274085998535
training step: 44270, total_loss: 4.153783798217773
training step: 44271, total_loss: 7.06844425201416
training step: 44272, total_loss: 4.491891384124756
training step: 44273, total_loss: 3.611456871032715
training step: 44274, total_loss: 4.417352199554443
training step: 44275, total_loss: 4.632721900939941
training step: 44276, total_loss: 4.433798789978027
training step: 44277, total_loss: 1.271512746810913
training step: 44278, total_loss: 3.5540804862976074
training step: 44279, total_loss: 3.599670886993408
training step: 44280, total_loss: 5.534080505371094
training step: 44281, total_loss: 5.034416198730469
training step: 44282, total_loss: 5.016365051269531
training step: 44283, total_loss: 5.828784465789795
training step: 44284, total_loss: 4.168319225311279
training step: 44285, total_loss: 0.9517863392829895
training step: 44286, total_loss: 4.733884811401367
training step: 44287, total_loss: 3.75000262260437
training step: 44288, total_loss: 4.076658248901367
training step: 44289, total_loss: 3.311208724975586
training step: 44290, total_loss: 4.666403293609619
training step: 44291, total_loss: 4.379666328430176
training step: 44292, total_loss: 5.170328617095947
training step: 44293, total_loss: 6.14195442199707
training step: 44294, total_loss: 3.7580578327178955
training step: 44295, total_loss: 3.5231339931488037
training step: 44296, total_loss: 3.769916534423828
training step: 44297, total_loss: 4.6479716300964355
training step: 44298, total_loss: 4.4600830078125
training step: 44299, total_loss: 3.7298526763916016
training step: 44300, total_loss: 4.100502014160156
training step: 44301, total_loss: 3.617621898651123
training step: 44302, total_loss: 1.3946890830993652
training step: 44303, total_loss: 5.0111236572265625
training step: 44304, total_loss: 3.6722707748413086
training step: 44305, total_loss: 4.580187797546387
training step: 44306, total_loss: 4.657624244689941
training step: 44307, total_loss: 3.216829299926758
training step: 44308, total_loss: 4.971621990203857
training step: 44309, total_loss: 4.968292713165283
training step: 44310, total_loss: 4.829301834106445
training step: 44311, total_loss: 3.0755507946014404
training step: 44312, total_loss: 4.451169967651367
training step: 44313, total_loss: 4.500298500061035
training step: 44314, total_loss: 3.96976375579834
training step: 44315, total_loss: 4.891828536987305
training step: 44316, total_loss: 5.8783860206604
training step: 44317, total_loss: 3.508450984954834
training step: 44318, total_loss: 4.324718952178955
training step: 44319, total_loss: 6.252012729644775
training step: 44320, total_loss: 4.1504225730896
training step: 44321, total_loss: 4.839369773864746
training step: 44322, total_loss: 4.861616134643555
training step: 44323, total_loss: 4.191349983215332
training step: 44324, total_loss: 3.776155471801758
training step: 44325, total_loss: 4.0737152099609375
training step: 44326, total_loss: 5.031355857849121
training step: 44327, total_loss: 4.516834259033203
training step: 44328, total_loss: 4.107966423034668
training step: 44329, total_loss: 5.608787536621094
training step: 44330, total_loss: 3.9040188789367676
training step: 44331, total_loss: 5.056709289550781
training step: 44332, total_loss: 3.836561441421509
training step: 44333, total_loss: 5.751795768737793
training step: 44334, total_loss: 4.342189788818359
training step: 44335, total_loss: 3.675189256668091
training step: 44336, total_loss: 4.960628986358643
training step: 44337, total_loss: 4.407970428466797
training step: 44338, total_loss: 4.237119674682617
training step: 44339, total_loss: 3.322805881500244
training step: 44340, total_loss: 3.740926742553711
training step: 44341, total_loss: 5.501750946044922
training step: 44342, total_loss: 3.634850263595581
training step: 44343, total_loss: 4.761504173278809
training step: 44344, total_loss: 3.307094097137451
training step: 44345, total_loss: 1.3113713264465332
training step: 44346, total_loss: 5.386704921722412
training step: 44347, total_loss: 4.04557466506958
training step: 44348, total_loss: 5.125699996948242
training step: 44349, total_loss: 4.751702308654785
training step: 44350, total_loss: 7.614999771118164
training step: 44351, total_loss: 4.7925214767456055
training step: 44352, total_loss: 0.9754362106323242
training step: 44353, total_loss: 4.772750377655029
training step: 44354, total_loss: 4.1919755935668945
training step: 44355, total_loss: 3.9503180980682373
training step: 44356, total_loss: 4.5550971031188965
training step: 44357, total_loss: 5.504467964172363
training step: 44358, total_loss: 4.90826416015625
training step: 44359, total_loss: 4.8050642013549805
training step: 44360, total_loss: 5.058919429779053
training step: 44361, total_loss: 2.2592225074768066
training step: 44362, total_loss: 3.790667772293091
training step: 44363, total_loss: 3.8376314640045166
training step: 44364, total_loss: 3.586841583251953
training step: 44365, total_loss: 5.051815986633301
training step: 44366, total_loss: 3.4859228134155273
training step: 44367, total_loss: 5.150104522705078
training step: 44368, total_loss: 4.549304008483887
training step: 44369, total_loss: 4.606081008911133
training step: 44370, total_loss: 4.372494220733643
training step: 44371, total_loss: 3.9454245567321777
training step: 44372, total_loss: 2.91715407371521
training step: 44373, total_loss: 5.3498029708862305
training step: 44374, total_loss: 4.253622531890869
training step: 44375, total_loss: 4.1327972412109375
training step: 44376, total_loss: 4.904563903808594
training step: 44377, total_loss: 5.0168867111206055
training step: 44378, total_loss: 3.051176071166992
training step: 44379, total_loss: 3.4332542419433594
training step: 44380, total_loss: 5.018487930297852
training step: 44381, total_loss: 4.99899959564209
training step: 44382, total_loss: 4.714208126068115
training step: 44383, total_loss: 3.9182581901550293
training step: 44384, total_loss: 4.685764789581299
training step: 44385, total_loss: 3.915463924407959
training step: 44386, total_loss: 4.728209972381592
training step: 44387, total_loss: 5.179805755615234
training step: 44388, total_loss: 1.1381222009658813
training step: 44389, total_loss: 3.762146472930908
training step: 44390, total_loss: 2.1939680576324463
training step: 44391, total_loss: 5.195373058319092
training step: 44392, total_loss: 6.110169410705566
training step: 44393, total_loss: 4.343181610107422
training step: 44394, total_loss: 4.280580997467041
training step: 44395, total_loss: 3.1257269382476807
training step: 44396, total_loss: 4.187816619873047
training step: 44397, total_loss: 2.26776385307312
training step: 44398, total_loss: 3.9301724433898926
training step: 44399, total_loss: 4.483360767364502
training step: 44400, total_loss: 3.2254600524902344
training step: 44401, total_loss: 5.692289352416992
training step: 44402, total_loss: 4.135152339935303
training step: 44403, total_loss: 2.054821729660034
training step: 44404, total_loss: 4.182621002197266
training step: 44405, total_loss: 4.428770065307617
training step: 44406, total_loss: 3.1225810050964355
training step: 44407, total_loss: 2.3458666801452637
training step: 44408, total_loss: 2.3199381828308105
training step: 44409, total_loss: 3.7548599243164062
training step: 44410, total_loss: 4.773577690124512
training step: 44411, total_loss: 7.340391159057617
training step: 44412, total_loss: 3.535979747772217
training step: 44413, total_loss: 4.717693328857422
training step: 44414, total_loss: 4.194479942321777
training step: 44415, total_loss: 4.165323257446289
training step: 44416, total_loss: 3.5848748683929443
training step: 44417, total_loss: 4.880375862121582
training step: 44418, total_loss: 5.579945087432861
training step: 44419, total_loss: 5.855530738830566
training step: 44420, total_loss: 5.490415573120117
training step: 44421, total_loss: 5.331948280334473
training step: 44422, total_loss: 4.686142444610596
training step: 44423, total_loss: 4.977210998535156
training step: 44424, total_loss: 6.052451133728027
training step: 44425, total_loss: 2.672208786010742
training step: 44426, total_loss: 6.134075164794922
training step: 44427, total_loss: 3.928463935852051
training step: 44428, total_loss: 5.31118106842041
training step: 44429, total_loss: 0.9451637268066406
training step: 44430, total_loss: 7.344993591308594
training step: 44431, total_loss: 3.3441667556762695
training step: 44432, total_loss: 5.239201545715332
training step: 44433, total_loss: 4.873841285705566
training step: 44434, total_loss: 3.9942214488983154
training step: 44435, total_loss: 3.391627788543701
training step: 44436, total_loss: 5.047398567199707
training step: 44437, total_loss: 0.98430997133255
training step: 44438, total_loss: 4.408137321472168
training step: 44439, total_loss: 3.7389578819274902
training step: 44440, total_loss: 4.455362319946289
training step: 44441, total_loss: 5.634781837463379
training step: 44442, total_loss: 5.543802261352539
training step: 44443, total_loss: 4.751036643981934
training step: 44444, total_loss: 4.708136558532715
training step: 44445, total_loss: 5.840266227722168
training step: 44446, total_loss: 3.06882643699646
training step: 44447, total_loss: 4.71423864364624
training step: 44448, total_loss: 3.875673294067383
training step: 44449, total_loss: 3.376317262649536
training step: 44450, total_loss: 5.78386926651001
training step: 44451, total_loss: 4.337108612060547
training step: 44452, total_loss: 5.207340717315674
training step: 44453, total_loss: 4.299219131469727
training step: 44454, total_loss: 4.11057186126709
training step: 44455, total_loss: 4.419062614440918
training step: 44456, total_loss: 3.4069952964782715
training step: 44457, total_loss: 5.34718656539917
training step: 44458, total_loss: 3.5085361003875732
training step: 44459, total_loss: 4.269073963165283
training step: 44460, total_loss: 4.238698959350586
training step: 44461, total_loss: 4.728620529174805
training step: 44462, total_loss: 5.554426670074463
training step: 44463, total_loss: 4.204404830932617
training step: 44464, total_loss: 6.923552513122559
training step: 44465, total_loss: 3.889068126678467
training step: 44466, total_loss: 4.558920383453369
training step: 44467, total_loss: 4.339061737060547
training step: 44468, total_loss: 3.992368221282959
training step: 44469, total_loss: 3.724085807800293
training step: 44470, total_loss: 5.638577938079834
training step: 44471, total_loss: 3.7484984397888184
training step: 44472, total_loss: 5.255868911743164
training step: 44473, total_loss: 4.094914436340332
training step: 44474, total_loss: 5.930566310882568
training step: 44475, total_loss: 5.273231029510498
training step: 44476, total_loss: 3.619074821472168
training step: 44477, total_loss: 4.947598457336426
training step: 44478, total_loss: 6.707582950592041
training step: 44479, total_loss: 4.792724609375
training step: 44480, total_loss: 5.084294319152832
training step: 44481, total_loss: 3.6866044998168945
training step: 44482, total_loss: 4.262445449829102
training step: 44483, total_loss: 4.432621479034424
training step: 44484, total_loss: 5.758540630340576
training step: 44485, total_loss: 5.417341232299805
training step: 44486, total_loss: 5.123924255371094
training step: 44487, total_loss: 5.427195072174072
training step: 44488, total_loss: 4.0483078956604
training step: 44489, total_loss: 1.142289161682129
training step: 44490, total_loss: 3.308011054992676
training step: 44491, total_loss: 4.184513568878174
training step: 44492, total_loss: 4.649850368499756
training step: 44493, total_loss: 4.014497756958008
training step: 44494, total_loss: 1.1538712978363037
training step: 44495, total_loss: 3.241213321685791
training step: 44496, total_loss: 6.330578804016113
training step: 44497, total_loss: 4.371077060699463
training step: 44498, total_loss: 2.174905776977539
training step: 44499, total_loss: 3.4655184745788574
training step: 44500, total_loss: 4.485176086425781
training step: 44501, total_loss: 3.069512128829956
training step: 44502, total_loss: 4.680670261383057
training step: 44503, total_loss: 4.142533779144287
training step: 44504, total_loss: 5.982699871063232
training step: 44505, total_loss: 4.212933540344238
training step: 44506, total_loss: 3.383368968963623
training step: 44507, total_loss: 3.3601937294006348
training step: 44508, total_loss: 5.474535942077637
training step: 44509, total_loss: 5.478115081787109
training step: 44510, total_loss: 5.214287281036377
training step: 44511, total_loss: 2.953974962234497
training step: 44512, total_loss: 5.3444623947143555
training step: 44513, total_loss: 4.562304496765137
training step: 44514, total_loss: 5.526770114898682
training step: 44515, total_loss: 5.460555076599121
training step: 44516, total_loss: 4.225902080535889
training step: 44517, total_loss: 5.999451637268066
training step: 44518, total_loss: 5.1019697189331055
training step: 44519, total_loss: 3.7199883460998535
training step: 44520, total_loss: 4.128664016723633
training step: 44521, total_loss: 5.417928218841553
training step: 44522, total_loss: 4.087665557861328
training step: 44523, total_loss: 6.247727870941162
training step: 44524, total_loss: 4.331819534301758
training step: 44525, total_loss: 4.628331184387207
training step: 44526, total_loss: 4.341394901275635
training step: 44527, total_loss: 4.31952428817749
training step: 44528, total_loss: 3.665666103363037
training step: 44529, total_loss: 4.662981986999512
training step: 44530, total_loss: 5.054804801940918
training step: 44531, total_loss: 5.579524517059326
training step: 44532, total_loss: 4.9423112869262695
training step: 44533, total_loss: 3.8691611289978027
training step: 44534, total_loss: 2.9136857986450195
training step: 44535, total_loss: 3.860006809234619
training step: 44536, total_loss: 3.0400097370147705
training step: 44537, total_loss: 5.005049705505371
training step: 44538, total_loss: 4.7342939376831055
training step: 44539, total_loss: 4.521309852600098
training step: 44540, total_loss: 4.184133529663086
training step: 44541, total_loss: 4.398623943328857
training step: 44542, total_loss: 3.637540340423584
training step: 44543, total_loss: 5.595965385437012
training step: 44544, total_loss: 2.9526772499084473
training step: 44545, total_loss: 4.718044281005859
training step: 44546, total_loss: 4.879059791564941
training step: 44547, total_loss: 4.286139488220215
training step: 44548, total_loss: 5.387172698974609
training step: 44549, total_loss: 4.252109527587891
training step: 44550, total_loss: 4.207703113555908
training step: 44551, total_loss: 3.1473388671875
training step: 44552, total_loss: 5.456472873687744
training step: 44553, total_loss: 4.752242088317871
training step: 44554, total_loss: 5.010562896728516
training step: 44555, total_loss: 3.888805627822876
training step: 44556, total_loss: 5.741518020629883
training step: 44557, total_loss: 5.665898323059082
training step: 44558, total_loss: 4.760171413421631
training step: 44559, total_loss: 3.3650155067443848
training step: 44560, total_loss: 4.515423774719238
training step: 44561, total_loss: 4.7843828201293945
training step: 44562, total_loss: 4.773051738739014
training step: 44563, total_loss: 4.8813982009887695
training step: 44564, total_loss: 5.7331862449646
training step: 44565, total_loss: 4.827124118804932
training step: 44566, total_loss: 3.009645938873291
training step: 44567, total_loss: 4.530999183654785
training step: 44568, total_loss: 4.300324440002441
training step: 44569, total_loss: 4.656774520874023
training step: 44570, total_loss: 4.460386276245117
training step: 44571, total_loss: 4.296471118927002
training step: 44572, total_loss: 4.180052280426025
training step: 44573, total_loss: 5.985036849975586
training step: 44574, total_loss: 4.192411422729492
training step: 44575, total_loss: 5.413021087646484
training step: 44576, total_loss: 4.810131072998047
training step: 44577, total_loss: 5.854905605316162
training step: 44578, total_loss: 4.175273895263672
training step: 44579, total_loss: 2.3981223106384277
training step: 44580, total_loss: 4.6046295166015625
training step: 44581, total_loss: 5.233721733093262
training step: 44582, total_loss: 5.094209671020508
training step: 44583, total_loss: 3.9395480155944824
training step: 44584, total_loss: 3.203770160675049
training step: 44585, total_loss: 2.410209894180298
training step: 44586, total_loss: 3.3223438262939453
training step: 44587, total_loss: 4.603580474853516
training step: 44588, total_loss: 4.105239391326904
training step: 44589, total_loss: 2.7717528343200684
training step: 44590, total_loss: 3.521521806716919
training step: 44591, total_loss: 4.614299774169922
training step: 44592, total_loss: 5.2294816970825195
training step: 44593, total_loss: 4.561666011810303
training step: 44594, total_loss: 3.7918403148651123
training step: 44595, total_loss: 5.263419151306152
training step: 44596, total_loss: 5.0374755859375
training step: 44597, total_loss: 5.641086578369141
training step: 44598, total_loss: 2.328566789627075
training step: 44599, total_loss: 3.594957113265991
training step: 44600, total_loss: 4.904212951660156
training step: 44601, total_loss: 3.8293914794921875
training step: 44602, total_loss: 2.921367883682251
training step: 44603, total_loss: 4.01518440246582
training step: 44604, total_loss: 2.7049214839935303
training step: 44605, total_loss: 4.632148742675781
training step: 44606, total_loss: 1.3773372173309326
training step: 44607, total_loss: 6.507717132568359
training step: 44608, total_loss: 4.070676803588867
training step: 44609, total_loss: 5.5018134117126465
training step: 44610, total_loss: 2.938396453857422
training step: 44611, total_loss: 3.934328079223633
training step: 44612, total_loss: 4.212334632873535
training step: 44613, total_loss: 3.0670552253723145
training step: 44614, total_loss: 3.9240565299987793
training step: 44615, total_loss: 0.9766860604286194
epoch finished! shuffle=True
training step: 44616, total_loss: 2.892580986022949
training step: 44617, total_loss: 3.541856288909912
training step: 44618, total_loss: 5.581579208374023
training step: 44619, total_loss: 3.9536855220794678
training step: 44620, total_loss: 5.942022323608398
training step: 44621, total_loss: 4.323360443115234
training step: 44622, total_loss: 4.8275909423828125
training step: 44623, total_loss: 3.756901741027832
training step: 44624, total_loss: 4.389232635498047
training step: 44625, total_loss: 4.6165618896484375
training step: 44626, total_loss: 3.5583138465881348
training step: 44627, total_loss: 5.933304786682129
training step: 44628, total_loss: 4.212204456329346
training step: 44629, total_loss: 4.442259311676025
training step: 44630, total_loss: 1.184024691581726
training step: 44631, total_loss: 4.251314163208008
training step: 44632, total_loss: 3.062485694885254
training step: 44633, total_loss: 3.677393674850464
training step: 44634, total_loss: 3.7633252143859863
training step: 44635, total_loss: 5.039341926574707
training step: 44636, total_loss: 5.230666160583496
training step: 44637, total_loss: 4.345706939697266
training step: 44638, total_loss: 6.834140300750732
training step: 44639, total_loss: 4.309628009796143
training step: 44640, total_loss: 4.254045486450195
training step: 44641, total_loss: 4.439524173736572
training step: 44642, total_loss: 4.634718418121338
training step: 44643, total_loss: 3.9968507289886475
training step: 44644, total_loss: 3.8660519123077393
training step: 44645, total_loss: 4.9029998779296875
training step: 44646, total_loss: 5.120573043823242
training step: 44647, total_loss: 4.608497619628906
training step: 44648, total_loss: 3.558835506439209
training step: 44649, total_loss: 3.7611632347106934
training step: 44650, total_loss: 4.834389686584473
training step: 44651, total_loss: 2.6540493965148926
training step: 44652, total_loss: 4.447216033935547
training step: 44653, total_loss: 4.764448165893555
training step: 44654, total_loss: 4.83247709274292
training step: 44655, total_loss: 4.634474754333496
training step: 44656, total_loss: 4.022698402404785
training step: 44657, total_loss: 4.965283393859863
training step: 44658, total_loss: 4.33851957321167
training step: 44659, total_loss: 2.737954616546631
training step: 44660, total_loss: 4.478459358215332
training step: 44661, total_loss: 4.482085704803467
training step: 44662, total_loss: 3.7689075469970703
training step: 44663, total_loss: 5.244566917419434
training step: 44664, total_loss: 4.67005729675293
training step: 44665, total_loss: 3.1777431964874268
training step: 44666, total_loss: 4.900903701782227
training step: 44667, total_loss: 4.49078893661499
training step: 44668, total_loss: 5.601602554321289
training step: 44669, total_loss: 5.3769073486328125
training step: 44670, total_loss: 2.287050247192383
training step: 44671, total_loss: 4.308221340179443
training step: 44672, total_loss: 4.075979232788086
training step: 44673, total_loss: 4.367623329162598
training step: 44674, total_loss: 3.9706151485443115
training step: 44675, total_loss: 4.112937927246094
training step: 44676, total_loss: 4.751793384552002
training step: 44677, total_loss: 5.444456100463867
training step: 44678, total_loss: 5.601327896118164
training step: 44679, total_loss: 2.4628098011016846
training step: 44680, total_loss: 4.01070499420166
training step: 44681, total_loss: 4.847583770751953
training step: 44682, total_loss: 4.817262649536133
training step: 44683, total_loss: 5.116214275360107
training step: 44684, total_loss: 4.499109268188477
training step: 44685, total_loss: 3.0767855644226074
training step: 44686, total_loss: 4.425214767456055
training step: 44687, total_loss: 4.0819549560546875
training step: 44688, total_loss: 4.405057907104492
training step: 44689, total_loss: 5.189981460571289
training step: 44690, total_loss: 5.8098955154418945
training step: 44691, total_loss: 3.8192138671875
training step: 44692, total_loss: 4.3167219161987305
training step: 44693, total_loss: 5.450896263122559
training step: 44694, total_loss: 3.3519930839538574
training step: 44695, total_loss: 5.709128379821777
training step: 44696, total_loss: 3.694396734237671
training step: 44697, total_loss: 3.8462181091308594
training step: 44698, total_loss: 6.345383644104004
training step: 44699, total_loss: 6.446005821228027
training step: 44700, total_loss: 2.9553685188293457
training step: 44701, total_loss: 4.283801555633545
training step: 44702, total_loss: 3.5075879096984863
training step: 44703, total_loss: 3.88468599319458
training step: 44704, total_loss: 4.770505905151367
training step: 44705, total_loss: 2.811708688735962
training step: 44706, total_loss: 5.6465229988098145
training step: 44707, total_loss: 6.571882247924805
training step: 44708, total_loss: 4.532808303833008
training step: 44709, total_loss: 4.534153938293457
training step: 44710, total_loss: 5.71897029876709
training step: 44711, total_loss: 2.4136714935302734
training step: 44712, total_loss: 4.312710762023926
training step: 44713, total_loss: 3.748548984527588
training step: 44714, total_loss: 3.9492852687835693
training step: 44715, total_loss: 4.697254657745361
training step: 44716, total_loss: 5.605165958404541
training step: 44717, total_loss: 4.122742652893066
training step: 44718, total_loss: 5.775920867919922
training step: 44719, total_loss: 4.815396308898926
training step: 44720, total_loss: 3.175473690032959
training step: 44721, total_loss: 4.145342826843262
training step: 44722, total_loss: 3.941169261932373
training step: 44723, total_loss: 4.637211322784424
training step: 44724, total_loss: 4.645177841186523
training step: 44725, total_loss: 5.207673072814941
training step: 44726, total_loss: 5.481015682220459
training step: 44727, total_loss: 5.5677947998046875
training step: 44728, total_loss: 5.672469139099121
training step: 44729, total_loss: 4.205830097198486
training step: 44730, total_loss: 2.2389369010925293
training step: 44731, total_loss: 3.527778148651123
training step: 44732, total_loss: 2.890984535217285
training step: 44733, total_loss: 4.107564449310303
training step: 44734, total_loss: 4.5916032791137695
training step: 44735, total_loss: 2.49332332611084
training step: 44736, total_loss: 3.999871253967285
training step: 44737, total_loss: 3.8513131141662598
training step: 44738, total_loss: 1.278470516204834
training step: 44739, total_loss: 5.911189079284668
training step: 44740, total_loss: 4.305619239807129
training step: 44741, total_loss: 4.362480640411377
training step: 44742, total_loss: 5.0635857582092285
training step: 44743, total_loss: 4.8484978675842285
training step: 44744, total_loss: 4.733433723449707
training step: 44745, total_loss: 4.901524543762207
training step: 44746, total_loss: 5.5556559562683105
training step: 44747, total_loss: 4.873008728027344
training step: 44748, total_loss: 4.435309886932373
training step: 44749, total_loss: 5.445174217224121
training step: 44750, total_loss: 3.4943337440490723
training step: 44751, total_loss: 5.602128028869629
training step: 44752, total_loss: 5.112773895263672
training step: 44753, total_loss: 5.036660194396973
training step: 44754, total_loss: 2.4824843406677246
training step: 44755, total_loss: 5.164917945861816
training step: 44756, total_loss: 4.514899253845215
training step: 44757, total_loss: 4.272521495819092
training step: 44758, total_loss: 4.862285614013672
training step: 44759, total_loss: 4.069447040557861
training step: 44760, total_loss: 5.249547958374023
training step: 44761, total_loss: 3.995652914047241
training step: 44762, total_loss: 4.224952697753906
training step: 44763, total_loss: 3.328455686569214
training step: 44764, total_loss: 3.9934732913970947
training step: 44765, total_loss: 4.231131076812744
training step: 44766, total_loss: 4.940239429473877
training step: 44767, total_loss: 3.831786632537842
training step: 44768, total_loss: 3.966517210006714
training step: 44769, total_loss: 4.224081516265869
training step: 44770, total_loss: 3.628248691558838
training step: 44771, total_loss: 4.405616283416748
training step: 44772, total_loss: 4.869317054748535
training step: 44773, total_loss: 4.667051792144775
training step: 44774, total_loss: 3.9311611652374268
training step: 44775, total_loss: 4.768461227416992
training step: 44776, total_loss: 4.566302299499512
training step: 44777, total_loss: 4.135125160217285
training step: 44778, total_loss: 3.873805046081543
training step: 44779, total_loss: 4.755191802978516
training step: 44780, total_loss: 4.963836669921875
training step: 44781, total_loss: 5.382857322692871
training step: 44782, total_loss: 5.410484313964844
training step: 44783, total_loss: 4.464682579040527
training step: 44784, total_loss: 2.60738468170166
training step: 44785, total_loss: 3.959948778152466
training step: 44786, total_loss: 4.710355758666992
training step: 44787, total_loss: 3.8448469638824463
training step: 44788, total_loss: 5.1928887367248535
training step: 44789, total_loss: 5.217403411865234
training step: 44790, total_loss: 4.368783950805664
training step: 44791, total_loss: 4.284404754638672
training step: 44792, total_loss: 4.314695835113525
training step: 44793, total_loss: 6.585111618041992
training step: 44794, total_loss: 6.434890270233154
training step: 44795, total_loss: 3.934807300567627
training step: 44796, total_loss: 4.586173057556152
training step: 44797, total_loss: 4.482353687286377
training step: 44798, total_loss: 3.9948177337646484
training step: 44799, total_loss: 3.1733288764953613
training step: 44800, total_loss: 4.4422502517700195
training step: 44801, total_loss: 4.998725414276123
training step: 44802, total_loss: 5.16414213180542
training step: 44803, total_loss: 4.347936630249023
training step: 44804, total_loss: 4.572534561157227
training step: 44805, total_loss: 5.347618103027344
training step: 44806, total_loss: 4.120990753173828
training step: 44807, total_loss: 3.821118116378784
training step: 44808, total_loss: 4.9745330810546875
training step: 44809, total_loss: 4.327147006988525
training step: 44810, total_loss: 3.819976329803467
training step: 44811, total_loss: 1.3308839797973633
training step: 44812, total_loss: 4.444197654724121
training step: 44813, total_loss: 4.56337308883667
training step: 44814, total_loss: 4.106151580810547
training step: 44815, total_loss: 5.5822954177856445
training step: 44816, total_loss: 4.966043472290039
training step: 44817, total_loss: 5.602573394775391
training step: 44818, total_loss: 4.909579753875732
training step: 44819, total_loss: 4.835278511047363
training step: 44820, total_loss: 4.9259796142578125
training step: 44821, total_loss: 4.273238182067871
training step: 44822, total_loss: 5.927330017089844
training step: 44823, total_loss: 3.0135691165924072
training step: 44824, total_loss: 4.256157875061035
training step: 44825, total_loss: 4.656156539916992
training step: 44826, total_loss: 7.48726749420166
training step: 44827, total_loss: 5.145956039428711
training step: 44828, total_loss: 4.375776290893555
training step: 44829, total_loss: 3.610903739929199
training step: 44830, total_loss: 3.806696891784668
training step: 44831, total_loss: 4.1387553215026855
training step: 44832, total_loss: 4.85029411315918
training step: 44833, total_loss: 3.6956663131713867
training step: 44834, total_loss: 4.644376277923584
training step: 44835, total_loss: 4.33442497253418
training step: 44836, total_loss: 6.1849260330200195
training step: 44837, total_loss: 3.780198097229004
training step: 44838, total_loss: 8.398693084716797
training step: 44839, total_loss: 1.2656095027923584
training step: 44840, total_loss: 5.53662109375
training step: 44841, total_loss: 4.23055362701416
training step: 44842, total_loss: 4.518758773803711
training step: 44843, total_loss: 3.4382705688476562
training step: 44844, total_loss: 4.278275489807129
training step: 44845, total_loss: 4.438718795776367
training step: 44846, total_loss: 4.046831130981445
training step: 44847, total_loss: 5.494827747344971
training step: 44848, total_loss: 2.7291340827941895
training step: 44849, total_loss: 5.078128814697266
training step: 44850, total_loss: 3.540012836456299
training step: 44851, total_loss: 4.874770641326904
training step: 44852, total_loss: 4.6505889892578125
training step: 44853, total_loss: 5.131275177001953
training step: 44854, total_loss: 3.245835304260254
training step: 44855, total_loss: 4.735344886779785
training step: 44856, total_loss: 4.986190319061279
training step: 44857, total_loss: 4.9141106605529785
training step: 44858, total_loss: 3.828355073928833
training step: 44859, total_loss: 4.206058502197266
training step: 44860, total_loss: 5.35256814956665
training step: 44861, total_loss: 6.528473854064941
training step: 44862, total_loss: 3.044625997543335
training step: 44863, total_loss: 4.886573791503906
training step: 44864, total_loss: 3.6571781635284424
training step: 44865, total_loss: 4.655691146850586
training step: 44866, total_loss: 5.154903888702393
training step: 44867, total_loss: 3.995360851287842
training step: 44868, total_loss: 4.322775840759277
training step: 44869, total_loss: 4.655418395996094
training step: 44870, total_loss: 3.641714096069336
training step: 44871, total_loss: 5.120746612548828
training step: 44872, total_loss: 4.558119773864746
training step: 44873, total_loss: 4.14121675491333
training step: 44874, total_loss: 7.275527000427246
training step: 44875, total_loss: 3.968506336212158
training step: 44876, total_loss: 5.178309917449951
training step: 44877, total_loss: 5.227598190307617
training step: 44878, total_loss: 4.399755477905273
training step: 44879, total_loss: 4.58278751373291
training step: 44880, total_loss: 1.1693006753921509
training step: 44881, total_loss: 5.2881693840026855
training step: 44882, total_loss: 3.9225714206695557
training step: 44883, total_loss: 6.137596130371094
training step: 44884, total_loss: 3.999091386795044
training step: 44885, total_loss: 3.646312713623047
training step: 44886, total_loss: 4.020612716674805
training step: 44887, total_loss: 4.946972846984863
training step: 44888, total_loss: 4.580598831176758
training step: 44889, total_loss: 5.002144813537598
training step: 44890, total_loss: 4.232416152954102
training step: 44891, total_loss: 5.261752605438232
training step: 44892, total_loss: 3.616209030151367
training step: 44893, total_loss: 5.403628349304199
training step: 44894, total_loss: 3.6788430213928223
training step: 44895, total_loss: 5.237481117248535
training step: 44896, total_loss: 5.369523048400879
training step: 44897, total_loss: 4.986199855804443
training step: 44898, total_loss: 2.6037137508392334
training step: 44899, total_loss: 5.087973117828369
training step: 44900, total_loss: 4.006176471710205
training step: 44901, total_loss: 4.319060325622559
training step: 44902, total_loss: 3.7955069541931152
training step: 44903, total_loss: 0.8458950519561768
training step: 44904, total_loss: 5.018393516540527
training step: 44905, total_loss: 4.72343635559082
training step: 44906, total_loss: 4.475128173828125
training step: 44907, total_loss: 3.4619548320770264
training step: 44908, total_loss: 4.2839035987854
training step: 44909, total_loss: 5.550055503845215
training step: 44910, total_loss: 4.789401531219482
training step: 44911, total_loss: 4.592433452606201
training step: 44912, total_loss: 5.2139739990234375
training step: 44913, total_loss: 2.7298085689544678
training step: 44914, total_loss: 3.907614231109619
training step: 44915, total_loss: 4.637001037597656
training step: 44916, total_loss: 5.042840003967285
training step: 44917, total_loss: 3.3152902126312256
training step: 44918, total_loss: 4.86857271194458
training step: 44919, total_loss: 4.2498016357421875
training step: 44920, total_loss: 4.415910720825195
training step: 44921, total_loss: 2.8250937461853027
training step: 44922, total_loss: 4.269438743591309
training step: 44923, total_loss: 4.326874732971191
training step: 44924, total_loss: 5.410307884216309
training step: 44925, total_loss: 4.067775249481201
training step: 44926, total_loss: 4.488523483276367
training step: 44927, total_loss: 5.4208598136901855
training step: 44928, total_loss: 4.842593193054199
training step: 44929, total_loss: 4.447958469390869
training step: 44930, total_loss: 3.7840609550476074
training step: 44931, total_loss: 6.250362396240234
training step: 44932, total_loss: 2.199978828430176
training step: 44933, total_loss: 4.6815948486328125
training step: 44934, total_loss: 3.9976553916931152
training step: 44935, total_loss: 2.599092483520508
training step: 44936, total_loss: 5.918126583099365
training step: 44937, total_loss: 4.200397968292236
training step: 44938, total_loss: 4.940305709838867
training step: 44939, total_loss: 2.0855445861816406
training step: 44940, total_loss: 5.142312049865723
training step: 44941, total_loss: 5.326926231384277
training step: 44942, total_loss: 3.7833786010742188
training step: 44943, total_loss: 4.344667434692383
training step: 44944, total_loss: 4.242201805114746
training step: 44945, total_loss: 7.345496654510498
training step: 44946, total_loss: 3.858490467071533
training step: 44947, total_loss: 3.935713768005371
training step: 44948, total_loss: 3.1904661655426025
training step: 44949, total_loss: 4.748071670532227
training step: 44950, total_loss: 3.854907274246216
training step: 44951, total_loss: 3.831169605255127
training step: 44952, total_loss: 1.2106988430023193
training step: 44953, total_loss: 8.489081382751465
training step: 44954, total_loss: 2.519497871398926
training step: 44955, total_loss: 3.5690126419067383
training step: 44956, total_loss: 4.023092269897461
training step: 44957, total_loss: 6.6072258949279785
training step: 44958, total_loss: 5.6865410804748535
training step: 44959, total_loss: 5.016566753387451
training step: 44960, total_loss: 3.4742259979248047
training step: 44961, total_loss: 5.043132781982422
training step: 44962, total_loss: 3.507415294647217
training step: 44963, total_loss: 4.95058536529541
training step: 44964, total_loss: 3.840399742126465
training step: 44965, total_loss: 3.5748047828674316
training step: 44966, total_loss: 4.938467979431152
training step: 44967, total_loss: 2.9281249046325684
training step: 44968, total_loss: 4.706736087799072
training step: 44969, total_loss: 5.759177207946777
training step: 44970, total_loss: 5.138643741607666
training step: 44971, total_loss: 5.321866512298584
training step: 44972, total_loss: 4.602838516235352
training step: 44973, total_loss: 3.5949482917785645
training step: 44974, total_loss: 2.6375374794006348
training step: 44975, total_loss: 4.485691070556641
training step: 44976, total_loss: 5.973671913146973
training step: 44977, total_loss: 3.3311586380004883
training step: 44978, total_loss: 4.794692516326904
training step: 44979, total_loss: 4.437891483306885
training step: 44980, total_loss: 3.12485933303833
training step: 44981, total_loss: 5.3385539054870605
training step: 44982, total_loss: 4.068756103515625
training step: 44983, total_loss: 5.535001277923584
training step: 44984, total_loss: 5.918699264526367
training step: 44985, total_loss: 4.532020092010498
training step: 44986, total_loss: 4.372992515563965
training step: 44987, total_loss: 3.8777523040771484
training step: 44988, total_loss: 5.077500343322754
training step: 44989, total_loss: 3.6148436069488525
training step: 44990, total_loss: 3.48191499710083
training step: 44991, total_loss: 5.416879653930664
training step: 44992, total_loss: 2.8455393314361572
training step: 44993, total_loss: 4.582636833190918
training step: 44994, total_loss: 4.698261737823486
training step: 44995, total_loss: 3.997964382171631
training step: 44996, total_loss: 4.593544006347656
training step: 44997, total_loss: 4.75978422164917
training step: 44998, total_loss: 3.8387928009033203
training step: 44999, total_loss: 5.556637287139893
training step: 45000, total_loss: 4.735733985900879
training step: 45001, total_loss: 6.357925891876221
training step: 45002, total_loss: 3.9722774028778076
training step: 45003, total_loss: 3.881239414215088
training step: 45004, total_loss: 5.594123840332031
training step: 45005, total_loss: 3.851625680923462
training step: 45006, total_loss: 4.9094719886779785
training step: 45007, total_loss: 3.8533639907836914
training step: 45008, total_loss: 1.081254482269287
training step: 45009, total_loss: 4.711719989776611
training step: 45010, total_loss: 5.1811041831970215
training step: 45011, total_loss: 5.259687423706055
training step: 45012, total_loss: 3.7526161670684814
training step: 45013, total_loss: 3.397735595703125
training step: 45014, total_loss: 3.5843148231506348
training step: 45015, total_loss: 1.4155771732330322
training step: 45016, total_loss: 3.8597114086151123
training step: 45017, total_loss: 4.4941630363464355
training step: 45018, total_loss: 4.527990341186523
training step: 45019, total_loss: 4.600378513336182
training step: 45020, total_loss: 5.3388261795043945
training step: 45021, total_loss: 2.828282117843628
training step: 45022, total_loss: 5.167049407958984
training step: 45023, total_loss: 3.7750391960144043
training step: 45024, total_loss: 3.22892427444458
training step: 45025, total_loss: 6.364928722381592
training step: 45026, total_loss: 5.2714996337890625
training step: 45027, total_loss: 3.7682647705078125
training step: 45028, total_loss: 4.210927963256836
training step: 45029, total_loss: 4.450117588043213
training step: 45030, total_loss: 4.082633018493652
training step: 45031, total_loss: 3.5693142414093018
training step: 45032, total_loss: 5.438979148864746
training step: 45033, total_loss: 2.5593783855438232
training step: 45034, total_loss: 5.410300254821777
training step: 45035, total_loss: 4.0999884605407715
training step: 45036, total_loss: 2.5560572147369385
training step: 45037, total_loss: 5.6433892250061035
training step: 45038, total_loss: 2.732390880584717
training step: 45039, total_loss: 4.921908378601074
training step: 45040, total_loss: 4.282888412475586
training step: 45041, total_loss: 2.019972324371338
training step: 45042, total_loss: 3.6469216346740723
training step: 45043, total_loss: 3.820408821105957
training step: 45044, total_loss: 5.285714149475098
training step: 45045, total_loss: 4.351089000701904
training step: 45046, total_loss: 3.218801736831665
training step: 45047, total_loss: 3.1987624168395996
training step: 45048, total_loss: 5.169075965881348
training step: 45049, total_loss: 4.466404914855957
training step: 45050, total_loss: 4.2964558601379395
training step: 45051, total_loss: 4.383464336395264
training step: 45052, total_loss: 3.3270702362060547
training step: 45053, total_loss: 4.638792991638184
training step: 45054, total_loss: 4.37296724319458
training step: 45055, total_loss: 4.363147735595703
training step: 45056, total_loss: 3.9633052349090576
training step: 45057, total_loss: 4.986588954925537
training step: 45058, total_loss: 5.406371116638184
training step: 45059, total_loss: 4.506584167480469
training step: 45060, total_loss: 3.7535910606384277
training step: 45061, total_loss: 4.486959457397461
training step: 45062, total_loss: 4.927563667297363
training step: 45063, total_loss: 5.388224124908447
training step: 45064, total_loss: 4.994136333465576
training step: 45065, total_loss: 3.206526517868042
training step: 45066, total_loss: 3.296861171722412
training step: 45067, total_loss: 4.310072422027588
training step: 45068, total_loss: 4.254377365112305
training step: 45069, total_loss: 4.795590400695801
training step: 45070, total_loss: 6.006122589111328
training step: 45071, total_loss: 4.881805419921875
training step: 45072, total_loss: 4.436924457550049
training step: 45073, total_loss: 5.254344940185547
training step: 45074, total_loss: 4.424302577972412
training step: 45075, total_loss: 3.6727447509765625
training step: 45076, total_loss: 4.930559158325195
training step: 45077, total_loss: 5.6701555252075195
training step: 45078, total_loss: 5.776575088500977
training step: 45079, total_loss: 4.129134178161621
training step: 45080, total_loss: 4.009897708892822
training step: 45081, total_loss: 4.1905083656311035
training step: 45082, total_loss: 3.2967681884765625
training step: 45083, total_loss: 4.345188140869141
training step: 45084, total_loss: 4.889392852783203
training step: 45085, total_loss: 4.817318916320801
training step: 45086, total_loss: 3.168063163757324
training step: 45087, total_loss: 5.253633499145508
training step: 45088, total_loss: 4.5896992683410645
training step: 45089, total_loss: 5.423923492431641
training step: 45090, total_loss: 3.248293399810791
training step: 45091, total_loss: 3.3651795387268066
training step: 45092, total_loss: 5.960088729858398
training step: 45093, total_loss: 4.223719120025635
training step: 45094, total_loss: 4.756387233734131
training step: 45095, total_loss: 5.451944828033447
training step: 45096, total_loss: 4.525712966918945
training step: 45097, total_loss: 3.887153387069702
training step: 45098, total_loss: 3.2810277938842773
training step: 45099, total_loss: 3.7502269744873047
training step: 45100, total_loss: 4.3513712882995605
training step: 45101, total_loss: 5.464390754699707
training step: 45102, total_loss: 1.3007080554962158
training step: 45103, total_loss: 5.730173110961914
training step: 45104, total_loss: 3.5520756244659424
training step: 45105, total_loss: 5.224629878997803
training step: 45106, total_loss: 5.159111976623535
training step: 45107, total_loss: 3.5898690223693848
training step: 45108, total_loss: 5.600744247436523
training step: 45109, total_loss: 5.13044548034668
training step: 45110, total_loss: 3.1342225074768066
training step: 45111, total_loss: 0.8972780704498291
training step: 45112, total_loss: 5.041369438171387
training step: 45113, total_loss: 2.361166000366211
training step: 45114, total_loss: 4.453239440917969
training step: 45115, total_loss: 4.257068634033203
training step: 45116, total_loss: 4.318253993988037
training step: 45117, total_loss: 5.292763710021973
training step: 45118, total_loss: 5.695745468139648
training step: 45119, total_loss: 4.318591117858887
training step: 45120, total_loss: 4.653992652893066
training step: 45121, total_loss: 5.0237226486206055
training step: 45122, total_loss: 4.995302200317383
training step: 45123, total_loss: 5.977749824523926
training step: 45124, total_loss: 4.627598762512207
training step: 45125, total_loss: 1.1189727783203125
training step: 45126, total_loss: 2.8747012615203857
training step: 45127, total_loss: 2.6450040340423584
training step: 45128, total_loss: 4.558811187744141
training step: 45129, total_loss: 6.1821699142456055
training step: 45130, total_loss: 4.252040863037109
training step: 45131, total_loss: 5.954185485839844
training step: 45132, total_loss: 5.313553810119629
training step: 45133, total_loss: 2.80777645111084
training step: 45134, total_loss: 5.164532661437988
training step: 45135, total_loss: 7.789515972137451
training step: 45136, total_loss: 4.408773422241211
training step: 45137, total_loss: 4.19283390045166
training step: 45138, total_loss: 3.3962202072143555
training step: 45139, total_loss: 4.984635353088379
training step: 45140, total_loss: 3.8972272872924805
training step: 45141, total_loss: 5.9340667724609375
training step: 45142, total_loss: 4.447958469390869
training step: 45143, total_loss: 5.595063209533691
training step: 45144, total_loss: 3.5700902938842773
training step: 45145, total_loss: 4.800877571105957
training step: 45146, total_loss: 3.242316722869873
training step: 45147, total_loss: 6.05604362487793
training step: 45148, total_loss: 4.374950408935547
training step: 45149, total_loss: 2.621361017227173
training step: 45150, total_loss: 0.8955989480018616
training step: 45151, total_loss: 4.550468444824219
training step: 45152, total_loss: 7.089024543762207
training step: 45153, total_loss: 3.3230972290039062
training step: 45154, total_loss: 5.580514907836914
training step: 45155, total_loss: 4.226106643676758
training step: 45156, total_loss: 3.4640252590179443
training step: 45157, total_loss: 5.785266876220703
training step: 45158, total_loss: 4.691046714782715
training step: 45159, total_loss: 4.198084831237793
training step: 45160, total_loss: 4.146501541137695
training step: 45161, total_loss: 3.8129544258117676
training step: 45162, total_loss: 4.6087846755981445
training step: 45163, total_loss: 4.398552894592285
training step: 45164, total_loss: 4.98643684387207
training step: 45165, total_loss: 5.555022239685059
training step: 45166, total_loss: 2.357724189758301
training step: 45167, total_loss: 4.560971736907959
training step: 45168, total_loss: 5.417640209197998
training step: 45169, total_loss: 4.948127269744873
training step: 45170, total_loss: 4.6856794357299805
training step: 45171, total_loss: 4.080116271972656
training step: 45172, total_loss: 4.3640828132629395
training step: 45173, total_loss: 3.78519868850708
training step: 45174, total_loss: 2.531510829925537
training step: 45175, total_loss: 5.160524368286133
training step: 45176, total_loss: 4.6353840827941895
training step: 45177, total_loss: 3.5797667503356934
training step: 45178, total_loss: 3.5313050746917725
training step: 45179, total_loss: 4.125883102416992
training step: 45180, total_loss: 5.345874786376953
training step: 45181, total_loss: 4.497410297393799
training step: 45182, total_loss: 3.7116267681121826
training step: 45183, total_loss: 3.7467703819274902
training step: 45184, total_loss: 3.0920495986938477
training step: 45185, total_loss: 5.233054161071777
training step: 45186, total_loss: 4.394800186157227
training step: 45187, total_loss: 4.724828720092773
training step: 45188, total_loss: 4.210318088531494
training step: 45189, total_loss: 2.0028727054595947
training step: 45190, total_loss: 4.647796630859375
training step: 45191, total_loss: 2.843562602996826
training step: 45192, total_loss: 5.172654628753662
training step: 45193, total_loss: 4.043645858764648
training step: 45194, total_loss: 4.9668288230896
training step: 45195, total_loss: 5.546161651611328
training step: 45196, total_loss: 5.846819877624512
training step: 45197, total_loss: 5.377543926239014
training step: 45198, total_loss: 4.9773993492126465
training step: 45199, total_loss: 5.174181938171387
training step: 45200, total_loss: 3.671339750289917
training step: 45201, total_loss: 4.933438301086426
training step: 45202, total_loss: 6.175189018249512
training step: 45203, total_loss: 3.1823348999023438
training step: 45204, total_loss: 4.8295793533325195
training step: 45205, total_loss: 4.853376865386963
training step: 45206, total_loss: 4.464040279388428
training step: 45207, total_loss: 3.6118195056915283
training step: 45208, total_loss: 3.844104290008545
training step: 45209, total_loss: 4.425734519958496
training step: 45210, total_loss: 4.855292320251465
training step: 45211, total_loss: 5.444862365722656
training step: 45212, total_loss: 5.230024337768555
training step: 45213, total_loss: 4.376689910888672
training step: 45214, total_loss: 4.934478759765625
training step: 45215, total_loss: 2.8648829460144043
training step: 45216, total_loss: 6.751147270202637
training step: 45217, total_loss: 3.6915669441223145
training step: 45218, total_loss: 5.403214454650879
training step: 45219, total_loss: 4.811254501342773
training step: 45220, total_loss: 3.5940334796905518
training step: 45221, total_loss: 2.619194507598877
training step: 45222, total_loss: 3.536080837249756
training step: 45223, total_loss: 4.899319171905518
training step: 45224, total_loss: 4.385246276855469
training step: 45225, total_loss: 5.155401229858398
training step: 45226, total_loss: 3.5298585891723633
training step: 45227, total_loss: 5.464870452880859
training step: 45228, total_loss: 4.5917816162109375
training step: 45229, total_loss: 3.7126379013061523
training step: 45230, total_loss: 3.3543763160705566
training step: 45231, total_loss: 4.363409042358398
training step: 45232, total_loss: 4.695783615112305
training step: 45233, total_loss: 5.282532215118408
training step: 45234, total_loss: 5.713116645812988
training step: 45235, total_loss: 5.161096096038818
training step: 45236, total_loss: 5.670995712280273
training step: 45237, total_loss: 4.023534297943115
training step: 45238, total_loss: 4.809515953063965
training step: 45239, total_loss: 5.515148639678955
training step: 45240, total_loss: 4.864675521850586
training step: 45241, total_loss: 3.5198307037353516
training step: 45242, total_loss: 3.5567638874053955
training step: 45243, total_loss: 4.962610244750977
training step: 45244, total_loss: 5.402425765991211
training step: 45245, total_loss: 4.020251274108887
training step: 45246, total_loss: 4.030182838439941
training step: 45247, total_loss: 7.173978805541992
training step: 45248, total_loss: 4.790847301483154
training step: 45249, total_loss: 4.154228210449219
training step: 45250, total_loss: 5.212973117828369
training step: 45251, total_loss: 4.770639419555664
training step: 45252, total_loss: 5.232519149780273
training step: 45253, total_loss: 3.962146759033203
training step: 45254, total_loss: 4.47904109954834
training step: 45255, total_loss: 3.8696670532226562
training step: 45256, total_loss: 4.158473014831543
training step: 45257, total_loss: 4.912841796875
training step: 45258, total_loss: 5.741809844970703
training step: 45259, total_loss: 4.766940116882324
training step: 45260, total_loss: 4.198576927185059
training step: 45261, total_loss: 2.7657065391540527
training step: 45262, total_loss: 2.2482852935791016
training step: 45263, total_loss: 4.064250469207764
training step: 45264, total_loss: 5.342276573181152
training step: 45265, total_loss: 4.682110786437988
training step: 45266, total_loss: 6.407026290893555
training step: 45267, total_loss: 5.641000747680664
training step: 45268, total_loss: 4.405871868133545
training step: 45269, total_loss: 1.0682978630065918
training step: 45270, total_loss: 4.801571846008301
training step: 45271, total_loss: 1.3973313570022583
training step: 45272, total_loss: 4.878197193145752
training step: 45273, total_loss: 4.63638162612915
training step: 45274, total_loss: 4.35512638092041
training step: 45275, total_loss: 5.829460144042969
training step: 45276, total_loss: 4.954614639282227
training step: 45277, total_loss: 5.660368919372559
training step: 45278, total_loss: 4.246249675750732
training step: 45279, total_loss: 4.864431381225586
training step: 45280, total_loss: 4.509032249450684
training step: 45281, total_loss: 5.332555770874023
training step: 45282, total_loss: 4.806519508361816
training step: 45283, total_loss: 4.249562740325928
training step: 45284, total_loss: 3.516788959503174
training step: 45285, total_loss: 4.137210845947266
training step: 45286, total_loss: 3.3648617267608643
training step: 45287, total_loss: 3.123831272125244
training step: 45288, total_loss: 4.015495300292969
training step: 45289, total_loss: 4.939311981201172
training step: 45290, total_loss: 4.928840637207031
training step: 45291, total_loss: 4.779393196105957
training step: 45292, total_loss: 4.332807540893555
training step: 45293, total_loss: 3.8445301055908203
training step: 45294, total_loss: 4.699326038360596
training step: 45295, total_loss: 3.5040879249572754
training step: 45296, total_loss: 6.683948516845703
training step: 45297, total_loss: 5.366420745849609
training step: 45298, total_loss: 3.2605700492858887
training step: 45299, total_loss: 3.450425863265991
training step: 45300, total_loss: 4.988142013549805
training step: 45301, total_loss: 5.851655960083008
training step: 45302, total_loss: 4.81342887878418
training step: 45303, total_loss: 4.254179000854492
training step: 45304, total_loss: 4.405495643615723
training step: 45305, total_loss: 3.969245433807373
training step: 45306, total_loss: 4.72108793258667
training step: 45307, total_loss: 4.434817790985107
training step: 45308, total_loss: 3.8112430572509766
training step: 45309, total_loss: 3.209047317504883
training step: 45310, total_loss: 6.479381084442139
training step: 45311, total_loss: 3.4943528175354004
training step: 45312, total_loss: 4.838881492614746
training step: 45313, total_loss: 3.7509050369262695
training step: 45314, total_loss: 4.532066822052002
training step: 45315, total_loss: 5.457653045654297
training step: 45316, total_loss: 5.021323204040527
training step: 45317, total_loss: 5.099498271942139
training step: 45318, total_loss: 5.052165985107422
training step: 45319, total_loss: 4.977982521057129
training step: 45320, total_loss: 4.624881744384766
training step: 45321, total_loss: 1.158928394317627
training step: 45322, total_loss: 4.023163318634033
training step: 45323, total_loss: 2.9940805435180664
training step: 45324, total_loss: 3.9145493507385254
training step: 45325, total_loss: 5.099789619445801
training step: 45326, total_loss: 2.5932250022888184
training step: 45327, total_loss: 4.247115135192871
training step: 45328, total_loss: 4.681542873382568
training step: 45329, total_loss: 3.8618392944335938
training step: 45330, total_loss: 5.367756366729736
training step: 45331, total_loss: 4.855387210845947
training step: 45332, total_loss: 6.363039970397949
training step: 45333, total_loss: 4.40337610244751
training step: 45334, total_loss: 4.518183708190918
training step: 45335, total_loss: 5.338604927062988
training step: 45336, total_loss: 4.854208469390869
training step: 45337, total_loss: 4.657186031341553
training step: 45338, total_loss: 4.655326843261719
training step: 45339, total_loss: 3.726881980895996
training step: 45340, total_loss: 4.326891899108887
training step: 45341, total_loss: 3.720236301422119
training step: 45342, total_loss: 4.827127456665039
training step: 45343, total_loss: 5.985086917877197
training step: 45344, total_loss: 1.25032377243042
training step: 45345, total_loss: 4.067939281463623
training step: 45346, total_loss: 3.9380557537078857
training step: 45347, total_loss: 4.013251781463623
training step: 45348, total_loss: 4.364361763000488
training step: 45349, total_loss: 5.2082743644714355
training step: 45350, total_loss: 4.30476188659668
training step: 45351, total_loss: 3.2267942428588867
training step: 45352, total_loss: 3.7386770248413086
training step: 45353, total_loss: 3.9751248359680176
training step: 45354, total_loss: 5.662815093994141
training step: 45355, total_loss: 5.774763584136963
training step: 45356, total_loss: 5.363089561462402
training step: 45357, total_loss: 3.4368832111358643
training step: 45358, total_loss: 4.282814025878906
training step: 45359, total_loss: 5.497403144836426
training step: 45360, total_loss: 4.884933948516846
training step: 45361, total_loss: 2.4542040824890137
training step: 45362, total_loss: 2.3514511585235596
training step: 45363, total_loss: 3.7982492446899414
training step: 45364, total_loss: 3.9811489582061768
training step: 45365, total_loss: 4.704455375671387
training step: 45366, total_loss: 4.986363887786865
training step: 45367, total_loss: 2.8772573471069336
training step: 45368, total_loss: 5.287915229797363
training step: 45369, total_loss: 4.497243881225586
training step: 45370, total_loss: 3.6186933517456055
training step: 45371, total_loss: 3.601325273513794
training step: 45372, total_loss: 5.164383411407471
training step: 45373, total_loss: 7.00739049911499
training step: 45374, total_loss: 5.369302272796631
training step: 45375, total_loss: 3.336057662963867
training step: 45376, total_loss: 5.301434516906738
training step: 45377, total_loss: 3.608269214630127
training step: 45378, total_loss: 3.742434501647949
training step: 45379, total_loss: 5.199841499328613
training step: 45380, total_loss: 5.148215293884277
training step: 45381, total_loss: 3.074791431427002
training step: 45382, total_loss: 2.6514735221862793
training step: 45383, total_loss: 4.017885208129883
training step: 45384, total_loss: 4.051614761352539
training step: 45385, total_loss: 5.3735809326171875
training step: 45386, total_loss: 5.560666084289551
training step: 45387, total_loss: 1.3889330625534058
training step: 45388, total_loss: 2.7935097217559814
training step: 45389, total_loss: 0.9126002788543701
training step: 45390, total_loss: 4.142810344696045
training step: 45391, total_loss: 5.592015266418457
training step: 45392, total_loss: 4.420865058898926
training step: 45393, total_loss: 4.738748550415039
training step: 45394, total_loss: 3.337405204772949
training step: 45395, total_loss: 4.832053184509277
training step: 45396, total_loss: 5.098653793334961
training step: 45397, total_loss: 4.995692253112793
training step: 45398, total_loss: 4.896652698516846
training step: 45399, total_loss: 3.3577585220336914
training step: 45400, total_loss: 3.8176827430725098
training step: 45401, total_loss: 4.528400421142578
training step: 45402, total_loss: 5.023865699768066
training step: 45403, total_loss: 7.043209075927734
training step: 45404, total_loss: 5.02424955368042
training step: 45405, total_loss: 4.5985941886901855
training step: 45406, total_loss: 4.442084789276123
training step: 45407, total_loss: 4.805850028991699
training step: 45408, total_loss: 3.3180484771728516
training step: 45409, total_loss: 5.290600776672363
training step: 45410, total_loss: 5.984897136688232
training step: 45411, total_loss: 3.345674514770508
training step: 45412, total_loss: 4.421319007873535
training step: 45413, total_loss: 4.139705181121826
training step: 45414, total_loss: 3.816802978515625
training step: 45415, total_loss: 4.254795074462891
training step: 45416, total_loss: 5.7994232177734375
training step: 45417, total_loss: 4.265130996704102
training step: 45418, total_loss: 5.000226020812988
training step: 45419, total_loss: 3.9354336261749268
training step: 45420, total_loss: 4.6123504638671875
training step: 45421, total_loss: 5.328506946563721
training step: 45422, total_loss: 3.0987601280212402
training step: 45423, total_loss: 3.910783529281616
training step: 45424, total_loss: 4.730923652648926
training step: 45425, total_loss: 3.8021440505981445
training step: 45426, total_loss: 5.367647647857666
training step: 45427, total_loss: 2.6740174293518066
training step: 45428, total_loss: 4.159838676452637
training step: 45429, total_loss: 4.378992080688477
training step: 45430, total_loss: 2.679363250732422
training step: 45431, total_loss: 2.901624917984009
training step: 45432, total_loss: 4.826138496398926
training step: 45433, total_loss: 3.37068510055542
training step: 45434, total_loss: 5.87210750579834
training step: 45435, total_loss: 1.0402066707611084
training step: 45436, total_loss: 6.075285911560059
training step: 45437, total_loss: 4.949272155761719
training step: 45438, total_loss: 3.509307384490967
training step: 45439, total_loss: 4.8548078536987305
training step: 45440, total_loss: 5.185351371765137
training step: 45441, total_loss: 6.134911060333252
training step: 45442, total_loss: 4.034358024597168
training step: 45443, total_loss: 2.353193759918213
training step: 45444, total_loss: 2.686418056488037
training step: 45445, total_loss: 3.6267642974853516
training step: 45446, total_loss: 4.742952346801758
training step: 45447, total_loss: 4.033379554748535
training step: 45448, total_loss: 4.55075740814209
training step: 45449, total_loss: 3.17940092086792
training step: 45450, total_loss: 4.940799713134766
training step: 45451, total_loss: 3.5401358604431152
training step: 45452, total_loss: 5.108483791351318
training step: 45453, total_loss: 4.126152515411377
training step: 45454, total_loss: 4.187296390533447
training step: 45455, total_loss: 4.711792945861816
training step: 45456, total_loss: 3.4861679077148438
training step: 45457, total_loss: 5.082747459411621
training step: 45458, total_loss: 5.1819024085998535
training step: 45459, total_loss: 4.289677619934082
training step: 45460, total_loss: 4.083672523498535
training step: 45461, total_loss: 3.7997641563415527
training step: 45462, total_loss: 4.469862937927246
training step: 45463, total_loss: 2.9406094551086426
training step: 45464, total_loss: 5.475345611572266
training step: 45465, total_loss: 3.0593767166137695
training step: 45466, total_loss: 4.5724053382873535
training step: 45467, total_loss: 4.808633804321289
training step: 45468, total_loss: 3.5630030632019043
training step: 45469, total_loss: 4.888072967529297
training step: 45470, total_loss: 2.5752549171447754
training step: 45471, total_loss: 4.919061183929443
training step: 45472, total_loss: 3.966787815093994
training step: 45473, total_loss: 6.841529369354248
training step: 45474, total_loss: 4.191734313964844
training step: 45475, total_loss: 4.251385688781738
training step: 45476, total_loss: 4.573888778686523
training step: 45477, total_loss: 3.8894643783569336
training step: 45478, total_loss: 3.680634021759033
training step: 45479, total_loss: 5.839059829711914
training step: 45480, total_loss: 7.495246410369873
training step: 45481, total_loss: 6.026825904846191
training step: 45482, total_loss: 5.722347259521484
training step: 45483, total_loss: 5.033167362213135
training step: 45484, total_loss: 1.0259935855865479
training step: 45485, total_loss: 3.9746861457824707
training step: 45486, total_loss: 5.5168867111206055
training step: 45487, total_loss: 3.8083972930908203
training step: 45488, total_loss: 6.713653564453125
training step: 45489, total_loss: 4.8276448249816895
training step: 45490, total_loss: 5.623147964477539
training step: 45491, total_loss: 4.296356201171875
training step: 45492, total_loss: 5.520465850830078
training step: 45493, total_loss: 4.459281921386719
training step: 45494, total_loss: 5.167290687561035
training step: 45495, total_loss: 5.144677639007568
training step: 45496, total_loss: 4.174345016479492
training step: 45497, total_loss: 5.328050136566162
training step: 45498, total_loss: 4.548618793487549
training step: 45499, total_loss: 0.9064955711364746
training step: 45500, total_loss: 3.7052135467529297
training step: 45501, total_loss: 2.8467206954956055
training step: 45502, total_loss: 4.935847282409668
training step: 45503, total_loss: 3.2817225456237793
training step: 45504, total_loss: 5.428022384643555
training step: 45505, total_loss: 5.1340131759643555
training step: 45506, total_loss: 3.637544870376587
training step: 45507, total_loss: 3.863614082336426
training step: 45508, total_loss: 4.578357696533203
training step: 45509, total_loss: 4.826261520385742
training step: 45510, total_loss: 4.586786270141602
training step: 45511, total_loss: 3.726902961730957
training step: 45512, total_loss: 4.863407135009766
training step: 45513, total_loss: 4.657016277313232
training step: 45514, total_loss: 5.037196159362793
training step: 45515, total_loss: 5.666521072387695
training step: 45516, total_loss: 4.9975996017456055
training step: 45517, total_loss: 6.854160785675049
training step: 45518, total_loss: 6.415915489196777
training step: 45519, total_loss: 7.167702674865723
training step: 45520, total_loss: 5.33514404296875
training step: 45521, total_loss: 0.9022305011749268
training step: 45522, total_loss: 2.9913015365600586
training step: 45523, total_loss: 5.268613338470459
training step: 45524, total_loss: 4.235228538513184
training step: 45525, total_loss: 2.701414108276367
training step: 45526, total_loss: 4.4095306396484375
training step: 45527, total_loss: 4.1283159255981445
training step: 45528, total_loss: 3.3566837310791016
training step: 45529, total_loss: 6.791794300079346
training step: 45530, total_loss: 4.940088272094727
training step: 45531, total_loss: 4.289541721343994
training step: 45532, total_loss: 4.899711608886719
training step: 45533, total_loss: 3.4946112632751465
training step: 45534, total_loss: 4.574974536895752
training step: 45535, total_loss: 4.80859375
training step: 45536, total_loss: 5.632969856262207
training step: 45537, total_loss: 1.167873740196228
training step: 45538, total_loss: 1.0515379905700684
training step: 45539, total_loss: 3.471053123474121
training step: 45540, total_loss: 1.1244943141937256
training step: 45541, total_loss: 5.181137561798096
training step: 45542, total_loss: 4.621067047119141
training step: 45543, total_loss: 5.268028259277344
training step: 45544, total_loss: 4.388200759887695
training step: 45545, total_loss: 5.111642837524414
training step: 45546, total_loss: 3.539583683013916
training step: 45547, total_loss: 4.26025915145874
training step: 45548, total_loss: 0.9237721562385559
training step: 45549, total_loss: 4.154423236846924
training step: 45550, total_loss: 3.2797446250915527
training step: 45551, total_loss: 5.418676376342773
training step: 45552, total_loss: 3.5885872840881348
training step: 45553, total_loss: 4.612063407897949
training step: 45554, total_loss: 1.3375297784805298
training step: 45555, total_loss: 4.604743957519531
training step: 45556, total_loss: 3.2412376403808594
training step: 45557, total_loss: 4.948802947998047
training step: 45558, total_loss: 3.0375990867614746
training step: 45559, total_loss: 5.121890068054199
training step: 45560, total_loss: 4.616324424743652
training step: 45561, total_loss: 5.2624030113220215
training step: 45562, total_loss: 4.316465854644775
training step: 45563, total_loss: 4.79939079284668
training step: 45564, total_loss: 4.263092041015625
training step: 45565, total_loss: 4.352880477905273
training step: 45566, total_loss: 4.146026134490967
training step: 45567, total_loss: 4.187811851501465
training step: 45568, total_loss: 2.5612776279449463
training step: 45569, total_loss: 3.80607271194458
training step: 45570, total_loss: 6.8424835205078125
training step: 45571, total_loss: 0.8351904153823853
training step: 45572, total_loss: 6.743773460388184
training step: 45573, total_loss: 3.899646520614624
training step: 45574, total_loss: 3.871560573577881
training step: 45575, total_loss: 2.1371889114379883
training step: 45576, total_loss: 4.385402679443359
training step: 45577, total_loss: 4.229590892791748
training step: 45578, total_loss: 4.98294734954834
training step: 45579, total_loss: 5.673708915710449
training step: 45580, total_loss: 0.7053001523017883
training step: 45581, total_loss: 3.808943748474121
training step: 45582, total_loss: 5.482672691345215
training step: 45583, total_loss: 4.473213195800781
training step: 45584, total_loss: 5.801929473876953
training step: 45585, total_loss: 5.3550286293029785
training step: 45586, total_loss: 2.7315597534179688
training step: 45587, total_loss: 4.710371971130371
training step: 45588, total_loss: 4.436521530151367
training step: 45589, total_loss: 2.3916196823120117
training step: 45590, total_loss: 4.3799824714660645
training step: 45591, total_loss: 3.2675704956054688
training step: 45592, total_loss: 4.39393424987793
training step: 45593, total_loss: 4.912564277648926
training step: 45594, total_loss: 4.4334940910339355
training step: 45595, total_loss: 3.549412250518799
training step: 45596, total_loss: 5.678662300109863
training step: 45597, total_loss: 5.358788013458252
training step: 45598, total_loss: 5.689450740814209
training step: 45599, total_loss: 5.895486831665039
training step: 45600, total_loss: 2.3425981998443604
training step: 45601, total_loss: 4.657054901123047
training step: 45602, total_loss: 4.208495616912842
training step: 45603, total_loss: 4.897993087768555
training step: 45604, total_loss: 6.01434850692749
training step: 45605, total_loss: 4.362112522125244
training step: 45606, total_loss: 4.845663070678711
training step: 45607, total_loss: 2.965343952178955
training step: 45608, total_loss: 4.5646257400512695
training step: 45609, total_loss: 3.8833746910095215
training step: 45610, total_loss: 5.4743452072143555
training step: 45611, total_loss: 3.1606764793395996
training step: 45612, total_loss: 4.521160125732422
training step: 45613, total_loss: 2.7510786056518555
training step: 45614, total_loss: 4.323760032653809
training step: 45615, total_loss: 4.739090919494629
training step: 45616, total_loss: 5.5729899406433105
training step: 45617, total_loss: 5.368059158325195
training step: 45618, total_loss: 4.845312595367432
training step: 45619, total_loss: 5.439664840698242
training step: 45620, total_loss: 5.764770984649658
training step: 45621, total_loss: 5.144543647766113
training step: 45622, total_loss: 5.992426872253418
training step: 45623, total_loss: 4.018957614898682
training step: 45624, total_loss: 5.019000053405762
training step: 45625, total_loss: 3.2276551723480225
training step: 45626, total_loss: 5.107059955596924
training step: 45627, total_loss: 4.756547927856445
training step: 45628, total_loss: 4.261913299560547
training step: 45629, total_loss: 3.9336061477661133
training step: 45630, total_loss: 4.388407230377197
training step: 45631, total_loss: 5.6084794998168945
training step: 45632, total_loss: 4.360943794250488
training step: 45633, total_loss: 4.1613874435424805
training step: 45634, total_loss: 3.768573760986328
training step: 45635, total_loss: 4.567014694213867
training step: 45636, total_loss: 2.2776734828948975
training step: 45637, total_loss: 3.355210065841675
training step: 45638, total_loss: 3.815829038619995
training step: 45639, total_loss: 4.296934127807617
training step: 45640, total_loss: 3.7260401248931885
training step: 45641, total_loss: 4.19141960144043
training step: 45642, total_loss: 3.1942107677459717
training step: 45643, total_loss: 5.3815226554870605
training step: 45644, total_loss: 3.4649181365966797
training step: 45645, total_loss: 4.050637722015381
training step: 45646, total_loss: 4.542551040649414
training step: 45647, total_loss: 2.9196829795837402
training step: 45648, total_loss: 4.363311767578125
training step: 45649, total_loss: 3.8166000843048096
training step: 45650, total_loss: 4.248455047607422
training step: 45651, total_loss: 4.216817855834961
training step: 45652, total_loss: 5.4227294921875
training step: 45653, total_loss: 4.485657691955566
training step: 45654, total_loss: 2.769294023513794
training step: 45655, total_loss: 4.579881191253662
training step: 45656, total_loss: 6.878078460693359
training step: 45657, total_loss: 5.7115888595581055
training step: 45658, total_loss: 3.511782646179199
training step: 45659, total_loss: 3.9237685203552246
training step: 45660, total_loss: 4.701199531555176
training step: 45661, total_loss: 3.6087779998779297
training step: 45662, total_loss: 5.220697402954102
training step: 45663, total_loss: 4.13275671005249
training step: 45664, total_loss: 5.49854850769043
training step: 45665, total_loss: 5.337677001953125
training step: 45666, total_loss: 4.327948093414307
training step: 45667, total_loss: 3.8378546237945557
training step: 45668, total_loss: 4.777457237243652
training step: 45669, total_loss: 5.065145492553711
training step: 45670, total_loss: 3.9541025161743164
training step: 45671, total_loss: 5.894518852233887
training step: 45672, total_loss: 4.544095039367676
training step: 45673, total_loss: 3.487356185913086
training step: 45674, total_loss: 5.756936073303223
training step: 45675, total_loss: 5.60707950592041
training step: 45676, total_loss: 4.6478071212768555
training step: 45677, total_loss: 4.514418601989746
training step: 45678, total_loss: 4.414759635925293
training step: 45679, total_loss: 3.014284133911133
training step: 45680, total_loss: 1.8471323251724243
training step: 45681, total_loss: 4.605195045471191
training step: 45682, total_loss: 1.9566478729248047
training step: 45683, total_loss: 4.731198787689209
training step: 45684, total_loss: 4.617243766784668
training step: 45685, total_loss: 2.5383424758911133
training step: 45686, total_loss: 4.349175930023193
training step: 45687, total_loss: 5.333378791809082
training step: 45688, total_loss: 5.054727554321289
training step: 45689, total_loss: 4.138591766357422
training step: 45690, total_loss: 4.622769832611084
training step: 45691, total_loss: 5.492262840270996
training step: 45692, total_loss: 4.453467845916748
training step: 45693, total_loss: 4.028913497924805
training step: 45694, total_loss: 4.097864151000977
training step: 45695, total_loss: 4.57867956161499
training step: 45696, total_loss: 0.9866842031478882
training step: 45697, total_loss: 5.223013877868652
training step: 45698, total_loss: 4.931331634521484
training step: 45699, total_loss: 5.593628883361816
training step: 45700, total_loss: 5.9622063636779785
training step: 45701, total_loss: 4.40561580657959
training step: 45702, total_loss: 3.985950469970703
training step: 45703, total_loss: 3.44669246673584
training step: 45704, total_loss: 5.875576019287109
training step: 45705, total_loss: 0.9571866989135742
training step: 45706, total_loss: 5.573419570922852
training step: 45707, total_loss: 3.8536019325256348
training step: 45708, total_loss: 3.1681087017059326
training step: 45709, total_loss: 5.002096652984619
training step: 45710, total_loss: 4.710725784301758
training step: 45711, total_loss: 5.5212554931640625
training step: 45712, total_loss: 3.809927463531494
training step: 45713, total_loss: 3.6392922401428223
training step: 45714, total_loss: 3.808938980102539
training step: 45715, total_loss: 5.318912982940674
training step: 45716, total_loss: 3.3844780921936035
training step: 45717, total_loss: 3.010840892791748
training step: 45718, total_loss: 4.647793769836426
training step: 45719, total_loss: 4.887929439544678
training step: 45720, total_loss: 4.148347854614258
training step: 45721, total_loss: 4.408773422241211
training step: 45722, total_loss: 4.958311080932617
training step: 45723, total_loss: 3.3036670684814453
training step: 45724, total_loss: 3.6071436405181885
training step: 45725, total_loss: 5.301288604736328
training step: 45726, total_loss: 5.406475067138672
training step: 45727, total_loss: 4.923354148864746
training step: 45728, total_loss: 3.5110018253326416
training step: 45729, total_loss: 3.9803216457366943
training step: 45730, total_loss: 3.346355438232422
training step: 45731, total_loss: 3.072293281555176
training step: 45732, total_loss: 5.02023983001709
training step: 45733, total_loss: 5.292084693908691
training step: 45734, total_loss: 4.5118632316589355
training step: 45735, total_loss: 4.7163920402526855
training step: 45736, total_loss: 4.4064788818359375
training step: 45737, total_loss: 4.149169921875
training step: 45738, total_loss: 1.9061397314071655
training step: 45739, total_loss: 4.324319362640381
training step: 45740, total_loss: 3.796780586242676
training step: 45741, total_loss: 4.020314693450928
training step: 45742, total_loss: 5.817821502685547
training step: 45743, total_loss: 5.81397819519043
training step: 45744, total_loss: 4.1049885749816895
training step: 45745, total_loss: 3.921990394592285
training step: 45746, total_loss: 5.62405252456665
training step: 45747, total_loss: 4.338616371154785
training step: 45748, total_loss: 4.32199764251709
training step: 45749, total_loss: 4.46331787109375
training step: 45750, total_loss: 3.7043657302856445
training step: 45751, total_loss: 3.313626766204834
training step: 45752, total_loss: 4.778486728668213
training step: 45753, total_loss: 5.811048984527588
training step: 45754, total_loss: 2.6597228050231934
training step: 45755, total_loss: 4.0492072105407715
training step: 45756, total_loss: 4.926570415496826
training step: 45757, total_loss: 3.835118293762207
training step: 45758, total_loss: 4.205989360809326
training step: 45759, total_loss: 4.9157795906066895
training step: 45760, total_loss: 2.797802448272705
training step: 45761, total_loss: 3.847698450088501
training step: 45762, total_loss: 6.106090068817139
training step: 45763, total_loss: 3.9812676906585693
training step: 45764, total_loss: 4.251105308532715
training step: 45765, total_loss: 5.548479080200195
training step: 45766, total_loss: 5.4940290451049805
training step: 45767, total_loss: 5.015100479125977
training step: 45768, total_loss: 4.583901405334473
training step: 45769, total_loss: 3.903406858444214
training step: 45770, total_loss: 3.1138908863067627
training step: 45771, total_loss: 4.248604774475098
training step: 45772, total_loss: 3.662546396255493
training step: 45773, total_loss: 5.418133735656738
training step: 45774, total_loss: 4.732240676879883
training step: 45775, total_loss: 3.2169084548950195
training step: 45776, total_loss: 0.976446807384491
training step: 45777, total_loss: 3.4813759326934814
training step: 45778, total_loss: 6.9079389572143555
training step: 45779, total_loss: 6.952819347381592
training step: 45780, total_loss: 5.350841522216797
training step: 45781, total_loss: 5.149249076843262
training step: 45782, total_loss: 3.97676944732666
training step: 45783, total_loss: 5.766836643218994
training step: 45784, total_loss: 3.101996421813965
training step: 45785, total_loss: 3.81181001663208
training step: 45786, total_loss: 4.225131988525391
training step: 45787, total_loss: 4.322565078735352
training step: 45788, total_loss: 4.637574195861816
training step: 45789, total_loss: 4.637331008911133
training step: 45790, total_loss: 2.387054443359375
training step: 45791, total_loss: 4.885372161865234
training step: 45792, total_loss: 5.075479030609131
training step: 45793, total_loss: 0.7106714844703674
training step: 45794, total_loss: 5.0140533447265625
training step: 45795, total_loss: 5.5575103759765625
training step: 45796, total_loss: 5.096724510192871
training step: 45797, total_loss: 3.3182334899902344
training step: 45798, total_loss: 4.855633735656738
training step: 45799, total_loss: 4.882346153259277
training step: 45800, total_loss: 4.313441276550293
training step: 45801, total_loss: 3.55741024017334
training step: 45802, total_loss: 3.9140267372131348
training step: 45803, total_loss: 5.439788818359375
training step: 45804, total_loss: 4.530697822570801
training step: 45805, total_loss: 4.170109748840332
training step: 45806, total_loss: 3.8357691764831543
training step: 45807, total_loss: 4.106959342956543
training step: 45808, total_loss: 5.415736198425293
training step: 45809, total_loss: 3.1257920265197754
training step: 45810, total_loss: 2.366267442703247
training step: 45811, total_loss: 3.6425390243530273
training step: 45812, total_loss: 3.261172294616699
training step: 45813, total_loss: 3.7592053413391113
training step: 45814, total_loss: 4.15687894821167
training step: 45815, total_loss: 4.086678504943848
training step: 45816, total_loss: 4.253044605255127
training step: 45817, total_loss: 4.427653789520264
training step: 45818, total_loss: 4.205061912536621
training step: 45819, total_loss: 5.360888481140137
training step: 45820, total_loss: 4.541445732116699
training step: 45821, total_loss: 5.349331855773926
training step: 45822, total_loss: 5.106180191040039
training step: 45823, total_loss: 3.715245008468628
training step: 45824, total_loss: 2.5709962844848633
training step: 45825, total_loss: 4.013981819152832
training step: 45826, total_loss: 3.9456660747528076
training step: 45827, total_loss: 2.264047622680664
training step: 45828, total_loss: 5.814907073974609
training step: 45829, total_loss: 4.419388771057129
training step: 45830, total_loss: 2.4604246616363525
training step: 45831, total_loss: 2.933727741241455
training step: 45832, total_loss: 0.865641713142395
training step: 45833, total_loss: 3.5035719871520996
training step: 45834, total_loss: 5.173128128051758
training step: 45835, total_loss: 4.5308637619018555
training step: 45836, total_loss: 3.2889552116394043
training step: 45837, total_loss: 4.872680187225342
training step: 45838, total_loss: 5.4770965576171875
training step: 45839, total_loss: 3.0450820922851562
training step: 45840, total_loss: 4.962898254394531
training step: 45841, total_loss: 3.388396978378296
training step: 45842, total_loss: 3.71553111076355
training step: 45843, total_loss: 3.6208574771881104
training step: 45844, total_loss: 4.759657382965088
training step: 45845, total_loss: 4.977775573730469
training step: 45846, total_loss: 5.141140937805176
training step: 45847, total_loss: 5.049809455871582
training step: 45848, total_loss: 5.080779075622559
training step: 45849, total_loss: 2.888913154602051
training step: 45850, total_loss: 4.246827125549316
training step: 45851, total_loss: 4.4341206550598145
training step: 45852, total_loss: 4.112457275390625
training step: 45853, total_loss: 4.514578342437744
training step: 45854, total_loss: 2.84519100189209
training step: 45855, total_loss: 4.743708610534668
training step: 45856, total_loss: 5.421964645385742
training step: 45857, total_loss: 4.110199928283691
training step: 45858, total_loss: 4.306309223175049
training step: 45859, total_loss: 4.1330790519714355
training step: 45860, total_loss: 3.0727930068969727
training step: 45861, total_loss: 4.819033622741699
training step: 45862, total_loss: 3.9725403785705566
training step: 45863, total_loss: 4.549039840698242
training step: 45864, total_loss: 3.5669896602630615
training step: 45865, total_loss: 4.566840171813965
training step: 45866, total_loss: 4.646526336669922
training step: 45867, total_loss: 5.707087516784668
training step: 45868, total_loss: 7.802188873291016
training step: 45869, total_loss: 4.414878845214844
training step: 45870, total_loss: 4.96849250793457
training step: 45871, total_loss: 5.182939529418945
training step: 45872, total_loss: 5.088006973266602
training step: 45873, total_loss: 7.084799766540527
training step: 45874, total_loss: 4.262124538421631
training step: 45875, total_loss: 4.067746162414551
training step: 45876, total_loss: 4.223509311676025
training step: 45877, total_loss: 5.425361633300781
training step: 45878, total_loss: 4.724051475524902
training step: 45879, total_loss: 3.9194998741149902
training step: 45880, total_loss: 2.9151201248168945
training step: 45881, total_loss: 3.633714437484741
training step: 45882, total_loss: 5.424304962158203
training step: 45883, total_loss: 4.092904567718506
training step: 45884, total_loss: 3.6778512001037598
training step: 45885, total_loss: 2.5676326751708984
training step: 45886, total_loss: 5.4610748291015625
training step: 45887, total_loss: 4.376626968383789
training step: 45888, total_loss: 3.6130471229553223
training step: 45889, total_loss: 5.628992557525635
training step: 45890, total_loss: 3.9638657569885254
training step: 45891, total_loss: 3.58469820022583
training step: 45892, total_loss: 2.947152614593506
training step: 45893, total_loss: 4.721100330352783
training step: 45894, total_loss: 3.4639594554901123
training step: 45895, total_loss: 5.262630939483643
training step: 45896, total_loss: 3.4049582481384277
training step: 45897, total_loss: 4.665665626525879
training step: 45898, total_loss: 4.159801959991455
training step: 45899, total_loss: 2.839456796646118
training step: 45900, total_loss: 3.0074095726013184
training step: 45901, total_loss: 1.1562535762786865
training step: 45902, total_loss: 4.554487228393555
training step: 45903, total_loss: 3.9360008239746094
training step: 45904, total_loss: 2.925869941711426
training step: 45905, total_loss: 3.9635350704193115
training step: 45906, total_loss: 4.601870536804199
training step: 45907, total_loss: 4.226465225219727
training step: 45908, total_loss: 3.432279109954834
training step: 45909, total_loss: 5.337368011474609
training step: 45910, total_loss: 5.39925479888916
training step: 45911, total_loss: 4.254624366760254
training step: 45912, total_loss: 5.304837703704834
training step: 45913, total_loss: 6.034972667694092
training step: 45914, total_loss: 5.690644264221191
training step: 45915, total_loss: 5.004347801208496
training step: 45916, total_loss: 5.687917709350586
training step: 45917, total_loss: 3.963479518890381
training step: 45918, total_loss: 1.0127891302108765
training step: 45919, total_loss: 0.8305023908615112
training step: 45920, total_loss: 4.702235221862793
training step: 45921, total_loss: 5.080671310424805
training step: 45922, total_loss: 5.575762748718262
training step: 45923, total_loss: 5.1487836837768555
training step: 45924, total_loss: 4.901068210601807
training step: 45925, total_loss: 5.074859619140625
training step: 45926, total_loss: 4.502357482910156
training step: 45927, total_loss: 3.7141001224517822
training step: 45928, total_loss: 4.464813709259033
training step: 45929, total_loss: 3.3177969455718994
training step: 45930, total_loss: 3.6082892417907715
training step: 45931, total_loss: 4.280658721923828
training step: 45932, total_loss: 5.336878299713135
training step: 45933, total_loss: 4.131459712982178
training step: 45934, total_loss: 5.261721611022949
training step: 45935, total_loss: 4.5148773193359375
training step: 45936, total_loss: 5.549618721008301
training step: 45937, total_loss: 5.100127220153809
training step: 45938, total_loss: 5.0461835861206055
training step: 45939, total_loss: 4.377500534057617
training step: 45940, total_loss: 4.410868167877197
training step: 45941, total_loss: 3.899909257888794
training step: 45942, total_loss: 4.656769275665283
training step: 45943, total_loss: 2.800281047821045
training step: 45944, total_loss: 4.512049674987793
training step: 45945, total_loss: 5.125319957733154
training step: 45946, total_loss: 4.415856838226318
training step: 45947, total_loss: 6.469198226928711
training step: 45948, total_loss: 3.9259934425354004
training step: 45949, total_loss: 2.206078052520752
training step: 45950, total_loss: 5.228447914123535
training step: 45951, total_loss: 0.9410162568092346
training step: 45952, total_loss: 4.265827655792236
training step: 45953, total_loss: 3.5223755836486816
training step: 45954, total_loss: 2.653217077255249
training step: 45955, total_loss: 5.477782249450684
training step: 45956, total_loss: 5.691710948944092
training step: 45957, total_loss: 3.2201426029205322
training step: 45958, total_loss: 4.0668206214904785
training step: 45959, total_loss: 4.774021148681641
training step: 45960, total_loss: 3.2964439392089844
training step: 45961, total_loss: 4.607321262359619
training step: 45962, total_loss: 4.031418323516846
training step: 45963, total_loss: 4.069725513458252
training step: 45964, total_loss: 4.497431755065918
training step: 45965, total_loss: 3.917409658432007
training step: 45966, total_loss: 5.131703853607178
training step: 45967, total_loss: 3.9980220794677734
training step: 45968, total_loss: 5.227321147918701
training step: 45969, total_loss: 4.1283440589904785
training step: 45970, total_loss: 4.56013822555542
training step: 45971, total_loss: 4.378640651702881
training step: 45972, total_loss: 0.7141405344009399
training step: 45973, total_loss: 2.526418447494507
training step: 45974, total_loss: 4.224267959594727
training step: 45975, total_loss: 5.437914848327637
training step: 45976, total_loss: 5.681702613830566
training step: 45977, total_loss: 5.017505645751953
training step: 45978, total_loss: 2.6726901531219482
training step: 45979, total_loss: 4.658291816711426
training step: 45980, total_loss: 5.598328590393066
training step: 45981, total_loss: 4.7937774658203125
training step: 45982, total_loss: 3.711284875869751
training step: 45983, total_loss: 4.657807350158691
training step: 45984, total_loss: 3.9059503078460693
training step: 45985, total_loss: 3.5645415782928467
training step: 45986, total_loss: 4.635973930358887
training step: 45987, total_loss: 5.514891624450684
training step: 45988, total_loss: 4.831143856048584
training step: 45989, total_loss: 5.271939277648926
training step: 45990, total_loss: 5.388080596923828
training step: 45991, total_loss: 4.029979705810547
training step: 45992, total_loss: 3.252492904663086
training step: 45993, total_loss: 4.476523399353027
training step: 45994, total_loss: 4.481034755706787
training step: 45995, total_loss: 4.227158546447754
training step: 45996, total_loss: 4.9265570640563965
training step: 45997, total_loss: 3.491490364074707
training step: 45998, total_loss: 3.2967100143432617
training step: 45999, total_loss: 4.116419315338135
training step: 46000, total_loss: 6.565755367279053
training step: 46001, total_loss: 5.6638569831848145
training step: 46002, total_loss: 3.4846391677856445
training step: 46003, total_loss: 5.198299407958984
training step: 46004, total_loss: 3.235611915588379
training step: 46005, total_loss: 4.716689109802246
training step: 46006, total_loss: 4.942609786987305
training step: 46007, total_loss: 3.397667646408081
training step: 46008, total_loss: 5.063608169555664
training step: 46009, total_loss: 5.26673698425293
training step: 46010, total_loss: 4.0540947914123535
training step: 46011, total_loss: 4.2627482414245605
training step: 46012, total_loss: 1.3738651275634766
training step: 46013, total_loss: 5.723254680633545
training step: 46014, total_loss: 4.0416388511657715
training step: 46015, total_loss: 3.8884568214416504
training step: 46016, total_loss: 2.571782350540161
training step: 46017, total_loss: 4.493705749511719
training step: 46018, total_loss: 4.741729259490967
training step: 46019, total_loss: 2.8961215019226074
training step: 46020, total_loss: 5.927454948425293
training step: 46021, total_loss: 4.81463623046875
training step: 46022, total_loss: 5.232661247253418
training step: 46023, total_loss: 4.2064056396484375
training step: 46024, total_loss: 5.304206848144531
training step: 46025, total_loss: 4.4179911613464355
training step: 46026, total_loss: 4.147006988525391
training step: 46027, total_loss: 2.257934093475342
training step: 46028, total_loss: 3.896063804626465
training step: 46029, total_loss: 2.5363783836364746
training step: 46030, total_loss: 5.005417823791504
training step: 46031, total_loss: 2.628828763961792
training step: 46032, total_loss: 2.8609275817871094
training step: 46033, total_loss: 5.2196736335754395
training step: 46034, total_loss: 4.083349227905273
training step: 46035, total_loss: 4.622900009155273
training step: 46036, total_loss: 5.051204681396484
training step: 46037, total_loss: 4.64073371887207
training step: 46038, total_loss: 4.805839538574219
training step: 46039, total_loss: 3.5844106674194336
training step: 46040, total_loss: 3.273195743560791
training step: 46041, total_loss: 4.147326469421387
training step: 46042, total_loss: 4.249309062957764
training step: 46043, total_loss: 5.715738296508789
training step: 46044, total_loss: 3.523494243621826
training step: 46045, total_loss: 4.569430828094482
training step: 46046, total_loss: 4.404833793640137
training step: 46047, total_loss: 4.192230224609375
training step: 46048, total_loss: 4.426826477050781
training step: 46049, total_loss: 3.9803080558776855
training step: 46050, total_loss: 4.999699592590332
training step: 46051, total_loss: 1.280548095703125
training step: 46052, total_loss: 2.6362199783325195
training step: 46053, total_loss: 4.653055191040039
training step: 46054, total_loss: 4.236193656921387
training step: 46055, total_loss: 4.625448703765869
training step: 46056, total_loss: 3.8696556091308594
training step: 46057, total_loss: 3.532085657119751
training step: 46058, total_loss: 3.8368358612060547
training step: 46059, total_loss: 3.4908716678619385
training step: 46060, total_loss: 3.402454137802124
training step: 46061, total_loss: 2.589120864868164
training step: 46062, total_loss: 4.974839687347412
training step: 46063, total_loss: 2.8290481567382812
training step: 46064, total_loss: 3.28080415725708
training step: 46065, total_loss: 5.804220199584961
training step: 46066, total_loss: 3.942960739135742
training step: 46067, total_loss: 3.629504919052124
training step: 46068, total_loss: 5.017618179321289
training step: 46069, total_loss: 3.8414762020111084
training step: 46070, total_loss: 4.42570161819458
training step: 46071, total_loss: 3.001622438430786
training step: 46072, total_loss: 3.77640962600708
training step: 46073, total_loss: 3.8486480712890625
training step: 46074, total_loss: 5.4441680908203125
training step: 46075, total_loss: 5.036466598510742
training step: 46076, total_loss: 4.530486106872559
training step: 46077, total_loss: 4.70784330368042
training step: 46078, total_loss: 6.380734443664551
training step: 46079, total_loss: 3.740354299545288
training step: 46080, total_loss: 4.522032260894775
training step: 46081, total_loss: 3.117954969406128
training step: 46082, total_loss: 2.862426519393921
training step: 46083, total_loss: 2.888673782348633
training step: 46084, total_loss: 4.002812385559082
training step: 46085, total_loss: 5.229585647583008
training step: 46086, total_loss: 4.190585136413574
training step: 46087, total_loss: 3.799535036087036
training step: 46088, total_loss: 2.298029661178589
training step: 46089, total_loss: 3.7736096382141113
training step: 46090, total_loss: 4.585692405700684
training step: 46091, total_loss: 4.936172962188721
training step: 46092, total_loss: 4.711692810058594
training step: 46093, total_loss: 2.8456056118011475
training step: 46094, total_loss: 5.734858512878418
training step: 46095, total_loss: 5.7131242752075195
training step: 46096, total_loss: 1.900195598602295
training step: 46097, total_loss: 4.635491371154785
training step: 46098, total_loss: 4.593449592590332
training step: 46099, total_loss: 5.006416320800781
training step: 46100, total_loss: 6.775743007659912
training step: 46101, total_loss: 3.9966840744018555
training step: 46102, total_loss: 5.606302738189697
training step: 46103, total_loss: 3.9070441722869873
training step: 46104, total_loss: 6.419771194458008
training step: 46105, total_loss: 5.928435325622559
training step: 46106, total_loss: 4.000244140625
training step: 46107, total_loss: 4.879502296447754
training step: 46108, total_loss: 5.461818695068359
training step: 46109, total_loss: 4.135845184326172
training step: 46110, total_loss: 5.146546840667725
training step: 46111, total_loss: 4.342474937438965
training step: 46112, total_loss: 5.0524702072143555
training step: 46113, total_loss: 5.411102294921875
training step: 46114, total_loss: 3.2093656063079834
training step: 46115, total_loss: 1.5490062236785889
training step: 46116, total_loss: 5.431572914123535
training step: 46117, total_loss: 4.169136047363281
training step: 46118, total_loss: 3.320852756500244
training step: 46119, total_loss: 6.031637191772461
training step: 46120, total_loss: 4.858667373657227
training step: 46121, total_loss: 4.193872451782227
training step: 46122, total_loss: 3.4605441093444824
training step: 46123, total_loss: 5.254039287567139
training step: 46124, total_loss: 3.6245369911193848
training step: 46125, total_loss: 2.1291770935058594
training step: 46126, total_loss: 4.782492160797119
training step: 46127, total_loss: 3.412264347076416
training step: 46128, total_loss: 3.455050468444824
training step: 46129, total_loss: 4.149127960205078
training step: 46130, total_loss: 3.809553384780884
training step: 46131, total_loss: 3.9738571643829346
training step: 46132, total_loss: 5.035611152648926
training step: 46133, total_loss: 3.824507713317871
training step: 46134, total_loss: 4.236137866973877
training step: 46135, total_loss: 4.625605583190918
training step: 46136, total_loss: 4.263909816741943
training step: 46137, total_loss: 4.897431373596191
training step: 46138, total_loss: 4.097310543060303
training step: 46139, total_loss: 3.7525579929351807
training step: 46140, total_loss: 3.9516477584838867
training step: 46141, total_loss: 1.0807652473449707
training step: 46142, total_loss: 3.6379103660583496
training step: 46143, total_loss: 4.464132308959961
training step: 46144, total_loss: 4.320940017700195
training step: 46145, total_loss: 4.0335001945495605
training step: 46146, total_loss: 5.010010719299316
training step: 46147, total_loss: 3.4214258193969727
training step: 46148, total_loss: 4.712435722351074
training step: 46149, total_loss: 5.771016597747803
training step: 46150, total_loss: 1.2528260946273804
training step: 46151, total_loss: 4.443594932556152
training step: 46152, total_loss: 2.9622550010681152
training step: 46153, total_loss: 4.676956653594971
training step: 46154, total_loss: 4.092945098876953
training step: 46155, total_loss: 3.6939125061035156
training step: 46156, total_loss: 3.226512908935547
training step: 46157, total_loss: 4.077664852142334
training step: 46158, total_loss: 3.416950225830078
training step: 46159, total_loss: 4.310549259185791
training step: 46160, total_loss: 4.349440097808838
training step: 46161, total_loss: 5.045881271362305
training step: 46162, total_loss: 4.501574516296387
training step: 46163, total_loss: 4.981884479522705
training step: 46164, total_loss: 5.507359504699707
training step: 46165, total_loss: 4.248071670532227
training step: 46166, total_loss: 5.463055610656738
training step: 46167, total_loss: 4.4824628829956055
training step: 46168, total_loss: 4.404477119445801
training step: 46169, total_loss: 4.873739719390869
training step: 46170, total_loss: 0.8658938407897949
training step: 46171, total_loss: 5.171504974365234
training step: 46172, total_loss: 3.1805624961853027
training step: 46173, total_loss: 5.367674827575684
training step: 46174, total_loss: 4.038441181182861
training step: 46175, total_loss: 4.293526649475098
training step: 46176, total_loss: 5.044960021972656
training step: 46177, total_loss: 6.401849269866943
training step: 46178, total_loss: 4.880926132202148
training step: 46179, total_loss: 4.129914283752441
training step: 46180, total_loss: 5.3377203941345215
training step: 46181, total_loss: 1.6919622421264648
training step: 46182, total_loss: 6.674781799316406
training step: 46183, total_loss: 5.2521562576293945
training step: 46184, total_loss: 2.4865455627441406
training step: 46185, total_loss: 4.471831798553467
training step: 46186, total_loss: 6.276538848876953
training step: 46187, total_loss: 3.718644142150879
training step: 46188, total_loss: 2.912961959838867
training step: 46189, total_loss: 5.379710674285889
training step: 46190, total_loss: 2.738278865814209
training step: 46191, total_loss: 2.8772618770599365
training step: 46192, total_loss: 3.183687210083008
training step: 46193, total_loss: 3.7394752502441406
training step: 46194, total_loss: 6.240330696105957
training step: 46195, total_loss: 2.8875985145568848
training step: 46196, total_loss: 4.594320774078369
training step: 46197, total_loss: 6.213787078857422
training step: 46198, total_loss: 2.1264781951904297
training step: 46199, total_loss: 4.781648635864258
training step: 46200, total_loss: 5.407605171203613
training step: 46201, total_loss: 3.374439239501953
training step: 46202, total_loss: 4.320659637451172
training step: 46203, total_loss: 3.962693214416504
training step: 46204, total_loss: 5.030311107635498
training step: 46205, total_loss: 3.4110910892486572
training step: 46206, total_loss: 2.582993507385254
training step: 46207, total_loss: 6.113897323608398
training step: 46208, total_loss: 0.8838798999786377
training step: 46209, total_loss: 5.026024341583252
training step: 46210, total_loss: 4.130313873291016
training step: 46211, total_loss: 2.200054883956909
training step: 46212, total_loss: 2.959865093231201
training step: 46213, total_loss: 3.543125867843628
training step: 46214, total_loss: 2.8950624465942383
training step: 46215, total_loss: 5.441670894622803
training step: 46216, total_loss: 4.124049663543701
training step: 46217, total_loss: 5.304555892944336
training step: 46218, total_loss: 3.40946102142334
training step: 46219, total_loss: 2.5759472846984863
training step: 46220, total_loss: 5.562469959259033
training step: 46221, total_loss: 6.00385856628418
training step: 46222, total_loss: 5.255118370056152
training step: 46223, total_loss: 4.980561256408691
training step: 46224, total_loss: 5.650877952575684
training step: 46225, total_loss: 3.9501969814300537
training step: 46226, total_loss: 3.8073978424072266
training step: 46227, total_loss: 4.740306854248047
training step: 46228, total_loss: 5.84512186050415
training step: 46229, total_loss: 4.410334587097168
training step: 46230, total_loss: 4.829697132110596
training step: 46231, total_loss: 4.980960845947266
training step: 46232, total_loss: 4.512166976928711
training step: 46233, total_loss: 5.103569030761719
training step: 46234, total_loss: 5.410125255584717
training step: 46235, total_loss: 3.657062530517578
training step: 46236, total_loss: 4.719325065612793
training step: 46237, total_loss: 4.754740238189697
training step: 46238, total_loss: 4.8428850173950195
training step: 46239, total_loss: 4.649228096008301
training step: 46240, total_loss: 3.8538217544555664
training step: 46241, total_loss: 5.339598178863525
training step: 46242, total_loss: 4.471434593200684
training step: 46243, total_loss: 4.4827799797058105
training step: 46244, total_loss: 3.8779397010803223
training step: 46245, total_loss: 5.9942827224731445
training step: 46246, total_loss: 4.637725830078125
training step: 46247, total_loss: 4.496809959411621
training step: 46248, total_loss: 5.453304290771484
training step: 46249, total_loss: 3.3664145469665527
training step: 46250, total_loss: 4.947893142700195
training step: 46251, total_loss: 3.9278643131256104
training step: 46252, total_loss: 4.664050579071045
training step: 46253, total_loss: 5.710021018981934
training step: 46254, total_loss: 4.278467655181885
training step: 46255, total_loss: 3.8624515533447266
training step: 46256, total_loss: 3.5098812580108643
training step: 46257, total_loss: 5.220592975616455
training step: 46258, total_loss: 4.577854156494141
training step: 46259, total_loss: 4.638174533843994
training step: 46260, total_loss: 4.412371635437012
training step: 46261, total_loss: 3.586933135986328
training step: 46262, total_loss: 4.438442707061768
training step: 46263, total_loss: 4.6114702224731445
training step: 46264, total_loss: 4.406269073486328
training step: 46265, total_loss: 4.602052211761475
training step: 46266, total_loss: 6.022436618804932
training step: 46267, total_loss: 5.037647247314453
training step: 46268, total_loss: 4.421808242797852
training step: 46269, total_loss: 4.1099114418029785
training step: 46270, total_loss: 3.583831787109375
training step: 46271, total_loss: 3.796621799468994
training step: 46272, total_loss: 3.989100933074951
training step: 46273, total_loss: 5.574950218200684
training step: 46274, total_loss: 0.9390891194343567
training step: 46275, total_loss: 3.217928409576416
training step: 46276, total_loss: 3.478182315826416
training step: 46277, total_loss: 4.890036582946777
training step: 46278, total_loss: 3.8345723152160645
training step: 46279, total_loss: 3.756558656692505
training step: 46280, total_loss: 4.21331262588501
training step: 46281, total_loss: 1.902907133102417
training step: 46282, total_loss: 5.359731674194336
training step: 46283, total_loss: 5.936675071716309
training step: 46284, total_loss: 4.747705459594727
training step: 46285, total_loss: 4.445934772491455
training step: 46286, total_loss: 5.520227432250977
training step: 46287, total_loss: 5.107673168182373
training step: 46288, total_loss: 3.469883441925049
training step: 46289, total_loss: 3.9910006523132324
training step: 46290, total_loss: 2.849426746368408
training step: 46291, total_loss: 4.095366954803467
training step: 46292, total_loss: 6.095206260681152
training step: 46293, total_loss: 4.6086273193359375
training step: 46294, total_loss: 2.897289276123047
training step: 46295, total_loss: 4.530951976776123
training step: 46296, total_loss: 5.429461479187012
training step: 46297, total_loss: 4.137827396392822
training step: 46298, total_loss: 4.261895656585693
training step: 46299, total_loss: 3.2811472415924072
training step: 46300, total_loss: 5.109926223754883
training step: 46301, total_loss: 4.6015472412109375
training step: 46302, total_loss: 4.165309429168701
training step: 46303, total_loss: 4.274105072021484
training step: 46304, total_loss: 5.677286148071289
training step: 46305, total_loss: 7.031215190887451
training step: 46306, total_loss: 4.246975421905518
training step: 46307, total_loss: 4.5809221267700195
training step: 46308, total_loss: 4.424405097961426
training step: 46309, total_loss: 4.517433166503906
training step: 46310, total_loss: 4.172789573669434
training step: 46311, total_loss: 2.57814359664917
training step: 46312, total_loss: 4.316720008850098
training step: 46313, total_loss: 4.076873779296875
training step: 46314, total_loss: 4.541218280792236
training step: 46315, total_loss: 3.425814628601074
training step: 46316, total_loss: 4.273070335388184
training step: 46317, total_loss: 5.098299980163574
training step: 46318, total_loss: 5.092776775360107
training step: 46319, total_loss: 4.964886665344238
training step: 46320, total_loss: 5.224244117736816
training step: 46321, total_loss: 1.1423277854919434
training step: 46322, total_loss: 5.251989364624023
training step: 46323, total_loss: 2.9123635292053223
training step: 46324, total_loss: 4.463037014007568
training step: 46325, total_loss: 3.857484817504883
training step: 46326, total_loss: 5.585664749145508
training step: 46327, total_loss: 5.930135726928711
training step: 46328, total_loss: 4.177651405334473
training step: 46329, total_loss: 3.2330880165100098
training step: 46330, total_loss: 3.892409324645996
training step: 46331, total_loss: 5.121220588684082
training step: 46332, total_loss: 5.463583946228027
training step: 46333, total_loss: 3.421060800552368
training step: 46334, total_loss: 4.827535629272461
training step: 46335, total_loss: 4.753034591674805
training step: 46336, total_loss: 7.3497138023376465
training step: 46337, total_loss: 5.661362648010254
training step: 46338, total_loss: 6.050310134887695
training step: 46339, total_loss: 4.386941909790039
training step: 46340, total_loss: 2.890467643737793
training step: 46341, total_loss: 4.050108909606934
training step: 46342, total_loss: 4.990246772766113
training step: 46343, total_loss: 3.5185036659240723
training step: 46344, total_loss: 3.8550221920013428
training step: 46345, total_loss: 4.633865833282471
training step: 46346, total_loss: 3.0856213569641113
training step: 46347, total_loss: 3.7023801803588867
training step: 46348, total_loss: 5.121216297149658
training step: 46349, total_loss: 4.6829729080200195
training step: 46350, total_loss: 5.764706611633301
training step: 46351, total_loss: 4.295165061950684
training step: 46352, total_loss: 5.157605171203613
training step: 46353, total_loss: 1.0991504192352295
training step: 46354, total_loss: 4.040911674499512
training step: 46355, total_loss: 4.833881378173828
training step: 46356, total_loss: 4.75014591217041
training step: 46357, total_loss: 5.556870460510254
training step: 46358, total_loss: 3.9573464393615723
training step: 46359, total_loss: 4.727006435394287
training step: 46360, total_loss: 5.872593879699707
training step: 46361, total_loss: 3.1889805793762207
training step: 46362, total_loss: 5.65071439743042
training step: 46363, total_loss: 4.016139507293701
training step: 46364, total_loss: 4.789978981018066
training step: 46365, total_loss: 4.978354454040527
training step: 46366, total_loss: 3.648587465286255
training step: 46367, total_loss: 6.013896942138672
training step: 46368, total_loss: 1.2135004997253418
training step: 46369, total_loss: 3.987356662750244
training step: 46370, total_loss: 4.022311687469482
training step: 46371, total_loss: 4.292916297912598
training step: 46372, total_loss: 6.358809471130371
training step: 46373, total_loss: 4.977062225341797
training step: 46374, total_loss: 4.48418664932251
training step: 46375, total_loss: 4.2032389640808105
training step: 46376, total_loss: 5.02565860748291
training step: 46377, total_loss: 4.196027755737305
training step: 46378, total_loss: 4.053709983825684
training step: 46379, total_loss: 4.757603645324707
training step: 46380, total_loss: 5.714474678039551
training step: 46381, total_loss: 3.831963539123535
training step: 46382, total_loss: 4.651923656463623
training step: 46383, total_loss: 3.648085832595825
training step: 46384, total_loss: 4.870654106140137
training step: 46385, total_loss: 4.0903472900390625
training step: 46386, total_loss: 4.036044120788574
training step: 46387, total_loss: 3.7938199043273926
training step: 46388, total_loss: 4.737837791442871
training step: 46389, total_loss: 1.0565428733825684
training step: 46390, total_loss: 4.380414009094238
training step: 46391, total_loss: 3.943878173828125
training step: 46392, total_loss: 4.772106170654297
training step: 46393, total_loss: 5.436529159545898
training step: 46394, total_loss: 3.7993321418762207
training step: 46395, total_loss: 4.354220867156982
training step: 46396, total_loss: 5.5074782371521
training step: 46397, total_loss: 3.2131035327911377
training step: 46398, total_loss: 2.8545217514038086
training step: 46399, total_loss: 4.327999114990234
training step: 46400, total_loss: 4.173807621002197
training step: 46401, total_loss: 4.1757307052612305
training step: 46402, total_loss: 4.347755432128906
training step: 46403, total_loss: 4.787994384765625
training step: 46404, total_loss: 3.8413000106811523
training step: 46405, total_loss: 4.802728652954102
training step: 46406, total_loss: 5.276920318603516
training step: 46407, total_loss: 4.825716495513916
training step: 46408, total_loss: 5.0963969230651855
training step: 46409, total_loss: 4.353283405303955
training step: 46410, total_loss: 1.2231725454330444
training step: 46411, total_loss: 4.512741565704346
training step: 46412, total_loss: 3.140875816345215
training step: 46413, total_loss: 5.432893753051758
training step: 46414, total_loss: 3.467470645904541
training step: 46415, total_loss: 4.2758026123046875
training step: 46416, total_loss: 4.315190315246582
training step: 46417, total_loss: 4.147967338562012
training step: 46418, total_loss: 5.427114486694336
training step: 46419, total_loss: 4.016514301300049
training step: 46420, total_loss: 3.4729137420654297
training step: 46421, total_loss: 3.1352412700653076
training step: 46422, total_loss: 3.5731685161590576
training step: 46423, total_loss: 4.723853588104248
training step: 46424, total_loss: 4.348441123962402
training step: 46425, total_loss: 4.353687286376953
training step: 46426, total_loss: 4.071126461029053
training step: 46427, total_loss: 4.848822593688965
training step: 46428, total_loss: 3.950155258178711
training step: 46429, total_loss: 2.5535457134246826
training step: 46430, total_loss: 4.607822418212891
training step: 46431, total_loss: 2.106090545654297
training step: 46432, total_loss: 4.923463344573975
training step: 46433, total_loss: 3.799154281616211
training step: 46434, total_loss: 4.619686603546143
training step: 46435, total_loss: 3.5547947883605957
training step: 46436, total_loss: 6.080655097961426
training step: 46437, total_loss: 5.49717378616333
training step: 46438, total_loss: 4.205938339233398
training step: 46439, total_loss: 5.5941057205200195
training step: 46440, total_loss: 5.25233793258667
training step: 46441, total_loss: 2.8642375469207764
training step: 46442, total_loss: 4.742681503295898
training step: 46443, total_loss: 5.323923110961914
training step: 46444, total_loss: 4.233882904052734
training step: 46445, total_loss: 5.118158340454102
training step: 46446, total_loss: 4.446578502655029
training step: 46447, total_loss: 4.172600269317627
training step: 46448, total_loss: 3.27569580078125
training step: 46449, total_loss: 3.549138307571411
training step: 46450, total_loss: 5.876052379608154
training step: 46451, total_loss: 3.9074978828430176
training step: 46452, total_loss: 3.2374911308288574
training step: 46453, total_loss: 4.8869099617004395
training step: 46454, total_loss: 4.757594585418701
training step: 46455, total_loss: 5.475154399871826
training step: 46456, total_loss: 4.497254371643066
training step: 46457, total_loss: 3.0257608890533447
training step: 46458, total_loss: 4.309045314788818
training step: 46459, total_loss: 5.2705535888671875
training step: 46460, total_loss: 5.717110633850098
training step: 46461, total_loss: 3.0267796516418457
training step: 46462, total_loss: 3.635185956954956
training step: 46463, total_loss: 1.0483227968215942
training step: 46464, total_loss: 3.847714900970459
training step: 46465, total_loss: 4.6864495277404785
training step: 46466, total_loss: 6.165081977844238
training step: 46467, total_loss: 5.426206588745117
training step: 46468, total_loss: 4.419369220733643
training step: 46469, total_loss: 5.491754531860352
training step: 46470, total_loss: 3.4905800819396973
training step: 46471, total_loss: 3.0002408027648926
training step: 46472, total_loss: 4.018651962280273
training step: 46473, total_loss: 5.12904691696167
training step: 46474, total_loss: 4.580960273742676
training step: 46475, total_loss: 3.6588032245635986
training step: 46476, total_loss: 5.7947468757629395
training step: 46477, total_loss: 4.991022109985352
training step: 46478, total_loss: 4.925962924957275
training step: 46479, total_loss: 5.641423225402832
training step: 46480, total_loss: 4.217545986175537
training step: 46481, total_loss: 4.397431373596191
training step: 46482, total_loss: 4.112819671630859
training step: 46483, total_loss: 1.5925354957580566
training step: 46484, total_loss: 4.337401390075684
training step: 46485, total_loss: 5.257922172546387
training step: 46486, total_loss: 3.991283893585205
training step: 46487, total_loss: 3.936311721801758
training step: 46488, total_loss: 5.367813587188721
training step: 46489, total_loss: 3.4765825271606445
training step: 46490, total_loss: 5.041327476501465
training step: 46491, total_loss: 5.571808815002441
training step: 46492, total_loss: 3.1001219749450684
training step: 46493, total_loss: 3.801541328430176
training step: 46494, total_loss: 4.027857780456543
training step: 46495, total_loss: 1.4112659692764282
training step: 46496, total_loss: 3.612515687942505
training step: 46497, total_loss: 4.563873291015625
training step: 46498, total_loss: 4.339138984680176
training step: 46499, total_loss: 5.7525811195373535
training step: 46500, total_loss: 5.6641082763671875
training step: 46501, total_loss: 4.774824142456055
training step: 46502, total_loss: 3.618955612182617
training step: 46503, total_loss: 4.296315670013428
training step: 46504, total_loss: 3.3232879638671875
training step: 46505, total_loss: 5.424670219421387
training step: 46506, total_loss: 4.320428848266602
training step: 46507, total_loss: 2.31158447265625
training step: 46508, total_loss: 3.7888565063476562
training step: 46509, total_loss: 3.0534958839416504
training step: 46510, total_loss: 5.6537322998046875
training step: 46511, total_loss: 4.771679401397705
training step: 46512, total_loss: 4.756732940673828
training step: 46513, total_loss: 2.2714648246765137
training step: 46514, total_loss: 3.4433236122131348
training step: 46515, total_loss: 5.564851760864258
training step: 46516, total_loss: 5.66021203994751
training step: 46517, total_loss: 3.5294814109802246
training step: 46518, total_loss: 2.670758008956909
training step: 46519, total_loss: 3.429591178894043
training step: 46520, total_loss: 3.116619110107422
training step: 46521, total_loss: 3.2726073265075684
training step: 46522, total_loss: 4.157175064086914
training step: 46523, total_loss: 5.235410213470459
training step: 46524, total_loss: 4.439319610595703
training step: 46525, total_loss: 2.916064739227295
training step: 46526, total_loss: 5.2614850997924805
training step: 46527, total_loss: 5.418954372406006
training step: 46528, total_loss: 5.1291303634643555
training step: 46529, total_loss: 3.016433000564575
training step: 46530, total_loss: 4.376242637634277
training step: 46531, total_loss: 4.872232437133789
training step: 46532, total_loss: 6.425765037536621
training step: 46533, total_loss: 5.613091468811035
training step: 46534, total_loss: 4.618129253387451
training step: 46535, total_loss: 3.943436861038208
training step: 46536, total_loss: 6.270525932312012
training step: 46537, total_loss: 3.493891716003418
training step: 46538, total_loss: 3.4905567169189453
training step: 46539, total_loss: 2.0802831649780273
training step: 46540, total_loss: 4.408095359802246
training step: 46541, total_loss: 5.185664176940918
training step: 46542, total_loss: 3.8485965728759766
training step: 46543, total_loss: 0.9477430582046509
training step: 46544, total_loss: 3.4557132720947266
training step: 46545, total_loss: 2.781904697418213
training step: 46546, total_loss: 4.266383647918701
training step: 46547, total_loss: 4.698347091674805
training step: 46548, total_loss: 3.190600872039795
training step: 46549, total_loss: 4.339303016662598
training step: 46550, total_loss: 5.13983678817749
training step: 46551, total_loss: 3.8270983695983887
training step: 46552, total_loss: 4.8321990966796875
training step: 46553, total_loss: 3.9860315322875977
training step: 46554, total_loss: 5.227972030639648
training step: 46555, total_loss: 3.164125919342041
training step: 46556, total_loss: 3.7507166862487793
training step: 46557, total_loss: 6.038650989532471
training step: 46558, total_loss: 5.556333541870117
training step: 46559, total_loss: 1.9611155986785889
training step: 46560, total_loss: 3.9574851989746094
training step: 46561, total_loss: 5.099710464477539
training step: 46562, total_loss: 3.7066307067871094
training step: 46563, total_loss: 3.2587685585021973
training step: 46564, total_loss: 4.029437065124512
training step: 46565, total_loss: 3.710695743560791
training step: 46566, total_loss: 3.5988025665283203
training step: 46567, total_loss: 5.296380519866943
training step: 46568, total_loss: 3.649001121520996
training step: 46569, total_loss: 4.690886497497559
training step: 46570, total_loss: 5.219485282897949
training step: 46571, total_loss: 5.320493698120117
training step: 46572, total_loss: 3.4874744415283203
training step: 46573, total_loss: 3.787006139755249
training step: 46574, total_loss: 5.85860538482666
training step: 46575, total_loss: 5.4005279541015625
training step: 46576, total_loss: 4.231290340423584
training step: 46577, total_loss: 3.806987762451172
training step: 46578, total_loss: 4.120657444000244
training step: 46579, total_loss: 4.750876426696777
training step: 46580, total_loss: 4.762314796447754
training step: 46581, total_loss: 4.540212154388428
training step: 46582, total_loss: 6.727939605712891
training step: 46583, total_loss: 3.1335668563842773
training step: 46584, total_loss: 4.86392068862915
training step: 46585, total_loss: 2.459174156188965
training step: 46586, total_loss: 3.297328233718872
training step: 46587, total_loss: 5.888924598693848
training step: 46588, total_loss: 2.5445451736450195
training step: 46589, total_loss: 3.8798916339874268
training step: 46590, total_loss: 2.777275562286377
training step: 46591, total_loss: 1.3403687477111816
training step: 46592, total_loss: 5.344482421875
training step: 46593, total_loss: 5.173884391784668
training step: 46594, total_loss: 4.800736427307129
training step: 46595, total_loss: 4.7008490562438965
training step: 46596, total_loss: 3.8380560874938965
training step: 46597, total_loss: 4.801976680755615
training step: 46598, total_loss: 5.377744197845459
training step: 46599, total_loss: 4.539114952087402
training step: 46600, total_loss: 2.7213516235351562
training step: 46601, total_loss: 4.474543571472168
training step: 46602, total_loss: 5.6117143630981445
training step: 46603, total_loss: 5.595690727233887
training step: 46604, total_loss: 3.3128504753112793
training step: 46605, total_loss: 4.292685031890869
training step: 46606, total_loss: 4.19591760635376
training step: 46607, total_loss: 4.904832363128662
training step: 46608, total_loss: 5.856705665588379
training step: 46609, total_loss: 4.558501720428467
training step: 46610, total_loss: 4.5914435386657715
training step: 46611, total_loss: 3.3820536136627197
training step: 46612, total_loss: 5.780041694641113
training step: 46613, total_loss: 3.935486316680908
training step: 46614, total_loss: 4.759660720825195
training step: 46615, total_loss: 4.931243896484375
training step: 46616, total_loss: 2.9644556045532227
training step: 46617, total_loss: 0.7577884197235107
training step: 46618, total_loss: 3.2581214904785156
training step: 46619, total_loss: 5.3485283851623535
training step: 46620, total_loss: 5.4021711349487305
training step: 46621, total_loss: 5.447126388549805
training step: 46622, total_loss: 2.8801488876342773
training step: 46623, total_loss: 4.1696600914001465
training step: 46624, total_loss: 7.702920913696289
training step: 46625, total_loss: 3.652308464050293
training step: 46626, total_loss: 4.229817867279053
training step: 46627, total_loss: 4.886369705200195
training step: 46628, total_loss: 3.1457502841949463
training step: 46629, total_loss: 4.452276706695557
training step: 46630, total_loss: 3.424593925476074
training step: 46631, total_loss: 5.34031867980957
training step: 46632, total_loss: 4.929484844207764
training step: 46633, total_loss: 3.677189350128174
training step: 46634, total_loss: 4.104557514190674
training step: 46635, total_loss: 4.974056720733643
training step: 46636, total_loss: 2.200923204421997
training step: 46637, total_loss: 3.89267635345459
training step: 46638, total_loss: 4.380880355834961
training step: 46639, total_loss: 2.071009635925293
training step: 46640, total_loss: 3.456163167953491
training step: 46641, total_loss: 2.5350301265716553
training step: 46642, total_loss: 2.7601802349090576
training step: 46643, total_loss: 4.669922828674316
training step: 46644, total_loss: 4.299286365509033
training step: 46645, total_loss: 2.967074394226074
training step: 46646, total_loss: 4.613373279571533
training step: 46647, total_loss: 4.522021770477295
training step: 46648, total_loss: 5.838949203491211
training step: 46649, total_loss: 5.173834800720215
training step: 46650, total_loss: 3.4290566444396973
training step: 46651, total_loss: 5.2207746505737305
training step: 46652, total_loss: 4.968980312347412
training step: 46653, total_loss: 4.280908584594727
training step: 46654, total_loss: 3.2207682132720947
training step: 46655, total_loss: 4.203041076660156
training step: 46656, total_loss: 5.497655868530273
training step: 46657, total_loss: 5.460664749145508
training step: 46658, total_loss: 3.626659870147705
training step: 46659, total_loss: 4.5716753005981445
training step: 46660, total_loss: 4.889455318450928
training step: 46661, total_loss: 5.058101654052734
training step: 46662, total_loss: 3.0671491622924805
training step: 46663, total_loss: 4.996892929077148
training step: 46664, total_loss: 5.379613876342773
training step: 46665, total_loss: 3.354550361633301
training step: 46666, total_loss: 4.6582231521606445
training step: 46667, total_loss: 5.23770809173584
training step: 46668, total_loss: 5.18795108795166
training step: 46669, total_loss: 4.9756059646606445
training step: 46670, total_loss: 3.8436403274536133
training step: 46671, total_loss: 4.152694225311279
training step: 46672, total_loss: 3.8936619758605957
training step: 46673, total_loss: 4.813899040222168
training step: 46674, total_loss: 4.897627830505371
training step: 46675, total_loss: 3.7619681358337402
training step: 46676, total_loss: 3.778651237487793
training step: 46677, total_loss: 6.011087417602539
training step: 46678, total_loss: 5.13295841217041
training step: 46679, total_loss: 4.266658306121826
training step: 46680, total_loss: 4.876154899597168
training step: 46681, total_loss: 3.491095542907715
training step: 46682, total_loss: 4.196713447570801
training step: 46683, total_loss: 4.321010589599609
training step: 46684, total_loss: 3.7860755920410156
training step: 46685, total_loss: 6.006283283233643
training step: 46686, total_loss: 4.956677436828613
training step: 46687, total_loss: 5.28859281539917
training step: 46688, total_loss: 0.993735671043396
training step: 46689, total_loss: 4.148749351501465
training step: 46690, total_loss: 4.376380920410156
training step: 46691, total_loss: 5.212329864501953
training step: 46692, total_loss: 5.079716205596924
training step: 46693, total_loss: 4.638548851013184
training step: 46694, total_loss: 4.400819301605225
training step: 46695, total_loss: 2.4436397552490234
training step: 46696, total_loss: 5.873636245727539
training step: 46697, total_loss: 4.464744567871094
training step: 46698, total_loss: 3.6798477172851562
training step: 46699, total_loss: 4.535210609436035
training step: 46700, total_loss: 6.398551940917969
training step: 46701, total_loss: 5.410444259643555
training step: 46702, total_loss: 5.062106132507324
training step: 46703, total_loss: 0.6876989603042603
training step: 46704, total_loss: 3.1142284870147705
training step: 46705, total_loss: 4.551425933837891
training step: 46706, total_loss: 4.365030288696289
training step: 46707, total_loss: 3.5579402446746826
training step: 46708, total_loss: 3.3929619789123535
training step: 46709, total_loss: 2.6682729721069336
training step: 46710, total_loss: 5.507119178771973
training step: 46711, total_loss: 4.220396995544434
training step: 46712, total_loss: 6.272428512573242
training step: 46713, total_loss: 5.823163986206055
training step: 46714, total_loss: 4.111488342285156
training step: 46715, total_loss: 5.53488826751709
training step: 46716, total_loss: 3.876742124557495
training step: 46717, total_loss: 4.027029991149902
training step: 46718, total_loss: 2.055368185043335
training step: 46719, total_loss: 5.959095478057861
training step: 46720, total_loss: 2.8754358291625977
training step: 46721, total_loss: 3.728093147277832
training step: 46722, total_loss: 0.8414599299430847
training step: 46723, total_loss: 4.195713996887207
training step: 46724, total_loss: 4.864463806152344
training step: 46725, total_loss: 5.343440532684326
training step: 46726, total_loss: 6.121108055114746
training step: 46727, total_loss: 4.490079879760742
training step: 46728, total_loss: 5.102749347686768
training step: 46729, total_loss: 5.828706741333008
training step: 46730, total_loss: 4.477615833282471
training step: 46731, total_loss: 3.768104314804077
training step: 46732, total_loss: 2.1986448764801025
training step: 46733, total_loss: 5.069298267364502
training step: 46734, total_loss: 4.391681671142578
training step: 46735, total_loss: 5.38797664642334
training step: 46736, total_loss: 3.3580482006073
training step: 46737, total_loss: 4.545870780944824
training step: 46738, total_loss: 2.737698554992676
training step: 46739, total_loss: 3.076819658279419
training step: 46740, total_loss: 4.5253448486328125
training step: 46741, total_loss: 4.861044883728027
training step: 46742, total_loss: 3.749699831008911
training step: 46743, total_loss: 7.433298110961914
training step: 46744, total_loss: 2.9609169960021973
training step: 46745, total_loss: 4.017053127288818
training step: 46746, total_loss: 5.43658447265625
training step: 46747, total_loss: 5.501123905181885
training step: 46748, total_loss: 2.4473509788513184
training step: 46749, total_loss: 4.891969680786133
training step: 46750, total_loss: 5.347535133361816
training step: 46751, total_loss: 5.182696342468262
training step: 46752, total_loss: 4.442409515380859
training step: 46753, total_loss: 5.081785202026367
training step: 46754, total_loss: 2.4586336612701416
training step: 46755, total_loss: 4.109235763549805
training step: 46756, total_loss: 5.1537251472473145
training step: 46757, total_loss: 1.9888569116592407
training step: 46758, total_loss: 3.5005691051483154
training step: 46759, total_loss: 4.487496376037598
training step: 46760, total_loss: 5.504486083984375
training step: 46761, total_loss: 4.999388217926025
training step: 46762, total_loss: 4.991278648376465
training step: 46763, total_loss: 3.7795677185058594
training step: 46764, total_loss: 2.772963523864746
training step: 46765, total_loss: 3.0963048934936523
training step: 46766, total_loss: 4.414864540100098
training step: 46767, total_loss: 4.451732635498047
training step: 46768, total_loss: 4.872474670410156
training step: 46769, total_loss: 5.475469589233398
training step: 46770, total_loss: 4.078342437744141
training step: 46771, total_loss: 3.8570332527160645
training step: 46772, total_loss: 4.142524719238281
training step: 46773, total_loss: 5.3755011558532715
training step: 46774, total_loss: 5.702754974365234
training step: 46775, total_loss: 5.549071788787842
training step: 46776, total_loss: 1.4814281463623047
training step: 46777, total_loss: 1.246312141418457
training step: 46778, total_loss: 3.8775243759155273
training step: 46779, total_loss: 5.781806945800781
training step: 46780, total_loss: 4.355317115783691
training step: 46781, total_loss: 3.981867551803589
training step: 46782, total_loss: 5.12313175201416
training step: 46783, total_loss: 7.445115089416504
training step: 46784, total_loss: 2.7609171867370605
training step: 46785, total_loss: 4.405328750610352
training step: 46786, total_loss: 4.763018608093262
training step: 46787, total_loss: 6.242498397827148
training step: 46788, total_loss: 3.3782665729522705
training step: 46789, total_loss: 5.416225433349609
training step: 46790, total_loss: 6.560238838195801
training step: 46791, total_loss: 4.293598651885986
training step: 46792, total_loss: 2.67936635017395
training step: 46793, total_loss: 4.901495456695557
training step: 46794, total_loss: 3.9332756996154785
training step: 46795, total_loss: 2.611659049987793
training step: 46796, total_loss: 4.553745746612549
training step: 46797, total_loss: 4.129568099975586
training step: 46798, total_loss: 4.694262504577637
training step: 46799, total_loss: 4.384443283081055
training step: 46800, total_loss: 5.287782669067383
training step: 46801, total_loss: 5.768067836761475
training step: 46802, total_loss: 6.070320129394531
training step: 46803, total_loss: 6.158424377441406
training step: 46804, total_loss: 2.938509702682495
training step: 46805, total_loss: 4.3047380447387695
training step: 46806, total_loss: 5.269992828369141
training step: 46807, total_loss: 2.8956704139709473
training step: 46808, total_loss: 3.6136627197265625
training step: 46809, total_loss: 5.005527019500732
training step: 46810, total_loss: 3.975003719329834
training step: 46811, total_loss: 5.199704647064209
training step: 46812, total_loss: 5.684162139892578
training step: 46813, total_loss: 3.6490089893341064
training step: 46814, total_loss: 5.370820999145508
training step: 46815, total_loss: 5.270284652709961
training step: 46816, total_loss: 5.747335433959961
training step: 46817, total_loss: 4.696761131286621
training step: 46818, total_loss: 2.153120994567871
training step: 46819, total_loss: 5.002346038818359
training step: 46820, total_loss: 3.8956894874572754
training step: 46821, total_loss: 4.47090482711792
training step: 46822, total_loss: 3.928412914276123
training step: 46823, total_loss: 4.309238433837891
training step: 46824, total_loss: 4.364775657653809
training step: 46825, total_loss: 6.438763618469238
training step: 46826, total_loss: 4.992871284484863
training step: 46827, total_loss: 7.332042694091797
training step: 46828, total_loss: 4.270867347717285
training step: 46829, total_loss: 5.524031639099121
training step: 46830, total_loss: 0.8297908306121826
training step: 46831, total_loss: 2.6679298877716064
training step: 46832, total_loss: 0.9905254244804382
training step: 46833, total_loss: 4.308755397796631
training step: 46834, total_loss: 4.0386457443237305
training step: 46835, total_loss: 4.015361785888672
training step: 46836, total_loss: 3.0176522731781006
training step: 46837, total_loss: 3.3882246017456055
training step: 46838, total_loss: 5.3900065422058105
training step: 46839, total_loss: 4.245815753936768
training step: 46840, total_loss: 3.640176773071289
training step: 46841, total_loss: 3.725881576538086
training step: 46842, total_loss: 5.6151533126831055
training step: 46843, total_loss: 4.9800615310668945
training step: 46844, total_loss: 4.827134609222412
training step: 46845, total_loss: 4.597588539123535
training step: 46846, total_loss: 3.1291441917419434
training step: 46847, total_loss: 4.442779064178467
training step: 46848, total_loss: 6.8913116455078125
training step: 46849, total_loss: 6.022303581237793
training step: 46850, total_loss: 5.570856094360352
training step: 46851, total_loss: 4.59084415435791
training step: 46852, total_loss: 5.015061378479004
training step: 46853, total_loss: 4.9697041511535645
training step: 46854, total_loss: 4.122466564178467
training step: 46855, total_loss: 3.234745502471924
training step: 46856, total_loss: 3.2105674743652344
training step: 46857, total_loss: 3.215595006942749
training step: 46858, total_loss: 5.3827385902404785
training step: 46859, total_loss: 3.550278425216675
training step: 46860, total_loss: 6.621214866638184
training step: 46861, total_loss: 4.092526435852051
training step: 46862, total_loss: 4.095203399658203
training step: 46863, total_loss: 4.912447929382324
training step: 46864, total_loss: 3.3289496898651123
training step: 46865, total_loss: 5.798057556152344
training step: 46866, total_loss: 3.826953649520874
training step: 46867, total_loss: 0.8050240278244019
training step: 46868, total_loss: 4.36893367767334
training step: 46869, total_loss: 6.39683723449707
training step: 46870, total_loss: 5.3496880531311035
training step: 46871, total_loss: 4.498695373535156
training step: 46872, total_loss: 3.3518919944763184
training step: 46873, total_loss: 3.7585511207580566
training step: 46874, total_loss: 3.166933059692383
training step: 46875, total_loss: 3.986222267150879
training step: 46876, total_loss: 4.332592964172363
training step: 46877, total_loss: 4.812221527099609
training step: 46878, total_loss: 3.899712085723877
training step: 46879, total_loss: 3.8383960723876953
training step: 46880, total_loss: 3.04343318939209
training step: 46881, total_loss: 4.904343128204346
training step: 46882, total_loss: 4.597925662994385
training step: 46883, total_loss: 1.5766143798828125
training step: 46884, total_loss: 4.196310997009277
training step: 46885, total_loss: 3.505049705505371
training step: 46886, total_loss: 4.313162803649902
training step: 46887, total_loss: 5.4621124267578125
training step: 46888, total_loss: 5.587710380554199
training step: 46889, total_loss: 2.1492114067077637
training step: 46890, total_loss: 3.9872915744781494
training step: 46891, total_loss: 4.58233642578125
training step: 46892, total_loss: 4.301329612731934
training step: 46893, total_loss: 0.7917388081550598
training step: 46894, total_loss: 5.110068321228027
training step: 46895, total_loss: 4.299907684326172
training step: 46896, total_loss: 5.014015197753906
training step: 46897, total_loss: 5.910072326660156
training step: 46898, total_loss: 3.767251491546631
training step: 46899, total_loss: 3.7163584232330322
training step: 46900, total_loss: 4.468942642211914
training step: 46901, total_loss: 4.635383605957031
training step: 46902, total_loss: 4.847805976867676
training step: 46903, total_loss: 2.4183740615844727
training step: 46904, total_loss: 5.147458076477051
training step: 46905, total_loss: 3.8852155208587646
training step: 46906, total_loss: 3.4264888763427734
training step: 46907, total_loss: 3.6474103927612305
training step: 46908, total_loss: 5.765407562255859
training step: 46909, total_loss: 5.075192451477051
training step: 46910, total_loss: 6.101005554199219
training step: 46911, total_loss: 2.960097312927246
training step: 46912, total_loss: 3.405223846435547
training step: 46913, total_loss: 5.147055625915527
training step: 46914, total_loss: 2.413435459136963
training step: 46915, total_loss: 4.253809928894043
training step: 46916, total_loss: 6.082507610321045
training step: 46917, total_loss: 3.773974895477295
training step: 46918, total_loss: 5.089037895202637
training step: 46919, total_loss: 4.498321533203125
training step: 46920, total_loss: 5.018819808959961
training step: 46921, total_loss: 6.684361934661865
training step: 46922, total_loss: 3.297590732574463
training step: 46923, total_loss: 4.184969425201416
training step: 46924, total_loss: 5.098386287689209
training step: 46925, total_loss: 4.345132350921631
training step: 46926, total_loss: 4.43410587310791
training step: 46927, total_loss: 4.7938995361328125
training step: 46928, total_loss: 4.992138385772705
training step: 46929, total_loss: 3.170941114425659
training step: 46930, total_loss: 4.235326766967773
training step: 46931, total_loss: 4.807830810546875
training step: 46932, total_loss: 6.953394889831543
training step: 46933, total_loss: 4.456155300140381
training step: 46934, total_loss: 3.308302879333496
training step: 46935, total_loss: 3.559704303741455
training step: 46936, total_loss: 5.125930309295654
training step: 46937, total_loss: 5.538248062133789
training step: 46938, total_loss: 3.9105544090270996
training step: 46939, total_loss: 3.1984965801239014
training step: 46940, total_loss: 3.5883283615112305
training step: 46941, total_loss: 4.285998344421387
training step: 46942, total_loss: 4.589480400085449
training step: 46943, total_loss: 4.615032196044922
training step: 46944, total_loss: 4.163139343261719
training step: 46945, total_loss: 2.768571615219116
training step: 46946, total_loss: 5.0878005027771
training step: 46947, total_loss: 4.984930515289307
training step: 46948, total_loss: 7.754642486572266
training step: 46949, total_loss: 4.431520462036133
training step: 46950, total_loss: 5.199203968048096
training step: 46951, total_loss: 5.447166919708252
training step: 46952, total_loss: 4.7323174476623535
training step: 46953, total_loss: 4.6759033203125
training step: 46954, total_loss: 5.123953819274902
training step: 46955, total_loss: 4.126672267913818
training step: 46956, total_loss: 5.214495658874512
training step: 46957, total_loss: 3.5782816410064697
training step: 46958, total_loss: 2.4187023639678955
training step: 46959, total_loss: 5.1019744873046875
training step: 46960, total_loss: 4.283731460571289
training step: 46961, total_loss: 4.949516773223877
training step: 46962, total_loss: 3.0094988346099854
training step: 46963, total_loss: 3.9903082847595215
training step: 46964, total_loss: 4.745729446411133
training step: 46965, total_loss: 3.679004669189453
training step: 46966, total_loss: 4.7375640869140625
training step: 46967, total_loss: 0.7542605400085449
training step: 46968, total_loss: 5.219108581542969
training step: 46969, total_loss: 1.1469266414642334
training step: 46970, total_loss: 6.188437461853027
training step: 46971, total_loss: 5.41802978515625
training step: 46972, total_loss: 4.326729774475098
training step: 46973, total_loss: 4.997073650360107
training step: 46974, total_loss: 4.119147300720215
training step: 46975, total_loss: 5.088564872741699
training step: 46976, total_loss: 4.297222137451172
training step: 46977, total_loss: 3.769103765487671
training step: 46978, total_loss: 5.418265342712402
training step: 46979, total_loss: 4.709418773651123
training step: 46980, total_loss: 4.297760963439941
training step: 46981, total_loss: 5.324141502380371
training step: 46982, total_loss: 3.3948893547058105
training step: 46983, total_loss: 3.8946356773376465
training step: 46984, total_loss: 7.362393379211426
training step: 46985, total_loss: 4.238028526306152
training step: 46986, total_loss: 4.78887939453125
training step: 46987, total_loss: 4.486879348754883
training step: 46988, total_loss: 3.6791720390319824
training step: 46989, total_loss: 4.198157787322998
training step: 46990, total_loss: 3.947153329849243
training step: 46991, total_loss: 5.3449296951293945
training step: 46992, total_loss: 4.498653411865234
training step: 46993, total_loss: 5.170608043670654
training step: 46994, total_loss: 4.910708904266357
training step: 46995, total_loss: 3.608048439025879
training step: 46996, total_loss: 5.535321235656738
training step: 46997, total_loss: 5.7140960693359375
training step: 46998, total_loss: 0.9204537868499756
training step: 46999, total_loss: 5.009150505065918
training step: 47000, total_loss: 4.090724945068359
training step: 47001, total_loss: 4.820037364959717
training step: 47002, total_loss: 4.303492546081543
training step: 47003, total_loss: 5.267343521118164
training step: 47004, total_loss: 3.5025997161865234
training step: 47005, total_loss: 4.665884971618652
training step: 47006, total_loss: 3.2923338413238525
training step: 47007, total_loss: 5.207064628601074
training step: 47008, total_loss: 3.585966110229492
training step: 47009, total_loss: 4.555380821228027
training step: 47010, total_loss: 4.620535850524902
training step: 47011, total_loss: 4.906210422515869
training step: 47012, total_loss: 4.302877426147461
training step: 47013, total_loss: 4.491368293762207
training step: 47014, total_loss: 4.92880392074585
training step: 47015, total_loss: 6.507742881774902
training step: 47016, total_loss: 4.234915733337402
training step: 47017, total_loss: 5.4762115478515625
training step: 47018, total_loss: 2.225924015045166
training step: 47019, total_loss: 2.5869498252868652
training step: 47020, total_loss: 2.5428452491760254
training step: 47021, total_loss: 4.839578628540039
training step: 47022, total_loss: 6.685739517211914
training step: 47023, total_loss: 5.221203804016113
training step: 47024, total_loss: 4.229770660400391
training step: 47025, total_loss: 2.9746510982513428
training step: 47026, total_loss: 4.884211540222168
training step: 47027, total_loss: 5.056568145751953
training step: 47028, total_loss: 3.9220643043518066
training step: 47029, total_loss: 4.153164386749268
training step: 47030, total_loss: 4.4898176193237305
training step: 47031, total_loss: 5.152367115020752
training step: 47032, total_loss: 4.238476753234863
training step: 47033, total_loss: 3.5532870292663574
training step: 47034, total_loss: 4.6024932861328125
training step: 47035, total_loss: 3.8575847148895264
training step: 47036, total_loss: 3.5817904472351074
training step: 47037, total_loss: 4.6270952224731445
training step: 47038, total_loss: 4.507142066955566
training step: 47039, total_loss: 4.906917572021484
training step: 47040, total_loss: 5.749371528625488
training step: 47041, total_loss: 2.5616326332092285
training step: 47042, total_loss: 5.267401695251465
training step: 47043, total_loss: 0.8791730999946594
training step: 47044, total_loss: 4.0690693855285645
training step: 47045, total_loss: 4.537598133087158
training step: 47046, total_loss: 5.296047210693359
training step: 47047, total_loss: 3.674351453781128
training step: 47048, total_loss: 4.5658369064331055
training step: 47049, total_loss: 5.124138832092285
training step: 47050, total_loss: 3.191108226776123
training step: 47051, total_loss: 6.283919334411621
training step: 47052, total_loss: 3.991313934326172
training step: 47053, total_loss: 5.430683135986328
training step: 47054, total_loss: 7.103595733642578
training step: 47055, total_loss: 5.69497013092041
training step: 47056, total_loss: 5.0145721435546875
training step: 47057, total_loss: 4.655817031860352
training step: 47058, total_loss: 5.979556083679199
training step: 47059, total_loss: 5.9773268699646
training step: 47060, total_loss: 5.814763069152832
training step: 47061, total_loss: 4.891523361206055
training step: 47062, total_loss: 5.109385967254639
training step: 47063, total_loss: 4.50112247467041
training step: 47064, total_loss: 4.549848556518555
training step: 47065, total_loss: 3.897315263748169
training step: 47066, total_loss: 3.4246110916137695
training step: 47067, total_loss: 5.226485252380371
training step: 47068, total_loss: 3.8362207412719727
training step: 47069, total_loss: 3.2112739086151123
training step: 47070, total_loss: 4.752784729003906
training step: 47071, total_loss: 3.726762056350708
training step: 47072, total_loss: 4.173140525817871
training step: 47073, total_loss: 4.440536975860596
training step: 47074, total_loss: 4.739672660827637
training step: 47075, total_loss: 3.3814635276794434
training step: 47076, total_loss: 5.017814636230469
training step: 47077, total_loss: 4.352327346801758
training step: 47078, total_loss: 4.348196983337402
training step: 47079, total_loss: 4.348357200622559
training step: 47080, total_loss: 5.4397101402282715
training step: 47081, total_loss: 4.450079917907715
training step: 47082, total_loss: 5.352882385253906
training step: 47083, total_loss: 3.5021204948425293
training step: 47084, total_loss: 3.754509925842285
training step: 47085, total_loss: 5.500436782836914
training step: 47086, total_loss: 4.5667619705200195
training step: 47087, total_loss: 4.531103610992432
training step: 47088, total_loss: 4.58496618270874
training step: 47089, total_loss: 4.954625606536865
training step: 47090, total_loss: 3.685257911682129
training step: 47091, total_loss: 2.409717082977295
training step: 47092, total_loss: 3.2081918716430664
training step: 47093, total_loss: 4.796855926513672
training step: 47094, total_loss: 4.10592794418335
training step: 47095, total_loss: 5.127301216125488
training step: 47096, total_loss: 4.520934104919434
training step: 47097, total_loss: 4.244097709655762
training step: 47098, total_loss: 1.1687102317810059
training step: 47099, total_loss: 1.7597997188568115
training step: 47100, total_loss: 5.691946506500244
training step: 47101, total_loss: 4.304323673248291
training step: 47102, total_loss: 5.166394233703613
training step: 47103, total_loss: 4.343819618225098
training step: 47104, total_loss: 4.0154852867126465
training step: 47105, total_loss: 5.031517028808594
training step: 47106, total_loss: 4.175540924072266
training step: 47107, total_loss: 3.7627193927764893
training step: 47108, total_loss: 3.7440409660339355
training step: 47109, total_loss: 3.7490344047546387
training step: 47110, total_loss: 6.635178565979004
training step: 47111, total_loss: 4.582232475280762
training step: 47112, total_loss: 4.908454895019531
training step: 47113, total_loss: 4.2159929275512695
training step: 47114, total_loss: 5.258240699768066
training step: 47115, total_loss: 4.652583599090576
training step: 47116, total_loss: 3.6218762397766113
training step: 47117, total_loss: 4.1263604164123535
training step: 47118, total_loss: 4.799248695373535
training step: 47119, total_loss: 3.830763578414917
training step: 47120, total_loss: 3.8930306434631348
training step: 47121, total_loss: 5.591255187988281
training step: 47122, total_loss: 3.9009504318237305
training step: 47123, total_loss: 3.339231014251709
training step: 47124, total_loss: 6.6489410400390625
training step: 47125, total_loss: 4.110963344573975
training step: 47126, total_loss: 4.802749156951904
training step: 47127, total_loss: 4.606768608093262
training step: 47128, total_loss: 4.52651309967041
training step: 47129, total_loss: 5.314684867858887
training step: 47130, total_loss: 3.069538116455078
training step: 47131, total_loss: 4.511498928070068
training step: 47132, total_loss: 4.246803283691406
training step: 47133, total_loss: 5.121274948120117
training step: 47134, total_loss: 4.951240539550781
training step: 47135, total_loss: 3.2201151847839355
training step: 47136, total_loss: 2.7497968673706055
training step: 47137, total_loss: 4.144548416137695
training step: 47138, total_loss: 2.993919610977173
training step: 47139, total_loss: 4.598970890045166
training step: 47140, total_loss: 4.8566484451293945
training step: 47141, total_loss: 2.432187080383301
training step: 47142, total_loss: 4.9609880447387695
training step: 47143, total_loss: 3.7086033821105957
training step: 47144, total_loss: 4.340332984924316
training step: 47145, total_loss: 3.904684066772461
training step: 47146, total_loss: 4.401876449584961
training step: 47147, total_loss: 5.585899829864502
training step: 47148, total_loss: 5.830859661102295
training step: 47149, total_loss: 5.115261554718018
training step: 47150, total_loss: 3.875824213027954
training step: 47151, total_loss: 5.350268363952637
training step: 47152, total_loss: 1.7427314519882202
training step: 47153, total_loss: 4.633813381195068
training step: 47154, total_loss: 3.5175726413726807
training step: 47155, total_loss: 4.059192657470703
training step: 47156, total_loss: 5.610317230224609
training step: 47157, total_loss: 2.8653054237365723
training step: 47158, total_loss: 3.861907958984375
training step: 47159, total_loss: 4.288731575012207
training step: 47160, total_loss: 4.648418426513672
training step: 47161, total_loss: 5.0960001945495605
training step: 47162, total_loss: 4.626178741455078
training step: 47163, total_loss: 4.638851165771484
training step: 47164, total_loss: 4.093560218811035
training step: 47165, total_loss: 4.336342811584473
training step: 47166, total_loss: 5.6996378898620605
training step: 47167, total_loss: 5.239500999450684
training step: 47168, total_loss: 4.805624008178711
training step: 47169, total_loss: 4.244105815887451
training step: 47170, total_loss: 3.783607006072998
training step: 47171, total_loss: 5.3237223625183105
training step: 47172, total_loss: 5.111650466918945
training step: 47173, total_loss: 3.8754754066467285
training step: 47174, total_loss: 0.8392419815063477
training step: 47175, total_loss: 4.022974491119385
training step: 47176, total_loss: 4.037140846252441
training step: 47177, total_loss: 2.9842302799224854
training step: 47178, total_loss: 2.744264841079712
training step: 47179, total_loss: 2.3691165447235107
training step: 47180, total_loss: 4.882354736328125
training step: 47181, total_loss: 3.732541084289551
training step: 47182, total_loss: 5.139095783233643
training step: 47183, total_loss: 4.400294303894043
training step: 47184, total_loss: 4.78898286819458
training step: 47185, total_loss: 4.455129623413086
training step: 47186, total_loss: 5.295712471008301
training step: 47187, total_loss: 4.763669013977051
training step: 47188, total_loss: 4.640977382659912
training step: 47189, total_loss: 2.5139589309692383
training step: 47190, total_loss: 4.672239303588867
training step: 47191, total_loss: 2.2703185081481934
training step: 47192, total_loss: 1.5633021593093872
training step: 47193, total_loss: 5.411443710327148
training step: 47194, total_loss: 4.046661376953125
training step: 47195, total_loss: 2.198016405105591
training step: 47196, total_loss: 5.2005510330200195
training step: 47197, total_loss: 3.795018196105957
training step: 47198, total_loss: 6.014887809753418
training step: 47199, total_loss: 5.089231014251709
training step: 47200, total_loss: 3.8979663848876953
training step: 47201, total_loss: 3.5469565391540527
training step: 47202, total_loss: 6.66635799407959
training step: 47203, total_loss: 2.629854202270508
training step: 47204, total_loss: 6.92934513092041
training step: 47205, total_loss: 4.276965618133545
training step: 47206, total_loss: 4.32266092300415
training step: 47207, total_loss: 6.506550312042236
training step: 47208, total_loss: 5.918867111206055
training step: 47209, total_loss: 5.768706321716309
training step: 47210, total_loss: 1.3219730854034424
training step: 47211, total_loss: 3.4995319843292236
training step: 47212, total_loss: 3.8255696296691895
training step: 47213, total_loss: 4.185029029846191
training step: 47214, total_loss: 5.21268892288208
training step: 47215, total_loss: 3.848947525024414
training step: 47216, total_loss: 5.3091936111450195
training step: 47217, total_loss: 4.333871364593506
training step: 47218, total_loss: 4.639362812042236
training step: 47219, total_loss: 4.074167728424072
training step: 47220, total_loss: 6.0748186111450195
training step: 47221, total_loss: 5.58967399597168
training step: 47222, total_loss: 4.569117546081543
training step: 47223, total_loss: 3.3306822776794434
training step: 47224, total_loss: 5.460458755493164
training step: 47225, total_loss: 3.791226387023926
training step: 47226, total_loss: 4.691629409790039
training step: 47227, total_loss: 5.26447868347168
training step: 47228, total_loss: 3.729602098464966
training step: 47229, total_loss: 5.310680389404297
training step: 47230, total_loss: 5.175690650939941
training step: 47231, total_loss: 4.274977684020996
training step: 47232, total_loss: 5.371333599090576
training step: 47233, total_loss: 3.3790016174316406
training step: 47234, total_loss: 3.6864118576049805
training step: 47235, total_loss: 5.102939128875732
training step: 47236, total_loss: 4.540343284606934
training step: 47237, total_loss: 5.748785972595215
training step: 47238, total_loss: 3.6078128814697266
training step: 47239, total_loss: 4.408677577972412
training step: 47240, total_loss: 4.812278747558594
training step: 47241, total_loss: 4.1539740562438965
training step: 47242, total_loss: 5.5072197914123535
training step: 47243, total_loss: 4.7585039138793945
training step: 47244, total_loss: 4.306476593017578
training step: 47245, total_loss: 3.753901243209839
training step: 47246, total_loss: 4.460752964019775
training step: 47247, total_loss: 3.896451950073242
training step: 47248, total_loss: 4.297277450561523
training step: 47249, total_loss: 4.149360656738281
training step: 47250, total_loss: 6.848907947540283
training step: 47251, total_loss: 5.507055282592773
training step: 47252, total_loss: 4.663222789764404
training step: 47253, total_loss: 1.7689707279205322
training step: 47254, total_loss: 4.445883750915527
training step: 47255, total_loss: 4.9417724609375
training step: 47256, total_loss: 4.073858261108398
training step: 47257, total_loss: 6.207741737365723
training step: 47258, total_loss: 3.7108139991760254
training step: 47259, total_loss: 4.226393222808838
training step: 47260, total_loss: 4.268440246582031
training step: 47261, total_loss: 4.045587539672852
training step: 47262, total_loss: 4.1641035079956055
training step: 47263, total_loss: 4.819731712341309
training step: 47264, total_loss: 5.198217868804932
training step: 47265, total_loss: 3.085111141204834
training step: 47266, total_loss: 3.184643030166626
training step: 47267, total_loss: 4.043411731719971
training step: 47268, total_loss: 5.172301769256592
training step: 47269, total_loss: 4.882530689239502
training step: 47270, total_loss: 5.193818092346191
training step: 47271, total_loss: 5.668552398681641
training step: 47272, total_loss: 5.02907657623291
training step: 47273, total_loss: 3.714694023132324
training step: 47274, total_loss: 5.038771629333496
training step: 47275, total_loss: 4.165243148803711
training step: 47276, total_loss: 3.4049344062805176
training step: 47277, total_loss: 4.995521068572998
training step: 47278, total_loss: 3.282960891723633
training step: 47279, total_loss: 3.559657573699951
training step: 47280, total_loss: 4.387802600860596
training step: 47281, total_loss: 1.2386789321899414
training step: 47282, total_loss: 3.8741135597229004
training step: 47283, total_loss: 4.992332458496094
training step: 47284, total_loss: 4.107451438903809
training step: 47285, total_loss: 1.0572552680969238
training step: 47286, total_loss: 4.3292646408081055
training step: 47287, total_loss: 3.4818902015686035
training step: 47288, total_loss: 3.729637622833252
training step: 47289, total_loss: 3.1706228256225586
training step: 47290, total_loss: 3.1365554332733154
training step: 47291, total_loss: 2.6640472412109375
training step: 47292, total_loss: 4.666290283203125
training step: 47293, total_loss: 5.024783611297607
training step: 47294, total_loss: 3.5467753410339355
training step: 47295, total_loss: 3.457693099975586
training step: 47296, total_loss: 4.9632110595703125
training step: 47297, total_loss: 3.326737642288208
training step: 47298, total_loss: 2.8127338886260986
training step: 47299, total_loss: 5.73479700088501
training step: 47300, total_loss: 5.189057350158691
training step: 47301, total_loss: 3.477651834487915
training step: 47302, total_loss: 4.879973411560059
training step: 47303, total_loss: 2.163729190826416
training step: 47304, total_loss: 4.886107921600342
training step: 47305, total_loss: 4.7924113273620605
training step: 47306, total_loss: 4.39517879486084
training step: 47307, total_loss: 3.4983744621276855
training step: 47308, total_loss: 3.2462968826293945
training step: 47309, total_loss: 3.608903169631958
training step: 47310, total_loss: 6.0566253662109375
training step: 47311, total_loss: 3.8029799461364746
training step: 47312, total_loss: 5.962812423706055
training step: 47313, total_loss: 5.971667289733887
training step: 47314, total_loss: 3.0409741401672363
training step: 47315, total_loss: 3.5516507625579834
training step: 47316, total_loss: 1.2597984075546265
training step: 47317, total_loss: 4.17490816116333
training step: 47318, total_loss: 3.4947080612182617
training step: 47319, total_loss: 4.846473693847656
training step: 47320, total_loss: 2.9841713905334473
training step: 47321, total_loss: 5.148163795471191
training step: 47322, total_loss: 4.990729331970215
training step: 47323, total_loss: 4.8508687019348145
training step: 47324, total_loss: 4.855445861816406
training step: 47325, total_loss: 5.626494407653809
training step: 47326, total_loss: 5.444339275360107
training step: 47327, total_loss: 7.014379501342773
training step: 47328, total_loss: 4.144526958465576
training step: 47329, total_loss: 2.776512622833252
training step: 47330, total_loss: 5.234579086303711
training step: 47331, total_loss: 4.65058708190918
training step: 47332, total_loss: 5.548605442047119
training step: 47333, total_loss: 3.8990836143493652
training step: 47334, total_loss: 2.466787099838257
training step: 47335, total_loss: 6.01561164855957
training step: 47336, total_loss: 4.537316799163818
training step: 47337, total_loss: 3.858668804168701
training step: 47338, total_loss: 2.6227192878723145
training step: 47339, total_loss: 3.2752914428710938
training step: 47340, total_loss: 2.566331386566162
training step: 47341, total_loss: 5.514054298400879
training step: 47342, total_loss: 3.9938201904296875
training step: 47343, total_loss: 5.198361396789551
training step: 47344, total_loss: 4.159868240356445
training step: 47345, total_loss: 4.2324137687683105
training step: 47346, total_loss: 4.523731231689453
training step: 47347, total_loss: 4.585829257965088
training step: 47348, total_loss: 5.29302978515625
training step: 47349, total_loss: 4.032704830169678
training step: 47350, total_loss: 1.0716569423675537
training step: 47351, total_loss: 5.343642234802246
training step: 47352, total_loss: 4.060338973999023
training step: 47353, total_loss: 4.736424446105957
training step: 47354, total_loss: 4.526124954223633
training step: 47355, total_loss: 2.5776689052581787
training step: 47356, total_loss: 4.787617206573486
training step: 47357, total_loss: 4.989760398864746
training step: 47358, total_loss: 4.081430912017822
training step: 47359, total_loss: 4.821100234985352
training step: 47360, total_loss: 3.470454692840576
training step: 47361, total_loss: 4.917088508605957
training step: 47362, total_loss: 3.6955132484436035
training step: 47363, total_loss: 3.2662079334259033
training step: 47364, total_loss: 5.463111877441406
training step: 47365, total_loss: 5.079776763916016
training step: 47366, total_loss: 4.373150825500488
training step: 47367, total_loss: 4.542679786682129
training step: 47368, total_loss: 3.581665515899658
training step: 47369, total_loss: 5.734755992889404
training step: 47370, total_loss: 4.7490057945251465
training step: 47371, total_loss: 6.602141380310059
training step: 47372, total_loss: 4.9500651359558105
training step: 47373, total_loss: 4.19874382019043
training step: 47374, total_loss: 4.315834999084473
training step: 47375, total_loss: 5.571479797363281
training step: 47376, total_loss: 5.223532676696777
training step: 47377, total_loss: 3.7320706844329834
training step: 47378, total_loss: 5.303958415985107
training step: 47379, total_loss: 4.796483516693115
training step: 47380, total_loss: 4.558843612670898
training step: 47381, total_loss: 4.568359851837158
training step: 47382, total_loss: 2.9511704444885254
training step: 47383, total_loss: 3.1853585243225098
training step: 47384, total_loss: 3.1899847984313965
training step: 47385, total_loss: 6.617032051086426
training step: 47386, total_loss: 4.557999134063721
training step: 47387, total_loss: 4.410233020782471
training step: 47388, total_loss: 4.007679462432861
training step: 47389, total_loss: 4.285776615142822
training step: 47390, total_loss: 4.644531726837158
training step: 47391, total_loss: 4.743081569671631
training step: 47392, total_loss: 5.057257652282715
training step: 47393, total_loss: 4.906757831573486
training step: 47394, total_loss: 2.445157051086426
training step: 47395, total_loss: 4.407617092132568
training step: 47396, total_loss: 5.455862045288086
training step: 47397, total_loss: 4.630801677703857
training step: 47398, total_loss: 3.4276013374328613
training step: 47399, total_loss: 0.9263041019439697
training step: 47400, total_loss: 5.3231916427612305
training step: 47401, total_loss: 5.6145219802856445
training step: 47402, total_loss: 3.5828609466552734
training step: 47403, total_loss: 4.442983627319336
training step: 47404, total_loss: 4.200246810913086
training step: 47405, total_loss: 4.047229766845703
training step: 47406, total_loss: 3.0148205757141113
training step: 47407, total_loss: 5.980833530426025
training step: 47408, total_loss: 5.170861721038818
training step: 47409, total_loss: 1.0538147687911987
training step: 47410, total_loss: 4.497518539428711
training step: 47411, total_loss: 2.924086093902588
training step: 47412, total_loss: 3.510484218597412
training step: 47413, total_loss: 4.3347063064575195
training step: 47414, total_loss: 5.06905460357666
training step: 47415, total_loss: 4.695828914642334
training step: 47416, total_loss: 0.97101229429245
training step: 47417, total_loss: 3.521946430206299
training step: 47418, total_loss: 5.611454963684082
training step: 47419, total_loss: 3.601130485534668
training step: 47420, total_loss: 4.3466572761535645
training step: 47421, total_loss: 3.6716678142547607
training step: 47422, total_loss: 3.5463037490844727
training step: 47423, total_loss: 4.1211371421813965
training step: 47424, total_loss: 5.343095302581787
training step: 47425, total_loss: 4.418417453765869
training step: 47426, total_loss: 4.865184307098389
training step: 47427, total_loss: 0.8012129068374634
training step: 47428, total_loss: 4.280193328857422
training step: 47429, total_loss: 6.2189178466796875
training step: 47430, total_loss: 4.157423496246338
training step: 47431, total_loss: 3.860994815826416
training step: 47432, total_loss: 0.7037391662597656
training step: 47433, total_loss: 5.099186897277832
training step: 47434, total_loss: 4.1505866050720215
training step: 47435, total_loss: 4.746149063110352
training step: 47436, total_loss: 2.25227427482605
training step: 47437, total_loss: 5.449377059936523
training step: 47438, total_loss: 4.55868673324585
training step: 47439, total_loss: 3.928758382797241
training step: 47440, total_loss: 4.747776031494141
training step: 47441, total_loss: 3.9576594829559326
training step: 47442, total_loss: 4.824664115905762
training step: 47443, total_loss: 5.3198957443237305
training step: 47444, total_loss: 4.0758514404296875
training step: 47445, total_loss: 4.146485328674316
training step: 47446, total_loss: 3.731799364089966
training step: 47447, total_loss: 3.2502803802490234
training step: 47448, total_loss: 4.196342468261719
training step: 47449, total_loss: 5.688861846923828
training step: 47450, total_loss: 3.3492279052734375
training step: 47451, total_loss: 4.721449851989746
training step: 47452, total_loss: 3.7356467247009277
training step: 47453, total_loss: 3.188321590423584
training step: 47454, total_loss: 4.459382057189941
training step: 47455, total_loss: 4.288307189941406
training step: 47456, total_loss: 4.163266181945801
training step: 47457, total_loss: 4.9501566886901855
training step: 47458, total_loss: 3.845952033996582
training step: 47459, total_loss: 4.317177772521973
training step: 47460, total_loss: 3.1488003730773926
training step: 47461, total_loss: 0.5700846910476685
training step: 47462, total_loss: 4.394659996032715
training step: 47463, total_loss: 3.2139105796813965
training step: 47464, total_loss: 3.292536497116089
training step: 47465, total_loss: 4.640006065368652
training step: 47466, total_loss: 4.602455139160156
training step: 47467, total_loss: 5.299736022949219
training step: 47468, total_loss: 6.03281307220459
training step: 47469, total_loss: 3.5925474166870117
training step: 47470, total_loss: 3.492147207260132
training step: 47471, total_loss: 3.307337999343872
training step: 47472, total_loss: 3.3701376914978027
training step: 47473, total_loss: 3.8786423206329346
training step: 47474, total_loss: 3.9571425914764404
training step: 47475, total_loss: 5.096531867980957
training step: 47476, total_loss: 5.696083068847656
training step: 47477, total_loss: 0.7915242910385132
training step: 47478, total_loss: 4.422085285186768
training step: 47479, total_loss: 5.9699602127075195
training step: 47480, total_loss: 4.633815765380859
training step: 47481, total_loss: 4.452291011810303
training step: 47482, total_loss: 3.4090700149536133
training step: 47483, total_loss: 1.772081971168518
training step: 47484, total_loss: 4.457954406738281
training step: 47485, total_loss: 0.8149358034133911
training step: 47486, total_loss: 2.799527168273926
training step: 47487, total_loss: 5.584227561950684
training step: 47488, total_loss: 3.9203667640686035
training step: 47489, total_loss: 5.091597557067871
training step: 47490, total_loss: 4.674983024597168
training step: 47491, total_loss: 4.261629104614258
training step: 47492, total_loss: 3.7655653953552246
training step: 47493, total_loss: 4.0380754470825195
training step: 47494, total_loss: 2.985886812210083
training step: 47495, total_loss: 2.8788654804229736
training step: 47496, total_loss: 3.239047050476074
training step: 47497, total_loss: 6.169497489929199
training step: 47498, total_loss: 3.0038466453552246
training step: 47499, total_loss: 3.797726631164551
training step: 47500, total_loss: 2.4865925312042236
training step: 47501, total_loss: 4.603560447692871
training step: 47502, total_loss: 3.0577220916748047
training step: 47503, total_loss: 3.93769907951355
training step: 47504, total_loss: 2.0485897064208984
training step: 47505, total_loss: 4.583518028259277
training step: 47506, total_loss: 4.362261772155762
training step: 47507, total_loss: 4.066353797912598
training step: 47508, total_loss: 5.245967864990234
training step: 47509, total_loss: 5.413701057434082
training step: 47510, total_loss: 6.677333831787109
training step: 47511, total_loss: 5.1439666748046875
training step: 47512, total_loss: 5.767220497131348
training step: 47513, total_loss: 3.63613224029541
training step: 47514, total_loss: 4.687053680419922
training step: 47515, total_loss: 3.638324022293091
training step: 47516, total_loss: 5.533003807067871
training step: 47517, total_loss: 3.789323329925537
training step: 47518, total_loss: 3.5078859329223633
training step: 47519, total_loss: 5.604684352874756
training step: 47520, total_loss: 4.803297996520996
training step: 47521, total_loss: 4.123730659484863
training step: 47522, total_loss: 4.2780866622924805
training step: 47523, total_loss: 4.6475348472595215
training step: 47524, total_loss: 4.836451053619385
training step: 47525, total_loss: 4.293675899505615
training step: 47526, total_loss: 5.187260627746582
training step: 47527, total_loss: 3.178377151489258
training step: 47528, total_loss: 6.217749118804932
training step: 47529, total_loss: 4.294681072235107
training step: 47530, total_loss: 4.112758636474609
training step: 47531, total_loss: 3.5394725799560547
training step: 47532, total_loss: 5.412321090698242
training step: 47533, total_loss: 3.837153434753418
training step: 47534, total_loss: 4.190898895263672
training step: 47535, total_loss: 5.209085464477539
training step: 47536, total_loss: 3.6429922580718994
training step: 47537, total_loss: 5.329061985015869
training step: 47538, total_loss: 4.626990795135498
training step: 47539, total_loss: 7.770386219024658
training step: 47540, total_loss: 2.632750988006592
training step: 47541, total_loss: 4.046159267425537
training step: 47542, total_loss: 3.583425521850586
training step: 47543, total_loss: 5.573156356811523
training step: 47544, total_loss: 2.7616353034973145
training step: 47545, total_loss: 3.482023239135742
training step: 47546, total_loss: 4.689969062805176
training step: 47547, total_loss: 5.254169940948486
training step: 47548, total_loss: 6.520183563232422
training step: 47549, total_loss: 4.121280670166016
training step: 47550, total_loss: 4.198450565338135
training step: 47551, total_loss: 3.3859641551971436
training step: 47552, total_loss: 6.859023571014404
training step: 47553, total_loss: 2.5330944061279297
training step: 47554, total_loss: 4.389538764953613
training step: 47555, total_loss: 4.848121643066406
training step: 47556, total_loss: 5.307681560516357
training step: 47557, total_loss: 2.8786253929138184
training step: 47558, total_loss: 3.956717014312744
training step: 47559, total_loss: 3.8984663486480713
training step: 47560, total_loss: 5.340591907501221
training step: 47561, total_loss: 3.179839849472046
training step: 47562, total_loss: 6.6182661056518555
training step: 47563, total_loss: 5.480964660644531
training step: 47564, total_loss: 3.849013328552246
training step: 47565, total_loss: 5.205062389373779
training step: 47566, total_loss: 3.4406702518463135
training step: 47567, total_loss: 5.3629021644592285
training step: 47568, total_loss: 3.6421031951904297
training step: 47569, total_loss: 2.299386501312256
training step: 47570, total_loss: 6.2396674156188965
training step: 47571, total_loss: 4.221007823944092
training step: 47572, total_loss: 4.027833461761475
training step: 47573, total_loss: 2.2112042903900146
training step: 47574, total_loss: 3.7950477600097656
training step: 47575, total_loss: 5.178919792175293
training step: 47576, total_loss: 6.531403541564941
training step: 47577, total_loss: 4.453574180603027
training step: 47578, total_loss: 3.5595147609710693
training step: 47579, total_loss: 4.297942161560059
training step: 47580, total_loss: 4.575885772705078
training step: 47581, total_loss: 3.9934792518615723
training step: 47582, total_loss: 3.076162576675415
training step: 47583, total_loss: 4.425365447998047
training step: 47584, total_loss: 5.378150939941406
training step: 47585, total_loss: 0.7184112668037415
training step: 47586, total_loss: 4.858526706695557
training step: 47587, total_loss: 4.105940818786621
training step: 47588, total_loss: 5.855700969696045
training step: 47589, total_loss: 4.789341926574707
training step: 47590, total_loss: 4.713836669921875
training step: 47591, total_loss: 3.4202663898468018
training step: 47592, total_loss: 3.6738293170928955
training step: 47593, total_loss: 4.78342342376709
training step: 47594, total_loss: 3.5395801067352295
training step: 47595, total_loss: 3.895063877105713
training step: 47596, total_loss: 2.666409492492676
training step: 47597, total_loss: 3.6983041763305664
training step: 47598, total_loss: 3.8374791145324707
training step: 47599, total_loss: 3.498149871826172
training step: 47600, total_loss: 4.467227935791016
training step: 47601, total_loss: 3.4934849739074707
training step: 47602, total_loss: 3.2073984146118164
training step: 47603, total_loss: 2.040670394897461
training step: 47604, total_loss: 3.9268412590026855
training step: 47605, total_loss: 3.2325351238250732
training step: 47606, total_loss: 4.99517822265625
training step: 47607, total_loss: 3.607377052307129
training step: 47608, total_loss: 3.8833603858947754
training step: 47609, total_loss: 6.445352077484131
training step: 47610, total_loss: 4.894471645355225
training step: 47611, total_loss: 4.266862392425537
training step: 47612, total_loss: 3.9674630165100098
training step: 47613, total_loss: 4.133020401000977
training step: 47614, total_loss: 5.1929612159729
training step: 47615, total_loss: 2.807185173034668
training step: 47616, total_loss: 2.5563464164733887
training step: 47617, total_loss: 5.4390411376953125
training step: 47618, total_loss: 4.063342094421387
training step: 47619, total_loss: 4.609489917755127
training step: 47620, total_loss: 3.1519315242767334
training step: 47621, total_loss: 3.8743419647216797
training step: 47622, total_loss: 0.6458618640899658
training step: 47623, total_loss: 5.051538944244385
training step: 47624, total_loss: 5.231090545654297
training step: 47625, total_loss: 5.018826484680176
training step: 47626, total_loss: 4.074583530426025
training step: 47627, total_loss: 2.706145763397217
training step: 47628, total_loss: 2.753636121749878
training step: 47629, total_loss: 4.1518025398254395
training step: 47630, total_loss: 4.12485933303833
training step: 47631, total_loss: 3.662074089050293
training step: 47632, total_loss: 5.16879940032959
training step: 47633, total_loss: 4.380210876464844
training step: 47634, total_loss: 4.938543319702148
training step: 47635, total_loss: 3.9693031311035156
training step: 47636, total_loss: 6.128640174865723
training step: 47637, total_loss: 5.415322303771973
training step: 47638, total_loss: 6.435341835021973
training step: 47639, total_loss: 4.549570083618164
training step: 47640, total_loss: 3.6494786739349365
training step: 47641, total_loss: 4.707223892211914
training step: 47642, total_loss: 3.653193235397339
training step: 47643, total_loss: 4.438835144042969
training step: 47644, total_loss: 6.125973701477051
training step: 47645, total_loss: 4.083490371704102
training step: 47646, total_loss: 4.176563262939453
training step: 47647, total_loss: 4.814946174621582
training step: 47648, total_loss: 2.383413791656494
training step: 47649, total_loss: 5.301474571228027
training step: 47650, total_loss: 5.453998565673828
training step: 47651, total_loss: 3.8447134494781494
training step: 47652, total_loss: 4.1251373291015625
training step: 47653, total_loss: 3.5635359287261963
training step: 47654, total_loss: 4.102863311767578
training step: 47655, total_loss: 4.347570419311523
training step: 47656, total_loss: 2.8705101013183594
training step: 47657, total_loss: 4.541976451873779
training step: 47658, total_loss: 5.182468891143799
training step: 47659, total_loss: 3.1257128715515137
training step: 47660, total_loss: 5.693732738494873
training step: 47661, total_loss: 5.279628753662109
training step: 47662, total_loss: 4.174256324768066
training step: 47663, total_loss: 6.124306678771973
training step: 47664, total_loss: 4.667108535766602
training step: 47665, total_loss: 5.0130510330200195
training step: 47666, total_loss: 4.918580055236816
training step: 47667, total_loss: 2.4933419227600098
training step: 47668, total_loss: 4.415987014770508
training step: 47669, total_loss: 4.6630539894104
training step: 47670, total_loss: 4.741643905639648
training step: 47671, total_loss: 5.344842910766602
training step: 47672, total_loss: 4.115235328674316
training step: 47673, total_loss: 2.9557669162750244
training step: 47674, total_loss: 4.538454055786133
training step: 47675, total_loss: 4.466069221496582
training step: 47676, total_loss: 4.242778301239014
training step: 47677, total_loss: 4.592691898345947
training step: 47678, total_loss: 6.231142520904541
training step: 47679, total_loss: 5.319022178649902
training step: 47680, total_loss: 4.762826919555664
training step: 47681, total_loss: 5.0914716720581055
training step: 47682, total_loss: 5.401202201843262
training step: 47683, total_loss: 4.38359260559082
training step: 47684, total_loss: 3.7724599838256836
training step: 47685, total_loss: 2.364619731903076
training step: 47686, total_loss: 2.9100661277770996
training step: 47687, total_loss: 4.324496746063232
training step: 47688, total_loss: 5.15911865234375
training step: 47689, total_loss: 5.609718322753906
training step: 47690, total_loss: 3.9375741481781006
training step: 47691, total_loss: 4.7757158279418945
training step: 47692, total_loss: 3.6932244300842285
training step: 47693, total_loss: 5.099315166473389
training step: 47694, total_loss: 5.486173629760742
training step: 47695, total_loss: 4.0952863693237305
training step: 47696, total_loss: 5.028385162353516
training step: 47697, total_loss: 4.378408432006836
training step: 47698, total_loss: 4.011257648468018
training step: 47699, total_loss: 1.8435771465301514
training step: 47700, total_loss: 4.267245292663574
training step: 47701, total_loss: 3.477879524230957
training step: 47702, total_loss: 2.004671096801758
training step: 47703, total_loss: 4.916101455688477
training step: 47704, total_loss: 4.80848503112793
training step: 47705, total_loss: 5.079272270202637
training step: 47706, total_loss: 4.497524261474609
training step: 47707, total_loss: 4.470207214355469
training step: 47708, total_loss: 3.993839740753174
training step: 47709, total_loss: 3.6294965744018555
training step: 47710, total_loss: 1.1933743953704834
training step: 47711, total_loss: 4.89901876449585
training step: 47712, total_loss: 4.385612487792969
training step: 47713, total_loss: 4.40200138092041
training step: 47714, total_loss: 5.1022186279296875
training step: 47715, total_loss: 3.3644275665283203
training step: 47716, total_loss: 4.022494316101074
training step: 47717, total_loss: 4.122564792633057
training step: 47718, total_loss: 3.8086957931518555
training step: 47719, total_loss: 4.19411563873291
training step: 47720, total_loss: 4.491348743438721
training step: 47721, total_loss: 4.97641658782959
training step: 47722, total_loss: 3.321139335632324
training step: 47723, total_loss: 3.9287192821502686
training step: 47724, total_loss: 4.1880035400390625
training step: 47725, total_loss: 4.588135242462158
training step: 47726, total_loss: 6.245519638061523
training step: 47727, total_loss: 4.697179794311523
training step: 47728, total_loss: 5.183297157287598
training step: 47729, total_loss: 4.1933674812316895
training step: 47730, total_loss: 3.2842655181884766
training step: 47731, total_loss: 3.659648895263672
training step: 47732, total_loss: 5.314609050750732
training step: 47733, total_loss: 3.987828254699707
training step: 47734, total_loss: 4.9721150398254395
training step: 47735, total_loss: 3.1145715713500977
training step: 47736, total_loss: 4.452895164489746
training step: 47737, total_loss: 5.094914436340332
training step: 47738, total_loss: 5.179780960083008
training step: 47739, total_loss: 4.163677215576172
training step: 47740, total_loss: 3.0407052040100098
training step: 47741, total_loss: 4.529274940490723
training step: 47742, total_loss: 3.117363214492798
training step: 47743, total_loss: 4.417108535766602
training step: 47744, total_loss: 5.157701015472412
training step: 47745, total_loss: 4.524106025695801
training step: 47746, total_loss: 0.8263821601867676
training step: 47747, total_loss: 4.945990085601807
training step: 47748, total_loss: 5.014980316162109
training step: 47749, total_loss: 4.636234760284424
training step: 47750, total_loss: 5.038592338562012
training step: 47751, total_loss: 3.3675670623779297
training step: 47752, total_loss: 3.342899799346924
training step: 47753, total_loss: 4.488173961639404
training step: 47754, total_loss: 4.905944347381592
training step: 47755, total_loss: 4.901843547821045
training step: 47756, total_loss: 4.930817127227783
training step: 47757, total_loss: 5.400359153747559
training step: 47758, total_loss: 1.5759825706481934
training step: 47759, total_loss: 8.043037414550781
training step: 47760, total_loss: 4.7592668533325195
training step: 47761, total_loss: 4.880789279937744
training step: 47762, total_loss: 2.354569673538208
training step: 47763, total_loss: 4.628523826599121
training step: 47764, total_loss: 4.893759727478027
training step: 47765, total_loss: 3.9709720611572266
training step: 47766, total_loss: 4.0743632316589355
training step: 47767, total_loss: 3.4905264377593994
training step: 47768, total_loss: 5.902957916259766
training step: 47769, total_loss: 4.270951747894287
training step: 47770, total_loss: 5.267265319824219
training step: 47771, total_loss: 4.467580795288086
training step: 47772, total_loss: 5.098853588104248
training step: 47773, total_loss: 4.5437703132629395
training step: 47774, total_loss: 6.805281162261963
training step: 47775, total_loss: 1.5919897556304932
training step: 47776, total_loss: 6.107333660125732
training step: 47777, total_loss: 4.132966995239258
training step: 47778, total_loss: 5.606664180755615
training step: 47779, total_loss: 5.389005661010742
training step: 47780, total_loss: 1.0110273361206055
training step: 47781, total_loss: 3.244257926940918
training step: 47782, total_loss: 4.0925984382629395
training step: 47783, total_loss: 3.2507271766662598
training step: 47784, total_loss: 4.676928520202637
training step: 47785, total_loss: 3.842355251312256
training step: 47786, total_loss: 4.88808536529541
training step: 47787, total_loss: 2.527254581451416
training step: 47788, total_loss: 3.7936837673187256
training step: 47789, total_loss: 5.8604254722595215
training step: 47790, total_loss: 4.542360782623291
training step: 47791, total_loss: 4.766110420227051
training step: 47792, total_loss: 5.534885883331299
training step: 47793, total_loss: 3.404137134552002
training step: 47794, total_loss: 4.13287878036499
training step: 47795, total_loss: 4.373409271240234
training step: 47796, total_loss: 2.756136178970337
training step: 47797, total_loss: 4.116440296173096
training step: 47798, total_loss: 6.807438850402832
training step: 47799, total_loss: 4.629802703857422
training step: 47800, total_loss: 5.253193378448486
training step: 47801, total_loss: 2.2662532329559326
training step: 47802, total_loss: 5.086780548095703
training step: 47803, total_loss: 4.252162933349609
training step: 47804, total_loss: 4.640869140625
training step: 47805, total_loss: 3.827589988708496
training step: 47806, total_loss: 4.562587738037109
training step: 47807, total_loss: 3.161581516265869
training step: 47808, total_loss: 4.714444160461426
training step: 47809, total_loss: 4.64215087890625
training step: 47810, total_loss: 5.090368747711182
training step: 47811, total_loss: 3.5458855628967285
training step: 47812, total_loss: 5.352890968322754
training step: 47813, total_loss: 2.8357841968536377
training step: 47814, total_loss: 3.680163860321045
training step: 47815, total_loss: 3.2002034187316895
training step: 47816, total_loss: 6.290741443634033
training step: 47817, total_loss: 5.1822075843811035
training step: 47818, total_loss: 3.751893997192383
training step: 47819, total_loss: 3.9169864654541016
training step: 47820, total_loss: 4.519221305847168
training step: 47821, total_loss: 4.841036796569824
training step: 47822, total_loss: 5.2732086181640625
training step: 47823, total_loss: 4.130963325500488
training step: 47824, total_loss: 4.182135581970215
training step: 47825, total_loss: 5.651281356811523
training step: 47826, total_loss: 4.550205707550049
training step: 47827, total_loss: 4.248443603515625
training step: 47828, total_loss: 2.6297106742858887
training step: 47829, total_loss: 4.203728675842285
training step: 47830, total_loss: 2.590728759765625
training step: 47831, total_loss: 4.9185991287231445
training step: 47832, total_loss: 4.244695663452148
training step: 47833, total_loss: 4.491663455963135
training step: 47834, total_loss: 4.106518745422363
training step: 47835, total_loss: 2.445216655731201
training step: 47836, total_loss: 3.907987117767334
training step: 47837, total_loss: 5.023983001708984
training step: 47838, total_loss: 4.394443511962891
training step: 47839, total_loss: 1.8239896297454834
training step: 47840, total_loss: 2.5654678344726562
training step: 47841, total_loss: 3.0428147315979004
training step: 47842, total_loss: 4.475437641143799
training step: 47843, total_loss: 3.594341278076172
training step: 47844, total_loss: 1.0057493448257446
training step: 47845, total_loss: 5.569886207580566
training step: 47846, total_loss: 3.4467110633850098
training step: 47847, total_loss: 3.7230224609375
training step: 47848, total_loss: 3.604569435119629
training step: 47849, total_loss: 6.092555999755859
training step: 47850, total_loss: 4.221643447875977
training step: 47851, total_loss: 4.174421310424805
training step: 47852, total_loss: 3.605618953704834
training step: 47853, total_loss: 4.579922676086426
training step: 47854, total_loss: 4.727137088775635
training step: 47855, total_loss: 5.549722671508789
training step: 47856, total_loss: 4.872232437133789
training step: 47857, total_loss: 4.073341369628906
training step: 47858, total_loss: 1.7522339820861816
training step: 47859, total_loss: 3.792731285095215
training step: 47860, total_loss: 3.365283966064453
training step: 47861, total_loss: 2.790947914123535
training step: 47862, total_loss: 3.0723443031311035
training step: 47863, total_loss: 4.165750026702881
training step: 47864, total_loss: 4.022730827331543
training step: 47865, total_loss: 3.2159833908081055
training step: 47866, total_loss: 3.791828155517578
training step: 47867, total_loss: 5.213432312011719
training step: 47868, total_loss: 5.369227409362793
training step: 47869, total_loss: 0.7341095209121704
training step: 47870, total_loss: 6.635319232940674
training step: 47871, total_loss: 2.5768966674804688
training step: 47872, total_loss: 4.801136016845703
training step: 47873, total_loss: 3.0998520851135254
training step: 47874, total_loss: 3.8987064361572266
training step: 47875, total_loss: 3.767096519470215
training step: 47876, total_loss: 3.836927652359009
training step: 47877, total_loss: 5.402070999145508
training step: 47878, total_loss: 4.7859086990356445
training step: 47879, total_loss: 5.3931474685668945
training step: 47880, total_loss: 5.866522789001465
training step: 47881, total_loss: 4.5200300216674805
training step: 47882, total_loss: 5.363642692565918
training step: 47883, total_loss: 5.001440048217773
training step: 47884, total_loss: 3.3571648597717285
training step: 47885, total_loss: 2.2272095680236816
training step: 47886, total_loss: 4.3160834312438965
training step: 47887, total_loss: 4.427947998046875
training step: 47888, total_loss: 4.259066581726074
training step: 47889, total_loss: 3.7830443382263184
training step: 47890, total_loss: 2.9118735790252686
training step: 47891, total_loss: 4.6085028648376465
training step: 47892, total_loss: 4.853772163391113
training step: 47893, total_loss: 2.9281725883483887
training step: 47894, total_loss: 4.248167991638184
training step: 47895, total_loss: 6.225934982299805
training step: 47896, total_loss: 2.9640896320343018
training step: 47897, total_loss: 5.458517074584961
training step: 47898, total_loss: 5.405884742736816
training step: 47899, total_loss: 4.292595863342285
training step: 47900, total_loss: 4.350255012512207
training step: 47901, total_loss: 6.212048530578613
training step: 47902, total_loss: 4.401323318481445
training step: 47903, total_loss: 5.1530256271362305
training step: 47904, total_loss: 0.7063897848129272
training step: 47905, total_loss: 4.70091438293457
training step: 47906, total_loss: 2.741706371307373
training step: 47907, total_loss: 3.4957046508789062
training step: 47908, total_loss: 3.55153226852417
training step: 47909, total_loss: 3.2416696548461914
training step: 47910, total_loss: 2.9972071647644043
training step: 47911, total_loss: 3.8629746437072754
training step: 47912, total_loss: 4.800172328948975
training step: 47913, total_loss: 2.8545424938201904
training step: 47914, total_loss: 3.542841911315918
training step: 47915, total_loss: 2.043519973754883
training step: 47916, total_loss: 4.581506729125977
training step: 47917, total_loss: 3.015057325363159
training step: 47918, total_loss: 0.526924729347229
training step: 47919, total_loss: 5.164968967437744
training step: 47920, total_loss: 4.816092014312744
training step: 47921, total_loss: 2.966590404510498
training step: 47922, total_loss: 4.622087001800537
training step: 47923, total_loss: 2.945634365081787
training step: 47924, total_loss: 5.399179458618164
training step: 47925, total_loss: 4.46539306640625
training step: 47926, total_loss: 4.65073299407959
training step: 47927, total_loss: 3.6018869876861572
training step: 47928, total_loss: 4.008611679077148
training step: 47929, total_loss: 4.080358982086182
training step: 47930, total_loss: 1.663872480392456
training step: 47931, total_loss: 4.310833930969238
training step: 47932, total_loss: 5.026483535766602
training step: 47933, total_loss: 4.643928050994873
training step: 47934, total_loss: 2.2457807064056396
training step: 47935, total_loss: 4.861170768737793
training step: 47936, total_loss: 3.529520034790039
training step: 47937, total_loss: 4.78235387802124
training step: 47938, total_loss: 4.779751300811768
training step: 47939, total_loss: 6.883899688720703
training step: 47940, total_loss: 4.847149848937988
training step: 47941, total_loss: 4.351372241973877
training step: 47942, total_loss: 5.251401901245117
training step: 47943, total_loss: 4.738080978393555
training step: 47944, total_loss: 4.930748462677002
training step: 47945, total_loss: 7.158757209777832
training step: 47946, total_loss: 3.7452569007873535
training step: 47947, total_loss: 4.102665901184082
training step: 47948, total_loss: 3.5095467567443848
training step: 47949, total_loss: 4.345855712890625
training step: 47950, total_loss: 5.2165069580078125
training step: 47951, total_loss: 3.894441604614258
training step: 47952, total_loss: 5.018227577209473
training step: 47953, total_loss: 3.104788303375244
training step: 47954, total_loss: 4.533421039581299
training step: 47955, total_loss: 4.206048488616943
training step: 47956, total_loss: 4.318747043609619
training step: 47957, total_loss: 5.361902236938477
training step: 47958, total_loss: 4.096755504608154
training step: 47959, total_loss: 4.263546943664551
training step: 47960, total_loss: 5.405830383300781
training step: 47961, total_loss: 1.6392531394958496
training step: 47962, total_loss: 2.5225560665130615
training step: 47963, total_loss: 2.140190362930298
training step: 47964, total_loss: 3.68941068649292
training step: 47965, total_loss: 5.134075164794922
training step: 47966, total_loss: 4.304189682006836
training step: 47967, total_loss: 5.484806060791016
training step: 47968, total_loss: 3.0738933086395264
training step: 47969, total_loss: 0.5729113817214966
training step: 47970, total_loss: 3.845794200897217
training step: 47971, total_loss: 5.706336975097656
training step: 47972, total_loss: 0.7840725779533386
training step: 47973, total_loss: 6.916116714477539
training step: 47974, total_loss: 4.719674110412598
training step: 47975, total_loss: 6.037115097045898
training step: 47976, total_loss: 2.732732057571411
training step: 47977, total_loss: 4.474496841430664
training step: 47978, total_loss: 6.5468363761901855
training step: 47979, total_loss: 3.65055513381958
training step: 47980, total_loss: 3.364673614501953
training step: 47981, total_loss: 4.950344085693359
training step: 47982, total_loss: 5.243689060211182
training step: 47983, total_loss: 6.3538055419921875
training step: 47984, total_loss: 4.277146816253662
training step: 47985, total_loss: 5.984853744506836
training step: 47986, total_loss: 4.371441841125488
training step: 47987, total_loss: 5.327872276306152
training step: 47988, total_loss: 5.792001724243164
training step: 47989, total_loss: 4.593084812164307
training step: 47990, total_loss: 3.3658225536346436
training step: 47991, total_loss: 1.9085893630981445
training step: 47992, total_loss: 4.924356460571289
training step: 47993, total_loss: 5.550590515136719
training step: 47994, total_loss: 4.183526039123535
training step: 47995, total_loss: 3.011478900909424
training step: 47996, total_loss: 2.925994396209717
training step: 47997, total_loss: 6.691458702087402
training step: 47998, total_loss: 4.172372341156006
training step: 47999, total_loss: 6.536897659301758
training step: 48000, total_loss: 2.232837200164795
training step: 48001, total_loss: 5.9514899253845215
training step: 48002, total_loss: 5.42509126663208
training step: 48003, total_loss: 4.259940147399902
training step: 48004, total_loss: 1.5356640815734863
training step: 48005, total_loss: 2.344053268432617
training step: 48006, total_loss: 3.8655505180358887
training step: 48007, total_loss: 5.7437944412231445
training step: 48008, total_loss: 4.144855499267578
training step: 48009, total_loss: 3.3701181411743164
training step: 48010, total_loss: 4.759158134460449
training step: 48011, total_loss: 0.8655470609664917
training step: 48012, total_loss: 3.0991759300231934
training step: 48013, total_loss: 4.613916397094727
training step: 48014, total_loss: 4.003779411315918
training step: 48015, total_loss: 4.440984725952148
training step: 48016, total_loss: 4.541571140289307
training step: 48017, total_loss: 5.120887279510498
training step: 48018, total_loss: 4.2452311515808105
training step: 48019, total_loss: 2.254115104675293
training step: 48020, total_loss: 4.439052581787109
training step: 48021, total_loss: 1.1004576683044434
training step: 48022, total_loss: 4.013980865478516
training step: 48023, total_loss: 4.591325283050537
training step: 48024, total_loss: 3.7943384647369385
training step: 48025, total_loss: 4.364812850952148
training step: 48026, total_loss: 4.002240180969238
training step: 48027, total_loss: 4.449711799621582
training step: 48028, total_loss: 4.426674842834473
training step: 48029, total_loss: 4.031487941741943
training step: 48030, total_loss: 4.401647090911865
training step: 48031, total_loss: 2.0167829990386963
training step: 48032, total_loss: 4.9969072341918945
training step: 48033, total_loss: 4.780554294586182
training step: 48034, total_loss: 3.4010610580444336
training step: 48035, total_loss: 3.2355504035949707
training step: 48036, total_loss: 4.609227180480957
training step: 48037, total_loss: 4.501990795135498
training step: 48038, total_loss: 4.796901702880859
training step: 48039, total_loss: 4.571008682250977
training step: 48040, total_loss: 5.217837333679199
training step: 48041, total_loss: 3.595560073852539
training step: 48042, total_loss: 3.7442352771759033
training step: 48043, total_loss: 2.3814682960510254
training step: 48044, total_loss: 4.774433135986328
training step: 48045, total_loss: 4.984090328216553
training step: 48046, total_loss: 5.018970012664795
training step: 48047, total_loss: 5.452938079833984
training step: 48048, total_loss: 5.162510395050049
training step: 48049, total_loss: 5.444995880126953
training step: 48050, total_loss: 4.071109294891357
training step: 48051, total_loss: 4.759871959686279
training step: 48052, total_loss: 3.824892997741699
training step: 48053, total_loss: 4.051313400268555
training step: 48054, total_loss: 3.7275967597961426
training step: 48055, total_loss: 3.2199597358703613
training step: 48056, total_loss: 4.727095603942871
training step: 48057, total_loss: 4.9554314613342285
training step: 48058, total_loss: 4.336923599243164
training step: 48059, total_loss: 4.905426025390625
training step: 48060, total_loss: 3.4091291427612305
training step: 48061, total_loss: 6.238707542419434
training step: 48062, total_loss: 4.954906940460205
training step: 48063, total_loss: 5.703108310699463
training step: 48064, total_loss: 2.548454761505127
training step: 48065, total_loss: 6.169877529144287
training step: 48066, total_loss: 2.9834556579589844
training step: 48067, total_loss: 3.202153205871582
training step: 48068, total_loss: 4.180893898010254
training step: 48069, total_loss: 5.151241302490234
training step: 48070, total_loss: 2.5848677158355713
training step: 48071, total_loss: 4.2778215408325195
training step: 48072, total_loss: 2.8950023651123047
training step: 48073, total_loss: 4.1159539222717285
training step: 48074, total_loss: 4.54072904586792
training step: 48075, total_loss: 3.2304656505584717
training step: 48076, total_loss: 3.6698241233825684
training step: 48077, total_loss: 4.736981391906738
training step: 48078, total_loss: 3.7264342308044434
training step: 48079, total_loss: 5.7920684814453125
training step: 48080, total_loss: 4.378746509552002
training step: 48081, total_loss: 4.684021949768066
training step: 48082, total_loss: 4.362289905548096
training step: 48083, total_loss: 2.4904980659484863
training step: 48084, total_loss: 2.6358046531677246
training step: 48085, total_loss: 3.1873817443847656
training step: 48086, total_loss: 3.573622226715088
training step: 48087, total_loss: 5.430887222290039
training step: 48088, total_loss: 4.208622455596924
training step: 48089, total_loss: 4.819653511047363
training step: 48090, total_loss: 5.076339244842529
training step: 48091, total_loss: 5.195718288421631
training step: 48092, total_loss: 3.7042572498321533
training step: 48093, total_loss: 5.430154800415039
training step: 48094, total_loss: 2.7688169479370117
training step: 48095, total_loss: 5.108786582946777
training step: 48096, total_loss: 6.141385555267334
training step: 48097, total_loss: 5.47856330871582
training step: 48098, total_loss: 4.600464344024658
training step: 48099, total_loss: 5.00091552734375
training step: 48100, total_loss: 6.069147109985352
training step: 48101, total_loss: 4.3988752365112305
training step: 48102, total_loss: 6.17305326461792
training step: 48103, total_loss: 5.880791664123535
training step: 48104, total_loss: 5.166069030761719
training step: 48105, total_loss: 2.1441287994384766
training step: 48106, total_loss: 3.8590307235717773
training step: 48107, total_loss: 4.041905403137207
training step: 48108, total_loss: 4.813478946685791
training step: 48109, total_loss: 5.177594184875488
training step: 48110, total_loss: 4.645899772644043
training step: 48111, total_loss: 0.9816834926605225
training step: 48112, total_loss: 3.807870864868164
training step: 48113, total_loss: 4.562509536743164
training step: 48114, total_loss: 5.33492374420166
training step: 48115, total_loss: 4.724289894104004
training step: 48116, total_loss: 3.2568366527557373
training step: 48117, total_loss: 3.792226552963257
training step: 48118, total_loss: 0.748731255531311
training step: 48119, total_loss: 4.501665115356445
training step: 48120, total_loss: 5.036771774291992
training step: 48121, total_loss: 4.531791687011719
training step: 48122, total_loss: 5.561760902404785
training step: 48123, total_loss: 5.768052101135254
training step: 48124, total_loss: 5.279358863830566
training step: 48125, total_loss: 3.8761301040649414
training step: 48126, total_loss: 3.8838534355163574
training step: 48127, total_loss: 4.59442138671875
training step: 48128, total_loss: 4.6153717041015625
training step: 48129, total_loss: 3.074061155319214
training step: 48130, total_loss: 0.8205936551094055
training step: 48131, total_loss: 2.5492169857025146
training step: 48132, total_loss: 4.8979949951171875
training step: 48133, total_loss: 3.920659303665161
training step: 48134, total_loss: 6.386702537536621
training step: 48135, total_loss: 5.0495710372924805
training step: 48136, total_loss: 4.137068271636963
training step: 48137, total_loss: 5.990152359008789
training step: 48138, total_loss: 4.646466255187988
training step: 48139, total_loss: 4.5437726974487305
training step: 48140, total_loss: 3.8055613040924072
training step: 48141, total_loss: 5.51646614074707
training step: 48142, total_loss: 5.938755512237549
training step: 48143, total_loss: 4.951262474060059
training step: 48144, total_loss: 5.08183479309082
training step: 48145, total_loss: 3.597461462020874
training step: 48146, total_loss: 3.7985684871673584
training step: 48147, total_loss: 4.404131889343262
training step: 48148, total_loss: 6.050046443939209
training step: 48149, total_loss: 3.896440029144287
training step: 48150, total_loss: 6.521330833435059
training step: 48151, total_loss: 7.066659927368164
training step: 48152, total_loss: 4.804914951324463
training step: 48153, total_loss: 3.905527114868164
training step: 48154, total_loss: 4.918909549713135
training step: 48155, total_loss: 4.470421314239502
training step: 48156, total_loss: 4.2703166007995605
training step: 48157, total_loss: 4.1701531410217285
training step: 48158, total_loss: 3.239503860473633
training step: 48159, total_loss: 5.843059539794922
training step: 48160, total_loss: 4.226691722869873
training step: 48161, total_loss: 2.5563254356384277
training step: 48162, total_loss: 4.277554512023926
training step: 48163, total_loss: 4.614866256713867
training step: 48164, total_loss: 5.874323844909668
training step: 48165, total_loss: 2.3746209144592285
training step: 48166, total_loss: 4.184607028961182
training step: 48167, total_loss: 1.920414924621582
training step: 48168, total_loss: 5.324220657348633
training step: 48169, total_loss: 3.855783462524414
training step: 48170, total_loss: 3.390883684158325
training step: 48171, total_loss: 3.449896812438965
training step: 48172, total_loss: 4.722250938415527
training step: 48173, total_loss: 3.8297061920166016
training step: 48174, total_loss: 0.6506412625312805
training step: 48175, total_loss: 0.7864375710487366
training step: 48176, total_loss: 4.8856587409973145
training step: 48177, total_loss: 2.041187047958374
training step: 48178, total_loss: 3.709150791168213
training step: 48179, total_loss: 2.281642436981201
training step: 48180, total_loss: 2.5643558502197266
training step: 48181, total_loss: 4.5178914070129395
training step: 48182, total_loss: 5.062399864196777
training step: 48183, total_loss: 0.7038710117340088
training step: 48184, total_loss: 4.750679969787598
training step: 48185, total_loss: 5.586146354675293
training step: 48186, total_loss: 0.6349135637283325
training step: 48187, total_loss: 5.52850341796875
training step: 48188, total_loss: 3.591935873031616
training step: 48189, total_loss: 5.234747886657715
training step: 48190, total_loss: 4.284285068511963
training step: 48191, total_loss: 5.284478664398193
training step: 48192, total_loss: 3.285048246383667
training step: 48193, total_loss: 4.600428581237793
training step: 48194, total_loss: 4.230058670043945
training step: 48195, total_loss: 4.377410888671875
training step: 48196, total_loss: 3.685621738433838
training step: 48197, total_loss: 0.5554696917533875
training step: 48198, total_loss: 2.7082154750823975
training step: 48199, total_loss: 2.0747616291046143
training step: 48200, total_loss: 4.6235151290893555
training step: 48201, total_loss: 3.8795852661132812
training step: 48202, total_loss: 4.234452247619629
training step: 48203, total_loss: 4.441069602966309
training step: 48204, total_loss: 4.78840970993042
training step: 48205, total_loss: 4.1767449378967285
training step: 48206, total_loss: 3.735671281814575
training step: 48207, total_loss: 4.479920387268066
training step: 48208, total_loss: 6.025569915771484
training step: 48209, total_loss: 4.011679649353027
training step: 48210, total_loss: 4.221779823303223
training step: 48211, total_loss: 6.5105438232421875
training step: 48212, total_loss: 6.064109802246094
training step: 48213, total_loss: 5.423391342163086
training step: 48214, total_loss: 4.934213161468506
training step: 48215, total_loss: 3.4950554370880127
training step: 48216, total_loss: 5.076812744140625
training step: 48217, total_loss: 3.6721091270446777
training step: 48218, total_loss: 4.546616554260254
training step: 48219, total_loss: 4.257765769958496
training step: 48220, total_loss: 5.45747709274292
training step: 48221, total_loss: 4.971570014953613
training step: 48222, total_loss: 5.423206806182861
training step: 48223, total_loss: 2.640277624130249
training step: 48224, total_loss: 4.353442192077637
training step: 48225, total_loss: 5.484611511230469
training step: 48226, total_loss: 6.076773643493652
training step: 48227, total_loss: 3.2551989555358887
training step: 48228, total_loss: 4.625940322875977
training step: 48229, total_loss: 6.740115642547607
training step: 48230, total_loss: 4.559418678283691
training step: 48231, total_loss: 4.840878486633301
training step: 48232, total_loss: 4.811480522155762
training step: 48233, total_loss: 5.480338096618652
training step: 48234, total_loss: 3.3278727531433105
training step: 48235, total_loss: 5.182122707366943
training step: 48236, total_loss: 6.236926078796387
training step: 48237, total_loss: 2.893805503845215
training step: 48238, total_loss: 3.8219475746154785
training step: 48239, total_loss: 5.809464454650879
training step: 48240, total_loss: 5.354930877685547
training step: 48241, total_loss: 5.493026256561279
training step: 48242, total_loss: 4.7785186767578125
training step: 48243, total_loss: 2.479447603225708
training step: 48244, total_loss: 2.865847110748291
training step: 48245, total_loss: 5.412342548370361
training step: 48246, total_loss: 4.069317817687988
training step: 48247, total_loss: 3.7284257411956787
training step: 48248, total_loss: 6.635693550109863
training step: 48249, total_loss: 5.931301116943359
training step: 48250, total_loss: 3.75911808013916
training step: 48251, total_loss: 4.265745162963867
training step: 48252, total_loss: 5.068089008331299
training step: 48253, total_loss: 4.608288764953613
training step: 48254, total_loss: 4.339208602905273
training step: 48255, total_loss: 4.0691237449646
training step: 48256, total_loss: 4.107391357421875
training step: 48257, total_loss: 2.985990524291992
training step: 48258, total_loss: 4.229981899261475
training step: 48259, total_loss: 3.0511395931243896
training step: 48260, total_loss: 3.9264631271362305
training step: 48261, total_loss: 0.6799826622009277
training step: 48262, total_loss: 5.521495342254639
training step: 48263, total_loss: 5.524580955505371
training step: 48264, total_loss: 3.7751708030700684
training step: 48265, total_loss: 5.587489128112793
training step: 48266, total_loss: 2.7036361694335938
training step: 48267, total_loss: 3.986053943634033
training step: 48268, total_loss: 4.687994956970215
training step: 48269, total_loss: 4.473825931549072
training step: 48270, total_loss: 3.944897413253784
training step: 48271, total_loss: 3.9278323650360107
training step: 48272, total_loss: 6.081972599029541
training step: 48273, total_loss: 2.518033266067505
training step: 48274, total_loss: 3.232034683227539
training step: 48275, total_loss: 4.706225395202637
training step: 48276, total_loss: 3.957892894744873
training step: 48277, total_loss: 3.7672269344329834
training step: 48278, total_loss: 0.6709774732589722
training step: 48279, total_loss: 5.804797172546387
training step: 48280, total_loss: 4.289559841156006
training step: 48281, total_loss: 5.067575454711914
training step: 48282, total_loss: 6.8695268630981445
training step: 48283, total_loss: 0.557208776473999
training step: 48284, total_loss: 3.546457290649414
training step: 48285, total_loss: 7.138820648193359
training step: 48286, total_loss: 5.734469890594482
training step: 48287, total_loss: 4.783929824829102
training step: 48288, total_loss: 3.4929356575012207
training step: 48289, total_loss: 4.015588760375977
training step: 48290, total_loss: 3.4463019371032715
training step: 48291, total_loss: 3.1245837211608887
training step: 48292, total_loss: 2.4581565856933594
training step: 48293, total_loss: 4.690455436706543
training step: 48294, total_loss: 4.477315902709961
training step: 48295, total_loss: 4.706544399261475
training step: 48296, total_loss: 3.8058433532714844
training step: 48297, total_loss: 4.604985237121582
training step: 48298, total_loss: 0.6815385818481445
training step: 48299, total_loss: 3.9543616771698
training step: 48300, total_loss: 5.065263748168945
training step: 48301, total_loss: 5.343584060668945
training step: 48302, total_loss: 5.371764183044434
training step: 48303, total_loss: 4.716876983642578
training step: 48304, total_loss: 4.273349761962891
training step: 48305, total_loss: 4.31227970123291
training step: 48306, total_loss: 6.4777960777282715
training step: 48307, total_loss: 5.595822811126709
training step: 48308, total_loss: 4.518860340118408
training step: 48309, total_loss: 0.5637146234512329
training step: 48310, total_loss: 4.1865434646606445
training step: 48311, total_loss: 2.200014591217041
training step: 48312, total_loss: 7.449177265167236
training step: 48313, total_loss: 4.363680839538574
training step: 48314, total_loss: 3.980422019958496
training step: 48315, total_loss: 6.710492134094238
training step: 48316, total_loss: 3.2447643280029297
training step: 48317, total_loss: 3.5986571311950684
training step: 48318, total_loss: 5.438101768493652
training step: 48319, total_loss: 4.439464569091797
training step: 48320, total_loss: 3.304194450378418
training step: 48321, total_loss: 3.41706919670105
training step: 48322, total_loss: 4.808509826660156
training step: 48323, total_loss: 2.616002321243286
training step: 48324, total_loss: 2.8096530437469482
training step: 48325, total_loss: 4.247927665710449
training step: 48326, total_loss: 3.758645534515381
training step: 48327, total_loss: 5.824615478515625
training step: 48328, total_loss: 3.553065299987793
training step: 48329, total_loss: 4.976320743560791
training step: 48330, total_loss: 5.138089179992676
training step: 48331, total_loss: 3.876002788543701
training step: 48332, total_loss: 4.584348201751709
training step: 48333, total_loss: 4.394136428833008
training step: 48334, total_loss: 5.062350273132324
training step: 48335, total_loss: 5.268488883972168
training step: 48336, total_loss: 3.9192862510681152
training step: 48337, total_loss: 4.5748796463012695
training step: 48338, total_loss: 6.262641429901123
training step: 48339, total_loss: 4.77016544342041
training step: 48340, total_loss: 3.7746329307556152
training step: 48341, total_loss: 4.64432954788208
training step: 48342, total_loss: 2.30194091796875
training step: 48343, total_loss: 3.13895845413208
training step: 48344, total_loss: 3.239793300628662
training step: 48345, total_loss: 4.852388381958008
training step: 48346, total_loss: 4.648627281188965
training step: 48347, total_loss: 4.263187408447266
training step: 48348, total_loss: 5.533281326293945
training step: 48349, total_loss: 3.9711384773254395
training step: 48350, total_loss: 4.1220502853393555
training step: 48351, total_loss: 2.8423619270324707
training step: 48352, total_loss: 3.8934624195098877
training step: 48353, total_loss: 4.089000225067139
training step: 48354, total_loss: 4.950757026672363
training step: 48355, total_loss: 4.4177470207214355
training step: 48356, total_loss: 2.6189932823181152
training step: 48357, total_loss: 3.600949764251709
training step: 48358, total_loss: 4.358641624450684
training step: 48359, total_loss: 1.3493247032165527
training step: 48360, total_loss: 5.143423080444336
training step: 48361, total_loss: 4.3127264976501465
training step: 48362, total_loss: 5.353365898132324
training step: 48363, total_loss: 3.863081693649292
training step: 48364, total_loss: 4.6607561111450195
training step: 48365, total_loss: 3.7249679565429688
training step: 48366, total_loss: 2.256138563156128
training step: 48367, total_loss: 2.0551228523254395
training step: 48368, total_loss: 4.807750225067139
training step: 48369, total_loss: 5.492652416229248
training step: 48370, total_loss: 5.49017333984375
training step: 48371, total_loss: 4.790816307067871
training step: 48372, total_loss: 4.493181228637695
training step: 48373, total_loss: 4.546329498291016
training step: 48374, total_loss: 5.177374362945557
training step: 48375, total_loss: 3.3573241233825684
training step: 48376, total_loss: 4.633317947387695
training step: 48377, total_loss: 6.637068271636963
training step: 48378, total_loss: 5.244863510131836
training step: 48379, total_loss: 3.697948455810547
training step: 48380, total_loss: 4.151479721069336
training step: 48381, total_loss: 3.5318593978881836
training step: 48382, total_loss: 4.371793270111084
training step: 48383, total_loss: 5.057840347290039
training step: 48384, total_loss: 4.973153591156006
training step: 48385, total_loss: 5.672845840454102
training step: 48386, total_loss: 4.351531028747559
training step: 48387, total_loss: 5.358495235443115
training step: 48388, total_loss: 4.068723678588867
training step: 48389, total_loss: 4.332221031188965
training step: 48390, total_loss: 5.529348373413086
training step: 48391, total_loss: 2.8796815872192383
training step: 48392, total_loss: 3.648751735687256
training step: 48393, total_loss: 3.6276888847351074
training step: 48394, total_loss: 5.071558952331543
training step: 48395, total_loss: 2.8284056186676025
training step: 48396, total_loss: 6.223328590393066
training step: 48397, total_loss: 3.1946334838867188
training step: 48398, total_loss: 4.324254512786865
training step: 48399, total_loss: 5.448039531707764
training step: 48400, total_loss: 3.6120502948760986
training step: 48401, total_loss: 3.9723942279815674
training step: 48402, total_loss: 3.1927695274353027
training step: 48403, total_loss: 5.08297061920166
training step: 48404, total_loss: 5.876768112182617
training step: 48405, total_loss: 4.317084789276123
training step: 48406, total_loss: 3.1044251918792725
training step: 48407, total_loss: 4.7914347648620605
training step: 48408, total_loss: 5.683227062225342
training step: 48409, total_loss: 5.59752082824707
training step: 48410, total_loss: 4.460770606994629
training step: 48411, total_loss: 4.338649749755859
training step: 48412, total_loss: 4.555207252502441
training step: 48413, total_loss: 3.1034305095672607
training step: 48414, total_loss: 3.646529197692871
training step: 48415, total_loss: 5.330410480499268
training step: 48416, total_loss: 2.877790689468384
training step: 48417, total_loss: 4.319533348083496
training step: 48418, total_loss: 5.205681800842285
training step: 48419, total_loss: 3.4564380645751953
training step: 48420, total_loss: 5.955896377563477
training step: 48421, total_loss: 5.973758697509766
training step: 48422, total_loss: 3.854032516479492
training step: 48423, total_loss: 5.036879539489746
training step: 48424, total_loss: 5.033494472503662
training step: 48425, total_loss: 3.376375198364258
training step: 48426, total_loss: 5.324577331542969
training step: 48427, total_loss: 4.149375915527344
training step: 48428, total_loss: 5.858508110046387
training step: 48429, total_loss: 5.3147101402282715
training step: 48430, total_loss: 4.096187591552734
training step: 48431, total_loss: 2.807192325592041
training step: 48432, total_loss: 3.5956263542175293
training step: 48433, total_loss: 2.911569595336914
training step: 48434, total_loss: 5.148176193237305
training step: 48435, total_loss: 3.4185996055603027
training step: 48436, total_loss: 3.245988368988037
training step: 48437, total_loss: 5.501291275024414
training step: 48438, total_loss: 6.1263837814331055
training step: 48439, total_loss: 3.92533540725708
training step: 48440, total_loss: 5.044360637664795
training step: 48441, total_loss: 3.462592363357544
training step: 48442, total_loss: 3.4668240547180176
training step: 48443, total_loss: 2.064879894256592
training step: 48444, total_loss: 3.802018642425537
training step: 48445, total_loss: 4.891304969787598
training step: 48446, total_loss: 0.7155846953392029
training step: 48447, total_loss: 4.900045871734619
training step: 48448, total_loss: 4.672359466552734
training step: 48449, total_loss: 4.457021713256836
training step: 48450, total_loss: 4.909294128417969
training step: 48451, total_loss: 6.954611778259277
training step: 48452, total_loss: 4.969978332519531
training step: 48453, total_loss: 2.7802624702453613
training step: 48454, total_loss: 3.435934066772461
training step: 48455, total_loss: 1.1540874242782593
training step: 48456, total_loss: 4.924332618713379
training step: 48457, total_loss: 3.755253791809082
training step: 48458, total_loss: 6.0287957191467285
training step: 48459, total_loss: 5.494203090667725
training step: 48460, total_loss: 5.308124542236328
training step: 48461, total_loss: 4.644942760467529
training step: 48462, total_loss: 4.105615615844727
training step: 48463, total_loss: 0.8214763402938843
training step: 48464, total_loss: 4.485955715179443
training step: 48465, total_loss: 5.100226879119873
training step: 48466, total_loss: 4.627734184265137
training step: 48467, total_loss: 4.984471321105957
training step: 48468, total_loss: 5.537303447723389
training step: 48469, total_loss: 5.1346435546875
training step: 48470, total_loss: 4.770263671875
training step: 48471, total_loss: 2.8770132064819336
training step: 48472, total_loss: 5.407860279083252
training step: 48473, total_loss: 4.7973103523254395
training step: 48474, total_loss: 3.6918935775756836
training step: 48475, total_loss: 3.6387746334075928
training step: 48476, total_loss: 3.0346975326538086
training step: 48477, total_loss: 2.6610183715820312
training step: 48478, total_loss: 3.222710609436035
training step: 48479, total_loss: 5.476646900177002
training step: 48480, total_loss: 5.879997730255127
training step: 48481, total_loss: 3.5660486221313477
training step: 48482, total_loss: 2.9590394496917725
training step: 48483, total_loss: 7.075357437133789
training step: 48484, total_loss: 4.1638875007629395
training step: 48485, total_loss: 4.152048110961914
training step: 48486, total_loss: 3.6116394996643066
training step: 48487, total_loss: 4.581119060516357
training step: 48488, total_loss: 5.787136554718018
training step: 48489, total_loss: 4.483545303344727
training step: 48490, total_loss: 5.419172286987305
training step: 48491, total_loss: 2.830784320831299
training step: 48492, total_loss: 5.473369121551514
training step: 48493, total_loss: 4.812199592590332
training step: 48494, total_loss: 3.6882145404815674
training step: 48495, total_loss: 5.037590980529785
training step: 48496, total_loss: 4.0593366622924805
training step: 48497, total_loss: 3.7417001724243164
training step: 48498, total_loss: 4.7848310470581055
training step: 48499, total_loss: 4.450742721557617
training step: 48500, total_loss: 5.2036895751953125
training step: 48501, total_loss: 5.203448295593262
training step: 48502, total_loss: 4.5064921379089355
training step: 48503, total_loss: 4.660187721252441
training step: 48504, total_loss: 4.546319961547852
training step: 48505, total_loss: 4.456333637237549
training step: 48506, total_loss: 4.139890670776367
training step: 48507, total_loss: 2.1964926719665527
training step: 48508, total_loss: 4.952833652496338
training step: 48509, total_loss: 0.8572590351104736
training step: 48510, total_loss: 4.768110275268555
training step: 48511, total_loss: 4.475641250610352
training step: 48512, total_loss: 3.7398440837860107
training step: 48513, total_loss: 3.8643784523010254
training step: 48514, total_loss: 3.7077553272247314
training step: 48515, total_loss: 4.8585615158081055
training step: 48516, total_loss: 5.623808860778809
training step: 48517, total_loss: 2.3038582801818848
training step: 48518, total_loss: 4.224581241607666
training step: 48519, total_loss: 4.411348819732666
training step: 48520, total_loss: 2.996054172515869
training step: 48521, total_loss: 4.4172139167785645
training step: 48522, total_loss: 6.830239772796631
training step: 48523, total_loss: 4.203082084655762
training step: 48524, total_loss: 3.9455599784851074
training step: 48525, total_loss: 5.511773586273193
training step: 48526, total_loss: 6.429572105407715
training step: 48527, total_loss: 3.1519343852996826
training step: 48528, total_loss: 5.498701095581055
training step: 48529, total_loss: 3.240177631378174
training step: 48530, total_loss: 2.5816147327423096
training step: 48531, total_loss: 4.222649574279785
training step: 48532, total_loss: 5.3250932693481445
training step: 48533, total_loss: 4.058851718902588
training step: 48534, total_loss: 3.1225528717041016
training step: 48535, total_loss: 4.554873466491699
training step: 48536, total_loss: 5.546504974365234
training step: 48537, total_loss: 4.825180530548096
training step: 48538, total_loss: 4.231928825378418
training step: 48539, total_loss: 5.062824726104736
training step: 48540, total_loss: 4.653434753417969
training step: 48541, total_loss: 3.8957271575927734
training step: 48542, total_loss: 3.6806564331054688
training step: 48543, total_loss: 3.876893997192383
training step: 48544, total_loss: 4.510311126708984
training step: 48545, total_loss: 5.800311088562012
training step: 48546, total_loss: 4.488882541656494
training step: 48547, total_loss: 3.6133804321289062
training step: 48548, total_loss: 3.6573026180267334
training step: 48549, total_loss: 5.084661483764648
training step: 48550, total_loss: 4.544308185577393
training step: 48551, total_loss: 4.618927478790283
training step: 48552, total_loss: 4.921124458312988
training step: 48553, total_loss: 3.4674859046936035
training step: 48554, total_loss: 5.169397354125977
training step: 48555, total_loss: 4.16883659362793
training step: 48556, total_loss: 4.211329460144043
training step: 48557, total_loss: 4.200194835662842
training step: 48558, total_loss: 4.454381942749023
training step: 48559, total_loss: 5.033057689666748
training step: 48560, total_loss: 4.579793453216553
training step: 48561, total_loss: 4.75666618347168
training step: 48562, total_loss: 5.23563289642334
training step: 48563, total_loss: 1.4959468841552734
training step: 48564, total_loss: 6.053522109985352
training step: 48565, total_loss: 4.04923152923584
training step: 48566, total_loss: 5.384737968444824
training step: 48567, total_loss: 1.7958295345306396
training step: 48568, total_loss: 4.510051727294922
training step: 48569, total_loss: 4.711655616760254
training step: 48570, total_loss: 4.085600852966309
training step: 48571, total_loss: 4.595778465270996
training step: 48572, total_loss: 3.380679130554199
training step: 48573, total_loss: 4.700634002685547
training step: 48574, total_loss: 3.2045938968658447
training step: 48575, total_loss: 5.285599708557129
training step: 48576, total_loss: 5.699707984924316
training step: 48577, total_loss: 4.681707382202148
training step: 48578, total_loss: 4.922562599182129
training step: 48579, total_loss: 4.726618766784668
training step: 48580, total_loss: 4.2983903884887695
training step: 48581, total_loss: 2.6642932891845703
training step: 48582, total_loss: 4.259867191314697
training step: 48583, total_loss: 3.7765493392944336
training step: 48584, total_loss: 5.118533611297607
training step: 48585, total_loss: 4.976587295532227
training step: 48586, total_loss: 5.593377113342285
training step: 48587, total_loss: 4.228689193725586
training step: 48588, total_loss: 4.041161060333252
training step: 48589, total_loss: 3.534372329711914
training step: 48590, total_loss: 5.200387001037598
training step: 48591, total_loss: 4.384342193603516
training step: 48592, total_loss: 4.290868759155273
training step: 48593, total_loss: 3.8997247219085693
training step: 48594, total_loss: 4.5706024169921875
training step: 48595, total_loss: 3.967757225036621
training step: 48596, total_loss: 0.933868944644928
training step: 48597, total_loss: 4.079033851623535
training step: 48598, total_loss: 4.698983192443848
training step: 48599, total_loss: 4.253820419311523
training step: 48600, total_loss: 4.620593070983887
training step: 48601, total_loss: 3.7456815242767334
training step: 48602, total_loss: 5.112212181091309
training step: 48603, total_loss: 4.209310531616211
training step: 48604, total_loss: 5.198338508605957
training step: 48605, total_loss: 3.722083330154419
training step: 48606, total_loss: 4.734828472137451
training step: 48607, total_loss: 4.279808044433594
training step: 48608, total_loss: 3.9669127464294434
training step: 48609, total_loss: 3.2901062965393066
training step: 48610, total_loss: 3.8358802795410156
training step: 48611, total_loss: 4.890811920166016
training step: 48612, total_loss: 3.3819785118103027
training step: 48613, total_loss: 4.088434219360352
training step: 48614, total_loss: 3.988358974456787
training step: 48615, total_loss: 3.9823365211486816
training step: 48616, total_loss: 3.260261058807373
training step: 48617, total_loss: 4.346778869628906
training step: 48618, total_loss: 5.387833595275879
training step: 48619, total_loss: 3.9560208320617676
training step: 48620, total_loss: 5.752599239349365
training step: 48621, total_loss: 4.250463485717773
training step: 48622, total_loss: 3.7382850646972656
training step: 48623, total_loss: 2.3413543701171875
training step: 48624, total_loss: 3.2486157417297363
training step: 48625, total_loss: 5.704065322875977
training step: 48626, total_loss: 4.653035640716553
training step: 48627, total_loss: 2.5563793182373047
training step: 48628, total_loss: 3.808598518371582
training step: 48629, total_loss: 4.381410598754883
training step: 48630, total_loss: 4.522902965545654
training step: 48631, total_loss: 4.740103721618652
training step: 48632, total_loss: 3.991626739501953
training step: 48633, total_loss: 4.556304931640625
training step: 48634, total_loss: 4.791065216064453
training step: 48635, total_loss: 3.2716481685638428
training step: 48636, total_loss: 6.259411334991455
training step: 48637, total_loss: 3.862523078918457
training step: 48638, total_loss: 5.6349029541015625
training step: 48639, total_loss: 4.887584209442139
training step: 48640, total_loss: 4.758833885192871
training step: 48641, total_loss: 3.9930434226989746
training step: 48642, total_loss: 3.7855823040008545
training step: 48643, total_loss: 3.2387006282806396
training step: 48644, total_loss: 3.9056835174560547
training step: 48645, total_loss: 3.9578728675842285
training step: 48646, total_loss: 5.006769180297852
training step: 48647, total_loss: 4.380454063415527
training step: 48648, total_loss: 2.1699485778808594
training step: 48649, total_loss: 3.4628548622131348
training step: 48650, total_loss: 4.514434337615967
training step: 48651, total_loss: 3.294607639312744
training step: 48652, total_loss: 4.316880226135254
training step: 48653, total_loss: 3.62223482131958
training step: 48654, total_loss: 4.262664794921875
training step: 48655, total_loss: 5.136480808258057
training step: 48656, total_loss: 4.959231376647949
training step: 48657, total_loss: 4.47098970413208
training step: 48658, total_loss: 3.3704066276550293
training step: 48659, total_loss: 3.999203681945801
training step: 48660, total_loss: 4.783359527587891
training step: 48661, total_loss: 4.504594802856445
training step: 48662, total_loss: 4.565515518188477
training step: 48663, total_loss: 3.743062973022461
training step: 48664, total_loss: 4.651677131652832
training step: 48665, total_loss: 3.197730779647827
training step: 48666, total_loss: 2.8480308055877686
training step: 48667, total_loss: 4.105037689208984
training step: 48668, total_loss: 6.245882034301758
training step: 48669, total_loss: 5.375999450683594
training step: 48670, total_loss: 3.7238333225250244
training step: 48671, total_loss: 4.317244529724121
training step: 48672, total_loss: 3.1094212532043457
training step: 48673, total_loss: 4.7137651443481445
training step: 48674, total_loss: 4.872195243835449
training step: 48675, total_loss: 5.6584858894348145
training step: 48676, total_loss: 4.502415180206299
training step: 48677, total_loss: 4.785863876342773
training step: 48678, total_loss: 4.463351726531982
training step: 48679, total_loss: 5.092054843902588
training step: 48680, total_loss: 1.333191156387329
training step: 48681, total_loss: 4.30366325378418
training step: 48682, total_loss: 4.117821216583252
training step: 48683, total_loss: 4.582310676574707
training step: 48684, total_loss: 5.166248798370361
training step: 48685, total_loss: 4.364733695983887
training step: 48686, total_loss: 3.8684072494506836
training step: 48687, total_loss: 3.378190517425537
training step: 48688, total_loss: 3.273453712463379
training step: 48689, total_loss: 3.2396483421325684
training step: 48690, total_loss: 3.872222900390625
training step: 48691, total_loss: 2.405988931655884
training step: 48692, total_loss: 2.6979942321777344
training step: 48693, total_loss: 5.730294227600098
training step: 48694, total_loss: 2.456759214401245
training step: 48695, total_loss: 3.731053590774536
training step: 48696, total_loss: 3.593568801879883
training step: 48697, total_loss: 2.7733001708984375
training step: 48698, total_loss: 4.37421178817749
training step: 48699, total_loss: 3.558339834213257
training step: 48700, total_loss: 5.371564865112305
training step: 48701, total_loss: 4.01566219329834
training step: 48702, total_loss: 0.8258985280990601
training step: 48703, total_loss: 6.670876502990723
training step: 48704, total_loss: 5.5148234367370605
training step: 48705, total_loss: 4.928022384643555
training step: 48706, total_loss: 4.399084091186523
training step: 48707, total_loss: 5.011178016662598
training step: 48708, total_loss: 4.012567043304443
training step: 48709, total_loss: 5.78291130065918
training step: 48710, total_loss: 5.2044548988342285
training step: 48711, total_loss: 4.413971900939941
training step: 48712, total_loss: 2.875278949737549
training step: 48713, total_loss: 2.980742931365967
training step: 48714, total_loss: 4.402062892913818
training step: 48715, total_loss: 3.47209095954895
training step: 48716, total_loss: 3.9114575386047363
training step: 48717, total_loss: 2.668431282043457
training step: 48718, total_loss: 3.932713031768799
training step: 48719, total_loss: 4.759409427642822
training step: 48720, total_loss: 4.8332672119140625
training step: 48721, total_loss: 5.027821063995361
training step: 48722, total_loss: 4.589434623718262
training step: 48723, total_loss: 4.770923614501953
training step: 48724, total_loss: 4.278264999389648
training step: 48725, total_loss: 1.5234873294830322
training step: 48726, total_loss: 5.2984161376953125
training step: 48727, total_loss: 4.233077049255371
training step: 48728, total_loss: 5.279776096343994
training step: 48729, total_loss: 3.7429702281951904
training step: 48730, total_loss: 3.94856595993042
training step: 48731, total_loss: 3.325127124786377
training step: 48732, total_loss: 3.883620262145996
training step: 48733, total_loss: 4.016902446746826
training step: 48734, total_loss: 5.8095855712890625
training step: 48735, total_loss: 4.624165058135986
training step: 48736, total_loss: 4.64726448059082
training step: 48737, total_loss: 4.343257904052734
training step: 48738, total_loss: 4.115238189697266
training step: 48739, total_loss: 3.86993408203125
training step: 48740, total_loss: 3.7682104110717773
training step: 48741, total_loss: 6.460141658782959
training step: 48742, total_loss: 4.224380970001221
training step: 48743, total_loss: 4.943606376647949
training step: 48744, total_loss: 4.899957180023193
training step: 48745, total_loss: 5.840205669403076
training step: 48746, total_loss: 6.27225923538208
training step: 48747, total_loss: 4.856228828430176
training step: 48748, total_loss: 4.588101863861084
training step: 48749, total_loss: 6.3262786865234375
training step: 48750, total_loss: 3.2687134742736816
training step: 48751, total_loss: 4.544905185699463
training step: 48752, total_loss: 4.66524600982666
training step: 48753, total_loss: 4.184961318969727
training step: 48754, total_loss: 3.7686896324157715
training step: 48755, total_loss: 2.385420799255371
training step: 48756, total_loss: 4.907049655914307
training step: 48757, total_loss: 3.9173245429992676
training step: 48758, total_loss: 4.503087043762207
training step: 48759, total_loss: 7.95884370803833
training step: 48760, total_loss: 2.9647560119628906
training step: 48761, total_loss: 4.947695255279541
training step: 48762, total_loss: 4.578563690185547
training step: 48763, total_loss: 4.1343302726745605
training step: 48764, total_loss: 3.9607322216033936
training step: 48765, total_loss: 3.4786667823791504
training step: 48766, total_loss: 5.533432960510254
training step: 48767, total_loss: 3.8812689781188965
training step: 48768, total_loss: 2.7146716117858887
training step: 48769, total_loss: 5.696176528930664
training step: 48770, total_loss: 4.968605995178223
training step: 48771, total_loss: 3.9518446922302246
training step: 48772, total_loss: 3.0352721214294434
training step: 48773, total_loss: 3.228865146636963
training step: 48774, total_loss: 3.4897968769073486
training step: 48775, total_loss: 3.786447048187256
training step: 48776, total_loss: 5.098283767700195
training step: 48777, total_loss: 3.7105090618133545
training step: 48778, total_loss: 3.7450506687164307
training step: 48779, total_loss: 4.6017913818359375
training step: 48780, total_loss: 3.935673713684082
training step: 48781, total_loss: 3.7809338569641113
training step: 48782, total_loss: 1.9968410730361938
training step: 48783, total_loss: 5.348633289337158
training step: 48784, total_loss: 3.3385467529296875
training step: 48785, total_loss: 5.033049583435059
training step: 48786, total_loss: 4.434317588806152
training step: 48787, total_loss: 3.3387653827667236
training step: 48788, total_loss: 5.222081184387207
training step: 48789, total_loss: 4.220930576324463
training step: 48790, total_loss: 4.858077526092529
training step: 48791, total_loss: 2.935347557067871
training step: 48792, total_loss: 3.971043825149536
training step: 48793, total_loss: 4.227609634399414
training step: 48794, total_loss: 3.3723487854003906
training step: 48795, total_loss: 6.169683456420898
training step: 48796, total_loss: 3.3448452949523926
training step: 48797, total_loss: 3.279775619506836
training step: 48798, total_loss: 3.8460452556610107
training step: 48799, total_loss: 3.4645371437072754
training step: 48800, total_loss: 3.4499504566192627
training step: 48801, total_loss: 4.500826835632324
training step: 48802, total_loss: 4.4644904136657715
training step: 48803, total_loss: 6.784252166748047
training step: 48804, total_loss: 5.05444860458374
training step: 48805, total_loss: 4.751863479614258
training step: 48806, total_loss: 5.664511680603027
training step: 48807, total_loss: 1.2916717529296875
training step: 48808, total_loss: 5.4456868171691895
training step: 48809, total_loss: 4.886103630065918
training step: 48810, total_loss: 3.3034708499908447
training step: 48811, total_loss: 4.155601501464844
training step: 48812, total_loss: 4.4448652267456055
training step: 48813, total_loss: 3.226245641708374
training step: 48814, total_loss: 3.4950551986694336
training step: 48815, total_loss: 4.478302955627441
training step: 48816, total_loss: 3.542663335800171
training step: 48817, total_loss: 5.127577781677246
training step: 48818, total_loss: 1.048102617263794
training step: 48819, total_loss: 4.422233581542969
training step: 48820, total_loss: 5.48075008392334
training step: 48821, total_loss: 4.595327854156494
training step: 48822, total_loss: 2.089486837387085
training step: 48823, total_loss: 4.523280143737793
training step: 48824, total_loss: 4.801591396331787
training step: 48825, total_loss: 6.139564514160156
training step: 48826, total_loss: 5.590431213378906
training step: 48827, total_loss: 4.0588531494140625
training step: 48828, total_loss: 6.41263484954834
training step: 48829, total_loss: 5.023457050323486
training step: 48830, total_loss: 4.428593158721924
training step: 48831, total_loss: 2.690908908843994
training step: 48832, total_loss: 4.942869186401367
training step: 48833, total_loss: 1.2075879573822021
training step: 48834, total_loss: 3.8202896118164062
training step: 48835, total_loss: 5.402387619018555
training step: 48836, total_loss: 6.041346549987793
training step: 48837, total_loss: 4.115625381469727
training step: 48838, total_loss: 5.032870769500732
training step: 48839, total_loss: 5.343984603881836
training step: 48840, total_loss: 4.2370924949646
training step: 48841, total_loss: 4.623189926147461
training step: 48842, total_loss: 3.2125749588012695
training step: 48843, total_loss: 3.8656210899353027
training step: 48844, total_loss: 1.940866470336914
training step: 48845, total_loss: 4.382316589355469
training step: 48846, total_loss: 3.7058067321777344
training step: 48847, total_loss: 5.217498779296875
training step: 48848, total_loss: 4.563580513000488
training step: 48849, total_loss: 4.820947647094727
training step: 48850, total_loss: 4.407764434814453
training step: 48851, total_loss: 4.114687919616699
training step: 48852, total_loss: 4.595369338989258
training step: 48853, total_loss: 4.675647258758545
training step: 48854, total_loss: 4.570830345153809
training step: 48855, total_loss: 3.1961750984191895
training step: 48856, total_loss: 5.92625617980957
training step: 48857, total_loss: 4.063498020172119
training step: 48858, total_loss: 4.351539611816406
training step: 48859, total_loss: 2.6775035858154297
training step: 48860, total_loss: 3.914771795272827
training step: 48861, total_loss: 3.879258632659912
training step: 48862, total_loss: 4.545228004455566
training step: 48863, total_loss: 4.398778915405273
training step: 48864, total_loss: 4.851843357086182
training step: 48865, total_loss: 3.79958176612854
training step: 48866, total_loss: 4.090450763702393
training step: 48867, total_loss: 2.1693243980407715
training step: 48868, total_loss: 3.3100028038024902
training step: 48869, total_loss: 4.57874870300293
training step: 48870, total_loss: 4.8431196212768555
training step: 48871, total_loss: 2.851484537124634
training step: 48872, total_loss: 4.251026630401611
training step: 48873, total_loss: 4.46769380569458
training step: 48874, total_loss: 3.729677677154541
training step: 48875, total_loss: 3.829859495162964
training step: 48876, total_loss: 4.350350379943848
training step: 48877, total_loss: 5.425650596618652
training step: 48878, total_loss: 5.145559310913086
training step: 48879, total_loss: 5.116087913513184
training step: 48880, total_loss: 4.332620143890381
training step: 48881, total_loss: 0.8655732870101929
training step: 48882, total_loss: 4.348562240600586
training step: 48883, total_loss: 4.251543045043945
training step: 48884, total_loss: 4.725762367248535
training step: 48885, total_loss: 4.591282844543457
training step: 48886, total_loss: 2.4142093658447266
training step: 48887, total_loss: 5.263316631317139
training step: 48888, total_loss: 2.160372257232666
training step: 48889, total_loss: 4.385785102844238
training step: 48890, total_loss: 3.8231828212738037
training step: 48891, total_loss: 5.450849533081055
training step: 48892, total_loss: 3.170032024383545
training step: 48893, total_loss: 4.960150718688965
training step: 48894, total_loss: 3.51179838180542
training step: 48895, total_loss: 3.2907791137695312
training step: 48896, total_loss: 3.3048558235168457
training step: 48897, total_loss: 4.9086689949035645
training step: 48898, total_loss: 5.152937412261963
training step: 48899, total_loss: 4.874967575073242
training step: 48900, total_loss: 5.692568302154541
training step: 48901, total_loss: 4.811617374420166
training step: 48902, total_loss: 4.282862663269043
training step: 48903, total_loss: 4.72511100769043
training step: 48904, total_loss: 4.981112480163574
training step: 48905, total_loss: 3.1565890312194824
training step: 48906, total_loss: 5.026808738708496
training step: 48907, total_loss: 5.021944046020508
training step: 48908, total_loss: 5.221069812774658
training step: 48909, total_loss: 3.208767890930176
training step: 48910, total_loss: 5.957374572753906
training step: 48911, total_loss: 5.0705671310424805
training step: 48912, total_loss: 4.649260997772217
training step: 48913, total_loss: 4.7306599617004395
training step: 48914, total_loss: 3.723771095275879
training step: 48915, total_loss: 4.422158241271973
training step: 48916, total_loss: 5.115480422973633
training step: 48917, total_loss: 3.907130479812622
training step: 48918, total_loss: 3.561478614807129
training step: 48919, total_loss: 3.191936492919922
training step: 48920, total_loss: 5.291783332824707
training step: 48921, total_loss: 5.282008171081543
training step: 48922, total_loss: 5.269627571105957
training step: 48923, total_loss: 3.774423599243164
training step: 48924, total_loss: 6.201789855957031
training step: 48925, total_loss: 3.3537023067474365
training step: 48926, total_loss: 5.7849249839782715
training step: 48927, total_loss: 7.737084865570068
training step: 48928, total_loss: 4.560801029205322
training step: 48929, total_loss: 4.619451999664307
training step: 48930, total_loss: 5.477677345275879
training step: 48931, total_loss: 3.4140987396240234
training step: 48932, total_loss: 4.715263366699219
training step: 48933, total_loss: 5.601224899291992
training step: 48934, total_loss: 4.313857555389404
training step: 48935, total_loss: 4.844529151916504
training step: 48936, total_loss: 5.982280254364014
training step: 48937, total_loss: 5.7803955078125
training step: 48938, total_loss: 6.424178123474121
training step: 48939, total_loss: 3.8333230018615723
training step: 48940, total_loss: 3.3625216484069824
training step: 48941, total_loss: 1.1375226974487305
training step: 48942, total_loss: 3.9912703037261963
training step: 48943, total_loss: 3.7242157459259033
training step: 48944, total_loss: 4.429699420928955
training step: 48945, total_loss: 4.151731491088867
training step: 48946, total_loss: 4.41103458404541
training step: 48947, total_loss: 4.480527877807617
training step: 48948, total_loss: 4.905916690826416
training step: 48949, total_loss: 3.554799795150757
training step: 48950, total_loss: 6.704991340637207
training step: 48951, total_loss: 3.5863184928894043
training step: 48952, total_loss: 2.933298110961914
training step: 48953, total_loss: 1.167872667312622
training step: 48954, total_loss: 5.033778190612793
training step: 48955, total_loss: 4.2698140144348145
training step: 48956, total_loss: 3.4185729026794434
training step: 48957, total_loss: 4.13411283493042
training step: 48958, total_loss: 4.26434850692749
training step: 48959, total_loss: 4.765864372253418
training step: 48960, total_loss: 4.7588958740234375
training step: 48961, total_loss: 3.9770169258117676
training step: 48962, total_loss: 4.479541778564453
training step: 48963, total_loss: 4.318334579467773
training step: 48964, total_loss: 5.014108657836914
training step: 48965, total_loss: 3.196748733520508
training step: 48966, total_loss: 4.162121772766113
training step: 48967, total_loss: 6.465588569641113
training step: 48968, total_loss: 2.995897054672241
training step: 48969, total_loss: 3.6335697174072266
training step: 48970, total_loss: 5.14571475982666
training step: 48971, total_loss: 2.5937557220458984
training step: 48972, total_loss: 4.308459281921387
training step: 48973, total_loss: 3.8319950103759766
training step: 48974, total_loss: 3.805731773376465
training step: 48975, total_loss: 3.3163886070251465
training step: 48976, total_loss: 4.12729549407959
training step: 48977, total_loss: 3.868499517440796
training step: 48978, total_loss: 4.786660194396973
training step: 48979, total_loss: 3.4863429069519043
training step: 48980, total_loss: 3.3314361572265625
training step: 48981, total_loss: 3.1350369453430176
training step: 48982, total_loss: 5.9571990966796875
training step: 48983, total_loss: 3.9967596530914307
training step: 48984, total_loss: 2.466750144958496
training step: 48985, total_loss: 4.725795269012451
training step: 48986, total_loss: 3.7246546745300293
training step: 48987, total_loss: 4.759900093078613
training step: 48988, total_loss: 4.776183128356934
training step: 48989, total_loss: 3.1081862449645996
training step: 48990, total_loss: 4.916239261627197
training step: 48991, total_loss: 4.186656951904297
training step: 48992, total_loss: 5.285937786102295
training step: 48993, total_loss: 3.752579689025879
training step: 48994, total_loss: 4.138119697570801
training step: 48995, total_loss: 4.50527286529541
training step: 48996, total_loss: 3.776252269744873
training step: 48997, total_loss: 3.6729912757873535
training step: 48998, total_loss: 4.951362609863281
training step: 48999, total_loss: 2.921578884124756
training step: 49000, total_loss: 3.331019401550293
training step: 49001, total_loss: 3.1738393306732178
training step: 49002, total_loss: 5.896137237548828
training step: 49003, total_loss: 5.002796173095703
training step: 49004, total_loss: 3.955075263977051
training step: 49005, total_loss: 4.330380439758301
training step: 49006, total_loss: 5.405980110168457
training step: 49007, total_loss: 4.142030715942383
training step: 49008, total_loss: 4.400749206542969
training step: 49009, total_loss: 3.7738053798675537
training step: 49010, total_loss: 3.05257248878479
training step: 49011, total_loss: 8.09164047241211
training step: 49012, total_loss: 5.231663703918457
training step: 49013, total_loss: 3.614824056625366
training step: 49014, total_loss: 4.009228229522705
training step: 49015, total_loss: 4.531488418579102
training step: 49016, total_loss: 5.195570945739746
training step: 49017, total_loss: 5.781551361083984
training step: 49018, total_loss: 3.9996914863586426
training step: 49019, total_loss: 4.899501800537109
training step: 49020, total_loss: 5.764278411865234
training step: 49021, total_loss: 5.289524078369141
training step: 49022, total_loss: 5.16331148147583
training step: 49023, total_loss: 3.6857032775878906
training step: 49024, total_loss: 3.950118064880371
training step: 49025, total_loss: 4.228015899658203
training step: 49026, total_loss: 4.33057165145874
training step: 49027, total_loss: 4.782801628112793
training step: 49028, total_loss: 5.6993842124938965
training step: 49029, total_loss: 5.326735973358154
training step: 49030, total_loss: 2.2655422687530518
training step: 49031, total_loss: 4.0230255126953125
training step: 49032, total_loss: 3.4898853302001953
training step: 49033, total_loss: 2.965233325958252
training step: 49034, total_loss: 4.583915710449219
training step: 49035, total_loss: 4.789247035980225
training step: 49036, total_loss: 3.6235239505767822
training step: 49037, total_loss: 3.941514492034912
training step: 49038, total_loss: 3.876573085784912
training step: 49039, total_loss: 4.916339874267578
training step: 49040, total_loss: 5.231195449829102
training step: 49041, total_loss: 5.9117841720581055
training step: 49042, total_loss: 3.1185526847839355
training step: 49043, total_loss: 4.786189556121826
training step: 49044, total_loss: 3.7075929641723633
training step: 49045, total_loss: 5.480493545532227
training step: 49046, total_loss: 4.062186241149902
training step: 49047, total_loss: 4.707271575927734
training step: 49048, total_loss: 2.9459996223449707
training step: 49049, total_loss: 4.987156391143799
training step: 49050, total_loss: 6.106784820556641
training step: 49051, total_loss: 5.535342216491699
training step: 49052, total_loss: 2.804349899291992
training step: 49053, total_loss: 4.583536148071289
training step: 49054, total_loss: 4.608193397521973
training step: 49055, total_loss: 3.9242630004882812
training step: 49056, total_loss: 4.635303497314453
training step: 49057, total_loss: 5.175389289855957
training step: 49058, total_loss: 3.330822467803955
training step: 49059, total_loss: 4.5386457443237305
training step: 49060, total_loss: 4.474434852600098
training step: 49061, total_loss: 5.090964317321777
training step: 49062, total_loss: 2.5884358882904053
training step: 49063, total_loss: 4.466287136077881
training step: 49064, total_loss: 4.003756999969482
training step: 49065, total_loss: 4.217483997344971
training step: 49066, total_loss: 3.8596644401550293
training step: 49067, total_loss: 5.59843111038208
training step: 49068, total_loss: 6.150607585906982
training step: 49069, total_loss: 4.790431022644043
training step: 49070, total_loss: 3.649728775024414
training step: 49071, total_loss: 3.9516260623931885
training step: 49072, total_loss: 4.637878894805908
training step: 49073, total_loss: 5.196593761444092
training step: 49074, total_loss: 2.6184024810791016
training step: 49075, total_loss: 5.29201602935791
training step: 49076, total_loss: 4.295123100280762
training step: 49077, total_loss: 3.7471671104431152
training step: 49078, total_loss: 5.243589401245117
training step: 49079, total_loss: 4.318495750427246
training step: 49080, total_loss: 3.780816078186035
training step: 49081, total_loss: 3.688692808151245
training step: 49082, total_loss: 6.11771297454834
training step: 49083, total_loss: 4.721513748168945
training step: 49084, total_loss: 5.657370567321777
training step: 49085, total_loss: 4.588150978088379
training step: 49086, total_loss: 3.5735154151916504
training step: 49087, total_loss: 4.465476036071777
training step: 49088, total_loss: 3.906306743621826
training step: 49089, total_loss: 3.972628355026245
training step: 49090, total_loss: 4.489463806152344
training step: 49091, total_loss: 4.850128173828125
training step: 49092, total_loss: 5.496285915374756
training step: 49093, total_loss: 3.867725133895874
training step: 49094, total_loss: 2.6616780757904053
training step: 49095, total_loss: 3.7063803672790527
training step: 49096, total_loss: 4.46078634262085
training step: 49097, total_loss: 5.269224166870117
training step: 49098, total_loss: 4.8728227615356445
training step: 49099, total_loss: 4.34702205657959
training step: 49100, total_loss: 5.429756164550781
training step: 49101, total_loss: 6.003253936767578
training step: 49102, total_loss: 5.293727874755859
training step: 49103, total_loss: 4.70168399810791
training step: 49104, total_loss: 4.454892635345459
training step: 49105, total_loss: 4.44809627532959
training step: 49106, total_loss: 2.5781474113464355
training step: 49107, total_loss: 4.4679412841796875
training step: 49108, total_loss: 6.204083442687988
training step: 49109, total_loss: 5.330639362335205
training step: 49110, total_loss: 4.550638198852539
training step: 49111, total_loss: 5.208907127380371
training step: 49112, total_loss: 4.026821613311768
training step: 49113, total_loss: 4.323225975036621
training step: 49114, total_loss: 4.481088638305664
training step: 49115, total_loss: 5.596188545227051
training step: 49116, total_loss: 4.571795463562012
training step: 49117, total_loss: 3.5774478912353516
training step: 49118, total_loss: 2.492906093597412
training step: 49119, total_loss: 5.219074249267578
training step: 49120, total_loss: 5.025402069091797
training step: 49121, total_loss: 4.56446647644043
training step: 49122, total_loss: 4.122006416320801
training step: 49123, total_loss: 4.655791282653809
training step: 49124, total_loss: 4.615708351135254
training step: 49125, total_loss: 3.639000654220581
training step: 49126, total_loss: 4.58559513092041
training step: 49127, total_loss: 4.539603233337402
training step: 49128, total_loss: 5.87275505065918
training step: 49129, total_loss: 4.769182205200195
training step: 49130, total_loss: 5.04108190536499
training step: 49131, total_loss: 0.8857565522193909
training step: 49132, total_loss: 4.865022659301758
training step: 49133, total_loss: 3.8155293464660645
training step: 49134, total_loss: 4.2621049880981445
training step: 49135, total_loss: 3.591071128845215
training step: 49136, total_loss: 4.570196151733398
training step: 49137, total_loss: 0.8111344575881958
training step: 49138, total_loss: 6.134565353393555
training step: 49139, total_loss: 3.775172233581543
training step: 49140, total_loss: 1.0115547180175781
training step: 49141, total_loss: 4.380736351013184
training step: 49142, total_loss: 3.8456923961639404
training step: 49143, total_loss: 4.474135398864746
training step: 49144, total_loss: 4.3394775390625
training step: 49145, total_loss: 4.119749069213867
training step: 49146, total_loss: 3.897528648376465
training step: 49147, total_loss: 4.449801445007324
training step: 49148, total_loss: 4.9075822830200195
training step: 49149, total_loss: 3.320132255554199
training step: 49150, total_loss: 4.066736221313477
training step: 49151, total_loss: 5.58474588394165
training step: 49152, total_loss: 5.261573791503906
training step: 49153, total_loss: 3.3203258514404297
training step: 49154, total_loss: 3.6599597930908203
training step: 49155, total_loss: 3.7960872650146484
training step: 49156, total_loss: 5.953234672546387
training step: 49157, total_loss: 4.670286655426025
training step: 49158, total_loss: 3.512737274169922
training step: 49159, total_loss: 4.45380973815918
training step: 49160, total_loss: 1.4129111766815186
training step: 49161, total_loss: 5.024476051330566
training step: 49162, total_loss: 2.844176769256592
training step: 49163, total_loss: 4.334360122680664
training step: 49164, total_loss: 4.237208843231201
training step: 49165, total_loss: 3.8314404487609863
training step: 49166, total_loss: 5.373394012451172
training step: 49167, total_loss: 3.578001022338867
training step: 49168, total_loss: 4.660023212432861
training step: 49169, total_loss: 1.7832002639770508
training step: 49170, total_loss: 4.934861183166504
training step: 49171, total_loss: 4.303801536560059
training step: 49172, total_loss: 5.095624923706055
training step: 49173, total_loss: 5.46730899810791
training step: 49174, total_loss: 4.157387733459473
training step: 49175, total_loss: 6.001946449279785
training step: 49176, total_loss: 4.774629592895508
training step: 49177, total_loss: 5.538233757019043
training step: 49178, total_loss: 3.8342533111572266
training step: 49179, total_loss: 4.4714837074279785
training step: 49180, total_loss: 4.39232063293457
training step: 49181, total_loss: 6.11689567565918
training step: 49182, total_loss: 5.3104729652404785
training step: 49183, total_loss: 1.175005316734314
training step: 49184, total_loss: 3.060426712036133
training step: 49185, total_loss: 4.083943843841553
training step: 49186, total_loss: 6.090325355529785
training step: 49187, total_loss: 4.417644500732422
training step: 49188, total_loss: 4.386451721191406
training step: 49189, total_loss: 4.648935317993164
training step: 49190, total_loss: 5.648809432983398
training step: 49191, total_loss: 4.612062454223633
training step: 49192, total_loss: 4.147268295288086
training step: 49193, total_loss: 3.8808043003082275
training step: 49194, total_loss: 4.200980186462402
training step: 49195, total_loss: 3.3057899475097656
training step: 49196, total_loss: 3.4661574363708496
training step: 49197, total_loss: 4.328083038330078
training step: 49198, total_loss: 4.198424339294434
training step: 49199, total_loss: 4.269011974334717
training step: 49200, total_loss: 3.946042060852051
training step: 49201, total_loss: 4.95162296295166
training step: 49202, total_loss: 4.008589744567871
training step: 49203, total_loss: 4.1027326583862305
training step: 49204, total_loss: 3.1765971183776855
training step: 49205, total_loss: 3.6332149505615234
training step: 49206, total_loss: 3.272467613220215
training step: 49207, total_loss: 2.884727716445923
training step: 49208, total_loss: 4.032475471496582
training step: 49209, total_loss: 3.4959683418273926
training step: 49210, total_loss: 4.9668779373168945
training step: 49211, total_loss: 3.876546621322632
training step: 49212, total_loss: 5.257696151733398
training step: 49213, total_loss: 3.6140456199645996
training step: 49214, total_loss: 3.5830025672912598
training step: 49215, total_loss: 3.2790913581848145
training step: 49216, total_loss: 5.629634857177734
training step: 49217, total_loss: 4.584679126739502
training step: 49218, total_loss: 4.970841407775879
training step: 49219, total_loss: 4.898373126983643
training step: 49220, total_loss: 3.6841797828674316
training step: 49221, total_loss: 3.757517099380493
training step: 49222, total_loss: 4.534074783325195
training step: 49223, total_loss: 4.080618858337402
training step: 49224, total_loss: 2.960789680480957
training step: 49225, total_loss: 3.79481840133667
training step: 49226, total_loss: 4.543987274169922
training step: 49227, total_loss: 3.6671152114868164
training step: 49228, total_loss: 3.51401424407959
training step: 49229, total_loss: 2.8436036109924316
training step: 49230, total_loss: 4.91967248916626
training step: 49231, total_loss: 4.732616901397705
training step: 49232, total_loss: 4.554112911224365
training step: 49233, total_loss: 3.821192741394043
training step: 49234, total_loss: 4.725584983825684
training step: 49235, total_loss: 3.7967801094055176
training step: 49236, total_loss: 3.7965691089630127
training step: 49237, total_loss: 4.362999439239502
training step: 49238, total_loss: 5.530196189880371
training step: 49239, total_loss: 4.600231170654297
training step: 49240, total_loss: 5.758481025695801
training step: 49241, total_loss: 4.062408924102783
training step: 49242, total_loss: 5.252366065979004
training step: 49243, total_loss: 4.438977241516113
training step: 49244, total_loss: 3.681788921356201
training step: 49245, total_loss: 3.812854766845703
training step: 49246, total_loss: 1.0048904418945312
training step: 49247, total_loss: 1.9385154247283936
training step: 49248, total_loss: 4.687527656555176
training step: 49249, total_loss: 3.1760873794555664
training step: 49250, total_loss: 4.000133037567139
training step: 49251, total_loss: 3.885662317276001
training step: 49252, total_loss: 3.9502506256103516
training step: 49253, total_loss: 3.6903157234191895
training step: 49254, total_loss: 5.135965347290039
training step: 49255, total_loss: 5.127103805541992
training step: 49256, total_loss: 4.860988140106201
training step: 49257, total_loss: 3.9831862449645996
training step: 49258, total_loss: 7.255799293518066
training step: 49259, total_loss: 3.6730923652648926
training step: 49260, total_loss: 4.24344539642334
training step: 49261, total_loss: 5.655467510223389
training step: 49262, total_loss: 3.355189800262451
training step: 49263, total_loss: 4.6397905349731445
training step: 49264, total_loss: 3.6551895141601562
training step: 49265, total_loss: 5.474361896514893
training step: 49266, total_loss: 5.930356979370117
training step: 49267, total_loss: 2.7283642292022705
training step: 49268, total_loss: 4.6870269775390625
training step: 49269, total_loss: 4.147724628448486
training step: 49270, total_loss: 4.652594566345215
training step: 49271, total_loss: 4.865361213684082
training step: 49272, total_loss: 4.580805778503418
training step: 49273, total_loss: 5.394854545593262
training step: 49274, total_loss: 4.014065265655518
training step: 49275, total_loss: 5.270209789276123
training step: 49276, total_loss: 4.763988494873047
training step: 49277, total_loss: 3.1721086502075195
training step: 49278, total_loss: 6.007400035858154
training step: 49279, total_loss: 3.210115432739258
training step: 49280, total_loss: 3.8907980918884277
training step: 49281, total_loss: 5.236542701721191
training step: 49282, total_loss: 5.888861179351807
training step: 49283, total_loss: 1.6139435768127441
training step: 49284, total_loss: 4.276304244995117
training step: 49285, total_loss: 5.712554931640625
training step: 49286, total_loss: 5.137903213500977
training step: 49287, total_loss: 3.79431414604187
training step: 49288, total_loss: 5.759147644042969
training step: 49289, total_loss: 3.5392963886260986
training step: 49290, total_loss: 2.884866237640381
training step: 49291, total_loss: 3.745321750640869
training step: 49292, total_loss: 5.775568962097168
training step: 49293, total_loss: 4.238574981689453
training step: 49294, total_loss: 4.6488752365112305
training step: 49295, total_loss: 5.343423843383789
training step: 49296, total_loss: 4.106930732727051
training step: 49297, total_loss: 3.9425268173217773
training step: 49298, total_loss: 2.6294291019439697
training step: 49299, total_loss: 3.6891863346099854
training step: 49300, total_loss: 5.947144508361816
training step: 49301, total_loss: 3.363345146179199
training step: 49302, total_loss: 4.732353687286377
training step: 49303, total_loss: 4.914736747741699
training step: 49304, total_loss: 3.632765293121338
training step: 49305, total_loss: 4.278661727905273
training step: 49306, total_loss: 6.421175003051758
training step: 49307, total_loss: 4.27549934387207
training step: 49308, total_loss: 5.050005912780762
training step: 49309, total_loss: 4.861508369445801
training step: 49310, total_loss: 4.419277191162109
training step: 49311, total_loss: 4.234925270080566
training step: 49312, total_loss: 3.8174190521240234
training step: 49313, total_loss: 4.094703674316406
training step: 49314, total_loss: 5.697469711303711
training step: 49315, total_loss: 5.034063816070557
training step: 49316, total_loss: 3.3544535636901855
training step: 49317, total_loss: 4.971053600311279
training step: 49318, total_loss: 5.382822036743164
training step: 49319, total_loss: 2.824657917022705
training step: 49320, total_loss: 4.248073577880859
training step: 49321, total_loss: 3.2562291622161865
training step: 49322, total_loss: 6.249956130981445
training step: 49323, total_loss: 4.471353530883789
training step: 49324, total_loss: 6.106077671051025
training step: 49325, total_loss: 3.3257663249969482
training step: 49326, total_loss: 4.450870513916016
training step: 49327, total_loss: 2.6647493839263916
training step: 49328, total_loss: 4.989625930786133
training step: 49329, total_loss: 3.219651460647583
training step: 49330, total_loss: 3.920776844024658
training step: 49331, total_loss: 4.398800849914551
training step: 49332, total_loss: 4.483209609985352
training step: 49333, total_loss: 3.637263774871826
training step: 49334, total_loss: 5.475395202636719
training step: 49335, total_loss: 4.457388877868652
training step: 49336, total_loss: 4.55450439453125
training step: 49337, total_loss: 4.829381942749023
training step: 49338, total_loss: 5.9579973220825195
training step: 49339, total_loss: 3.463963747024536
training step: 49340, total_loss: 3.932894468307495
training step: 49341, total_loss: 4.472366809844971
training step: 49342, total_loss: 4.186398029327393
training step: 49343, total_loss: 5.774352073669434
training step: 49344, total_loss: 4.296460151672363
training step: 49345, total_loss: 4.180327415466309
training step: 49346, total_loss: 5.636183738708496
training step: 49347, total_loss: 4.577691078186035
training step: 49348, total_loss: 3.1511664390563965
training step: 49349, total_loss: 3.5449743270874023
training step: 49350, total_loss: 4.621525764465332
training step: 49351, total_loss: 5.548233509063721
training step: 49352, total_loss: 3.6452274322509766
training step: 49353, total_loss: 4.238024711608887
training step: 49354, total_loss: 6.058743476867676
training step: 49355, total_loss: 5.396790504455566
training step: 49356, total_loss: 4.789912223815918
training step: 49357, total_loss: 4.358928680419922
training step: 49358, total_loss: 4.942422866821289
training step: 49359, total_loss: 4.704707145690918
training step: 49360, total_loss: 3.321746587753296
training step: 49361, total_loss: 1.0973732471466064
training step: 49362, total_loss: 3.7903711795806885
training step: 49363, total_loss: 3.6152663230895996
training step: 49364, total_loss: 2.8122410774230957
training step: 49365, total_loss: 4.474123954772949
training step: 49366, total_loss: 2.986365795135498
training step: 49367, total_loss: 3.8583662509918213
training step: 49368, total_loss: 3.940718173980713
training step: 49369, total_loss: 5.623660087585449
training step: 49370, total_loss: 4.152431011199951
training step: 49371, total_loss: 5.796533107757568
training step: 49372, total_loss: 5.189929962158203
training step: 49373, total_loss: 4.07504415512085
training step: 49374, total_loss: 5.276159286499023
training step: 49375, total_loss: 3.5874369144439697
training step: 49376, total_loss: 3.4701404571533203
training step: 49377, total_loss: 4.959452152252197
training step: 49378, total_loss: 5.876652717590332
training step: 49379, total_loss: 4.4803571701049805
training step: 49380, total_loss: 3.703134298324585
training step: 49381, total_loss: 3.6663033962249756
training step: 49382, total_loss: 4.733132839202881
training step: 49383, total_loss: 3.221792697906494
training step: 49384, total_loss: 3.736299514770508
training step: 49385, total_loss: 5.784373760223389
training step: 49386, total_loss: 4.891536712646484
training step: 49387, total_loss: 1.019912838935852
training step: 49388, total_loss: 5.337048530578613
training step: 49389, total_loss: 5.1952128410339355
training step: 49390, total_loss: 4.047702789306641
training step: 49391, total_loss: 3.8274149894714355
training step: 49392, total_loss: 4.418788433074951
training step: 49393, total_loss: 3.990648031234741
training step: 49394, total_loss: 2.501502513885498
training step: 49395, total_loss: 4.735910415649414
training step: 49396, total_loss: 3.492685556411743
training step: 49397, total_loss: 4.343760013580322
training step: 49398, total_loss: 4.019852161407471
training step: 49399, total_loss: 4.373759746551514
training step: 49400, total_loss: 4.364767551422119
training step: 49401, total_loss: 4.103687286376953
training step: 49402, total_loss: 3.273418426513672
training step: 49403, total_loss: 5.9881696701049805
training step: 49404, total_loss: 5.181474685668945
training step: 49405, total_loss: 5.199690818786621
training step: 49406, total_loss: 1.5216867923736572
training step: 49407, total_loss: 3.9209587574005127
training step: 49408, total_loss: 4.864408493041992
training step: 49409, total_loss: 3.8622217178344727
training step: 49410, total_loss: 5.969034194946289
training step: 49411, total_loss: 2.8167307376861572
training step: 49412, total_loss: 3.7496285438537598
training step: 49413, total_loss: 5.020003318786621
training step: 49414, total_loss: 7.690635681152344
training step: 49415, total_loss: 1.2233035564422607
training step: 49416, total_loss: 4.2316155433654785
training step: 49417, total_loss: 4.349915504455566
training step: 49418, total_loss: 2.3470139503479004
training step: 49419, total_loss: 5.004702568054199
training step: 49420, total_loss: 5.167571067810059
training step: 49421, total_loss: 3.1692352294921875
training step: 49422, total_loss: 4.59378719329834
training step: 49423, total_loss: 3.4817590713500977
training step: 49424, total_loss: 3.9727118015289307
training step: 49425, total_loss: 4.535167694091797
training step: 49426, total_loss: 4.963220596313477
training step: 49427, total_loss: 5.034807205200195
training step: 49428, total_loss: 4.403878688812256
training step: 49429, total_loss: 3.924731731414795
training step: 49430, total_loss: 3.618988275527954
training step: 49431, total_loss: 1.6847223043441772
training step: 49432, total_loss: 5.245223045349121
training step: 49433, total_loss: 4.28536319732666
training step: 49434, total_loss: 4.661591529846191
training step: 49435, total_loss: 4.268174171447754
training step: 49436, total_loss: 5.482339859008789
training step: 49437, total_loss: 4.786125183105469
training step: 49438, total_loss: 5.5508575439453125
training step: 49439, total_loss: 4.490367412567139
training step: 49440, total_loss: 5.117263317108154
training step: 49441, total_loss: 2.5311741828918457
training step: 49442, total_loss: 4.29888391494751
training step: 49443, total_loss: 4.161627769470215
training step: 49444, total_loss: 2.522127151489258
training step: 49445, total_loss: 4.640669345855713
training step: 49446, total_loss: 5.559033393859863
training step: 49447, total_loss: 4.649801254272461
training step: 49448, total_loss: 5.067028999328613
training step: 49449, total_loss: 5.560704708099365
training step: 49450, total_loss: 4.78919792175293
training step: 49451, total_loss: 5.564907073974609
training step: 49452, total_loss: 3.475041627883911
training step: 49453, total_loss: 4.834000587463379
training step: 49454, total_loss: 1.2803244590759277
training step: 49455, total_loss: 4.82450008392334
training step: 49456, total_loss: 4.85952615737915
training step: 49457, total_loss: 5.371448516845703
training step: 49458, total_loss: 3.818016529083252
training step: 49459, total_loss: 4.82525634765625
training step: 49460, total_loss: 4.438418388366699
training step: 49461, total_loss: 2.617204427719116
training step: 49462, total_loss: 4.425402641296387
training step: 49463, total_loss: 4.876614570617676
training step: 49464, total_loss: 5.36952018737793
training step: 49465, total_loss: 5.022548198699951
training step: 49466, total_loss: 2.850193977355957
training step: 49467, total_loss: 3.5524916648864746
training step: 49468, total_loss: 3.7063374519348145
training step: 49469, total_loss: 4.815100193023682
training step: 49470, total_loss: 4.422123908996582
training step: 49471, total_loss: 4.517898082733154
training step: 49472, total_loss: 4.911933898925781
training step: 49473, total_loss: 6.699831962585449
training step: 49474, total_loss: 3.290930986404419
training step: 49475, total_loss: 3.3213953971862793
training step: 49476, total_loss: 5.069382667541504
training step: 49477, total_loss: 3.5832414627075195
training step: 49478, total_loss: 4.921773433685303
training step: 49479, total_loss: 4.422146797180176
training step: 49480, total_loss: 2.777693510055542
training step: 49481, total_loss: 4.550992012023926
training step: 49482, total_loss: 3.56817626953125
training step: 49483, total_loss: 5.373680114746094
training step: 49484, total_loss: 4.220012664794922
training step: 49485, total_loss: 5.399426460266113
training step: 49486, total_loss: 5.214947700500488
training step: 49487, total_loss: 3.7138519287109375
training step: 49488, total_loss: 3.297748565673828
training step: 49489, total_loss: 3.8756046295166016
training step: 49490, total_loss: 4.408130168914795
training step: 49491, total_loss: 1.013052225112915
training step: 49492, total_loss: 5.160702705383301
training step: 49493, total_loss: 4.428711891174316
training step: 49494, total_loss: 4.825058937072754
training step: 49495, total_loss: 6.082878589630127
training step: 49496, total_loss: 3.340430974960327
training step: 49497, total_loss: 3.6746418476104736
training step: 49498, total_loss: 2.2975540161132812
training step: 49499, total_loss: 4.809474468231201
training step: 49500, total_loss: 3.9603426456451416
training step: 49501, total_loss: 4.199485778808594
training step: 49502, total_loss: 4.540040016174316
training step: 49503, total_loss: 5.395552158355713
training step: 49504, total_loss: 4.085301399230957
training step: 49505, total_loss: 4.5534868240356445
training step: 49506, total_loss: 3.945729970932007
training step: 49507, total_loss: 3.453460693359375
training step: 49508, total_loss: 3.838749885559082
training step: 49509, total_loss: 4.865964889526367
training step: 49510, total_loss: 3.863719940185547
training step: 49511, total_loss: 3.3846263885498047
training step: 49512, total_loss: 5.084856033325195
training step: 49513, total_loss: 5.305916786193848
training step: 49514, total_loss: 4.148271560668945
training step: 49515, total_loss: 5.0106120109558105
training step: 49516, total_loss: 4.588747501373291
training step: 49517, total_loss: 4.400069713592529
training step: 49518, total_loss: 3.179391384124756
training step: 49519, total_loss: 3.9669885635375977
training step: 49520, total_loss: 4.577972412109375
training step: 49521, total_loss: 4.584059715270996
training step: 49522, total_loss: 4.743555068969727
training step: 49523, total_loss: 4.2982306480407715
training step: 49524, total_loss: 0.9618998169898987
training step: 49525, total_loss: 4.147821426391602
training step: 49526, total_loss: 2.6850972175598145
training step: 49527, total_loss: 5.838587760925293
training step: 49528, total_loss: 3.6019325256347656
training step: 49529, total_loss: 3.2928452491760254
training step: 49530, total_loss: 5.7062273025512695
training step: 49531, total_loss: 4.406125068664551
training step: 49532, total_loss: 4.977668285369873
training step: 49533, total_loss: 4.828158378601074
training step: 49534, total_loss: 3.339879274368286
training step: 49535, total_loss: 2.795652151107788
training step: 49536, total_loss: 0.916843831539154
training step: 49537, total_loss: 4.838481903076172
training step: 49538, total_loss: 3.433959484100342
training step: 49539, total_loss: 4.032153606414795
training step: 49540, total_loss: 3.5425913333892822
training step: 49541, total_loss: 5.365171432495117
training step: 49542, total_loss: 4.594605445861816
training step: 49543, total_loss: 2.861891984939575
training step: 49544, total_loss: 4.1722869873046875
training step: 49545, total_loss: 2.538723945617676
training step: 49546, total_loss: 4.707013130187988
training step: 49547, total_loss: 3.0588297843933105
training step: 49548, total_loss: 5.226471900939941
training step: 49549, total_loss: 5.1791791915893555
training step: 49550, total_loss: 6.241382598876953
training step: 49551, total_loss: 2.934396266937256
training step: 49552, total_loss: 2.96272611618042
training step: 49553, total_loss: 4.856285095214844
training step: 49554, total_loss: 3.6180787086486816
training step: 49555, total_loss: 1.1983063220977783
training step: 49556, total_loss: 4.7809247970581055
training step: 49557, total_loss: 4.575481414794922
training step: 49558, total_loss: 4.074732303619385
training step: 49559, total_loss: 3.818817138671875
training step: 49560, total_loss: 4.2516632080078125
training step: 49561, total_loss: 3.254322052001953
training step: 49562, total_loss: 4.436559200286865
training step: 49563, total_loss: 1.0498825311660767
training step: 49564, total_loss: 4.805662155151367
training step: 49565, total_loss: 5.125468730926514
training step: 49566, total_loss: 3.1014721393585205
training step: 49567, total_loss: 2.9317474365234375
training step: 49568, total_loss: 0.8966306447982788
training step: 49569, total_loss: 4.041470527648926
training step: 49570, total_loss: 3.838599443435669
training step: 49571, total_loss: 3.5614233016967773
training step: 49572, total_loss: 5.044407844543457
training step: 49573, total_loss: 0.9586694240570068
training step: 49574, total_loss: 5.075560092926025
training step: 49575, total_loss: 3.02641224861145
training step: 49576, total_loss: 3.3717968463897705
training step: 49577, total_loss: 4.054356575012207
training step: 49578, total_loss: 4.515966892242432
training step: 49579, total_loss: 4.909290313720703
training step: 49580, total_loss: 4.27482795715332
training step: 49581, total_loss: 4.368890285491943
training step: 49582, total_loss: 3.3506946563720703
training step: 49583, total_loss: 3.5306177139282227
training step: 49584, total_loss: 6.134060382843018
training step: 49585, total_loss: 4.297600746154785
training step: 49586, total_loss: 5.905016899108887
training step: 49587, total_loss: 4.32640266418457
training step: 49588, total_loss: 3.802370071411133
training step: 49589, total_loss: 5.427433490753174
training step: 49590, total_loss: 5.209540843963623
training step: 49591, total_loss: 4.6921586990356445
training step: 49592, total_loss: 3.9753949642181396
training step: 49593, total_loss: 4.619717597961426
training step: 49594, total_loss: 6.0654191970825195
training step: 49595, total_loss: 4.615631103515625
training step: 49596, total_loss: 5.2259063720703125
training step: 49597, total_loss: 5.265944480895996
training step: 49598, total_loss: 3.133194923400879
training step: 49599, total_loss: 2.7182350158691406
training step: 49600, total_loss: 4.8365983963012695
training step: 49601, total_loss: 4.734993934631348
training step: 49602, total_loss: 4.398748874664307
training step: 49603, total_loss: 0.7955172657966614
training step: 49604, total_loss: 2.361008882522583
training step: 49605, total_loss: 4.227530479431152
training step: 49606, total_loss: 3.172473907470703
training step: 49607, total_loss: 5.589895248413086
training step: 49608, total_loss: 3.1931543350219727
training step: 49609, total_loss: 5.450416564941406
training step: 49610, total_loss: 2.80086088180542
training step: 49611, total_loss: 4.627048492431641
training step: 49612, total_loss: 4.0521440505981445
training step: 49613, total_loss: 3.0523600578308105
training step: 49614, total_loss: 4.762800693511963
training step: 49615, total_loss: 5.585713863372803
training step: 49616, total_loss: 4.44227409362793
training step: 49617, total_loss: 4.351544380187988
training step: 49618, total_loss: 6.9586615562438965
training step: 49619, total_loss: 4.961791038513184
training step: 49620, total_loss: 4.59591817855835
training step: 49621, total_loss: 3.764578342437744
training step: 49622, total_loss: 4.731845378875732
training step: 49623, total_loss: 4.234375953674316
training step: 49624, total_loss: 5.686890602111816
training step: 49625, total_loss: 4.68594217300415
training step: 49626, total_loss: 4.310041427612305
training step: 49627, total_loss: 3.6816067695617676
training step: 49628, total_loss: 7.9827423095703125
training step: 49629, total_loss: 4.128117561340332
training step: 49630, total_loss: 4.582109451293945
training step: 49631, total_loss: 1.0602409839630127
training step: 49632, total_loss: 6.665712833404541
training step: 49633, total_loss: 4.438477039337158
training step: 49634, total_loss: 4.955195426940918
training step: 49635, total_loss: 5.221839904785156
training step: 49636, total_loss: 4.207111835479736
training step: 49637, total_loss: 3.67234468460083
training step: 49638, total_loss: 3.19882869720459
training step: 49639, total_loss: 3.542299747467041
training step: 49640, total_loss: 4.757018566131592
training step: 49641, total_loss: 2.5121312141418457
training step: 49642, total_loss: 4.140162467956543
training step: 49643, total_loss: 3.8946690559387207
training step: 49644, total_loss: 4.809304714202881
training step: 49645, total_loss: 2.0706982612609863
training step: 49646, total_loss: 4.3844451904296875
training step: 49647, total_loss: 4.138064384460449
training step: 49648, total_loss: 6.240824222564697
training step: 49649, total_loss: 2.2618188858032227
training step: 49650, total_loss: 1.8667504787445068
training step: 49651, total_loss: 2.9352164268493652
training step: 49652, total_loss: 3.59977126121521
training step: 49653, total_loss: 4.987900733947754
training step: 49654, total_loss: 4.880242347717285
training step: 49655, total_loss: 4.516597747802734
training step: 49656, total_loss: 5.51867151260376
training step: 49657, total_loss: 2.998901605606079
training step: 49658, total_loss: 4.863805770874023
training step: 49659, total_loss: 3.985471248626709
training step: 49660, total_loss: 5.432923793792725
training step: 49661, total_loss: 3.058495283126831
training step: 49662, total_loss: 3.909742832183838
training step: 49663, total_loss: 4.441555976867676
training step: 49664, total_loss: 4.5811662673950195
training step: 49665, total_loss: 4.07542085647583
training step: 49666, total_loss: 3.494058609008789
training step: 49667, total_loss: 4.1698150634765625
training step: 49668, total_loss: 5.919078826904297
training step: 49669, total_loss: 4.0374064445495605
training step: 49670, total_loss: 5.384124755859375
training step: 49671, total_loss: 3.4363512992858887
training step: 49672, total_loss: 0.9441779851913452
training step: 49673, total_loss: 2.5850038528442383
training step: 49674, total_loss: 4.2877116203308105
training step: 49675, total_loss: 4.371030330657959
training step: 49676, total_loss: 4.566501140594482
training step: 49677, total_loss: 4.351190567016602
training step: 49678, total_loss: 3.6356754302978516
training step: 49679, total_loss: 4.028619289398193
training step: 49680, total_loss: 4.332100868225098
training step: 49681, total_loss: 4.235553741455078
training step: 49682, total_loss: 4.905970573425293
training step: 49683, total_loss: 4.114106178283691
training step: 49684, total_loss: 4.47901725769043
training step: 49685, total_loss: 4.709225654602051
training step: 49686, total_loss: 4.563199520111084
training step: 49687, total_loss: 4.907414436340332
training step: 49688, total_loss: 5.007020950317383
training step: 49689, total_loss: 5.0970916748046875
training step: 49690, total_loss: 4.823734283447266
training step: 49691, total_loss: 3.082217216491699
training step: 49692, total_loss: 2.9003121852874756
training step: 49693, total_loss: 3.7148637771606445
training step: 49694, total_loss: 5.795506954193115
training step: 49695, total_loss: 3.351412773132324
training step: 49696, total_loss: 4.736171722412109
training step: 49697, total_loss: 4.906551361083984
training step: 49698, total_loss: 6.0793867111206055
training step: 49699, total_loss: 4.491122722625732
training step: 49700, total_loss: 6.262099266052246
training step: 49701, total_loss: 5.559911727905273
training step: 49702, total_loss: 6.035033226013184
training step: 49703, total_loss: 7.35153865814209
training step: 49704, total_loss: 2.8528709411621094
training step: 49705, total_loss: 5.4191412925720215
training step: 49706, total_loss: 2.710759162902832
training step: 49707, total_loss: 3.663299560546875
training step: 49708, total_loss: 4.500692367553711
training step: 49709, total_loss: 5.350379467010498
training step: 49710, total_loss: 4.958263397216797
training step: 49711, total_loss: 2.539900302886963
training step: 49712, total_loss: 3.3177409172058105
training step: 49713, total_loss: 5.068001747131348
training step: 49714, total_loss: 5.611258029937744
training step: 49715, total_loss: 4.406238079071045
training step: 49716, total_loss: 5.154804229736328
training step: 49717, total_loss: 4.0746307373046875
training step: 49718, total_loss: 3.615628719329834
training step: 49719, total_loss: 4.763845443725586
training step: 49720, total_loss: 2.5424060821533203
training step: 49721, total_loss: 5.125493049621582
training step: 49722, total_loss: 4.428211688995361
training step: 49723, total_loss: 5.986512660980225
training step: 49724, total_loss: 4.829192161560059
training step: 49725, total_loss: 4.976694583892822
training step: 49726, total_loss: 5.523534774780273
training step: 49727, total_loss: 3.9755876064300537
training step: 49728, total_loss: 3.5733256340026855
training step: 49729, total_loss: 5.021692752838135
training step: 49730, total_loss: 4.2762651443481445
training step: 49731, total_loss: 5.454110622406006
training step: 49732, total_loss: 3.999462604522705
training step: 49733, total_loss: 5.54481840133667
training step: 49734, total_loss: 4.143017768859863
training step: 49735, total_loss: 4.324600696563721
training step: 49736, total_loss: 3.1803250312805176
training step: 49737, total_loss: 4.387837886810303
training step: 49738, total_loss: 1.9012880325317383
training step: 49739, total_loss: 6.174273490905762
training step: 49740, total_loss: 3.7127668857574463
training step: 49741, total_loss: 4.9070329666137695
training step: 49742, total_loss: 4.888597011566162
training step: 49743, total_loss: 2.4308526515960693
training step: 49744, total_loss: 3.8252041339874268
training step: 49745, total_loss: 4.055703163146973
training step: 49746, total_loss: 3.755842685699463
training step: 49747, total_loss: 4.0743513107299805
training step: 49748, total_loss: 4.617822170257568
training step: 49749, total_loss: 2.9520492553710938
training step: 49750, total_loss: 4.232497215270996
training step: 49751, total_loss: 2.9865972995758057
training step: 49752, total_loss: 5.010197162628174
training step: 49753, total_loss: 3.0861711502075195
training step: 49754, total_loss: 3.468815326690674
training step: 49755, total_loss: 4.106407165527344
training step: 49756, total_loss: 2.507092237472534
training step: 49757, total_loss: 4.569994926452637
training step: 49758, total_loss: 4.321869850158691
training step: 49759, total_loss: 7.175023555755615
training step: 49760, total_loss: 7.197680473327637
training step: 49761, total_loss: 1.2113964557647705
training step: 49762, total_loss: 5.011174201965332
training step: 49763, total_loss: 4.867181777954102
training step: 49764, total_loss: 3.365102767944336
training step: 49765, total_loss: 5.015528202056885
training step: 49766, total_loss: 4.073230743408203
training step: 49767, total_loss: 3.3110318183898926
training step: 49768, total_loss: 4.579942226409912
training step: 49769, total_loss: 4.174066066741943
training step: 49770, total_loss: 5.137170791625977
training step: 49771, total_loss: 4.955759048461914
training step: 49772, total_loss: 5.2465009689331055
training step: 49773, total_loss: 5.388125896453857
training step: 49774, total_loss: 4.090507984161377
training step: 49775, total_loss: 5.898087024688721
training step: 49776, total_loss: 5.064884662628174
training step: 49777, total_loss: 4.518702983856201
training step: 49778, total_loss: 3.896629810333252
training step: 49779, total_loss: 4.617055416107178
training step: 49780, total_loss: 3.449582576751709
training step: 49781, total_loss: 4.820528030395508
training step: 49782, total_loss: 6.485235214233398
training step: 49783, total_loss: 4.354846477508545
training step: 49784, total_loss: 4.015289783477783
training step: 49785, total_loss: 5.438144207000732
training step: 49786, total_loss: 4.402505874633789
training step: 49787, total_loss: 5.443680763244629
training step: 49788, total_loss: 1.1325898170471191
training step: 49789, total_loss: 6.391806602478027
training step: 49790, total_loss: 4.260825157165527
training step: 49791, total_loss: 5.461845397949219
training step: 49792, total_loss: 4.047817230224609
training step: 49793, total_loss: 4.439668655395508
training step: 49794, total_loss: 6.055307388305664
training step: 49795, total_loss: 3.6514620780944824
training step: 49796, total_loss: 4.186037540435791
training step: 49797, total_loss: 3.4557905197143555
training step: 49798, total_loss: 5.176810264587402
training step: 49799, total_loss: 3.390928268432617
training step: 49800, total_loss: 4.616616725921631
training step: 49801, total_loss: 3.365020275115967
training step: 49802, total_loss: 4.760156631469727
training step: 49803, total_loss: 5.055440902709961
training step: 49804, total_loss: 4.043225288391113
training step: 49805, total_loss: 3.1598687171936035
training step: 49806, total_loss: 4.577852725982666
training step: 49807, total_loss: 4.73366641998291
training step: 49808, total_loss: 5.0362091064453125
training step: 49809, total_loss: 5.965063095092773
training step: 49810, total_loss: 4.330683708190918
training step: 49811, total_loss: 2.0796170234680176
training step: 49812, total_loss: 3.317951202392578
training step: 49813, total_loss: 5.123639106750488
training step: 49814, total_loss: 6.171724319458008
training step: 49815, total_loss: 4.351144313812256
training step: 49816, total_loss: 5.047351837158203
training step: 49817, total_loss: 3.9558615684509277
training step: 49818, total_loss: 2.6102280616760254
training step: 49819, total_loss: 4.61216926574707
training step: 49820, total_loss: 4.720463752746582
training step: 49821, total_loss: 3.389881134033203
training step: 49822, total_loss: 4.717348575592041
training step: 49823, total_loss: 4.278666019439697
training step: 49824, total_loss: 4.376547813415527
training step: 49825, total_loss: 4.278935432434082
training step: 49826, total_loss: 5.263487339019775
training step: 49827, total_loss: 4.482327461242676
training step: 49828, total_loss: 3.9862594604492188
training step: 49829, total_loss: 5.085431098937988
training step: 49830, total_loss: 4.778101921081543
training step: 49831, total_loss: 4.6219658851623535
training step: 49832, total_loss: 3.1702589988708496
training step: 49833, total_loss: 2.319349765777588
training step: 49834, total_loss: 1.0269787311553955
training step: 49835, total_loss: 2.7948458194732666
training step: 49836, total_loss: 5.703038215637207
training step: 49837, total_loss: 2.146012544631958
training step: 49838, total_loss: 3.6683835983276367
training step: 49839, total_loss: 4.969854354858398
training step: 49840, total_loss: 3.08394718170166
training step: 49841, total_loss: 4.0321502685546875
training step: 49842, total_loss: 4.3375983238220215
training step: 49843, total_loss: 4.206725120544434
training step: 49844, total_loss: 4.781013488769531
training step: 49845, total_loss: 3.850827693939209
training step: 49846, total_loss: 4.661620616912842
training step: 49847, total_loss: 4.483791351318359
training step: 49848, total_loss: 4.952317237854004
training step: 49849, total_loss: 4.090497016906738
training step: 49850, total_loss: 4.221364498138428
training step: 49851, total_loss: 6.660623550415039
training step: 49852, total_loss: 2.3675246238708496
training step: 49853, total_loss: 4.362603187561035
training step: 49854, total_loss: 6.715094566345215
training step: 49855, total_loss: 2.605741500854492
training step: 49856, total_loss: 5.786158561706543
training step: 49857, total_loss: 4.3401899337768555
training step: 49858, total_loss: 4.006904125213623
training step: 49859, total_loss: 5.157680511474609
training step: 49860, total_loss: 3.778339147567749
training step: 49861, total_loss: 5.293938636779785
training step: 49862, total_loss: 5.165369033813477
training step: 49863, total_loss: 4.3264594078063965
training step: 49864, total_loss: 4.290288925170898
training step: 49865, total_loss: 4.556574821472168
training step: 49866, total_loss: 5.34512186050415
training step: 49867, total_loss: 5.100869178771973
training step: 49868, total_loss: 3.6180129051208496
training step: 49869, total_loss: 4.583973407745361
training step: 49870, total_loss: 3.6884076595306396
training step: 49871, total_loss: 3.622936725616455
training step: 49872, total_loss: 3.8751273155212402
training step: 49873, total_loss: 4.8688201904296875
training step: 49874, total_loss: 2.2351908683776855
training step: 49875, total_loss: 3.7235352993011475
training step: 49876, total_loss: 2.7301032543182373
training step: 49877, total_loss: 5.0544586181640625
training step: 49878, total_loss: 4.787354469299316
training step: 49879, total_loss: 2.2864930629730225
training step: 49880, total_loss: 4.160945415496826
training step: 49881, total_loss: 4.631113529205322
training step: 49882, total_loss: 4.828959941864014
training step: 49883, total_loss: 5.379703521728516
training step: 49884, total_loss: 4.612048149108887
training step: 49885, total_loss: 2.645735740661621
training step: 49886, total_loss: 5.919754981994629
training step: 49887, total_loss: 4.660059452056885
training step: 49888, total_loss: 4.797344207763672
training step: 49889, total_loss: 2.3673441410064697
training step: 49890, total_loss: 4.50600528717041
training step: 49891, total_loss: 0.9496762752532959
training step: 49892, total_loss: 4.101874828338623
training step: 49893, total_loss: 4.481290817260742
training step: 49894, total_loss: 4.878391742706299
training step: 49895, total_loss: 5.450521469116211
training step: 49896, total_loss: 3.4533684253692627
training step: 49897, total_loss: 3.158029079437256
training step: 49898, total_loss: 1.786379337310791
training step: 49899, total_loss: 2.393157720565796
training step: 49900, total_loss: 3.8275680541992188
training step: 49901, total_loss: 3.9951670169830322
training step: 49902, total_loss: 3.2697901725769043
training step: 49903, total_loss: 5.310934543609619
training step: 49904, total_loss: 4.285843849182129
training step: 49905, total_loss: 3.004103183746338
training step: 49906, total_loss: 3.8671364784240723
training step: 49907, total_loss: 5.357194423675537
training step: 49908, total_loss: 3.5280885696411133
training step: 49909, total_loss: 4.551570415496826
training step: 49910, total_loss: 4.6667280197143555
training step: 49911, total_loss: 3.151329517364502
training step: 49912, total_loss: 4.910703659057617
training step: 49913, total_loss: 3.78377366065979
training step: 49914, total_loss: 3.9368038177490234
training step: 49915, total_loss: 4.127121925354004
training step: 49916, total_loss: 4.34946346282959
training step: 49917, total_loss: 5.901166915893555
training step: 49918, total_loss: 3.802882194519043
training step: 49919, total_loss: 3.794983386993408
training step: 49920, total_loss: 5.26180362701416
training step: 49921, total_loss: 4.8979878425598145
training step: 49922, total_loss: 3.6551942825317383
training step: 49923, total_loss: 4.03053617477417
training step: 49924, total_loss: 4.576223373413086
training step: 49925, total_loss: 4.835550308227539
training step: 49926, total_loss: 5.076166152954102
training step: 49927, total_loss: 3.7546372413635254
training step: 49928, total_loss: 4.038664817810059
training step: 49929, total_loss: 4.090057373046875
training step: 49930, total_loss: 5.3305816650390625
training step: 49931, total_loss: 0.8280491828918457
training step: 49932, total_loss: 5.294849395751953
training step: 49933, total_loss: 5.783486366271973
training step: 49934, total_loss: 4.34542989730835
training step: 49935, total_loss: 3.688871383666992
training step: 49936, total_loss: 2.6790945529937744
training step: 49937, total_loss: 5.3380351066589355
training step: 49938, total_loss: 3.9671573638916016
training step: 49939, total_loss: 5.989823341369629
training step: 49940, total_loss: 5.799984931945801
training step: 49941, total_loss: 4.122461318969727
training step: 49942, total_loss: 4.0320000648498535
training step: 49943, total_loss: 4.122939109802246
training step: 49944, total_loss: 3.9225263595581055
training step: 49945, total_loss: 5.139776229858398
training step: 49946, total_loss: 4.331439018249512
training step: 49947, total_loss: 2.808917999267578
training step: 49948, total_loss: 4.403240203857422
training step: 49949, total_loss: 4.48307466506958
training step: 49950, total_loss: 4.442525863647461
training step: 49951, total_loss: 4.435122966766357
training step: 49952, total_loss: 3.969595193862915
training step: 49953, total_loss: 4.6348724365234375
training step: 49954, total_loss: 4.542828559875488
training step: 49955, total_loss: 5.182525634765625
training step: 49956, total_loss: 5.590876579284668
training step: 49957, total_loss: 2.1413345336914062
training step: 49958, total_loss: 5.5987629890441895
training step: 49959, total_loss: 2.8896632194519043
training step: 49960, total_loss: 4.959115982055664
training step: 49961, total_loss: 4.8718743324279785
training step: 49962, total_loss: 5.711999893188477
training step: 49963, total_loss: 4.634888648986816
training step: 49964, total_loss: 4.127458095550537
training step: 49965, total_loss: 3.328904628753662
training step: 49966, total_loss: 4.062777996063232
training step: 49967, total_loss: 1.9561543464660645
training step: 49968, total_loss: 3.0392637252807617
training step: 49969, total_loss: 4.873354911804199
training step: 49970, total_loss: 4.425164699554443
training step: 49971, total_loss: 4.035699367523193
training step: 49972, total_loss: 4.323493957519531
training step: 49973, total_loss: 5.1650590896606445
training step: 49974, total_loss: 6.026474952697754
training step: 49975, total_loss: 4.825162410736084
training step: 49976, total_loss: 3.938732624053955
training step: 49977, total_loss: 5.19923210144043
training step: 49978, total_loss: 2.7822341918945312/home/user/miniconda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/home/user/miniconda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
INFO:tensorflow:Writing predictions to: residual_output/predictions_50000.json
INFO:tensorflow:Writing nbest to: residual_output/nbest_predictions_50000.json

training step: 49979, total_loss: 5.954100608825684
training step: 49980, total_loss: 3.5088846683502197
training step: 49981, total_loss: 3.8607876300811768
training step: 49982, total_loss: 4.7210798263549805
training step: 49983, total_loss: 4.424069404602051
training step: 49984, total_loss: 4.395796775817871
training step: 49985, total_loss: 4.092759609222412
training step: 49986, total_loss: 4.612918853759766
training step: 49987, total_loss: 4.740669250488281
training step: 49988, total_loss: 5.426717758178711
training step: 49989, total_loss: 4.1133646965026855
training step: 49990, total_loss: 5.138986110687256
training step: 49991, total_loss: 0.7488338351249695
training step: 49992, total_loss: 3.9425902366638184
training step: 49993, total_loss: 4.104706764221191
training step: 49994, total_loss: 3.340726852416992
training step: 49995, total_loss: 4.5654730796813965
training step: 49996, total_loss: 4.195619583129883
training step: 49997, total_loss: 3.8323206901550293
training step: 49998, total_loss: 2.605264186859131
training step: 49999, total_loss: 3.8857550621032715
training step: 50000, total_loss: 5.081750392913818
epoch finished! shuffle=False
evaluation: 50000, total_loss: 2.3150384426116943, f1: 23.440224748404475, followup: 18.378213905370455, yesno: 1.6126578426897915, heq: 22.957553628480145, dheq: 0.8

Model saved in path residual_output//model_50000.ckpt
training step: 50001, total_loss: 3.8325376510620117
training step: 50002, total_loss: 3.177661895751953
training step: 50003, total_loss: 4.22075080871582
training step: 50004, total_loss: 3.914557695388794
training step: 50005, total_loss: 2.9405484199523926
training step: 50006, total_loss: 3.54447865486145
training step: 50007, total_loss: 4.613702297210693
training step: 50008, total_loss: 5.1305131912231445
training step: 50009, total_loss: 4.445003032684326
training step: 50010, total_loss: 5.330320835113525
training step: 50011, total_loss: 4.363608360290527
training step: 50012, total_loss: 4.090305805206299
training step: 50013, total_loss: 4.67185115814209
training step: 50014, total_loss: 4.305639743804932
training step: 50015, total_loss: 4.212514877319336
training step: 50016, total_loss: 3.398125648498535
training step: 50017, total_loss: 6.847084999084473
training step: 50018, total_loss: 4.390630722045898
training step: 50019, total_loss: 5.347899436950684
training step: 50020, total_loss: 4.905121803283691
training step: 50021, total_loss: 5.515599727630615
training step: 50022, total_loss: 6.175099849700928
training step: 50023, total_loss: 4.646973609924316
training step: 50024, total_loss: 4.3347697257995605
training step: 50025, total_loss: 3.5499815940856934
training step: 50026, total_loss: 4.303752899169922
training step: 50027, total_loss: 3.8913512229919434
training step: 50028, total_loss: 5.195219993591309
training step: 50029, total_loss: 4.5538482666015625
training step: 50030, total_loss: 4.726555824279785
training step: 50031, total_loss: 5.041228771209717
training step: 50032, total_loss: 2.805398464202881
training step: 50033, total_loss: 4.3837995529174805
training step: 50034, total_loss: 3.479379177093506
training step: 50035, total_loss: 4.307857513427734
training step: 50036, total_loss: 3.7608494758605957
training step: 50037, total_loss: 2.9020090103149414
training step: 50038, total_loss: 4.831093788146973
training step: 50039, total_loss: 4.121941566467285
training step: 50040, total_loss: 3.4654126167297363
training step: 50041, total_loss: 4.835144996643066
training step: 50042, total_loss: 4.334458351135254
training step: 50043, total_loss: 4.120429515838623
training step: 50044, total_loss: 4.990568161010742
training step: 50045, total_loss: 4.272911071777344
training step: 50046, total_loss: 4.0571722984313965
training step: 50047, total_loss: 5.422054290771484
training step: 50048, total_loss: 2.242365598678589
training step: 50049, total_loss: 4.453094005584717
training step: 50050, total_loss: 2.286068916320801
training step: 50051, total_loss: 6.6529083251953125
training step: 50052, total_loss: 6.3267340660095215
training step: 50053, total_loss: 4.516905307769775
training step: 50054, total_loss: 5.018623352050781
training step: 50055, total_loss: 3.9506335258483887
training step: 50056, total_loss: 5.377899646759033
training step: 50057, total_loss: 2.1675608158111572
training step: 50058, total_loss: 3.9758992195129395
training step: 50059, total_loss: 4.493669509887695
training step: 50060, total_loss: 3.533076763153076
training step: 50061, total_loss: 3.1359760761260986
training step: 50062, total_loss: 2.6139330863952637
training step: 50063, total_loss: 4.997796058654785
training step: 50064, total_loss: 4.399612903594971
training step: 50065, total_loss: 2.6399083137512207
training step: 50066, total_loss: 4.83660888671875
training step: 50067, total_loss: 4.678160667419434
training step: 50068, total_loss: 5.8334455490112305
training step: 50069, total_loss: 3.9619429111480713
training step: 50070, total_loss: 4.979293346405029
training step: 50071, total_loss: 7.226299285888672
training step: 50072, total_loss: 5.852503776550293
training step: 50073, total_loss: 4.226429462432861
training step: 50074, total_loss: 4.904135704040527
training step: 50075, total_loss: 5.2201762199401855
training step: 50076, total_loss: 5.8257551193237305
training step: 50077, total_loss: 4.2507710456848145
training step: 50078, total_loss: 4.623023986816406
training step: 50079, total_loss: 8.752365112304688
training step: 50080, total_loss: 3.7574291229248047
training step: 50081, total_loss: 5.631462097167969
training step: 50082, total_loss: 4.069745063781738
training step: 50083, total_loss: 4.251262664794922
training step: 50084, total_loss: 4.377633094787598
training step: 50085, total_loss: 4.093896389007568
training step: 50086, total_loss: 3.686023235321045
training step: 50087, total_loss: 4.686483383178711
training step: 50088, total_loss: 4.535651206970215
training step: 50089, total_loss: 2.356163740158081
training step: 50090, total_loss: 4.556330680847168
training step: 50091, total_loss: 3.819492816925049
training step: 50092, total_loss: 4.50563907623291
training step: 50093, total_loss: 6.541566848754883
training step: 50094, total_loss: 6.154656410217285
training step: 50095, total_loss: 4.800165176391602
training step: 50096, total_loss: 4.49724817276001
training step: 50097, total_loss: 2.868788957595825
training step: 50098, total_loss: 4.188204765319824
training step: 50099, total_loss: 2.5534989833831787
training step: 50100, total_loss: 2.796506404876709
training step: 50101, total_loss: 4.997732639312744
training step: 50102, total_loss: 1.2284777164459229
training step: 50103, total_loss: 3.386754035949707
training step: 50104, total_loss: 5.173190116882324
training step: 50105, total_loss: 4.38763952255249
training step: 50106, total_loss: 5.081282615661621
training step: 50107, total_loss: 5.173852920532227
training step: 50108, total_loss: 2.754519462585449
training step: 50109, total_loss: 5.110536575317383
training step: 50110, total_loss: 4.614400863647461
training step: 50111, total_loss: 4.2279462814331055
training step: 50112, total_loss: 4.459043025970459
training step: 50113, total_loss: 6.083157539367676
training step: 50114, total_loss: 2.808907985687256
training step: 50115, total_loss: 4.03863000869751
training step: 50116, total_loss: 5.232558727264404
training step: 50117, total_loss: 4.039486408233643
training step: 50118, total_loss: 6.010819435119629
training step: 50119, total_loss: 7.230835914611816
training step: 50120, total_loss: 3.77949595451355
training step: 50121, total_loss: 4.183388710021973
training step: 50122, total_loss: 3.6752431392669678
training step: 50123, total_loss: 4.00421667098999
training step: 50124, total_loss: 4.201589584350586
training step: 50125, total_loss: 3.6307296752929688
training step: 50126, total_loss: 3.0769643783569336
training step: 50127, total_loss: 4.134240627288818
training step: 50128, total_loss: 5.637997627258301
training step: 50129, total_loss: 4.761223793029785
training step: 50130, total_loss: 4.5234832763671875
training step: 50131, total_loss: 4.689754009246826
training step: 50132, total_loss: 4.064458847045898
training step: 50133, total_loss: 4.330645561218262
training step: 50134, total_loss: 5.113659381866455
training step: 50135, total_loss: 5.819738388061523
training step: 50136, total_loss: 5.273471832275391
training step: 50137, total_loss: 4.109631538391113
training step: 50138, total_loss: 4.920910358428955
training step: 50139, total_loss: 4.381690979003906
training step: 50140, total_loss: 4.3667755126953125
training step: 50141, total_loss: 4.253329277038574
training step: 50142, total_loss: 3.980018138885498
training step: 50143, total_loss: 3.174659252166748
training step: 50144, total_loss: 6.5656232833862305
training step: 50145, total_loss: 2.9296021461486816
training step: 50146, total_loss: 5.063840389251709
training step: 50147, total_loss: 4.725162506103516
training step: 50148, total_loss: 4.798391342163086
training step: 50149, total_loss: 4.226229190826416
training step: 50150, total_loss: 4.756138801574707
training step: 50151, total_loss: 3.806264877319336
training step: 50152, total_loss: 5.176506042480469
training step: 50153, total_loss: 4.865758419036865
training step: 50154, total_loss: 3.1222777366638184
training step: 50155, total_loss: 5.1913042068481445
training step: 50156, total_loss: 2.292111396789551
training step: 50157, total_loss: 4.968822479248047
training step: 50158, total_loss: 4.244589328765869
training step: 50159, total_loss: 7.082719802856445
training step: 50160, total_loss: 4.091358661651611
training step: 50161, total_loss: 4.6181745529174805
training step: 50162, total_loss: 5.447310447692871
training step: 50163, total_loss: 1.062678337097168
training step: 50164, total_loss: 4.190389156341553
training step: 50165, total_loss: 4.604101181030273
training step: 50166, total_loss: 5.631182670593262
training step: 50167, total_loss: 4.847732067108154
training step: 50168, total_loss: 4.428027153015137
training step: 50169, total_loss: 5.2941694259643555
training step: 50170, total_loss: 5.519696235656738
training step: 50171, total_loss: 2.901754856109619
training step: 50172, total_loss: 4.597639083862305
training step: 50173, total_loss: 5.231192588806152
training step: 50174, total_loss: 5.866706848144531
training step: 50175, total_loss: 6.1126179695129395
training step: 50176, total_loss: 5.4828643798828125
training step: 50177, total_loss: 4.302056312561035
training step: 50178, total_loss: 5.2804365158081055
training step: 50179, total_loss: 4.570240497589111
training step: 50180, total_loss: 3.5316004753112793
training step: 50181, total_loss: 4.870194435119629
training step: 50182, total_loss: 4.115894317626953
training step: 50183, total_loss: 4.864377021789551
training step: 50184, total_loss: 5.856433391571045
training step: 50185, total_loss: 4.917269229888916
training step: 50186, total_loss: 3.558826446533203
training step: 50187, total_loss: 4.825514793395996
training step: 50188, total_loss: 3.367706537246704
training step: 50189, total_loss: 5.695894241333008
training step: 50190, total_loss: 5.245281219482422
training step: 50191, total_loss: 3.984358787536621
training step: 50192, total_loss: 2.270033836364746
training step: 50193, total_loss: 2.7347545623779297
training step: 50194, total_loss: 5.100547790527344
training step: 50195, total_loss: 5.249518394470215
training step: 50196, total_loss: 2.8693299293518066
training step: 50197, total_loss: 5.183526039123535
training step: 50198, total_loss: 4.468735694885254
training step: 50199, total_loss: 5.360529899597168
training step: 50200, total_loss: 1.6857540607452393
training step: 50201, total_loss: 4.587169170379639
training step: 50202, total_loss: 4.560243606567383
training step: 50203, total_loss: 4.470623016357422
training step: 50204, total_loss: 4.4078474044799805
training step: 50205, total_loss: 5.021090030670166
training step: 50206, total_loss: 3.8593575954437256
training step: 50207, total_loss: 3.1676297187805176
training step: 50208, total_loss: 0.8781991004943848
training step: 50209, total_loss: 2.9835057258605957
training step: 50210, total_loss: 6.0918474197387695
training step: 50211, total_loss: 3.179222583770752
training step: 50212, total_loss: 4.694007873535156
training step: 50213, total_loss: 4.49155855178833
training step: 50214, total_loss: 4.560235023498535
training step: 50215, total_loss: 5.530941486358643
training step: 50216, total_loss: 2.3199448585510254
training step: 50217, total_loss: 4.256866455078125
training step: 50218, total_loss: 3.6248552799224854
training step: 50219, total_loss: 4.731327056884766
training step: 50220, total_loss: 4.282747268676758
training step: 50221, total_loss: 5.274828910827637
training step: 50222, total_loss: 3.5397162437438965
training step: 50223, total_loss: 4.989574432373047
training step: 50224, total_loss: 4.784398555755615
training step: 50225, total_loss: 4.573796272277832
training step: 50226, total_loss: 5.441361427307129
training step: 50227, total_loss: 4.233992576599121
training step: 50228, total_loss: 3.087822675704956
training step: 50229, total_loss: 5.56380558013916
training step: 50230, total_loss: 5.2258195877075195
training step: 50231, total_loss: 4.776001930236816
training step: 50232, total_loss: 4.579977989196777
training step: 50233, total_loss: 3.2642438411712646
training step: 50234, total_loss: 2.749495029449463
training step: 50235, total_loss: 3.7056713104248047
training step: 50236, total_loss: 5.314531326293945
training step: 50237, total_loss: 4.953653335571289
training step: 50238, total_loss: 1.0172004699707031
training step: 50239, total_loss: 3.8745627403259277
training step: 50240, total_loss: 4.277011871337891
training step: 50241, total_loss: 4.028046607971191
training step: 50242, total_loss: 6.196131706237793
training step: 50243, total_loss: 4.9969940185546875
training step: 50244, total_loss: 4.761999607086182
training step: 50245, total_loss: 3.1249618530273438
training step: 50246, total_loss: 5.452164649963379
training step: 50247, total_loss: 3.545921564102173
training step: 50248, total_loss: 4.9869585037231445
training step: 50249, total_loss: 4.521339416503906
training step: 50250, total_loss: 5.737630844116211
training step: 50251, total_loss: 3.8158979415893555
training step: 50252, total_loss: 3.9283246994018555
training step: 50253, total_loss: 4.6421098709106445
training step: 50254, total_loss: 3.904404878616333
training step: 50255, total_loss: 2.1714158058166504
training step: 50256, total_loss: 4.7371015548706055
training step: 50257, total_loss: 6.62954044342041
training step: 50258, total_loss: 5.146103858947754
training step: 50259, total_loss: 6.213262557983398
training step: 50260, total_loss: 4.848637580871582
training step: 50261, total_loss: 4.425205230712891
training step: 50262, total_loss: 5.411654949188232
training step: 50263, total_loss: 3.605123281478882
training step: 50264, total_loss: 3.903017520904541
training step: 50265, total_loss: 4.062992095947266
training step: 50266, total_loss: 4.321042537689209
training step: 50267, total_loss: 5.211740970611572
training step: 50268, total_loss: 5.782422065734863
training step: 50269, total_loss: 4.740017890930176
training step: 50270, total_loss: 3.490358591079712
training step: 50271, total_loss: 2.6635427474975586
training step: 50272, total_loss: 6.288939476013184
training step: 50273, total_loss: 5.722661972045898
training step: 50274, total_loss: 3.867781400680542
training step: 50275, total_loss: 3.865551471710205
training step: 50276, total_loss: 0.9010576605796814
training step: 50277, total_loss: 4.361240386962891
training step: 50278, total_loss: 3.373121500015259
training step: 50279, total_loss: 1.4578734636306763
training step: 50280, total_loss: 3.991464853286743
training step: 50281, total_loss: 3.8612375259399414
training step: 50282, total_loss: 5.193025588989258
training step: 50283, total_loss: 5.40428352355957
training step: 50284, total_loss: 3.7651681900024414
training step: 50285, total_loss: 4.91544771194458
training step: 50286, total_loss: 4.263598442077637
training step: 50287, total_loss: 3.5399231910705566
training step: 50288, total_loss: 3.921574354171753
training step: 50289, total_loss: 3.2907497882843018
training step: 50290, total_loss: 4.094544410705566
training step: 50291, total_loss: 5.240324974060059
training step: 50292, total_loss: 2.9256162643432617
training step: 50293, total_loss: 4.555673122406006
training step: 50294, total_loss: 4.8067426681518555
training step: 50295, total_loss: 3.6431736946105957
training step: 50296, total_loss: 4.429771423339844
training step: 50297, total_loss: 4.457237243652344
training step: 50298, total_loss: 4.018639087677002
training step: 50299, total_loss: 0.8409279584884644
training step: 50300, total_loss: 2.865776538848877
training step: 50301, total_loss: 2.9611310958862305
training step: 50302, total_loss: 5.4684953689575195
training step: 50303, total_loss: 4.973522186279297
training step: 50304, total_loss: 3.6214699745178223
training step: 50305, total_loss: 4.975379943847656
training step: 50306, total_loss: 4.657505989074707
training step: 50307, total_loss: 3.290344715118408
training step: 50308, total_loss: 3.4450485706329346
training step: 50309, total_loss: 4.715310096740723
training step: 50310, total_loss: 4.148861408233643
training step: 50311, total_loss: 3.7901644706726074
training step: 50312, total_loss: 6.74423885345459
training step: 50313, total_loss: 3.1846938133239746
training step: 50314, total_loss: 4.945326805114746
training step: 50315, total_loss: 4.002479553222656
training step: 50316, total_loss: 4.712563991546631
training step: 50317, total_loss: 4.555266380310059
training step: 50318, total_loss: 4.028714179992676
training step: 50319, total_loss: 3.5175538063049316
training step: 50320, total_loss: 6.304409980773926
training step: 50321, total_loss: 3.2949843406677246
training step: 50322, total_loss: 7.4788713455200195
training step: 50323, total_loss: 4.179954528808594
training step: 50324, total_loss: 3.330080032348633
training step: 50325, total_loss: 2.245340347290039
training step: 50326, total_loss: 5.188871383666992
training step: 50327, total_loss: 4.305261611938477
training step: 50328, total_loss: 4.543560981750488
training step: 50329, total_loss: 5.868136405944824
training step: 50330, total_loss: 4.681801795959473
training step: 50331, total_loss: 4.783587455749512
training step: 50332, total_loss: 4.655252933502197
training step: 50333, total_loss: 4.907437324523926
training step: 50334, total_loss: 4.510548114776611
training step: 50335, total_loss: 4.818754196166992
training step: 50336, total_loss: 3.467879295349121
training step: 50337, total_loss: 4.675362586975098
training step: 50338, total_loss: 3.7751946449279785
training step: 50339, total_loss: 4.813821315765381
training step: 50340, total_loss: 3.6712379455566406
training step: 50341, total_loss: 5.487723350524902
training step: 50342, total_loss: 3.3937220573425293
training step: 50343, total_loss: 6.8201727867126465
training step: 50344, total_loss: 6.341455459594727
training step: 50345, total_loss: 4.631380081176758
training step: 50346, total_loss: 4.064598560333252
training step: 50347, total_loss: 4.2841339111328125
training step: 50348, total_loss: 4.882497310638428
training step: 50349, total_loss: 4.338873863220215
training step: 50350, total_loss: 2.5663514137268066
training step: 50351, total_loss: 3.9470081329345703
training step: 50352, total_loss: 4.488447666168213
training step: 50353, total_loss: 4.518594264984131
training step: 50354, total_loss: 4.437979698181152
training step: 50355, total_loss: 1.6295671463012695
training step: 50356, total_loss: 3.1956028938293457
training step: 50357, total_loss: 4.308189392089844
training step: 50358, total_loss: 5.356700420379639
training step: 50359, total_loss: 5.904274940490723
training step: 50360, total_loss: 3.7859296798706055
training step: 50361, total_loss: 4.330199718475342
training step: 50362, total_loss: 4.583952903747559
training step: 50363, total_loss: 5.783452987670898
training step: 50364, total_loss: 4.564750671386719
training step: 50365, total_loss: 5.603483200073242
training step: 50366, total_loss: 4.237209796905518
training step: 50367, total_loss: 4.918458938598633
training step: 50368, total_loss: 4.235705375671387
training step: 50369, total_loss: 4.596200942993164
training step: 50370, total_loss: 3.764885425567627
training step: 50371, total_loss: 5.0862932205200195
training step: 50372, total_loss: 2.738090753555298
training step: 50373, total_loss: 4.532045364379883
training step: 50374, total_loss: 4.399844646453857
training step: 50375, total_loss: 1.2226418256759644
training step: 50376, total_loss: 5.583349227905273
training step: 50377, total_loss: 5.633417129516602
training step: 50378, total_loss: 4.207289695739746
training step: 50379, total_loss: 4.827741622924805
training step: 50380, total_loss: 5.201822757720947
training step: 50381, total_loss: 4.580904483795166
training step: 50382, total_loss: 3.804309606552124
training step: 50383, total_loss: 5.902617454528809
training step: 50384, total_loss: 6.823277950286865
training step: 50385, total_loss: 3.5901103019714355
training step: 50386, total_loss: 4.9194111824035645
training step: 50387, total_loss: 4.702733993530273
training step: 50388, total_loss: 7.539057731628418
training step: 50389, total_loss: 5.412505149841309
training step: 50390, total_loss: 2.547954559326172
training step: 50391, total_loss: 2.837749719619751
training step: 50392, total_loss: 3.7697341442108154
training step: 50393, total_loss: 5.703604698181152
training step: 50394, total_loss: 4.607632160186768
training step: 50395, total_loss: 5.121335029602051
training step: 50396, total_loss: 2.490588903427124
training step: 50397, total_loss: 4.688561916351318
training step: 50398, total_loss: 4.448124885559082
training step: 50399, total_loss: 4.399540424346924
training step: 50400, total_loss: 2.640247344970703
training step: 50401, total_loss: 5.616089820861816
training step: 50402, total_loss: 4.315891265869141
training step: 50403, total_loss: 5.174487113952637
training step: 50404, total_loss: 4.061141014099121
training step: 50405, total_loss: 1.0269203186035156
training step: 50406, total_loss: 4.17525577545166
training step: 50407, total_loss: 5.01979398727417
training step: 50408, total_loss: 3.543137550354004
training step: 50409, total_loss: 4.409265518188477
training step: 50410, total_loss: 3.8876733779907227
training step: 50411, total_loss: 5.100691795349121
training step: 50412, total_loss: 4.339608669281006
training step: 50413, total_loss: 5.8369526863098145
training step: 50414, total_loss: 4.128190517425537
training step: 50415, total_loss: 4.077489852905273
training step: 50416, total_loss: 3.9551925659179688
training step: 50417, total_loss: 5.5889892578125
training step: 50418, total_loss: 4.101504325866699
training step: 50419, total_loss: 4.401135444641113
training step: 50420, total_loss: 3.9783341884613037
training step: 50421, total_loss: 2.944396495819092
training step: 50422, total_loss: 3.16937255859375
training step: 50423, total_loss: 4.371759414672852
training step: 50424, total_loss: 0.9525775909423828
training step: 50425, total_loss: 4.871383190155029
training step: 50426, total_loss: 4.440955638885498
training step: 50427, total_loss: 5.45577335357666
training step: 50428, total_loss: 5.936636447906494
training step: 50429, total_loss: 6.593923091888428
training step: 50430, total_loss: 4.30825138092041
training step: 50431, total_loss: 5.214528560638428
training step: 50432, total_loss: 3.0030388832092285
training step: 50433, total_loss: 5.807633876800537
training step: 50434, total_loss: 4.694345474243164
training step: 50435, total_loss: 3.5644564628601074
training step: 50436, total_loss: 4.6360650062561035
training step: 50437, total_loss: 6.072543144226074
training step: 50438, total_loss: 5.683193206787109
training step: 50439, total_loss: 4.220182418823242
training step: 50440, total_loss: 3.7661452293395996
training step: 50441, total_loss: 5.196415424346924
training step: 50442, total_loss: 5.212919235229492
training step: 50443, total_loss: 5.14195442199707
training step: 50444, total_loss: 2.598137855529785
training step: 50445, total_loss: 4.276622295379639
training step: 50446, total_loss: 4.536394119262695
training step: 50447, total_loss: 4.534219741821289
training step: 50448, total_loss: 4.561927795410156
training step: 50449, total_loss: 4.096894264221191
training step: 50450, total_loss: 3.452192783355713
training step: 50451, total_loss: 4.375295639038086
training step: 50452, total_loss: 4.179669380187988
training step: 50453, total_loss: 2.1208457946777344
training step: 50454, total_loss: 4.828420162200928
training step: 50455, total_loss: 5.180490016937256
training step: 50456, total_loss: 3.1698555946350098
training step: 50457, total_loss: 4.952245712280273
training step: 50458, total_loss: 5.594775199890137
training step: 50459, total_loss: 4.368185043334961
training step: 50460, total_loss: 4.2125563621521
training step: 50461, total_loss: 4.651481628417969
training step: 50462, total_loss: 3.450117588043213
training step: 50463, total_loss: 4.969247817993164
training step: 50464, total_loss: 4.806136608123779
training step: 50465, total_loss: 4.17078161239624
training step: 50466, total_loss: 5.250209808349609
training step: 50467, total_loss: 5.329140663146973
training step: 50468, total_loss: 2.4712917804718018
training step: 50469, total_loss: 3.927586555480957
training step: 50470, total_loss: 4.059770584106445
training step: 50471, total_loss: 5.618036270141602
training step: 50472, total_loss: 3.537893295288086
training step: 50473, total_loss: 3.2152762413024902
training step: 50474, total_loss: 3.79651141166687
training step: 50475, total_loss: 4.955191135406494
training step: 50476, total_loss: 6.622933387756348
training step: 50477, total_loss: 3.6351237297058105
training step: 50478, total_loss: 5.264472961425781
training step: 50479, total_loss: 4.995217323303223
training step: 50480, total_loss: 3.8327383995056152
training step: 50481, total_loss: 3.3458786010742188
training step: 50482, total_loss: 4.433959007263184
training step: 50483, total_loss: 5.077371597290039
training step: 50484, total_loss: 3.654222249984741
training step: 50485, total_loss: 4.038791656494141
training step: 50486, total_loss: 3.8547677993774414
training step: 50487, total_loss: 5.044557571411133
training step: 50488, total_loss: 6.846314907073975
training step: 50489, total_loss: 2.9854655265808105
training step: 50490, total_loss: 4.712322235107422
training step: 50491, total_loss: 4.292323112487793
training step: 50492, total_loss: 4.42466402053833
training step: 50493, total_loss: 4.695673942565918
training step: 50494, total_loss: 3.274660348892212
training step: 50495, total_loss: 4.249159812927246
training step: 50496, total_loss: 2.8062572479248047
training step: 50497, total_loss: 4.135689735412598
training step: 50498, total_loss: 4.594700813293457
training step: 50499, total_loss: 5.609570503234863
training step: 50500, total_loss: 3.441215753555298
training step: 50501, total_loss: 3.4415411949157715
training step: 50502, total_loss: 3.88555645942688
training step: 50503, total_loss: 4.061059951782227
training step: 50504, total_loss: 6.742884635925293
training step: 50505, total_loss: 2.5922670364379883
training step: 50506, total_loss: 3.6938016414642334
training step: 50507, total_loss: 4.659511566162109
training step: 50508, total_loss: 3.6749117374420166
training step: 50509, total_loss: 4.149011135101318
training step: 50510, total_loss: 3.8426830768585205
training step: 50511, total_loss: 3.238299608230591
training step: 50512, total_loss: 3.7659752368927
training step: 50513, total_loss: 4.633273124694824
training step: 50514, total_loss: 4.72910737991333
training step: 50515, total_loss: 4.548664093017578
training step: 50516, total_loss: 4.271780490875244
training step: 50517, total_loss: 4.222780704498291
training step: 50518, total_loss: 5.815192222595215
training step: 50519, total_loss: 2.4256954193115234
training step: 50520, total_loss: 3.3614866733551025
training step: 50521, total_loss: 4.729432106018066
training step: 50522, total_loss: 4.828413009643555
training step: 50523, total_loss: 3.584364891052246
training step: 50524, total_loss: 4.559015274047852
training step: 50525, total_loss: 4.281776428222656
training step: 50526, total_loss: 5.008057594299316
training step: 50527, total_loss: 4.512125015258789
training step: 50528, total_loss: 4.991454601287842
training step: 50529, total_loss: 6.44289493560791
training step: 50530, total_loss: 5.695631980895996
training step: 50531, total_loss: 5.390474796295166
training step: 50532, total_loss: 4.445079803466797
training step: 50533, total_loss: 4.378377914428711
training step: 50534, total_loss: 4.688806533813477
training step: 50535, total_loss: 3.1583328247070312
training step: 50536, total_loss: 2.9508299827575684
training step: 50537, total_loss: 4.136725425720215
training step: 50538, total_loss: 4.281167030334473
training step: 50539, total_loss: 3.7173404693603516
training step: 50540, total_loss: 5.066857814788818
training step: 50541, total_loss: 4.6415181159973145
training step: 50542, total_loss: 3.418893814086914
training step: 50543, total_loss: 3.686647891998291
training step: 50544, total_loss: 3.9354982376098633
training step: 50545, total_loss: 3.999696731567383
training step: 50546, total_loss: 3.973872661590576
training step: 50547, total_loss: 6.376867771148682
training step: 50548, total_loss: 2.814833164215088
training step: 50549, total_loss: 3.082371234893799
training step: 50550, total_loss: 4.002843856811523
training step: 50551, total_loss: 4.486841201782227
training step: 50552, total_loss: 3.7352724075317383
training step: 50553, total_loss: 4.122851848602295
training step: 50554, total_loss: 3.3063178062438965
training step: 50555, total_loss: 3.9991750717163086
training step: 50556, total_loss: 4.383806228637695
training step: 50557, total_loss: 4.908627033233643
training step: 50558, total_loss: 4.878076553344727
training step: 50559, total_loss: 2.4518423080444336
training step: 50560, total_loss: 2.936880588531494
training step: 50561, total_loss: 3.1014838218688965
training step: 50562, total_loss: 4.28662109375
training step: 50563, total_loss: 5.261703014373779
training step: 50564, total_loss: 6.102012634277344
training step: 50565, total_loss: 3.150906801223755
training step: 50566, total_loss: 5.220213890075684
training step: 50567, total_loss: 5.778181076049805
training step: 50568, total_loss: 4.116933822631836
training step: 50569, total_loss: 3.8672432899475098
training step: 50570, total_loss: 4.844260215759277
training step: 50571, total_loss: 3.54636287689209
training step: 50572, total_loss: 5.538886547088623
training step: 50573, total_loss: 4.0929059982299805
training step: 50574, total_loss: 5.220757484436035
training step: 50575, total_loss: 4.027255058288574
training step: 50576, total_loss: 4.936850070953369
training step: 50577, total_loss: 5.7784929275512695
training step: 50578, total_loss: 3.3533616065979004
training step: 50579, total_loss: 3.2655513286590576
training step: 50580, total_loss: 5.309567451477051
training step: 50581, total_loss: 4.394847393035889
training step: 50582, total_loss: 5.425118923187256
training step: 50583, total_loss: 4.240475654602051
training step: 50584, total_loss: 2.5683882236480713
training step: 50585, total_loss: 4.248171329498291
training step: 50586, total_loss: 4.168447494506836
training step: 50587, total_loss: 3.848475933074951
training step: 50588, total_loss: 2.3639705181121826
training step: 50589, total_loss: 3.791436195373535
training step: 50590, total_loss: 2.505138397216797
training step: 50591, total_loss: 3.012869358062744
training step: 50592, total_loss: 4.903470993041992
training step: 50593, total_loss: 2.714261770248413
training step: 50594, total_loss: 5.988574028015137
training step: 50595, total_loss: 4.0774922370910645
training step: 50596, total_loss: 4.566329002380371
training step: 50597, total_loss: 3.5202932357788086
training step: 50598, total_loss: 3.2057743072509766
training step: 50599, total_loss: 4.431788444519043
training step: 50600, total_loss: 5.308962345123291
training step: 50601, total_loss: 4.688874244689941
training step: 50602, total_loss: 3.5878005027770996
training step: 50603, total_loss: 4.685538291931152
training step: 50604, total_loss: 4.783974647521973
training step: 50605, total_loss: 3.869347095489502
training step: 50606, total_loss: 5.393130302429199
training step: 50607, total_loss: 4.6740946769714355
training step: 50608, total_loss: 4.368710517883301
training step: 50609, total_loss: 3.829533576965332
training step: 50610, total_loss: 3.607451915740967
training step: 50611, total_loss: 2.6422739028930664
training step: 50612, total_loss: 5.962971210479736
training step: 50613, total_loss: 3.8362197875976562
training step: 50614, total_loss: 4.982478141784668
training step: 50615, total_loss: 4.303609848022461
training step: 50616, total_loss: 4.34669303894043
training step: 50617, total_loss: 2.832892894744873
training step: 50618, total_loss: 5.0841217041015625
training step: 50619, total_loss: 5.531354904174805
training step: 50620, total_loss: 5.013766288757324
training step: 50621, total_loss: 2.8561151027679443
training step: 50622, total_loss: 3.450993061065674
training step: 50623, total_loss: 4.181542873382568
training step: 50624, total_loss: 4.867454528808594
training step: 50625, total_loss: 4.291621208190918
training step: 50626, total_loss: 4.798569202423096
training step: 50627, total_loss: 4.595458030700684
training step: 50628, total_loss: 5.316948890686035
training step: 50629, total_loss: 3.998730421066284
training step: 50630, total_loss: 5.781756401062012
training step: 50631, total_loss: 2.409825325012207
training step: 50632, total_loss: 5.081162452697754
training step: 50633, total_loss: 3.766993522644043
training step: 50634, total_loss: 5.911772727966309
training step: 50635, total_loss: 3.889188289642334
training step: 50636, total_loss: 4.614177227020264
training step: 50637, total_loss: 2.256424903869629
training step: 50638, total_loss: 2.5460472106933594
training step: 50639, total_loss: 4.244378089904785
training step: 50640, total_loss: 4.527566432952881
training step: 50641, total_loss: 5.649740219116211
training step: 50642, total_loss: 2.7039594650268555
training step: 50643, total_loss: 5.373114585876465
training step: 50644, total_loss: 1.2840330600738525
training step: 50645, total_loss: 4.5269060134887695
training step: 50646, total_loss: 1.1280319690704346
training step: 50647, total_loss: 5.82585334777832
training step: 50648, total_loss: 4.54844331741333
training step: 50649, total_loss: 4.525452613830566
training step: 50650, total_loss: 5.8299455642700195
training step: 50651, total_loss: 3.1661312580108643
training step: 50652, total_loss: 4.598948001861572
training step: 50653, total_loss: 3.3344674110412598
training step: 50654, total_loss: 4.104767799377441
training step: 50655, total_loss: 5.6070780754089355
training step: 50656, total_loss: 4.113117218017578
training step: 50657, total_loss: 5.564400672912598
training step: 50658, total_loss: 2.5844221115112305
training step: 50659, total_loss: 3.7897231578826904
training step: 50660, total_loss: 4.998072624206543
training step: 50661, total_loss: 4.203949928283691
training step: 50662, total_loss: 5.359020709991455
training step: 50663, total_loss: 5.0215911865234375
training step: 50664, total_loss: 4.183628082275391
training step: 50665, total_loss: 3.808373212814331
training step: 50666, total_loss: 4.360123634338379
training step: 50667, total_loss: 4.407894134521484
training step: 50668, total_loss: 3.601151704788208
training step: 50669, total_loss: 4.49793815612793
training step: 50670, total_loss: 4.353845596313477
training step: 50671, total_loss: 5.690892696380615
training step: 50672, total_loss: 3.1726105213165283
training step: 50673, total_loss: 4.496316432952881
training step: 50674, total_loss: 4.210728645324707
training step: 50675, total_loss: 4.703948020935059
training step: 50676, total_loss: 2.621490478515625
training step: 50677, total_loss: 5.816543102264404
training step: 50678, total_loss: 5.364778995513916
training step: 50679, total_loss: 3.1200811862945557
training step: 50680, total_loss: 5.523982524871826
training step: 50681, total_loss: 4.22020149230957
training step: 50682, total_loss: 5.641218185424805
training step: 50683, total_loss: 4.880163192749023
training step: 50684, total_loss: 5.570626258850098
training step: 50685, total_loss: 4.345949172973633
training step: 50686, total_loss: 2.654815196990967
training step: 50687, total_loss: 5.145020008087158
training step: 50688, total_loss: 3.491593360900879
training step: 50689, total_loss: 4.165842056274414
training step: 50690, total_loss: 3.542233943939209
training step: 50691, total_loss: 4.87020206451416
training step: 50692, total_loss: 3.5899853706359863
training step: 50693, total_loss: 5.4261932373046875
training step: 50694, total_loss: 3.133610725402832
training step: 50695, total_loss: 3.7791571617126465
training step: 50696, total_loss: 3.0340020656585693
training step: 50697, total_loss: 4.389647483825684
training step: 50698, total_loss: 6.469302177429199
training step: 50699, total_loss: 3.302586317062378
training step: 50700, total_loss: 5.257140159606934
training step: 50701, total_loss: 4.260192394256592
training step: 50702, total_loss: 4.159218788146973
training step: 50703, total_loss: 4.850956916809082
training step: 50704, total_loss: 3.441026210784912
training step: 50705, total_loss: 5.234930038452148
training step: 50706, total_loss: 3.028270721435547
training step: 50707, total_loss: 3.3589000701904297
training step: 50708, total_loss: 3.4833059310913086
training step: 50709, total_loss: 4.834702491760254
training step: 50710, total_loss: 4.045808792114258
training step: 50711, total_loss: 2.8173460960388184
training step: 50712, total_loss: 4.468657493591309
training step: 50713, total_loss: 3.119666576385498
training step: 50714, total_loss: 2.4678006172180176
training step: 50715, total_loss: 3.287327289581299
training step: 50716, total_loss: 4.485898494720459
training step: 50717, total_loss: 3.2975873947143555
training step: 50718, total_loss: 3.278323173522949
training step: 50719, total_loss: 5.885476112365723
training step: 50720, total_loss: 4.191336154937744
training step: 50721, total_loss: 4.062774181365967
training step: 50722, total_loss: 0.7790000438690186
training step: 50723, total_loss: 4.518135070800781
training step: 50724, total_loss: 4.828063011169434
training step: 50725, total_loss: 6.763233661651611
training step: 50726, total_loss: 4.398249626159668
training step: 50727, total_loss: 3.897894859313965
training step: 50728, total_loss: 4.202258110046387
training step: 50729, total_loss: 2.334322929382324
training step: 50730, total_loss: 2.9943079948425293
training step: 50731, total_loss: 6.476713180541992
training step: 50732, total_loss: 6.066563129425049
training step: 50733, total_loss: 4.32961893081665
training step: 50734, total_loss: 4.152059555053711
training step: 50735, total_loss: 2.2212839126586914
training step: 50736, total_loss: 0.9336259365081787
training step: 50737, total_loss: 3.5459721088409424
training step: 50738, total_loss: 4.037580490112305
training step: 50739, total_loss: 4.907170295715332
training step: 50740, total_loss: 5.308213233947754
training step: 50741, total_loss: 6.054213523864746
training step: 50742, total_loss: 4.149158000946045
training step: 50743, total_loss: 0.9225708246231079
training step: 50744, total_loss: 5.204964637756348
training step: 50745, total_loss: 5.257817268371582
training step: 50746, total_loss: 5.443297386169434
training step: 50747, total_loss: 4.905999660491943
training step: 50748, total_loss: 4.093791961669922
training step: 50749, total_loss: 6.065705299377441
training step: 50750, total_loss: 4.234543800354004
training step: 50751, total_loss: 6.284237384796143
training step: 50752, total_loss: 4.059050559997559
training step: 50753, total_loss: 5.492055892944336
training step: 50754, total_loss: 3.985208511352539
training step: 50755, total_loss: 5.0674214363098145
training step: 50756, total_loss: 4.14357852935791
training step: 50757, total_loss: 4.16719388961792
training step: 50758, total_loss: 4.3467488288879395
training step: 50759, total_loss: 4.086209774017334
training step: 50760, total_loss: 5.265745162963867
training step: 50761, total_loss: 3.4681084156036377
training step: 50762, total_loss: 5.372383117675781
training step: 50763, total_loss: 5.044143199920654
training step: 50764, total_loss: 3.834671974182129
training step: 50765, total_loss: 4.358695983886719
training step: 50766, total_loss: 4.166008949279785
training step: 50767, total_loss: 4.033474922180176
training step: 50768, total_loss: 3.52290678024292
training step: 50769, total_loss: 4.640216827392578
training step: 50770, total_loss: 4.099952697753906
training step: 50771, total_loss: 5.131133556365967
training step: 50772, total_loss: 2.3812007904052734
training step: 50773, total_loss: 4.6641526222229
training step: 50774, total_loss: 3.196027994155884
training step: 50775, total_loss: 5.5470194816589355
training step: 50776, total_loss: 5.278285026550293
training step: 50777, total_loss: 4.896710395812988
training step: 50778, total_loss: 4.015612602233887
training step: 50779, total_loss: 4.503136157989502
training step: 50780, total_loss: 4.179960250854492
training step: 50781, total_loss: 4.222936630249023
training step: 50782, total_loss: 4.741759300231934
training step: 50783, total_loss: 5.086901664733887
training step: 50784, total_loss: 4.370296955108643
training step: 50785, total_loss: 5.019186973571777
training step: 50786, total_loss: 2.5855183601379395
training step: 50787, total_loss: 2.9909982681274414
training step: 50788, total_loss: 4.056916236877441
training step: 50789, total_loss: 4.388739109039307
training step: 50790, total_loss: 5.015328407287598
training step: 50791, total_loss: 5.116438865661621
training step: 50792, total_loss: 4.719985008239746
training step: 50793, total_loss: 4.547388076782227
training step: 50794, total_loss: 4.426949501037598
training step: 50795, total_loss: 3.850947856903076
training step: 50796, total_loss: 4.758061408996582
training step: 50797, total_loss: 4.229481220245361
training step: 50798, total_loss: 3.2332046031951904
training step: 50799, total_loss: 3.1500678062438965
training step: 50800, total_loss: 3.2662453651428223
training step: 50801, total_loss: 2.8846797943115234
training step: 50802, total_loss: 3.257904052734375
training step: 50803, total_loss: 0.9999169707298279
training step: 50804, total_loss: 4.668227195739746
training step: 50805, total_loss: 4.337718486785889
training step: 50806, total_loss: 3.041095733642578
training step: 50807, total_loss: 4.986874103546143
training step: 50808, total_loss: 4.381341457366943
training step: 50809, total_loss: 5.77923059463501
training step: 50810, total_loss: 3.948910713195801
training step: 50811, total_loss: 4.300468444824219
training step: 50812, total_loss: 4.532042026519775
training step: 50813, total_loss: 2.297969102859497
training step: 50814, total_loss: 2.416090488433838
training step: 50815, total_loss: 4.707285404205322
training step: 50816, total_loss: 4.803797721862793
training step: 50817, total_loss: 4.2447829246521
training step: 50818, total_loss: 4.246817588806152
training step: 50819, total_loss: 4.252396583557129
training step: 50820, total_loss: 5.580667972564697
training step: 50821, total_loss: 6.218116760253906
training step: 50822, total_loss: 4.30487060546875
training step: 50823, total_loss: 4.900336265563965
training step: 50824, total_loss: 3.194365978240967
training step: 50825, total_loss: 4.935789108276367
training step: 50826, total_loss: 5.537724018096924
training step: 50827, total_loss: 5.324222564697266
training step: 50828, total_loss: 5.246288299560547
training step: 50829, total_loss: 4.97265625
training step: 50830, total_loss: 4.913608074188232
training step: 50831, total_loss: 4.6073527336120605
training step: 50832, total_loss: 3.7284350395202637
training step: 50833, total_loss: 4.806931495666504
training step: 50834, total_loss: 5.040225028991699
training step: 50835, total_loss: 4.317157745361328
training step: 50836, total_loss: 0.9775657653808594
training step: 50837, total_loss: 5.130413055419922
training step: 50838, total_loss: 3.765305280685425
training step: 50839, total_loss: 3.180325984954834
training step: 50840, total_loss: 2.5478978157043457
training step: 50841, total_loss: 2.9252824783325195
training step: 50842, total_loss: 4.863503932952881
training step: 50843, total_loss: 3.9496922492980957
training step: 50844, total_loss: 4.424465179443359
training step: 50845, total_loss: 3.745328903198242
training step: 50846, total_loss: 4.141293525695801
training step: 50847, total_loss: 3.6800708770751953
training step: 50848, total_loss: 4.34476900100708
training step: 50849, total_loss: 4.094766616821289
training step: 50850, total_loss: 4.894116401672363
training step: 50851, total_loss: 4.591131210327148
training step: 50852, total_loss: 4.77164363861084
training step: 50853, total_loss: 6.092568397521973
training step: 50854, total_loss: 3.347747325897217
training step: 50855, total_loss: 3.088716745376587
training step: 50856, total_loss: 0.8952392935752869
training step: 50857, total_loss: 4.462614059448242
training step: 50858, total_loss: 3.75956130027771
training step: 50859, total_loss: 2.636723518371582
training step: 50860, total_loss: 3.4465346336364746
training step: 50861, total_loss: 3.946732521057129
training step: 50862, total_loss: 3.2449140548706055
training step: 50863, total_loss: 5.669936180114746
training step: 50864, total_loss: 3.3212180137634277
training step: 50865, total_loss: 4.010744571685791
training step: 50866, total_loss: 4.658048629760742
training step: 50867, total_loss: 5.735952377319336
training step: 50868, total_loss: 4.401549816131592
training step: 50869, total_loss: 4.070503234863281
training step: 50870, total_loss: 5.27076530456543
training step: 50871, total_loss: 4.388204097747803
training step: 50872, total_loss: 4.128464698791504
training step: 50873, total_loss: 2.3288450241088867
training step: 50874, total_loss: 4.567363262176514
training step: 50875, total_loss: 3.584826946258545
training step: 50876, total_loss: 5.931410789489746
training step: 50877, total_loss: 4.65106201171875
training step: 50878, total_loss: 4.427035331726074
training step: 50879, total_loss: 5.154709815979004
training step: 50880, total_loss: 4.6177167892456055
training step: 50881, total_loss: 3.896975040435791
training step: 50882, total_loss: 5.594944000244141
training step: 50883, total_loss: 3.465883493423462
training step: 50884, total_loss: 4.021766662597656
training step: 50885, total_loss: 4.139654636383057
training step: 50886, total_loss: 4.9583420753479
training step: 50887, total_loss: 4.257339000701904
training step: 50888, total_loss: 3.0148868560791016
training step: 50889, total_loss: 3.333498954772949
training step: 50890, total_loss: 3.8444480895996094
training step: 50891, total_loss: 3.8930091857910156
training step: 50892, total_loss: 4.239198207855225
training step: 50893, total_loss: 3.5159711837768555
training step: 50894, total_loss: 4.451871395111084
training step: 50895, total_loss: 3.549910068511963
training step: 50896, total_loss: 3.4665117263793945
training step: 50897, total_loss: 4.496705055236816
training step: 50898, total_loss: 8.75381088256836
training step: 50899, total_loss: 1.9517453908920288
training step: 50900, total_loss: 5.524558067321777
training step: 50901, total_loss: 5.579600811004639
training step: 50902, total_loss: 4.611268997192383
training step: 50903, total_loss: 4.666426658630371
training step: 50904, total_loss: 5.213523864746094
training step: 50905, total_loss: 3.6702613830566406
training step: 50906, total_loss: 4.515048980712891
training step: 50907, total_loss: 4.919724464416504
training step: 50908, total_loss: 5.154988765716553
training step: 50909, total_loss: 4.232256889343262
training step: 50910, total_loss: 4.437839508056641
training step: 50911, total_loss: 4.665555953979492
training step: 50912, total_loss: 3.928893566131592
training step: 50913, total_loss: 3.1566970348358154
training step: 50914, total_loss: 5.158860206604004
training step: 50915, total_loss: 4.39135217666626
training step: 50916, total_loss: 5.1173810958862305
training step: 50917, total_loss: 6.197301864624023
training step: 50918, total_loss: 4.08100700378418
training step: 50919, total_loss: 5.39836311340332INFO:tensorflow:Writing predictions to: residual_output/predictions_51000.json
INFO:tensorflow:Writing nbest to: residual_output/nbest_predictions_51000.json

training step: 50920, total_loss: 4.441190242767334
training step: 50921, total_loss: 5.103103160858154
training step: 50922, total_loss: 5.304083824157715
training step: 50923, total_loss: 3.6890857219696045
training step: 50924, total_loss: 3.7647337913513184
training step: 50925, total_loss: 4.1834259033203125
training step: 50926, total_loss: 4.228878974914551
training step: 50927, total_loss: 4.044529914855957
training step: 50928, total_loss: 6.004077911376953
training step: 50929, total_loss: 3.1134753227233887
training step: 50930, total_loss: 5.170542240142822
training step: 50931, total_loss: 5.655819416046143
training step: 50932, total_loss: 4.174742698669434
training step: 50933, total_loss: 6.000300407409668
training step: 50934, total_loss: 5.596268653869629
training step: 50935, total_loss: 3.396012783050537
training step: 50936, total_loss: 4.2857818603515625
training step: 50937, total_loss: 4.624510288238525
training step: 50938, total_loss: 4.1114115715026855
training step: 50939, total_loss: 4.033257961273193
training step: 50940, total_loss: 2.425684928894043
training step: 50941, total_loss: 5.272614479064941
training step: 50942, total_loss: 3.191127300262451
training step: 50943, total_loss: 3.894728660583496
training step: 50944, total_loss: 4.8032636642456055
training step: 50945, total_loss: 4.356997489929199
training step: 50946, total_loss: 4.285732269287109
training step: 50947, total_loss: 4.310379981994629
training step: 50948, total_loss: 4.377100467681885
training step: 50949, total_loss: 4.538728713989258
training step: 50950, total_loss: 5.023913383483887
training step: 50951, total_loss: 3.7588400840759277
training step: 50952, total_loss: 3.497387170791626
training step: 50953, total_loss: 2.9635891914367676
training step: 50954, total_loss: 4.6876935958862305
training step: 50955, total_loss: 4.458647727966309
training step: 50956, total_loss: 4.070752143859863
training step: 50957, total_loss: 3.325923442840576
training step: 50958, total_loss: 4.831056594848633
training step: 50959, total_loss: 4.479857444763184
training step: 50960, total_loss: 2.944481611251831
training step: 50961, total_loss: 4.416377067565918
training step: 50962, total_loss: 4.508310317993164
training step: 50963, total_loss: 5.325982093811035
training step: 50964, total_loss: 3.4363718032836914
training step: 50965, total_loss: 5.218843460083008
training step: 50966, total_loss: 3.9947080612182617
training step: 50967, total_loss: 4.333511829376221
training step: 50968, total_loss: 4.960620880126953
training step: 50969, total_loss: 6.787081718444824
training step: 50970, total_loss: 3.676619052886963
training step: 50971, total_loss: 5.254331111907959
training step: 50972, total_loss: 5.105025768280029
training step: 50973, total_loss: 4.295928478240967
training step: 50974, total_loss: 5.3937788009643555
training step: 50975, total_loss: 4.525960922241211
training step: 50976, total_loss: 2.0144684314727783
training step: 50977, total_loss: 4.896378993988037
training step: 50978, total_loss: 4.9271650314331055
training step: 50979, total_loss: 3.9568874835968018
training step: 50980, total_loss: 4.641538143157959
training step: 50981, total_loss: 2.8443527221679688
training step: 50982, total_loss: 2.7130231857299805
training step: 50983, total_loss: 4.879693031311035
training step: 50984, total_loss: 3.657276153564453
training step: 50985, total_loss: 4.7582926750183105
training step: 50986, total_loss: 4.879920482635498
training step: 50987, total_loss: 2.3879594802856445
training step: 50988, total_loss: 4.89797306060791
training step: 50989, total_loss: 3.6784260272979736
training step: 50990, total_loss: 4.263721466064453
training step: 50991, total_loss: 2.1905972957611084
training step: 50992, total_loss: 5.3029279708862305
training step: 50993, total_loss: 3.970980405807495
training step: 50994, total_loss: 4.312742710113525
training step: 50995, total_loss: 4.537074089050293
training step: 50996, total_loss: 4.446656703948975
training step: 50997, total_loss: 4.63104248046875
training step: 50998, total_loss: 5.108391761779785
training step: 50999, total_loss: 4.321177959442139
training step: 51000, total_loss: 4.525538444519043
epoch finished! shuffle=False
evaluation: 51000, total_loss: 2.3197829723358154, f1: 23.167776861638345, followup: 18.378213905370455, yesno: 1.6126578426897915, heq: 22.62285105735585, dheq: 0.6

Model saved in path residual_output//model_51000.ckpt
training step: 51001, total_loss: 4.860148906707764
training step: 51002, total_loss: 5.763581275939941
training step: 51003, total_loss: 4.83942985534668
training step: 51004, total_loss: 5.041505336761475
training step: 51005, total_loss: 2.836594820022583
training step: 51006, total_loss: 3.8481709957122803
training step: 51007, total_loss: 5.294086456298828
training step: 51008, total_loss: 5.813820838928223
training step: 51009, total_loss: 4.128024101257324
training step: 51010, total_loss: 4.672111511230469
training step: 51011, total_loss: 3.6825995445251465
training step: 51012, total_loss: 2.8250720500946045
training step: 51013, total_loss: 4.515470027923584
training step: 51014, total_loss: 3.300952911376953
training step: 51015, total_loss: 4.485302448272705
training step: 51016, total_loss: 5.981986045837402
training step: 51017, total_loss: 4.2318315505981445
training step: 51018, total_loss: 7.007737159729004
training step: 51019, total_loss: 4.609457969665527
training step: 51020, total_loss: 3.8098788261413574
training step: 51021, total_loss: 4.637322425842285
training step: 51022, total_loss: 4.0826640129089355
training step: 51023, total_loss: 2.813045024871826
training step: 51024, total_loss: 5.135767459869385
training step: 51025, total_loss: 3.4582982063293457
training step: 51026, total_loss: 4.841020584106445
training step: 51027, total_loss: 6.648738861083984
training step: 51028, total_loss: 4.744368553161621
training step: 51029, total_loss: 5.355447769165039
training step: 51030, total_loss: 3.0930256843566895
training step: 51031, total_loss: 4.361183166503906
training step: 51032, total_loss: 5.064990997314453
training step: 51033, total_loss: 6.49259090423584
training step: 51034, total_loss: 1.013002872467041
training step: 51035, total_loss: 4.396381378173828
training step: 51036, total_loss: 4.300768852233887
training step: 51037, total_loss: 2.1852595806121826
training step: 51038, total_loss: 3.7747647762298584
training step: 51039, total_loss: 4.440335273742676
training step: 51040, total_loss: 4.311758995056152
training step: 51041, total_loss: 1.1371533870697021
training step: 51042, total_loss: 2.5939793586730957
training step: 51043, total_loss: 4.0867815017700195
training step: 51044, total_loss: 3.9941515922546387
training step: 51045, total_loss: 4.761188507080078
training step: 51046, total_loss: 4.506661891937256
training step: 51047, total_loss: 1.0887744426727295
training step: 51048, total_loss: 3.766350269317627
training step: 51049, total_loss: 5.992514133453369
training step: 51050, total_loss: 4.118199348449707
training step: 51051, total_loss: 4.07805871963501
training step: 51052, total_loss: 4.9206953048706055
training step: 51053, total_loss: 3.222560405731201
training step: 51054, total_loss: 4.130102634429932
training step: 51055, total_loss: 4.249773025512695
training step: 51056, total_loss: 4.950382709503174
training step: 51057, total_loss: 4.669557094573975
training step: 51058, total_loss: 3.367558479309082
training step: 51059, total_loss: 3.844135284423828
training step: 51060, total_loss: 4.810656547546387
training step: 51061, total_loss: 4.245787620544434
training step: 51062, total_loss: 3.839468479156494
training step: 51063, total_loss: 5.593708038330078
training step: 51064, total_loss: 4.630396842956543
training step: 51065, total_loss: 1.016309380531311
training step: 51066, total_loss: 2.3917534351348877
training step: 51067, total_loss: 4.243888854980469
training step: 51068, total_loss: 4.132784843444824
training step: 51069, total_loss: 4.474676132202148
training step: 51070, total_loss: 4.4216532707214355
training step: 51071, total_loss: 3.839351177215576
training step: 51072, total_loss: 3.561570644378662
training step: 51073, total_loss: 6.2709527015686035
training step: 51074, total_loss: 3.395282745361328
training step: 51075, total_loss: 4.5319719314575195
training step: 51076, total_loss: 4.51701021194458
training step: 51077, total_loss: 5.120683670043945
training step: 51078, total_loss: 4.34437894821167
training step: 51079, total_loss: 3.8850741386413574
training step: 51080, total_loss: 3.793828248977661
training step: 51081, total_loss: 5.285621166229248
training step: 51082, total_loss: 4.367849826812744
training step: 51083, total_loss: 2.9964680671691895
training step: 51084, total_loss: 4.992673873901367
training step: 51085, total_loss: 6.653193473815918
training step: 51086, total_loss: 5.917466640472412
training step: 51087, total_loss: 3.9390499591827393
training step: 51088, total_loss: 4.68995475769043
training step: 51089, total_loss: 3.735487461090088
training step: 51090, total_loss: 5.4725494384765625
training step: 51091, total_loss: 4.995418548583984
training step: 51092, total_loss: 3.9669535160064697
training step: 51093, total_loss: 4.264758110046387
training step: 51094, total_loss: 3.980423927307129
training step: 51095, total_loss: 5.379193305969238
training step: 51096, total_loss: 5.306639671325684
training step: 51097, total_loss: 1.3313593864440918
training step: 51098, total_loss: 5.093884468078613
training step: 51099, total_loss: 5.233489513397217
training step: 51100, total_loss: 4.766171455383301
training step: 51101, total_loss: 4.330770492553711
training step: 51102, total_loss: 4.297040939331055
training step: 51103, total_loss: 6.249294281005859
training step: 51104, total_loss: 4.000943183898926
training step: 51105, total_loss: 3.010049819946289
training step: 51106, total_loss: 1.1346989870071411
training step: 51107, total_loss: 6.1849751472473145
training step: 51108, total_loss: 3.686528205871582
training step: 51109, total_loss: 4.984234809875488
training step: 51110, total_loss: 3.8488876819610596
training step: 51111, total_loss: 4.817066192626953
training step: 51112, total_loss: 2.434349536895752
training step: 51113, total_loss: 2.7056994438171387
training step: 51114, total_loss: 6.9103498458862305
training step: 51115, total_loss: 4.487105369567871
training step: 51116, total_loss: 4.321941375732422
training step: 51117, total_loss: 4.546197891235352
training step: 51118, total_loss: 4.967801570892334
training step: 51119, total_loss: 4.103691101074219
training step: 51120, total_loss: 3.7395873069763184
training step: 51121, total_loss: 4.878442764282227
training step: 51122, total_loss: 4.237618446350098
training step: 51123, total_loss: 2.785163402557373
training step: 51124, total_loss: 5.2235212326049805
training step: 51125, total_loss: 3.293038845062256
training step: 51126, total_loss: 4.654878616333008
training step: 51127, total_loss: 5.429834365844727
training step: 51128, total_loss: 3.8323183059692383
training step: 51129, total_loss: 1.4508134126663208
training step: 51130, total_loss: 0.970971941947937
training step: 51131, total_loss: 3.967496871948242
training step: 51132, total_loss: 5.896867752075195
training step: 51133, total_loss: 4.475813388824463
training step: 51134, total_loss: 2.8211023807525635
training step: 51135, total_loss: 4.695173263549805
training step: 51136, total_loss: 1.8420476913452148
training step: 51137, total_loss: 4.125400066375732
training step: 51138, total_loss: 4.181537628173828
training step: 51139, total_loss: 4.42329740524292
training step: 51140, total_loss: 4.5049543380737305
training step: 51141, total_loss: 4.45330810546875
training step: 51142, total_loss: 0.8627541065216064
training step: 51143, total_loss: 4.5854315757751465
training step: 51144, total_loss: 3.0057334899902344
training step: 51145, total_loss: 4.708033561706543
training step: 51146, total_loss: 3.6559014320373535
training step: 51147, total_loss: 4.34108304977417
training step: 51148, total_loss: 5.309189796447754
training step: 51149, total_loss: 3.529616355895996
training step: 51150, total_loss: 3.965561866760254
training step: 51151, total_loss: 4.941071033477783
training step: 51152, total_loss: 2.6814141273498535
training step: 51153, total_loss: 4.079373359680176
training step: 51154, total_loss: 3.5416579246520996
training step: 51155, total_loss: 0.9241056442260742
training step: 51156, total_loss: 4.183828830718994
training step: 51157, total_loss: 4.556684970855713
training step: 51158, total_loss: 4.40932559967041
training step: 51159, total_loss: 3.9327778816223145
training step: 51160, total_loss: 5.543034553527832
training step: 51161, total_loss: 4.064133167266846
training step: 51162, total_loss: 7.502862930297852
training step: 51163, total_loss: 4.429430961608887
training step: 51164, total_loss: 3.9984402656555176
training step: 51165, total_loss: 5.523753643035889
training step: 51166, total_loss: 2.527752161026001
training step: 51167, total_loss: 2.5657150745391846
training step: 51168, total_loss: 5.426136016845703
training step: 51169, total_loss: 5.681756019592285
training step: 51170, total_loss: 3.3845105171203613
training step: 51171, total_loss: 5.269664764404297
training step: 51172, total_loss: 0.8891630172729492
training step: 51173, total_loss: 4.3192267417907715
training step: 51174, total_loss: 3.2387442588806152
training step: 51175, total_loss: 3.282116413116455
training step: 51176, total_loss: 4.654276371002197
training step: 51177, total_loss: 5.368675231933594
training step: 51178, total_loss: 5.125182628631592
training step: 51179, total_loss: 3.993558883666992
training step: 51180, total_loss: 4.147450923919678
training step: 51181, total_loss: 4.658773422241211
training step: 51182, total_loss: 4.265810966491699
training step: 51183, total_loss: 5.55822229385376
training step: 51184, total_loss: 4.449271202087402
training step: 51185, total_loss: 5.530868053436279
training step: 51186, total_loss: 5.312126159667969
training step: 51187, total_loss: 3.127521514892578
training step: 51188, total_loss: 4.230264186859131
training step: 51189, total_loss: 4.230222702026367
training step: 51190, total_loss: 3.7177700996398926
training step: 51191, total_loss: 3.6516213417053223
training step: 51192, total_loss: 3.38278865814209
training step: 51193, total_loss: 3.8543801307678223
training step: 51194, total_loss: 3.4313535690307617
training step: 51195, total_loss: 5.484562873840332
training step: 51196, total_loss: 5.693748474121094
training step: 51197, total_loss: 3.2057623863220215
training step: 51198, total_loss: 4.51060676574707
training step: 51199, total_loss: 4.48088264465332
training step: 51200, total_loss: 3.8634705543518066
training step: 51201, total_loss: 4.755456924438477
training step: 51202, total_loss: 3.9946038722991943
training step: 51203, total_loss: 4.426654815673828
training step: 51204, total_loss: 6.766855716705322
training step: 51205, total_loss: 4.045119285583496
training step: 51206, total_loss: 3.4623653888702393
training step: 51207, total_loss: 5.367470741271973
training step: 51208, total_loss: 2.981379508972168
training step: 51209, total_loss: 2.9367470741271973
training step: 51210, total_loss: 4.267218589782715
training step: 51211, total_loss: 6.7449164390563965
training step: 51212, total_loss: 3.231998920440674
training step: 51213, total_loss: 4.113821029663086
training step: 51214, total_loss: 3.1998002529144287
training step: 51215, total_loss: 5.352425575256348
training step: 51216, total_loss: 3.920544147491455
training step: 51217, total_loss: 4.724143028259277
training step: 51218, total_loss: 3.9656381607055664
training step: 51219, total_loss: 5.5714850425720215
training step: 51220, total_loss: 5.116227626800537
training step: 51221, total_loss: 4.542240142822266
training step: 51222, total_loss: 4.571925640106201
training step: 51223, total_loss: 3.811188220977783
training step: 51224, total_loss: 5.264848232269287
training step: 51225, total_loss: 4.161088943481445
training step: 51226, total_loss: 6.264350891113281
training step: 51227, total_loss: 4.496483325958252
training step: 51228, total_loss: 6.788154125213623
training step: 51229, total_loss: 6.019973278045654
training step: 51230, total_loss: 3.8423070907592773
training step: 51231, total_loss: 4.629405975341797
training step: 51232, total_loss: 3.3454365730285645
training step: 51233, total_loss: 3.353782892227173
training step: 51234, total_loss: 5.949533462524414
training step: 51235, total_loss: 5.387264251708984
training step: 51236, total_loss: 3.034217357635498
training step: 51237, total_loss: 4.647924900054932
training step: 51238, total_loss: 5.070345401763916
training step: 51239, total_loss: 4.306394577026367
training step: 51240, total_loss: 5.203302383422852
training step: 51241, total_loss: 4.647236347198486
training step: 51242, total_loss: 4.163304328918457
training step: 51243, total_loss: 5.767219066619873
training step: 51244, total_loss: 3.6006712913513184
training step: 51245, total_loss: 3.5529944896698
training step: 51246, total_loss: 4.756186485290527
training step: 51247, total_loss: 5.317765235900879
training step: 51248, total_loss: 4.485321998596191
training step: 51249, total_loss: 4.173312187194824
training step: 51250, total_loss: 4.766024589538574
training step: 51251, total_loss: 4.340677261352539
training step: 51252, total_loss: 3.8822708129882812
training step: 51253, total_loss: 5.1288347244262695
training step: 51254, total_loss: 4.062353134155273
training step: 51255, total_loss: 4.79115629196167
training step: 51256, total_loss: 4.121094703674316
training step: 51257, total_loss: 5.164890289306641
training step: 51258, total_loss: 3.974905014038086
training step: 51259, total_loss: 4.267685890197754
training step: 51260, total_loss: 4.002860069274902
training step: 51261, total_loss: 4.546666145324707
training step: 51262, total_loss: 4.439509868621826
training step: 51263, total_loss: 4.619466781616211
training step: 51264, total_loss: 6.749210357666016
training step: 51265, total_loss: 5.049221992492676
training step: 51266, total_loss: 4.197208404541016
training step: 51267, total_loss: 3.9104630947113037
training step: 51268, total_loss: 3.592315673828125
training step: 51269, total_loss: 3.632080316543579
training step: 51270, total_loss: 3.79180908203125
training step: 51271, total_loss: 3.5258750915527344
training step: 51272, total_loss: 3.124972105026245
training step: 51273, total_loss: 5.622734546661377
training step: 51274, total_loss: 4.087553977966309
training step: 51275, total_loss: 3.4854822158813477
training step: 51276, total_loss: 3.25545072555542
training step: 51277, total_loss: 3.6145853996276855
training step: 51278, total_loss: 5.005999565124512
training step: 51279, total_loss: 3.9651589393615723
training step: 51280, total_loss: 3.6682796478271484
training step: 51281, total_loss: 3.9758007526397705
training step: 51282, total_loss: 3.1079277992248535
training step: 51283, total_loss: 5.312984466552734
training step: 51284, total_loss: 4.788702011108398
training step: 51285, total_loss: 4.031968116760254
training step: 51286, total_loss: 4.445302963256836
training step: 51287, total_loss: 3.8178763389587402
training step: 51288, total_loss: 4.793835639953613
training step: 51289, total_loss: 4.391329765319824
training step: 51290, total_loss: 4.5697174072265625
training step: 51291, total_loss: 2.2093050479888916
training step: 51292, total_loss: 5.346242904663086
training step: 51293, total_loss: 3.6954140663146973
training step: 51294, total_loss: 4.0662522315979
training step: 51295, total_loss: 4.457213401794434
training step: 51296, total_loss: 2.90216064453125
training step: 51297, total_loss: 6.109750270843506
training step: 51298, total_loss: 3.9196577072143555
training step: 51299, total_loss: 4.3090925216674805
training step: 51300, total_loss: 3.399989604949951
training step: 51301, total_loss: 5.077905654907227
training step: 51302, total_loss: 4.617410659790039
training step: 51303, total_loss: 3.0671749114990234
training step: 51304, total_loss: 3.0785794258117676
training step: 51305, total_loss: 4.503664016723633
training step: 51306, total_loss: 5.2503461837768555
training step: 51307, total_loss: 3.6903696060180664
training step: 51308, total_loss: 4.990119934082031
training step: 51309, total_loss: 5.5998663902282715
training step: 51310, total_loss: 3.8296101093292236
training step: 51311, total_loss: 4.4900031089782715
training step: 51312, total_loss: 4.814092636108398
training step: 51313, total_loss: 6.002930641174316
training step: 51314, total_loss: 2.1981019973754883
training step: 51315, total_loss: 3.228158712387085
training step: 51316, total_loss: 5.072457313537598
training step: 51317, total_loss: 4.562997341156006
training step: 51318, total_loss: 4.158785820007324
training step: 51319, total_loss: 3.106257915496826
training step: 51320, total_loss: 3.4504613876342773
training step: 51321, total_loss: 3.865790367126465
training step: 51322, total_loss: 4.065398216247559
training step: 51323, total_loss: 4.815762519836426
training step: 51324, total_loss: 3.1173157691955566
training step: 51325, total_loss: 4.453545570373535
training step: 51326, total_loss: 4.732761383056641
training step: 51327, total_loss: 3.675015687942505
training step: 51328, total_loss: 5.597002029418945
training step: 51329, total_loss: 5.1802520751953125
training step: 51330, total_loss: 1.691546082496643
training step: 51331, total_loss: 2.747767448425293
training step: 51332, total_loss: 1.6432433128356934
training step: 51333, total_loss: 5.802145957946777
training step: 51334, total_loss: 4.355511665344238
training step: 51335, total_loss: 4.683947563171387
training step: 51336, total_loss: 5.0487565994262695
training step: 51337, total_loss: 4.216475486755371
training step: 51338, total_loss: 4.537735462188721
training step: 51339, total_loss: 4.758103847503662
training step: 51340, total_loss: 3.5968222618103027
training step: 51341, total_loss: 4.04662561416626
training step: 51342, total_loss: 4.416190147399902
training step: 51343, total_loss: 3.515498638153076
training step: 51344, total_loss: 5.5224432945251465
training step: 51345, total_loss: 3.8357253074645996
training step: 51346, total_loss: 4.05034065246582
training step: 51347, total_loss: 2.5662479400634766
training step: 51348, total_loss: 4.490221977233887
training step: 51349, total_loss: 5.679728984832764
training step: 51350, total_loss: 4.536074638366699
training step: 51351, total_loss: 4.251422882080078
training step: 51352, total_loss: 4.535270690917969
training step: 51353, total_loss: 4.74134635925293
training step: 51354, total_loss: 2.5347933769226074
training step: 51355, total_loss: 2.3434207439422607
training step: 51356, total_loss: 4.185963153839111
training step: 51357, total_loss: 2.762040615081787
training step: 51358, total_loss: 7.055449485778809
training step: 51359, total_loss: 3.8337979316711426
training step: 51360, total_loss: 5.095318794250488
training step: 51361, total_loss: 3.2895071506500244
training step: 51362, total_loss: 5.223276138305664
training step: 51363, total_loss: 2.4670279026031494
training step: 51364, total_loss: 3.3043813705444336
training step: 51365, total_loss: 3.4546914100646973
training step: 51366, total_loss: 5.153381824493408
training step: 51367, total_loss: 3.803837776184082
training step: 51368, total_loss: 3.6753225326538086
training step: 51369, total_loss: 3.8413376808166504
training step: 51370, total_loss: 3.511542558670044
training step: 51371, total_loss: 5.105307102203369
training step: 51372, total_loss: 1.9175715446472168
training step: 51373, total_loss: 5.750909805297852
training step: 51374, total_loss: 2.746915340423584
training step: 51375, total_loss: 4.064154624938965
training step: 51376, total_loss: 5.626660346984863
training step: 51377, total_loss: 4.659191131591797
training step: 51378, total_loss: 6.325640678405762
training step: 51379, total_loss: 4.026641845703125
training step: 51380, total_loss: 4.544134140014648
training step: 51381, total_loss: 5.288022994995117
training step: 51382, total_loss: 4.6575093269348145
training step: 51383, total_loss: 4.1538190841674805
training step: 51384, total_loss: 1.1844909191131592
training step: 51385, total_loss: 5.214670181274414
training step: 51386, total_loss: 2.4870779514312744
training step: 51387, total_loss: 5.110630512237549
training step: 51388, total_loss: 3.4284796714782715
training step: 51389, total_loss: 3.9058732986450195
training step: 51390, total_loss: 5.421635150909424
training step: 51391, total_loss: 3.1417741775512695
training step: 51392, total_loss: 3.948137044906616
training step: 51393, total_loss: 4.539626121520996
training step: 51394, total_loss: 4.168416976928711
training step: 51395, total_loss: 5.861459732055664
training step: 51396, total_loss: 6.339944839477539
training step: 51397, total_loss: 5.691954612731934
training step: 51398, total_loss: 4.559270858764648
training step: 51399, total_loss: 3.648632049560547
training step: 51400, total_loss: 4.900268077850342
training step: 51401, total_loss: 5.489870071411133
training step: 51402, total_loss: 3.882539749145508
training step: 51403, total_loss: 3.3304946422576904
training step: 51404, total_loss: 4.410359859466553
training step: 51405, total_loss: 4.267642021179199
training step: 51406, total_loss: 4.21175479888916
training step: 51407, total_loss: 3.275275230407715
training step: 51408, total_loss: 3.588172435760498
training step: 51409, total_loss: 1.1200547218322754
training step: 51410, total_loss: 3.857621908187866
training step: 51411, total_loss: 5.230576515197754
training step: 51412, total_loss: 3.5091137886047363
training step: 51413, total_loss: 3.3673453330993652
training step: 51414, total_loss: 4.7235918045043945
training step: 51415, total_loss: 4.596722602844238
training step: 51416, total_loss: 2.014003038406372
training step: 51417, total_loss: 5.390913486480713
training step: 51418, total_loss: 4.16949987411499
training step: 51419, total_loss: 4.901156425476074
training step: 51420, total_loss: 3.9862914085388184
training step: 51421, total_loss: 3.2961106300354004
training step: 51422, total_loss: 2.540301561355591
training step: 51423, total_loss: 4.3473358154296875
training step: 51424, total_loss: 3.670851945877075
training step: 51425, total_loss: 4.714838027954102
training step: 51426, total_loss: 4.383255958557129
training step: 51427, total_loss: 4.372324466705322
training step: 51428, total_loss: 2.323476791381836
training step: 51429, total_loss: 4.027130126953125
training step: 51430, total_loss: 4.11591911315918
training step: 51431, total_loss: 6.713565349578857
training step: 51432, total_loss: 3.4211769104003906
training step: 51433, total_loss: 5.197116851806641
training step: 51434, total_loss: 4.956339359283447
training step: 51435, total_loss: 3.9793686866760254
training step: 51436, total_loss: 5.08612585067749
training step: 51437, total_loss: 4.745074272155762
training step: 51438, total_loss: 3.794015645980835
training step: 51439, total_loss: 3.8941121101379395
training step: 51440, total_loss: 3.8190319538116455
training step: 51441, total_loss: 3.435770034790039
training step: 51442, total_loss: 5.627439975738525
training step: 51443, total_loss: 3.6644599437713623
training step: 51444, total_loss: 3.6209702491760254
training step: 51445, total_loss: 4.84108829498291
training step: 51446, total_loss: 4.061683177947998
training step: 51447, total_loss: 5.3324198722839355
training step: 51448, total_loss: 3.749133825302124
training step: 51449, total_loss: 3.8781285285949707
training step: 51450, total_loss: 4.455605983734131
training step: 51451, total_loss: 4.288455963134766
training step: 51452, total_loss: 6.424943923950195
training step: 51453, total_loss: 4.800201416015625
training step: 51454, total_loss: 3.5065865516662598
training step: 51455, total_loss: 5.265948295593262
training step: 51456, total_loss: 5.090395927429199
training step: 51457, total_loss: 3.855816125869751
training step: 51458, total_loss: 3.671205520629883
training step: 51459, total_loss: 3.990988254547119
training step: 51460, total_loss: 5.005636692047119
training step: 51461, total_loss: 3.26155948638916
training step: 51462, total_loss: 4.911520957946777
training step: 51463, total_loss: 5.616120338439941
training step: 51464, total_loss: 3.371206283569336
training step: 51465, total_loss: 2.8290953636169434
training step: 51466, total_loss: 2.9850082397460938
training step: 51467, total_loss: 5.218976020812988
training step: 51468, total_loss: 3.3247194290161133
training step: 51469, total_loss: 4.253266334533691
training step: 51470, total_loss: 6.611399173736572
training step: 51471, total_loss: 4.173314094543457
training step: 51472, total_loss: 4.568450927734375
training step: 51473, total_loss: 3.7252659797668457
training step: 51474, total_loss: 3.8148860931396484
training step: 51475, total_loss: 3.9753921031951904
training step: 51476, total_loss: 3.7444686889648438
training step: 51477, total_loss: 4.13034200668335
training step: 51478, total_loss: 5.081830978393555
training step: 51479, total_loss: 4.178266525268555
training step: 51480, total_loss: 3.417407512664795
training step: 51481, total_loss: 4.700474739074707
training step: 51482, total_loss: 4.60748815536499
training step: 51483, total_loss: 4.768801689147949
training step: 51484, total_loss: 2.7300734519958496
training step: 51485, total_loss: 5.432014465332031
training step: 51486, total_loss: 3.806703805923462
training step: 51487, total_loss: 2.7967751026153564
training step: 51488, total_loss: 5.819883823394775
training step: 51489, total_loss: 6.126235008239746
training step: 51490, total_loss: 3.68408203125
training step: 51491, total_loss: 4.991307258605957
training step: 51492, total_loss: 4.003571510314941
training step: 51493, total_loss: 3.428617238998413
training step: 51494, total_loss: 6.95353889465332
training step: 51495, total_loss: 5.256330966949463
training step: 51496, total_loss: 3.9668939113616943
training step: 51497, total_loss: 3.987123966217041
training step: 51498, total_loss: 4.462335586547852
training step: 51499, total_loss: 3.282149076461792
training step: 51500, total_loss: 4.743898391723633
training step: 51501, total_loss: 6.137619972229004
training step: 51502, total_loss: 3.4948678016662598
training step: 51503, total_loss: 3.491727352142334
training step: 51504, total_loss: 3.508985757827759
training step: 51505, total_loss: 4.801626682281494
training step: 51506, total_loss: 4.727699279785156
training step: 51507, total_loss: 5.784224510192871
training step: 51508, total_loss: 3.968073844909668
training step: 51509, total_loss: 3.462761878967285
training step: 51510, total_loss: 2.443133592605591
training step: 51511, total_loss: 5.62650203704834
training step: 51512, total_loss: 3.4325175285339355
training step: 51513, total_loss: 2.7260894775390625
training step: 51514, total_loss: 5.023869514465332
training step: 51515, total_loss: 4.663744926452637
training step: 51516, total_loss: 4.682804107666016
training step: 51517, total_loss: 4.52490234375
training step: 51518, total_loss: 3.6802783012390137
training step: 51519, total_loss: 0.8300690650939941
training step: 51520, total_loss: 2.529592514038086
training step: 51521, total_loss: 5.349941253662109
training step: 51522, total_loss: 5.036733627319336
training step: 51523, total_loss: 3.9663028717041016
training step: 51524, total_loss: 4.357234001159668
training step: 51525, total_loss: 4.256351470947266
training step: 51526, total_loss: 3.281543731689453
training step: 51527, total_loss: 4.885871887207031
training step: 51528, total_loss: 4.102470874786377
training step: 51529, total_loss: 7.728574752807617
training step: 51530, total_loss: 4.782516002655029
training step: 51531, total_loss: 5.358852863311768
training step: 51532, total_loss: 4.695868015289307
training step: 51533, total_loss: 4.717487335205078
training step: 51534, total_loss: 4.659547328948975
training step: 51535, total_loss: 5.510459899902344
training step: 51536, total_loss: 4.7369184494018555
training step: 51537, total_loss: 3.6121463775634766
training step: 51538, total_loss: 3.405836582183838
training step: 51539, total_loss: 3.805610179901123
training step: 51540, total_loss: 4.306292533874512
training step: 51541, total_loss: 4.292733192443848
training step: 51542, total_loss: 4.608948707580566
training step: 51543, total_loss: 3.1310763359069824
training step: 51544, total_loss: 4.908867835998535
training step: 51545, total_loss: 5.398647308349609
training step: 51546, total_loss: 5.771599769592285
training step: 51547, total_loss: 5.083096027374268
training step: 51548, total_loss: 1.0438754558563232
training step: 51549, total_loss: 4.181873321533203
training step: 51550, total_loss: 3.596010208129883
training step: 51551, total_loss: 5.024165630340576
training step: 51552, total_loss: 3.764669418334961
training step: 51553, total_loss: 5.471287727355957
training step: 51554, total_loss: 4.172422885894775
training step: 51555, total_loss: 5.247764587402344
training step: 51556, total_loss: 5.361644744873047
training step: 51557, total_loss: 4.058474540710449
training step: 51558, total_loss: 6.1126251220703125
training step: 51559, total_loss: 4.443281650543213
training step: 51560, total_loss: 3.6670281887054443
training step: 51561, total_loss: 4.634338855743408
training step: 51562, total_loss: 8.116461753845215
training step: 51563, total_loss: 3.7834227085113525
training step: 51564, total_loss: 4.318358421325684
training step: 51565, total_loss: 2.872067451477051
training step: 51566, total_loss: 2.409421443939209
training step: 51567, total_loss: 4.6512322425842285
training step: 51568, total_loss: 4.281189918518066
training step: 51569, total_loss: 5.197422981262207
training step: 51570, total_loss: 3.166531562805176
training step: 51571, total_loss: 4.9743852615356445
training step: 51572, total_loss: 3.9197640419006348
training step: 51573, total_loss: 2.1955041885375977
training step: 51574, total_loss: 4.042116165161133
training step: 51575, total_loss: 4.393098831176758
training step: 51576, total_loss: 4.259091377258301
training step: 51577, total_loss: 4.442018985748291
training step: 51578, total_loss: 2.507147789001465
training step: 51579, total_loss: 6.859373092651367
training step: 51580, total_loss: 3.533950090408325
training step: 51581, total_loss: 5.573366641998291
training step: 51582, total_loss: 6.471096992492676
training step: 51583, total_loss: 4.252817630767822
training step: 51584, total_loss: 4.611374378204346
training step: 51585, total_loss: 5.613208770751953
training step: 51586, total_loss: 3.9312520027160645
training step: 51587, total_loss: 5.516441822052002
training step: 51588, total_loss: 6.7442145347595215
training step: 51589, total_loss: 6.433712005615234
training step: 51590, total_loss: 4.902390956878662
training step: 51591, total_loss: 4.221395492553711
training step: 51592, total_loss: 4.302708625793457
training step: 51593, total_loss: 3.6419835090637207
training step: 51594, total_loss: 4.323874473571777
training step: 51595, total_loss: 4.551327705383301
training step: 51596, total_loss: 5.95147705078125
training step: 51597, total_loss: 4.493861198425293
training step: 51598, total_loss: 3.6353540420532227
training step: 51599, total_loss: 4.302595138549805
training step: 51600, total_loss: 3.7110137939453125
training step: 51601, total_loss: 5.5052103996276855
training step: 51602, total_loss: 4.456019878387451
training step: 51603, total_loss: 4.487865447998047
training step: 51604, total_loss: 2.2088875770568848
training step: 51605, total_loss: 5.245748519897461
training step: 51606, total_loss: 2.468806028366089
training step: 51607, total_loss: 4.37978982925415
training step: 51608, total_loss: 3.563796281814575
training step: 51609, total_loss: 2.918807029724121
training step: 51610, total_loss: 5.483260154724121
training step: 51611, total_loss: 3.945124387741089
training step: 51612, total_loss: 3.9773736000061035
training step: 51613, total_loss: 0.9072794914245605
training step: 51614, total_loss: 6.2158403396606445
training step: 51615, total_loss: 4.110154628753662
training step: 51616, total_loss: 4.6546735763549805
training step: 51617, total_loss: 3.914306640625
training step: 51618, total_loss: 3.8601365089416504
training step: 51619, total_loss: 3.910813331604004
training step: 51620, total_loss: 4.740940093994141
training step: 51621, total_loss: 4.776676654815674
training step: 51622, total_loss: 4.116403579711914
training step: 51623, total_loss: 6.26689338684082
training step: 51624, total_loss: 5.489864349365234
training step: 51625, total_loss: 4.009634971618652
training step: 51626, total_loss: 6.4511799812316895
training step: 51627, total_loss: 6.6306986808776855
training step: 51628, total_loss: 3.584906578063965
training step: 51629, total_loss: 4.270542144775391
training step: 51630, total_loss: 5.7140302658081055
training step: 51631, total_loss: 4.467184066772461
training step: 51632, total_loss: 5.165131568908691
training step: 51633, total_loss: 3.4504644870758057
training step: 51634, total_loss: 1.8397269248962402
training step: 51635, total_loss: 3.5396902561187744
training step: 51636, total_loss: 4.639890670776367
training step: 51637, total_loss: 4.749480724334717
training step: 51638, total_loss: 4.308333396911621
training step: 51639, total_loss: 5.866357803344727
training step: 51640, total_loss: 4.726396560668945
training step: 51641, total_loss: 4.280135154724121
training step: 51642, total_loss: 3.41452693939209
training step: 51643, total_loss: 2.6809563636779785
training step: 51644, total_loss: 3.7249035835266113
training step: 51645, total_loss: 3.8023509979248047
training step: 51646, total_loss: 5.166868209838867
training step: 51647, total_loss: 4.961037635803223
training step: 51648, total_loss: 4.770721912384033
training step: 51649, total_loss: 5.687305450439453
training step: 51650, total_loss: 4.270231246948242
training step: 51651, total_loss: 5.360898971557617
training step: 51652, total_loss: 5.8742194175720215
training step: 51653, total_loss: 1.117318868637085
training step: 51654, total_loss: 3.92415714263916
training step: 51655, total_loss: 5.788251876831055
training step: 51656, total_loss: 3.879087209701538
training step: 51657, total_loss: 4.164740562438965
training step: 51658, total_loss: 4.602663993835449
training step: 51659, total_loss: 3.39017653465271
training step: 51660, total_loss: 5.764430046081543
training step: 51661, total_loss: 2.9816083908081055
training step: 51662, total_loss: 5.9232683181762695
training step: 51663, total_loss: 5.327919006347656
training step: 51664, total_loss: 1.2953678369522095
training step: 51665, total_loss: 3.8975930213928223
training step: 51666, total_loss: 5.479507923126221
training step: 51667, total_loss: 4.434471130371094
training step: 51668, total_loss: 5.248894691467285
training step: 51669, total_loss: 5.235200881958008
training step: 51670, total_loss: 6.451080799102783
training step: 51671, total_loss: 3.338283061981201
training step: 51672, total_loss: 2.917719602584839
training step: 51673, total_loss: 4.410861968994141
training step: 51674, total_loss: 3.90899658203125
training step: 51675, total_loss: 4.7703728675842285
training step: 51676, total_loss: 5.257212162017822
training step: 51677, total_loss: 4.095428466796875
training step: 51678, total_loss: 2.6340701580047607
training step: 51679, total_loss: 4.781656265258789
training step: 51680, total_loss: 6.019038200378418
training step: 51681, total_loss: 5.190937042236328
training step: 51682, total_loss: 4.713535308837891
training step: 51683, total_loss: 5.536248683929443
training step: 51684, total_loss: 2.293605327606201
training step: 51685, total_loss: 3.7597415447235107
training step: 51686, total_loss: 4.727693557739258
training step: 51687, total_loss: 5.906141757965088
training step: 51688, total_loss: 4.619741916656494
training step: 51689, total_loss: 4.515168190002441
training step: 51690, total_loss: 4.860652923583984
training step: 51691, total_loss: 3.300452947616577
training step: 51692, total_loss: 3.902475357055664
training step: 51693, total_loss: 5.025282859802246
training step: 51694, total_loss: 3.9258315563201904
training step: 51695, total_loss: 3.3771815299987793
training step: 51696, total_loss: 4.567352294921875
training step: 51697, total_loss: 4.150775909423828
training step: 51698, total_loss: 4.277976989746094
training step: 51699, total_loss: 3.5454137325286865
training step: 51700, total_loss: 4.279451370239258
training step: 51701, total_loss: 3.1257901191711426
training step: 51702, total_loss: 5.170543670654297
training step: 51703, total_loss: 4.383476257324219
training step: 51704, total_loss: 4.654776573181152
training step: 51705, total_loss: 3.769771099090576
training step: 51706, total_loss: 3.9869368076324463
training step: 51707, total_loss: 4.403410911560059
training step: 51708, total_loss: 4.680737495422363
training step: 51709, total_loss: 4.871611595153809
training step: 51710, total_loss: 3.9756083488464355
training step: 51711, total_loss: 4.862959861755371
training step: 51712, total_loss: 4.0390167236328125
training step: 51713, total_loss: 4.202813148498535
training step: 51714, total_loss: 6.280618190765381
training step: 51715, total_loss: 5.256053447723389
training step: 51716, total_loss: 2.198686361312866
training step: 51717, total_loss: 4.530243873596191
training step: 51718, total_loss: 4.515545845031738
training step: 51719, total_loss: 4.258974075317383
training step: 51720, total_loss: 4.947747707366943
training step: 51721, total_loss: 4.556504249572754
training step: 51722, total_loss: 3.159839630126953
training step: 51723, total_loss: 3.7909111976623535
training step: 51724, total_loss: 6.1879119873046875
training step: 51725, total_loss: 6.005268096923828
training step: 51726, total_loss: 4.8070149421691895
training step: 51727, total_loss: 5.165238380432129
training step: 51728, total_loss: 2.715719699859619
training step: 51729, total_loss: 4.674779891967773
training step: 51730, total_loss: 3.835681200027466
training step: 51731, total_loss: 4.476934432983398
training step: 51732, total_loss: 4.412708282470703
training step: 51733, total_loss: 3.530090570449829
training step: 51734, total_loss: 5.298938751220703
training step: 51735, total_loss: 5.113286018371582
training step: 51736, total_loss: 4.1937994956970215
training step: 51737, total_loss: 3.802004814147949
training step: 51738, total_loss: 4.503881454467773
training step: 51739, total_loss: 5.371625900268555
training step: 51740, total_loss: 4.4903388023376465
training step: 51741, total_loss: 3.4743568897247314
training step: 51742, total_loss: 5.236839771270752
training step: 51743, total_loss: 0.8866982460021973
training step: 51744, total_loss: 3.8067500591278076
training step: 51745, total_loss: 2.6469924449920654
training step: 51746, total_loss: 3.7010698318481445
training step: 51747, total_loss: 3.649260997772217
training step: 51748, total_loss: 3.914677381515503
training step: 51749, total_loss: 3.8767247200012207
training step: 51750, total_loss: 4.699876308441162
training step: 51751, total_loss: 4.039559364318848
training step: 51752, total_loss: 4.555505275726318
training step: 51753, total_loss: 6.647753715515137
training step: 51754, total_loss: 5.138278007507324
training step: 51755, total_loss: 5.139362812042236
training step: 51756, total_loss: 4.743646621704102
training step: 51757, total_loss: 4.3248701095581055
training step: 51758, total_loss: 4.4887542724609375
training step: 51759, total_loss: 4.683682441711426
training step: 51760, total_loss: 4.723094940185547
training step: 51761, total_loss: 4.447177886962891
training step: 51762, total_loss: 4.121013641357422
training step: 51763, total_loss: 3.6841042041778564
training step: 51764, total_loss: 4.693525791168213
training step: 51765, total_loss: 5.2829179763793945
training step: 51766, total_loss: 4.594847679138184
training step: 51767, total_loss: 3.917905569076538
training step: 51768, total_loss: 3.288713216781616
training step: 51769, total_loss: 4.638201713562012
training step: 51770, total_loss: 3.276312828063965
training step: 51771, total_loss: 4.398062705993652
training step: 51772, total_loss: 5.367714881896973
training step: 51773, total_loss: 4.712071418762207
training step: 51774, total_loss: 3.1261847019195557
training step: 51775, total_loss: 3.8702147006988525
training step: 51776, total_loss: 4.605334281921387
training step: 51777, total_loss: 5.819493293762207
training step: 51778, total_loss: 3.7007312774658203
training step: 51779, total_loss: 4.245499610900879
training step: 51780, total_loss: 4.336886882781982
training step: 51781, total_loss: 4.284977436065674
training step: 51782, total_loss: 6.809101104736328
training step: 51783, total_loss: 3.644547939300537
training step: 51784, total_loss: 5.972095489501953
training step: 51785, total_loss: 3.857412815093994
training step: 51786, total_loss: 4.453237533569336
training step: 51787, total_loss: 4.724980354309082
training step: 51788, total_loss: 4.2128753662109375
training step: 51789, total_loss: 4.73306941986084
training step: 51790, total_loss: 4.290744304656982
training step: 51791, total_loss: 2.8157801628112793
training step: 51792, total_loss: 5.579017639160156
training step: 51793, total_loss: 5.583480358123779
training step: 51794, total_loss: 5.870494842529297
training step: 51795, total_loss: 4.902338027954102
training step: 51796, total_loss: 3.9941763877868652
training step: 51797, total_loss: 3.4862728118896484
training step: 51798, total_loss: 4.1443915367126465
training step: 51799, total_loss: 4.556118965148926
training step: 51800, total_loss: 3.3964178562164307
training step: 51801, total_loss: 3.9340827465057373
training step: 51802, total_loss: 5.788558006286621
training step: 51803, total_loss: 2.642185688018799
training step: 51804, total_loss: 4.748882293701172
training step: 51805, total_loss: 4.249262809753418
training step: 51806, total_loss: 3.491539716720581
training step: 51807, total_loss: 3.818765878677368
training step: 51808, total_loss: 4.140873432159424
training step: 51809, total_loss: 3.895237922668457
training step: 51810, total_loss: 3.7719883918762207
training step: 51811, total_loss: 5.448631286621094
training step: 51812, total_loss: 4.825816631317139
training step: 51813, total_loss: 5.550752639770508
training step: 51814, total_loss: 4.449019432067871
training step: 51815, total_loss: 4.273475646972656
training step: 51816, total_loss: 3.1971583366394043
training step: 51817, total_loss: 3.5798702239990234
training step: 51818, total_loss: 3.9960060119628906
training step: 51819, total_loss: 4.081361770629883
training step: 51820, total_loss: 4.05094051361084
training step: 51821, total_loss: 4.928024768829346
training step: 51822, total_loss: 4.506298542022705
training step: 51823, total_loss: 5.048325061798096
training step: 51824, total_loss: 4.239688396453857
training step: 51825, total_loss: 4.1717681884765625
training step: 51826, total_loss: 5.657499313354492
training step: 51827, total_loss: 5.438717365264893
training step: 51828, total_loss: 4.376543045043945
training step: 51829, total_loss: 3.080491542816162
training step: 51830, total_loss: 3.9692859649658203
training step: 51831, total_loss: 4.237764358520508
training step: 51832, total_loss: 1.1886121034622192
training step: 51833, total_loss: 3.434810161590576
training step: 51834, total_loss: 6.108282089233398
training step: 51835, total_loss: 4.53371524810791
training step: 51836, total_loss: 4.215805530548096
training step: 51837, total_loss: 3.6315722465515137
training step: 51838, total_loss: 3.743678569793701
training step: 51839, total_loss: 5.673015117645264
training step: 51840, total_loss: 4.437580108642578
training step: 51841, total_loss: 5.769290924072266
training step: 51842, total_loss: 4.131488800048828
training step: 51843, total_loss: 4.211853504180908
training step: 51844, total_loss: 5.155117988586426
training step: 51845, total_loss: 3.7419095039367676
training step: 51846, total_loss: 3.451519012451172
training step: 51847, total_loss: 4.421690464019775
training step: 51848, total_loss: 4.197793483734131
training step: 51849, total_loss: 4.689393043518066
training step: 51850, total_loss: 4.044498920440674
training step: 51851, total_loss: 3.7796287536621094
training step: 51852, total_loss: 4.33692741394043
training step: 51853, total_loss: 4.310146331787109
training step: 51854, total_loss: 6.113363265991211
training step: 51855, total_loss: 3.0684995651245117
training step: 51856, total_loss: 4.605579853057861
training step: 51857, total_loss: 2.7896909713745117
training step: 51858, total_loss: 2.9247183799743652INFO:tensorflow:Writing predictions to: residual_output/predictions_52000.json
INFO:tensorflow:Writing nbest to: residual_output/nbest_predictions_52000.json

training step: 51859, total_loss: 4.134217262268066
training step: 51860, total_loss: 3.3227550983428955
training step: 51861, total_loss: 5.223508834838867
training step: 51862, total_loss: 5.348286151885986
training step: 51863, total_loss: 5.671414852142334
training step: 51864, total_loss: 5.524089813232422
training step: 51865, total_loss: 5.277489185333252
training step: 51866, total_loss: 4.274557590484619
training step: 51867, total_loss: 4.878849029541016
training step: 51868, total_loss: 4.648950099945068
training step: 51869, total_loss: 2.1366286277770996
training step: 51870, total_loss: 3.8120203018188477
training step: 51871, total_loss: 5.114469528198242
training step: 51872, total_loss: 3.7783379554748535
training step: 51873, total_loss: 5.338135719299316
training step: 51874, total_loss: 0.9167048335075378
training step: 51875, total_loss: 3.683645725250244
training step: 51876, total_loss: 5.607311725616455
training step: 51877, total_loss: 4.936897277832031
training step: 51878, total_loss: 3.8544044494628906
training step: 51879, total_loss: 4.554647445678711
training step: 51880, total_loss: 4.094225883483887
training step: 51881, total_loss: 3.452937602996826
training step: 51882, total_loss: 3.3243250846862793
training step: 51883, total_loss: 5.008160591125488
training step: 51884, total_loss: 3.749908685684204
training step: 51885, total_loss: 3.6547951698303223
training step: 51886, total_loss: 5.01516056060791
training step: 51887, total_loss: 4.9918718338012695
training step: 51888, total_loss: 4.151216983795166
training step: 51889, total_loss: 4.549488544464111
training step: 51890, total_loss: 3.1494858264923096
training step: 51891, total_loss: 5.328429698944092
training step: 51892, total_loss: 4.643543243408203
training step: 51893, total_loss: 5.536679267883301
training step: 51894, total_loss: 4.732643127441406
training step: 51895, total_loss: 2.584078073501587
training step: 51896, total_loss: 4.663674354553223
training step: 51897, total_loss: 3.9925951957702637
training step: 51898, total_loss: 4.139759063720703
training step: 51899, total_loss: 5.179205894470215
training step: 51900, total_loss: 3.557040214538574
training step: 51901, total_loss: 5.413569450378418
training step: 51902, total_loss: 5.741884231567383
training step: 51903, total_loss: 3.6231119632720947
training step: 51904, total_loss: 5.16651725769043
training step: 51905, total_loss: 3.171226739883423
training step: 51906, total_loss: 4.6288161277771
training step: 51907, total_loss: 3.33640193939209
training step: 51908, total_loss: 5.859714508056641
training step: 51909, total_loss: 4.454678535461426
training step: 51910, total_loss: 4.524103164672852
training step: 51911, total_loss: 3.533453941345215
training step: 51912, total_loss: 1.1794133186340332
training step: 51913, total_loss: 4.617176055908203
training step: 51914, total_loss: 4.004258632659912
training step: 51915, total_loss: 4.187989234924316
training step: 51916, total_loss: 3.4141509532928467
training step: 51917, total_loss: 3.2022242546081543
training step: 51918, total_loss: 5.0021467208862305
training step: 51919, total_loss: 4.737109184265137
training step: 51920, total_loss: 4.525866508483887
training step: 51921, total_loss: 5.272965908050537
training step: 51922, total_loss: 4.1992950439453125
training step: 51923, total_loss: 3.536968231201172
training step: 51924, total_loss: 3.29484224319458
training step: 51925, total_loss: 4.782100677490234
training step: 51926, total_loss: 3.61100435256958
training step: 51927, total_loss: 7.158984184265137
training step: 51928, total_loss: 3.721001386642456
training step: 51929, total_loss: 4.865131378173828
training step: 51930, total_loss: 4.999855041503906
training step: 51931, total_loss: 4.343857765197754
training step: 51932, total_loss: 4.70741081237793
training step: 51933, total_loss: 4.792818069458008
training step: 51934, total_loss: 3.321011543273926
training step: 51935, total_loss: 3.7554373741149902
training step: 51936, total_loss: 5.220090866088867
training step: 51937, total_loss: 3.379412889480591
training step: 51938, total_loss: 4.749345779418945
training step: 51939, total_loss: 4.148710250854492
training step: 51940, total_loss: 6.380943298339844
training step: 51941, total_loss: 3.630817174911499
training step: 51942, total_loss: 5.157334804534912
training step: 51943, total_loss: 3.805171012878418
training step: 51944, total_loss: 4.687752723693848
training step: 51945, total_loss: 4.97456169128418
training step: 51946, total_loss: 5.878046989440918
training step: 51947, total_loss: 5.600003719329834
training step: 51948, total_loss: 3.5297017097473145
training step: 51949, total_loss: 5.860831260681152
training step: 51950, total_loss: 3.5077664852142334
training step: 51951, total_loss: 4.702264308929443
training step: 51952, total_loss: 4.026988983154297
training step: 51953, total_loss: 3.9857072830200195
training step: 51954, total_loss: 5.2740678787231445
training step: 51955, total_loss: 5.149397373199463
training step: 51956, total_loss: 0.8616284132003784
training step: 51957, total_loss: 5.924405097961426
training step: 51958, total_loss: 4.263883590698242
training step: 51959, total_loss: 5.989482402801514
training step: 51960, total_loss: 4.28790807723999
training step: 51961, total_loss: 3.472029685974121
training step: 51962, total_loss: 5.861985206604004
training step: 51963, total_loss: 3.7890095710754395
training step: 51964, total_loss: 3.9439845085144043
training step: 51965, total_loss: 3.2645671367645264
training step: 51966, total_loss: 3.239551067352295
training step: 51967, total_loss: 4.249163627624512
training step: 51968, total_loss: 5.140041351318359
training step: 51969, total_loss: 3.9800374507904053
training step: 51970, total_loss: 4.647036075592041
training step: 51971, total_loss: 4.7075724601745605
training step: 51972, total_loss: 3.553561210632324
training step: 51973, total_loss: 4.010008811950684
training step: 51974, total_loss: 5.4746246337890625
training step: 51975, total_loss: 3.48161244392395
training step: 51976, total_loss: 4.175305366516113
training step: 51977, total_loss: 3.6747469902038574
training step: 51978, total_loss: 5.254517555236816
training step: 51979, total_loss: 1.2098324298858643
training step: 51980, total_loss: 6.451014041900635
training step: 51981, total_loss: 5.628055572509766
training step: 51982, total_loss: 2.386606454849243
training step: 51983, total_loss: 2.5220391750335693
training step: 51984, total_loss: 3.9804587364196777
training step: 51985, total_loss: 4.14936637878418
training step: 51986, total_loss: 3.709826946258545
training step: 51987, total_loss: 5.789342403411865
training step: 51988, total_loss: 1.1362581253051758
training step: 51989, total_loss: 4.2468581199646
training step: 51990, total_loss: 4.934110641479492
training step: 51991, total_loss: 4.108460903167725
training step: 51992, total_loss: 4.817237854003906
training step: 51993, total_loss: 3.688129425048828
training step: 51994, total_loss: 3.3806941509246826
training step: 51995, total_loss: 3.5743985176086426
training step: 51996, total_loss: 5.283722877502441
training step: 51997, total_loss: 4.507542610168457
training step: 51998, total_loss: 4.806815147399902
training step: 51999, total_loss: 4.086579322814941
training step: 52000, total_loss: 3.861436367034912
epoch finished! shuffle=False
evaluation: 52000, total_loss: 2.331850528717041, f1: 23.369872869456678, followup: 18.378213905370455, yesno: 1.6126578426897915, heq: 20.78198691617222, dheq: 0.6

Model saved in path residual_output//model_52000.ckpt
training step: 52001, total_loss: 4.700829029083252
training step: 52002, total_loss: 3.2359156608581543
training step: 52003, total_loss: 4.941061973571777
training step: 52004, total_loss: 4.511406898498535
training step: 52005, total_loss: 3.327198028564453
training step: 52006, total_loss: 4.499664306640625
training step: 52007, total_loss: 2.5310091972351074
training step: 52008, total_loss: 4.237290382385254
training step: 52009, total_loss: 4.772313117980957
training step: 52010, total_loss: 4.243577480316162
training step: 52011, total_loss: 4.41054105758667
training step: 52012, total_loss: 4.611917495727539
training step: 52013, total_loss: 5.124924182891846
training step: 52014, total_loss: 3.6238760948181152
training step: 52015, total_loss: 2.9747862815856934
training step: 52016, total_loss: 2.7097251415252686
training step: 52017, total_loss: 4.589126110076904
training step: 52018, total_loss: 4.655716896057129
training step: 52019, total_loss: 3.578522205352783
training step: 52020, total_loss: 4.6219682693481445
training step: 52021, total_loss: 3.6558690071105957
training step: 52022, total_loss: 3.8464274406433105
training step: 52023, total_loss: 3.5597894191741943
training step: 52024, total_loss: 4.22403621673584
training step: 52025, total_loss: 5.277587413787842
training step: 52026, total_loss: 4.291294097900391
training step: 52027, total_loss: 4.4047064781188965
training step: 52028, total_loss: 4.067346096038818
training step: 52029, total_loss: 3.583150863647461
training step: 52030, total_loss: 4.120204448699951
training step: 52031, total_loss: 4.093688488006592
training step: 52032, total_loss: 3.687507152557373
training step: 52033, total_loss: 3.9458093643188477
training step: 52034, total_loss: 4.39047908782959
training step: 52035, total_loss: 4.3611273765563965
training step: 52036, total_loss: 4.545811176300049
training step: 52037, total_loss: 4.28972053527832
training step: 52038, total_loss: 4.422032833099365
training step: 52039, total_loss: 4.762334823608398
training step: 52040, total_loss: 3.7251086235046387
training step: 52041, total_loss: 4.362680435180664
training step: 52042, total_loss: 2.5925583839416504
training step: 52043, total_loss: 5.060124397277832
training step: 52044, total_loss: 3.8532662391662598
training step: 52045, total_loss: 5.13131856918335
training step: 52046, total_loss: 4.828080177307129
training step: 52047, total_loss: 4.904994964599609
training step: 52048, total_loss: 5.18902587890625
training step: 52049, total_loss: 3.068976640701294
training step: 52050, total_loss: 3.7979722023010254
training step: 52051, total_loss: 4.07921838760376
training step: 52052, total_loss: 3.1215593814849854
training step: 52053, total_loss: 3.7674241065979004
training step: 52054, total_loss: 5.272050380706787
training step: 52055, total_loss: 4.429858207702637
training step: 52056, total_loss: 5.399728775024414
training step: 52057, total_loss: 5.042827606201172
training step: 52058, total_loss: 4.4798359870910645
training step: 52059, total_loss: 3.791494131088257
training step: 52060, total_loss: 4.758520126342773
training step: 52061, total_loss: 4.512045860290527
training step: 52062, total_loss: 5.0578508377075195
training step: 52063, total_loss: 1.307481288909912
training step: 52064, total_loss: 4.290703773498535
training step: 52065, total_loss: 5.047208309173584
training step: 52066, total_loss: 5.355026721954346
training step: 52067, total_loss: 3.787534236907959
training step: 52068, total_loss: 2.7478928565979004
training step: 52069, total_loss: 4.751547813415527
training step: 52070, total_loss: 4.549380302429199
training step: 52071, total_loss: 4.3514404296875
training step: 52072, total_loss: 2.384948253631592
training step: 52073, total_loss: 3.2253942489624023
training step: 52074, total_loss: 4.303060054779053
training step: 52075, total_loss: 4.570765495300293
training step: 52076, total_loss: 4.390316486358643
training step: 52077, total_loss: 4.1283650398254395
training step: 52078, total_loss: 3.000640392303467
training step: 52079, total_loss: 4.699667930603027
training step: 52080, total_loss: 2.793637752532959
training step: 52081, total_loss: 4.8619890213012695
training step: 52082, total_loss: 4.281325340270996
training step: 52083, total_loss: 5.032001972198486
training step: 52084, total_loss: 3.833841562271118
training step: 52085, total_loss: 4.870950698852539
training step: 52086, total_loss: 3.4907960891723633
training step: 52087, total_loss: 4.007274150848389
training step: 52088, total_loss: 4.299386501312256
training step: 52089, total_loss: 4.407048225402832
training step: 52090, total_loss: 5.649600028991699
training step: 52091, total_loss: 3.993180751800537
training step: 52092, total_loss: 4.105140686035156
training step: 52093, total_loss: 5.016322135925293
training step: 52094, total_loss: 4.600428581237793
training step: 52095, total_loss: 3.9087963104248047
training step: 52096, total_loss: 6.273561477661133
training step: 52097, total_loss: 5.4812774658203125
training step: 52098, total_loss: 4.96337890625
training step: 52099, total_loss: 3.0624711513519287
training step: 52100, total_loss: 4.642741680145264
training step: 52101, total_loss: 5.241153717041016
training step: 52102, total_loss: 4.991406440734863
training step: 52103, total_loss: 4.534002304077148
training step: 52104, total_loss: 3.6927380561828613
training step: 52105, total_loss: 5.5915632247924805
training step: 52106, total_loss: 1.99678635597229
training step: 52107, total_loss: 5.425489902496338
training step: 52108, total_loss: 4.247872352600098
training step: 52109, total_loss: 2.964064121246338
training step: 52110, total_loss: 4.748288154602051
training step: 52111, total_loss: 3.972414255142212
training step: 52112, total_loss: 4.13529109954834
training step: 52113, total_loss: 4.722589015960693
training step: 52114, total_loss: 4.285060405731201
training step: 52115, total_loss: 6.0217790603637695
training step: 52116, total_loss: 3.337862968444824
training step: 52117, total_loss: 4.631507396697998
training step: 52118, total_loss: 1.1144436597824097
training step: 52119, total_loss: 3.789367914199829
training step: 52120, total_loss: 5.421770095825195
training step: 52121, total_loss: 5.292851448059082
training step: 52122, total_loss: 4.480832099914551
training step: 52123, total_loss: 5.616206169128418
training step: 52124, total_loss: 4.672211647033691
training step: 52125, total_loss: 3.881315231323242
training step: 52126, total_loss: 4.361301898956299
training step: 52127, total_loss: 1.1596126556396484
training step: 52128, total_loss: 5.885684013366699
training step: 52129, total_loss: 4.163898944854736
training step: 52130, total_loss: 4.615490436553955
training step: 52131, total_loss: 4.361351013183594
training step: 52132, total_loss: 2.7901039123535156
training step: 52133, total_loss: 4.41782283782959
training step: 52134, total_loss: 3.8367700576782227
training step: 52135, total_loss: 4.366044998168945
training step: 52136, total_loss: 3.367405414581299
training step: 52137, total_loss: 3.1316490173339844
training step: 52138, total_loss: 4.689830780029297
training step: 52139, total_loss: 4.302214622497559
training step: 52140, total_loss: 4.956504821777344
training step: 52141, total_loss: 2.8762636184692383
training step: 52142, total_loss: 3.9657318592071533
training step: 52143, total_loss: 5.511041164398193
training step: 52144, total_loss: 6.862399101257324
training step: 52145, total_loss: 5.620694637298584
training step: 52146, total_loss: 4.167074680328369
training step: 52147, total_loss: 7.051753520965576
training step: 52148, total_loss: 4.577126979827881
training step: 52149, total_loss: 3.360886573791504
training step: 52150, total_loss: 5.9789886474609375
training step: 52151, total_loss: 3.6204748153686523
training step: 52152, total_loss: 4.539718151092529
training step: 52153, total_loss: 5.131313323974609
training step: 52154, total_loss: 4.083070755004883
training step: 52155, total_loss: 4.3483991622924805
training step: 52156, total_loss: 3.9036450386047363
training step: 52157, total_loss: 4.8591461181640625
training step: 52158, total_loss: 5.454129219055176
training step: 52159, total_loss: 5.398051738739014
training step: 52160, total_loss: 5.565934181213379
training step: 52161, total_loss: 3.919722080230713
training step: 52162, total_loss: 3.6332383155822754
training step: 52163, total_loss: 3.9973082542419434
training step: 52164, total_loss: 4.7456464767456055
training step: 52165, total_loss: 2.042797565460205
training step: 52166, total_loss: 4.717116832733154
training step: 52167, total_loss: 3.6565260887145996
training step: 52168, total_loss: 3.2755544185638428
training step: 52169, total_loss: 5.8433732986450195
training step: 52170, total_loss: 5.184759140014648
training step: 52171, total_loss: 2.3583450317382812
training step: 52172, total_loss: 5.269246578216553
training step: 52173, total_loss: 3.7855494022369385
training step: 52174, total_loss: 3.096165657043457
training step: 52175, total_loss: 4.985941410064697
training step: 52176, total_loss: 5.840677738189697
training step: 52177, total_loss: 5.566141128540039
training step: 52178, total_loss: 3.6817235946655273
training step: 52179, total_loss: 4.104370594024658
training step: 52180, total_loss: 4.675766944885254
training step: 52181, total_loss: 3.997680425643921
training step: 52182, total_loss: 2.6334221363067627
training step: 52183, total_loss: 4.406042098999023
training step: 52184, total_loss: 4.99120569229126
training step: 52185, total_loss: 4.842643737792969
training step: 52186, total_loss: 4.296733856201172
training step: 52187, total_loss: 5.101633071899414
training step: 52188, total_loss: 3.273301601409912
training step: 52189, total_loss: 5.980413436889648
training step: 52190, total_loss: 5.538543701171875
training step: 52191, total_loss: 5.690229415893555
training step: 52192, total_loss: 3.661032199859619
training step: 52193, total_loss: 4.304408073425293
training step: 52194, total_loss: 3.1700425148010254
training step: 52195, total_loss: 5.5677714347839355
training step: 52196, total_loss: 6.228555679321289
training step: 52197, total_loss: 4.432407379150391
training step: 52198, total_loss: 3.1787779331207275
training step: 52199, total_loss: 3.7825803756713867
training step: 52200, total_loss: 5.321846961975098
training step: 52201, total_loss: 5.399245262145996
training step: 52202, total_loss: 5.102407932281494
training step: 52203, total_loss: 3.6291937828063965
training step: 52204, total_loss: 4.078216552734375
training step: 52205, total_loss: 4.020480155944824
training step: 52206, total_loss: 4.674620628356934
training step: 52207, total_loss: 4.560888290405273
training step: 52208, total_loss: 3.8273162841796875
training step: 52209, total_loss: 3.242269992828369
training step: 52210, total_loss: 4.261940956115723
training step: 52211, total_loss: 4.070690155029297
training step: 52212, total_loss: 3.8478498458862305
training step: 52213, total_loss: 3.8941650390625
training step: 52214, total_loss: 3.5279078483581543
training step: 52215, total_loss: 5.093968391418457
training step: 52216, total_loss: 5.102743148803711
training step: 52217, total_loss: 3.9126229286193848
training step: 52218, total_loss: 3.8524627685546875
training step: 52219, total_loss: 3.0258419513702393
training step: 52220, total_loss: 5.189097881317139
training step: 52221, total_loss: 1.6324511766433716
training step: 52222, total_loss: 4.305873870849609
training step: 52223, total_loss: 5.6172637939453125
training step: 52224, total_loss: 6.418354511260986
training step: 52225, total_loss: 4.316246509552002
training step: 52226, total_loss: 5.092364311218262
training step: 52227, total_loss: 4.609423637390137
training step: 52228, total_loss: 4.1306071281433105
training step: 52229, total_loss: 3.085754871368408
training step: 52230, total_loss: 3.3394827842712402
training step: 52231, total_loss: 5.106817245483398
training step: 52232, total_loss: 4.540874481201172
training step: 52233, total_loss: 4.216711521148682
training step: 52234, total_loss: 5.400176048278809
training step: 52235, total_loss: 4.882428169250488
training step: 52236, total_loss: 4.304447174072266
training step: 52237, total_loss: 4.731414318084717
training step: 52238, total_loss: 5.713261604309082
training step: 52239, total_loss: 2.412598133087158
training step: 52240, total_loss: 3.8321285247802734
training step: 52241, total_loss: 3.5702741146087646
training step: 52242, total_loss: 5.527005195617676
training step: 52243, total_loss: 5.494192123413086
training step: 52244, total_loss: 4.007436752319336
training step: 52245, total_loss: 2.609231472015381
training step: 52246, total_loss: 3.8274624347686768
training step: 52247, total_loss: 4.052599906921387
training step: 52248, total_loss: 4.172162055969238
training step: 52249, total_loss: 5.291229248046875
training step: 52250, total_loss: 5.663020133972168
training step: 52251, total_loss: 5.188603401184082
training step: 52252, total_loss: 3.532977342605591
training step: 52253, total_loss: 3.4672691822052
training step: 52254, total_loss: 4.271681785583496
training step: 52255, total_loss: 3.398379325866699
training step: 52256, total_loss: 3.632477045059204
training step: 52257, total_loss: 4.024745941162109
training step: 52258, total_loss: 3.810941219329834
training step: 52259, total_loss: 5.520865440368652
training step: 52260, total_loss: 5.616788864135742
training step: 52261, total_loss: 6.459650993347168
training step: 52262, total_loss: 4.014184951782227
training step: 52263, total_loss: 3.2614853382110596
training step: 52264, total_loss: 3.5891852378845215
training step: 52265, total_loss: 4.664851188659668
training step: 52266, total_loss: 3.0960752964019775
training step: 52267, total_loss: 3.262359857559204
training step: 52268, total_loss: 4.9588189125061035
training step: 52269, total_loss: 3.2257041931152344
training step: 52270, total_loss: 4.548973560333252
training step: 52271, total_loss: 1.5801632404327393
training step: 52272, total_loss: 4.653217315673828
training step: 52273, total_loss: 5.008682727813721
training step: 52274, total_loss: 4.404412269592285
training step: 52275, total_loss: 3.891951084136963
training step: 52276, total_loss: 5.065751075744629
training step: 52277, total_loss: 4.286927223205566
training step: 52278, total_loss: 4.773931503295898
training step: 52279, total_loss: 4.207267761230469
training step: 52280, total_loss: 3.9871110916137695
training step: 52281, total_loss: 4.790698051452637
training step: 52282, total_loss: 5.236001968383789
training step: 52283, total_loss: 4.455820083618164
training step: 52284, total_loss: 5.946996212005615
training step: 52285, total_loss: 5.070822715759277
training step: 52286, total_loss: 3.516737461090088
training step: 52287, total_loss: 3.737823247909546
training step: 52288, total_loss: 6.355282306671143
training step: 52289, total_loss: 2.803506851196289
training step: 52290, total_loss: 3.8074045181274414
training step: 52291, total_loss: 2.9580397605895996
training step: 52292, total_loss: 6.481322288513184
training step: 52293, total_loss: 4.715932846069336
training step: 52294, total_loss: 4.886189937591553
training step: 52295, total_loss: 4.220249652862549
training step: 52296, total_loss: 6.298603057861328
training step: 52297, total_loss: 5.916210174560547
training step: 52298, total_loss: 4.336539268493652
training step: 52299, total_loss: 5.866689682006836
training step: 52300, total_loss: 5.052026748657227
training step: 52301, total_loss: 4.087600231170654
training step: 52302, total_loss: 3.9520583152770996
training step: 52303, total_loss: 4.788523197174072
training step: 52304, total_loss: 4.881531238555908
training step: 52305, total_loss: 4.9370832443237305
training step: 52306, total_loss: 4.119054794311523
training step: 52307, total_loss: 5.031363010406494
training step: 52308, total_loss: 4.157171249389648
training step: 52309, total_loss: 4.297452449798584
training step: 52310, total_loss: 4.960148811340332
training step: 52311, total_loss: 4.333196640014648
training step: 52312, total_loss: 4.442853927612305
training step: 52313, total_loss: 4.543021202087402
training step: 52314, total_loss: 4.1494951248168945
training step: 52315, total_loss: 2.9456958770751953
training step: 52316, total_loss: 2.537999391555786
training step: 52317, total_loss: 5.40521240234375
training step: 52318, total_loss: 4.1273393630981445
training step: 52319, total_loss: 4.176449298858643
training step: 52320, total_loss: 4.583074569702148
training step: 52321, total_loss: 2.5533549785614014
training step: 52322, total_loss: 3.8756802082061768
training step: 52323, total_loss: 5.039937973022461
training step: 52324, total_loss: 3.8524909019470215
training step: 52325, total_loss: 4.16649055480957
training step: 52326, total_loss: 5.497451305389404
training step: 52327, total_loss: 3.966369867324829
training step: 52328, total_loss: 5.09844446182251
training step: 52329, total_loss: 3.6875157356262207
training step: 52330, total_loss: 2.7623178958892822
training step: 52331, total_loss: 5.385016918182373
training step: 52332, total_loss: 4.181487083435059
training step: 52333, total_loss: 4.2000226974487305
training step: 52334, total_loss: 4.2389068603515625
training step: 52335, total_loss: 3.127310276031494
training step: 52336, total_loss: 4.283288478851318
training step: 52337, total_loss: 4.335351943969727
training step: 52338, total_loss: 5.4058427810668945
training step: 52339, total_loss: 4.596231460571289
training step: 52340, total_loss: 3.6944379806518555
training step: 52341, total_loss: 3.2839064598083496
training step: 52342, total_loss: 3.189087390899658
training step: 52343, total_loss: 3.9815611839294434
training step: 52344, total_loss: 2.2237799167633057
training step: 52345, total_loss: 4.137763500213623
training step: 52346, total_loss: 3.152815103530884
training step: 52347, total_loss: 3.1878929138183594
training step: 52348, total_loss: 4.3416948318481445
training step: 52349, total_loss: 3.010340690612793
training step: 52350, total_loss: 5.124874114990234
training step: 52351, total_loss: 5.010766983032227
training step: 52352, total_loss: 5.874349594116211
training step: 52353, total_loss: 3.5535285472869873
training step: 52354, total_loss: 4.776440620422363
training step: 52355, total_loss: 4.645898342132568
training step: 52356, total_loss: 4.705927848815918
training step: 52357, total_loss: 4.686293601989746
training step: 52358, total_loss: 5.294356822967529
training step: 52359, total_loss: 8.303498268127441
training step: 52360, total_loss: 3.2435550689697266
training step: 52361, total_loss: 5.227109909057617
training step: 52362, total_loss: 4.502821922302246
training step: 52363, total_loss: 4.679892539978027
training step: 52364, total_loss: 4.528069972991943
training step: 52365, total_loss: 4.112354278564453
training step: 52366, total_loss: 3.2202320098876953
training step: 52367, total_loss: 5.1706342697143555
training step: 52368, total_loss: 3.63464617729187
training step: 52369, total_loss: 1.461616039276123
training step: 52370, total_loss: 3.6041126251220703
training step: 52371, total_loss: 5.043187618255615
training step: 52372, total_loss: 4.544220924377441
training step: 52373, total_loss: 4.415732383728027
training step: 52374, total_loss: 2.0817201137542725
training step: 52375, total_loss: 3.922055244445801
training step: 52376, total_loss: 5.662205696105957
training step: 52377, total_loss: 4.747434616088867
training step: 52378, total_loss: 5.272283554077148
training step: 52379, total_loss: 4.018454074859619
training step: 52380, total_loss: 5.077466011047363
training step: 52381, total_loss: 3.894416332244873
training step: 52382, total_loss: 5.888916969299316
training step: 52383, total_loss: 4.555437088012695
training step: 52384, total_loss: 5.087100028991699
training step: 52385, total_loss: 4.085345268249512
training step: 52386, total_loss: 4.941030502319336
training step: 52387, total_loss: 2.764221668243408
training step: 52388, total_loss: 4.090274810791016
training step: 52389, total_loss: 4.303448677062988
training step: 52390, total_loss: 5.003454685211182
training step: 52391, total_loss: 2.2956442832946777
training step: 52392, total_loss: 3.8118722438812256
training step: 52393, total_loss: 3.269237995147705
training step: 52394, total_loss: 3.0521957874298096
training step: 52395, total_loss: 6.905457973480225
training step: 52396, total_loss: 4.845017433166504
training step: 52397, total_loss: 3.1632373332977295
training step: 52398, total_loss: 4.642725944519043
training step: 52399, total_loss: 5.737816333770752
training step: 52400, total_loss: 4.673221588134766
training step: 52401, total_loss: 4.593118667602539
training step: 52402, total_loss: 5.796324729919434
training step: 52403, total_loss: 5.243197441101074
training step: 52404, total_loss: 4.318610668182373
training step: 52405, total_loss: 4.5455732345581055
training step: 52406, total_loss: 4.938906669616699
training step: 52407, total_loss: 4.1406049728393555
training step: 52408, total_loss: 4.372125625610352
training step: 52409, total_loss: 3.5067129135131836
training step: 52410, total_loss: 3.3375556468963623
training step: 52411, total_loss: 3.7281041145324707
training step: 52412, total_loss: 4.620019912719727
training step: 52413, total_loss: 3.1108317375183105
training step: 52414, total_loss: 4.42789363861084
training step: 52415, total_loss: 3.9993481636047363
training step: 52416, total_loss: 4.082348346710205
training step: 52417, total_loss: 4.622993469238281
training step: 52418, total_loss: 4.259636878967285
training step: 52419, total_loss: 3.5921688079833984
training step: 52420, total_loss: 4.754921913146973
training step: 52421, total_loss: 5.491858959197998
training step: 52422, total_loss: 3.9257936477661133
training step: 52423, total_loss: 3.6775312423706055
training step: 52424, total_loss: 5.43966817855835
training step: 52425, total_loss: 4.462231159210205
training step: 52426, total_loss: 6.001522541046143
training step: 52427, total_loss: 4.712457180023193
training step: 52428, total_loss: 4.0776801109313965
training step: 52429, total_loss: 4.464375019073486
training step: 52430, total_loss: 4.15458869934082
training step: 52431, total_loss: 4.146707534790039
training step: 52432, total_loss: 4.000556945800781
training step: 52433, total_loss: 4.358380317687988
training step: 52434, total_loss: 5.527748107910156
training step: 52435, total_loss: 5.365182876586914
training step: 52436, total_loss: 4.663319110870361
training step: 52437, total_loss: 3.1844968795776367
training step: 52438, total_loss: 4.615886688232422
training step: 52439, total_loss: 4.824409484863281
training step: 52440, total_loss: 3.7295122146606445
training step: 52441, total_loss: 4.780294418334961
training step: 52442, total_loss: 3.557492733001709
training step: 52443, total_loss: 4.5921220779418945
training step: 52444, total_loss: 4.7982282638549805
training step: 52445, total_loss: 5.937193393707275
training step: 52446, total_loss: 6.524120330810547
training step: 52447, total_loss: 4.351773262023926
training step: 52448, total_loss: 2.6211843490600586
training step: 52449, total_loss: 3.5532188415527344
training step: 52450, total_loss: 5.15187931060791
training step: 52451, total_loss: 4.74317741394043
training step: 52452, total_loss: 1.0661870241165161
training step: 52453, total_loss: 2.3535571098327637
training step: 52454, total_loss: 3.3840670585632324
training step: 52455, total_loss: 0.9869188070297241
training step: 52456, total_loss: 4.5120463371276855
training step: 52457, total_loss: 3.1352248191833496
training step: 52458, total_loss: 4.780162334442139
training step: 52459, total_loss: 3.0970401763916016
training step: 52460, total_loss: 5.386682987213135
training step: 52461, total_loss: 5.608186721801758
training step: 52462, total_loss: 4.033370018005371
training step: 52463, total_loss: 4.462760925292969
training step: 52464, total_loss: 2.6456336975097656
training step: 52465, total_loss: 4.203292369842529
training step: 52466, total_loss: 0.9330582618713379
training step: 52467, total_loss: 4.169029235839844
training step: 52468, total_loss: 5.009057521820068
training step: 52469, total_loss: 4.852002143859863
training step: 52470, total_loss: 6.743963241577148
training step: 52471, total_loss: 4.116271495819092
training step: 52472, total_loss: 4.031957149505615
training step: 52473, total_loss: 4.0522847175598145
training step: 52474, total_loss: 3.6625008583068848
training step: 52475, total_loss: 1.2513502836227417
training step: 52476, total_loss: 3.658151388168335
training step: 52477, total_loss: 4.41673469543457
training step: 52478, total_loss: 5.135148525238037
training step: 52479, total_loss: 5.089376449584961
training step: 52480, total_loss: 5.450638771057129
training step: 52481, total_loss: 3.5711989402770996
training step: 52482, total_loss: 3.7065348625183105
training step: 52483, total_loss: 4.3455810546875
training step: 52484, total_loss: 6.195749282836914
training step: 52485, total_loss: 3.5015339851379395
training step: 52486, total_loss: 4.026704788208008
training step: 52487, total_loss: 5.3110504150390625
training step: 52488, total_loss: 4.333559036254883
training step: 52489, total_loss: 3.4296631813049316
training step: 52490, total_loss: 3.5808939933776855
training step: 52491, total_loss: 4.290068626403809
training step: 52492, total_loss: 4.939787864685059
training step: 52493, total_loss: 6.2456207275390625
training step: 52494, total_loss: 3.983156681060791
training step: 52495, total_loss: 3.8791425228118896
training step: 52496, total_loss: 4.7477264404296875
training step: 52497, total_loss: 5.32040548324585
training step: 52498, total_loss: 4.474776744842529
training step: 52499, total_loss: 2.3330843448638916
training step: 52500, total_loss: 5.30865478515625
training step: 52501, total_loss: 2.1435396671295166
training step: 52502, total_loss: 3.5129470825195312
training step: 52503, total_loss: 3.1474411487579346
training step: 52504, total_loss: 4.336777687072754
training step: 52505, total_loss: 3.1745338439941406
training step: 52506, total_loss: 5.570046424865723
training step: 52507, total_loss: 3.825458526611328
training step: 52508, total_loss: 2.9614715576171875
training step: 52509, total_loss: 4.318633079528809
training step: 52510, total_loss: 1.0378857851028442
training step: 52511, total_loss: 4.4795942306518555
training step: 52512, total_loss: 4.263453483581543
training step: 52513, total_loss: 3.92515230178833
training step: 52514, total_loss: 5.001822471618652
training step: 52515, total_loss: 5.257455348968506
training step: 52516, total_loss: 5.766671180725098
training step: 52517, total_loss: 3.199446201324463
training step: 52518, total_loss: 4.549759387969971
training step: 52519, total_loss: 4.8652167320251465
training step: 52520, total_loss: 3.906177043914795
training step: 52521, total_loss: 4.229288101196289
training step: 52522, total_loss: 4.061063766479492
training step: 52523, total_loss: 4.357117176055908
training step: 52524, total_loss: 1.108644723892212
training step: 52525, total_loss: 3.2721683979034424
training step: 52526, total_loss: 4.042532920837402
training step: 52527, total_loss: 4.6005144119262695
training step: 52528, total_loss: 5.704926490783691
training step: 52529, total_loss: 6.7714667320251465
training step: 52530, total_loss: 3.2822861671447754
training step: 52531, total_loss: 4.942147254943848
training step: 52532, total_loss: 3.9274096488952637
training step: 52533, total_loss: 2.435335397720337
training step: 52534, total_loss: 4.561925888061523
training step: 52535, total_loss: 3.792743682861328
training step: 52536, total_loss: 4.533296585083008
training step: 52537, total_loss: 4.70473575592041
training step: 52538, total_loss: 4.415091514587402
training step: 52539, total_loss: 4.678362846374512
training step: 52540, total_loss: 3.575615167617798
training step: 52541, total_loss: 4.645036697387695
training step: 52542, total_loss: 4.368190288543701
training step: 52543, total_loss: 4.3229451179504395
training step: 52544, total_loss: 3.0944390296936035
training step: 52545, total_loss: 4.5836381912231445
training step: 52546, total_loss: 4.845168113708496
training step: 52547, total_loss: 4.199377059936523
training step: 52548, total_loss: 4.638476371765137
training step: 52549, total_loss: 3.354346752166748
training step: 52550, total_loss: 0.8592886924743652
training step: 52551, total_loss: 4.469018936157227
training step: 52552, total_loss: 4.919260025024414
training step: 52553, total_loss: 3.279954433441162
training step: 52554, total_loss: 5.130731582641602
training step: 52555, total_loss: 2.8674838542938232
training step: 52556, total_loss: 3.5885093212127686
training step: 52557, total_loss: 4.6403985023498535
training step: 52558, total_loss: 3.3375508785247803
training step: 52559, total_loss: 4.284512519836426
training step: 52560, total_loss: 5.526812553405762
training step: 52561, total_loss: 4.724313735961914
training step: 52562, total_loss: 4.080127716064453
training step: 52563, total_loss: 3.152981996536255
training step: 52564, total_loss: 4.772238731384277
training step: 52565, total_loss: 4.571572780609131
training step: 52566, total_loss: 5.780656337738037
training step: 52567, total_loss: 4.979795455932617
training step: 52568, total_loss: 4.207724571228027
training step: 52569, total_loss: 4.571089267730713
training step: 52570, total_loss: 4.161005020141602
training step: 52571, total_loss: 5.265045166015625
training step: 52572, total_loss: 2.4223337173461914
training step: 52573, total_loss: 4.424327373504639
training step: 52574, total_loss: 4.550565719604492
training step: 52575, total_loss: 4.355102062225342
training step: 52576, total_loss: 4.267831802368164
training step: 52577, total_loss: 5.660769462585449
training step: 52578, total_loss: 6.715362071990967
training step: 52579, total_loss: 5.340956211090088
training step: 52580, total_loss: 3.325962543487549
training step: 52581, total_loss: 4.9925007820129395
training step: 52582, total_loss: 3.748751640319824
training step: 52583, total_loss: 4.830370903015137
training step: 52584, total_loss: 4.956730365753174
training step: 52585, total_loss: 4.582511901855469
training step: 52586, total_loss: 4.794512748718262
training step: 52587, total_loss: 2.1521477699279785
training step: 52588, total_loss: 3.6729676723480225
training step: 52589, total_loss: 4.751187324523926
training step: 52590, total_loss: 3.236604928970337
training step: 52591, total_loss: 6.377490043640137
training step: 52592, total_loss: 5.672894477844238
training step: 52593, total_loss: 4.1520185470581055
training step: 52594, total_loss: 2.839505195617676
training step: 52595, total_loss: 3.2315492630004883
training step: 52596, total_loss: 4.219394683837891
training step: 52597, total_loss: 3.4081687927246094
training step: 52598, total_loss: 4.510336875915527
training step: 52599, total_loss: 2.912996768951416
training step: 52600, total_loss: 5.916730880737305
training step: 52601, total_loss: 5.5055131912231445
training step: 52602, total_loss: 4.230337619781494
training step: 52603, total_loss: 4.070784568786621
training step: 52604, total_loss: 5.850870132446289
training step: 52605, total_loss: 2.3957443237304688
training step: 52606, total_loss: 4.470415115356445
training step: 52607, total_loss: 4.865790367126465
training step: 52608, total_loss: 4.804806232452393
training step: 52609, total_loss: 5.298712730407715
training step: 52610, total_loss: 4.277242660522461
training step: 52611, total_loss: 3.3144736289978027
training step: 52612, total_loss: 3.868699550628662
training step: 52613, total_loss: 4.475945472717285
training step: 52614, total_loss: 4.470705986022949
training step: 52615, total_loss: 4.038439750671387
training step: 52616, total_loss: 4.411912441253662
training step: 52617, total_loss: 3.7551732063293457
training step: 52618, total_loss: 4.350073337554932
training step: 52619, total_loss: 4.841998100280762
training step: 52620, total_loss: 3.5624752044677734
training step: 52621, total_loss: 3.5945491790771484
training step: 52622, total_loss: 5.871648788452148
training step: 52623, total_loss: 3.319960355758667
training step: 52624, total_loss: 4.514845848083496
training step: 52625, total_loss: 4.412509441375732
training step: 52626, total_loss: 4.685457229614258
training step: 52627, total_loss: 5.218898773193359
training step: 52628, total_loss: 5.066325664520264
training step: 52629, total_loss: 4.979236125946045
training step: 52630, total_loss: 3.359889268875122
training step: 52631, total_loss: 4.4185895919799805
training step: 52632, total_loss: 2.679908275604248
training step: 52633, total_loss: 2.3057990074157715
training step: 52634, total_loss: 4.0302276611328125
training step: 52635, total_loss: 4.330137252807617
training step: 52636, total_loss: 4.298184394836426
training step: 52637, total_loss: 6.114718437194824
training step: 52638, total_loss: 6.089510917663574
training step: 52639, total_loss: 4.991556167602539
training step: 52640, total_loss: 5.804771423339844
training step: 52641, total_loss: 4.897787094116211
training step: 52642, total_loss: 5.149101257324219
training step: 52643, total_loss: 5.080602645874023
training step: 52644, total_loss: 5.189933776855469
training step: 52645, total_loss: 4.021266937255859
training step: 52646, total_loss: 3.868417501449585
training step: 52647, total_loss: 4.5463056564331055
training step: 52648, total_loss: 2.546720027923584
training step: 52649, total_loss: 4.470560073852539
training step: 52650, total_loss: 4.121223449707031
training step: 52651, total_loss: 4.526823997497559
training step: 52652, total_loss: 2.3038949966430664
training step: 52653, total_loss: 2.8718161582946777
training step: 52654, total_loss: 4.275536060333252
training step: 52655, total_loss: 5.020053863525391
training step: 52656, total_loss: 0.888472318649292
training step: 52657, total_loss: 4.199807167053223
training step: 52658, total_loss: 3.1707329750061035
training step: 52659, total_loss: 4.515904426574707
training step: 52660, total_loss: 4.481265068054199
training step: 52661, total_loss: 6.229739189147949
training step: 52662, total_loss: 3.863832950592041
training step: 52663, total_loss: 4.819190502166748
training step: 52664, total_loss: 5.9319353103637695
training step: 52665, total_loss: 4.308358192443848
training step: 52666, total_loss: 5.2987518310546875
training step: 52667, total_loss: 3.2369651794433594
training step: 52668, total_loss: 3.985525131225586
training step: 52669, total_loss: 3.3599517345428467
training step: 52670, total_loss: 2.8708996772766113
training step: 52671, total_loss: 4.63486385345459
training step: 52672, total_loss: 3.5213141441345215
training step: 52673, total_loss: 4.129485607147217
training step: 52674, total_loss: 4.814193248748779
training step: 52675, total_loss: 4.321233749389648
training step: 52676, total_loss: 5.562684535980225
training step: 52677, total_loss: 3.92191219329834
training step: 52678, total_loss: 4.871305465698242
training step: 52679, total_loss: 4.446075916290283
training step: 52680, total_loss: 4.95413875579834
training step: 52681, total_loss: 2.464517593383789
training step: 52682, total_loss: 4.604646682739258
training step: 52683, total_loss: 5.407106399536133
training step: 52684, total_loss: 4.147540092468262
training step: 52685, total_loss: 4.941448211669922
training step: 52686, total_loss: 4.33380651473999
training step: 52687, total_loss: 2.6204323768615723
training step: 52688, total_loss: 3.520103931427002
training step: 52689, total_loss: 3.818331718444824
training step: 52690, total_loss: 4.522253036499023
training step: 52691, total_loss: 3.762542247772217
training step: 52692, total_loss: 4.909628391265869
training step: 52693, total_loss: 5.4527764320373535
training step: 52694, total_loss: 5.094904899597168
training step: 52695, total_loss: 4.365655899047852
training step: 52696, total_loss: 5.162962913513184
training step: 52697, total_loss: 4.040291786193848
training step: 52698, total_loss: 3.028540849685669
training step: 52699, total_loss: 4.56908655166626
training step: 52700, total_loss: 4.423630714416504
training step: 52701, total_loss: 4.21333122253418
training step: 52702, total_loss: 6.264348983764648
training step: 52703, total_loss: 4.344081878662109
training step: 52704, total_loss: 4.817229270935059
training step: 52705, total_loss: 3.8412742614746094
training step: 52706, total_loss: 5.967287063598633
training step: 52707, total_loss: 4.033022403717041
training step: 52708, total_loss: 6.385770797729492
training step: 52709, total_loss: 2.481691360473633
training step: 52710, total_loss: 2.4689581394195557
training step: 52711, total_loss: 4.079654693603516
training step: 52712, total_loss: 5.1350998878479
training step: 52713, total_loss: 4.5849714279174805
training step: 52714, total_loss: 4.43235969543457
training step: 52715, total_loss: 5.0856242179870605
training step: 52716, total_loss: 4.22998046875
training step: 52717, total_loss: 4.038124084472656
training step: 52718, total_loss: 5.457557201385498
training step: 52719, total_loss: 4.509057998657227
training step: 52720, total_loss: 5.555300712585449
training step: 52721, total_loss: 3.7038211822509766
training step: 52722, total_loss: 4.232788562774658
training step: 52723, total_loss: 5.480426788330078
training step: 52724, total_loss: 4.088770866394043
training step: 52725, total_loss: 5.50679349899292
training step: 52726, total_loss: 4.005423545837402
training step: 52727, total_loss: 4.211524963378906
training step: 52728, total_loss: 4.228213310241699
training step: 52729, total_loss: 4.966350555419922
training step: 52730, total_loss: 3.928327798843384
training step: 52731, total_loss: 5.594133377075195
training step: 52732, total_loss: 5.882909774780273
training step: 52733, total_loss: 4.158285140991211
training step: 52734, total_loss: 4.429446220397949
training step: 52735, total_loss: 4.816799640655518
training step: 52736, total_loss: 4.450117111206055
training step: 52737, total_loss: 0.9805728197097778
training step: 52738, total_loss: 5.151707172393799
training step: 52739, total_loss: 6.48175048828125
training step: 52740, total_loss: 3.7071590423583984
training step: 52741, total_loss: 4.407941818237305
training step: 52742, total_loss: 6.763370513916016
training step: 52743, total_loss: 4.167648792266846
training step: 52744, total_loss: 4.33351993560791
training step: 52745, total_loss: 5.1315155029296875
training step: 52746, total_loss: 3.46039080619812
training step: 52747, total_loss: 3.9344115257263184
training step: 52748, total_loss: 4.346153259277344
training step: 52749, total_loss: 4.075586795806885
training step: 52750, total_loss: 3.78566837310791
training step: 52751, total_loss: 4.058232307434082
training step: 52752, total_loss: 2.4628422260284424
training step: 52753, total_loss: 4.508251667022705
training step: 52754, total_loss: 4.759865760803223
training step: 52755, total_loss: 3.225139856338501
training step: 52756, total_loss: 3.780803680419922
training step: 52757, total_loss: 1.0658628940582275
training step: 52758, total_loss: 3.4113521575927734
training step: 52759, total_loss: 4.208194255828857
training step: 52760, total_loss: 4.908957481384277
training step: 52761, total_loss: 5.646636009216309
training step: 52762, total_loss: 4.0235137939453125
training step: 52763, total_loss: 4.935052871704102
training step: 52764, total_loss: 4.390982627868652
training step: 52765, total_loss: 4.395647048950195
training step: 52766, total_loss: 5.149191856384277
training step: 52767, total_loss: 4.399456024169922
training step: 52768, total_loss: 3.223972797393799
training step: 52769, total_loss: 3.796541213989258
training step: 52770, total_loss: 1.862804651260376
training step: 52771, total_loss: 3.9458115100860596
training step: 52772, total_loss: 6.08018684387207
training step: 52773, total_loss: 4.707832336425781
training step: 52774, total_loss: 2.698005437850952
training step: 52775, total_loss: 4.625946998596191
training step: 52776, total_loss: 4.2653656005859375
training step: 52777, total_loss: 3.061824083328247
training step: 52778, total_loss: 3.2640817165374756
training step: 52779, total_loss: 4.935212135314941
training step: 52780, total_loss: 2.0863780975341797
training step: 52781, total_loss: 3.7348484992980957
training step: 52782, total_loss: 3.6712708473205566
training step: 52783, total_loss: 3.555866241455078
training step: 52784, total_loss: 3.085292339324951
training step: 52785, total_loss: 2.36104154586792
training step: 52786, total_loss: 4.759003639221191
training step: 52787, total_loss: 4.264850616455078
training step: 52788, total_loss: 3.320892810821533
training step: 52789, total_loss: 4.757702827453613
training step: 52790, total_loss: 5.142809867858887
training step: 52791, total_loss: 5.941641330718994
training step: 52792, total_loss: 2.9732024669647217
training step: 52793, total_loss: 4.126026153564453
training step: 52794, total_loss: 3.529799461364746
training step: 52795, total_loss: 4.768851280212402
training step: 52796, total_loss: 4.859409332275391
training step: 52797, total_loss: 4.245099067687988
training step: 52798, total_loss: 4.4639058113098145
training step: 52799, total_loss: 3.9757068157196045
training step: 52800, total_loss: 4.862442493438721
training step: 52801, total_loss: 0.740488588809967
training step: 52802, total_loss: 5.200867176055908
training step: 52803, total_loss: 3.5174832344055176
training step: 52804, total_loss: 3.8704702854156494
training step: 52805, total_loss: 4.695466995239258
training step: 52806, total_loss: 3.2400155067443848
training step: 52807, total_loss: 4.619983673095703
training step: 52808, total_loss: 4.493549346923828
training step: 52809, total_loss: 3.4406001567840576
training step: 52810, total_loss: 3.871243476867676
training step: 52811, total_loss: 4.135028839111328
training step: 52812, total_loss: 4.358068466186523
training step: 52813, total_loss: 5.250434875488281
training step: 52814, total_loss: 5.538488864898682
training step: 52815, total_loss: 4.58995246887207
training step: 52816, total_loss: 3.3275675773620605
training step: 52817, total_loss: 3.5967018604278564
training step: 52818, total_loss: 4.199587345123291
training step: 52819, total_loss: 4.667384147644043
training step: 52820, total_loss: 4.728709697723389
training step: 52821, total_loss: 2.8995351791381836
training step: 52822, total_loss: 3.2605390548706055
training step: 52823, total_loss: 5.088446617126465
training step: 52824, total_loss: 7.206501007080078
training step: 52825, total_loss: 4.298399925231934
training step: 52826, total_loss: 5.184757232666016
training step: 52827, total_loss: 3.052567958831787
training step: 52828, total_loss: 4.662518501281738
training step: 52829, total_loss: 1.065481185913086
training step: 52830, total_loss: 2.87440824508667
training step: 52831, total_loss: 5.22422981262207
training step: 52832, total_loss: 4.195436000823975
training step: 52833, total_loss: 2.730534076690674
training step: 52834, total_loss: 5.403238296508789
training step: 52835, total_loss: 4.622615337371826
training step: 52836, total_loss: 4.326381683349609
training step: 52837, total_loss: 4.706377029418945
training step: 52838, total_loss: 4.972679138183594
training step: 52839, total_loss: 3.8448245525360107
training step: 52840, total_loss: 3.7761969566345215
training step: 52841, total_loss: 4.834651947021484
training step: 52842, total_loss: 3.992699384689331
training step: 52843, total_loss: 5.24937105178833
training step: 52844, total_loss: 0.8196961879730225
training step: 52845, total_loss: 3.665982723236084
training step: 52846, total_loss: 3.2943813800811768
training step: 52847, total_loss: 4.424892425537109
training step: 52848, total_loss: 5.704797744750977
training step: 52849, total_loss: 0.8165991306304932
training step: 52850, total_loss: 3.3290207386016846
training step: 52851, total_loss: 5.7414703369140625
training step: 52852, total_loss: 2.820641279220581
training step: 52853, total_loss: 4.296069145202637
training step: 52854, total_loss: 4.20093297958374
training step: 52855, total_loss: 5.104496955871582
training step: 52856, total_loss: 4.7360310554504395
training step: 52857, total_loss: 5.086823463439941
training step: 52858, total_loss: 0.72358238697052
training step: 52859, total_loss: 4.523089408874512
training step: 52860, total_loss: 3.203032970428467
training step: 52861, total_loss: 4.355883598327637
training step: 52862, total_loss: 4.313250541687012
training step: 52863, total_loss: 3.130702495574951
training step: 52864, total_loss: 4.507134437561035
training step: 52865, total_loss: 3.530773639678955
training step: 52866, total_loss: 5.340932369232178
training step: 52867, total_loss: 4.723038196563721
training step: 52868, total_loss: 4.477733135223389
training step: 52869, total_loss: 3.9178271293640137
training step: 52870, total_loss: 2.507925510406494
training step: 52871, total_loss: 3.7226462364196777
training step: 52872, total_loss: 4.578073501586914
training step: 52873, total_loss: 3.793814182281494
training step: 52874, total_loss: 4.684456825256348
training step: 52875, total_loss: 4.401372909545898
training step: 52876, total_loss: 4.066954135894775
training step: 52877, total_loss: 4.318483352661133
training step: 52878, total_loss: 4.981222629547119
training step: 52879, total_loss: 4.759145736694336
training step: 52880, total_loss: 2.964505672454834
training step: 52881, total_loss: 4.536025047302246
training step: 52882, total_loss: 5.718008041381836
training step: 52883, total_loss: 0.6460371017456055
training step: 52884, total_loss: 0.8292236328125
training step: 52885, total_loss: 3.555966377258301
training step: 52886, total_loss: 3.9764838218688965
training step: 52887, total_loss: 3.63338041305542
training step: 52888, total_loss: 4.430818557739258
training step: 52889, total_loss: 0.8591167330741882
training step: 52890, total_loss: 4.368100643157959
training step: 52891, total_loss: 3.5152456760406494
training step: 52892, total_loss: 2.707353115081787
training step: 52893, total_loss: 3.632497549057007
training step: 52894, total_loss: 4.503872871398926
training step: 52895, total_loss: 4.610043525695801
training step: 52896, total_loss: 6.20137882232666
training step: 52897, total_loss: 4.442419528961182
training step: 52898, total_loss: 5.335967063903809
training step: 52899, total_loss: 3.103102207183838
training step: 52900, total_loss: 3.4970762729644775
training step: 52901, total_loss: 4.861053466796875
training step: 52902, total_loss: 3.9387919902801514
training step: 52903, total_loss: 3.02937650680542
training step: 52904, total_loss: 4.334084510803223
training step: 52905, total_loss: 3.8988418579101562
training step: 52906, total_loss: 5.218087673187256
training step: 52907, total_loss: 4.457223415374756
training step: 52908, total_loss: 4.9871063232421875
training step: 52909, total_loss: 7.428248882293701
training step: 52910, total_loss: 3.2533750534057617
training step: 52911, total_loss: 0.8764172792434692
training step: 52912, total_loss: 6.262070178985596
training step: 52913, total_loss: 4.555273056030273
training step: 52914, total_loss: 3.5462920665740967
training step: 52915, total_loss: 4.8263678550720215
training step: 52916, total_loss: 5.544105529785156
training step: 52917, total_loss: 5.4076690673828125
training step: 52918, total_loss: 4.157223224639893
training step: 52919, total_loss: 2.7829113006591797
training step: 52920, total_loss: 4.111331462860107
training step: 52921, total_loss: 4.095760822296143
training step: 52922, total_loss: 4.5288166999816895
training step: 52923, total_loss: 3.659550905227661
training step: 52924, total_loss: 4.537580490112305
training step: 52925, total_loss: 4.56447696685791
training step: 52926, total_loss: 0.6206739544868469
training step: 52927, total_loss: 4.283224582672119
training step: 52928, total_loss: 4.782270908355713
training step: 52929, total_loss: 5.315082550048828
training step: 52930, total_loss: 4.018017292022705
training step: 52931, total_loss: 4.162333011627197
training step: 52932, total_loss: 5.4364166259765625
training step: 52933, total_loss: 4.502096176147461
training step: 52934, total_loss: 4.291236877441406
training step: 52935, total_loss: 4.0754475593566895
training step: 52936, total_loss: 4.395376682281494
training step: 52937, total_loss: 5.126914024353027
training step: 52938, total_loss: 4.972859859466553
training step: 52939, total_loss: 3.475893497467041
training step: 52940, total_loss: 4.780595779418945
training step: 52941, total_loss: 4.420546531677246
training step: 52942, total_loss: 5.986093997955322
training step: 52943, total_loss: 4.693207740783691
training step: 52944, total_loss: 4.4626007080078125
training step: 52945, total_loss: 3.9616994857788086
training step: 52946, total_loss: 3.151681423187256
training step: 52947, total_loss: 3.8410725593566895
training step: 52948, total_loss: 6.511382102966309
training step: 52949, total_loss: 4.3999128341674805
training step: 52950, total_loss: 3.262277126312256
training step: 52951, total_loss: 4.1971282958984375
training step: 52952, total_loss: 2.276170253753662
training step: 52953, total_loss: 0.8588732481002808
training step: 52954, total_loss: 5.126091957092285INFO:tensorflow:Writing predictions to: residual_output/predictions_53000.json
INFO:tensorflow:Writing nbest to: residual_output/nbest_predictions_53000.json

training step: 52955, total_loss: 3.9277663230895996
training step: 52956, total_loss: 3.281191110610962
training step: 52957, total_loss: 2.8965916633605957
training step: 52958, total_loss: 3.9514107704162598
training step: 52959, total_loss: 5.127540588378906
training step: 52960, total_loss: 3.3562638759613037
training step: 52961, total_loss: 5.090893745422363
training step: 52962, total_loss: 5.131059646606445
training step: 52963, total_loss: 3.1588587760925293
training step: 52964, total_loss: 2.715178966522217
training step: 52965, total_loss: 3.3468008041381836
training step: 52966, total_loss: 4.791213035583496
training step: 52967, total_loss: 4.369552135467529
training step: 52968, total_loss: 4.98392391204834
training step: 52969, total_loss: 2.525240898132324
training step: 52970, total_loss: 4.03424596786499
training step: 52971, total_loss: 3.9862797260284424
training step: 52972, total_loss: 2.3276331424713135
training step: 52973, total_loss: 6.2917938232421875
training step: 52974, total_loss: 3.9933583736419678
training step: 52975, total_loss: 3.7330944538116455
training step: 52976, total_loss: 4.870876312255859
training step: 52977, total_loss: 4.1324052810668945
training step: 52978, total_loss: 3.990285873413086
training step: 52979, total_loss: 3.114182233810425
training step: 52980, total_loss: 5.072455883026123
training step: 52981, total_loss: 5.652403831481934
training step: 52982, total_loss: 4.08302116394043
training step: 52983, total_loss: 4.570278167724609
training step: 52984, total_loss: 5.3766632080078125
training step: 52985, total_loss: 5.471221923828125
training step: 52986, total_loss: 3.512857437133789
training step: 52987, total_loss: 4.170124053955078
training step: 52988, total_loss: 4.5016069412231445
training step: 52989, total_loss: 5.008212566375732
training step: 52990, total_loss: 3.3791120052337646
training step: 52991, total_loss: 4.2385053634643555
training step: 52992, total_loss: 4.0143842697143555
training step: 52993, total_loss: 4.011893272399902
training step: 52994, total_loss: 4.4591145515441895
training step: 52995, total_loss: 2.810182571411133
training step: 52996, total_loss: 4.625326633453369
training step: 52997, total_loss: 4.406879425048828
training step: 52998, total_loss: 2.1284987926483154
training step: 52999, total_loss: 2.3508806228637695
training step: 53000, total_loss: 3.678866147994995
epoch finished! shuffle=False
evaluation: 53000, total_loss: 2.323772668838501, f1: 23.753122785868886, followup: 18.378213905370455, yesno: 1.6126578426897915, heq: 23.018408641411835, dheq: 0.6

Model saved in path residual_output//model_53000.ckpt
training step: 53001, total_loss: 5.072231292724609
training step: 53002, total_loss: 5.087025165557861
training step: 53003, total_loss: 5.091668605804443
training step: 53004, total_loss: 4.443092346191406
training step: 53005, total_loss: 4.398366928100586
training step: 53006, total_loss: 5.3071441650390625
training step: 53007, total_loss: 3.626070737838745
training step: 53008, total_loss: 6.113972187042236
training step: 53009, total_loss: 3.850687026977539
training step: 53010, total_loss: 3.414201259613037
training step: 53011, total_loss: 3.2880823612213135
training step: 53012, total_loss: 4.188690185546875
training step: 53013, total_loss: 3.6291399002075195
training step: 53014, total_loss: 5.405886173248291
training step: 53015, total_loss: 5.865030288696289
training step: 53016, total_loss: 4.1363115310668945
training step: 53017, total_loss: 3.5490047931671143
training step: 53018, total_loss: 2.4367270469665527
training step: 53019, total_loss: 3.140084743499756
training step: 53020, total_loss: 4.276329040527344
training step: 53021, total_loss: 5.080131530761719
training step: 53022, total_loss: 2.8514909744262695
training step: 53023, total_loss: 1.9508341550827026
training step: 53024, total_loss: 3.6508729457855225
training step: 53025, total_loss: 4.698030471801758
training step: 53026, total_loss: 4.377873420715332
training step: 53027, total_loss: 4.020694732666016
training step: 53028, total_loss: 5.148726940155029
training step: 53029, total_loss: 3.6130881309509277
training step: 53030, total_loss: 4.5950236320495605
training step: 53031, total_loss: 6.167284965515137
training step: 53032, total_loss: 6.029201507568359
training step: 53033, total_loss: 3.5953991413116455
training step: 53034, total_loss: 6.212725639343262
training step: 53035, total_loss: 4.1277570724487305
training step: 53036, total_loss: 4.220119953155518
training step: 53037, total_loss: 4.207556247711182
training step: 53038, total_loss: 3.452120780944824
training step: 53039, total_loss: 5.848033905029297
training step: 53040, total_loss: 3.76020884513855
training step: 53041, total_loss: 5.277419567108154
training step: 53042, total_loss: 3.5448336601257324
training step: 53043, total_loss: 3.6527395248413086
training step: 53044, total_loss: 3.3344483375549316
training step: 53045, total_loss: 5.13728666305542
training step: 53046, total_loss: 5.429842472076416
training step: 53047, total_loss: 5.683553695678711
training step: 53048, total_loss: 3.8555867671966553
training step: 53049, total_loss: 5.956752300262451
training step: 53050, total_loss: 4.978628158569336
training step: 53051, total_loss: 6.1606059074401855
training step: 53052, total_loss: 4.3096747398376465
training step: 53053, total_loss: 6.137339115142822
training step: 53054, total_loss: 4.279048919677734
training step: 53055, total_loss: 6.054311275482178
training step: 53056, total_loss: 3.7433254718780518
training step: 53057, total_loss: 2.361438751220703
training step: 53058, total_loss: 3.9282045364379883
training step: 53059, total_loss: 4.041774272918701
training step: 53060, total_loss: 3.242915630340576
training step: 53061, total_loss: 3.8186378479003906
training step: 53062, total_loss: 2.757955551147461
training step: 53063, total_loss: 4.456014633178711
training step: 53064, total_loss: 3.901364803314209
training step: 53065, total_loss: 4.705710411071777
training step: 53066, total_loss: 4.527750492095947
training step: 53067, total_loss: 4.712323188781738
training step: 53068, total_loss: 4.409802436828613
training step: 53069, total_loss: 2.562340259552002
training step: 53070, total_loss: 5.473886489868164
training step: 53071, total_loss: 4.273490905761719
training step: 53072, total_loss: 3.503718852996826
training step: 53073, total_loss: 4.385687828063965
training step: 53074, total_loss: 5.841840744018555
training step: 53075, total_loss: 2.506709575653076
training step: 53076, total_loss: 3.1458892822265625
training step: 53077, total_loss: 3.8325490951538086
training step: 53078, total_loss: 3.8470044136047363
training step: 53079, total_loss: 1.801116943359375
training step: 53080, total_loss: 4.87893533706665
training step: 53081, total_loss: 3.03324031829834
training step: 53082, total_loss: 2.7535581588745117
training step: 53083, total_loss: 3.751774311065674
training step: 53084, total_loss: 4.534057140350342
training step: 53085, total_loss: 5.274730205535889
training step: 53086, total_loss: 7.4558916091918945
training step: 53087, total_loss: 4.484231948852539
training step: 53088, total_loss: 5.621486663818359
training step: 53089, total_loss: 4.928696155548096
training step: 53090, total_loss: 5.111838340759277
training step: 53091, total_loss: 3.3063039779663086
training step: 53092, total_loss: 4.965216636657715
training step: 53093, total_loss: 2.487583637237549
training step: 53094, total_loss: 0.8062793612480164
training step: 53095, total_loss: 7.6393723487854
training step: 53096, total_loss: 5.010616302490234
training step: 53097, total_loss: 4.898541450500488
training step: 53098, total_loss: 2.2614643573760986
training step: 53099, total_loss: 5.0668253898620605
training step: 53100, total_loss: 4.334792137145996
training step: 53101, total_loss: 5.257505416870117
training step: 53102, total_loss: 4.579414367675781
training step: 53103, total_loss: 5.14748477935791
training step: 53104, total_loss: 2.7590456008911133
training step: 53105, total_loss: 4.790391445159912
training step: 53106, total_loss: 5.309843063354492
training step: 53107, total_loss: 6.437143802642822
training step: 53108, total_loss: 4.04041862487793
training step: 53109, total_loss: 6.555516719818115
training step: 53110, total_loss: 4.535825729370117
training step: 53111, total_loss: 4.237335205078125
training step: 53112, total_loss: 4.920175075531006
training step: 53113, total_loss: 4.21466064453125
training step: 53114, total_loss: 3.2252047061920166
training step: 53115, total_loss: 4.4499125480651855
training step: 53116, total_loss: 3.7209880352020264
training step: 53117, total_loss: 3.856748580932617
training step: 53118, total_loss: 4.073592185974121
training step: 53119, total_loss: 5.474722862243652
training step: 53120, total_loss: 4.049925327301025
training step: 53121, total_loss: 4.229741096496582
training step: 53122, total_loss: 4.990484714508057
training step: 53123, total_loss: 3.895643711090088
training step: 53124, total_loss: 4.056941509246826
training step: 53125, total_loss: 3.0305793285369873
training step: 53126, total_loss: 5.0706939697265625
training step: 53127, total_loss: 4.753566741943359
training step: 53128, total_loss: 2.2154839038848877
training step: 53129, total_loss: 3.9778530597686768
training step: 53130, total_loss: 3.7448835372924805
training step: 53131, total_loss: 4.394325256347656
training step: 53132, total_loss: 3.1161599159240723
training step: 53133, total_loss: 4.938723087310791
training step: 53134, total_loss: 3.25675630569458
training step: 53135, total_loss: 6.8267364501953125
training step: 53136, total_loss: 4.754638671875
training step: 53137, total_loss: 4.585513114929199
training step: 53138, total_loss: 4.059504985809326
training step: 53139, total_loss: 4.329990863800049
training step: 53140, total_loss: 5.734485626220703
training step: 53141, total_loss: 4.489170551300049
training step: 53142, total_loss: 4.535239219665527
training step: 53143, total_loss: 3.8286941051483154
training step: 53144, total_loss: 3.8942275047302246
training step: 53145, total_loss: 4.411184787750244
training step: 53146, total_loss: 5.0050883293151855
training step: 53147, total_loss: 5.207611083984375
training step: 53148, total_loss: 4.055251121520996
training step: 53149, total_loss: 3.6508872509002686
training step: 53150, total_loss: 3.7764041423797607
training step: 53151, total_loss: 6.022649765014648
training step: 53152, total_loss: 2.7164742946624756
training step: 53153, total_loss: 4.003416538238525
training step: 53154, total_loss: 6.333793640136719
training step: 53155, total_loss: 3.5629968643188477
training step: 53156, total_loss: 5.833957672119141
training step: 53157, total_loss: 2.326986789703369
training step: 53158, total_loss: 5.029699325561523
training step: 53159, total_loss: 5.475172996520996
training step: 53160, total_loss: 4.28562068939209
training step: 53161, total_loss: 1.8091479539871216
training step: 53162, total_loss: 5.021394729614258
training step: 53163, total_loss: 5.567887306213379
training step: 53164, total_loss: 5.008392333984375
training step: 53165, total_loss: 5.007909774780273
training step: 53166, total_loss: 3.9303693771362305
training step: 53167, total_loss: 4.7566986083984375
training step: 53168, total_loss: 4.361153602600098
training step: 53169, total_loss: 3.723740577697754
training step: 53170, total_loss: 4.232928276062012
training step: 53171, total_loss: 5.937279224395752
training step: 53172, total_loss: 3.7257399559020996
training step: 53173, total_loss: 4.344672203063965
training step: 53174, total_loss: 4.480676651000977
training step: 53175, total_loss: 4.670121192932129
training step: 53176, total_loss: 5.358191013336182
training step: 53177, total_loss: 3.774082899093628
training step: 53178, total_loss: 4.369403839111328
training step: 53179, total_loss: 4.243720054626465
training step: 53180, total_loss: 5.908909797668457
training step: 53181, total_loss: 4.333765506744385
training step: 53182, total_loss: 3.822065830230713
training step: 53183, total_loss: 4.4069037437438965
training step: 53184, total_loss: 5.037906169891357
training step: 53185, total_loss: 2.867300510406494
training step: 53186, total_loss: 4.2929277420043945
training step: 53187, total_loss: 4.717072010040283
training step: 53188, total_loss: 4.475024223327637
training step: 53189, total_loss: 3.7511205673217773
training step: 53190, total_loss: 2.7568342685699463
training step: 53191, total_loss: 1.132502794265747
training step: 53192, total_loss: 7.394155502319336
training step: 53193, total_loss: 4.901381015777588
training step: 53194, total_loss: 4.469547271728516
training step: 53195, total_loss: 5.731262683868408
training step: 53196, total_loss: 4.0084686279296875
training step: 53197, total_loss: 5.288220405578613
training step: 53198, total_loss: 5.084244728088379
training step: 53199, total_loss: 3.338988780975342
training step: 53200, total_loss: 4.8937458992004395
training step: 53201, total_loss: 4.296278953552246
training step: 53202, total_loss: 4.966712474822998
training step: 53203, total_loss: 4.682925701141357
training step: 53204, total_loss: 6.136684894561768
training step: 53205, total_loss: 5.737164497375488
training step: 53206, total_loss: 2.2252633571624756
training step: 53207, total_loss: 5.657649040222168
training step: 53208, total_loss: 4.025550842285156
training step: 53209, total_loss: 3.9388551712036133
training step: 53210, total_loss: 4.533107757568359
training step: 53211, total_loss: 3.5033247470855713
training step: 53212, total_loss: 3.8869900703430176
training step: 53213, total_loss: 3.635066032409668
training step: 53214, total_loss: 4.0362653732299805
training step: 53215, total_loss: 4.658879280090332
training step: 53216, total_loss: 4.768313407897949
training step: 53217, total_loss: 2.4242165088653564
training step: 53218, total_loss: 5.5454792976379395
training step: 53219, total_loss: 5.710382461547852
training step: 53220, total_loss: 3.4588918685913086
training step: 53221, total_loss: 5.029892921447754
training step: 53222, total_loss: 3.3755338191986084
training step: 53223, total_loss: 3.8981101512908936
training step: 53224, total_loss: 3.628770351409912
training step: 53225, total_loss: 5.284124374389648
training step: 53226, total_loss: 3.368377685546875
training step: 53227, total_loss: 5.631843090057373
training step: 53228, total_loss: 2.901017189025879
training step: 53229, total_loss: 4.454790115356445
training step: 53230, total_loss: 4.766587734222412
training step: 53231, total_loss: 3.4538776874542236
training step: 53232, total_loss: 3.8155088424682617
training step: 53233, total_loss: 4.751913070678711
training step: 53234, total_loss: 3.8982832431793213
training step: 53235, total_loss: 3.8901619911193848
training step: 53236, total_loss: 3.5548782348632812
training step: 53237, total_loss: 3.2594099044799805
training step: 53238, total_loss: 5.896485328674316
training step: 53239, total_loss: 4.58842134475708
training step: 53240, total_loss: 5.833039283752441
training step: 53241, total_loss: 4.054037570953369
training step: 53242, total_loss: 3.7659878730773926
training step: 53243, total_loss: 2.771812915802002
training step: 53244, total_loss: 4.811495304107666
training step: 53245, total_loss: 4.441440105438232
training step: 53246, total_loss: 4.738228797912598
training step: 53247, total_loss: 4.011120796203613
training step: 53248, total_loss: 5.146744728088379
training step: 53249, total_loss: 4.674604415893555
training step: 53250, total_loss: 4.7605814933776855
training step: 53251, total_loss: 5.190528869628906
training step: 53252, total_loss: 2.971047878265381
training step: 53253, total_loss: 5.23478364944458
training step: 53254, total_loss: 1.4315447807312012
training step: 53255, total_loss: 4.2953782081604
training step: 53256, total_loss: 5.958518028259277
training step: 53257, total_loss: 1.8025364875793457
training step: 53258, total_loss: 6.809103488922119
training step: 53259, total_loss: 4.398075103759766
training step: 53260, total_loss: 5.1917643547058105
training step: 53261, total_loss: 4.2523040771484375
training step: 53262, total_loss: 4.724703788757324
training step: 53263, total_loss: 4.405250549316406
training step: 53264, total_loss: 4.767315864562988
training step: 53265, total_loss: 5.264013290405273
training step: 53266, total_loss: 4.702680587768555
training step: 53267, total_loss: 4.292984962463379
training step: 53268, total_loss: 5.988916873931885
training step: 53269, total_loss: 3.36958646774292
training step: 53270, total_loss: 4.875391960144043
training step: 53271, total_loss: 3.5060174465179443
training step: 53272, total_loss: 3.819345235824585
training step: 53273, total_loss: 4.239270210266113
training step: 53274, total_loss: 1.9360623359680176
training step: 53275, total_loss: 6.094196319580078
training step: 53276, total_loss: 5.232619285583496
training step: 53277, total_loss: 5.477631568908691
training step: 53278, total_loss: 4.612513542175293
training step: 53279, total_loss: 4.609242916107178
training step: 53280, total_loss: 5.182227611541748
training step: 53281, total_loss: 0.8602258563041687
training step: 53282, total_loss: 4.694639205932617
training step: 53283, total_loss: 4.744314193725586
training step: 53284, total_loss: 3.399644613265991
training step: 53285, total_loss: 5.646455764770508
training step: 53286, total_loss: 3.2375144958496094
training step: 53287, total_loss: 4.006745338439941
training step: 53288, total_loss: 4.170304298400879
training step: 53289, total_loss: 3.3472237586975098
training step: 53290, total_loss: 3.4702746868133545
training step: 53291, total_loss: 6.275692939758301
training step: 53292, total_loss: 4.657036304473877
training step: 53293, total_loss: 4.827552318572998
training step: 53294, total_loss: 3.5018091201782227
training step: 53295, total_loss: 3.967334270477295
training step: 53296, total_loss: 3.286428451538086
training step: 53297, total_loss: 2.6003432273864746
training step: 53298, total_loss: 3.390194892883301
training step: 53299, total_loss: 5.726588249206543
training step: 53300, total_loss: 4.861691474914551
training step: 53301, total_loss: 4.229622840881348
training step: 53302, total_loss: 3.243380069732666
training step: 53303, total_loss: 6.606001377105713
training step: 53304, total_loss: 4.792280673980713
training step: 53305, total_loss: 2.742985248565674
training step: 53306, total_loss: 4.692956924438477
training step: 53307, total_loss: 3.193557024002075
training step: 53308, total_loss: 4.335400581359863
training step: 53309, total_loss: 3.196768045425415
training step: 53310, total_loss: 4.0717010498046875
training step: 53311, total_loss: 3.7401533126831055
training step: 53312, total_loss: 2.9811959266662598
training step: 53313, total_loss: 3.2567262649536133
training step: 53314, total_loss: 5.397313594818115
training step: 53315, total_loss: 4.792425155639648
training step: 53316, total_loss: 3.6515069007873535
training step: 53317, total_loss: 4.801540374755859
training step: 53318, total_loss: 4.108848571777344
training step: 53319, total_loss: 5.640502452850342
training step: 53320, total_loss: 5.914681434631348
training step: 53321, total_loss: 4.528517246246338
training step: 53322, total_loss: 4.061676979064941
training step: 53323, total_loss: 5.35413932800293
training step: 53324, total_loss: 4.015935897827148
training step: 53325, total_loss: 2.879790782928467
training step: 53326, total_loss: 5.3629631996154785
training step: 53327, total_loss: 5.481647491455078
training step: 53328, total_loss: 4.213091850280762
training step: 53329, total_loss: 3.4095325469970703
training step: 53330, total_loss: 4.867612361907959
training step: 53331, total_loss: 4.375792026519775
training step: 53332, total_loss: 4.535953521728516
training step: 53333, total_loss: 4.741827011108398
training step: 53334, total_loss: 4.779996871948242
training step: 53335, total_loss: 2.7438125610351562
training step: 53336, total_loss: 4.55548620223999
training step: 53337, total_loss: 4.962216854095459
training step: 53338, total_loss: 4.634580612182617
training step: 53339, total_loss: 2.7517952919006348
training step: 53340, total_loss: 4.556402683258057
training step: 53341, total_loss: 3.4244444370269775
training step: 53342, total_loss: 5.396437644958496
training step: 53343, total_loss: 4.603339195251465
training step: 53344, total_loss: 3.4810242652893066
training step: 53345, total_loss: 3.3860952854156494
training step: 53346, total_loss: 5.108250141143799
training step: 53347, total_loss: 2.9119157791137695
training step: 53348, total_loss: 5.449274063110352
training step: 53349, total_loss: 2.517775058746338
training step: 53350, total_loss: 3.799764633178711
training step: 53351, total_loss: 4.568426132202148
training step: 53352, total_loss: 4.757672309875488
training step: 53353, total_loss: 4.820202827453613
training step: 53354, total_loss: 5.250725269317627
training step: 53355, total_loss: 4.740105628967285
training step: 53356, total_loss: 5.711347579956055
training step: 53357, total_loss: 3.493557929992676
training step: 53358, total_loss: 2.964778423309326
training step: 53359, total_loss: 4.727758407592773
training step: 53360, total_loss: 3.226043701171875
training step: 53361, total_loss: 5.177568435668945
training step: 53362, total_loss: 5.400064468383789
training step: 53363, total_loss: 4.414632797241211
training step: 53364, total_loss: 3.3836755752563477
training step: 53365, total_loss: 3.6308579444885254
training step: 53366, total_loss: 4.795986175537109
training step: 53367, total_loss: 4.918447494506836
training step: 53368, total_loss: 3.282986640930176
training step: 53369, total_loss: 3.381474494934082
training step: 53370, total_loss: 3.350874423980713
training step: 53371, total_loss: 4.821764945983887
training step: 53372, total_loss: 4.131984710693359
training step: 53373, total_loss: 2.3300342559814453
training step: 53374, total_loss: 4.054459571838379
training step: 53375, total_loss: 5.518927574157715
training step: 53376, total_loss: 2.7337350845336914
training step: 53377, total_loss: 4.131930351257324
training step: 53378, total_loss: 2.3366148471832275
training step: 53379, total_loss: 4.188131332397461
training step: 53380, total_loss: 3.680619239807129
training step: 53381, total_loss: 4.583888053894043
training step: 53382, total_loss: 5.32905387878418
training step: 53383, total_loss: 2.796647071838379
training step: 53384, total_loss: 4.933411598205566
training step: 53385, total_loss: 5.931448936462402
training step: 53386, total_loss: 4.474225044250488
training step: 53387, total_loss: 4.016958236694336
training step: 53388, total_loss: 3.3080878257751465
training step: 53389, total_loss: 3.9781222343444824
training step: 53390, total_loss: 4.077763557434082
training step: 53391, total_loss: 5.602575302124023
training step: 53392, total_loss: 3.303508758544922
training step: 53393, total_loss: 4.642480850219727
training step: 53394, total_loss: 4.238555431365967
training step: 53395, total_loss: 5.434652805328369
training step: 53396, total_loss: 3.0233752727508545
training step: 53397, total_loss: 4.617483139038086
training step: 53398, total_loss: 4.804196357727051
training step: 53399, total_loss: 3.741666316986084
training step: 53400, total_loss: 4.597893714904785
training step: 53401, total_loss: 4.453249454498291
training step: 53402, total_loss: 4.813279151916504
training step: 53403, total_loss: 4.04656982421875
training step: 53404, total_loss: 3.184863805770874
training step: 53405, total_loss: 5.184317111968994
training step: 53406, total_loss: 4.06933069229126
training step: 53407, total_loss: 5.802204132080078
training step: 53408, total_loss: 4.375395774841309
training step: 53409, total_loss: 2.550030469894409
training step: 53410, total_loss: 7.332911491394043
training step: 53411, total_loss: 5.451103687286377
training step: 53412, total_loss: 4.276894569396973
training step: 53413, total_loss: 4.933906555175781
training step: 53414, total_loss: 4.976560592651367
training step: 53415, total_loss: 4.441183090209961
training step: 53416, total_loss: 3.6156182289123535
training step: 53417, total_loss: 4.256904125213623
training step: 53418, total_loss: 3.19104266166687
training step: 53419, total_loss: 4.454113960266113
training step: 53420, total_loss: 3.0716214179992676
training step: 53421, total_loss: 4.36359977722168
training step: 53422, total_loss: 4.1505584716796875
training step: 53423, total_loss: 1.3037981986999512
training step: 53424, total_loss: 4.359911918640137
training step: 53425, total_loss: 5.1498565673828125
training step: 53426, total_loss: 4.938051700592041
training step: 53427, total_loss: 3.724475860595703
training step: 53428, total_loss: 3.5207359790802
training step: 53429, total_loss: 4.966428279876709
training step: 53430, total_loss: 4.962414264678955
training step: 53431, total_loss: 3.596513032913208
training step: 53432, total_loss: 3.40012264251709
training step: 53433, total_loss: 4.604991912841797
training step: 53434, total_loss: 4.093837738037109
training step: 53435, total_loss: 2.4725394248962402
training step: 53436, total_loss: 4.302702903747559
training step: 53437, total_loss: 4.041548728942871
training step: 53438, total_loss: 3.897387742996216
training step: 53439, total_loss: 5.207963943481445
training step: 53440, total_loss: 4.165802955627441
training step: 53441, total_loss: 3.422572374343872
training step: 53442, total_loss: 4.4894609451293945
training step: 53443, total_loss: 4.616781234741211
training step: 53444, total_loss: 4.509683132171631
training step: 53445, total_loss: 4.49320650100708
training step: 53446, total_loss: 4.770943641662598
training step: 53447, total_loss: 3.9040067195892334
training step: 53448, total_loss: 5.79237174987793
training step: 53449, total_loss: 5.942806243896484
training step: 53450, total_loss: 6.354849338531494
training step: 53451, total_loss: 3.75217604637146
training step: 53452, total_loss: 5.577487945556641
training step: 53453, total_loss: 4.310260772705078
training step: 53454, total_loss: 3.5095481872558594
training step: 53455, total_loss: 4.207969665527344
training step: 53456, total_loss: 5.06422758102417
training step: 53457, total_loss: 2.4413082599639893
training step: 53458, total_loss: 2.9569475650787354
training step: 53459, total_loss: 5.03072452545166
training step: 53460, total_loss: 4.671621322631836
training step: 53461, total_loss: 5.12381649017334
training step: 53462, total_loss: 4.755022048950195
training step: 53463, total_loss: 5.577899932861328
training step: 53464, total_loss: 1.8699686527252197
training step: 53465, total_loss: 4.74234676361084
training step: 53466, total_loss: 2.8466196060180664
training step: 53467, total_loss: 5.190755844116211
training step: 53468, total_loss: 4.5286078453063965
training step: 53469, total_loss: 6.423910617828369
training step: 53470, total_loss: 3.367766857147217
training step: 53471, total_loss: 5.216732978820801
training step: 53472, total_loss: 3.460226058959961
training step: 53473, total_loss: 2.5849876403808594
training step: 53474, total_loss: 3.231407642364502
training step: 53475, total_loss: 4.375879287719727
training step: 53476, total_loss: 5.35890007019043
training step: 53477, total_loss: 5.322432041168213
training step: 53478, total_loss: 4.851245403289795
training step: 53479, total_loss: 4.621750831604004
training step: 53480, total_loss: 4.656991004943848
training step: 53481, total_loss: 4.879241943359375
training step: 53482, total_loss: 5.997118949890137
training step: 53483, total_loss: 4.338639736175537
training step: 53484, total_loss: 6.192346572875977
training step: 53485, total_loss: 5.303431510925293
training step: 53486, total_loss: 4.86767578125
training step: 53487, total_loss: 6.728010177612305
training step: 53488, total_loss: 5.328684329986572
training step: 53489, total_loss: 5.7289910316467285
training step: 53490, total_loss: 4.865724086761475
training step: 53491, total_loss: 5.091738700866699
training step: 53492, total_loss: 3.4517922401428223
training step: 53493, total_loss: 4.497574806213379
training step: 53494, total_loss: 5.055096626281738
training step: 53495, total_loss: 0.9569402933120728
training step: 53496, total_loss: 5.288699150085449
training step: 53497, total_loss: 4.085699558258057
training step: 53498, total_loss: 4.4620561599731445
training step: 53499, total_loss: 2.5539674758911133
training step: 53500, total_loss: 3.063791513442993
training step: 53501, total_loss: 6.107227802276611
training step: 53502, total_loss: 4.730943202972412
training step: 53503, total_loss: 3.716693878173828
training step: 53504, total_loss: 4.772711753845215
training step: 53505, total_loss: 2.0614709854125977
training step: 53506, total_loss: 5.423547267913818
training step: 53507, total_loss: 4.8029375076293945
training step: 53508, total_loss: 5.177530288696289
training step: 53509, total_loss: 1.0477808713912964
training step: 53510, total_loss: 4.775239944458008
training step: 53511, total_loss: 3.7438981533050537
training step: 53512, total_loss: 3.6370227336883545
training step: 53513, total_loss: 3.897468328475952
training step: 53514, total_loss: 4.441367149353027
training step: 53515, total_loss: 4.9618730545043945
training step: 53516, total_loss: 4.268891334533691
training step: 53517, total_loss: 5.446237564086914
training step: 53518, total_loss: 4.844412803649902
training step: 53519, total_loss: 4.823155879974365
training step: 53520, total_loss: 5.418949604034424
training step: 53521, total_loss: 4.858942031860352
training step: 53522, total_loss: 3.7407097816467285
training step: 53523, total_loss: 3.5465736389160156
training step: 53524, total_loss: 4.210684776306152
training step: 53525, total_loss: 4.050790786743164
training step: 53526, total_loss: 3.848573684692383
training step: 53527, total_loss: 4.411831378936768
training step: 53528, total_loss: 6.009429931640625
training step: 53529, total_loss: 2.932689905166626
training step: 53530, total_loss: 5.0153913497924805
training step: 53531, total_loss: 5.453378677368164
training step: 53532, total_loss: 4.965744972229004
training step: 53533, total_loss: 3.881180763244629
training step: 53534, total_loss: 4.206815719604492
training step: 53535, total_loss: 4.777537822723389
training step: 53536, total_loss: 4.105369567871094
training step: 53537, total_loss: 4.29844331741333
training step: 53538, total_loss: 6.635410308837891
training step: 53539, total_loss: 4.844914436340332
training step: 53540, total_loss: 2.9195332527160645
training step: 53541, total_loss: 2.9746241569519043
training step: 53542, total_loss: 5.170326232910156
training step: 53543, total_loss: 5.79279899597168
training step: 53544, total_loss: 3.8645057678222656
training step: 53545, total_loss: 4.023674964904785
training step: 53546, total_loss: 4.58730936050415
training step: 53547, total_loss: 4.983448028564453
training step: 53548, total_loss: 4.193524360656738
training step: 53549, total_loss: 3.1492199897766113
training step: 53550, total_loss: 4.016147613525391
training step: 53551, total_loss: 4.735442161560059
training step: 53552, total_loss: 5.973298072814941
training step: 53553, total_loss: 4.48950719833374
training step: 53554, total_loss: 3.613259792327881
training step: 53555, total_loss: 5.006148338317871
training step: 53556, total_loss: 4.894193649291992
training step: 53557, total_loss: 5.001531600952148
training step: 53558, total_loss: 4.67406702041626
training step: 53559, total_loss: 3.2019267082214355
training step: 53560, total_loss: 6.143601894378662
training step: 53561, total_loss: 3.5715138912200928
training step: 53562, total_loss: 5.104281902313232
training step: 53563, total_loss: 4.662896156311035
training step: 53564, total_loss: 3.2563669681549072
training step: 53565, total_loss: 7.478209495544434
training step: 53566, total_loss: 4.98537540435791
training step: 53567, total_loss: 4.36214542388916
training step: 53568, total_loss: 4.839632511138916
training step: 53569, total_loss: 4.7175798416137695
training step: 53570, total_loss: 3.9072396755218506
training step: 53571, total_loss: 3.2288923263549805
training step: 53572, total_loss: 5.617218971252441
training step: 53573, total_loss: 4.221411228179932
training step: 53574, total_loss: 3.5533552169799805
training step: 53575, total_loss: 4.980252265930176
training step: 53576, total_loss: 4.971236705780029
training step: 53577, total_loss: 3.944082021713257
training step: 53578, total_loss: 3.3189620971679688
training step: 53579, total_loss: 3.0773401260375977
training step: 53580, total_loss: 5.2219462394714355
training step: 53581, total_loss: 4.756007194519043
training step: 53582, total_loss: 3.291323661804199
training step: 53583, total_loss: 2.192671775817871
training step: 53584, total_loss: 4.231695175170898
training step: 53585, total_loss: 3.8772120475769043
training step: 53586, total_loss: 4.57175350189209
training step: 53587, total_loss: 3.832303047180176
training step: 53588, total_loss: 3.4185070991516113
training step: 53589, total_loss: 5.91395378112793
training step: 53590, total_loss: 6.103629112243652
training step: 53591, total_loss: 4.448726654052734
training step: 53592, total_loss: 4.754273414611816
training step: 53593, total_loss: 5.479850769042969
training step: 53594, total_loss: 4.354990005493164
training step: 53595, total_loss: 4.126220226287842
training step: 53596, total_loss: 2.931422710418701
training step: 53597, total_loss: 2.872084379196167
training step: 53598, total_loss: 4.208260536193848
training step: 53599, total_loss: 3.989306926727295
training step: 53600, total_loss: 4.652166366577148
training step: 53601, total_loss: 5.234031677246094
training step: 53602, total_loss: 3.9551429748535156
training step: 53603, total_loss: 2.622176170349121
training step: 53604, total_loss: 6.547039031982422
training step: 53605, total_loss: 4.552462577819824
training step: 53606, total_loss: 4.612232208251953
training step: 53607, total_loss: 4.882898330688477
training step: 53608, total_loss: 3.8994550704956055
training step: 53609, total_loss: 4.038658618927002
training step: 53610, total_loss: 4.197438716888428
training step: 53611, total_loss: 4.108204364776611
training step: 53612, total_loss: 5.058659553527832
training step: 53613, total_loss: 3.4025766849517822
training step: 53614, total_loss: 4.158086776733398
training step: 53615, total_loss: 3.697662353515625
training step: 53616, total_loss: 4.138144016265869
training step: 53617, total_loss: 4.947517395019531
training step: 53618, total_loss: 6.409174919128418
training step: 53619, total_loss: 4.3506669998168945
training step: 53620, total_loss: 3.619276762008667
training step: 53621, total_loss: 2.960709571838379
training step: 53622, total_loss: 5.360367774963379
training step: 53623, total_loss: 3.386106491088867
training step: 53624, total_loss: 5.4353837966918945
training step: 53625, total_loss: 3.3429391384124756
training step: 53626, total_loss: 4.356967926025391
training step: 53627, total_loss: 4.766656875610352
training step: 53628, total_loss: 3.827007293701172
training step: 53629, total_loss: 5.70394229888916
training step: 53630, total_loss: 4.505669593811035
training step: 53631, total_loss: 4.554513454437256
training step: 53632, total_loss: 5.109034538269043
training step: 53633, total_loss: 3.935842990875244
training step: 53634, total_loss: 4.0386505126953125
training step: 53635, total_loss: 4.3288493156433105
training step: 53636, total_loss: 4.353604316711426
training step: 53637, total_loss: 4.277649402618408
training step: 53638, total_loss: 4.610564708709717
training step: 53639, total_loss: 3.714838981628418
training step: 53640, total_loss: 2.983954906463623
training step: 53641, total_loss: 5.119980335235596
training step: 53642, total_loss: 5.014657020568848
training step: 53643, total_loss: 3.7160940170288086
training step: 53644, total_loss: 5.831306457519531
training step: 53645, total_loss: 2.723557233810425
training step: 53646, total_loss: 2.3369381427764893
training step: 53647, total_loss: 2.991286039352417
training step: 53648, total_loss: 4.5002288818359375
training step: 53649, total_loss: 3.725470542907715
training step: 53650, total_loss: 3.9081497192382812
training step: 53651, total_loss: 4.7938761711120605
training step: 53652, total_loss: 3.644056797027588
training step: 53653, total_loss: 2.481764316558838
training step: 53654, total_loss: 5.3939008712768555
training step: 53655, total_loss: 2.9395828247070312
training step: 53656, total_loss: 4.094691276550293
training step: 53657, total_loss: 2.8302793502807617
training step: 53658, total_loss: 2.947960615158081
training step: 53659, total_loss: 3.9898769855499268
training step: 53660, total_loss: 5.373628616333008
training step: 53661, total_loss: 5.035381317138672
training step: 53662, total_loss: 2.432194948196411
training step: 53663, total_loss: 3.286287784576416
training step: 53664, total_loss: 4.960131645202637
training step: 53665, total_loss: 6.052460670471191
training step: 53666, total_loss: 3.452718734741211
training step: 53667, total_loss: 3.994009494781494
training step: 53668, total_loss: 3.557659149169922
training step: 53669, total_loss: 4.024999618530273
training step: 53670, total_loss: 1.3144941329956055
training step: 53671, total_loss: 2.7170863151550293
training step: 53672, total_loss: 4.091204643249512
training step: 53673, total_loss: 4.139833450317383
training step: 53674, total_loss: 4.161348342895508
training step: 53675, total_loss: 3.611529588699341
training step: 53676, total_loss: 4.062864780426025
training step: 53677, total_loss: 4.962050437927246
training step: 53678, total_loss: 5.84207820892334
training step: 53679, total_loss: 4.378552436828613
training step: 53680, total_loss: 3.7789556980133057
training step: 53681, total_loss: 4.152176856994629
training step: 53682, total_loss: 3.988945960998535
training step: 53683, total_loss: 6.173848628997803
training step: 53684, total_loss: 5.097147464752197
training step: 53685, total_loss: 4.379842758178711
training step: 53686, total_loss: 3.9961392879486084
training step: 53687, total_loss: 4.033465385437012
training step: 53688, total_loss: 2.9775588512420654
training step: 53689, total_loss: 3.9032111167907715
training step: 53690, total_loss: 4.86932373046875
training step: 53691, total_loss: 4.345645427703857
training step: 53692, total_loss: 4.416234016418457
training step: 53693, total_loss: 3.1746268272399902
training step: 53694, total_loss: 5.4290924072265625
training step: 53695, total_loss: 3.2551491260528564
training step: 53696, total_loss: 3.4648804664611816
training step: 53697, total_loss: 4.174534797668457
training step: 53698, total_loss: 4.2899580001831055
training step: 53699, total_loss: 4.321197986602783
training step: 53700, total_loss: 4.909782409667969
training step: 53701, total_loss: 4.96343994140625
training step: 53702, total_loss: 4.4231648445129395
training step: 53703, total_loss: 1.6993224620819092
training step: 53704, total_loss: 3.2910776138305664
training step: 53705, total_loss: 4.483232021331787
training step: 53706, total_loss: 2.4580767154693604
training step: 53707, total_loss: 4.493456840515137
training step: 53708, total_loss: 4.669188022613525
training step: 53709, total_loss: 3.5706748962402344
training step: 53710, total_loss: 4.4318413734436035
training step: 53711, total_loss: 2.4012858867645264
training step: 53712, total_loss: 3.7327208518981934
training step: 53713, total_loss: 4.136686325073242
training step: 53714, total_loss: 4.860578536987305
training step: 53715, total_loss: 3.444044828414917
training step: 53716, total_loss: 4.302382469177246
training step: 53717, total_loss: 3.364784002304077
training step: 53718, total_loss: 6.323004722595215
training step: 53719, total_loss: 3.9732565879821777
training step: 53720, total_loss: 4.69321346282959
training step: 53721, total_loss: 4.491005897521973
training step: 53722, total_loss: 4.210770130157471
training step: 53723, total_loss: 3.3279919624328613
training step: 53724, total_loss: 4.252427577972412
training step: 53725, total_loss: 5.774362564086914
training step: 53726, total_loss: 5.218498229980469
training step: 53727, total_loss: 4.449599266052246
training step: 53728, total_loss: 3.593418598175049
training step: 53729, total_loss: 4.383321285247803
training step: 53730, total_loss: 4.168368816375732
training step: 53731, total_loss: 4.816102504730225
training step: 53732, total_loss: 4.874205589294434
training step: 53733, total_loss: 3.157351016998291
training step: 53734, total_loss: 4.338532447814941
training step: 53735, total_loss: 4.934492111206055
training step: 53736, total_loss: 4.678795337677002
training step: 53737, total_loss: 2.6379475593566895
training step: 53738, total_loss: 4.713692665100098
training step: 53739, total_loss: 4.023355960845947
training step: 53740, total_loss: 5.262999534606934
training step: 53741, total_loss: 6.245328426361084
training step: 53742, total_loss: 5.446791648864746
training step: 53743, total_loss: 4.228265762329102
training step: 53744, total_loss: 1.0686691999435425
training step: 53745, total_loss: 4.256471157073975
training step: 53746, total_loss: 3.09299373626709
training step: 53747, total_loss: 5.213706970214844
training step: 53748, total_loss: 3.9179792404174805
training step: 53749, total_loss: 4.638633728027344
training step: 53750, total_loss: 4.348147392272949
training step: 53751, total_loss: 4.789457321166992
training step: 53752, total_loss: 5.09373664855957
training step: 53753, total_loss: 5.261965751647949
training step: 53754, total_loss: 4.601442813873291
training step: 53755, total_loss: 4.470399379730225
training step: 53756, total_loss: 4.656632900238037
training step: 53757, total_loss: 4.898321628570557
training step: 53758, total_loss: 4.508049011230469
training step: 53759, total_loss: 3.916250705718994
training step: 53760, total_loss: 3.4420409202575684
training step: 53761, total_loss: 4.7431793212890625
training step: 53762, total_loss: 4.353855133056641
training step: 53763, total_loss: 4.437771320343018
training step: 53764, total_loss: 5.011119842529297
training step: 53765, total_loss: 5.4465227127075195
training step: 53766, total_loss: 4.516228675842285
training step: 53767, total_loss: 4.159252166748047
training step: 53768, total_loss: 4.569950580596924
training step: 53769, total_loss: 3.301698923110962
training step: 53770, total_loss: 3.3578903675079346
training step: 53771, total_loss: 2.5317025184631348
training step: 53772, total_loss: 5.329540252685547
training step: 53773, total_loss: 6.814958572387695
training step: 53774, total_loss: 4.586014747619629
training step: 53775, total_loss: 4.4247541427612305
training step: 53776, total_loss: 4.191314697265625
training step: 53777, total_loss: 3.3885297775268555
training step: 53778, total_loss: 2.7612767219543457
training step: 53779, total_loss: 3.918382167816162
training step: 53780, total_loss: 3.1932244300842285
training step: 53781, total_loss: 4.57935905456543
training step: 53782, total_loss: 4.846982479095459
training step: 53783, total_loss: 4.585794925689697
training step: 53784, total_loss: 2.9950008392333984
training step: 53785, total_loss: 4.999968528747559
training step: 53786, total_loss: 3.609875440597534
training step: 53787, total_loss: 5.166377544403076
training step: 53788, total_loss: 4.285573959350586
training step: 53789, total_loss: 3.3865177631378174
training step: 53790, total_loss: 1.6355637311935425
training step: 53791, total_loss: 4.856905937194824
training step: 53792, total_loss: 4.168521881103516
training step: 53793, total_loss: 5.632216930389404
training step: 53794, total_loss: 3.456775426864624
training step: 53795, total_loss: 6.051487922668457
training step: 53796, total_loss: 6.111456394195557
training step: 53797, total_loss: 4.2717485427856445
training step: 53798, total_loss: 4.781439304351807
training step: 53799, total_loss: 4.731960296630859
training step: 53800, total_loss: 2.59702730178833
training step: 53801, total_loss: 4.737576484680176
training step: 53802, total_loss: 3.674075126647949
training step: 53803, total_loss: 4.141725540161133
training step: 53804, total_loss: 3.738088369369507
training step: 53805, total_loss: 4.908879280090332
training step: 53806, total_loss: 4.974043846130371
training step: 53807, total_loss: 2.9138636589050293
training step: 53808, total_loss: 5.855741500854492
training step: 53809, total_loss: 5.006032943725586
training step: 53810, total_loss: 4.317437171936035
training step: 53811, total_loss: 6.0070013999938965
training step: 53812, total_loss: 4.615903854370117
training step: 53813, total_loss: 4.556323051452637
training step: 53814, total_loss: 4.610848426818848
training step: 53815, total_loss: 4.966222286224365
training step: 53816, total_loss: 4.475958824157715
training step: 53817, total_loss: 4.358713150024414
training step: 53818, total_loss: 4.778048515319824
training step: 53819, total_loss: 3.570283889770508
training step: 53820, total_loss: 4.501829147338867
training step: 53821, total_loss: 3.953463077545166
training step: 53822, total_loss: 4.0942487716674805
training step: 53823, total_loss: 5.197078227996826
training step: 53824, total_loss: 4.214381694793701
training step: 53825, total_loss: 4.490072250366211
training step: 53826, total_loss: 3.6788718700408936
training step: 53827, total_loss: 4.2248921394348145
training step: 53828, total_loss: 5.063399791717529
training step: 53829, total_loss: 5.010187149047852
training step: 53830, total_loss: 2.57913875579834
training step: 53831, total_loss: 4.6227216720581055
training step: 53832, total_loss: 4.946476936340332
training step: 53833, total_loss: 5.288867950439453
training step: 53834, total_loss: 3.418257236480713
training step: 53835, total_loss: 4.906733512878418
training step: 53836, total_loss: 3.632023334503174
training step: 53837, total_loss: 3.371551513671875
training step: 53838, total_loss: 3.803546905517578
training step: 53839, total_loss: 5.798127174377441
training step: 53840, total_loss: 3.3057496547698975
training step: 53841, total_loss: 4.17185640335083
training step: 53842, total_loss: 3.8469181060791016
training step: 53843, total_loss: 4.6347784996032715
training step: 53844, total_loss: 4.036275863647461
training step: 53845, total_loss: 4.0804762840271
training step: 53846, total_loss: 5.718997001647949
training step: 53847, total_loss: 4.18197774887085
training step: 53848, total_loss: 4.112858772277832
training step: 53849, total_loss: 3.887132167816162
training step: 53850, total_loss: 3.038240432739258
training step: 53851, total_loss: 5.333470344543457
training step: 53852, total_loss: 4.141767501831055
training step: 53853, total_loss: 3.3996005058288574
training step: 53854, total_loss: 5.157686233520508
training step: 53855, total_loss: 4.031689167022705
training step: 53856, total_loss: 4.3539838790893555
training step: 53857, total_loss: 4.554935932159424
training step: 53858, total_loss: 3.9518847465515137
training step: 53859, total_loss: 4.159940719604492
training step: 53860, total_loss: 5.1371917724609375
training step: 53861, total_loss: 3.634082078933716
training step: 53862, total_loss: 5.284337997436523
training step: 53863, total_loss: 3.7252464294433594
training step: 53864, total_loss: 3.4788625240325928
training step: 53865, total_loss: 4.407322883605957
training step: 53866, total_loss: 4.7870402336120605
training step: 53867, total_loss: 4.6949687004089355
training step: 53868, total_loss: 2.9179015159606934
training step: 53869, total_loss: 6.087547302246094
training step: 53870, total_loss: 6.653352737426758
training step: 53871, total_loss: 4.784483909606934
training step: 53872, total_loss: 3.731235980987549
training step: 53873, total_loss: 5.035072326660156
training step: 53874, total_loss: 4.169334411621094
training step: 53875, total_loss: 4.177187919616699
training step: 53876, total_loss: 5.0311198234558105
training step: 53877, total_loss: 3.5880870819091797
training step: 53878, total_loss: 5.5547099113464355
training step: 53879, total_loss: 5.0814056396484375
training step: 53880, total_loss: 4.01171875
training step: 53881, total_loss: 3.1175808906555176
training step: 53882, total_loss: 4.0998406410217285
training step: 53883, total_loss: 4.362215042114258
training step: 53884, total_loss: 4.617220878601074
training step: 53885, total_loss: 4.086838722229004
training step: 53886, total_loss: 4.182164192199707
training step: 53887, total_loss: 4.731086730957031
training step: 53888, total_loss: 5.316075325012207
training step: 53889, total_loss: 4.438226222991943
training step: 53890, total_loss: 2.529149293899536
training step: 53891, total_loss: 4.773689270019531
training step: 53892, total_loss: 4.124300003051758
training step: 53893, total_loss: 3.3882763385772705
training step: 53894, total_loss: 5.254715442657471INFO:tensorflow:Writing predictions to: residual_output/predictions_54000.json
INFO:tensorflow:Writing nbest to: residual_output/nbest_predictions_54000.json

training step: 53895, total_loss: 4.870792865753174
training step: 53896, total_loss: 5.397803783416748
training step: 53897, total_loss: 5.441694259643555
training step: 53898, total_loss: 4.20329475402832
training step: 53899, total_loss: 3.527280330657959
training step: 53900, total_loss: 4.785584449768066
training step: 53901, total_loss: 4.28757381439209
training step: 53902, total_loss: 4.258818626403809
training step: 53903, total_loss: 4.719013214111328
training step: 53904, total_loss: 3.832580804824829
training step: 53905, total_loss: 3.263747215270996
training step: 53906, total_loss: 3.292632579803467
training step: 53907, total_loss: 3.8711676597595215
training step: 53908, total_loss: 4.589510917663574
training step: 53909, total_loss: 4.486444473266602
training step: 53910, total_loss: 4.441765785217285
training step: 53911, total_loss: 3.561068534851074
training step: 53912, total_loss: 4.562736511230469
training step: 53913, total_loss: 4.258922100067139
training step: 53914, total_loss: 4.4473066329956055
training step: 53915, total_loss: 4.399473667144775
training step: 53916, total_loss: 4.736398696899414
training step: 53917, total_loss: 4.334674835205078
training step: 53918, total_loss: 4.587325572967529
training step: 53919, total_loss: 3.421818256378174
training step: 53920, total_loss: 3.7532966136932373
training step: 53921, total_loss: 4.715926170349121
training step: 53922, total_loss: 2.8707571029663086
training step: 53923, total_loss: 3.0567588806152344
training step: 53924, total_loss: 5.037327766418457
training step: 53925, total_loss: 5.388648509979248
training step: 53926, total_loss: 4.72413444519043
training step: 53927, total_loss: 3.3406925201416016
training step: 53928, total_loss: 4.676353931427002
training step: 53929, total_loss: 3.706057071685791
training step: 53930, total_loss: 5.602582931518555
training step: 53931, total_loss: 4.660348892211914
training step: 53932, total_loss: 3.9702413082122803
training step: 53933, total_loss: 3.942115306854248
training step: 53934, total_loss: 3.9726078510284424
training step: 53935, total_loss: 3.584545612335205
training step: 53936, total_loss: 4.063723087310791
training step: 53937, total_loss: 5.233926773071289
training step: 53938, total_loss: 4.396454811096191
training step: 53939, total_loss: 5.016149520874023
training step: 53940, total_loss: 4.27265739440918
training step: 53941, total_loss: 4.599689483642578
training step: 53942, total_loss: 4.072233200073242
training step: 53943, total_loss: 3.9525740146636963
training step: 53944, total_loss: 4.235517978668213
training step: 53945, total_loss: 3.9070563316345215
training step: 53946, total_loss: 4.13372802734375
training step: 53947, total_loss: 3.9433541297912598
training step: 53948, total_loss: 4.3632941246032715
training step: 53949, total_loss: 5.194375514984131
training step: 53950, total_loss: 2.767779588699341
training step: 53951, total_loss: 4.9086012840271
training step: 53952, total_loss: 5.073239326477051
training step: 53953, total_loss: 4.5051445960998535
training step: 53954, total_loss: 2.9864070415496826
training step: 53955, total_loss: 4.751669406890869
training step: 53956, total_loss: 3.059065341949463
training step: 53957, total_loss: 5.007713317871094
training step: 53958, total_loss: 4.8057355880737305
training step: 53959, total_loss: 3.6977200508117676
training step: 53960, total_loss: 4.466713905334473
training step: 53961, total_loss: 4.996850490570068
training step: 53962, total_loss: 5.580057144165039
training step: 53963, total_loss: 3.5768771171569824
training step: 53964, total_loss: 2.508575439453125
training step: 53965, total_loss: 5.709288597106934
training step: 53966, total_loss: 2.791081428527832
training step: 53967, total_loss: 6.479918479919434
training step: 53968, total_loss: 5.8067851066589355
training step: 53969, total_loss: 6.851722240447998
training step: 53970, total_loss: 4.374699592590332
training step: 53971, total_loss: 5.53433895111084
training step: 53972, total_loss: 6.388286590576172
training step: 53973, total_loss: 4.389954090118408
training step: 53974, total_loss: 4.681227684020996
training step: 53975, total_loss: 5.583812713623047
training step: 53976, total_loss: 3.4687628746032715
training step: 53977, total_loss: 4.48026180267334
training step: 53978, total_loss: 4.113351821899414
training step: 53979, total_loss: 3.799163341522217
training step: 53980, total_loss: 3.7559304237365723
training step: 53981, total_loss: 4.793356418609619
training step: 53982, total_loss: 5.602365493774414
training step: 53983, total_loss: 4.24293851852417
training step: 53984, total_loss: 4.315086364746094
training step: 53985, total_loss: 3.015212059020996
training step: 53986, total_loss: 4.596707344055176
training step: 53987, total_loss: 4.136676788330078
training step: 53988, total_loss: 4.514967918395996
training step: 53989, total_loss: 3.8480634689331055
training step: 53990, total_loss: 2.133974075317383
training step: 53991, total_loss: 5.034963607788086
training step: 53992, total_loss: 2.409865140914917
training step: 53993, total_loss: 4.104946136474609
training step: 53994, total_loss: 4.807531356811523
training step: 53995, total_loss: 4.2981367111206055
training step: 53996, total_loss: 3.8480396270751953
training step: 53997, total_loss: 5.715180397033691
training step: 53998, total_loss: 2.611192464828491
training step: 53999, total_loss: 4.118697643280029
training step: 54000, total_loss: 6.436991214752197
epoch finished! shuffle=False
evaluation: 54000, total_loss: 2.3239212036132812, f1: 23.71268386839674, followup: 18.378213905370455, yesno: 1.6126578426897915, heq: 22.4554997717937, dheq: 0.4

Model saved in path residual_output//model_54000.ckpt
training step: 54001, total_loss: 5.110053539276123
training step: 54002, total_loss: 4.195438861846924
training step: 54003, total_loss: 6.382027626037598
training step: 54004, total_loss: 4.551424026489258
training step: 54005, total_loss: 4.588285446166992
training step: 54006, total_loss: 4.315976619720459
training step: 54007, total_loss: 2.2789480686187744
training step: 54008, total_loss: 4.787230491638184
training step: 54009, total_loss: 4.8812055587768555
training step: 54010, total_loss: 4.387213230133057
training step: 54011, total_loss: 4.375479698181152
training step: 54012, total_loss: 4.987293720245361
training step: 54013, total_loss: 2.628605365753174
training step: 54014, total_loss: 2.5007643699645996
training step: 54015, total_loss: 5.0385422706604
training step: 54016, total_loss: 3.9569826126098633
training step: 54017, total_loss: 4.57290506362915
training step: 54018, total_loss: 3.8880093097686768
training step: 54019, total_loss: 5.31172513961792
training step: 54020, total_loss: 4.739895343780518
training step: 54021, total_loss: 4.2825493812561035
training step: 54022, total_loss: 4.854827880859375
training step: 54023, total_loss: 5.323416709899902
training step: 54024, total_loss: 5.397967338562012
training step: 54025, total_loss: 3.922334671020508
training step: 54026, total_loss: 5.878232955932617
training step: 54027, total_loss: 4.188697814941406
training step: 54028, total_loss: 5.224861145019531
training step: 54029, total_loss: 5.070740699768066
training step: 54030, total_loss: 1.0721629858016968
training step: 54031, total_loss: 4.798750877380371
training step: 54032, total_loss: 4.190940856933594
training step: 54033, total_loss: 3.192805767059326
training step: 54034, total_loss: 4.919950485229492
training step: 54035, total_loss: 5.964512348175049
training step: 54036, total_loss: 3.0999083518981934
training step: 54037, total_loss: 4.922433853149414
training step: 54038, total_loss: 5.747561931610107
training step: 54039, total_loss: 4.7078986167907715
training step: 54040, total_loss: 4.53485107421875
training step: 54041, total_loss: 4.990331649780273
training step: 54042, total_loss: 3.514845371246338
training step: 54043, total_loss: 3.5296225547790527
training step: 54044, total_loss: 4.17220401763916
training step: 54045, total_loss: 5.965801239013672
training step: 54046, total_loss: 3.1304402351379395
training step: 54047, total_loss: 1.5974230766296387
training step: 54048, total_loss: 3.3139233589172363
training step: 54049, total_loss: 1.1052864789962769
training step: 54050, total_loss: 4.341243743896484
training step: 54051, total_loss: 3.958749294281006
training step: 54052, total_loss: 4.374329566955566
training step: 54053, total_loss: 4.092667579650879
training step: 54054, total_loss: 4.703404426574707
training step: 54055, total_loss: 4.741725921630859
training step: 54056, total_loss: 3.8815712928771973
training step: 54057, total_loss: 5.035586357116699
training step: 54058, total_loss: 4.166670322418213
training step: 54059, total_loss: 4.7215166091918945
training step: 54060, total_loss: 4.203093528747559
training step: 54061, total_loss: 4.119255542755127
training step: 54062, total_loss: 4.734054088592529
training step: 54063, total_loss: 4.466897964477539
training step: 54064, total_loss: 3.0942187309265137
training step: 54065, total_loss: 3.959019184112549
training step: 54066, total_loss: 5.3869428634643555
training step: 54067, total_loss: 4.623894691467285
training step: 54068, total_loss: 4.202751159667969
training step: 54069, total_loss: 4.803560256958008
training step: 54070, total_loss: 5.008497714996338
training step: 54071, total_loss: 5.249350070953369
training step: 54072, total_loss: 4.0718231201171875
training step: 54073, total_loss: 4.7138848304748535
training step: 54074, total_loss: 4.25714635848999
training step: 54075, total_loss: 5.298382759094238
training step: 54076, total_loss: 4.105838775634766
training step: 54077, total_loss: 3.876645088195801
training step: 54078, total_loss: 6.023155212402344
training step: 54079, total_loss: 3.9031295776367188
training step: 54080, total_loss: 3.6744306087493896
training step: 54081, total_loss: 5.413376331329346
training step: 54082, total_loss: 3.7741127014160156
training step: 54083, total_loss: 4.444980621337891
training step: 54084, total_loss: 5.015765190124512
training step: 54085, total_loss: 4.229461193084717
training step: 54086, total_loss: 3.1260452270507812
training step: 54087, total_loss: 3.124405860900879
training step: 54088, total_loss: 5.184708595275879
training step: 54089, total_loss: 5.147597789764404
training step: 54090, total_loss: 3.6793136596679688
training step: 54091, total_loss: 4.461888313293457
training step: 54092, total_loss: 3.497471809387207
training step: 54093, total_loss: 4.326299667358398
training step: 54094, total_loss: 5.374950885772705
training step: 54095, total_loss: 5.057336807250977
training step: 54096, total_loss: 4.298854827880859
training step: 54097, total_loss: 3.9923501014709473
training step: 54098, total_loss: 2.9502620697021484
training step: 54099, total_loss: 5.480870246887207
training step: 54100, total_loss: 4.69938850402832
training step: 54101, total_loss: 4.313136577606201
training step: 54102, total_loss: 4.660050392150879
training step: 54103, total_loss: 2.9098541736602783
training step: 54104, total_loss: 2.884284019470215
training step: 54105, total_loss: 3.850248098373413
training step: 54106, total_loss: 3.2708911895751953
training step: 54107, total_loss: 4.063106536865234
training step: 54108, total_loss: 4.18719482421875
training step: 54109, total_loss: 4.857937812805176
training step: 54110, total_loss: 4.621082782745361
training step: 54111, total_loss: 3.3282179832458496
training step: 54112, total_loss: 4.410886764526367
training step: 54113, total_loss: 5.954254150390625
training step: 54114, total_loss: 1.1619316339492798
training step: 54115, total_loss: 4.258613109588623
training step: 54116, total_loss: 3.5208749771118164
training step: 54117, total_loss: 4.267640113830566
training step: 54118, total_loss: 3.9466075897216797
training step: 54119, total_loss: 4.0397114753723145
training step: 54120, total_loss: 3.318009614944458
training step: 54121, total_loss: 4.02264928817749
training step: 54122, total_loss: 3.1356616020202637
training step: 54123, total_loss: 4.801186561584473
training step: 54124, total_loss: 3.9784884452819824
training step: 54125, total_loss: 3.315866470336914
training step: 54126, total_loss: 4.693626403808594
training step: 54127, total_loss: 5.156285285949707
training step: 54128, total_loss: 4.0964179039001465
training step: 54129, total_loss: 4.128522872924805
training step: 54130, total_loss: 4.116450786590576
training step: 54131, total_loss: 4.788272857666016
training step: 54132, total_loss: 3.691006660461426
training step: 54133, total_loss: 4.610351085662842
training step: 54134, total_loss: 4.743166923522949
training step: 54135, total_loss: 3.5907201766967773
training step: 54136, total_loss: 4.979860305786133
training step: 54137, total_loss: 2.9659154415130615
training step: 54138, total_loss: 4.037664413452148
training step: 54139, total_loss: 4.336940288543701
training step: 54140, total_loss: 8.036348342895508
training step: 54141, total_loss: 4.154521465301514
training step: 54142, total_loss: 3.7046289443969727
training step: 54143, total_loss: 5.703094482421875
training step: 54144, total_loss: 3.9790995121002197
training step: 54145, total_loss: 2.5946667194366455
training step: 54146, total_loss: 3.2690813541412354
training step: 54147, total_loss: 3.5111231803894043
training step: 54148, total_loss: 3.4203743934631348
training step: 54149, total_loss: 5.062912940979004
training step: 54150, total_loss: 4.566428184509277
training step: 54151, total_loss: 4.395849227905273
training step: 54152, total_loss: 4.181882858276367
training step: 54153, total_loss: 4.1307878494262695
training step: 54154, total_loss: 4.234155654907227
training step: 54155, total_loss: 4.427485942840576
training step: 54156, total_loss: 5.454494476318359
training step: 54157, total_loss: 1.0675115585327148
training step: 54158, total_loss: 2.9688663482666016
training step: 54159, total_loss: 3.5651841163635254
training step: 54160, total_loss: 4.136256217956543
training step: 54161, total_loss: 4.7496843338012695
training step: 54162, total_loss: 3.386685609817505
training step: 54163, total_loss: 4.717085361480713
training step: 54164, total_loss: 3.437972068786621
training step: 54165, total_loss: 5.079784393310547
training step: 54166, total_loss: 3.425031900405884
training step: 54167, total_loss: 4.925445079803467
training step: 54168, total_loss: 1.1030209064483643
training step: 54169, total_loss: 4.948822021484375
training step: 54170, total_loss: 4.458831787109375
training step: 54171, total_loss: 3.962615489959717
training step: 54172, total_loss: 4.685664176940918
training step: 54173, total_loss: 5.560883522033691
training step: 54174, total_loss: 4.813324928283691
training step: 54175, total_loss: 5.119806289672852
training step: 54176, total_loss: 3.946751594543457
training step: 54177, total_loss: 5.7083587646484375
training step: 54178, total_loss: 3.8423824310302734
training step: 54179, total_loss: 3.0352694988250732
training step: 54180, total_loss: 3.2989611625671387
training step: 54181, total_loss: 5.003327369689941
training step: 54182, total_loss: 5.662386894226074
training step: 54183, total_loss: 4.278571128845215
training step: 54184, total_loss: 4.699750900268555
training step: 54185, total_loss: 4.102250576019287
training step: 54186, total_loss: 4.0414347648620605
training step: 54187, total_loss: 4.512783527374268
training step: 54188, total_loss: 3.137552261352539
training step: 54189, total_loss: 3.9755208492279053
training step: 54190, total_loss: 3.6205663681030273
training step: 54191, total_loss: 4.533367156982422
training step: 54192, total_loss: 3.6485772132873535
training step: 54193, total_loss: 4.653338432312012
training step: 54194, total_loss: 5.55531120300293
training step: 54195, total_loss: 3.0653233528137207
training step: 54196, total_loss: 4.734511375427246
training step: 54197, total_loss: 4.7954864501953125
training step: 54198, total_loss: 4.392595291137695
training step: 54199, total_loss: 3.099916696548462
training step: 54200, total_loss: 5.0544610023498535
training step: 54201, total_loss: 3.2406249046325684
training step: 54202, total_loss: 4.791977882385254
training step: 54203, total_loss: 4.925909996032715
training step: 54204, total_loss: 5.610544204711914
training step: 54205, total_loss: 3.639047145843506
training step: 54206, total_loss: 4.468245506286621
training step: 54207, total_loss: 4.980437755584717
training step: 54208, total_loss: 4.467308044433594
training step: 54209, total_loss: 3.8270928859710693
training step: 54210, total_loss: 5.427044868469238
training step: 54211, total_loss: 4.002773284912109
training step: 54212, total_loss: 4.1585693359375
training step: 54213, total_loss: 4.00318717956543
training step: 54214, total_loss: 2.750063180923462
training step: 54215, total_loss: 4.370021820068359
training step: 54216, total_loss: 2.988492012023926
training step: 54217, total_loss: 4.142849922180176
training step: 54218, total_loss: 6.0614142417907715
training step: 54219, total_loss: 4.828778266906738
training step: 54220, total_loss: 4.377378463745117
training step: 54221, total_loss: 4.783931732177734
training step: 54222, total_loss: 4.267969131469727
training step: 54223, total_loss: 2.322868824005127
training step: 54224, total_loss: 5.169651031494141
training step: 54225, total_loss: 4.1735758781433105
training step: 54226, total_loss: 2.935183525085449
training step: 54227, total_loss: 4.731578350067139
training step: 54228, total_loss: 3.766559362411499
training step: 54229, total_loss: 4.199281692504883
training step: 54230, total_loss: 3.7695326805114746
training step: 54231, total_loss: 4.205995559692383
training step: 54232, total_loss: 4.164192199707031
training step: 54233, total_loss: 4.394278526306152
training step: 54234, total_loss: 3.1746859550476074
training step: 54235, total_loss: 5.030277729034424
training step: 54236, total_loss: 4.589869499206543
training step: 54237, total_loss: 3.4524922370910645
training step: 54238, total_loss: 5.392561912536621
training step: 54239, total_loss: 4.568448066711426
training step: 54240, total_loss: 4.804693222045898
training step: 54241, total_loss: 5.152499198913574
training step: 54242, total_loss: 4.975496292114258
training step: 54243, total_loss: 5.6464338302612305
training step: 54244, total_loss: 5.141567230224609
training step: 54245, total_loss: 4.014564514160156
training step: 54246, total_loss: 3.0845518112182617
training step: 54247, total_loss: 4.5684404373168945
training step: 54248, total_loss: 4.199296951293945
training step: 54249, total_loss: 3.5523009300231934
training step: 54250, total_loss: 4.732095718383789
training step: 54251, total_loss: 4.889510154724121
training step: 54252, total_loss: 4.847268104553223
training step: 54253, total_loss: 4.872278213500977
training step: 54254, total_loss: 4.166400909423828
training step: 54255, total_loss: 5.438889980316162
training step: 54256, total_loss: 2.675724983215332
training step: 54257, total_loss: 5.123553276062012
training step: 54258, total_loss: 5.018924713134766
training step: 54259, total_loss: 4.855866432189941
training step: 54260, total_loss: 4.539677619934082
training step: 54261, total_loss: 5.414083480834961
training step: 54262, total_loss: 4.454416275024414
training step: 54263, total_loss: 3.865521192550659
training step: 54264, total_loss: 5.6466755867004395
training step: 54265, total_loss: 4.851717948913574
training step: 54266, total_loss: 3.1758008003234863
training step: 54267, total_loss: 4.220311641693115
training step: 54268, total_loss: 5.253070831298828
training step: 54269, total_loss: 4.311376571655273
training step: 54270, total_loss: 2.535081386566162
training step: 54271, total_loss: 4.581120014190674
training step: 54272, total_loss: 5.224673748016357
training step: 54273, total_loss: 4.662022590637207
training step: 54274, total_loss: 3.095254421234131
training step: 54275, total_loss: 5.22242546081543
training step: 54276, total_loss: 2.098449230194092
training step: 54277, total_loss: 4.445240020751953
training step: 54278, total_loss: 5.502692699432373
training step: 54279, total_loss: 5.468590259552002
training step: 54280, total_loss: 4.469392776489258
training step: 54281, total_loss: 3.6384191513061523
training step: 54282, total_loss: 4.19386625289917
training step: 54283, total_loss: 3.308505058288574
training step: 54284, total_loss: 4.012972831726074
training step: 54285, total_loss: 3.956890106201172
training step: 54286, total_loss: 4.8047027587890625
training step: 54287, total_loss: 5.15413236618042
training step: 54288, total_loss: 4.478407859802246
training step: 54289, total_loss: 5.6941375732421875
training step: 54290, total_loss: 3.6694436073303223
training step: 54291, total_loss: 4.006193161010742
training step: 54292, total_loss: 5.129424095153809
training step: 54293, total_loss: 3.7758729457855225
training step: 54294, total_loss: 3.7959842681884766
training step: 54295, total_loss: 4.876951217651367
training step: 54296, total_loss: 3.9711456298828125
training step: 54297, total_loss: 2.923731803894043
training step: 54298, total_loss: 3.8303518295288086
training step: 54299, total_loss: 5.732482433319092
training step: 54300, total_loss: 4.182506561279297
training step: 54301, total_loss: 4.486482620239258
training step: 54302, total_loss: 4.588738441467285
training step: 54303, total_loss: 5.538583755493164
training step: 54304, total_loss: 4.273257255554199
training step: 54305, total_loss: 3.383808135986328
training step: 54306, total_loss: 3.047851324081421
training step: 54307, total_loss: 4.502342700958252
training step: 54308, total_loss: 4.607324600219727
training step: 54309, total_loss: 2.8780179023742676
training step: 54310, total_loss: 4.997314453125
training step: 54311, total_loss: 3.4895706176757812
training step: 54312, total_loss: 4.783243656158447
training step: 54313, total_loss: 5.087622165679932
training step: 54314, total_loss: 4.271582126617432
training step: 54315, total_loss: 4.208768844604492
training step: 54316, total_loss: 4.893126487731934
training step: 54317, total_loss: 5.651861667633057
training step: 54318, total_loss: 5.064631938934326
training step: 54319, total_loss: 2.864577531814575
training step: 54320, total_loss: 4.049074649810791
training step: 54321, total_loss: 5.093103885650635
training step: 54322, total_loss: 5.165497779846191
training step: 54323, total_loss: 4.440244197845459
training step: 54324, total_loss: 4.58561897277832
training step: 54325, total_loss: 3.367537498474121
training step: 54326, total_loss: 5.566464424133301
training step: 54327, total_loss: 4.630902290344238
training step: 54328, total_loss: 2.759584426879883
training step: 54329, total_loss: 5.2424702644348145
training step: 54330, total_loss: 4.125515460968018
training step: 54331, total_loss: 2.9719510078430176
training step: 54332, total_loss: 4.135778903961182
training step: 54333, total_loss: 5.036086559295654
training step: 54334, total_loss: 6.131799697875977
training step: 54335, total_loss: 4.196478366851807
training step: 54336, total_loss: 3.315741777420044
training step: 54337, total_loss: 5.696879863739014
training step: 54338, total_loss: 5.453208923339844
training step: 54339, total_loss: 5.707543849945068
training step: 54340, total_loss: 3.9890894889831543
training step: 54341, total_loss: 5.304905414581299
training step: 54342, total_loss: 4.201515197753906
training step: 54343, total_loss: 5.471927165985107
training step: 54344, total_loss: 2.528487205505371
training step: 54345, total_loss: 4.283708572387695
training step: 54346, total_loss: 3.69612193107605
training step: 54347, total_loss: 4.515252113342285
training step: 54348, total_loss: 2.8311448097229004
training step: 54349, total_loss: 5.280475616455078
training step: 54350, total_loss: 4.303526878356934
training step: 54351, total_loss: 3.315491199493408
training step: 54352, total_loss: 5.11476993560791
training step: 54353, total_loss: 3.6759724617004395
training step: 54354, total_loss: 4.10006046295166
training step: 54355, total_loss: 5.419478416442871
training step: 54356, total_loss: 3.404168128967285
training step: 54357, total_loss: 3.868112564086914
training step: 54358, total_loss: 3.1027307510375977
training step: 54359, total_loss: 4.96303653717041
training step: 54360, total_loss: 3.81148099899292
training step: 54361, total_loss: 4.657292366027832
training step: 54362, total_loss: 4.107714653015137
training step: 54363, total_loss: 3.73250150680542
training step: 54364, total_loss: 4.467503547668457
training step: 54365, total_loss: 4.3314619064331055
training step: 54366, total_loss: 4.66956901550293
training step: 54367, total_loss: 3.1649169921875
training step: 54368, total_loss: 4.057682037353516
training step: 54369, total_loss: 5.191721439361572
training step: 54370, total_loss: 4.216835021972656
training step: 54371, total_loss: 3.161233425140381
training step: 54372, total_loss: 4.127089977264404
training step: 54373, total_loss: 4.411635398864746
training step: 54374, total_loss: 5.970788955688477
training step: 54375, total_loss: 4.876829147338867
training step: 54376, total_loss: 3.1063332557678223
training step: 54377, total_loss: 4.238780975341797
training step: 54378, total_loss: 5.0076446533203125
training step: 54379, total_loss: 3.4913716316223145
training step: 54380, total_loss: 4.310861587524414
training step: 54381, total_loss: 6.291755199432373
training step: 54382, total_loss: 4.707729339599609
training step: 54383, total_loss: 3.7053651809692383
training step: 54384, total_loss: 3.9567322731018066
training step: 54385, total_loss: 2.465697765350342
training step: 54386, total_loss: 5.0397772789001465
training step: 54387, total_loss: 3.9969494342803955
training step: 54388, total_loss: 4.052107810974121
training step: 54389, total_loss: 4.604730606079102
training step: 54390, total_loss: 4.314606189727783
training step: 54391, total_loss: 5.552373886108398
training step: 54392, total_loss: 7.996982574462891
training step: 54393, total_loss: 3.6897029876708984
training step: 54394, total_loss: 4.197752952575684
training step: 54395, total_loss: 5.403112411499023
training step: 54396, total_loss: 5.10134220123291
training step: 54397, total_loss: 3.669010639190674
training step: 54398, total_loss: 4.540990829467773
training step: 54399, total_loss: 4.046562194824219
training step: 54400, total_loss: 5.296448707580566
training step: 54401, total_loss: 4.270774841308594
training step: 54402, total_loss: 2.8560681343078613
training step: 54403, total_loss: 5.202632904052734
training step: 54404, total_loss: 3.2931182384490967
training step: 54405, total_loss: 4.220952033996582
training step: 54406, total_loss: 2.899139642715454
training step: 54407, total_loss: 3.8902463912963867
training step: 54408, total_loss: 4.4615983963012695
training step: 54409, total_loss: 1.4064245223999023
training step: 54410, total_loss: 4.070873260498047
training step: 54411, total_loss: 4.645484447479248
training step: 54412, total_loss: 2.9678168296813965
training step: 54413, total_loss: 4.999169826507568
training step: 54414, total_loss: 4.377081394195557
training step: 54415, total_loss: 4.5015058517456055
training step: 54416, total_loss: 3.570573329925537
training step: 54417, total_loss: 4.726848602294922
training step: 54418, total_loss: 3.3485164642333984
training step: 54419, total_loss: 5.828490734100342
training step: 54420, total_loss: 6.256875038146973
training step: 54421, total_loss: 5.631143093109131
training step: 54422, total_loss: 4.8203816413879395
training step: 54423, total_loss: 3.940220355987549
training step: 54424, total_loss: 4.502528190612793
training step: 54425, total_loss: 5.315642356872559
training step: 54426, total_loss: 5.829005718231201
training step: 54427, total_loss: 3.9500465393066406
training step: 54428, total_loss: 4.971219062805176
training step: 54429, total_loss: 4.159336090087891
training step: 54430, total_loss: 4.539788722991943
training step: 54431, total_loss: 4.009778022766113
training step: 54432, total_loss: 4.438240051269531
training step: 54433, total_loss: 3.1412034034729004
training step: 54434, total_loss: 2.4890077114105225
training step: 54435, total_loss: 4.007361888885498
training step: 54436, total_loss: 5.881287574768066
training step: 54437, total_loss: 1.0983340740203857
training step: 54438, total_loss: 4.8612775802612305
training step: 54439, total_loss: 4.505426406860352
training step: 54440, total_loss: 5.027997970581055
training step: 54441, total_loss: 4.462944030761719
training step: 54442, total_loss: 3.7585206031799316
training step: 54443, total_loss: 4.5294342041015625
training step: 54444, total_loss: 2.474641799926758
training step: 54445, total_loss: 5.104824066162109
training step: 54446, total_loss: 4.303195953369141
training step: 54447, total_loss: 3.4560580253601074
training step: 54448, total_loss: 5.159197807312012
training step: 54449, total_loss: 4.551191329956055
training step: 54450, total_loss: 4.521108627319336
training step: 54451, total_loss: 3.307737350463867
training step: 54452, total_loss: 4.358573913574219
training step: 54453, total_loss: 5.887326240539551
training step: 54454, total_loss: 5.1651458740234375
training step: 54455, total_loss: 3.253159999847412
training step: 54456, total_loss: 4.4145894050598145
training step: 54457, total_loss: 3.8572444915771484
training step: 54458, total_loss: 2.3442139625549316
training step: 54459, total_loss: 4.502019882202148
training step: 54460, total_loss: 4.101500511169434
training step: 54461, total_loss: 4.424543380737305
training step: 54462, total_loss: 4.224100112915039
training step: 54463, total_loss: 3.2828128337860107
training step: 54464, total_loss: 4.028102874755859
training step: 54465, total_loss: 3.196779727935791
training step: 54466, total_loss: 4.391747951507568
training step: 54467, total_loss: 4.173440933227539
training step: 54468, total_loss: 6.335381507873535
training step: 54469, total_loss: 3.8607499599456787
training step: 54470, total_loss: 5.098360061645508
training step: 54471, total_loss: 4.372063159942627
training step: 54472, total_loss: 3.8383617401123047
training step: 54473, total_loss: 4.555147171020508
training step: 54474, total_loss: 4.605049133300781
training step: 54475, total_loss: 3.979830026626587
training step: 54476, total_loss: 4.267416000366211
training step: 54477, total_loss: 4.307807922363281
training step: 54478, total_loss: 4.153007507324219
training step: 54479, total_loss: 4.634415626525879
training step: 54480, total_loss: 3.547089099884033
training step: 54481, total_loss: 4.772558212280273
training step: 54482, total_loss: 4.018198490142822
training step: 54483, total_loss: 5.244006633758545
training step: 54484, total_loss: 3.2556886672973633
training step: 54485, total_loss: 4.637832164764404
training step: 54486, total_loss: 5.840199947357178
training step: 54487, total_loss: 4.548827648162842
training step: 54488, total_loss: 4.303673267364502
training step: 54489, total_loss: 4.42221212387085
training step: 54490, total_loss: 4.279616355895996
training step: 54491, total_loss: 4.5493388175964355
training step: 54492, total_loss: 6.441326141357422
training step: 54493, total_loss: 4.834676742553711
training step: 54494, total_loss: 0.8847171664237976
training step: 54495, total_loss: 3.8464832305908203
training step: 54496, total_loss: 4.300710201263428
training step: 54497, total_loss: 4.823139667510986
training step: 54498, total_loss: 5.235620021820068
training step: 54499, total_loss: 6.167914390563965
training step: 54500, total_loss: 6.045714378356934
training step: 54501, total_loss: 4.120357513427734
training step: 54502, total_loss: 2.8187623023986816
training step: 54503, total_loss: 4.144003391265869
training step: 54504, total_loss: 2.6887803077697754
training step: 54505, total_loss: 4.637001991271973
training step: 54506, total_loss: 4.6466450691223145
training step: 54507, total_loss: 4.732530117034912
training step: 54508, total_loss: 4.025636672973633
training step: 54509, total_loss: 4.308538436889648
training step: 54510, total_loss: 4.287166118621826
training step: 54511, total_loss: 5.82490348815918
training step: 54512, total_loss: 5.815057754516602
training step: 54513, total_loss: 3.1419758796691895
training step: 54514, total_loss: 3.7452235221862793
training step: 54515, total_loss: 4.4323625564575195
training step: 54516, total_loss: 5.1468915939331055
training step: 54517, total_loss: 4.8895487785339355
training step: 54518, total_loss: 4.7948150634765625
training step: 54519, total_loss: 4.722485065460205
training step: 54520, total_loss: 4.8502326011657715
training step: 54521, total_loss: 5.158051013946533
training step: 54522, total_loss: 1.6798155307769775
training step: 54523, total_loss: 3.947883367538452
training step: 54524, total_loss: 3.940938711166382
training step: 54525, total_loss: 4.060298919677734
training step: 54526, total_loss: 3.909634590148926
training step: 54527, total_loss: 3.344236135482788
training step: 54528, total_loss: 4.517701148986816
training step: 54529, total_loss: 5.114165306091309
training step: 54530, total_loss: 2.998230457305908
training step: 54531, total_loss: 5.0357666015625
training step: 54532, total_loss: 4.608734607696533
training step: 54533, total_loss: 4.5105791091918945
training step: 54534, total_loss: 3.4447288513183594
training step: 54535, total_loss: 4.762221336364746
training step: 54536, total_loss: 5.443215370178223
training step: 54537, total_loss: 5.602764129638672
training step: 54538, total_loss: 4.271801471710205
training step: 54539, total_loss: 4.063523769378662
training step: 54540, total_loss: 5.201779365539551
training step: 54541, total_loss: 4.53904914855957
training step: 54542, total_loss: 2.3007473945617676
training step: 54543, total_loss: 4.179653644561768
training step: 54544, total_loss: 4.017459869384766
training step: 54545, total_loss: 3.9593493938446045
training step: 54546, total_loss: 4.536455154418945
training step: 54547, total_loss: 4.962855339050293
training step: 54548, total_loss: 2.6031298637390137
training step: 54549, total_loss: 3.609915256500244
training step: 54550, total_loss: 4.136993408203125
training step: 54551, total_loss: 4.719777584075928
training step: 54552, total_loss: 5.913393020629883
training step: 54553, total_loss: 6.291200637817383
training step: 54554, total_loss: 4.417484760284424
training step: 54555, total_loss: 4.2610015869140625
training step: 54556, total_loss: 3.373300313949585
training step: 54557, total_loss: 3.760155200958252
training step: 54558, total_loss: 4.448624134063721
training step: 54559, total_loss: 4.936219215393066
training step: 54560, total_loss: 4.850461959838867
training step: 54561, total_loss: 3.978973150253296
training step: 54562, total_loss: 6.255850791931152
training step: 54563, total_loss: 3.30293607711792
training step: 54564, total_loss: 4.033380508422852
training step: 54565, total_loss: 4.107676029205322
training step: 54566, total_loss: 3.2106103897094727
training step: 54567, total_loss: 3.9817914962768555
training step: 54568, total_loss: 4.132023811340332
training step: 54569, total_loss: 4.003844261169434
training step: 54570, total_loss: 3.944837808609009
training step: 54571, total_loss: 6.634161472320557
training step: 54572, total_loss: 2.6527462005615234
training step: 54573, total_loss: 5.338598251342773
training step: 54574, total_loss: 3.984619140625
training step: 54575, total_loss: 3.65724515914917
training step: 54576, total_loss: 3.1170482635498047
training step: 54577, total_loss: 1.0302625894546509
training step: 54578, total_loss: 3.2636756896972656
training step: 54579, total_loss: 3.7263426780700684
training step: 54580, total_loss: 4.817045211791992
training step: 54581, total_loss: 5.203639984130859
training step: 54582, total_loss: 2.66959810256958
training step: 54583, total_loss: 4.345890045166016
training step: 54584, total_loss: 4.053891658782959
training step: 54585, total_loss: 3.7366020679473877
training step: 54586, total_loss: 2.6588449478149414
training step: 54587, total_loss: 1.3562036752700806
training step: 54588, total_loss: 2.909576892852783
training step: 54589, total_loss: 4.155547142028809
training step: 54590, total_loss: 3.971186637878418
training step: 54591, total_loss: 4.970454216003418
training step: 54592, total_loss: 5.2825117111206055
training step: 54593, total_loss: 4.2909440994262695
training step: 54594, total_loss: 5.866973876953125
training step: 54595, total_loss: 5.186535835266113
training step: 54596, total_loss: 2.8860979080200195
training step: 54597, total_loss: 4.4257001876831055
training step: 54598, total_loss: 4.341607093811035
training step: 54599, total_loss: 4.025827884674072
training step: 54600, total_loss: 4.09528923034668
training step: 54601, total_loss: 3.596909523010254
training step: 54602, total_loss: 4.710867881774902
training step: 54603, total_loss: 3.493344783782959
training step: 54604, total_loss: 4.986516952514648
training step: 54605, total_loss: 5.142618656158447
training step: 54606, total_loss: 5.580260276794434
training step: 54607, total_loss: 4.745623588562012
training step: 54608, total_loss: 5.1348419189453125
training step: 54609, total_loss: 4.777743339538574
training step: 54610, total_loss: 2.5735292434692383
training step: 54611, total_loss: 4.493258953094482
training step: 54612, total_loss: 4.301218509674072
training step: 54613, total_loss: 4.241034507751465
training step: 54614, total_loss: 5.383578777313232
training step: 54615, total_loss: 3.968715190887451
training step: 54616, total_loss: 2.4790711402893066
training step: 54617, total_loss: 5.1946563720703125
training step: 54618, total_loss: 3.569797992706299
training step: 54619, total_loss: 3.9559361934661865
training step: 54620, total_loss: 4.42036247253418
training step: 54621, total_loss: 3.78694486618042
training step: 54622, total_loss: 4.298994064331055
training step: 54623, total_loss: 4.425878524780273
training step: 54624, total_loss: 3.867624044418335
training step: 54625, total_loss: 6.171423435211182
training step: 54626, total_loss: 5.3638386726379395
training step: 54627, total_loss: 2.6048340797424316
training step: 54628, total_loss: 5.235030174255371
training step: 54629, total_loss: 4.170100688934326
training step: 54630, total_loss: 5.3206281661987305
training step: 54631, total_loss: 4.148857593536377
training step: 54632, total_loss: 3.3035225868225098
training step: 54633, total_loss: 3.900808095932007
training step: 54634, total_loss: 4.124869346618652
training step: 54635, total_loss: 5.594517707824707
training step: 54636, total_loss: 5.038968563079834
training step: 54637, total_loss: 4.6546430587768555
training step: 54638, total_loss: 4.715312957763672
training step: 54639, total_loss: 4.1162824630737305
training step: 54640, total_loss: 3.9239625930786133
training step: 54641, total_loss: 3.1738784313201904
training step: 54642, total_loss: 4.435267925262451
training step: 54643, total_loss: 5.448660850524902
training step: 54644, total_loss: 4.342179298400879
training step: 54645, total_loss: 4.861401557922363
training step: 54646, total_loss: 5.0915679931640625
training step: 54647, total_loss: 4.4800591468811035
training step: 54648, total_loss: 4.147014617919922
training step: 54649, total_loss: 4.1546630859375
training step: 54650, total_loss: 5.441592216491699
training step: 54651, total_loss: 4.1644287109375
training step: 54652, total_loss: 4.680661678314209
training step: 54653, total_loss: 3.2049739360809326
training step: 54654, total_loss: 3.8835439682006836
training step: 54655, total_loss: 5.699051856994629
training step: 54656, total_loss: 4.718217372894287
training step: 54657, total_loss: 5.151845455169678
training step: 54658, total_loss: 5.255173206329346
training step: 54659, total_loss: 5.457375526428223
training step: 54660, total_loss: 4.766897678375244
training step: 54661, total_loss: 3.244964122772217
training step: 54662, total_loss: 4.465190410614014
training step: 54663, total_loss: 4.479528903961182
training step: 54664, total_loss: 4.793824195861816
training step: 54665, total_loss: 4.812812328338623
training step: 54666, total_loss: 3.6456058025360107
training step: 54667, total_loss: 4.281228542327881
training step: 54668, total_loss: 3.427584648132324
training step: 54669, total_loss: 5.440086364746094
training step: 54670, total_loss: 3.1286780834198
training step: 54671, total_loss: 5.252118110656738
training step: 54672, total_loss: 4.2707414627075195
training step: 54673, total_loss: 4.861526966094971
training step: 54674, total_loss: 5.066198825836182
training step: 54675, total_loss: 3.215470790863037
training step: 54676, total_loss: 4.127845287322998
training step: 54677, total_loss: 4.5261921882629395
training step: 54678, total_loss: 4.373134613037109
training step: 54679, total_loss: 3.9210596084594727
training step: 54680, total_loss: 4.213159561157227
training step: 54681, total_loss: 4.154074192047119
training step: 54682, total_loss: 4.043787002563477
training step: 54683, total_loss: 3.904183864593506
training step: 54684, total_loss: 5.215633869171143
training step: 54685, total_loss: 5.801061630249023
training step: 54686, total_loss: 4.3128156661987305
training step: 54687, total_loss: 3.6858110427856445
training step: 54688, total_loss: 3.9880220890045166
training step: 54689, total_loss: 5.3312788009643555
training step: 54690, total_loss: 4.3269429206848145
training step: 54691, total_loss: 4.761102676391602
training step: 54692, total_loss: 4.637920379638672
training step: 54693, total_loss: 2.903318405151367
training step: 54694, total_loss: 4.628657341003418
training step: 54695, total_loss: 4.632746696472168
training step: 54696, total_loss: 4.525937080383301
training step: 54697, total_loss: 3.432969808578491
training step: 54698, total_loss: 4.845283031463623
training step: 54699, total_loss: 3.300535202026367
training step: 54700, total_loss: 4.32717227935791
training step: 54701, total_loss: 3.8079142570495605
training step: 54702, total_loss: 3.48704195022583
training step: 54703, total_loss: 4.127570152282715
training step: 54704, total_loss: 4.874063491821289
training step: 54705, total_loss: 2.262820243835449
training step: 54706, total_loss: 4.678041458129883
training step: 54707, total_loss: 4.173405647277832
training step: 54708, total_loss: 4.379950523376465
training step: 54709, total_loss: 4.496237754821777
training step: 54710, total_loss: 3.7744596004486084
training step: 54711, total_loss: 5.443268775939941
training step: 54712, total_loss: 2.2749714851379395
training step: 54713, total_loss: 4.346242904663086
training step: 54714, total_loss: 2.008370876312256
training step: 54715, total_loss: 5.2213664054870605
training step: 54716, total_loss: 3.980191946029663
training step: 54717, total_loss: 3.9688053131103516
training step: 54718, total_loss: 3.0037522315979004
training step: 54719, total_loss: 4.96583366394043
training step: 54720, total_loss: 4.4358062744140625
training step: 54721, total_loss: 4.305301666259766
training step: 54722, total_loss: 3.8047330379486084
training step: 54723, total_loss: 4.276480674743652
training step: 54724, total_loss: 2.148118495941162
training step: 54725, total_loss: 4.964455604553223
training step: 54726, total_loss: 4.562597274780273
training step: 54727, total_loss: 4.0893754959106445
training step: 54728, total_loss: 5.117707252502441
training step: 54729, total_loss: 2.970493793487549
training step: 54730, total_loss: 4.3088788986206055
training step: 54731, total_loss: 3.911301612854004
training step: 54732, total_loss: 2.2947494983673096
training step: 54733, total_loss: 4.047240257263184
training step: 54734, total_loss: 4.59248161315918
training step: 54735, total_loss: 4.693486213684082
training step: 54736, total_loss: 4.625410556793213
training step: 54737, total_loss: 4.528870582580566
training step: 54738, total_loss: 2.7534728050231934
training step: 54739, total_loss: 4.989232540130615
training step: 54740, total_loss: 3.2431583404541016
training step: 54741, total_loss: 4.942202568054199
training step: 54742, total_loss: 4.420157432556152
training step: 54743, total_loss: 3.4545178413391113
training step: 54744, total_loss: 4.033509254455566
training step: 54745, total_loss: 4.789239883422852
training step: 54746, total_loss: 5.069189071655273
training step: 54747, total_loss: 4.689867973327637
training step: 54748, total_loss: 5.573075294494629
training step: 54749, total_loss: 3.385706901550293
training step: 54750, total_loss: 3.4036996364593506
training step: 54751, total_loss: 4.368350505828857
training step: 54752, total_loss: 4.000763893127441
training step: 54753, total_loss: 3.6321306228637695
training step: 54754, total_loss: 4.228722095489502
training step: 54755, total_loss: 5.000188827514648
training step: 54756, total_loss: 3.7909421920776367
training step: 54757, total_loss: 6.481350898742676
training step: 54758, total_loss: 6.939958572387695
training step: 54759, total_loss: 4.506872177124023
training step: 54760, total_loss: 3.7420926094055176
training step: 54761, total_loss: 1.1472254991531372
training step: 54762, total_loss: 3.634047508239746
training step: 54763, total_loss: 6.383092880249023
training step: 54764, total_loss: 4.534621715545654
training step: 54765, total_loss: 4.33674430847168
training step: 54766, total_loss: 4.417289733886719
training step: 54767, total_loss: 4.615963459014893
training step: 54768, total_loss: 4.705661773681641
training step: 54769, total_loss: 6.058375358581543
training step: 54770, total_loss: 4.0029425621032715
training step: 54771, total_loss: 4.284531593322754
training step: 54772, total_loss: 4.487174034118652
training step: 54773, total_loss: 5.638086318969727
training step: 54774, total_loss: 4.646928787231445
training step: 54775, total_loss: 3.1385247707366943
training step: 54776, total_loss: 4.809865951538086
training step: 54777, total_loss: 4.840871810913086
training step: 54778, total_loss: 5.0696940422058105
training step: 54779, total_loss: 4.695365905761719
training step: 54780, total_loss: 3.1094846725463867
training step: 54781, total_loss: 5.958378314971924
training step: 54782, total_loss: 4.498434543609619
training step: 54783, total_loss: 4.102646827697754
training step: 54784, total_loss: 5.188889980316162
training step: 54785, total_loss: 4.338417053222656
training step: 54786, total_loss: 4.485513687133789
training step: 54787, total_loss: 4.648349285125732
training step: 54788, total_loss: 5.106475830078125
training step: 54789, total_loss: 2.206697463989258
training step: 54790, total_loss: 4.3502278327941895
training step: 54791, total_loss: 3.7881247997283936
training step: 54792, total_loss: 4.207456111907959
training step: 54793, total_loss: 2.896693706512451
training step: 54794, total_loss: 4.695466995239258
training step: 54795, total_loss: 3.7817907333374023
training step: 54796, total_loss: 4.216095447540283
training step: 54797, total_loss: 1.6919575929641724
training step: 54798, total_loss: 3.909085273742676
training step: 54799, total_loss: 3.6893229484558105
training step: 54800, total_loss: 4.568999290466309
training step: 54801, total_loss: 4.4276652336120605
training step: 54802, total_loss: 3.8166232109069824
training step: 54803, total_loss: 4.615291595458984
training step: 54804, total_loss: 5.0780158042907715
training step: 54805, total_loss: 5.19010066986084
training step: 54806, total_loss: 3.0087220668792725
training step: 54807, total_loss: 3.5617873668670654
training step: 54808, total_loss: 6.020528793334961
training step: 54809, total_loss: 3.532205820083618
training step: 54810, total_loss: 4.876166820526123
training step: 54811, total_loss: 3.209554672241211
training step: 54812, total_loss: 3.6963047981262207
training step: 54813, total_loss: 5.126096725463867
training step: 54814, total_loss: 1.7407805919647217
training step: 54815, total_loss: 3.7931525707244873
training step: 54816, total_loss: 4.54368257522583
training step: 54817, total_loss: 3.3038489818573
training step: 54818, total_loss: 4.114656925201416
training step: 54819, total_loss: 3.1446456909179688
training step: 54820, total_loss: 4.15969181060791
training step: 54821, total_loss: 3.4763343334198
training step: 54822, total_loss: 1.0033304691314697
training step: 54823, total_loss: 5.027256488800049
training step: 54824, total_loss: 3.509145736694336
training step: 54825, total_loss: 5.479825496673584
training step: 54826, total_loss: 5.85653018951416
training step: 54827, total_loss: 5.349514961242676
training step: 54828, total_loss: 5.649875164031982
training step: 54829, total_loss: 4.851295471191406
training step: 54830, total_loss: 3.582132339477539
training step: 54831, total_loss: 4.770900249481201
training step: 54832, total_loss: 3.7906806468963623
training step: 54833, total_loss: 2.4763741493225098
training step: 54834, total_loss: 4.068846225738525
training step: 54835, total_loss: 4.911600589752197
training step: 54836, total_loss: 5.820268630981445
training step: 54837, total_loss: 4.566290855407715
training step: 54838, total_loss: 2.473846435546875
training step: 54839, total_loss: 4.5821967124938965
training step: 54840, total_loss: 5.290227890014648
training step: 54841, total_loss: 4.434922218322754
training step: 54842, total_loss: 4.3585591316223145
training step: 54843, total_loss: 6.0310845375061035
training step: 54844, total_loss: 4.751866817474365
training step: 54845, total_loss: 5.022215366363525
training step: 54846, total_loss: 3.133930206298828
training step: 54847, total_loss: 3.838006019592285
training step: 54848, total_loss: 4.03665018081665
training step: 54849, total_loss: 3.9118049144744873
training step: 54850, total_loss: 1.3623042106628418
training step: 54851, total_loss: 4.531582355499268
training step: 54852, total_loss: 3.982912540435791
training step: 54853, total_loss: 3.8416025638580322
training step: 54854, total_loss: 4.504123687744141
training step: 54855, total_loss: 4.700331687927246
training step: 54856, total_loss: 3.8231770992279053
training step: 54857, total_loss: 3.1885852813720703
training step: 54858, total_loss: 3.2010579109191895
training step: 54859, total_loss: 5.091129302978516
training step: 54860, total_loss: 3.928037166595459
training step: 54861, total_loss: 4.431731224060059
training step: 54862, total_loss: 5.547536849975586
training step: 54863, total_loss: 3.822763681411743
training step: 54864, total_loss: 4.915783405303955
training step: 54865, total_loss: 3.707575798034668
training step: 54866, total_loss: 5.335972785949707
training step: 54867, total_loss: 3.4351720809936523
training step: 54868, total_loss: 3.019777774810791
training step: 54869, total_loss: 4.291975021362305
training step: 54870, total_loss: 4.522380828857422
training step: 54871, total_loss: 4.103630065917969
training step: 54872, total_loss: 4.862186431884766
training step: 54873, total_loss: 5.160296440124512
training step: 54874, total_loss: 4.153583526611328
training step: 54875, total_loss: 4.6921491622924805
training step: 54876, total_loss: 5.418187618255615
training step: 54877, total_loss: 3.2450594902038574
training step: 54878, total_loss: 3.285433292388916
training step: 54879, total_loss: 4.587573051452637
training step: 54880, total_loss: 4.890589714050293
training step: 54881, total_loss: 5.645284652709961
training step: 54882, total_loss: 4.154630184173584
training step: 54883, total_loss: 4.643045902252197
training step: 54884, total_loss: 1.178676962852478
training step: 54885, total_loss: 4.310990333557129
training step: 54886, total_loss: 4.254962921142578
training step: 54887, total_loss: 3.2965586185455322
training step: 54888, total_loss: 4.846105575561523
training step: 54889, total_loss: 3.706040143966675
training step: 54890, total_loss: 4.445498466491699
training step: 54891, total_loss: 4.9911208152771
training step: 54892, total_loss: 5.740469455718994
training step: 54893, total_loss: 6.297328948974609
training step: 54894, total_loss: 4.736308574676514
training step: 54895, total_loss: 4.099142074584961
training step: 54896, total_loss: 4.818286418914795
training step: 54897, total_loss: 3.2462332248687744
training step: 54898, total_loss: 6.418994903564453
training step: 54899, total_loss: 2.747725486755371
training step: 54900, total_loss: 3.847446918487549
training step: 54901, total_loss: 4.226497650146484
training step: 54902, total_loss: 3.555206775665283
training step: 54903, total_loss: 4.703664779663086
training step: 54904, total_loss: 3.565173387527466
training step: 54905, total_loss: 3.9175078868865967
training step: 54906, total_loss: 5.115907192230225
training step: 54907, total_loss: 3.297168016433716
training step: 54908, total_loss: 5.553838729858398
training step: 54909, total_loss: 5.787590980529785
training step: 54910, total_loss: 5.259100914001465
training step: 54911, total_loss: 4.623528003692627
training step: 54912, total_loss: 1.8277214765548706
training step: 54913, total_loss: 5.107254981994629
training step: 54914, total_loss: 3.665257453918457
training step: 54915, total_loss: 4.100668907165527
training step: 54916, total_loss: 2.4711780548095703
training step: 54917, total_loss: 2.5424306392669678
training step: 54918, total_loss: 3.290316104888916
training step: 54919, total_loss: 4.385926723480225
training step: 54920, total_loss: 5.127943992614746
training step: 54921, total_loss: 2.650571346282959
training step: 54922, total_loss: 4.230193614959717
training step: 54923, total_loss: 5.149133205413818
training step: 54924, total_loss: 6.817173004150391
training step: 54925, total_loss: 5.506275177001953
training step: 54926, total_loss: 5.510093688964844
training step: 54927, total_loss: 3.110370635986328
training step: 54928, total_loss: 4.14986515045166
training step: 54929, total_loss: 4.405206203460693
training step: 54930, total_loss: 4.43562126159668
training step: 54931, total_loss: 3.6198275089263916
training step: 54932, total_loss: 3.9714102745056152
training step: 54933, total_loss: 4.280960559844971
training step: 54934, total_loss: 4.525821685791016
training step: 54935, total_loss: 3.641294479370117
training step: 54936, total_loss: 5.029392242431641
training step: 54937, total_loss: 5.726686477661133
training step: 54938, total_loss: 3.563469171524048
training step: 54939, total_loss: 4.664424896240234
training step: 54940, total_loss: 4.723292350769043
training step: 54941, total_loss: 3.8207902908325195
training step: 54942, total_loss: 3.3975837230682373
training step: 54943, total_loss: 4.303136348724365
training step: 54944, total_loss: 5.025389671325684
training step: 54945, total_loss: 4.221076011657715
training step: 54946, total_loss: 5.481744766235352
training step: 54947, total_loss: 4.125358581542969
training step: 54948, total_loss: 3.549025535583496
training step: 54949, total_loss: 3.4372024536132812
training step: 54950, total_loss: 4.593785285949707
training step: 54951, total_loss: 4.174238204956055
training step: 54952, total_loss: 5.542757987976074
training step: 54953, total_loss: 3.552368640899658
training step: 54954, total_loss: 2.4282748699188232
training step: 54955, total_loss: 3.5276618003845215
training step: 54956, total_loss: 4.700364112854004
training step: 54957, total_loss: 3.71881103515625
training step: 54958, total_loss: 5.275299072265625
training step: 54959, total_loss: 5.929410934448242
training step: 54960, total_loss: 4.275145053863525
training step: 54961, total_loss: 0.9289590120315552
training step: 54962, total_loss: 3.010106325149536
training step: 54963, total_loss: 5.979089736938477
training step: 54964, total_loss: 4.436656475067139
training step: 54965, total_loss: 4.976690292358398
training step: 54966, total_loss: 5.327098846435547
training step: 54967, total_loss: 0.8826347589492798
training step: 54968, total_loss: 3.724327564239502
training step: 54969, total_loss: 4.288799285888672
training step: 54970, total_loss: 4.999160289764404
training step: 54971, total_loss: 5.390324592590332
training step: 54972, total_loss: 2.9744873046875
training step: 54973, total_loss: 4.01075553894043
training step: 54974, total_loss: 1.595747470855713
training step: 54975, total_loss: 4.150274276733398
training step: 54976, total_loss: 3.9751389026641846
training step: 54977, total_loss: 3.0343310832977295
training step: 54978, total_loss: 4.115105152130127
training step: 54979, total_loss: 2.108610153198242
training step: 54980, total_loss: 3.5051217079162598
training step: 54981, total_loss: 4.977553367614746
training step: 54982, total_loss: 3.080915927886963
training step: 54983, total_loss: 4.413527965545654
training step: 54984, total_loss: 4.0412163734436035
training step: 54985, total_loss: 5.610084533691406
training step: 54986, total_loss: 3.3810319900512695
training step: 54987, total_loss: 4.393618106842041
training step: 54988, total_loss: 5.514427185058594
training step: 54989, total_loss: 4.869532108306885
training step: 54990, total_loss: 4.3386921882629395
training step: 54991, total_loss: 4.0328264236450195
training step: 54992, total_loss: 4.659664154052734INFO:tensorflow:Writing predictions to: residual_output/predictions_55000.json
INFO:tensorflow:Writing nbest to: residual_output/nbest_predictions_55000.json

training step: 54993, total_loss: 3.9802052974700928
training step: 54994, total_loss: 5.022857666015625
training step: 54995, total_loss: 5.073696136474609
training step: 54996, total_loss: 4.122039794921875
training step: 54997, total_loss: 4.222402572631836
training step: 54998, total_loss: 4.147972106933594
training step: 54999, total_loss: 3.9683494567871094
training step: 55000, total_loss: 6.247286796569824
epoch finished! shuffle=False
evaluation: 55000, total_loss: 2.32340669631958, f1: 23.446197331112252, followup: 18.378213905370455, yesno: 1.6126578426897915, heq: 22.790202342917997, dheq: 0.5

Model saved in path residual_output//model_55000.ckpt
training step: 55001, total_loss: 4.285127639770508
training step: 55002, total_loss: 5.2445478439331055
training step: 55003, total_loss: 3.1630656719207764
training step: 55004, total_loss: 5.2547173500061035
training step: 55005, total_loss: 3.5805158615112305
training step: 55006, total_loss: 3.811178684234619
training step: 55007, total_loss: 2.8489229679107666
training step: 55008, total_loss: 3.065199851989746
training step: 55009, total_loss: 3.0068156719207764
training step: 55010, total_loss: 3.6739840507507324
training step: 55011, total_loss: 6.2733612060546875
training step: 55012, total_loss: 5.829020023345947
training step: 55013, total_loss: 4.6570353507995605
training step: 55014, total_loss: 4.043898582458496
training step: 55015, total_loss: 5.391792297363281
training step: 55016, total_loss: 5.550633907318115
training step: 55017, total_loss: 4.357058525085449
training step: 55018, total_loss: 4.202191352844238
training step: 55019, total_loss: 5.574563980102539
training step: 55020, total_loss: 3.119691848754883
training step: 55021, total_loss: 2.936039924621582
training step: 55022, total_loss: 3.69026255607605
training step: 55023, total_loss: 4.087125778198242
training step: 55024, total_loss: 3.158902883529663
training step: 55025, total_loss: 4.008169174194336
training step: 55026, total_loss: 3.411996603012085
training step: 55027, total_loss: 5.140140533447266
training step: 55028, total_loss: 3.7411043643951416
training step: 55029, total_loss: 5.211155891418457
training step: 55030, total_loss: 8.31274127960205
training step: 55031, total_loss: 3.7303123474121094
training step: 55032, total_loss: 4.983641147613525
training step: 55033, total_loss: 5.239520072937012
training step: 55034, total_loss: 3.7132625579833984
training step: 55035, total_loss: 3.4799537658691406
training step: 55036, total_loss: 4.125449180603027
training step: 55037, total_loss: 2.7479500770568848
training step: 55038, total_loss: 3.6636929512023926
training step: 55039, total_loss: 3.6447033882141113
training step: 55040, total_loss: 3.503870964050293
training step: 55041, total_loss: 4.006206035614014
training step: 55042, total_loss: 5.828200340270996
training step: 55043, total_loss: 4.00501823425293
training step: 55044, total_loss: 2.3497848510742188
training step: 55045, total_loss: 4.436467170715332
training step: 55046, total_loss: 2.133775472640991
training step: 55047, total_loss: 2.820652961730957
training step: 55048, total_loss: 4.713214874267578
training step: 55049, total_loss: 5.026632308959961
training step: 55050, total_loss: 5.511935234069824
training step: 55051, total_loss: 2.5227162837982178
training step: 55052, total_loss: 6.006807327270508
training step: 55053, total_loss: 4.652027130126953
training step: 55054, total_loss: 3.8067469596862793
training step: 55055, total_loss: 4.521219253540039
training step: 55056, total_loss: 3.142899513244629
training step: 55057, total_loss: 5.207999229431152
training step: 55058, total_loss: 5.118572235107422
training step: 55059, total_loss: 3.608553409576416
training step: 55060, total_loss: 3.391439437866211
training step: 55061, total_loss: 4.2970757484436035
training step: 55062, total_loss: 3.694314479827881
training step: 55063, total_loss: 4.31342887878418
training step: 55064, total_loss: 4.210113525390625
training step: 55065, total_loss: 2.9544780254364014
training step: 55066, total_loss: 3.5485644340515137
training step: 55067, total_loss: 5.113354682922363
training step: 55068, total_loss: 3.490823984146118
training step: 55069, total_loss: 4.085012912750244
training step: 55070, total_loss: 5.898491859436035
training step: 55071, total_loss: 5.3972578048706055
training step: 55072, total_loss: 4.573567867279053
training step: 55073, total_loss: 4.385972499847412
training step: 55074, total_loss: 3.5644631385803223
training step: 55075, total_loss: 4.5062456130981445
training step: 55076, total_loss: 1.4487775564193726
training step: 55077, total_loss: 5.320437431335449
training step: 55078, total_loss: 3.6623916625976562
training step: 55079, total_loss: 4.019232273101807
training step: 55080, total_loss: 4.975745677947998
training step: 55081, total_loss: 3.7419028282165527
training step: 55082, total_loss: 4.728245735168457
training step: 55083, total_loss: 4.580631256103516
training step: 55084, total_loss: 4.587739944458008
training step: 55085, total_loss: 3.5396077632904053
training step: 55086, total_loss: 4.539654731750488
training step: 55087, total_loss: 4.656944751739502
training step: 55088, total_loss: 5.102357387542725
training step: 55089, total_loss: 4.512935638427734
training step: 55090, total_loss: 5.114325523376465
training step: 55091, total_loss: 2.8743741512298584
training step: 55092, total_loss: 4.1271467208862305
training step: 55093, total_loss: 4.203383922576904
training step: 55094, total_loss: 4.487704277038574
training step: 55095, total_loss: 3.4514541625976562
training step: 55096, total_loss: 5.253605842590332
training step: 55097, total_loss: 3.9436635971069336
training step: 55098, total_loss: 3.2234933376312256
training step: 55099, total_loss: 4.404596328735352
training step: 55100, total_loss: 3.017535924911499
training step: 55101, total_loss: 4.412425994873047
training step: 55102, total_loss: 4.722135543823242
training step: 55103, total_loss: 4.101990222930908
training step: 55104, total_loss: 5.375633239746094
training step: 55105, total_loss: 2.761420249938965
training step: 55106, total_loss: 5.489443778991699
training step: 55107, total_loss: 4.768556594848633
training step: 55108, total_loss: 4.914658546447754
training step: 55109, total_loss: 3.9509568214416504
training step: 55110, total_loss: 5.769923210144043
training step: 55111, total_loss: 3.9643473625183105
training step: 55112, total_loss: 4.425982475280762
training step: 55113, total_loss: 4.317041397094727
training step: 55114, total_loss: 4.835569858551025
training step: 55115, total_loss: 5.200285911560059
training step: 55116, total_loss: 4.682846546173096
training step: 55117, total_loss: 4.928064823150635
training step: 55118, total_loss: 4.220950603485107
training step: 55119, total_loss: 5.823159217834473
training step: 55120, total_loss: 4.296138286590576
training step: 55121, total_loss: 4.394179821014404
training step: 55122, total_loss: 4.039262294769287
training step: 55123, total_loss: 3.4609110355377197
training step: 55124, total_loss: 4.887416362762451
training step: 55125, total_loss: 3.36264967918396
training step: 55126, total_loss: 4.140318870544434
training step: 55127, total_loss: 4.255621910095215
training step: 55128, total_loss: 4.667300224304199
training step: 55129, total_loss: 5.360502243041992
training step: 55130, total_loss: 2.1778111457824707
training step: 55131, total_loss: 1.7582111358642578
training step: 55132, total_loss: 5.230524063110352
training step: 55133, total_loss: 4.603605270385742
training step: 55134, total_loss: 6.125947952270508
training step: 55135, total_loss: 2.899752616882324
training step: 55136, total_loss: 3.2678141593933105
training step: 55137, total_loss: 5.593329429626465
training step: 55138, total_loss: 3.8103790283203125
training step: 55139, total_loss: 4.300086975097656
training step: 55140, total_loss: 4.501456260681152
training step: 55141, total_loss: 3.5091776847839355
training step: 55142, total_loss: 3.7351062297821045
training step: 55143, total_loss: 2.0414299964904785
training step: 55144, total_loss: 4.799465656280518
training step: 55145, total_loss: 2.182605266571045
training step: 55146, total_loss: 6.562251091003418
training step: 55147, total_loss: 3.5903372764587402
training step: 55148, total_loss: 5.3977580070495605
training step: 55149, total_loss: 3.8400917053222656
training step: 55150, total_loss: 2.853954792022705
training step: 55151, total_loss: 2.3533403873443604
training step: 55152, total_loss: 3.3342370986938477
training step: 55153, total_loss: 4.593875885009766
training step: 55154, total_loss: 4.869643211364746
training step: 55155, total_loss: 1.7249224185943604
training step: 55156, total_loss: 2.8997268676757812
training step: 55157, total_loss: 2.9352915287017822
training step: 55158, total_loss: 6.0071821212768555
training step: 55159, total_loss: 3.788878917694092
training step: 55160, total_loss: 3.77716326713562
training step: 55161, total_loss: 5.133093357086182
training step: 55162, total_loss: 5.4398393630981445
training step: 55163, total_loss: 5.622336387634277
training step: 55164, total_loss: 2.8589134216308594
training step: 55165, total_loss: 4.954164505004883
training step: 55166, total_loss: 4.578117370605469
training step: 55167, total_loss: 4.131203651428223
training step: 55168, total_loss: 4.568222999572754
training step: 55169, total_loss: 3.880582809448242
training step: 55170, total_loss: 5.313345909118652
training step: 55171, total_loss: 4.0159759521484375
training step: 55172, total_loss: 5.03914737701416
training step: 55173, total_loss: 5.085843086242676
training step: 55174, total_loss: 3.263245105743408
training step: 55175, total_loss: 4.522345066070557
training step: 55176, total_loss: 3.4774677753448486
training step: 55177, total_loss: 5.612464904785156
training step: 55178, total_loss: 1.2404903173446655
training step: 55179, total_loss: 4.832303047180176
training step: 55180, total_loss: 4.49177360534668
training step: 55181, total_loss: 4.226463317871094
training step: 55182, total_loss: 3.3482754230499268
training step: 55183, total_loss: 4.886178493499756
training step: 55184, total_loss: 3.536696434020996
training step: 55185, total_loss: 4.025540351867676
training step: 55186, total_loss: 2.7281486988067627
training step: 55187, total_loss: 3.220252513885498
training step: 55188, total_loss: 1.8507771492004395
training step: 55189, total_loss: 5.040552139282227
training step: 55190, total_loss: 4.605630874633789
training step: 55191, total_loss: 4.588781356811523
training step: 55192, total_loss: 3.068325996398926
training step: 55193, total_loss: 4.57872200012207
training step: 55194, total_loss: 5.4502716064453125
training step: 55195, total_loss: 4.662680625915527
training step: 55196, total_loss: 4.853109836578369
training step: 55197, total_loss: 3.9707298278808594
training step: 55198, total_loss: 4.297601222991943
training step: 55199, total_loss: 4.830160140991211
training step: 55200, total_loss: 4.7013936042785645
training step: 55201, total_loss: 3.045577049255371
training step: 55202, total_loss: 4.264346599578857
training step: 55203, total_loss: 4.499600887298584
training step: 55204, total_loss: 3.7651119232177734
training step: 55205, total_loss: 1.7290103435516357
training step: 55206, total_loss: 4.313053131103516
training step: 55207, total_loss: 4.181225299835205
training step: 55208, total_loss: 3.1174066066741943
training step: 55209, total_loss: 4.722019672393799
training step: 55210, total_loss: 4.677888870239258
training step: 55211, total_loss: 5.568553924560547
training step: 55212, total_loss: 4.667012691497803
training step: 55213, total_loss: 5.650562286376953
training step: 55214, total_loss: 4.350483417510986
training step: 55215, total_loss: 5.676172256469727
training step: 55216, total_loss: 2.9901490211486816
training step: 55217, total_loss: 5.226463794708252
training step: 55218, total_loss: 3.2361083030700684
training step: 55219, total_loss: 3.8926210403442383
training step: 55220, total_loss: 3.806867837905884
training step: 55221, total_loss: 3.247541904449463
training step: 55222, total_loss: 5.4203643798828125
training step: 55223, total_loss: 4.442133903503418
training step: 55224, total_loss: 4.7965545654296875
training step: 55225, total_loss: 4.027130603790283
training step: 55226, total_loss: 3.869162082672119
training step: 55227, total_loss: 4.467673301696777
training step: 55228, total_loss: 4.034533500671387
training step: 55229, total_loss: 4.596829891204834
training step: 55230, total_loss: 5.086983680725098
training step: 55231, total_loss: 4.162744522094727
training step: 55232, total_loss: 5.530959606170654
training step: 55233, total_loss: 4.11272668838501
training step: 55234, total_loss: 4.962643623352051
training step: 55235, total_loss: 4.179112434387207
training step: 55236, total_loss: 1.1287795305252075
training step: 55237, total_loss: 3.751098155975342
training step: 55238, total_loss: 4.228832244873047
training step: 55239, total_loss: 5.456202983856201
training step: 55240, total_loss: 3.727790355682373
training step: 55241, total_loss: 4.770126819610596
training step: 55242, total_loss: 4.439037322998047
training step: 55243, total_loss: 4.829854965209961
training step: 55244, total_loss: 2.3621292114257812
training step: 55245, total_loss: 4.4995622634887695
training step: 55246, total_loss: 4.031731605529785
training step: 55247, total_loss: 6.3408002853393555
training step: 55248, total_loss: 5.573808670043945
training step: 55249, total_loss: 2.9523704051971436
training step: 55250, total_loss: 1.3957079648971558
training step: 55251, total_loss: 5.987949371337891
training step: 55252, total_loss: 1.029697060585022
training step: 55253, total_loss: 3.030940532684326
training step: 55254, total_loss: 1.2490853071212769
training step: 55255, total_loss: 4.028593063354492
training step: 55256, total_loss: 1.0808875560760498
training step: 55257, total_loss: 7.039164066314697
training step: 55258, total_loss: 3.6740365028381348
training step: 55259, total_loss: 4.831607818603516
training step: 55260, total_loss: 4.840048789978027
training step: 55261, total_loss: 5.532845497131348
training step: 55262, total_loss: 3.9823436737060547
training step: 55263, total_loss: 4.542499542236328
training step: 55264, total_loss: 5.34372615814209
training step: 55265, total_loss: 4.9824066162109375
training step: 55266, total_loss: 3.0764997005462646
training step: 55267, total_loss: 3.847476005554199
training step: 55268, total_loss: 3.8887124061584473
training step: 55269, total_loss: 4.985266208648682
training step: 55270, total_loss: 5.150708198547363
training step: 55271, total_loss: 4.004019260406494
training step: 55272, total_loss: 4.087662696838379
training step: 55273, total_loss: 3.6658554077148438
training step: 55274, total_loss: 4.567956924438477
training step: 55275, total_loss: 5.288532257080078
training step: 55276, total_loss: 4.232630729675293
training step: 55277, total_loss: 5.074397087097168
training step: 55278, total_loss: 4.264754772186279
training step: 55279, total_loss: 4.4442877769470215
training step: 55280, total_loss: 5.0689287185668945
training step: 55281, total_loss: 3.919816017150879
training step: 55282, total_loss: 4.127716541290283
training step: 55283, total_loss: 4.018470764160156
training step: 55284, total_loss: 4.6167192459106445
training step: 55285, total_loss: 6.114117622375488
training step: 55286, total_loss: 3.7716288566589355
training step: 55287, total_loss: 5.039773941040039
training step: 55288, total_loss: 3.827300548553467
training step: 55289, total_loss: 3.2113828659057617
training step: 55290, total_loss: 5.261238098144531
training step: 55291, total_loss: 4.170020580291748
training step: 55292, total_loss: 3.9544098377227783
training step: 55293, total_loss: 2.5503392219543457
training step: 55294, total_loss: 4.253570556640625
training step: 55295, total_loss: 4.511534214019775
training step: 55296, total_loss: 4.468574523925781
training step: 55297, total_loss: 4.35513973236084
training step: 55298, total_loss: 3.4751224517822266
training step: 55299, total_loss: 2.8985776901245117
training step: 55300, total_loss: 4.025521755218506
training step: 55301, total_loss: 4.491676330566406
training step: 55302, total_loss: 4.856844902038574
training step: 55303, total_loss: 1.2527976036071777
training step: 55304, total_loss: 2.7765345573425293
training step: 55305, total_loss: 4.255312442779541
training step: 55306, total_loss: 2.972416400909424
training step: 55307, total_loss: 4.263309001922607
training step: 55308, total_loss: 3.664494514465332
training step: 55309, total_loss: 3.801997184753418
training step: 55310, total_loss: 5.022758960723877
training step: 55311, total_loss: 3.952244997024536
training step: 55312, total_loss: 4.7037553787231445
training step: 55313, total_loss: 2.7096004486083984
training step: 55314, total_loss: 4.0111985206604
training step: 55315, total_loss: 4.187686920166016
training step: 55316, total_loss: 4.172725677490234
training step: 55317, total_loss: 3.744255542755127
training step: 55318, total_loss: 4.501763820648193
training step: 55319, total_loss: 5.862264633178711
training step: 55320, total_loss: 4.0630388259887695
training step: 55321, total_loss: 4.009336471557617
training step: 55322, total_loss: 5.546825408935547
training step: 55323, total_loss: 5.098299026489258
training step: 55324, total_loss: 4.641289710998535
training step: 55325, total_loss: 4.142350196838379
training step: 55326, total_loss: 3.0562448501586914
training step: 55327, total_loss: 5.670255184173584
training step: 55328, total_loss: 5.686841011047363
training step: 55329, total_loss: 4.1573405265808105
training step: 55330, total_loss: 3.7491519451141357
training step: 55331, total_loss: 3.1841158866882324
training step: 55332, total_loss: 4.79277229309082
training step: 55333, total_loss: 3.08004093170166
training step: 55334, total_loss: 3.413264274597168
training step: 55335, total_loss: 4.5825958251953125
training step: 55336, total_loss: 4.451937675476074
training step: 55337, total_loss: 4.342457294464111
training step: 55338, total_loss: 5.420474052429199
training step: 55339, total_loss: 2.9655723571777344
training step: 55340, total_loss: 4.333004951477051
training step: 55341, total_loss: 5.39395809173584
training step: 55342, total_loss: 4.075688362121582
training step: 55343, total_loss: 4.782093048095703
training step: 55344, total_loss: 4.063920021057129
training step: 55345, total_loss: 4.836091041564941
training step: 55346, total_loss: 3.860321521759033
training step: 55347, total_loss: 5.363426208496094
training step: 55348, total_loss: 4.42643928527832
training step: 55349, total_loss: 3.7621021270751953
training step: 55350, total_loss: 5.067625999450684
training step: 55351, total_loss: 5.151458263397217
training step: 55352, total_loss: 4.216869354248047
training step: 55353, total_loss: 0.8282996416091919
training step: 55354, total_loss: 3.1725828647613525
training step: 55355, total_loss: 5.320941925048828
training step: 55356, total_loss: 1.481940746307373
training step: 55357, total_loss: 4.287754058837891
training step: 55358, total_loss: 4.941525936126709
training step: 55359, total_loss: 4.363219261169434
training step: 55360, total_loss: 2.472701072692871
training step: 55361, total_loss: 4.509111404418945
training step: 55362, total_loss: 4.401599884033203
training step: 55363, total_loss: 3.895742893218994
training step: 55364, total_loss: 3.708159923553467
training step: 55365, total_loss: 4.724591255187988
training step: 55366, total_loss: 3.9630236625671387
training step: 55367, total_loss: 4.145211696624756
training step: 55368, total_loss: 3.8003780841827393
training step: 55369, total_loss: 4.1650872230529785
training step: 55370, total_loss: 3.237016201019287
training step: 55371, total_loss: 3.856144905090332
training step: 55372, total_loss: 4.49803352355957
training step: 55373, total_loss: 4.382692337036133
training step: 55374, total_loss: 4.486752033233643
training step: 55375, total_loss: 4.421982288360596
training step: 55376, total_loss: 5.003788471221924
training step: 55377, total_loss: 2.1975789070129395
training step: 55378, total_loss: 5.192862510681152
training step: 55379, total_loss: 3.367180109024048
training step: 55380, total_loss: 3.957686185836792
training step: 55381, total_loss: 2.7253527641296387
training step: 55382, total_loss: 1.091421365737915
training step: 55383, total_loss: 3.891277313232422
training step: 55384, total_loss: 4.900516033172607
training step: 55385, total_loss: 6.5806427001953125
training step: 55386, total_loss: 3.9114789962768555
training step: 55387, total_loss: 5.613905429840088
training step: 55388, total_loss: 5.2698259353637695
training step: 55389, total_loss: 4.957283020019531
training step: 55390, total_loss: 5.434693813323975
training step: 55391, total_loss: 3.6121253967285156
training step: 55392, total_loss: 4.082881927490234
training step: 55393, total_loss: 4.247779846191406
training step: 55394, total_loss: 1.068609356880188
training step: 55395, total_loss: 4.81146764755249
training step: 55396, total_loss: 4.762119293212891
training step: 55397, total_loss: 4.16130256652832
training step: 55398, total_loss: 5.957705974578857
training step: 55399, total_loss: 5.100081443786621
training step: 55400, total_loss: 4.896485328674316
training step: 55401, total_loss: 3.312527656555176
training step: 55402, total_loss: 3.1212573051452637
training step: 55403, total_loss: 1.869709849357605
training step: 55404, total_loss: 3.511274814605713
training step: 55405, total_loss: 6.070377349853516
training step: 55406, total_loss: 4.420918941497803
training step: 55407, total_loss: 4.1744842529296875
training step: 55408, total_loss: 4.48290491104126
training step: 55409, total_loss: 4.798111915588379
training step: 55410, total_loss: 4.287413597106934
training step: 55411, total_loss: 5.369694709777832
training step: 55412, total_loss: 4.690188407897949
training step: 55413, total_loss: 4.3434271812438965
training step: 55414, total_loss: 5.909745216369629
training step: 55415, total_loss: 5.094752311706543
training step: 55416, total_loss: 3.648622512817383
training step: 55417, total_loss: 4.069969177246094
training step: 55418, total_loss: 3.6357264518737793
training step: 55419, total_loss: 4.982456207275391
training step: 55420, total_loss: 3.7629990577697754
training step: 55421, total_loss: 4.587568283081055
training step: 55422, total_loss: 3.30869460105896
training step: 55423, total_loss: 3.8833675384521484
training step: 55424, total_loss: 4.285767555236816
training step: 55425, total_loss: 4.2556657791137695
training step: 55426, total_loss: 3.7712841033935547
training step: 55427, total_loss: 1.1529572010040283
training step: 55428, total_loss: 3.9316885471343994
training step: 55429, total_loss: 6.163853168487549
training step: 55430, total_loss: 3.511671304702759
training step: 55431, total_loss: 4.064546585083008
training step: 55432, total_loss: 5.608520030975342
training step: 55433, total_loss: 5.757338523864746
training step: 55434, total_loss: 4.236271381378174
training step: 55435, total_loss: 3.4283533096313477
training step: 55436, total_loss: 4.218349456787109
training step: 55437, total_loss: 6.143749237060547
training step: 55438, total_loss: 5.268746376037598
training step: 55439, total_loss: 3.9979429244995117
training step: 55440, total_loss: 4.924737930297852
training step: 55441, total_loss: 2.7462267875671387
training step: 55442, total_loss: 4.568844795227051
training step: 55443, total_loss: 4.62327766418457
training step: 55444, total_loss: 4.962288856506348
training step: 55445, total_loss: 5.438719272613525
training step: 55446, total_loss: 4.633606433868408
training step: 55447, total_loss: 4.6315765380859375
training step: 55448, total_loss: 3.281604051589966
training step: 55449, total_loss: 5.009148597717285
training step: 55450, total_loss: 4.95095157623291
training step: 55451, total_loss: 3.751673460006714
training step: 55452, total_loss: 5.634875297546387
training step: 55453, total_loss: 4.329856872558594
training step: 55454, total_loss: 4.618022918701172
training step: 55455, total_loss: 4.475462436676025
training step: 55456, total_loss: 3.5358452796936035
training step: 55457, total_loss: 3.503206968307495
training step: 55458, total_loss: 3.8669748306274414
training step: 55459, total_loss: 4.467501163482666
training step: 55460, total_loss: 3.7098546028137207
training step: 55461, total_loss: 5.398212432861328
training step: 55462, total_loss: 2.2514350414276123
training step: 55463, total_loss: 5.913479804992676
training step: 55464, total_loss: 2.0610032081604004
training step: 55465, total_loss: 5.060499668121338
training step: 55466, total_loss: 3.8451757431030273
training step: 55467, total_loss: 5.625724792480469
training step: 55468, total_loss: 2.8759925365448
training step: 55469, total_loss: 4.399257659912109
training step: 55470, total_loss: 5.417695045471191
training step: 55471, total_loss: 6.665028095245361
training step: 55472, total_loss: 4.534997940063477
training step: 55473, total_loss: 4.050634860992432
training step: 55474, total_loss: 5.060670852661133
training step: 55475, total_loss: 4.138930320739746
training step: 55476, total_loss: 4.604072570800781
training step: 55477, total_loss: 4.22947883605957
training step: 55478, total_loss: 5.291616439819336
training step: 55479, total_loss: 3.725238800048828
training step: 55480, total_loss: 1.3203144073486328
training step: 55481, total_loss: 3.7707951068878174
training step: 55482, total_loss: 1.201096534729004
training step: 55483, total_loss: 4.841514587402344
training step: 55484, total_loss: 3.923840284347534
training step: 55485, total_loss: 5.40275764465332
training step: 55486, total_loss: 4.617534637451172
training step: 55487, total_loss: 5.316970348358154
training step: 55488, total_loss: 1.6258975267410278
training step: 55489, total_loss: 5.495753765106201
training step: 55490, total_loss: 2.87032151222229
training step: 55491, total_loss: 4.8902692794799805
training step: 55492, total_loss: 4.850164890289307
training step: 55493, total_loss: 4.890781402587891
training step: 55494, total_loss: 3.0954041481018066
training step: 55495, total_loss: 5.3815412521362305
training step: 55496, total_loss: 4.050754547119141
training step: 55497, total_loss: 4.230908393859863
training step: 55498, total_loss: 3.207979917526245
training step: 55499, total_loss: 3.006025791168213
training step: 55500, total_loss: 3.8036344051361084
training step: 55501, total_loss: 5.565196990966797
training step: 55502, total_loss: 3.595681667327881
training step: 55503, total_loss: 4.824322700500488
training step: 55504, total_loss: 4.297181129455566
training step: 55505, total_loss: 4.01961612701416
training step: 55506, total_loss: 4.162566184997559
training step: 55507, total_loss: 4.410543441772461
training step: 55508, total_loss: 5.7061638832092285
training step: 55509, total_loss: 4.190175533294678
training step: 55510, total_loss: 4.020578384399414
training step: 55511, total_loss: 5.167911529541016
training step: 55512, total_loss: 2.9461987018585205
training step: 55513, total_loss: 4.649740219116211
training step: 55514, total_loss: 4.39687442779541
training step: 55515, total_loss: 5.645677089691162
training step: 55516, total_loss: 0.9611063599586487
training step: 55517, total_loss: 0.8787815570831299
training step: 55518, total_loss: 3.866551160812378
training step: 55519, total_loss: 5.366338729858398
training step: 55520, total_loss: 4.408839225769043
training step: 55521, total_loss: 5.24578857421875
training step: 55522, total_loss: 4.526269435882568
training step: 55523, total_loss: 5.692188262939453
training step: 55524, total_loss: 4.267675876617432
training step: 55525, total_loss: 3.7361292839050293
training step: 55526, total_loss: 3.86059308052063
training step: 55527, total_loss: 3.7126078605651855
training step: 55528, total_loss: 3.855511426925659
training step: 55529, total_loss: 4.620025634765625
training step: 55530, total_loss: 4.720380783081055
training step: 55531, total_loss: 3.067363977432251
training step: 55532, total_loss: 4.930612564086914
training step: 55533, total_loss: 3.884404182434082
training step: 55534, total_loss: 5.244842529296875
training step: 55535, total_loss: 4.166376113891602
training step: 55536, total_loss: 3.378051519393921
training step: 55537, total_loss: 4.025759220123291
training step: 55538, total_loss: 4.779262542724609
training step: 55539, total_loss: 3.4532997608184814
training step: 55540, total_loss: 4.388486862182617
training step: 55541, total_loss: 4.4205827713012695
training step: 55542, total_loss: 3.2518417835235596
training step: 55543, total_loss: 3.974903106689453
training step: 55544, total_loss: 3.200331211090088
training step: 55545, total_loss: 5.335221290588379
training step: 55546, total_loss: 3.9386682510375977
training step: 55547, total_loss: 6.02384090423584
training step: 55548, total_loss: 5.073202133178711
training step: 55549, total_loss: 4.363831520080566
training step: 55550, total_loss: 5.246636390686035
training step: 55551, total_loss: 4.754966735839844
training step: 55552, total_loss: 4.308280944824219
training step: 55553, total_loss: 4.544559001922607
training step: 55554, total_loss: 4.6057329177856445
training step: 55555, total_loss: 2.8633580207824707
training step: 55556, total_loss: 3.614366054534912
training step: 55557, total_loss: 4.5477166175842285
training step: 55558, total_loss: 5.493121147155762
training step: 55559, total_loss: 5.35069465637207
training step: 55560, total_loss: 5.775577068328857
training step: 55561, total_loss: 6.170596599578857
training step: 55562, total_loss: 2.3267979621887207
training step: 55563, total_loss: 4.440092086791992
training step: 55564, total_loss: 3.351909637451172
training step: 55565, total_loss: 4.236963272094727
training step: 55566, total_loss: 4.373847484588623
training step: 55567, total_loss: 4.911599636077881
training step: 55568, total_loss: 4.2209062576293945
training step: 55569, total_loss: 5.496194839477539
training step: 55570, total_loss: 4.264819622039795
training step: 55571, total_loss: 4.1861701011657715
training step: 55572, total_loss: 4.658985137939453
training step: 55573, total_loss: 5.2334818840026855
training step: 55574, total_loss: 2.879199504852295
training step: 55575, total_loss: 6.01639986038208
training step: 55576, total_loss: 3.796840190887451
training step: 55577, total_loss: 2.89626407623291
training step: 55578, total_loss: 3.412501335144043
training step: 55579, total_loss: 5.276118278503418
training step: 55580, total_loss: 4.643689155578613
training step: 55581, total_loss: 4.1652655601501465
training step: 55582, total_loss: 2.5645878314971924
training step: 55583, total_loss: 4.393660068511963
training step: 55584, total_loss: 4.873936176300049
training step: 55585, total_loss: 2.5263352394104004
training step: 55586, total_loss: 5.500510215759277
training step: 55587, total_loss: 5.179902076721191
training step: 55588, total_loss: 2.9283013343811035
training step: 55589, total_loss: 4.21556282043457
training step: 55590, total_loss: 3.6226115226745605
training step: 55591, total_loss: 5.178832054138184
training step: 55592, total_loss: 3.2654519081115723
training step: 55593, total_loss: 5.127017021179199
training step: 55594, total_loss: 3.5075979232788086
training step: 55595, total_loss: 4.316596984863281
training step: 55596, total_loss: 5.123920917510986
training step: 55597, total_loss: 4.454754829406738
training step: 55598, total_loss: 3.3650381565093994
training step: 55599, total_loss: 3.3695497512817383
training step: 55600, total_loss: 6.354930400848389
training step: 55601, total_loss: 4.492005348205566
training step: 55602, total_loss: 3.5002851486206055
training step: 55603, total_loss: 4.87644100189209
training step: 55604, total_loss: 2.922541618347168
training step: 55605, total_loss: 3.9946541786193848
training step: 55606, total_loss: 3.7935657501220703
training step: 55607, total_loss: 4.742284297943115
training step: 55608, total_loss: 4.63377571105957
training step: 55609, total_loss: 4.316065788269043
training step: 55610, total_loss: 6.07376766204834
training step: 55611, total_loss: 3.24491810798645
training step: 55612, total_loss: 3.987802028656006
training step: 55613, total_loss: 5.410630226135254
training step: 55614, total_loss: 4.304754734039307
training step: 55615, total_loss: 1.8428192138671875
training step: 55616, total_loss: 4.685784816741943
training step: 55617, total_loss: 4.572944641113281
training step: 55618, total_loss: 4.818784713745117
training step: 55619, total_loss: 2.4488327503204346
training step: 55620, total_loss: 4.678436279296875
training step: 55621, total_loss: 6.326223373413086
training step: 55622, total_loss: 4.495495796203613
training step: 55623, total_loss: 2.6148130893707275
training step: 55624, total_loss: 3.0646650791168213
training step: 55625, total_loss: 5.783246994018555
training step: 55626, total_loss: 5.111620903015137
training step: 55627, total_loss: 4.339792251586914
training step: 55628, total_loss: 4.247592926025391
training step: 55629, total_loss: 3.482837677001953
training step: 55630, total_loss: 4.478184700012207
training step: 55631, total_loss: 5.602785587310791
training step: 55632, total_loss: 3.9358527660369873
training step: 55633, total_loss: 4.5183844566345215
training step: 55634, total_loss: 4.248188018798828
training step: 55635, total_loss: 1.52986478805542
training step: 55636, total_loss: 2.680173397064209
training step: 55637, total_loss: 4.2102227210998535
training step: 55638, total_loss: 3.179456949234009
training step: 55639, total_loss: 3.196824073791504
training step: 55640, total_loss: 3.8484363555908203
training step: 55641, total_loss: 4.860532760620117
training step: 55642, total_loss: 3.4040513038635254
training step: 55643, total_loss: 6.21940803527832
training step: 55644, total_loss: 3.906811237335205
training step: 55645, total_loss: 3.380007743835449
training step: 55646, total_loss: 4.301657676696777
training step: 55647, total_loss: 4.223318099975586
training step: 55648, total_loss: 4.288204193115234
training step: 55649, total_loss: 5.094964027404785
training step: 55650, total_loss: 5.129456996917725
training step: 55651, total_loss: 5.810703277587891
training step: 55652, total_loss: 4.823456764221191
training step: 55653, total_loss: 3.2732443809509277
training step: 55654, total_loss: 4.433740615844727
training step: 55655, total_loss: 3.8332600593566895
training step: 55656, total_loss: 4.483104705810547
training step: 55657, total_loss: 4.56892204284668
training step: 55658, total_loss: 4.742749214172363
training step: 55659, total_loss: 2.1257660388946533
training step: 55660, total_loss: 7.217844009399414
training step: 55661, total_loss: 4.7750091552734375
training step: 55662, total_loss: 4.867783546447754
training step: 55663, total_loss: 3.6598899364471436
training step: 55664, total_loss: 4.6691179275512695
training step: 55665, total_loss: 5.351855278015137
training step: 55666, total_loss: 4.40568733215332
training step: 55667, total_loss: 3.121232032775879
training step: 55668, total_loss: 5.526125907897949
training step: 55669, total_loss: 5.34267520904541
training step: 55670, total_loss: 4.0769500732421875
training step: 55671, total_loss: 3.606689453125
training step: 55672, total_loss: 6.4426679611206055
training step: 55673, total_loss: 5.304958343505859
training step: 55674, total_loss: 4.418885707855225
training step: 55675, total_loss: 3.807081699371338
training step: 55676, total_loss: 4.142222881317139
training step: 55677, total_loss: 5.174280643463135
training step: 55678, total_loss: 4.478808403015137
training step: 55679, total_loss: 5.389172554016113
training step: 55680, total_loss: 4.100726127624512
training step: 55681, total_loss: 4.017784595489502
training step: 55682, total_loss: 4.660265922546387
training step: 55683, total_loss: 3.402172565460205
training step: 55684, total_loss: 4.987250328063965
training step: 55685, total_loss: 4.700191974639893
training step: 55686, total_loss: 5.0273637771606445
training step: 55687, total_loss: 8.215272903442383
training step: 55688, total_loss: 5.236185073852539
training step: 55689, total_loss: 3.7139289379119873
training step: 55690, total_loss: 4.298789978027344
training step: 55691, total_loss: 4.422922134399414
training step: 55692, total_loss: 1.262677550315857
training step: 55693, total_loss: 3.5681235790252686
training step: 55694, total_loss: 5.027585983276367
training step: 55695, total_loss: 4.169838905334473
training step: 55696, total_loss: 4.526106357574463
training step: 55697, total_loss: 1.87819242477417
training step: 55698, total_loss: 4.808361530303955
training step: 55699, total_loss: 4.475144863128662
training step: 55700, total_loss: 4.947108268737793
training step: 55701, total_loss: 3.0727787017822266
training step: 55702, total_loss: 4.379146099090576
training step: 55703, total_loss: 4.654987335205078
training step: 55704, total_loss: 4.615246772766113
training step: 55705, total_loss: 4.078917503356934
training step: 55706, total_loss: 4.604621410369873
training step: 55707, total_loss: 3.4701738357543945
training step: 55708, total_loss: 4.067966938018799
training step: 55709, total_loss: 2.8569388389587402
training step: 55710, total_loss: 4.608728885650635
training step: 55711, total_loss: 3.875093460083008
training step: 55712, total_loss: 3.773003101348877
training step: 55713, total_loss: 4.785030841827393
training step: 55714, total_loss: 2.962681293487549
training step: 55715, total_loss: 2.9651122093200684
training step: 55716, total_loss: 4.545287609100342
training step: 55717, total_loss: 3.095151901245117
training step: 55718, total_loss: 3.963642120361328
training step: 55719, total_loss: 5.76617431640625
training step: 55720, total_loss: 4.136076927185059
training step: 55721, total_loss: 3.6366119384765625
training step: 55722, total_loss: 5.835529804229736
training step: 55723, total_loss: 4.156050205230713
training step: 55724, total_loss: 3.568943977355957
training step: 55725, total_loss: 4.86398983001709
training step: 55726, total_loss: 3.407381772994995
training step: 55727, total_loss: 2.5393476486206055
training step: 55728, total_loss: 5.149075508117676
training step: 55729, total_loss: 2.722956418991089
training step: 55730, total_loss: 4.133300304412842
training step: 55731, total_loss: 3.411787986755371
training step: 55732, total_loss: 5.09301233291626
training step: 55733, total_loss: 4.127946853637695
training step: 55734, total_loss: 2.9862613677978516
training step: 55735, total_loss: 3.516831636428833
training step: 55736, total_loss: 5.093310356140137
training step: 55737, total_loss: 4.909201145172119
training step: 55738, total_loss: 5.496301174163818
training step: 55739, total_loss: 4.413819313049316
training step: 55740, total_loss: 4.074098587036133
training step: 55741, total_loss: 4.684803009033203
training step: 55742, total_loss: 5.119698524475098
training step: 55743, total_loss: 3.504676342010498
training step: 55744, total_loss: 2.7704057693481445
training step: 55745, total_loss: 3.8776955604553223
training step: 55746, total_loss: 5.034665107727051
training step: 55747, total_loss: 4.010100364685059
training step: 55748, total_loss: 5.003705978393555
training step: 55749, total_loss: 4.563050270080566
training step: 55750, total_loss: 3.8332529067993164
training step: 55751, total_loss: 3.5773634910583496
training step: 55752, total_loss: 4.098573684692383
training step: 55753, total_loss: 4.492643356323242
training step: 55754, total_loss: 5.509432792663574
training step: 55755, total_loss: 4.004955291748047
training step: 55756, total_loss: 3.7752294540405273
training step: 55757, total_loss: 5.4704179763793945
training step: 55758, total_loss: 3.8786044120788574
training step: 55759, total_loss: 3.346296548843384
training step: 55760, total_loss: 3.8322410583496094
training step: 55761, total_loss: 3.3386569023132324
training step: 55762, total_loss: 4.12396240234375
training step: 55763, total_loss: 2.731541633605957
training step: 55764, total_loss: 4.8344621658325195
training step: 55765, total_loss: 3.452986717224121
training step: 55766, total_loss: 4.764334201812744
training step: 55767, total_loss: 6.707085609436035
training step: 55768, total_loss: 5.616671085357666
training step: 55769, total_loss: 4.4083452224731445
training step: 55770, total_loss: 4.854302883148193
training step: 55771, total_loss: 2.9932708740234375
training step: 55772, total_loss: 5.012799263000488
training step: 55773, total_loss: 5.634389400482178
training step: 55774, total_loss: 4.004199504852295
training step: 55775, total_loss: 5.652843475341797
training step: 55776, total_loss: 3.521651268005371
training step: 55777, total_loss: 4.252264022827148
training step: 55778, total_loss: 5.05164909362793
training step: 55779, total_loss: 4.343874931335449
training step: 55780, total_loss: 3.4994521141052246
training step: 55781, total_loss: 5.387785911560059
training step: 55782, total_loss: 5.020872116088867
training step: 55783, total_loss: 4.334496021270752
training step: 55784, total_loss: 5.2974700927734375
training step: 55785, total_loss: 4.85655403137207
training step: 55786, total_loss: 3.2801527976989746
training step: 55787, total_loss: 2.5906760692596436
training step: 55788, total_loss: 3.1131930351257324
training step: 55789, total_loss: 2.9136769771575928
training step: 55790, total_loss: 4.741594314575195
training step: 55791, total_loss: 3.8154687881469727
training step: 55792, total_loss: 1.6949646472930908
training step: 55793, total_loss: 3.350254535675049
training step: 55794, total_loss: 3.7467265129089355
training step: 55795, total_loss: 2.1501870155334473
training step: 55796, total_loss: 4.267162322998047
training step: 55797, total_loss: 5.172221660614014
training step: 55798, total_loss: 4.120635986328125
training step: 55799, total_loss: 3.1375434398651123
training step: 55800, total_loss: 4.348349571228027
training step: 55801, total_loss: 3.6031036376953125
training step: 55802, total_loss: 4.461226463317871
training step: 55803, total_loss: 5.503771781921387
training step: 55804, total_loss: 3.4327120780944824
training step: 55805, total_loss: 2.8506133556365967
training step: 55806, total_loss: 4.6373066902160645
training step: 55807, total_loss: 3.818167209625244
training step: 55808, total_loss: 5.789736747741699
training step: 55809, total_loss: 3.163194179534912
training step: 55810, total_loss: 4.963222503662109
training step: 55811, total_loss: 5.472047328948975
training step: 55812, total_loss: 4.270464897155762
training step: 55813, total_loss: 4.248032093048096
training step: 55814, total_loss: 5.303906440734863
training step: 55815, total_loss: 4.447682857513428
training step: 55816, total_loss: 4.293087005615234
training step: 55817, total_loss: 3.0218191146850586
training step: 55818, total_loss: 3.977487802505493
training step: 55819, total_loss: 4.499629974365234
training step: 55820, total_loss: 5.965034484863281
training step: 55821, total_loss: 3.785820960998535
training step: 55822, total_loss: 5.226907253265381
training step: 55823, total_loss: 4.623099327087402
training step: 55824, total_loss: 3.3492655754089355
training step: 55825, total_loss: 2.8671388626098633
training step: 55826, total_loss: 3.7541112899780273
training step: 55827, total_loss: 3.7227189540863037
training step: 55828, total_loss: 0.9084312319755554
training step: 55829, total_loss: 3.9762141704559326
training step: 55830, total_loss: 6.579694747924805
training step: 55831, total_loss: 4.074383735656738
training step: 55832, total_loss: 4.527792453765869
training step: 55833, total_loss: 4.588317394256592
training step: 55834, total_loss: 5.187161445617676
training step: 55835, total_loss: 3.7193105220794678
training step: 55836, total_loss: 2.729579210281372
training step: 55837, total_loss: 3.3462648391723633
training step: 55838, total_loss: 3.9243783950805664
training step: 55839, total_loss: 4.172592639923096
training step: 55840, total_loss: 5.744317054748535
training step: 55841, total_loss: 3.9800631999969482
training step: 55842, total_loss: 3.4490013122558594
training step: 55843, total_loss: 4.154574871063232
training step: 55844, total_loss: 4.348379611968994
training step: 55845, total_loss: 4.083883285522461
training step: 55846, total_loss: 4.344038963317871
training step: 55847, total_loss: 3.884115219116211
training step: 55848, total_loss: 4.831167221069336
training step: 55849, total_loss: 5.016846656799316
training step: 55850, total_loss: 4.591806411743164
training step: 55851, total_loss: 3.83778715133667
training step: 55852, total_loss: 4.982938766479492
training step: 55853, total_loss: 5.005799770355225
training step: 55854, total_loss: 4.1006669998168945
training step: 55855, total_loss: 4.152688980102539
training step: 55856, total_loss: 4.208855628967285
training step: 55857, total_loss: 3.906214714050293
training step: 55858, total_loss: 2.93310546875
training step: 55859, total_loss: 6.482012748718262
training step: 55860, total_loss: 3.7987070083618164
training step: 55861, total_loss: 5.491354942321777
training step: 55862, total_loss: 3.6996870040893555
training step: 55863, total_loss: 3.134613275527954
training step: 55864, total_loss: 3.7079102993011475
training step: 55865, total_loss: 3.4980649948120117
training step: 55866, total_loss: 3.5434699058532715
training step: 55867, total_loss: 1.193453073501587
training step: 55868, total_loss: 3.591689109802246
training step: 55869, total_loss: 4.346420764923096
training step: 55870, total_loss: 4.311392307281494
training step: 55871, total_loss: 4.394743919372559
training step: 55872, total_loss: 3.89790678024292
training step: 55873, total_loss: 4.707106113433838
training step: 55874, total_loss: 4.236520290374756
training step: 55875, total_loss: 3.110470771789551
training step: 55876, total_loss: 6.1962385177612305
training step: 55877, total_loss: 4.136272430419922
training step: 55878, total_loss: 3.5685572624206543
training step: 55879, total_loss: 3.6856894493103027
training step: 55880, total_loss: 3.9236857891082764
training step: 55881, total_loss: 2.7879061698913574
training step: 55882, total_loss: 4.149999141693115
training step: 55883, total_loss: 4.4709248542785645
training step: 55884, total_loss: 5.3794403076171875
training step: 55885, total_loss: 2.5721564292907715
training step: 55886, total_loss: 2.9227304458618164
training step: 55887, total_loss: 4.2279181480407715
training step: 55888, total_loss: 3.993846893310547
training step: 55889, total_loss: 5.425308704376221
training step: 55890, total_loss: 4.720609664916992
training step: 55891, total_loss: 5.928689956665039
training step: 55892, total_loss: 4.279012680053711
training step: 55893, total_loss: 2.543637752532959
training step: 55894, total_loss: 5.158355236053467
training step: 55895, total_loss: 7.178683280944824
training step: 55896, total_loss: 4.5053935050964355
training step: 55897, total_loss: 4.554734230041504
training step: 55898, total_loss: 4.029412269592285
training step: 55899, total_loss: 3.7183139324188232
training step: 55900, total_loss: 4.623004913330078
training step: 55901, total_loss: 5.48844051361084
training step: 55902, total_loss: 5.443742752075195
training step: 55903, total_loss: 4.161379337310791
training step: 55904, total_loss: 4.510437488555908
training step: 55905, total_loss: 2.935584545135498
training step: 55906, total_loss: 3.5646238327026367
training step: 55907, total_loss: 3.668720245361328
training step: 55908, total_loss: 5.3394775390625
training step: 55909, total_loss: 4.660198211669922
training step: 55910, total_loss: 3.5177559852600098
training step: 55911, total_loss: 8.164570808410645
training step: 55912, total_loss: 2.927363872528076
training step: 55913, total_loss: 4.927030563354492
training step: 55914, total_loss: 4.1519775390625
training step: 55915, total_loss: 4.504513740539551
training step: 55916, total_loss: 4.670990943908691
training step: 55917, total_loss: 3.8883984088897705
training step: 55918, total_loss: 4.133408546447754
training step: 55919, total_loss: 3.770174503326416
training step: 55920, total_loss: 4.882569789886475
training step: 55921, total_loss: 1.7512948513031006
training step: 55922, total_loss: 5.028373718261719
training step: 55923, total_loss: 3.7709381580352783
training step: 55924, total_loss: 4.138972282409668
training step: 55925, total_loss: 4.737247467041016
training step: 55926, total_loss: 5.242703437805176
training step: 55927, total_loss: 3.386552572250366
training step: 55928, total_loss: 4.094576358795166
training step: 55929, total_loss: 6.422075271606445
training step: 55930, total_loss: 3.7569024562835693
training step: 55931, total_loss: 3.901254892349243
training step: 55932, total_loss: 2.937429428100586INFO:tensorflow:Writing predictions to: residual_output/predictions_56000.json
INFO:tensorflow:Writing nbest to: residual_output/nbest_predictions_56000.json

training step: 55933, total_loss: 3.867276668548584
training step: 55934, total_loss: 3.604203701019287
training step: 55935, total_loss: 6.346195220947266
training step: 55936, total_loss: 2.9551334381103516
training step: 55937, total_loss: 3.008425712585449
training step: 55938, total_loss: 4.874715805053711
training step: 55939, total_loss: 4.688767433166504
training step: 55940, total_loss: 4.529858589172363
training step: 55941, total_loss: 2.1364946365356445
training step: 55942, total_loss: 4.965248107910156
training step: 55943, total_loss: 3.556544065475464
training step: 55944, total_loss: 4.277735710144043
training step: 55945, total_loss: 4.500589370727539
training step: 55946, total_loss: 1.8988394737243652
training step: 55947, total_loss: 5.435285568237305
training step: 55948, total_loss: 3.790314197540283
training step: 55949, total_loss: 2.7070746421813965
training step: 55950, total_loss: 4.813508033752441
training step: 55951, total_loss: 3.47910737991333
training step: 55952, total_loss: 4.7311930656433105
training step: 55953, total_loss: 3.278252124786377
training step: 55954, total_loss: 5.169589996337891
training step: 55955, total_loss: 5.535944938659668
training step: 55956, total_loss: 4.933597564697266
training step: 55957, total_loss: 6.549849510192871
training step: 55958, total_loss: 4.486440658569336
training step: 55959, total_loss: 5.434695243835449
training step: 55960, total_loss: 5.141778945922852
training step: 55961, total_loss: 4.3455095291137695
training step: 55962, total_loss: 4.778310775756836
training step: 55963, total_loss: 6.172410011291504
training step: 55964, total_loss: 4.5048980712890625
training step: 55965, total_loss: 4.425450801849365
training step: 55966, total_loss: 5.195314884185791
training step: 55967, total_loss: 4.711904048919678
training step: 55968, total_loss: 5.024621963500977
training step: 55969, total_loss: 5.197384834289551
training step: 55970, total_loss: 6.002908229827881
training step: 55971, total_loss: 4.999120235443115
training step: 55972, total_loss: 4.065778732299805
training step: 55973, total_loss: 4.990267753601074
training step: 55974, total_loss: 5.976529121398926
training step: 55975, total_loss: 4.099025726318359
training step: 55976, total_loss: 7.349403381347656
training step: 55977, total_loss: 4.157733917236328
training step: 55978, total_loss: 5.559939384460449
training step: 55979, total_loss: 4.385298728942871
training step: 55980, total_loss: 4.3432722091674805
training step: 55981, total_loss: 5.934924125671387
training step: 55982, total_loss: 3.949883460998535
training step: 55983, total_loss: 6.182175636291504
training step: 55984, total_loss: 5.457383155822754
training step: 55985, total_loss: 3.357029914855957
training step: 55986, total_loss: 4.307069778442383
training step: 55987, total_loss: 4.614522457122803
training step: 55988, total_loss: 3.959482192993164
training step: 55989, total_loss: 4.350297451019287
training step: 55990, total_loss: 4.830193996429443
training step: 55991, total_loss: 4.870709419250488
training step: 55992, total_loss: 5.551642894744873
training step: 55993, total_loss: 4.848690032958984
training step: 55994, total_loss: 4.269798755645752
training step: 55995, total_loss: 4.731717109680176
training step: 55996, total_loss: 4.963532447814941
training step: 55997, total_loss: 4.444421768188477
training step: 55998, total_loss: 4.900190830230713
training step: 55999, total_loss: 3.0565929412841797
training step: 56000, total_loss: 3.6313254833221436
epoch finished! shuffle=False
evaluation: 56000, total_loss: 2.324202299118042, f1: 23.589278576828395, followup: 18.378213905370455, yesno: 1.6126578426897915, heq: 23.064049901110604, dheq: 0.6

Model saved in path residual_output//model_56000.ckpt
training step: 56001, total_loss: 4.295355796813965
training step: 56002, total_loss: 5.509082794189453
training step: 56003, total_loss: 3.760434150695801
training step: 56004, total_loss: 4.599398612976074
training step: 56005, total_loss: 4.551767349243164
training step: 56006, total_loss: 6.857673645019531
training step: 56007, total_loss: 5.413071155548096
training step: 56008, total_loss: 3.387507438659668
training step: 56009, total_loss: 3.76456618309021
training step: 56010, total_loss: 3.9575729370117188
training step: 56011, total_loss: 4.329598903656006
training step: 56012, total_loss: 5.4645490646362305
training step: 56013, total_loss: 4.19636344909668
training step: 56014, total_loss: 5.034632682800293
training step: 56015, total_loss: 3.7230844497680664
training step: 56016, total_loss: 4.505884647369385
training step: 56017, total_loss: 6.106106281280518
training step: 56018, total_loss: 5.564616680145264
training step: 56019, total_loss: 4.569393157958984
training step: 56020, total_loss: 2.720430850982666
training step: 56021, total_loss: 3.717535972595215
training step: 56022, total_loss: 3.8085103034973145
training step: 56023, total_loss: 4.772617816925049
training step: 56024, total_loss: 5.55354642868042
training step: 56025, total_loss: 3.535637855529785
training step: 56026, total_loss: 5.457999229431152
training step: 56027, total_loss: 5.562666893005371
training step: 56028, total_loss: 5.4070234298706055
training step: 56029, total_loss: 5.433895111083984
training step: 56030, total_loss: 3.3626694679260254
training step: 56031, total_loss: 4.558499336242676
training step: 56032, total_loss: 3.347531318664551
training step: 56033, total_loss: 3.9154069423675537
training step: 56034, total_loss: 2.8292675018310547
training step: 56035, total_loss: 4.44243860244751
training step: 56036, total_loss: 3.268413543701172
training step: 56037, total_loss: 3.5093274116516113
training step: 56038, total_loss: 4.063929557800293
training step: 56039, total_loss: 6.145230293273926
training step: 56040, total_loss: 4.722627639770508
training step: 56041, total_loss: 4.852084636688232
training step: 56042, total_loss: 2.452259063720703
training step: 56043, total_loss: 4.548220634460449
training step: 56044, total_loss: 4.555469036102295
training step: 56045, total_loss: 5.18610954284668
training step: 56046, total_loss: 3.1037216186523438
training step: 56047, total_loss: 2.6848456859588623
training step: 56048, total_loss: 4.669057369232178
training step: 56049, total_loss: 4.9117841720581055
training step: 56050, total_loss: 8.31281852722168
training step: 56051, total_loss: 3.8320364952087402
training step: 56052, total_loss: 4.980403900146484
training step: 56053, total_loss: 4.5869598388671875
training step: 56054, total_loss: 5.696116924285889
training step: 56055, total_loss: 4.795605659484863
training step: 56056, total_loss: 6.424080848693848
training step: 56057, total_loss: 4.320072174072266
training step: 56058, total_loss: 4.1427412033081055
training step: 56059, total_loss: 4.481721878051758
training step: 56060, total_loss: 5.055741310119629
training step: 56061, total_loss: 3.714081287384033
training step: 56062, total_loss: 5.303821563720703
training step: 56063, total_loss: 4.607566833496094
training step: 56064, total_loss: 4.984532356262207
training step: 56065, total_loss: 4.627317905426025
training step: 56066, total_loss: 4.134093761444092
training step: 56067, total_loss: 5.274384021759033
training step: 56068, total_loss: 1.4663634300231934
training step: 56069, total_loss: 3.320040464401245
training step: 56070, total_loss: 4.512399673461914
training step: 56071, total_loss: 4.603086948394775
training step: 56072, total_loss: 5.717887878417969
training step: 56073, total_loss: 4.022061347961426
training step: 56074, total_loss: 4.521018981933594
training step: 56075, total_loss: 5.288575172424316
training step: 56076, total_loss: 3.6128110885620117
training step: 56077, total_loss: 4.289735794067383
training step: 56078, total_loss: 4.0224480628967285
training step: 56079, total_loss: 1.4047340154647827
training step: 56080, total_loss: 6.881792068481445
training step: 56081, total_loss: 3.9203052520751953
training step: 56082, total_loss: 4.7771453857421875
training step: 56083, total_loss: 5.069457054138184
training step: 56084, total_loss: 5.263528823852539
training step: 56085, total_loss: 5.455039024353027
training step: 56086, total_loss: 4.396261692047119
training step: 56087, total_loss: 4.834695816040039
training step: 56088, total_loss: 4.197517395019531
training step: 56089, total_loss: 4.368317127227783
training step: 56090, total_loss: 5.825087547302246
training step: 56091, total_loss: 4.669958114624023
training step: 56092, total_loss: 4.460118293762207
training step: 56093, total_loss: 4.229944229125977
training step: 56094, total_loss: 4.178722381591797
training step: 56095, total_loss: 3.104447364807129
training step: 56096, total_loss: 2.8248496055603027
training step: 56097, total_loss: 1.1119279861450195
training step: 56098, total_loss: 4.831976890563965
training step: 56099, total_loss: 4.959578990936279
training step: 56100, total_loss: 5.328930377960205
training step: 56101, total_loss: 4.993254661560059
training step: 56102, total_loss: 4.064343452453613
training step: 56103, total_loss: 2.7208564281463623
training step: 56104, total_loss: 3.7683520317077637
training step: 56105, total_loss: 3.581770896911621
training step: 56106, total_loss: 1.0329663753509521
training step: 56107, total_loss: 4.378429412841797
training step: 56108, total_loss: 4.058979511260986
training step: 56109, total_loss: 5.046229362487793
training step: 56110, total_loss: 7.126727104187012
training step: 56111, total_loss: 3.0245261192321777
training step: 56112, total_loss: 3.486522674560547
training step: 56113, total_loss: 4.6923675537109375
training step: 56114, total_loss: 4.174210071563721
training step: 56115, total_loss: 4.561295986175537
training step: 56116, total_loss: 1.330851435661316
training step: 56117, total_loss: 3.512545108795166
training step: 56118, total_loss: 2.7646288871765137
training step: 56119, total_loss: 3.6877427101135254
training step: 56120, total_loss: 3.731757640838623
training step: 56121, total_loss: 4.863875389099121
training step: 56122, total_loss: 3.562232732772827
training step: 56123, total_loss: 4.422227382659912
training step: 56124, total_loss: 2.571234703063965
training step: 56125, total_loss: 4.2309370040893555
training step: 56126, total_loss: 4.314014911651611
training step: 56127, total_loss: 4.026463031768799
training step: 56128, total_loss: 4.764360427856445
training step: 56129, total_loss: 4.165996551513672
training step: 56130, total_loss: 4.647584915161133
training step: 56131, total_loss: 4.337818145751953
training step: 56132, total_loss: 4.581783294677734
training step: 56133, total_loss: 4.386575698852539
training step: 56134, total_loss: 5.066229820251465
training step: 56135, total_loss: 5.438093185424805
training step: 56136, total_loss: 4.207606315612793
training step: 56137, total_loss: 4.536810398101807
training step: 56138, total_loss: 4.204702854156494
training step: 56139, total_loss: 4.932652473449707
training step: 56140, total_loss: 2.410909652709961
training step: 56141, total_loss: 3.330249786376953
training step: 56142, total_loss: 4.009244441986084
training step: 56143, total_loss: 5.035984516143799
training step: 56144, total_loss: 4.169565200805664
training step: 56145, total_loss: 5.402637958526611
training step: 56146, total_loss: 4.44964075088501
training step: 56147, total_loss: 5.324559211730957
training step: 56148, total_loss: 3.8461506366729736
training step: 56149, total_loss: 4.41886568069458
training step: 56150, total_loss: 1.4075398445129395
training step: 56151, total_loss: 4.150383949279785
training step: 56152, total_loss: 3.783986806869507
training step: 56153, total_loss: 4.8987274169921875
training step: 56154, total_loss: 5.29315710067749
training step: 56155, total_loss: 3.7206618785858154
training step: 56156, total_loss: 4.694934844970703
training step: 56157, total_loss: 5.07304573059082
training step: 56158, total_loss: 4.442105293273926
training step: 56159, total_loss: 5.006608963012695
training step: 56160, total_loss: 4.769725799560547
training step: 56161, total_loss: 3.3421759605407715
training step: 56162, total_loss: 4.2156758308410645
training step: 56163, total_loss: 3.4810070991516113
training step: 56164, total_loss: 4.3036885261535645
training step: 56165, total_loss: 4.795812606811523
training step: 56166, total_loss: 5.939112186431885
training step: 56167, total_loss: 4.339914798736572
training step: 56168, total_loss: 4.573936939239502
training step: 56169, total_loss: 4.8177971839904785
training step: 56170, total_loss: 4.018075942993164
training step: 56171, total_loss: 4.749438285827637
training step: 56172, total_loss: 5.672811985015869
training step: 56173, total_loss: 3.7273178100585938
training step: 56174, total_loss: 3.4095492362976074
training step: 56175, total_loss: 2.570890188217163
training step: 56176, total_loss: 4.947806358337402
training step: 56177, total_loss: 6.913744926452637
training step: 56178, total_loss: 4.022940635681152
training step: 56179, total_loss: 4.067168235778809
training step: 56180, total_loss: 4.675910472869873
training step: 56181, total_loss: 4.365879058837891
training step: 56182, total_loss: 3.8875107765197754
training step: 56183, total_loss: 5.228609561920166
training step: 56184, total_loss: 5.050803184509277
training step: 56185, total_loss: 4.496265411376953
training step: 56186, total_loss: 3.8817343711853027
training step: 56187, total_loss: 5.179422855377197
training step: 56188, total_loss: 3.3085570335388184
training step: 56189, total_loss: 4.112486362457275
training step: 56190, total_loss: 4.482426166534424
training step: 56191, total_loss: 5.7896623611450195
training step: 56192, total_loss: 4.692138195037842
training step: 56193, total_loss: 3.560904026031494
training step: 56194, total_loss: 3.9079880714416504
training step: 56195, total_loss: 5.411935329437256
training step: 56196, total_loss: 3.233734607696533
training step: 56197, total_loss: 2.3753068447113037
training step: 56198, total_loss: 2.595508098602295
training step: 56199, total_loss: 2.872016429901123
training step: 56200, total_loss: 2.406435012817383
training step: 56201, total_loss: 4.89526891708374
training step: 56202, total_loss: 5.139283180236816
training step: 56203, total_loss: 4.493448257446289
training step: 56204, total_loss: 4.677797317504883
training step: 56205, total_loss: 4.343697547912598
training step: 56206, total_loss: 6.834388732910156
training step: 56207, total_loss: 4.818345069885254
training step: 56208, total_loss: 4.356067657470703
training step: 56209, total_loss: 4.373593330383301
training step: 56210, total_loss: 4.1282958984375
training step: 56211, total_loss: 3.4348256587982178
training step: 56212, total_loss: 4.068445205688477
training step: 56213, total_loss: 4.497186660766602
training step: 56214, total_loss: 3.8201968669891357
training step: 56215, total_loss: 3.892954111099243
training step: 56216, total_loss: 4.949068546295166
training step: 56217, total_loss: 4.641343116760254
training step: 56218, total_loss: 4.604599952697754
training step: 56219, total_loss: 4.004279613494873
training step: 56220, total_loss: 4.825723648071289
training step: 56221, total_loss: 4.825298309326172
training step: 56222, total_loss: 4.728173732757568
training step: 56223, total_loss: 1.793558955192566
training step: 56224, total_loss: 1.1617804765701294
training step: 56225, total_loss: 2.510392665863037
training step: 56226, total_loss: 3.191645622253418
training step: 56227, total_loss: 4.466461658477783
training step: 56228, total_loss: 5.866655349731445
training step: 56229, total_loss: 4.3902740478515625
training step: 56230, total_loss: 5.2469024658203125
training step: 56231, total_loss: 4.299517631530762
training step: 56232, total_loss: 5.593898296356201
training step: 56233, total_loss: 3.9499216079711914
training step: 56234, total_loss: 4.085086345672607
training step: 56235, total_loss: 4.453409194946289
training step: 56236, total_loss: 3.8283305168151855
training step: 56237, total_loss: 5.177072048187256
training step: 56238, total_loss: 4.398637771606445
training step: 56239, total_loss: 1.1828300952911377
training step: 56240, total_loss: 3.7565882205963135
training step: 56241, total_loss: 3.543722152709961
training step: 56242, total_loss: 4.152641773223877
training step: 56243, total_loss: 5.63797664642334
training step: 56244, total_loss: 1.1711409091949463
training step: 56245, total_loss: 4.296992778778076
training step: 56246, total_loss: 3.9850921630859375
training step: 56247, total_loss: 4.408316612243652
training step: 56248, total_loss: 3.793619155883789
training step: 56249, total_loss: 3.553154945373535
training step: 56250, total_loss: 6.001668930053711
training step: 56251, total_loss: 4.169099807739258
training step: 56252, total_loss: 5.220267295837402
training step: 56253, total_loss: 4.326415061950684
training step: 56254, total_loss: 4.718912601470947
training step: 56255, total_loss: 4.527674674987793
training step: 56256, total_loss: 5.670246124267578
training step: 56257, total_loss: 3.2731025218963623
training step: 56258, total_loss: 3.746581554412842
training step: 56259, total_loss: 5.14458703994751
training step: 56260, total_loss: 1.8577818870544434
training step: 56261, total_loss: 2.9105758666992188
training step: 56262, total_loss: 5.562867641448975
training step: 56263, total_loss: 4.8749213218688965
training step: 56264, total_loss: 1.0942214727401733
training step: 56265, total_loss: 3.8047738075256348
training step: 56266, total_loss: 3.511535882949829
training step: 56267, total_loss: 2.1150827407836914
training step: 56268, total_loss: 4.688519477844238
training step: 56269, total_loss: 4.213200569152832
training step: 56270, total_loss: 2.867283582687378
training step: 56271, total_loss: 5.067743301391602
training step: 56272, total_loss: 3.9136834144592285
training step: 56273, total_loss: 5.170070648193359
training step: 56274, total_loss: 3.980748176574707
training step: 56275, total_loss: 2.403306245803833
training step: 56276, total_loss: 6.008940696716309
training step: 56277, total_loss: 4.588974475860596
training step: 56278, total_loss: 3.224853992462158
training step: 56279, total_loss: 3.990671396255493
training step: 56280, total_loss: 4.799314498901367
training step: 56281, total_loss: 4.805047035217285
training step: 56282, total_loss: 3.987060546875
training step: 56283, total_loss: 4.710511207580566
training step: 56284, total_loss: 3.9158220291137695
training step: 56285, total_loss: 4.742767810821533
training step: 56286, total_loss: 2.3797008991241455
training step: 56287, total_loss: 3.7645111083984375
training step: 56288, total_loss: 4.518421173095703
training step: 56289, total_loss: 4.765509605407715
training step: 56290, total_loss: 5.793724060058594
training step: 56291, total_loss: 6.31589412689209
training step: 56292, total_loss: 4.613767147064209
training step: 56293, total_loss: 5.750261306762695
training step: 56294, total_loss: 3.111872673034668
training step: 56295, total_loss: 4.791271686553955
training step: 56296, total_loss: 2.423231601715088
training step: 56297, total_loss: 4.633955955505371
training step: 56298, total_loss: 3.0404229164123535
training step: 56299, total_loss: 5.134688377380371
training step: 56300, total_loss: 2.751268148422241
training step: 56301, total_loss: 4.547893524169922
training step: 56302, total_loss: 5.208063125610352
training step: 56303, total_loss: 2.292120933532715
training step: 56304, total_loss: 4.775792598724365
training step: 56305, total_loss: 5.303719520568848
training step: 56306, total_loss: 4.150911808013916
training step: 56307, total_loss: 3.9253149032592773
training step: 56308, total_loss: 7.555710792541504
training step: 56309, total_loss: 4.229007244110107
training step: 56310, total_loss: 4.981415748596191
training step: 56311, total_loss: 5.103449821472168
training step: 56312, total_loss: 5.032712459564209
training step: 56313, total_loss: 2.7901973724365234
training step: 56314, total_loss: 3.961341381072998
training step: 56315, total_loss: 2.2266242504119873
training step: 56316, total_loss: 5.386133193969727
training step: 56317, total_loss: 4.340208530426025
training step: 56318, total_loss: 0.9966847896575928
training step: 56319, total_loss: 3.5858030319213867
training step: 56320, total_loss: 4.892303943634033
training step: 56321, total_loss: 4.741324424743652
training step: 56322, total_loss: 5.802019119262695
training step: 56323, total_loss: 3.1745901107788086
training step: 56324, total_loss: 6.639165878295898
training step: 56325, total_loss: 3.6120505332946777
training step: 56326, total_loss: 4.816370010375977
training step: 56327, total_loss: 5.445376396179199
training step: 56328, total_loss: 4.490445137023926
training step: 56329, total_loss: 1.0987465381622314
training step: 56330, total_loss: 4.285529613494873
training step: 56331, total_loss: 3.013244867324829
training step: 56332, total_loss: 5.005135536193848
training step: 56333, total_loss: 3.405130386352539
training step: 56334, total_loss: 4.209990978240967
training step: 56335, total_loss: 4.45551872253418
training step: 56336, total_loss: 3.895033359527588
training step: 56337, total_loss: 3.3764400482177734
training step: 56338, total_loss: 4.0817718505859375
training step: 56339, total_loss: 3.162980556488037
training step: 56340, total_loss: 3.378082513809204
training step: 56341, total_loss: 3.871309518814087
training step: 56342, total_loss: 4.568646430969238
training step: 56343, total_loss: 2.9768104553222656
training step: 56344, total_loss: 2.681339979171753
training step: 56345, total_loss: 4.421058654785156
training step: 56346, total_loss: 3.358694553375244
training step: 56347, total_loss: 2.9926793575286865
training step: 56348, total_loss: 4.2946624755859375
training step: 56349, total_loss: 4.52964973449707
training step: 56350, total_loss: 2.441983699798584
training step: 56351, total_loss: 4.684855937957764
training step: 56352, total_loss: 3.959075689315796
training step: 56353, total_loss: 5.798627853393555
training step: 56354, total_loss: 3.3011868000030518
training step: 56355, total_loss: 4.857017517089844
training step: 56356, total_loss: 4.554436683654785
training step: 56357, total_loss: 5.26163387298584
training step: 56358, total_loss: 4.973570823669434
training step: 56359, total_loss: 4.564404010772705
training step: 56360, total_loss: 5.190122604370117
training step: 56361, total_loss: 5.108602523803711
training step: 56362, total_loss: 3.8015387058258057
training step: 56363, total_loss: 6.5508341789245605
training step: 56364, total_loss: 4.809945106506348
training step: 56365, total_loss: 4.067748069763184
training step: 56366, total_loss: 2.9467809200286865
training step: 56367, total_loss: 5.230983257293701
training step: 56368, total_loss: 2.3211779594421387
training step: 56369, total_loss: 4.508836269378662
training step: 56370, total_loss: 4.725135803222656
training step: 56371, total_loss: 3.6742513179779053
training step: 56372, total_loss: 3.280208110809326
training step: 56373, total_loss: 4.5196380615234375
training step: 56374, total_loss: 5.022613525390625
training step: 56375, total_loss: 5.49609375
training step: 56376, total_loss: 4.739436149597168
training step: 56377, total_loss: 5.747769355773926
training step: 56378, total_loss: 2.7264342308044434
training step: 56379, total_loss: 5.734539031982422
training step: 56380, total_loss: 3.8842992782592773
training step: 56381, total_loss: 3.5743441581726074
training step: 56382, total_loss: 4.941952228546143
training step: 56383, total_loss: 4.740010738372803
training step: 56384, total_loss: 6.005908966064453
training step: 56385, total_loss: 3.562809467315674
training step: 56386, total_loss: 4.467314720153809
training step: 56387, total_loss: 5.176898956298828
training step: 56388, total_loss: 3.0333895683288574
training step: 56389, total_loss: 3.393522262573242
training step: 56390, total_loss: 3.486401081085205
training step: 56391, total_loss: 4.437277793884277
training step: 56392, total_loss: 3.8398609161376953
training step: 56393, total_loss: 4.029697418212891
training step: 56394, total_loss: 4.370542526245117
training step: 56395, total_loss: 3.306128740310669
training step: 56396, total_loss: 0.9796877503395081
training step: 56397, total_loss: 2.6667208671569824
training step: 56398, total_loss: 2.6214897632598877
training step: 56399, total_loss: 5.391306400299072
training step: 56400, total_loss: 4.638599395751953
training step: 56401, total_loss: 4.852987289428711
training step: 56402, total_loss: 4.741607666015625
training step: 56403, total_loss: 4.367913246154785
training step: 56404, total_loss: 3.6423096656799316
training step: 56405, total_loss: 3.6979873180389404
training step: 56406, total_loss: 4.31008768081665
training step: 56407, total_loss: 4.3572235107421875
training step: 56408, total_loss: 4.076362609863281
training step: 56409, total_loss: 3.7571942806243896
training step: 56410, total_loss: 4.929919242858887
training step: 56411, total_loss: 4.430837631225586
training step: 56412, total_loss: 5.236082553863525
training step: 56413, total_loss: 5.02241325378418
training step: 56414, total_loss: 6.06768274307251
training step: 56415, total_loss: 4.611441612243652
training step: 56416, total_loss: 5.15421199798584
training step: 56417, total_loss: 5.443082809448242
training step: 56418, total_loss: 4.962291717529297
training step: 56419, total_loss: 5.817934513092041
training step: 56420, total_loss: 1.1608773469924927
training step: 56421, total_loss: 3.98176908493042
training step: 56422, total_loss: 3.9433419704437256
training step: 56423, total_loss: 4.86104679107666
training step: 56424, total_loss: 4.582704067230225
training step: 56425, total_loss: 4.70479154586792
training step: 56426, total_loss: 4.08073616027832
training step: 56427, total_loss: 4.578969478607178
training step: 56428, total_loss: 1.1164615154266357
training step: 56429, total_loss: 6.360198974609375
training step: 56430, total_loss: 3.3176310062408447
training step: 56431, total_loss: 5.060536861419678
training step: 56432, total_loss: 4.462313652038574
training step: 56433, total_loss: 5.275727272033691
training step: 56434, total_loss: 4.075850486755371
training step: 56435, total_loss: 1.5479421615600586
training step: 56436, total_loss: 4.8921403884887695
training step: 56437, total_loss: 4.829281806945801
training step: 56438, total_loss: 6.160874366760254
training step: 56439, total_loss: 3.97647762298584
training step: 56440, total_loss: 4.117108345031738
training step: 56441, total_loss: 3.9498941898345947
training step: 56442, total_loss: 4.760425090789795
training step: 56443, total_loss: 3.982959270477295
training step: 56444, total_loss: 3.7729434967041016
training step: 56445, total_loss: 4.520509243011475
training step: 56446, total_loss: 4.349212169647217
training step: 56447, total_loss: 4.604442119598389
training step: 56448, total_loss: 3.4271130561828613
training step: 56449, total_loss: 5.028800964355469
training step: 56450, total_loss: 3.5957515239715576
training step: 56451, total_loss: 4.121214389801025
training step: 56452, total_loss: 5.533530235290527
training step: 56453, total_loss: 3.505782127380371
training step: 56454, total_loss: 4.208503246307373
training step: 56455, total_loss: 6.173666954040527
training step: 56456, total_loss: 5.0368852615356445
training step: 56457, total_loss: 4.159267425537109
training step: 56458, total_loss: 4.484703063964844
training step: 56459, total_loss: 4.982941627502441
training step: 56460, total_loss: 2.7157135009765625
training step: 56461, total_loss: 4.775506973266602
training step: 56462, total_loss: 4.016258716583252
training step: 56463, total_loss: 3.499084949493408
training step: 56464, total_loss: 3.7137532234191895
training step: 56465, total_loss: 1.9869318008422852
training step: 56466, total_loss: 3.872586965560913
training step: 56467, total_loss: 4.924587249755859
training step: 56468, total_loss: 3.8149585723876953
training step: 56469, total_loss: 5.132782459259033
training step: 56470, total_loss: 2.5295987129211426
training step: 56471, total_loss: 4.9119157791137695
training step: 56472, total_loss: 2.6142773628234863
training step: 56473, total_loss: 3.335689067840576
training step: 56474, total_loss: 1.2465853691101074
training step: 56475, total_loss: 4.667888164520264
training step: 56476, total_loss: 2.891643524169922
training step: 56477, total_loss: 3.9918994903564453
training step: 56478, total_loss: 4.528220176696777
training step: 56479, total_loss: 3.5908803939819336
training step: 56480, total_loss: 4.939096927642822
training step: 56481, total_loss: 4.271805286407471
training step: 56482, total_loss: 4.43343448638916
training step: 56483, total_loss: 4.737936973571777
training step: 56484, total_loss: 4.5048112869262695
training step: 56485, total_loss: 7.061805725097656
training step: 56486, total_loss: 4.566515922546387
training step: 56487, total_loss: 4.054666519165039
training step: 56488, total_loss: 2.518104314804077
training step: 56489, total_loss: 4.253271102905273
training step: 56490, total_loss: 3.8524465560913086
training step: 56491, total_loss: 4.951709747314453
training step: 56492, total_loss: 5.3215179443359375
training step: 56493, total_loss: 4.579493522644043
training step: 56494, total_loss: 5.230774402618408
training step: 56495, total_loss: 4.451436996459961
training step: 56496, total_loss: 2.8963141441345215
training step: 56497, total_loss: 5.055253505706787
training step: 56498, total_loss: 4.994464874267578
training step: 56499, total_loss: 3.1475868225097656
training step: 56500, total_loss: 3.9075815677642822
training step: 56501, total_loss: 5.317810535430908
training step: 56502, total_loss: 4.924543857574463
training step: 56503, total_loss: 4.6316423416137695
training step: 56504, total_loss: 3.260018825531006
training step: 56505, total_loss: 5.355687141418457
training step: 56506, total_loss: 5.279656887054443
training step: 56507, total_loss: 4.853703022003174
training step: 56508, total_loss: 4.330689430236816
training step: 56509, total_loss: 5.5433807373046875
training step: 56510, total_loss: 2.326582193374634
training step: 56511, total_loss: 5.267956256866455
training step: 56512, total_loss: 5.447999477386475
training step: 56513, total_loss: 3.7113826274871826
training step: 56514, total_loss: 4.3061299324035645
training step: 56515, total_loss: 5.085026741027832
training step: 56516, total_loss: 3.9869580268859863
training step: 56517, total_loss: 4.028262138366699
training step: 56518, total_loss: 2.6011085510253906
training step: 56519, total_loss: 3.705472707748413
training step: 56520, total_loss: 4.940023422241211
training step: 56521, total_loss: 5.8616790771484375
training step: 56522, total_loss: 5.345973491668701
training step: 56523, total_loss: 4.980509281158447
training step: 56524, total_loss: 4.456850528717041
training step: 56525, total_loss: 4.056483268737793
training step: 56526, total_loss: 6.001002788543701
training step: 56527, total_loss: 3.8318557739257812
training step: 56528, total_loss: 4.868244171142578
training step: 56529, total_loss: 4.639261722564697
training step: 56530, total_loss: 5.030706405639648
training step: 56531, total_loss: 3.848548173904419
training step: 56532, total_loss: 4.432080268859863
training step: 56533, total_loss: 4.100246906280518
training step: 56534, total_loss: 4.937684059143066
training step: 56535, total_loss: 6.274317264556885
training step: 56536, total_loss: 3.4521970748901367
training step: 56537, total_loss: 5.24467134475708
training step: 56538, total_loss: 3.984804153442383
training step: 56539, total_loss: 3.762068271636963
training step: 56540, total_loss: 3.375946283340454
training step: 56541, total_loss: 4.793193817138672
training step: 56542, total_loss: 3.6803700923919678
training step: 56543, total_loss: 5.068568229675293
training step: 56544, total_loss: 3.304764747619629
training step: 56545, total_loss: 2.620575428009033
training step: 56546, total_loss: 0.9999303817749023
training step: 56547, total_loss: 5.546938896179199
training step: 56548, total_loss: 4.996935844421387
training step: 56549, total_loss: 3.1432230472564697
training step: 56550, total_loss: 5.513437747955322
training step: 56551, total_loss: 5.131140232086182
training step: 56552, total_loss: 4.261587619781494
training step: 56553, total_loss: 5.438018798828125
training step: 56554, total_loss: 5.5899834632873535
training step: 56555, total_loss: 3.7851462364196777
training step: 56556, total_loss: 5.11230993270874
training step: 56557, total_loss: 4.90894889831543
training step: 56558, total_loss: 4.100727558135986
training step: 56559, total_loss: 5.154618263244629
training step: 56560, total_loss: 4.323894500732422
training step: 56561, total_loss: 3.662187337875366
training step: 56562, total_loss: 4.117005825042725
training step: 56563, total_loss: 2.350219488143921
training step: 56564, total_loss: 5.761142253875732
training step: 56565, total_loss: 4.134737491607666
training step: 56566, total_loss: 3.606142520904541
training step: 56567, total_loss: 5.1892852783203125
training step: 56568, total_loss: 2.680359363555908
training step: 56569, total_loss: 4.469137191772461
training step: 56570, total_loss: 4.532051086425781
training step: 56571, total_loss: 3.8812801837921143
training step: 56572, total_loss: 3.4167861938476562
training step: 56573, total_loss: 3.9722707271575928
training step: 56574, total_loss: 4.6465020179748535
training step: 56575, total_loss: 4.206987380981445
training step: 56576, total_loss: 3.7190067768096924
training step: 56577, total_loss: 2.9273152351379395
training step: 56578, total_loss: 5.137008190155029
training step: 56579, total_loss: 3.920046806335449
training step: 56580, total_loss: 3.818129062652588
training step: 56581, total_loss: 5.522951126098633
training step: 56582, total_loss: 4.601149559020996
training step: 56583, total_loss: 4.8518171310424805
training step: 56584, total_loss: 3.4543464183807373
training step: 56585, total_loss: 4.522964954376221
training step: 56586, total_loss: 4.908092975616455
training step: 56587, total_loss: 5.135381698608398
training step: 56588, total_loss: 4.008810043334961
training step: 56589, total_loss: 4.264408111572266
training step: 56590, total_loss: 5.51535701751709
training step: 56591, total_loss: 6.123254299163818
training step: 56592, total_loss: 4.134124755859375
training step: 56593, total_loss: 4.499721527099609
training step: 56594, total_loss: 4.416738033294678
training step: 56595, total_loss: 4.181356430053711
training step: 56596, total_loss: 2.6724026203155518
training step: 56597, total_loss: 5.3259453773498535
training step: 56598, total_loss: 4.082281112670898
training step: 56599, total_loss: 4.682889938354492
training step: 56600, total_loss: 4.736816883087158
training step: 56601, total_loss: 3.680196523666382
training step: 56602, total_loss: 4.179680347442627
training step: 56603, total_loss: 2.893761157989502
training step: 56604, total_loss: 3.8438234329223633
training step: 56605, total_loss: 3.8469326496124268
training step: 56606, total_loss: 4.75554084777832
training step: 56607, total_loss: 4.712227821350098
training step: 56608, total_loss: 5.0030517578125
training step: 56609, total_loss: 3.801133155822754
training step: 56610, total_loss: 5.334017753601074
training step: 56611, total_loss: 5.021327972412109
training step: 56612, total_loss: 3.6103506088256836
training step: 56613, total_loss: 5.4513349533081055
training step: 56614, total_loss: 4.350110054016113
training step: 56615, total_loss: 3.5436758995056152
training step: 56616, total_loss: 7.03447151184082
training step: 56617, total_loss: 3.6095826625823975
training step: 56618, total_loss: 3.615337371826172
training step: 56619, total_loss: 4.962925434112549
training step: 56620, total_loss: 3.5917723178863525
training step: 56621, total_loss: 5.449678421020508
training step: 56622, total_loss: 2.8193678855895996
training step: 56623, total_loss: 4.067715167999268
training step: 56624, total_loss: 4.514560699462891
training step: 56625, total_loss: 4.682561874389648
training step: 56626, total_loss: 3.8382577896118164
training step: 56627, total_loss: 3.253011703491211
training step: 56628, total_loss: 4.494917869567871
training step: 56629, total_loss: 4.214957237243652
training step: 56630, total_loss: 4.073416709899902
training step: 56631, total_loss: 4.551521301269531
training step: 56632, total_loss: 3.1180968284606934
training step: 56633, total_loss: 2.5260672569274902
training step: 56634, total_loss: 5.394235610961914
training step: 56635, total_loss: 4.667444229125977
training step: 56636, total_loss: 4.041475296020508
training step: 56637, total_loss: 5.410280227661133
training step: 56638, total_loss: 4.527495861053467
training step: 56639, total_loss: 5.018019676208496
training step: 56640, total_loss: 3.659679889678955
training step: 56641, total_loss: 3.957136631011963
training step: 56642, total_loss: 5.78401517868042
training step: 56643, total_loss: 4.99423885345459
training step: 56644, total_loss: 4.5052924156188965
training step: 56645, total_loss: 4.616381645202637
training step: 56646, total_loss: 4.251710414886475
training step: 56647, total_loss: 4.8423614501953125
training step: 56648, total_loss: 4.161993503570557
training step: 56649, total_loss: 4.471719264984131
training step: 56650, total_loss: 3.920048952102661
training step: 56651, total_loss: 3.0052778720855713
training step: 56652, total_loss: 4.4127092361450195
training step: 56653, total_loss: 4.923606872558594
training step: 56654, total_loss: 3.470288038253784
training step: 56655, total_loss: 4.360161304473877
training step: 56656, total_loss: 3.413569688796997
training step: 56657, total_loss: 3.965831756591797
training step: 56658, total_loss: 2.3284873962402344
training step: 56659, total_loss: 2.9079079627990723
training step: 56660, total_loss: 4.415621757507324
training step: 56661, total_loss: 3.5191235542297363
training step: 56662, total_loss: 3.2742910385131836
training step: 56663, total_loss: 4.330415725708008
training step: 56664, total_loss: 3.753429651260376
training step: 56665, total_loss: 1.91355299949646
training step: 56666, total_loss: 4.331845760345459
training step: 56667, total_loss: 4.596154689788818
training step: 56668, total_loss: 3.191230297088623
training step: 56669, total_loss: 3.6473560333251953
training step: 56670, total_loss: 4.731133460998535
training step: 56671, total_loss: 4.620080947875977
training step: 56672, total_loss: 4.150363445281982
training step: 56673, total_loss: 5.141463279724121
training step: 56674, total_loss: 2.29882550239563
training step: 56675, total_loss: 3.880923271179199
training step: 56676, total_loss: 6.420004844665527
training step: 56677, total_loss: 6.330658912658691
training step: 56678, total_loss: 4.061533451080322
training step: 56679, total_loss: 5.395455360412598
training step: 56680, total_loss: 4.799025535583496
training step: 56681, total_loss: 3.85872745513916
training step: 56682, total_loss: 4.176151275634766
training step: 56683, total_loss: 5.361736297607422
training step: 56684, total_loss: 4.392162322998047
training step: 56685, total_loss: 4.087386608123779
training step: 56686, total_loss: 4.673722267150879
training step: 56687, total_loss: 5.462653160095215
training step: 56688, total_loss: 5.364295959472656
training step: 56689, total_loss: 4.115377902984619
training step: 56690, total_loss: 4.112428188323975
training step: 56691, total_loss: 4.204850196838379
training step: 56692, total_loss: 4.676733493804932
training step: 56693, total_loss: 4.42880916595459
training step: 56694, total_loss: 5.378615379333496
training step: 56695, total_loss: 4.043426513671875
training step: 56696, total_loss: 4.160309791564941
training step: 56697, total_loss: 3.211608409881592
training step: 56698, total_loss: 4.767367839813232
training step: 56699, total_loss: 3.970710515975952
training step: 56700, total_loss: 3.907818078994751
training step: 56701, total_loss: 5.034934043884277
training step: 56702, total_loss: 5.510231018066406
training step: 56703, total_loss: 5.008837699890137
training step: 56704, total_loss: 5.055524826049805
training step: 56705, total_loss: 4.669610023498535
training step: 56706, total_loss: 4.637904167175293
training step: 56707, total_loss: 4.399294853210449
training step: 56708, total_loss: 3.5833840370178223
training step: 56709, total_loss: 3.910236358642578
training step: 56710, total_loss: 3.4778635501861572
training step: 56711, total_loss: 2.5436086654663086
training step: 56712, total_loss: 4.096878528594971
training step: 56713, total_loss: 4.385879993438721
training step: 56714, total_loss: 7.583183765411377
training step: 56715, total_loss: 4.2235798835754395
training step: 56716, total_loss: 4.717483997344971
training step: 56717, total_loss: 5.572118759155273
training step: 56718, total_loss: 3.1801538467407227
training step: 56719, total_loss: 3.2615389823913574
training step: 56720, total_loss: 4.552828788757324
training step: 56721, total_loss: 5.122795104980469
training step: 56722, total_loss: 3.3155345916748047
training step: 56723, total_loss: 4.270871639251709
training step: 56724, total_loss: 5.15871524810791
training step: 56725, total_loss: 3.3933491706848145
training step: 56726, total_loss: 4.342859268188477
training step: 56727, total_loss: 4.017885684967041
training step: 56728, total_loss: 4.42559814453125
training step: 56729, total_loss: 4.625031471252441
training step: 56730, total_loss: 3.0733768939971924
training step: 56731, total_loss: 4.140689373016357
training step: 56732, total_loss: 3.8794164657592773
training step: 56733, total_loss: 2.918654441833496
training step: 56734, total_loss: 3.9089505672454834
training step: 56735, total_loss: 4.98691987991333
training step: 56736, total_loss: 5.746439456939697
training step: 56737, total_loss: 2.2947158813476562
training step: 56738, total_loss: 6.429083824157715
training step: 56739, total_loss: 2.763305187225342
training step: 56740, total_loss: 4.190884113311768
training step: 56741, total_loss: 3.1738734245300293
training step: 56742, total_loss: 5.119417667388916
training step: 56743, total_loss: 3.891096591949463
training step: 56744, total_loss: 4.246230125427246
training step: 56745, total_loss: 2.8889811038970947
training step: 56746, total_loss: 3.143819808959961
training step: 56747, total_loss: 3.8511669635772705
training step: 56748, total_loss: 3.9719600677490234
training step: 56749, total_loss: 5.421812057495117
training step: 56750, total_loss: 3.974435806274414
training step: 56751, total_loss: 3.0418219566345215
training step: 56752, total_loss: 5.154825210571289
training step: 56753, total_loss: 3.785126209259033
training step: 56754, total_loss: 4.823284149169922
training step: 56755, total_loss: 4.199688911437988
training step: 56756, total_loss: 4.5608439445495605
training step: 56757, total_loss: 4.292104721069336
training step: 56758, total_loss: 2.567714214324951
training step: 56759, total_loss: 3.0098695755004883
training step: 56760, total_loss: 5.231003284454346
training step: 56761, total_loss: 3.7491488456726074
training step: 56762, total_loss: 5.174831390380859
training step: 56763, total_loss: 4.561003684997559
training step: 56764, total_loss: 4.64794921875
training step: 56765, total_loss: 3.7746448516845703
training step: 56766, total_loss: 2.070176839828491
training step: 56767, total_loss: 1.2120518684387207
training step: 56768, total_loss: 3.2817554473876953
training step: 56769, total_loss: 4.028388977050781
training step: 56770, total_loss: 6.504657745361328
training step: 56771, total_loss: 4.401049613952637
training step: 56772, total_loss: 4.171533584594727
training step: 56773, total_loss: 4.404119968414307
training step: 56774, total_loss: 4.859545707702637
training step: 56775, total_loss: 6.237841606140137
training step: 56776, total_loss: 3.9533114433288574
training step: 56777, total_loss: 4.506592750549316
training step: 56778, total_loss: 5.24346923828125
training step: 56779, total_loss: 5.150794982910156
training step: 56780, total_loss: 6.002594470977783
training step: 56781, total_loss: 4.668810844421387
training step: 56782, total_loss: 5.121574878692627
training step: 56783, total_loss: 4.7113471031188965
training step: 56784, total_loss: 3.362074851989746
training step: 56785, total_loss: 4.513692378997803
training step: 56786, total_loss: 3.1387925148010254
training step: 56787, total_loss: 3.6395201683044434
training step: 56788, total_loss: 5.874153137207031
training step: 56789, total_loss: 4.100296974182129
training step: 56790, total_loss: 4.855053901672363
training step: 56791, total_loss: 4.615686416625977
training step: 56792, total_loss: 4.828080654144287
training step: 56793, total_loss: 2.8893985748291016
training step: 56794, total_loss: 3.9880762100219727
training step: 56795, total_loss: 4.7949748039245605
training step: 56796, total_loss: 4.707584381103516
training step: 56797, total_loss: 4.112198352813721
training step: 56798, total_loss: 4.464295387268066
training step: 56799, total_loss: 3.274569034576416
training step: 56800, total_loss: 3.938511371612549
training step: 56801, total_loss: 4.308755397796631
training step: 56802, total_loss: 5.119109630584717
training step: 56803, total_loss: 2.087505578994751
training step: 56804, total_loss: 4.924628257751465
training step: 56805, total_loss: 4.878089904785156
training step: 56806, total_loss: 4.908979892730713
training step: 56807, total_loss: 5.781455039978027
training step: 56808, total_loss: 3.6484646797180176
training step: 56809, total_loss: 5.156102180480957
training step: 56810, total_loss: 5.209102630615234
training step: 56811, total_loss: 5.363471031188965
training step: 56812, total_loss: 3.1092066764831543
training step: 56813, total_loss: 4.202027320861816
training step: 56814, total_loss: 6.233567237854004
training step: 56815, total_loss: 4.584816932678223
training step: 56816, total_loss: 5.697004795074463
training step: 56817, total_loss: 3.479887008666992
training step: 56818, total_loss: 4.1786322593688965
training step: 56819, total_loss: 3.885519027709961
training step: 56820, total_loss: 4.816293716430664
training step: 56821, total_loss: 5.569211959838867
training step: 56822, total_loss: 5.4296464920043945
training step: 56823, total_loss: 4.896367073059082
training step: 56824, total_loss: 3.5086450576782227
training step: 56825, total_loss: 4.225144386291504
training step: 56826, total_loss: 6.550358772277832
training step: 56827, total_loss: 2.730501651763916
training step: 56828, total_loss: 5.073168754577637
training step: 56829, total_loss: 4.414046287536621
training step: 56830, total_loss: 1.0299370288848877
training step: 56831, total_loss: 2.923675537109375
training step: 56832, total_loss: 4.8864850997924805
training step: 56833, total_loss: 4.94886589050293
training step: 56834, total_loss: 6.049801826477051
training step: 56835, total_loss: 4.33376407623291
training step: 56836, total_loss: 4.398216724395752
training step: 56837, total_loss: 5.367179870605469
training step: 56838, total_loss: 2.2656850814819336
training step: 56839, total_loss: 4.6378374099731445
training step: 56840, total_loss: 4.53249979019165
training step: 56841, total_loss: 3.261550188064575
training step: 56842, total_loss: 3.1963958740234375
training step: 56843, total_loss: 5.313408851623535
training step: 56844, total_loss: 2.7522401809692383
training step: 56845, total_loss: 4.594034194946289
training step: 56846, total_loss: 4.862648963928223
training step: 56847, total_loss: 2.9698715209960938
training step: 56848, total_loss: 3.870065212249756
training step: 56849, total_loss: 4.095633506774902
training step: 56850, total_loss: 1.4745748043060303
training step: 56851, total_loss: 5.770279884338379
training step: 56852, total_loss: 3.0920214653015137
training step: 56853, total_loss: 3.854313611984253
training step: 56854, total_loss: 6.013113975524902
training step: 56855, total_loss: 2.8953399658203125
training step: 56856, total_loss: 4.15341854095459
training step: 56857, total_loss: 3.9380202293395996
training step: 56858, total_loss: 3.7038004398345947
training step: 56859, total_loss: 3.599848508834839
training step: 56860, total_loss: 6.286578178405762
training step: 56861, total_loss: 3.375040292739868
training step: 56862, total_loss: 5.323606491088867
training step: 56863, total_loss: 3.785414934158325
training step: 56864, total_loss: 3.5803310871124268
training step: 56865, total_loss: 4.749269485473633
training step: 56866, total_loss: 4.874720573425293
training step: 56867, total_loss: 4.326229095458984
training step: 56868, total_loss: 2.9898929595947266
training step: 56869, total_loss: 1.032702088356018
training step: 56870, total_loss: 5.053694725036621
training step: 56871, total_loss: 4.1400275230407715
training step: 56872, total_loss: 5.686376094818115INFO:tensorflow:Writing predictions to: residual_output/predictions_57000.json
INFO:tensorflow:Writing nbest to: residual_output/nbest_predictions_57000.json

training step: 56873, total_loss: 3.9675021171569824
training step: 56874, total_loss: 1.4235527515411377
training step: 56875, total_loss: 5.214964866638184
training step: 56876, total_loss: 3.009375810623169
training step: 56877, total_loss: 5.137487411499023
training step: 56878, total_loss: 3.1557624340057373
training step: 56879, total_loss: 4.443199157714844
training step: 56880, total_loss: 4.215139389038086
training step: 56881, total_loss: 3.983193874359131
training step: 56882, total_loss: 3.390345573425293
training step: 56883, total_loss: 4.097194671630859
training step: 56884, total_loss: 4.3055644035339355
training step: 56885, total_loss: 0.7414658069610596
training step: 56886, total_loss: 4.580622673034668
training step: 56887, total_loss: 4.589077949523926
training step: 56888, total_loss: 4.6152849197387695
training step: 56889, total_loss: 3.3125617504119873
training step: 56890, total_loss: 4.5722455978393555
training step: 56891, total_loss: 5.533243179321289
training step: 56892, total_loss: 3.766246795654297
training step: 56893, total_loss: 4.835430145263672
training step: 56894, total_loss: 5.648763656616211
training step: 56895, total_loss: 4.627755165100098
training step: 56896, total_loss: 2.879408836364746
training step: 56897, total_loss: 4.109086513519287
training step: 56898, total_loss: 2.6939358711242676
training step: 56899, total_loss: 5.3675079345703125
training step: 56900, total_loss: 5.233356952667236
training step: 56901, total_loss: 4.764792442321777
training step: 56902, total_loss: 5.095859527587891
training step: 56903, total_loss: 2.954749345779419
training step: 56904, total_loss: 4.660834789276123
training step: 56905, total_loss: 4.372213363647461
training step: 56906, total_loss: 5.112522602081299
training step: 56907, total_loss: 5.754323959350586
training step: 56908, total_loss: 5.458096504211426
training step: 56909, total_loss: 3.4134116172790527
training step: 56910, total_loss: 5.098962306976318
training step: 56911, total_loss: 3.9844319820404053
training step: 56912, total_loss: 3.9277524948120117
training step: 56913, total_loss: 4.802238941192627
training step: 56914, total_loss: 3.4459216594696045
training step: 56915, total_loss: 6.785173416137695
training step: 56916, total_loss: 3.2419862747192383
training step: 56917, total_loss: 3.2691333293914795
training step: 56918, total_loss: 2.2695186138153076
training step: 56919, total_loss: 4.643341064453125
training step: 56920, total_loss: 3.905580997467041
training step: 56921, total_loss: 3.736496925354004
training step: 56922, total_loss: 4.829270362854004
training step: 56923, total_loss: 3.8918890953063965
training step: 56924, total_loss: 3.5181024074554443
training step: 56925, total_loss: 4.645082473754883
training step: 56926, total_loss: 3.4733424186706543
training step: 56927, total_loss: 6.850307464599609
training step: 56928, total_loss: 3.7326178550720215
training step: 56929, total_loss: 3.454677104949951
training step: 56930, total_loss: 5.147625923156738
training step: 56931, total_loss: 5.655146598815918
training step: 56932, total_loss: 3.8529343605041504
training step: 56933, total_loss: 4.72026252746582
training step: 56934, total_loss: 4.414495468139648
training step: 56935, total_loss: 4.678513050079346
training step: 56936, total_loss: 3.7205069065093994
training step: 56937, total_loss: 0.9148867130279541
training step: 56938, total_loss: 4.985391616821289
training step: 56939, total_loss: 4.377717971801758
training step: 56940, total_loss: 3.9260072708129883
training step: 56941, total_loss: 4.952170372009277
training step: 56942, total_loss: 5.108587265014648
training step: 56943, total_loss: 3.5468192100524902
training step: 56944, total_loss: 3.9580812454223633
training step: 56945, total_loss: 3.292647361755371
training step: 56946, total_loss: 3.428605556488037
training step: 56947, total_loss: 4.70977783203125
training step: 56948, total_loss: 4.29149866104126
training step: 56949, total_loss: 4.170063495635986
training step: 56950, total_loss: 3.0622141361236572
training step: 56951, total_loss: 5.8169732093811035
training step: 56952, total_loss: 5.33461332321167
training step: 56953, total_loss: 4.025433540344238
training step: 56954, total_loss: 4.405338764190674
training step: 56955, total_loss: 4.82807731628418
training step: 56956, total_loss: 4.132640838623047
training step: 56957, total_loss: 3.415956974029541
training step: 56958, total_loss: 2.8592257499694824
training step: 56959, total_loss: 4.829297065734863
training step: 56960, total_loss: 7.520493984222412
training step: 56961, total_loss: 4.803709030151367
training step: 56962, total_loss: 2.931058883666992
training step: 56963, total_loss: 5.785046577453613
training step: 56964, total_loss: 4.058652877807617
training step: 56965, total_loss: 3.8797457218170166
training step: 56966, total_loss: 4.773226737976074
training step: 56967, total_loss: 3.4894700050354004
training step: 56968, total_loss: 2.927870988845825
training step: 56969, total_loss: 5.4006781578063965
training step: 56970, total_loss: 4.406468868255615
training step: 56971, total_loss: 4.129835605621338
training step: 56972, total_loss: 5.258260726928711
training step: 56973, total_loss: 3.8084402084350586
training step: 56974, total_loss: 4.129425048828125
training step: 56975, total_loss: 4.027492523193359
training step: 56976, total_loss: 4.344381332397461
training step: 56977, total_loss: 3.314051628112793
training step: 56978, total_loss: 3.156522750854492
training step: 56979, total_loss: 5.375148773193359
training step: 56980, total_loss: 3.5199553966522217
training step: 56981, total_loss: 4.355353355407715
training step: 56982, total_loss: 3.9870433807373047
training step: 56983, total_loss: 3.758356809616089
training step: 56984, total_loss: 3.54054856300354
training step: 56985, total_loss: 3.9604787826538086
training step: 56986, total_loss: 4.278923034667969
training step: 56987, total_loss: 3.0702075958251953
training step: 56988, total_loss: 3.145493268966675
training step: 56989, total_loss: 4.088088035583496
training step: 56990, total_loss: 2.6948914527893066
training step: 56991, total_loss: 5.169358730316162
training step: 56992, total_loss: 3.6725854873657227
training step: 56993, total_loss: 5.413803577423096
training step: 56994, total_loss: 2.5549755096435547
training step: 56995, total_loss: 3.4652962684631348
training step: 56996, total_loss: 3.2792716026306152
training step: 56997, total_loss: 4.245598793029785
training step: 56998, total_loss: 3.7307019233703613
training step: 56999, total_loss: 4.850562572479248
training step: 57000, total_loss: 5.239884376525879
epoch finished! shuffle=False
evaluation: 57000, total_loss: 2.320443868637085, f1: 23.595075581589935, followup: 18.378213905370455, yesno: 1.6126578426897915, heq: 23.109691160809373, dheq: 0.6

Model saved in path residual_output//model_57000.ckpt
training step: 57001, total_loss: 5.456150054931641
training step: 57002, total_loss: 3.871354818344116
training step: 57003, total_loss: 5.086117267608643
training step: 57004, total_loss: 5.282251358032227
training step: 57005, total_loss: 4.993283271789551
training step: 57006, total_loss: 5.307256698608398
training step: 57007, total_loss: 4.737916946411133
training step: 57008, total_loss: 3.1201887130737305
training step: 57009, total_loss: 4.11139440536499
training step: 57010, total_loss: 3.803718328475952
training step: 57011, total_loss: 4.737794876098633
training step: 57012, total_loss: 4.256951332092285
training step: 57013, total_loss: 4.748219966888428
training step: 57014, total_loss: 4.056222438812256
training step: 57015, total_loss: 3.578763484954834
training step: 57016, total_loss: 5.356664657592773
training step: 57017, total_loss: 4.294856071472168
training step: 57018, total_loss: 3.421182632446289
training step: 57019, total_loss: 4.720912933349609
training step: 57020, total_loss: 5.043910503387451
training step: 57021, total_loss: 3.1812119483947754
training step: 57022, total_loss: 5.72437858581543
training step: 57023, total_loss: 3.5568532943725586
training step: 57024, total_loss: 4.116250514984131
training step: 57025, total_loss: 4.647372245788574
training step: 57026, total_loss: 4.464215278625488
training step: 57027, total_loss: 5.146598815917969
training step: 57028, total_loss: 3.8168835639953613
training step: 57029, total_loss: 5.704913139343262
training step: 57030, total_loss: 5.090127944946289
training step: 57031, total_loss: 3.242506504058838
training step: 57032, total_loss: 2.4011354446411133
training step: 57033, total_loss: 4.399771213531494
training step: 57034, total_loss: 5.0602874755859375
training step: 57035, total_loss: 4.305295944213867
training step: 57036, total_loss: 3.835462808609009
training step: 57037, total_loss: 3.1475892066955566
training step: 57038, total_loss: 1.198869228363037
training step: 57039, total_loss: 5.001173973083496
training step: 57040, total_loss: 2.8055272102355957
training step: 57041, total_loss: 4.203894138336182
training step: 57042, total_loss: 4.653210163116455
training step: 57043, total_loss: 4.924967288970947
training step: 57044, total_loss: 4.971274375915527
training step: 57045, total_loss: 3.4530832767486572
training step: 57046, total_loss: 5.927698135375977
training step: 57047, total_loss: 3.91921067237854
training step: 57048, total_loss: 4.782797813415527
training step: 57049, total_loss: 4.391209602355957
training step: 57050, total_loss: 4.490300178527832
training step: 57051, total_loss: 3.8388478755950928
training step: 57052, total_loss: 3.8794655799865723
training step: 57053, total_loss: 4.245495319366455
training step: 57054, total_loss: 4.701108932495117
training step: 57055, total_loss: 4.092639923095703
training step: 57056, total_loss: 2.349719762802124
training step: 57057, total_loss: 4.861855506896973
training step: 57058, total_loss: 2.7664291858673096
training step: 57059, total_loss: 4.666407108306885
training step: 57060, total_loss: 3.8496804237365723
training step: 57061, total_loss: 4.817265033721924
training step: 57062, total_loss: 2.986785888671875
training step: 57063, total_loss: 4.613290786743164
training step: 57064, total_loss: 3.7725658416748047
training step: 57065, total_loss: 3.6432135105133057
training step: 57066, total_loss: 4.430196285247803
training step: 57067, total_loss: 6.041439056396484
training step: 57068, total_loss: 2.939720630645752
training step: 57069, total_loss: 0.9104911088943481
training step: 57070, total_loss: 3.8568949699401855
training step: 57071, total_loss: 1.0501618385314941
training step: 57072, total_loss: 4.470606803894043
training step: 57073, total_loss: 4.979674339294434
training step: 57074, total_loss: 5.804003715515137
training step: 57075, total_loss: 3.049575090408325
training step: 57076, total_loss: 3.5627353191375732
training step: 57077, total_loss: 4.052342414855957
training step: 57078, total_loss: 3.346331834793091
training step: 57079, total_loss: 5.391119003295898
training step: 57080, total_loss: 5.015638828277588
training step: 57081, total_loss: 4.594881057739258
training step: 57082, total_loss: 2.796069383621216
training step: 57083, total_loss: 3.261111259460449
training step: 57084, total_loss: 4.7662506103515625
training step: 57085, total_loss: 2.0657176971435547
training step: 57086, total_loss: 4.526420593261719
training step: 57087, total_loss: 1.0178182125091553
training step: 57088, total_loss: 6.697171211242676
training step: 57089, total_loss: 6.203396797180176
training step: 57090, total_loss: 3.33862566947937
training step: 57091, total_loss: 4.920426845550537
training step: 57092, total_loss: 3.514350414276123
training step: 57093, total_loss: 3.351768970489502
training step: 57094, total_loss: 3.31658673286438
training step: 57095, total_loss: 4.225569248199463
training step: 57096, total_loss: 5.179599761962891
training step: 57097, total_loss: 2.1429576873779297
training step: 57098, total_loss: 2.1210877895355225
training step: 57099, total_loss: 2.2529234886169434
training step: 57100, total_loss: 3.5172204971313477
training step: 57101, total_loss: 5.217188358306885
training step: 57102, total_loss: 5.36313533782959
training step: 57103, total_loss: 3.8902411460876465
training step: 57104, total_loss: 3.083609104156494
training step: 57105, total_loss: 4.408832550048828
training step: 57106, total_loss: 5.4799675941467285
training step: 57107, total_loss: 4.342914581298828
training step: 57108, total_loss: 4.854389190673828
training step: 57109, total_loss: 4.031929016113281
training step: 57110, total_loss: 4.240103244781494
training step: 57111, total_loss: 4.026350975036621
training step: 57112, total_loss: 6.637057304382324
training step: 57113, total_loss: 3.844200611114502
training step: 57114, total_loss: 3.9766972064971924
training step: 57115, total_loss: 3.3332231044769287
training step: 57116, total_loss: 3.5012247562408447
training step: 57117, total_loss: 5.884488105773926
training step: 57118, total_loss: 4.983316421508789
training step: 57119, total_loss: 3.8710711002349854
training step: 57120, total_loss: 4.294131278991699
training step: 57121, total_loss: 4.027173042297363
training step: 57122, total_loss: 4.396707534790039
training step: 57123, total_loss: 5.411930084228516
training step: 57124, total_loss: 4.90907621383667
training step: 57125, total_loss: 4.310125350952148
training step: 57126, total_loss: 4.062067985534668
training step: 57127, total_loss: 3.1750521659851074
training step: 57128, total_loss: 3.5477898120880127
training step: 57129, total_loss: 5.041591644287109
training step: 57130, total_loss: 4.206622123718262
training step: 57131, total_loss: 4.32755708694458
training step: 57132, total_loss: 4.911072731018066
training step: 57133, total_loss: 4.866005897521973
training step: 57134, total_loss: 4.963766098022461
training step: 57135, total_loss: 3.546814441680908
training step: 57136, total_loss: 4.328295707702637
training step: 57137, total_loss: 5.324486255645752
training step: 57138, total_loss: 3.896831512451172
training step: 57139, total_loss: 2.3673198223114014
training step: 57140, total_loss: 4.853545188903809
training step: 57141, total_loss: 4.532937526702881
training step: 57142, total_loss: 3.811309337615967
training step: 57143, total_loss: 4.534055709838867
training step: 57144, total_loss: 4.1478400230407715
training step: 57145, total_loss: 4.211764335632324
training step: 57146, total_loss: 4.073783874511719
training step: 57147, total_loss: 4.886112213134766
training step: 57148, total_loss: 4.393280029296875
training step: 57149, total_loss: 3.77945876121521
training step: 57150, total_loss: 4.593319892883301
training step: 57151, total_loss: 6.502348899841309
training step: 57152, total_loss: 3.568277597427368
training step: 57153, total_loss: 3.878882884979248
training step: 57154, total_loss: 5.933977127075195
training step: 57155, total_loss: 5.065202713012695
training step: 57156, total_loss: 2.992537498474121
training step: 57157, total_loss: 4.328118801116943
training step: 57158, total_loss: 4.121840476989746
training step: 57159, total_loss: 3.5447564125061035
training step: 57160, total_loss: 2.06396746635437
training step: 57161, total_loss: 1.30708909034729
training step: 57162, total_loss: 5.121898651123047
training step: 57163, total_loss: 2.1228456497192383
training step: 57164, total_loss: 2.7696309089660645
training step: 57165, total_loss: 5.079395294189453
training step: 57166, total_loss: 4.243252754211426
training step: 57167, total_loss: 4.311892032623291
training step: 57168, total_loss: 5.086719512939453
training step: 57169, total_loss: 4.8006978034973145
training step: 57170, total_loss: 4.848061561584473
training step: 57171, total_loss: 2.98934268951416
training step: 57172, total_loss: 5.860281944274902
training step: 57173, total_loss: 3.893876552581787
training step: 57174, total_loss: 3.348740339279175
training step: 57175, total_loss: 4.3954877853393555
training step: 57176, total_loss: 4.176374435424805
training step: 57177, total_loss: 4.3353424072265625
training step: 57178, total_loss: 4.691039562225342
training step: 57179, total_loss: 5.813385009765625
training step: 57180, total_loss: 4.258938312530518
training step: 57181, total_loss: 2.9344568252563477
training step: 57182, total_loss: 4.480425834655762
training step: 57183, total_loss: 4.61674690246582
training step: 57184, total_loss: 3.5201988220214844
training step: 57185, total_loss: 3.466320037841797
training step: 57186, total_loss: 5.507126808166504
training step: 57187, total_loss: 2.776322364807129
training step: 57188, total_loss: 5.104325294494629
training step: 57189, total_loss: 6.012470722198486
training step: 57190, total_loss: 4.103690147399902
training step: 57191, total_loss: 4.661285400390625
training step: 57192, total_loss: 5.357541084289551
training step: 57193, total_loss: 3.623913049697876
training step: 57194, total_loss: 3.2812886238098145
training step: 57195, total_loss: 3.260132312774658
training step: 57196, total_loss: 4.150566577911377
training step: 57197, total_loss: 4.377164363861084
training step: 57198, total_loss: 4.53558874130249
training step: 57199, total_loss: 6.016995429992676
training step: 57200, total_loss: 4.124963760375977
training step: 57201, total_loss: 3.9965744018554688
training step: 57202, total_loss: 4.3986639976501465
training step: 57203, total_loss: 3.4851274490356445
training step: 57204, total_loss: 5.026313781738281
training step: 57205, total_loss: 3.2557759284973145
training step: 57206, total_loss: 4.768611431121826
training step: 57207, total_loss: 3.6709680557250977
training step: 57208, total_loss: 5.4406304359436035
training step: 57209, total_loss: 4.0357513427734375
training step: 57210, total_loss: 3.4627389907836914
training step: 57211, total_loss: 2.3195080757141113
training step: 57212, total_loss: 2.906738758087158
training step: 57213, total_loss: 3.8001151084899902
training step: 57214, total_loss: 5.296199798583984
training step: 57215, total_loss: 4.792423725128174
training step: 57216, total_loss: 3.477182388305664
training step: 57217, total_loss: 3.711981773376465
training step: 57218, total_loss: 4.3901848793029785
training step: 57219, total_loss: 4.372926712036133
training step: 57220, total_loss: 4.134587287902832
training step: 57221, total_loss: 3.071017026901245
training step: 57222, total_loss: 4.501832962036133
training step: 57223, total_loss: 5.009130477905273
training step: 57224, total_loss: 2.224123477935791
training step: 57225, total_loss: 5.571978569030762
training step: 57226, total_loss: 4.9420342445373535
training step: 57227, total_loss: 4.86421012878418
training step: 57228, total_loss: 4.068637847900391
training step: 57229, total_loss: 5.492875099182129
training step: 57230, total_loss: 3.3328452110290527
training step: 57231, total_loss: 3.9567909240722656
training step: 57232, total_loss: 3.8821864128112793
training step: 57233, total_loss: 4.355679512023926
training step: 57234, total_loss: 3.2549872398376465
training step: 57235, total_loss: 4.969651222229004
training step: 57236, total_loss: 2.7571680545806885
training step: 57237, total_loss: 5.837296962738037
training step: 57238, total_loss: 4.412975311279297
training step: 57239, total_loss: 5.206797122955322
training step: 57240, total_loss: 4.481467247009277
training step: 57241, total_loss: 1.2008776664733887
training step: 57242, total_loss: 3.8285326957702637
training step: 57243, total_loss: 3.5019946098327637
training step: 57244, total_loss: 4.294404029846191
training step: 57245, total_loss: 3.931129217147827
training step: 57246, total_loss: 4.630222320556641
training step: 57247, total_loss: 5.853090286254883
training step: 57248, total_loss: 4.840580940246582
training step: 57249, total_loss: 4.893054962158203
training step: 57250, total_loss: 3.584198474884033
training step: 57251, total_loss: 4.924147605895996
training step: 57252, total_loss: 4.403045177459717
training step: 57253, total_loss: 3.2282493114471436
training step: 57254, total_loss: 3.8746073246002197
training step: 57255, total_loss: 5.060942649841309
training step: 57256, total_loss: 5.360509395599365
training step: 57257, total_loss: 2.1862595081329346
training step: 57258, total_loss: 2.1659884452819824
training step: 57259, total_loss: 5.8925580978393555
training step: 57260, total_loss: 3.7433347702026367
training step: 57261, total_loss: 5.004247188568115
training step: 57262, total_loss: 3.6194915771484375
training step: 57263, total_loss: 4.428061485290527
training step: 57264, total_loss: 3.713895320892334
training step: 57265, total_loss: 5.082972526550293
training step: 57266, total_loss: 3.3606433868408203
training step: 57267, total_loss: 4.325002193450928
training step: 57268, total_loss: 5.440835952758789
training step: 57269, total_loss: 3.704634666442871
training step: 57270, total_loss: 3.6322078704833984
training step: 57271, total_loss: 4.302585601806641
training step: 57272, total_loss: 4.979086875915527
training step: 57273, total_loss: 4.123956203460693
training step: 57274, total_loss: 4.926326751708984
training step: 57275, total_loss: 3.6648945808410645
training step: 57276, total_loss: 5.189071178436279
training step: 57277, total_loss: 3.8900609016418457
training step: 57278, total_loss: 2.381351947784424
training step: 57279, total_loss: 4.2272491455078125
training step: 57280, total_loss: 4.3064374923706055
training step: 57281, total_loss: 4.9621381759643555
training step: 57282, total_loss: 3.5480432510375977
training step: 57283, total_loss: 3.543445587158203
training step: 57284, total_loss: 4.890695095062256
training step: 57285, total_loss: 2.8508806228637695
training step: 57286, total_loss: 4.558197498321533
training step: 57287, total_loss: 4.886832237243652
training step: 57288, total_loss: 6.885038375854492
training step: 57289, total_loss: 2.6991076469421387
training step: 57290, total_loss: 3.152318000793457
training step: 57291, total_loss: 5.021318435668945
training step: 57292, total_loss: 3.9023025035858154
training step: 57293, total_loss: 5.244009017944336
training step: 57294, total_loss: 4.436661720275879
training step: 57295, total_loss: 4.32975959777832
training step: 57296, total_loss: 4.795302391052246
training step: 57297, total_loss: 4.792679309844971
training step: 57298, total_loss: 4.5603179931640625
training step: 57299, total_loss: 4.504683494567871
training step: 57300, total_loss: 3.646543502807617
training step: 57301, total_loss: 3.109402894973755
training step: 57302, total_loss: 3.595798969268799
training step: 57303, total_loss: 5.590664863586426
training step: 57304, total_loss: 4.101029872894287
training step: 57305, total_loss: 3.843848943710327
training step: 57306, total_loss: 4.888795852661133
training step: 57307, total_loss: 5.434107303619385
training step: 57308, total_loss: 1.4144705533981323
training step: 57309, total_loss: 5.708572864532471
training step: 57310, total_loss: 4.436790466308594
training step: 57311, total_loss: 4.40733528137207
training step: 57312, total_loss: 4.272184371948242
training step: 57313, total_loss: 5.521279335021973
training step: 57314, total_loss: 5.926324367523193
training step: 57315, total_loss: 4.9099202156066895
training step: 57316, total_loss: 3.491575241088867
training step: 57317, total_loss: 4.848657131195068
training step: 57318, total_loss: 5.357375144958496
training step: 57319, total_loss: 4.593193054199219
training step: 57320, total_loss: 4.930975914001465
training step: 57321, total_loss: 2.4568123817443848
training step: 57322, total_loss: 4.294671535491943
training step: 57323, total_loss: 4.076471328735352
training step: 57324, total_loss: 2.853858470916748
training step: 57325, total_loss: 4.949461460113525
training step: 57326, total_loss: 1.2492755651474
training step: 57327, total_loss: 4.5911545753479
training step: 57328, total_loss: 5.073360443115234
training step: 57329, total_loss: 4.328050136566162
training step: 57330, total_loss: 4.529720783233643
training step: 57331, total_loss: 2.6426291465759277
training step: 57332, total_loss: 3.910801410675049
training step: 57333, total_loss: 5.207230091094971
training step: 57334, total_loss: 4.311763286590576
training step: 57335, total_loss: 4.603354454040527
training step: 57336, total_loss: 2.430634021759033
training step: 57337, total_loss: 6.4713921546936035
training step: 57338, total_loss: 5.789919376373291
training step: 57339, total_loss: 5.908318996429443
training step: 57340, total_loss: 0.9336704015731812
training step: 57341, total_loss: 5.352296829223633
training step: 57342, total_loss: 3.1749820709228516
training step: 57343, total_loss: 4.518311500549316
training step: 57344, total_loss: 3.551548957824707
training step: 57345, total_loss: 5.03328275680542
training step: 57346, total_loss: 1.5250635147094727
training step: 57347, total_loss: 3.4877443313598633
training step: 57348, total_loss: 5.304876804351807
training step: 57349, total_loss: 5.033496856689453
training step: 57350, total_loss: 4.023220062255859
training step: 57351, total_loss: 3.1502442359924316
training step: 57352, total_loss: 3.9094340801239014
training step: 57353, total_loss: 5.0403900146484375
training step: 57354, total_loss: 4.774714946746826
training step: 57355, total_loss: 4.599274635314941
training step: 57356, total_loss: 5.2669677734375
training step: 57357, total_loss: 4.286745071411133
training step: 57358, total_loss: 4.7436089515686035
training step: 57359, total_loss: 4.833935737609863
training step: 57360, total_loss: 1.543583631515503
training step: 57361, total_loss: 4.476648330688477
training step: 57362, total_loss: 3.4891982078552246
training step: 57363, total_loss: 4.607321262359619
training step: 57364, total_loss: 5.126156330108643
training step: 57365, total_loss: 3.446242094039917
training step: 57366, total_loss: 2.360499620437622
training step: 57367, total_loss: 3.6103668212890625
training step: 57368, total_loss: 3.0256104469299316
training step: 57369, total_loss: 5.342712879180908
training step: 57370, total_loss: 2.648555278778076
training step: 57371, total_loss: 3.9092297554016113
training step: 57372, total_loss: 3.839761257171631
training step: 57373, total_loss: 4.228113174438477
training step: 57374, total_loss: 2.584970712661743
training step: 57375, total_loss: 4.121842861175537
training step: 57376, total_loss: 5.702275276184082
training step: 57377, total_loss: 3.556612253189087
training step: 57378, total_loss: 3.762112855911255
training step: 57379, total_loss: 3.657205104827881
training step: 57380, total_loss: 2.882551670074463
training step: 57381, total_loss: 5.673182964324951
training step: 57382, total_loss: 3.607171058654785
training step: 57383, total_loss: 5.696503162384033
training step: 57384, total_loss: 3.5189123153686523
training step: 57385, total_loss: 3.792555332183838
training step: 57386, total_loss: 3.2326507568359375
training step: 57387, total_loss: 4.569288730621338
training step: 57388, total_loss: 5.285034656524658
training step: 57389, total_loss: 4.376503944396973
training step: 57390, total_loss: 2.9198031425476074
training step: 57391, total_loss: 4.667134761810303
training step: 57392, total_loss: 5.073627948760986
training step: 57393, total_loss: 3.6878974437713623
training step: 57394, total_loss: 4.455974578857422
training step: 57395, total_loss: 2.4244117736816406
training step: 57396, total_loss: 4.331564426422119
training step: 57397, total_loss: 3.809000253677368
training step: 57398, total_loss: 4.439319610595703
training step: 57399, total_loss: 4.113351821899414
training step: 57400, total_loss: 2.071526050567627
training step: 57401, total_loss: 3.2812914848327637
training step: 57402, total_loss: 3.6271142959594727
training step: 57403, total_loss: 3.651776075363159
training step: 57404, total_loss: 5.573883056640625
training step: 57405, total_loss: 3.594296455383301
training step: 57406, total_loss: 2.922652244567871
training step: 57407, total_loss: 1.0473148822784424
training step: 57408, total_loss: 4.24869441986084
training step: 57409, total_loss: 4.044933319091797
training step: 57410, total_loss: 4.032600402832031
training step: 57411, total_loss: 4.6286516189575195
training step: 57412, total_loss: 3.8923768997192383
training step: 57413, total_loss: 4.046245574951172
training step: 57414, total_loss: 3.0749473571777344
training step: 57415, total_loss: 3.8474831581115723
training step: 57416, total_loss: 3.441894054412842
training step: 57417, total_loss: 5.768448829650879
training step: 57418, total_loss: 4.4949140548706055
training step: 57419, total_loss: 3.988114833831787
training step: 57420, total_loss: 4.310769081115723
training step: 57421, total_loss: 3.903108596801758
training step: 57422, total_loss: 4.508882522583008
training step: 57423, total_loss: 3.341491222381592
training step: 57424, total_loss: 4.954570770263672
training step: 57425, total_loss: 4.522961139678955
training step: 57426, total_loss: 4.690741062164307
training step: 57427, total_loss: 4.525672912597656
training step: 57428, total_loss: 4.152474403381348
training step: 57429, total_loss: 4.09670352935791
training step: 57430, total_loss: 4.1215925216674805
training step: 57431, total_loss: 4.488180160522461
training step: 57432, total_loss: 3.5234663486480713
training step: 57433, total_loss: 3.7811524868011475
training step: 57434, total_loss: 4.313906669616699
training step: 57435, total_loss: 4.576281547546387
training step: 57436, total_loss: 4.527773857116699
training step: 57437, total_loss: 4.186270713806152
training step: 57438, total_loss: 4.020148277282715
training step: 57439, total_loss: 4.488115310668945
training step: 57440, total_loss: 3.3765158653259277
training step: 57441, total_loss: 4.317666053771973
training step: 57442, total_loss: 4.138500213623047
training step: 57443, total_loss: 5.07131290435791
training step: 57444, total_loss: 0.8673737049102783
training step: 57445, total_loss: 5.272127628326416
training step: 57446, total_loss: 4.018500804901123
training step: 57447, total_loss: 3.4095044136047363
training step: 57448, total_loss: 4.643202781677246
training step: 57449, total_loss: 4.247629642486572
training step: 57450, total_loss: 3.4323644638061523
training step: 57451, total_loss: 4.197345733642578
training step: 57452, total_loss: 3.50392746925354
training step: 57453, total_loss: 2.313786506652832
training step: 57454, total_loss: 5.373567581176758
training step: 57455, total_loss: 4.98137092590332
training step: 57456, total_loss: 5.122367858886719
training step: 57457, total_loss: 3.6934473514556885
training step: 57458, total_loss: 5.704654216766357
training step: 57459, total_loss: 6.082226753234863
training step: 57460, total_loss: 5.222782135009766
training step: 57461, total_loss: 2.637489080429077
training step: 57462, total_loss: 3.231626510620117
training step: 57463, total_loss: 4.678150653839111
training step: 57464, total_loss: 4.019356727600098
training step: 57465, total_loss: 4.378191947937012
training step: 57466, total_loss: 4.551344871520996
training step: 57467, total_loss: 4.767094612121582
training step: 57468, total_loss: 4.277907371520996
training step: 57469, total_loss: 2.943248748779297
training step: 57470, total_loss: 3.775197982788086
training step: 57471, total_loss: 5.526614189147949
training step: 57472, total_loss: 4.82602071762085
training step: 57473, total_loss: 5.111785888671875
training step: 57474, total_loss: 4.172601699829102
training step: 57475, total_loss: 2.9443092346191406
training step: 57476, total_loss: 5.234649658203125
training step: 57477, total_loss: 4.220671653747559
training step: 57478, total_loss: 5.321683883666992
training step: 57479, total_loss: 4.923326015472412
training step: 57480, total_loss: 3.1216235160827637
training step: 57481, total_loss: 4.6993842124938965
training step: 57482, total_loss: 4.8498125076293945
training step: 57483, total_loss: 4.356151580810547
training step: 57484, total_loss: 2.9156527519226074
training step: 57485, total_loss: 4.252896308898926
training step: 57486, total_loss: 4.214034080505371
training step: 57487, total_loss: 3.627199172973633
training step: 57488, total_loss: 4.041583061218262
training step: 57489, total_loss: 4.927942276000977
training step: 57490, total_loss: 5.057582855224609
training step: 57491, total_loss: 1.3949720859527588
training step: 57492, total_loss: 3.2454140186309814
training step: 57493, total_loss: 3.5614423751831055
training step: 57494, total_loss: 5.777278423309326
training step: 57495, total_loss: 5.474903106689453
training step: 57496, total_loss: 4.762665748596191
training step: 57497, total_loss: 4.767631530761719
training step: 57498, total_loss: 2.855090856552124
training step: 57499, total_loss: 4.726641654968262
training step: 57500, total_loss: 5.158345699310303
training step: 57501, total_loss: 1.3092631101608276
training step: 57502, total_loss: 4.385558605194092
training step: 57503, total_loss: 5.0530571937561035
training step: 57504, total_loss: 5.191591739654541
training step: 57505, total_loss: 4.20873498916626
training step: 57506, total_loss: 3.7921175956726074
training step: 57507, total_loss: 4.781280517578125
training step: 57508, total_loss: 3.103464126586914
training step: 57509, total_loss: 4.626028060913086
training step: 57510, total_loss: 4.61428165435791
training step: 57511, total_loss: 5.1240925788879395
training step: 57512, total_loss: 4.4915642738342285
training step: 57513, total_loss: 5.428782939910889
training step: 57514, total_loss: 4.296027183532715
training step: 57515, total_loss: 5.537906646728516
training step: 57516, total_loss: 2.5803146362304688
training step: 57517, total_loss: 5.1732683181762695
training step: 57518, total_loss: 3.8122620582580566
training step: 57519, total_loss: 5.475674629211426
training step: 57520, total_loss: 5.17933464050293
training step: 57521, total_loss: 6.0530171394348145
training step: 57522, total_loss: 4.44243860244751
training step: 57523, total_loss: 3.276916027069092
training step: 57524, total_loss: 3.8773622512817383
training step: 57525, total_loss: 4.03863525390625
training step: 57526, total_loss: 3.267479419708252
training step: 57527, total_loss: 4.35362434387207
training step: 57528, total_loss: 5.805365562438965
training step: 57529, total_loss: 3.7567901611328125
training step: 57530, total_loss: 4.768751621246338
training step: 57531, total_loss: 4.60117769241333
training step: 57532, total_loss: 2.54437255859375
training step: 57533, total_loss: 4.737563133239746
training step: 57534, total_loss: 3.8737363815307617
training step: 57535, total_loss: 2.8303236961364746
training step: 57536, total_loss: 5.521598815917969
training step: 57537, total_loss: 4.569826126098633
training step: 57538, total_loss: 5.460235595703125
training step: 57539, total_loss: 2.3992061614990234
training step: 57540, total_loss: 4.463502883911133
training step: 57541, total_loss: 4.44779109954834
training step: 57542, total_loss: 4.9049072265625
training step: 57543, total_loss: 3.1382827758789062
training step: 57544, total_loss: 4.41924524307251
training step: 57545, total_loss: 5.734874725341797
training step: 57546, total_loss: 4.087398529052734
training step: 57547, total_loss: 2.5346803665161133
training step: 57548, total_loss: 1.2537882328033447
training step: 57549, total_loss: 6.598492622375488
training step: 57550, total_loss: 4.736239433288574
training step: 57551, total_loss: 4.927363872528076
training step: 57552, total_loss: 3.43603253364563
training step: 57553, total_loss: 4.499279975891113
training step: 57554, total_loss: 3.5768866539001465
training step: 57555, total_loss: 4.3433122634887695
training step: 57556, total_loss: 5.376994609832764
training step: 57557, total_loss: 3.435351610183716
training step: 57558, total_loss: 4.539786338806152
training step: 57559, total_loss: 2.815310001373291
training step: 57560, total_loss: 4.779345989227295
training step: 57561, total_loss: 6.2154221534729
training step: 57562, total_loss: 3.5358211994171143
training step: 57563, total_loss: 6.695993423461914
training step: 57564, total_loss: 3.382338047027588
training step: 57565, total_loss: 4.472925186157227
training step: 57566, total_loss: 4.636880874633789
training step: 57567, total_loss: 3.8475289344787598
training step: 57568, total_loss: 3.9428954124450684
training step: 57569, total_loss: 2.954893112182617
training step: 57570, total_loss: 4.60909366607666
training step: 57571, total_loss: 4.075065612792969
training step: 57572, total_loss: 5.368884086608887
training step: 57573, total_loss: 5.377207279205322
training step: 57574, total_loss: 5.5526227951049805
training step: 57575, total_loss: 4.982168197631836
training step: 57576, total_loss: 5.8057355880737305
training step: 57577, total_loss: 0.8823828101158142
training step: 57578, total_loss: 5.102292060852051
training step: 57579, total_loss: 5.209199905395508
training step: 57580, total_loss: 4.2545013427734375
training step: 57581, total_loss: 2.3369436264038086
training step: 57582, total_loss: 5.7966814041137695
training step: 57583, total_loss: 5.511379241943359
training step: 57584, total_loss: 5.073659420013428
training step: 57585, total_loss: 4.096168518066406
training step: 57586, total_loss: 4.20075798034668
training step: 57587, total_loss: 3.9088335037231445
training step: 57588, total_loss: 5.54194450378418
training step: 57589, total_loss: 5.198526382446289
training step: 57590, total_loss: 4.312864303588867
training step: 57591, total_loss: 4.706218719482422
training step: 57592, total_loss: 5.2060112953186035
training step: 57593, total_loss: 4.5498046875
training step: 57594, total_loss: 3.218353748321533
training step: 57595, total_loss: 5.018218040466309
training step: 57596, total_loss: 4.7635178565979
training step: 57597, total_loss: 4.5601701736450195
training step: 57598, total_loss: 5.866905212402344
training step: 57599, total_loss: 3.4977879524230957
training step: 57600, total_loss: 5.031313419342041
training step: 57601, total_loss: 4.559414863586426
training step: 57602, total_loss: 4.848644256591797
training step: 57603, total_loss: 4.004996299743652
training step: 57604, total_loss: 3.9063644409179688
training step: 57605, total_loss: 2.8955509662628174
training step: 57606, total_loss: 4.3006134033203125
training step: 57607, total_loss: 3.4856839179992676
training step: 57608, total_loss: 4.627793312072754
training step: 57609, total_loss: 6.592807769775391
training step: 57610, total_loss: 4.206079483032227
training step: 57611, total_loss: 4.21478271484375
training step: 57612, total_loss: 4.83741569519043
training step: 57613, total_loss: 5.5132365226745605
training step: 57614, total_loss: 4.7903056144714355
training step: 57615, total_loss: 2.9038777351379395
training step: 57616, total_loss: 5.811176300048828
training step: 57617, total_loss: 4.856225967407227
training step: 57618, total_loss: 5.029648780822754
training step: 57619, total_loss: 3.4796066284179688
training step: 57620, total_loss: 3.259467124938965
training step: 57621, total_loss: 4.162278652191162
training step: 57622, total_loss: 4.9508233070373535
training step: 57623, total_loss: 3.461909055709839
training step: 57624, total_loss: 5.881091117858887
training step: 57625, total_loss: 5.283807754516602
training step: 57626, total_loss: 3.9746780395507812
training step: 57627, total_loss: 4.829599857330322
training step: 57628, total_loss: 4.249714374542236
training step: 57629, total_loss: 4.436870098114014
training step: 57630, total_loss: 4.736433982849121
training step: 57631, total_loss: 4.7049055099487305
training step: 57632, total_loss: 5.73372745513916
training step: 57633, total_loss: 2.929257869720459
training step: 57634, total_loss: 4.7597784996032715
training step: 57635, total_loss: 4.241905212402344
training step: 57636, total_loss: 3.892409324645996
training step: 57637, total_loss: 4.3467559814453125
training step: 57638, total_loss: 4.8572492599487305
training step: 57639, total_loss: 4.669482707977295
training step: 57640, total_loss: 4.006954669952393
training step: 57641, total_loss: 4.676207542419434
training step: 57642, total_loss: 4.649331092834473
training step: 57643, total_loss: 5.202205657958984
training step: 57644, total_loss: 5.205124378204346
training step: 57645, total_loss: 3.945849657058716
training step: 57646, total_loss: 3.133030414581299
training step: 57647, total_loss: 4.752808570861816
training step: 57648, total_loss: 3.2430977821350098
training step: 57649, total_loss: 3.2956743240356445
training step: 57650, total_loss: 4.226714134216309
training step: 57651, total_loss: 3.236469268798828
training step: 57652, total_loss: 0.986743688583374
training step: 57653, total_loss: 4.393426895141602
training step: 57654, total_loss: 3.973201036453247
training step: 57655, total_loss: 4.485488414764404
training step: 57656, total_loss: 3.993405818939209
training step: 57657, total_loss: 4.72329044342041
training step: 57658, total_loss: 5.106842041015625
training step: 57659, total_loss: 4.981357574462891
training step: 57660, total_loss: 4.6973700523376465
training step: 57661, total_loss: 2.230252981185913
training step: 57662, total_loss: 3.7599074840545654
training step: 57663, total_loss: 4.779041767120361
training step: 57664, total_loss: 3.5404889583587646
training step: 57665, total_loss: 4.065776824951172
training step: 57666, total_loss: 3.107863664627075
training step: 57667, total_loss: 4.410464286804199
training step: 57668, total_loss: 4.263247966766357
training step: 57669, total_loss: 4.719907760620117
training step: 57670, total_loss: 4.613758563995361
training step: 57671, total_loss: 3.4951589107513428
training step: 57672, total_loss: 3.5407299995422363
training step: 57673, total_loss: 4.619564056396484
training step: 57674, total_loss: 3.7391304969787598
training step: 57675, total_loss: 3.028730630874634
training step: 57676, total_loss: 4.3619279861450195
training step: 57677, total_loss: 3.867739200592041
training step: 57678, total_loss: 2.513155937194824
training step: 57679, total_loss: 4.522652626037598
training step: 57680, total_loss: 5.529357433319092
training step: 57681, total_loss: 2.833566665649414
training step: 57682, total_loss: 4.601409912109375
training step: 57683, total_loss: 5.962177753448486
training step: 57684, total_loss: 4.0658159255981445
training step: 57685, total_loss: 4.228336334228516
training step: 57686, total_loss: 4.682826519012451
training step: 57687, total_loss: 3.855419635772705
training step: 57688, total_loss: 3.895397901535034
training step: 57689, total_loss: 4.209261894226074
training step: 57690, total_loss: 4.9004340171813965
training step: 57691, total_loss: 4.2518486976623535
training step: 57692, total_loss: 4.633023262023926
training step: 57693, total_loss: 4.102468490600586
training step: 57694, total_loss: 3.1468987464904785
training step: 57695, total_loss: 4.671011924743652
training step: 57696, total_loss: 4.515844345092773
training step: 57697, total_loss: 5.202799320220947
training step: 57698, total_loss: 4.464761734008789
training step: 57699, total_loss: 4.1887617111206055
training step: 57700, total_loss: 4.31477165222168
training step: 57701, total_loss: 1.0998600721359253
training step: 57702, total_loss: 3.4961001873016357
training step: 57703, total_loss: 3.2814278602600098
training step: 57704, total_loss: 4.57707405090332
training step: 57705, total_loss: 3.7477269172668457
training step: 57706, total_loss: 3.581397533416748
training step: 57707, total_loss: 2.6679556369781494
training step: 57708, total_loss: 5.334277153015137
training step: 57709, total_loss: 5.681333541870117
training step: 57710, total_loss: 4.002094745635986
training step: 57711, total_loss: 2.7070224285125732
training step: 57712, total_loss: 4.262552261352539
training step: 57713, total_loss: 0.9343810677528381
training step: 57714, total_loss: 5.604928016662598
training step: 57715, total_loss: 3.6867520809173584
training step: 57716, total_loss: 4.975493431091309
training step: 57717, total_loss: 4.044601917266846
training step: 57718, total_loss: 4.205684661865234
training step: 57719, total_loss: 4.580167293548584
training step: 57720, total_loss: 4.768540382385254
training step: 57721, total_loss: 3.4563629627227783
training step: 57722, total_loss: 3.4345381259918213
training step: 57723, total_loss: 1.0776034593582153
training step: 57724, total_loss: 3.1336755752563477
training step: 57725, total_loss: 5.869445323944092
training step: 57726, total_loss: 3.6462793350219727
training step: 57727, total_loss: 4.375761985778809
training step: 57728, total_loss: 4.668645858764648
training step: 57729, total_loss: 4.479598522186279
training step: 57730, total_loss: 3.4874424934387207
training step: 57731, total_loss: 6.669460773468018
training step: 57732, total_loss: 4.120102882385254
training step: 57733, total_loss: 3.4896504878997803
training step: 57734, total_loss: 3.990920305252075
training step: 57735, total_loss: 4.190389156341553
training step: 57736, total_loss: 5.146204948425293
training step: 57737, total_loss: 4.43062162399292
training step: 57738, total_loss: 5.033174514770508
training step: 57739, total_loss: 4.259402751922607
training step: 57740, total_loss: 4.847806930541992
training step: 57741, total_loss: 5.1549272537231445
training step: 57742, total_loss: 4.586328506469727
training step: 57743, total_loss: 4.120521545410156
training step: 57744, total_loss: 3.924294948577881
training step: 57745, total_loss: 3.5036256313323975
training step: 57746, total_loss: 2.891608238220215
training step: 57747, total_loss: 4.388373374938965
training step: 57748, total_loss: 4.007812023162842
training step: 57749, total_loss: 4.351848125457764
training step: 57750, total_loss: 4.995421409606934
training step: 57751, total_loss: 2.9710302352905273
training step: 57752, total_loss: 1.209299087524414
training step: 57753, total_loss: 5.288599967956543
training step: 57754, total_loss: 5.4266533851623535
training step: 57755, total_loss: 6.506457328796387
training step: 57756, total_loss: 3.6145315170288086
training step: 57757, total_loss: 3.8081512451171875
training step: 57758, total_loss: 4.7869367599487305
training step: 57759, total_loss: 1.009279489517212
training step: 57760, total_loss: 3.8322324752807617
training step: 57761, total_loss: 2.465226173400879
training step: 57762, total_loss: 6.449763298034668
training step: 57763, total_loss: 5.825049877166748
training step: 57764, total_loss: 5.804812431335449
training step: 57765, total_loss: 4.332339763641357
training step: 57766, total_loss: 3.9382457733154297
training step: 57767, total_loss: 2.9533190727233887
training step: 57768, total_loss: 3.839677333831787
training step: 57769, total_loss: 3.756061315536499
training step: 57770, total_loss: 2.627676248550415
training step: 57771, total_loss: 4.927545070648193
training step: 57772, total_loss: 4.851175308227539
training step: 57773, total_loss: 3.4161016941070557
training step: 57774, total_loss: 3.5755205154418945
training step: 57775, total_loss: 4.052376747131348
training step: 57776, total_loss: 4.557046890258789
training step: 57777, total_loss: 5.285007476806641
training step: 57778, total_loss: 4.207626819610596
training step: 57779, total_loss: 4.597494125366211
training step: 57780, total_loss: 5.387434959411621
training step: 57781, total_loss: 6.603094577789307
training step: 57782, total_loss: 4.840463161468506
training step: 57783, total_loss: 5.574985027313232
training step: 57784, total_loss: 4.275941848754883
training step: 57785, total_loss: 3.9536614418029785
training step: 57786, total_loss: 5.205502033233643
training step: 57787, total_loss: 4.208710670471191
training step: 57788, total_loss: 3.898159980773926
training step: 57789, total_loss: 3.2179107666015625
training step: 57790, total_loss: 6.0539445877075195
training step: 57791, total_loss: 3.620448112487793
training step: 57792, total_loss: 2.459247589111328
training step: 57793, total_loss: 5.902599334716797
training step: 57794, total_loss: 4.829471588134766
training step: 57795, total_loss: 3.706101417541504
training step: 57796, total_loss: 5.063668251037598
training step: 57797, total_loss: 3.9863452911376953
training step: 57798, total_loss: 4.161084175109863
training step: 57799, total_loss: 2.786372184753418
training step: 57800, total_loss: 3.9441776275634766
training step: 57801, total_loss: 3.576754570007324
training step: 57802, total_loss: 4.595245361328125
training step: 57803, total_loss: 2.89505672454834
training step: 57804, total_loss: 4.791999816894531
training step: 57805, total_loss: 4.599086761474609
training step: 57806, total_loss: 3.9478094577789307
training step: 57807, total_loss: 3.761528491973877
training step: 57808, total_loss: 5.008821487426758
training step: 57809, total_loss: 5.335576057434082
training step: 57810, total_loss: 3.4644079208374023
training step: 57811, total_loss: 4.329698085784912
training step: 57812, total_loss: 4.864086151123047
training step: 57813, total_loss: 3.2594165802001953
training step: 57814, total_loss: 6.720093727111816
training step: 57815, total_loss: 4.2439656257629395
training step: 57816, total_loss: 4.744670391082764
training step: 57817, total_loss: 4.937311172485352
training step: 57818, total_loss: 5.842676639556885
training step: 57819, total_loss: 4.224376678466797
training step: 57820, total_loss: 4.592644691467285
training step: 57821, total_loss: 4.743995666503906
training step: 57822, total_loss: 4.018451690673828
training step: 57823, total_loss: 4.758779525756836
training step: 57824, total_loss: 2.8518505096435547
training step: 57825, total_loss: 4.8928446769714355
training step: 57826, total_loss: 6.870187759399414
training step: 57827, total_loss: 3.924792766571045
training step: 57828, total_loss: 3.8246984481811523
training step: 57829, total_loss: 4.908376693725586
training step: 57830, total_loss: 4.324462890625
training step: 57831, total_loss: 5.619847297668457
training step: 57832, total_loss: 5.1378350257873535
training step: 57833, total_loss: 3.5829272270202637
training step: 57834, total_loss: 5.977790832519531
training step: 57835, total_loss: 2.5529847145080566
training step: 57836, total_loss: 4.6420087814331055
training step: 57837, total_loss: 5.2174506187438965
training step: 57838, total_loss: 4.706272125244141
training step: 57839, total_loss: 4.10343074798584
training step: 57840, total_loss: 3.84081768989563
training step: 57841, total_loss: 4.424543380737305
training step: 57842, total_loss: 3.2288832664489746
training step: 57843, total_loss: 5.143190860748291
training step: 57844, total_loss: 6.548391342163086
training step: 57845, total_loss: 5.870156288146973
training step: 57846, total_loss: 5.087860584259033
training step: 57847, total_loss: 4.133826732635498
training step: 57848, total_loss: 4.588627815246582
training step: 57849, total_loss: 2.385528564453125
training step: 57850, total_loss: 6.849100112915039
training step: 57851, total_loss: 4.767095565795898
training step: 57852, total_loss: 3.676300048828125
training step: 57853, total_loss: 4.10284948348999
training step: 57854, total_loss: 3.9511451721191406
training step: 57855, total_loss: 3.7726495265960693
training step: 57856, total_loss: 4.240908622741699
training step: 57857, total_loss: 5.053542613983154
training step: 57858, total_loss: 5.521213531494141
training step: 57859, total_loss: 4.387831687927246
training step: 57860, total_loss: 0.9168578386306763
training step: 57861, total_loss: 3.4374136924743652
training step: 57862, total_loss: 4.958008766174316
training step: 57863, total_loss: 5.244793891906738
training step: 57864, total_loss: 4.718170166015625
training step: 57865, total_loss: 2.5630764961242676
training step: 57866, total_loss: 4.148106098175049
training step: 57867, total_loss: 3.8186192512512207
training step: 57868, total_loss: 4.446759223937988
training step: 57869, total_loss: 4.286983489990234
training step: 57870, total_loss: 5.134034633636475
training step: 57871, total_loss: 4.720552444458008
training step: 57872, total_loss: 4.45893669128418
training step: 57873, total_loss: 5.778189659118652
training step: 57874, total_loss: 4.975598335266113
training step: 57875, total_loss: 7.419553756713867
training step: 57876, total_loss: 4.71710205078125
training step: 57877, total_loss: 3.1556155681610107
training step: 57878, total_loss: 2.4191696643829346
training step: 57879, total_loss: 5.552970886230469
training step: 57880, total_loss: 0.8900405168533325
training step: 57881, total_loss: 3.8146541118621826
training step: 57882, total_loss: 4.307878017425537
training step: 57883, total_loss: 4.8013458251953125
training step: 57884, total_loss: 4.433322906494141
training step: 57885, total_loss: 1.0689678192138672
training step: 57886, total_loss: 4.321852684020996
training step: 57887, total_loss: 2.892091751098633
training step: 57888, total_loss: 5.648736476898193
training step: 57889, total_loss: 3.682584762573242
training step: 57890, total_loss: 5.54547119140625
training step: 57891, total_loss: 5.19594669342041
training step: 57892, total_loss: 4.256962776184082
training step: 57893, total_loss: 4.635793209075928
training step: 57894, total_loss: 5.987085342407227
training step: 57895, total_loss: 3.723283529281616
training step: 57896, total_loss: 5.256525993347168
training step: 57897, total_loss: 3.305621385574341
training step: 57898, total_loss: 4.510847091674805
training step: 57899, total_loss: 3.794858694076538
training step: 57900, total_loss: 4.440594673156738
training step: 57901, total_loss: 5.591768264770508
training step: 57902, total_loss: 4.615720748901367
training step: 57903, total_loss: 2.899401903152466
training step: 57904, total_loss: 5.753228187561035
training step: 57905, total_loss: 4.55534029006958
training step: 57906, total_loss: 4.506974697113037
training step: 57907, total_loss: 4.261333465576172
training step: 57908, total_loss: 1.8631374835968018
training step: 57909, total_loss: 3.8326172828674316
training step: 57910, total_loss: 3.4825210571289062
training step: 57911, total_loss: 2.4462618827819824
training step: 57912, total_loss: 3.4847209453582764
training step: 57913, total_loss: 2.6116139888763428
training step: 57914, total_loss: 5.404139995574951
training step: 57915, total_loss: 4.935823440551758
training step: 57916, total_loss: 5.1405839920043945
training step: 57917, total_loss: 4.900199890136719
training step: 57918, total_loss: 3.5511293411254883
training step: 57919, total_loss: 4.396110534667969
training step: 57920, total_loss: 5.084432601928711
training step: 57921, total_loss: 2.561169147491455
training step: 57922, total_loss: 3.6328418254852295
training step: 57923, total_loss: 4.648202896118164
training step: 57924, total_loss: 5.995706558227539
training step: 57925, total_loss: 3.1941161155700684
training step: 57926, total_loss: 5.251410484313965
training step: 57927, total_loss: 4.085337162017822
training step: 57928, total_loss: 6.131970405578613
training step: 57929, total_loss: 3.7629966735839844
training step: 57930, total_loss: 5.7235002517700195
training step: 57931, total_loss: 4.208041667938232
training step: 57932, total_loss: 3.461202383041382
training step: 57933, total_loss: 2.6572585105895996
training step: 57934, total_loss: 0.8651034235954285
training step: 57935, total_loss: 5.507271766662598
training step: 57936, total_loss: 4.071761608123779
training step: 57937, total_loss: 3.9260878562927246
training step: 57938, total_loss: 4.439552307128906
training step: 57939, total_loss: 5.3564910888671875
training step: 57940, total_loss: 4.600254535675049
training step: 57941, total_loss: 7.014896392822266
training step: 57942, total_loss: 3.429368019104004
training step: 57943, total_loss: 3.85200834274292
training step: 57944, total_loss: 5.639884948730469
training step: 57945, total_loss: 4.998988628387451
training step: 57946, total_loss: 2.9370641708374023
training step: 57947, total_loss: 4.754790306091309
training step: 57948, total_loss: 4.460619926452637
training step: 57949, total_loss: 5.08411979675293
training step: 57950, total_loss: 5.840994358062744
training step: 57951, total_loss: 4.977046489715576
training step: 57952, total_loss: 1.1644498109817505
training step: 57953, total_loss: 3.850598096847534
training step: 57954, total_loss: 5.401948928833008
training step: 57955, total_loss: 4.3074493408203125
training step: 57956, total_loss: 3.766103506088257
training step: 57957, total_loss: 2.732140064239502
training step: 57958, total_loss: 3.8722548484802246
training step: 57959, total_loss: 4.86652135848999
training step: 57960, total_loss: 4.156580924987793
training step: 57961, total_loss: 4.889263153076172
training step: 57962, total_loss: 5.553025245666504
training step: 57963, total_loss: 2.7926273345947266
training step: 57964, total_loss: 4.719275951385498
training step: 57965, total_loss: 4.0424346923828125
training step: 57966, total_loss: 3.4302916526794434
training step: 57967, total_loss: 3.156250476837158INFO:tensorflow:Writing predictions to: residual_output/predictions_58000.json
INFO:tensorflow:Writing nbest to: residual_output/nbest_predictions_58000.json

training step: 57968, total_loss: 4.886823654174805
training step: 57969, total_loss: 4.948724746704102
training step: 57970, total_loss: 4.714484214782715
training step: 57971, total_loss: 6.048220634460449
training step: 57972, total_loss: 3.308957099914551
training step: 57973, total_loss: 3.083218574523926
training step: 57974, total_loss: 4.4936628341674805
training step: 57975, total_loss: 3.4541773796081543
training step: 57976, total_loss: 3.41977596282959
training step: 57977, total_loss: 3.7304911613464355
training step: 57978, total_loss: 6.084065914154053
training step: 57979, total_loss: 2.984549045562744
training step: 57980, total_loss: 5.334908485412598
training step: 57981, total_loss: 5.8452558517456055
training step: 57982, total_loss: 4.931855201721191
training step: 57983, total_loss: 4.143343925476074
training step: 57984, total_loss: 3.5599350929260254
training step: 57985, total_loss: 4.163263320922852
training step: 57986, total_loss: 2.3706507682800293
training step: 57987, total_loss: 4.1095404624938965
training step: 57988, total_loss: 4.204559803009033
training step: 57989, total_loss: 4.596574783325195
training step: 57990, total_loss: 5.342862129211426
training step: 57991, total_loss: 5.20042610168457
training step: 57992, total_loss: 3.7061686515808105
training step: 57993, total_loss: 3.9217934608459473
training step: 57994, total_loss: 4.959437370300293
training step: 57995, total_loss: 4.427518844604492
training step: 57996, total_loss: 4.165306568145752
training step: 57997, total_loss: 3.307126045227051
training step: 57998, total_loss: 5.1337714195251465
training step: 57999, total_loss: 4.45793342590332
training step: 58000, total_loss: 4.344893455505371
epoch finished! shuffle=False
evaluation: 58000, total_loss: 2.32199764251709, f1: 23.51799472420491, followup: 18.378213905370455, yesno: 1.6126578426897915, heq: 23.018408641411835, dheq: 0.6

Model saved in path residual_output//model_58000.ckpt
